{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6000711828212125,
  "eval_steps": 500,
  "global_step": 20232,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014829754419266816,
      "grad_norm": 3.379183292388916,
      "learning_rate": 1.9703404911614665e-05,
      "loss": 1.384,
      "step": 500
    },
    {
      "epoch": 0.029659508838533633,
      "grad_norm": 4.512692451477051,
      "learning_rate": 1.940680982322933e-05,
      "loss": 1.3113,
      "step": 1000
    },
    {
      "epoch": 0.04448926325780045,
      "grad_norm": 3.9332263469696045,
      "learning_rate": 1.9110214734843993e-05,
      "loss": 1.2797,
      "step": 1500
    },
    {
      "epoch": 0.059319017677067265,
      "grad_norm": 4.316258430480957,
      "learning_rate": 1.8813619646458657e-05,
      "loss": 1.2417,
      "step": 2000
    },
    {
      "epoch": 0.07414877209633408,
      "grad_norm": 3.1469743251800537,
      "learning_rate": 1.851702455807332e-05,
      "loss": 1.2491,
      "step": 2500
    },
    {
      "epoch": 0.0889785265156009,
      "grad_norm": 3.3607499599456787,
      "learning_rate": 1.8220429469687984e-05,
      "loss": 1.2101,
      "step": 3000
    },
    {
      "epoch": 0.10380828093486771,
      "grad_norm": 3.8713254928588867,
      "learning_rate": 1.7923834381302648e-05,
      "loss": 1.2121,
      "step": 3500
    },
    {
      "epoch": 0.11863803535413453,
      "grad_norm": 3.9861958026885986,
      "learning_rate": 1.762723929291731e-05,
      "loss": 1.1948,
      "step": 4000
    },
    {
      "epoch": 0.13346778977340135,
      "grad_norm": 3.6647212505340576,
      "learning_rate": 1.7330644204531975e-05,
      "loss": 1.1911,
      "step": 4500
    },
    {
      "epoch": 0.14829754419266816,
      "grad_norm": 3.997205972671509,
      "learning_rate": 1.703404911614664e-05,
      "loss": 1.1787,
      "step": 5000
    },
    {
      "epoch": 0.16312729861193498,
      "grad_norm": 3.149146795272827,
      "learning_rate": 1.6737454027761303e-05,
      "loss": 1.1596,
      "step": 5500
    },
    {
      "epoch": 0.1779570530312018,
      "grad_norm": 3.8712313175201416,
      "learning_rate": 1.6440858939375966e-05,
      "loss": 1.1716,
      "step": 6000
    },
    {
      "epoch": 0.1927868074504686,
      "grad_norm": 3.1637535095214844,
      "learning_rate": 1.614426385099063e-05,
      "loss": 1.1506,
      "step": 6500
    },
    {
      "epoch": 0.20761656186973543,
      "grad_norm": 4.1643571853637695,
      "learning_rate": 1.5847668762605294e-05,
      "loss": 1.1352,
      "step": 7000
    },
    {
      "epoch": 0.22244631628900224,
      "grad_norm": 4.088586330413818,
      "learning_rate": 1.5551073674219958e-05,
      "loss": 1.1099,
      "step": 7500
    },
    {
      "epoch": 0.23727607070826906,
      "grad_norm": 5.110473155975342,
      "learning_rate": 1.525447858583462e-05,
      "loss": 1.1116,
      "step": 8000
    },
    {
      "epoch": 0.2521058251275359,
      "grad_norm": 4.16934871673584,
      "learning_rate": 1.4957883497449283e-05,
      "loss": 1.1263,
      "step": 8500
    },
    {
      "epoch": 0.2669355795468027,
      "grad_norm": 5.462007522583008,
      "learning_rate": 1.4661288409063947e-05,
      "loss": 1.1085,
      "step": 9000
    },
    {
      "epoch": 0.2817653339660695,
      "grad_norm": 4.3284993171691895,
      "learning_rate": 1.436469332067861e-05,
      "loss": 1.1018,
      "step": 9500
    },
    {
      "epoch": 0.2965950883853363,
      "grad_norm": 3.4224090576171875,
      "learning_rate": 1.4068098232293275e-05,
      "loss": 1.0648,
      "step": 10000
    },
    {
      "epoch": 0.31142484280460314,
      "grad_norm": 3.408519744873047,
      "learning_rate": 1.3771503143907938e-05,
      "loss": 1.0733,
      "step": 10500
    },
    {
      "epoch": 0.32625459722386996,
      "grad_norm": 4.667629241943359,
      "learning_rate": 1.3474908055522602e-05,
      "loss": 1.0706,
      "step": 11000
    },
    {
      "epoch": 0.3410843516431368,
      "grad_norm": 4.122029781341553,
      "learning_rate": 1.3178312967137266e-05,
      "loss": 1.0634,
      "step": 11500
    },
    {
      "epoch": 0.3559141060624036,
      "grad_norm": 7.151048183441162,
      "learning_rate": 1.288171787875193e-05,
      "loss": 1.0359,
      "step": 12000
    },
    {
      "epoch": 0.3707438604816704,
      "grad_norm": 5.733280181884766,
      "learning_rate": 1.2585122790366593e-05,
      "loss": 1.0464,
      "step": 12500
    },
    {
      "epoch": 0.3855736149009372,
      "grad_norm": 3.7180819511413574,
      "learning_rate": 1.2288527701981257e-05,
      "loss": 1.0343,
      "step": 13000
    },
    {
      "epoch": 0.40040336932020404,
      "grad_norm": 5.08220911026001,
      "learning_rate": 1.199193261359592e-05,
      "loss": 1.0365,
      "step": 13500
    },
    {
      "epoch": 0.41523312373947086,
      "grad_norm": 5.711700916290283,
      "learning_rate": 1.1695337525210584e-05,
      "loss": 1.0201,
      "step": 14000
    },
    {
      "epoch": 0.43006287815873767,
      "grad_norm": 8.384225845336914,
      "learning_rate": 1.1398742436825248e-05,
      "loss": 1.0105,
      "step": 14500
    },
    {
      "epoch": 0.4448926325780045,
      "grad_norm": 4.6636738777160645,
      "learning_rate": 1.1102147348439912e-05,
      "loss": 1.0149,
      "step": 15000
    },
    {
      "epoch": 0.4597223869972713,
      "grad_norm": 5.441359043121338,
      "learning_rate": 1.0805552260054576e-05,
      "loss": 1.0093,
      "step": 15500
    },
    {
      "epoch": 0.4745521414165381,
      "grad_norm": 4.598884105682373,
      "learning_rate": 1.0508957171669238e-05,
      "loss": 0.9901,
      "step": 16000
    },
    {
      "epoch": 0.48938189583580494,
      "grad_norm": 4.329555511474609,
      "learning_rate": 1.0212362083283901e-05,
      "loss": 0.9971,
      "step": 16500
    },
    {
      "epoch": 0.5042116502550718,
      "grad_norm": 4.971261501312256,
      "learning_rate": 9.915766994898565e-06,
      "loss": 0.9982,
      "step": 17000
    },
    {
      "epoch": 0.5190414046743386,
      "grad_norm": 4.851034641265869,
      "learning_rate": 9.619171906513229e-06,
      "loss": 0.9653,
      "step": 17500
    },
    {
      "epoch": 0.5338711590936054,
      "grad_norm": 4.549441814422607,
      "learning_rate": 9.322576818127893e-06,
      "loss": 0.9704,
      "step": 18000
    },
    {
      "epoch": 0.5487009135128722,
      "grad_norm": 4.795586109161377,
      "learning_rate": 9.025981729742556e-06,
      "loss": 0.9799,
      "step": 18500
    },
    {
      "epoch": 0.563530667932139,
      "grad_norm": 6.149899482727051,
      "learning_rate": 8.72938664135722e-06,
      "loss": 0.9413,
      "step": 19000
    },
    {
      "epoch": 0.5783604223514058,
      "grad_norm": 6.2900495529174805,
      "learning_rate": 8.432791552971884e-06,
      "loss": 0.9364,
      "step": 19500
    },
    {
      "epoch": 0.5931901767706727,
      "grad_norm": 5.153733253479004,
      "learning_rate": 8.136196464586547e-06,
      "loss": 0.9358,
      "step": 20000
    }
  ],
  "logging_steps": 500,
  "max_steps": 33716,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 6744,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.668303110231818e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
