{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 33716,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014829754419266816,
      "grad_norm": 3.379183292388916,
      "learning_rate": 1.9703404911614665e-05,
      "loss": 1.384,
      "step": 500
    },
    {
      "epoch": 0.029659508838533633,
      "grad_norm": 4.512692451477051,
      "learning_rate": 1.940680982322933e-05,
      "loss": 1.3113,
      "step": 1000
    },
    {
      "epoch": 0.04448926325780045,
      "grad_norm": 3.9332263469696045,
      "learning_rate": 1.9110214734843993e-05,
      "loss": 1.2797,
      "step": 1500
    },
    {
      "epoch": 0.059319017677067265,
      "grad_norm": 4.316258430480957,
      "learning_rate": 1.8813619646458657e-05,
      "loss": 1.2417,
      "step": 2000
    },
    {
      "epoch": 0.07414877209633408,
      "grad_norm": 3.1469743251800537,
      "learning_rate": 1.851702455807332e-05,
      "loss": 1.2491,
      "step": 2500
    },
    {
      "epoch": 0.0889785265156009,
      "grad_norm": 3.3607499599456787,
      "learning_rate": 1.8220429469687984e-05,
      "loss": 1.2101,
      "step": 3000
    },
    {
      "epoch": 0.10380828093486771,
      "grad_norm": 3.8713254928588867,
      "learning_rate": 1.7923834381302648e-05,
      "loss": 1.2121,
      "step": 3500
    },
    {
      "epoch": 0.11863803535413453,
      "grad_norm": 3.9861958026885986,
      "learning_rate": 1.762723929291731e-05,
      "loss": 1.1948,
      "step": 4000
    },
    {
      "epoch": 0.13346778977340135,
      "grad_norm": 3.6647212505340576,
      "learning_rate": 1.7330644204531975e-05,
      "loss": 1.1911,
      "step": 4500
    },
    {
      "epoch": 0.14829754419266816,
      "grad_norm": 3.997205972671509,
      "learning_rate": 1.703404911614664e-05,
      "loss": 1.1787,
      "step": 5000
    },
    {
      "epoch": 0.16312729861193498,
      "grad_norm": 3.149146795272827,
      "learning_rate": 1.6737454027761303e-05,
      "loss": 1.1596,
      "step": 5500
    },
    {
      "epoch": 0.1779570530312018,
      "grad_norm": 3.8712313175201416,
      "learning_rate": 1.6440858939375966e-05,
      "loss": 1.1716,
      "step": 6000
    },
    {
      "epoch": 0.1927868074504686,
      "grad_norm": 3.1637535095214844,
      "learning_rate": 1.614426385099063e-05,
      "loss": 1.1506,
      "step": 6500
    },
    {
      "epoch": 0.20761656186973543,
      "grad_norm": 4.1643571853637695,
      "learning_rate": 1.5847668762605294e-05,
      "loss": 1.1352,
      "step": 7000
    },
    {
      "epoch": 0.22244631628900224,
      "grad_norm": 4.088586330413818,
      "learning_rate": 1.5551073674219958e-05,
      "loss": 1.1099,
      "step": 7500
    },
    {
      "epoch": 0.23727607070826906,
      "grad_norm": 5.110473155975342,
      "learning_rate": 1.525447858583462e-05,
      "loss": 1.1116,
      "step": 8000
    },
    {
      "epoch": 0.2521058251275359,
      "grad_norm": 4.16934871673584,
      "learning_rate": 1.4957883497449283e-05,
      "loss": 1.1263,
      "step": 8500
    },
    {
      "epoch": 0.2669355795468027,
      "grad_norm": 5.462007522583008,
      "learning_rate": 1.4661288409063947e-05,
      "loss": 1.1085,
      "step": 9000
    },
    {
      "epoch": 0.2817653339660695,
      "grad_norm": 4.3284993171691895,
      "learning_rate": 1.436469332067861e-05,
      "loss": 1.1018,
      "step": 9500
    },
    {
      "epoch": 0.2965950883853363,
      "grad_norm": 3.4224090576171875,
      "learning_rate": 1.4068098232293275e-05,
      "loss": 1.0648,
      "step": 10000
    },
    {
      "epoch": 0.31142484280460314,
      "grad_norm": 3.408519744873047,
      "learning_rate": 1.3771503143907938e-05,
      "loss": 1.0733,
      "step": 10500
    },
    {
      "epoch": 0.32625459722386996,
      "grad_norm": 4.667629241943359,
      "learning_rate": 1.3474908055522602e-05,
      "loss": 1.0706,
      "step": 11000
    },
    {
      "epoch": 0.3410843516431368,
      "grad_norm": 4.122029781341553,
      "learning_rate": 1.3178312967137266e-05,
      "loss": 1.0634,
      "step": 11500
    },
    {
      "epoch": 0.3559141060624036,
      "grad_norm": 7.151048183441162,
      "learning_rate": 1.288171787875193e-05,
      "loss": 1.0359,
      "step": 12000
    },
    {
      "epoch": 0.3707438604816704,
      "grad_norm": 5.733280181884766,
      "learning_rate": 1.2585122790366593e-05,
      "loss": 1.0464,
      "step": 12500
    },
    {
      "epoch": 0.3855736149009372,
      "grad_norm": 3.7180819511413574,
      "learning_rate": 1.2288527701981257e-05,
      "loss": 1.0343,
      "step": 13000
    },
    {
      "epoch": 0.40040336932020404,
      "grad_norm": 5.08220911026001,
      "learning_rate": 1.199193261359592e-05,
      "loss": 1.0365,
      "step": 13500
    },
    {
      "epoch": 0.41523312373947086,
      "grad_norm": 5.711700916290283,
      "learning_rate": 1.1695337525210584e-05,
      "loss": 1.0201,
      "step": 14000
    },
    {
      "epoch": 0.43006287815873767,
      "grad_norm": 8.384225845336914,
      "learning_rate": 1.1398742436825248e-05,
      "loss": 1.0105,
      "step": 14500
    },
    {
      "epoch": 0.4448926325780045,
      "grad_norm": 4.6636738777160645,
      "learning_rate": 1.1102147348439912e-05,
      "loss": 1.0149,
      "step": 15000
    },
    {
      "epoch": 0.4597223869972713,
      "grad_norm": 5.441359043121338,
      "learning_rate": 1.0805552260054576e-05,
      "loss": 1.0093,
      "step": 15500
    },
    {
      "epoch": 0.4745521414165381,
      "grad_norm": 4.598884105682373,
      "learning_rate": 1.0508957171669238e-05,
      "loss": 0.9901,
      "step": 16000
    },
    {
      "epoch": 0.48938189583580494,
      "grad_norm": 4.329555511474609,
      "learning_rate": 1.0212362083283901e-05,
      "loss": 0.9971,
      "step": 16500
    },
    {
      "epoch": 0.5042116502550718,
      "grad_norm": 4.971261501312256,
      "learning_rate": 9.915766994898565e-06,
      "loss": 0.9982,
      "step": 17000
    },
    {
      "epoch": 0.5190414046743386,
      "grad_norm": 4.851034641265869,
      "learning_rate": 9.619171906513229e-06,
      "loss": 0.9653,
      "step": 17500
    },
    {
      "epoch": 0.5338711590936054,
      "grad_norm": 4.549441814422607,
      "learning_rate": 9.322576818127893e-06,
      "loss": 0.9704,
      "step": 18000
    },
    {
      "epoch": 0.5487009135128722,
      "grad_norm": 4.795586109161377,
      "learning_rate": 9.025981729742556e-06,
      "loss": 0.9799,
      "step": 18500
    },
    {
      "epoch": 0.563530667932139,
      "grad_norm": 6.149899482727051,
      "learning_rate": 8.72938664135722e-06,
      "loss": 0.9413,
      "step": 19000
    },
    {
      "epoch": 0.5783604223514058,
      "grad_norm": 6.2900495529174805,
      "learning_rate": 8.432791552971884e-06,
      "loss": 0.9364,
      "step": 19500
    },
    {
      "epoch": 0.5931901767706727,
      "grad_norm": 5.153733253479004,
      "learning_rate": 8.136196464586547e-06,
      "loss": 0.9358,
      "step": 20000
    },
    {
      "epoch": 0.6080199311899395,
      "grad_norm": 5.514628887176514,
      "learning_rate": 7.83960137620121e-06,
      "loss": 0.9215,
      "step": 20500
    },
    {
      "epoch": 0.6228496856092063,
      "grad_norm": 5.577573299407959,
      "learning_rate": 7.543006287815874e-06,
      "loss": 0.9094,
      "step": 21000
    },
    {
      "epoch": 0.6376794400284731,
      "grad_norm": 5.109535217285156,
      "learning_rate": 7.246411199430538e-06,
      "loss": 0.9329,
      "step": 21500
    },
    {
      "epoch": 0.6525091944477399,
      "grad_norm": 5.526914596557617,
      "learning_rate": 6.9498161110452015e-06,
      "loss": 0.9194,
      "step": 22000
    },
    {
      "epoch": 0.6673389488670067,
      "grad_norm": 6.416020393371582,
      "learning_rate": 6.653221022659864e-06,
      "loss": 0.9206,
      "step": 22500
    },
    {
      "epoch": 0.6821687032862735,
      "grad_norm": 5.036457061767578,
      "learning_rate": 6.356625934274528e-06,
      "loss": 0.9035,
      "step": 23000
    },
    {
      "epoch": 0.6969984577055404,
      "grad_norm": 6.800718784332275,
      "learning_rate": 6.060030845889192e-06,
      "loss": 0.9262,
      "step": 23500
    },
    {
      "epoch": 0.7118282121248072,
      "grad_norm": 6.341760158538818,
      "learning_rate": 5.763435757503856e-06,
      "loss": 0.8907,
      "step": 24000
    },
    {
      "epoch": 0.726657966544074,
      "grad_norm": 7.680421352386475,
      "learning_rate": 5.466840669118519e-06,
      "loss": 0.9033,
      "step": 24500
    },
    {
      "epoch": 0.7414877209633408,
      "grad_norm": 7.442012310028076,
      "learning_rate": 5.170245580733183e-06,
      "loss": 0.8827,
      "step": 25000
    },
    {
      "epoch": 0.7563174753826076,
      "grad_norm": 7.030877113342285,
      "learning_rate": 4.873650492347848e-06,
      "loss": 0.9406,
      "step": 25500
    },
    {
      "epoch": 0.7711472298018744,
      "grad_norm": 6.510293960571289,
      "learning_rate": 4.5770554039625105e-06,
      "loss": 0.875,
      "step": 26000
    },
    {
      "epoch": 0.7859769842211413,
      "grad_norm": 6.340671539306641,
      "learning_rate": 4.280460315577174e-06,
      "loss": 0.8856,
      "step": 26500
    },
    {
      "epoch": 0.8008067386404081,
      "grad_norm": 7.137031078338623,
      "learning_rate": 3.983865227191838e-06,
      "loss": 0.8502,
      "step": 27000
    },
    {
      "epoch": 0.8156364930596749,
      "grad_norm": 5.863558769226074,
      "learning_rate": 3.6872701388065017e-06,
      "loss": 0.8504,
      "step": 27500
    },
    {
      "epoch": 0.8304662474789417,
      "grad_norm": 4.734676361083984,
      "learning_rate": 3.3906750504211654e-06,
      "loss": 0.891,
      "step": 28000
    },
    {
      "epoch": 0.8452960018982085,
      "grad_norm": 5.585346698760986,
      "learning_rate": 3.094079962035829e-06,
      "loss": 0.857,
      "step": 28500
    },
    {
      "epoch": 0.8601257563174753,
      "grad_norm": 6.396625995635986,
      "learning_rate": 2.797484873650493e-06,
      "loss": 0.8257,
      "step": 29000
    },
    {
      "epoch": 0.8749555107367422,
      "grad_norm": 5.978829860687256,
      "learning_rate": 2.5008897852651566e-06,
      "loss": 0.8494,
      "step": 29500
    },
    {
      "epoch": 0.889785265156009,
      "grad_norm": 6.5218424797058105,
      "learning_rate": 2.20429469687982e-06,
      "loss": 0.8177,
      "step": 30000
    },
    {
      "epoch": 0.9046150195752758,
      "grad_norm": 6.126716613769531,
      "learning_rate": 1.9076996084944837e-06,
      "loss": 0.8632,
      "step": 30500
    },
    {
      "epoch": 0.9194447739945426,
      "grad_norm": 6.76673698425293,
      "learning_rate": 1.6111045201091472e-06,
      "loss": 0.8292,
      "step": 31000
    },
    {
      "epoch": 0.9342745284138094,
      "grad_norm": 6.923488616943359,
      "learning_rate": 1.3145094317238107e-06,
      "loss": 0.8102,
      "step": 31500
    },
    {
      "epoch": 0.9491042828330762,
      "grad_norm": 5.7603440284729,
      "learning_rate": 1.0179143433384744e-06,
      "loss": 0.8439,
      "step": 32000
    },
    {
      "epoch": 0.9639340372523431,
      "grad_norm": 6.6822590827941895,
      "learning_rate": 7.213192549531381e-07,
      "loss": 0.8163,
      "step": 32500
    },
    {
      "epoch": 0.9787637916716099,
      "grad_norm": 6.366642475128174,
      "learning_rate": 4.247241665678017e-07,
      "loss": 0.8203,
      "step": 33000
    },
    {
      "epoch": 0.9935935460908767,
      "grad_norm": 7.764448165893555,
      "learning_rate": 1.281290781824653e-07,
      "loss": 0.84,
      "step": 33500
    }
  ],
  "logging_steps": 500,
  "max_steps": 33716,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 6744,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1112520149494661e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
