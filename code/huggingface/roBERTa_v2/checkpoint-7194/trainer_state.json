{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.200400467211747,
  "eval_steps": 500,
  "global_step": 7194,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016686133822793258,
      "grad_norm": 12.055155754089355,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 4.3695,
      "step": 10
    },
    {
      "epoch": 0.0033372267645586516,
      "grad_norm": 11.911678314208984,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 4.4665,
      "step": 20
    },
    {
      "epoch": 0.005005840146837978,
      "grad_norm": 7.000014781951904,
      "learning_rate": 3e-06,
      "loss": 2.8126,
      "step": 30
    },
    {
      "epoch": 0.006674453529117303,
      "grad_norm": 13.199590682983398,
      "learning_rate": 4.000000000000001e-06,
      "loss": 4.2464,
      "step": 40
    },
    {
      "epoch": 0.00834306691139663,
      "grad_norm": 14.029197692871094,
      "learning_rate": 5e-06,
      "loss": 4.1144,
      "step": 50
    },
    {
      "epoch": 0.010011680293675955,
      "grad_norm": 9.302464485168457,
      "learning_rate": 6e-06,
      "loss": 3.3256,
      "step": 60
    },
    {
      "epoch": 0.011680293675955281,
      "grad_norm": 15.014753341674805,
      "learning_rate": 7.000000000000001e-06,
      "loss": 2.4877,
      "step": 70
    },
    {
      "epoch": 0.013348907058234607,
      "grad_norm": 9.79970932006836,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.5089,
      "step": 80
    },
    {
      "epoch": 0.015017520440513932,
      "grad_norm": 13.779865264892578,
      "learning_rate": 9e-06,
      "loss": 3.2794,
      "step": 90
    },
    {
      "epoch": 0.01668613382279326,
      "grad_norm": 11.301551818847656,
      "learning_rate": 1e-05,
      "loss": 3.6684,
      "step": 100
    },
    {
      "epoch": 0.018354747205072585,
      "grad_norm": 12.95022201538086,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 2.6943,
      "step": 110
    },
    {
      "epoch": 0.02002336058735191,
      "grad_norm": 9.577805519104004,
      "learning_rate": 1.2e-05,
      "loss": 3.3026,
      "step": 120
    },
    {
      "epoch": 0.021691973969631236,
      "grad_norm": 6.582576751708984,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 3.1611,
      "step": 130
    },
    {
      "epoch": 0.023360587351910562,
      "grad_norm": 9.120842933654785,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 2.5691,
      "step": 140
    },
    {
      "epoch": 0.025029200734189887,
      "grad_norm": 1.7658172845840454,
      "learning_rate": 1.5e-05,
      "loss": 2.146,
      "step": 150
    },
    {
      "epoch": 0.026697814116469213,
      "grad_norm": 9.7316255569458,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.7907,
      "step": 160
    },
    {
      "epoch": 0.02836642749874854,
      "grad_norm": 17.165279388427734,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 2.0825,
      "step": 170
    },
    {
      "epoch": 0.030035040881027864,
      "grad_norm": 7.478819847106934,
      "learning_rate": 1.8e-05,
      "loss": 2.0492,
      "step": 180
    },
    {
      "epoch": 0.03170365426330719,
      "grad_norm": 7.041898727416992,
      "learning_rate": 1.9e-05,
      "loss": 1.4729,
      "step": 190
    },
    {
      "epoch": 0.03337226764558652,
      "grad_norm": 9.482068061828613,
      "learning_rate": 2e-05,
      "loss": 1.9531,
      "step": 200
    },
    {
      "epoch": 0.035040881027865844,
      "grad_norm": 4.689290523529053,
      "learning_rate": 2.1e-05,
      "loss": 1.3763,
      "step": 210
    },
    {
      "epoch": 0.03670949441014517,
      "grad_norm": 7.296417236328125,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.4751,
      "step": 220
    },
    {
      "epoch": 0.038378107792424496,
      "grad_norm": 11.922574996948242,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 2.0907,
      "step": 230
    },
    {
      "epoch": 0.04004672117470382,
      "grad_norm": 5.450417995452881,
      "learning_rate": 2.4e-05,
      "loss": 1.7902,
      "step": 240
    },
    {
      "epoch": 0.04171533455698315,
      "grad_norm": 7.988636493682861,
      "learning_rate": 2.5e-05,
      "loss": 2.0059,
      "step": 250
    },
    {
      "epoch": 0.04338394793926247,
      "grad_norm": 5.704071521759033,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.4196,
      "step": 260
    },
    {
      "epoch": 0.0450525613215418,
      "grad_norm": 5.168555736541748,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.4292,
      "step": 270
    },
    {
      "epoch": 0.046721174703821124,
      "grad_norm": 5.6051435470581055,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.5838,
      "step": 280
    },
    {
      "epoch": 0.04838978808610045,
      "grad_norm": 8.265167236328125,
      "learning_rate": 2.9e-05,
      "loss": 1.5459,
      "step": 290
    },
    {
      "epoch": 0.050058401468379775,
      "grad_norm": 6.930691719055176,
      "learning_rate": 3e-05,
      "loss": 1.6044,
      "step": 300
    },
    {
      "epoch": 0.0517270148506591,
      "grad_norm": 7.2446699142456055,
      "learning_rate": 3.1e-05,
      "loss": 1.6727,
      "step": 310
    },
    {
      "epoch": 0.053395628232938426,
      "grad_norm": 5.798071384429932,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.667,
      "step": 320
    },
    {
      "epoch": 0.05506424161521775,
      "grad_norm": 7.059964179992676,
      "learning_rate": 3.3e-05,
      "loss": 1.619,
      "step": 330
    },
    {
      "epoch": 0.05673285499749708,
      "grad_norm": 5.899831295013428,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.0725,
      "step": 340
    },
    {
      "epoch": 0.0584014683797764,
      "grad_norm": 5.815085411071777,
      "learning_rate": 3.5e-05,
      "loss": 1.3692,
      "step": 350
    },
    {
      "epoch": 0.06007008176205573,
      "grad_norm": 5.109336853027344,
      "learning_rate": 3.6e-05,
      "loss": 1.3641,
      "step": 360
    },
    {
      "epoch": 0.06173869514433506,
      "grad_norm": 4.846375465393066,
      "learning_rate": 3.7e-05,
      "loss": 1.5955,
      "step": 370
    },
    {
      "epoch": 0.06340730852661439,
      "grad_norm": 9.159847259521484,
      "learning_rate": 3.8e-05,
      "loss": 1.663,
      "step": 380
    },
    {
      "epoch": 0.0650759219088937,
      "grad_norm": 6.52689790725708,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.1499,
      "step": 390
    },
    {
      "epoch": 0.06674453529117304,
      "grad_norm": 8.106498718261719,
      "learning_rate": 4e-05,
      "loss": 1.0195,
      "step": 400
    },
    {
      "epoch": 0.06841314867345236,
      "grad_norm": 7.403848648071289,
      "learning_rate": 4.1e-05,
      "loss": 1.0374,
      "step": 410
    },
    {
      "epoch": 0.07008176205573169,
      "grad_norm": 10.298356056213379,
      "learning_rate": 4.2e-05,
      "loss": 1.4083,
      "step": 420
    },
    {
      "epoch": 0.07175037543801101,
      "grad_norm": 8.604483604431152,
      "learning_rate": 4.3e-05,
      "loss": 0.9467,
      "step": 430
    },
    {
      "epoch": 0.07341898882029034,
      "grad_norm": 7.670446395874023,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.5065,
      "step": 440
    },
    {
      "epoch": 0.07508760220256966,
      "grad_norm": 6.878382682800293,
      "learning_rate": 4.5e-05,
      "loss": 1.2361,
      "step": 450
    },
    {
      "epoch": 0.07675621558484899,
      "grad_norm": 9.739946365356445,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.376,
      "step": 460
    },
    {
      "epoch": 0.07842482896712831,
      "grad_norm": 2.4443745613098145,
      "learning_rate": 4.7e-05,
      "loss": 1.0508,
      "step": 470
    },
    {
      "epoch": 0.08009344234940764,
      "grad_norm": 5.105490207672119,
      "learning_rate": 4.8e-05,
      "loss": 0.9467,
      "step": 480
    },
    {
      "epoch": 0.08176205573168698,
      "grad_norm": 1.9795540571212769,
      "learning_rate": 4.9e-05,
      "loss": 1.0421,
      "step": 490
    },
    {
      "epoch": 0.0834306691139663,
      "grad_norm": 13.910361289978027,
      "learning_rate": 5e-05,
      "loss": 0.9834,
      "step": 500
    },
    {
      "epoch": 0.08509928249624563,
      "grad_norm": 5.3670220375061035,
      "learning_rate": 4.9978698023176554e-05,
      "loss": 1.2034,
      "step": 510
    },
    {
      "epoch": 0.08676789587852494,
      "grad_norm": 8.683828353881836,
      "learning_rate": 4.9957396046353105e-05,
      "loss": 0.9199,
      "step": 520
    },
    {
      "epoch": 0.08843650926080428,
      "grad_norm": 8.722528457641602,
      "learning_rate": 4.9936094069529656e-05,
      "loss": 1.3851,
      "step": 530
    },
    {
      "epoch": 0.0901051226430836,
      "grad_norm": 5.5807881355285645,
      "learning_rate": 4.99147920927062e-05,
      "loss": 1.1402,
      "step": 540
    },
    {
      "epoch": 0.09177373602536293,
      "grad_norm": 7.571084976196289,
      "learning_rate": 4.989349011588276e-05,
      "loss": 1.3795,
      "step": 550
    },
    {
      "epoch": 0.09344234940764225,
      "grad_norm": 7.37730598449707,
      "learning_rate": 4.9872188139059304e-05,
      "loss": 0.81,
      "step": 560
    },
    {
      "epoch": 0.09511096278992158,
      "grad_norm": 10.168316841125488,
      "learning_rate": 4.985088616223586e-05,
      "loss": 1.3838,
      "step": 570
    },
    {
      "epoch": 0.0967795761722009,
      "grad_norm": 10.4512357711792,
      "learning_rate": 4.9829584185412406e-05,
      "loss": 0.9509,
      "step": 580
    },
    {
      "epoch": 0.09844818955448023,
      "grad_norm": 11.75351333618164,
      "learning_rate": 4.980828220858896e-05,
      "loss": 1.142,
      "step": 590
    },
    {
      "epoch": 0.10011680293675955,
      "grad_norm": 7.678175926208496,
      "learning_rate": 4.978698023176551e-05,
      "loss": 1.0443,
      "step": 600
    },
    {
      "epoch": 0.10178541631903888,
      "grad_norm": 5.490517616271973,
      "learning_rate": 4.976567825494206e-05,
      "loss": 1.269,
      "step": 610
    },
    {
      "epoch": 0.1034540297013182,
      "grad_norm": 6.006327152252197,
      "learning_rate": 4.974437627811861e-05,
      "loss": 0.9879,
      "step": 620
    },
    {
      "epoch": 0.10512264308359753,
      "grad_norm": 8.454747200012207,
      "learning_rate": 4.972307430129516e-05,
      "loss": 1.121,
      "step": 630
    },
    {
      "epoch": 0.10679125646587685,
      "grad_norm": 4.379626750946045,
      "learning_rate": 4.9701772324471714e-05,
      "loss": 1.2119,
      "step": 640
    },
    {
      "epoch": 0.10845986984815618,
      "grad_norm": 8.560583114624023,
      "learning_rate": 4.9680470347648266e-05,
      "loss": 0.933,
      "step": 650
    },
    {
      "epoch": 0.1101284832304355,
      "grad_norm": 5.742160797119141,
      "learning_rate": 4.965916837082482e-05,
      "loss": 1.3424,
      "step": 660
    },
    {
      "epoch": 0.11179709661271484,
      "grad_norm": 8.295968055725098,
      "learning_rate": 4.963786639400136e-05,
      "loss": 1.1824,
      "step": 670
    },
    {
      "epoch": 0.11346570999499415,
      "grad_norm": 7.665077209472656,
      "learning_rate": 4.961656441717792e-05,
      "loss": 1.0148,
      "step": 680
    },
    {
      "epoch": 0.11513432337727349,
      "grad_norm": 2.2763729095458984,
      "learning_rate": 4.9595262440354464e-05,
      "loss": 1.2039,
      "step": 690
    },
    {
      "epoch": 0.1168029367595528,
      "grad_norm": 3.3238821029663086,
      "learning_rate": 4.9573960463531015e-05,
      "loss": 0.9954,
      "step": 700
    },
    {
      "epoch": 0.11847155014183214,
      "grad_norm": 5.773782253265381,
      "learning_rate": 4.9552658486707574e-05,
      "loss": 0.8885,
      "step": 710
    },
    {
      "epoch": 0.12014016352411146,
      "grad_norm": 5.722370147705078,
      "learning_rate": 4.953135650988412e-05,
      "loss": 0.843,
      "step": 720
    },
    {
      "epoch": 0.12180877690639079,
      "grad_norm": 4.529634475708008,
      "learning_rate": 4.951005453306067e-05,
      "loss": 0.9794,
      "step": 730
    },
    {
      "epoch": 0.12347739028867012,
      "grad_norm": 12.99602222442627,
      "learning_rate": 4.948875255623722e-05,
      "loss": 1.4469,
      "step": 740
    },
    {
      "epoch": 0.12514600367094944,
      "grad_norm": 5.601666450500488,
      "learning_rate": 4.946745057941377e-05,
      "loss": 1.0332,
      "step": 750
    },
    {
      "epoch": 0.12681461705322877,
      "grad_norm": 5.496005535125732,
      "learning_rate": 4.944614860259032e-05,
      "loss": 1.2491,
      "step": 760
    },
    {
      "epoch": 0.1284832304355081,
      "grad_norm": 7.067525863647461,
      "learning_rate": 4.9424846625766875e-05,
      "loss": 0.9724,
      "step": 770
    },
    {
      "epoch": 0.1301518438177874,
      "grad_norm": 6.886786460876465,
      "learning_rate": 4.9403544648943426e-05,
      "loss": 0.9522,
      "step": 780
    },
    {
      "epoch": 0.13182045720006674,
      "grad_norm": 7.650302886962891,
      "learning_rate": 4.938224267211998e-05,
      "loss": 1.2355,
      "step": 790
    },
    {
      "epoch": 0.13348907058234608,
      "grad_norm": 14.218182563781738,
      "learning_rate": 4.936094069529653e-05,
      "loss": 0.9778,
      "step": 800
    },
    {
      "epoch": 0.1351576839646254,
      "grad_norm": 5.353604316711426,
      "learning_rate": 4.933963871847307e-05,
      "loss": 1.1231,
      "step": 810
    },
    {
      "epoch": 0.1368262973469047,
      "grad_norm": 10.568121910095215,
      "learning_rate": 4.931833674164963e-05,
      "loss": 1.0955,
      "step": 820
    },
    {
      "epoch": 0.13849491072918405,
      "grad_norm": 8.434700012207031,
      "learning_rate": 4.9297034764826176e-05,
      "loss": 0.8542,
      "step": 830
    },
    {
      "epoch": 0.14016352411146338,
      "grad_norm": 11.020655632019043,
      "learning_rate": 4.927573278800273e-05,
      "loss": 1.0711,
      "step": 840
    },
    {
      "epoch": 0.1418321374937427,
      "grad_norm": 6.90020751953125,
      "learning_rate": 4.925443081117928e-05,
      "loss": 1.0857,
      "step": 850
    },
    {
      "epoch": 0.14350075087602202,
      "grad_norm": 12.6170072555542,
      "learning_rate": 4.923312883435583e-05,
      "loss": 1.1352,
      "step": 860
    },
    {
      "epoch": 0.14516936425830135,
      "grad_norm": 5.879394054412842,
      "learning_rate": 4.921182685753238e-05,
      "loss": 1.1006,
      "step": 870
    },
    {
      "epoch": 0.14683797764058068,
      "grad_norm": 8.519241333007812,
      "learning_rate": 4.919052488070893e-05,
      "loss": 0.9405,
      "step": 880
    },
    {
      "epoch": 0.14850659102286,
      "grad_norm": 12.018880844116211,
      "learning_rate": 4.9169222903885484e-05,
      "loss": 1.0162,
      "step": 890
    },
    {
      "epoch": 0.15017520440513932,
      "grad_norm": 8.296252250671387,
      "learning_rate": 4.9147920927062035e-05,
      "loss": 0.9461,
      "step": 900
    },
    {
      "epoch": 0.15184381778741865,
      "grad_norm": 1.661017656326294,
      "learning_rate": 4.9126618950238587e-05,
      "loss": 0.8436,
      "step": 910
    },
    {
      "epoch": 0.15351243116969798,
      "grad_norm": 12.7459135055542,
      "learning_rate": 4.910531697341513e-05,
      "loss": 1.0236,
      "step": 920
    },
    {
      "epoch": 0.15518104455197732,
      "grad_norm": 7.691208362579346,
      "learning_rate": 4.908401499659169e-05,
      "loss": 0.7564,
      "step": 930
    },
    {
      "epoch": 0.15684965793425662,
      "grad_norm": 5.071497917175293,
      "learning_rate": 4.9062713019768234e-05,
      "loss": 1.0305,
      "step": 940
    },
    {
      "epoch": 0.15851827131653595,
      "grad_norm": 11.30626392364502,
      "learning_rate": 4.904141104294479e-05,
      "loss": 1.1542,
      "step": 950
    },
    {
      "epoch": 0.16018688469881529,
      "grad_norm": 3.5152103900909424,
      "learning_rate": 4.9020109066121336e-05,
      "loss": 1.1834,
      "step": 960
    },
    {
      "epoch": 0.16185549808109462,
      "grad_norm": 14.171195983886719,
      "learning_rate": 4.899880708929789e-05,
      "loss": 0.8233,
      "step": 970
    },
    {
      "epoch": 0.16352411146337395,
      "grad_norm": 10.198997497558594,
      "learning_rate": 4.897750511247444e-05,
      "loss": 0.8698,
      "step": 980
    },
    {
      "epoch": 0.16519272484565325,
      "grad_norm": 6.394326686859131,
      "learning_rate": 4.895620313565099e-05,
      "loss": 0.9039,
      "step": 990
    },
    {
      "epoch": 0.1668613382279326,
      "grad_norm": 5.254652976989746,
      "learning_rate": 4.893490115882754e-05,
      "loss": 0.9891,
      "step": 1000
    },
    {
      "epoch": 0.16852995161021192,
      "grad_norm": 15.370824813842773,
      "learning_rate": 4.891359918200409e-05,
      "loss": 0.8715,
      "step": 1010
    },
    {
      "epoch": 0.17019856499249125,
      "grad_norm": 7.787691593170166,
      "learning_rate": 4.8892297205180644e-05,
      "loss": 0.7746,
      "step": 1020
    },
    {
      "epoch": 0.17186717837477056,
      "grad_norm": 11.494077682495117,
      "learning_rate": 4.887099522835719e-05,
      "loss": 0.7561,
      "step": 1030
    },
    {
      "epoch": 0.1735357917570499,
      "grad_norm": 2.676873207092285,
      "learning_rate": 4.884969325153375e-05,
      "loss": 0.8851,
      "step": 1040
    },
    {
      "epoch": 0.17520440513932922,
      "grad_norm": 7.112656593322754,
      "learning_rate": 4.882839127471029e-05,
      "loss": 0.8012,
      "step": 1050
    },
    {
      "epoch": 0.17687301852160855,
      "grad_norm": 13.557592391967773,
      "learning_rate": 4.880708929788685e-05,
      "loss": 0.8545,
      "step": 1060
    },
    {
      "epoch": 0.17854163190388786,
      "grad_norm": 8.752182006835938,
      "learning_rate": 4.8785787321063394e-05,
      "loss": 1.0867,
      "step": 1070
    },
    {
      "epoch": 0.1802102452861672,
      "grad_norm": 14.975482940673828,
      "learning_rate": 4.8764485344239946e-05,
      "loss": 1.0206,
      "step": 1080
    },
    {
      "epoch": 0.18187885866844652,
      "grad_norm": 7.262783527374268,
      "learning_rate": 4.8743183367416504e-05,
      "loss": 1.142,
      "step": 1090
    },
    {
      "epoch": 0.18354747205072586,
      "grad_norm": 11.608201026916504,
      "learning_rate": 4.872188139059305e-05,
      "loss": 0.8128,
      "step": 1100
    },
    {
      "epoch": 0.18521608543300516,
      "grad_norm": 6.071269989013672,
      "learning_rate": 4.87005794137696e-05,
      "loss": 0.7834,
      "step": 1110
    },
    {
      "epoch": 0.1868846988152845,
      "grad_norm": 5.2202324867248535,
      "learning_rate": 4.867927743694615e-05,
      "loss": 1.1932,
      "step": 1120
    },
    {
      "epoch": 0.18855331219756383,
      "grad_norm": 6.854410648345947,
      "learning_rate": 4.86579754601227e-05,
      "loss": 0.8795,
      "step": 1130
    },
    {
      "epoch": 0.19022192557984316,
      "grad_norm": 6.516758441925049,
      "learning_rate": 4.863667348329925e-05,
      "loss": 0.9976,
      "step": 1140
    },
    {
      "epoch": 0.19189053896212246,
      "grad_norm": 6.325408935546875,
      "learning_rate": 4.8615371506475805e-05,
      "loss": 0.8822,
      "step": 1150
    },
    {
      "epoch": 0.1935591523444018,
      "grad_norm": 15.320943832397461,
      "learning_rate": 4.8594069529652356e-05,
      "loss": 0.6054,
      "step": 1160
    },
    {
      "epoch": 0.19522776572668113,
      "grad_norm": 8.960070610046387,
      "learning_rate": 4.857276755282891e-05,
      "loss": 0.9196,
      "step": 1170
    },
    {
      "epoch": 0.19689637910896046,
      "grad_norm": 7.015202045440674,
      "learning_rate": 4.855146557600546e-05,
      "loss": 0.6792,
      "step": 1180
    },
    {
      "epoch": 0.19856499249123977,
      "grad_norm": 8.809013366699219,
      "learning_rate": 4.8530163599182003e-05,
      "loss": 1.2103,
      "step": 1190
    },
    {
      "epoch": 0.2002336058735191,
      "grad_norm": 5.754108905792236,
      "learning_rate": 4.850886162235856e-05,
      "loss": 1.2232,
      "step": 1200
    },
    {
      "epoch": 0.20190221925579843,
      "grad_norm": 7.985579490661621,
      "learning_rate": 4.8487559645535106e-05,
      "loss": 1.1816,
      "step": 1210
    },
    {
      "epoch": 0.20357083263807776,
      "grad_norm": 2.9442548751831055,
      "learning_rate": 4.846625766871166e-05,
      "loss": 0.8967,
      "step": 1220
    },
    {
      "epoch": 0.2052394460203571,
      "grad_norm": 9.350631713867188,
      "learning_rate": 4.844495569188821e-05,
      "loss": 0.9031,
      "step": 1230
    },
    {
      "epoch": 0.2069080594026364,
      "grad_norm": 6.945474147796631,
      "learning_rate": 4.842365371506476e-05,
      "loss": 0.9129,
      "step": 1240
    },
    {
      "epoch": 0.20857667278491573,
      "grad_norm": 10.188994407653809,
      "learning_rate": 4.840235173824131e-05,
      "loss": 0.9243,
      "step": 1250
    },
    {
      "epoch": 0.21024528616719507,
      "grad_norm": 8.459782600402832,
      "learning_rate": 4.838104976141786e-05,
      "loss": 0.5827,
      "step": 1260
    },
    {
      "epoch": 0.2119138995494744,
      "grad_norm": 5.117980003356934,
      "learning_rate": 4.8359747784594414e-05,
      "loss": 0.8088,
      "step": 1270
    },
    {
      "epoch": 0.2135825129317537,
      "grad_norm": 11.113184928894043,
      "learning_rate": 4.8338445807770965e-05,
      "loss": 1.117,
      "step": 1280
    },
    {
      "epoch": 0.21525112631403304,
      "grad_norm": 8.368911743164062,
      "learning_rate": 4.831714383094752e-05,
      "loss": 0.9381,
      "step": 1290
    },
    {
      "epoch": 0.21691973969631237,
      "grad_norm": 3.736769914627075,
      "learning_rate": 4.829584185412406e-05,
      "loss": 0.715,
      "step": 1300
    },
    {
      "epoch": 0.2185883530785917,
      "grad_norm": 5.07656192779541,
      "learning_rate": 4.827453987730062e-05,
      "loss": 1.0564,
      "step": 1310
    },
    {
      "epoch": 0.220256966460871,
      "grad_norm": 3.2761898040771484,
      "learning_rate": 4.8253237900477164e-05,
      "loss": 0.972,
      "step": 1320
    },
    {
      "epoch": 0.22192557984315034,
      "grad_norm": 3.562837600708008,
      "learning_rate": 4.8231935923653715e-05,
      "loss": 0.8114,
      "step": 1330
    },
    {
      "epoch": 0.22359419322542967,
      "grad_norm": 5.412622451782227,
      "learning_rate": 4.8210633946830267e-05,
      "loss": 0.6172,
      "step": 1340
    },
    {
      "epoch": 0.225262806607709,
      "grad_norm": 4.77771520614624,
      "learning_rate": 4.818933197000682e-05,
      "loss": 0.6817,
      "step": 1350
    },
    {
      "epoch": 0.2269314199899883,
      "grad_norm": 13.6343994140625,
      "learning_rate": 4.816802999318337e-05,
      "loss": 1.0091,
      "step": 1360
    },
    {
      "epoch": 0.22860003337226764,
      "grad_norm": 9.30815601348877,
      "learning_rate": 4.814672801635992e-05,
      "loss": 0.9068,
      "step": 1370
    },
    {
      "epoch": 0.23026864675454697,
      "grad_norm": 6.772705554962158,
      "learning_rate": 4.812542603953647e-05,
      "loss": 0.9162,
      "step": 1380
    },
    {
      "epoch": 0.2319372601368263,
      "grad_norm": 4.869386196136475,
      "learning_rate": 4.810412406271302e-05,
      "loss": 0.9245,
      "step": 1390
    },
    {
      "epoch": 0.2336058735191056,
      "grad_norm": 4.640839099884033,
      "learning_rate": 4.8082822085889575e-05,
      "loss": 0.7241,
      "step": 1400
    },
    {
      "epoch": 0.23527448690138494,
      "grad_norm": 7.260838985443115,
      "learning_rate": 4.806152010906612e-05,
      "loss": 1.1159,
      "step": 1410
    },
    {
      "epoch": 0.23694310028366428,
      "grad_norm": 8.9894437789917,
      "learning_rate": 4.804021813224268e-05,
      "loss": 0.766,
      "step": 1420
    },
    {
      "epoch": 0.2386117136659436,
      "grad_norm": 5.941689491271973,
      "learning_rate": 4.801891615541922e-05,
      "loss": 1.0211,
      "step": 1430
    },
    {
      "epoch": 0.2402803270482229,
      "grad_norm": 6.099863529205322,
      "learning_rate": 4.799761417859577e-05,
      "loss": 1.1176,
      "step": 1440
    },
    {
      "epoch": 0.24194894043050225,
      "grad_norm": 18.322364807128906,
      "learning_rate": 4.7976312201772324e-05,
      "loss": 0.9547,
      "step": 1450
    },
    {
      "epoch": 0.24361755381278158,
      "grad_norm": 4.713418006896973,
      "learning_rate": 4.7955010224948876e-05,
      "loss": 1.0038,
      "step": 1460
    },
    {
      "epoch": 0.2452861671950609,
      "grad_norm": 5.954039573669434,
      "learning_rate": 4.7933708248125434e-05,
      "loss": 0.9859,
      "step": 1470
    },
    {
      "epoch": 0.24695478057734024,
      "grad_norm": 1.3553916215896606,
      "learning_rate": 4.791240627130198e-05,
      "loss": 0.8059,
      "step": 1480
    },
    {
      "epoch": 0.24862339395961955,
      "grad_norm": 4.211933612823486,
      "learning_rate": 4.789110429447853e-05,
      "loss": 0.8068,
      "step": 1490
    },
    {
      "epoch": 0.2502920073418989,
      "grad_norm": 10.577535629272461,
      "learning_rate": 4.786980231765508e-05,
      "loss": 0.9145,
      "step": 1500
    },
    {
      "epoch": 0.2519606207241782,
      "grad_norm": 12.839938163757324,
      "learning_rate": 4.784850034083163e-05,
      "loss": 1.0051,
      "step": 1510
    },
    {
      "epoch": 0.25362923410645755,
      "grad_norm": 10.59160041809082,
      "learning_rate": 4.782719836400818e-05,
      "loss": 0.7351,
      "step": 1520
    },
    {
      "epoch": 0.25529784748873685,
      "grad_norm": 6.757431507110596,
      "learning_rate": 4.7805896387184735e-05,
      "loss": 0.9431,
      "step": 1530
    },
    {
      "epoch": 0.2569664608710162,
      "grad_norm": 11.996758460998535,
      "learning_rate": 4.7784594410361286e-05,
      "loss": 0.9925,
      "step": 1540
    },
    {
      "epoch": 0.2586350742532955,
      "grad_norm": 7.938404560089111,
      "learning_rate": 4.776329243353784e-05,
      "loss": 1.077,
      "step": 1550
    },
    {
      "epoch": 0.2603036876355748,
      "grad_norm": 7.818968772888184,
      "learning_rate": 4.774199045671439e-05,
      "loss": 0.945,
      "step": 1560
    },
    {
      "epoch": 0.2619723010178542,
      "grad_norm": 7.099704265594482,
      "learning_rate": 4.7720688479890934e-05,
      "loss": 1.0696,
      "step": 1570
    },
    {
      "epoch": 0.2636409144001335,
      "grad_norm": 4.397469997406006,
      "learning_rate": 4.769938650306749e-05,
      "loss": 0.5265,
      "step": 1580
    },
    {
      "epoch": 0.2653095277824128,
      "grad_norm": 4.42056941986084,
      "learning_rate": 4.7678084526244036e-05,
      "loss": 1.0522,
      "step": 1590
    },
    {
      "epoch": 0.26697814116469215,
      "grad_norm": 9.443928718566895,
      "learning_rate": 4.765678254942059e-05,
      "loss": 1.0368,
      "step": 1600
    },
    {
      "epoch": 0.26864675454697146,
      "grad_norm": 3.618483543395996,
      "learning_rate": 4.763548057259714e-05,
      "loss": 0.8655,
      "step": 1610
    },
    {
      "epoch": 0.2703153679292508,
      "grad_norm": 6.898618698120117,
      "learning_rate": 4.761417859577369e-05,
      "loss": 0.9831,
      "step": 1620
    },
    {
      "epoch": 0.2719839813115301,
      "grad_norm": 8.875914573669434,
      "learning_rate": 4.759287661895024e-05,
      "loss": 0.7695,
      "step": 1630
    },
    {
      "epoch": 0.2736525946938094,
      "grad_norm": 9.395337104797363,
      "learning_rate": 4.757157464212679e-05,
      "loss": 0.8331,
      "step": 1640
    },
    {
      "epoch": 0.2753212080760888,
      "grad_norm": 8.659492492675781,
      "learning_rate": 4.7550272665303344e-05,
      "loss": 0.9533,
      "step": 1650
    },
    {
      "epoch": 0.2769898214583681,
      "grad_norm": 2.3157968521118164,
      "learning_rate": 4.7528970688479896e-05,
      "loss": 0.7154,
      "step": 1660
    },
    {
      "epoch": 0.2786584348406474,
      "grad_norm": 9.683950424194336,
      "learning_rate": 4.750766871165645e-05,
      "loss": 1.0787,
      "step": 1670
    },
    {
      "epoch": 0.28032704822292676,
      "grad_norm": 11.940595626831055,
      "learning_rate": 4.748636673483299e-05,
      "loss": 1.0501,
      "step": 1680
    },
    {
      "epoch": 0.28199566160520606,
      "grad_norm": 6.150341987609863,
      "learning_rate": 4.746506475800955e-05,
      "loss": 0.6178,
      "step": 1690
    },
    {
      "epoch": 0.2836642749874854,
      "grad_norm": 9.06094741821289,
      "learning_rate": 4.7443762781186094e-05,
      "loss": 0.9085,
      "step": 1700
    },
    {
      "epoch": 0.2853328883697647,
      "grad_norm": 12.801769256591797,
      "learning_rate": 4.7422460804362645e-05,
      "loss": 0.7393,
      "step": 1710
    },
    {
      "epoch": 0.28700150175204403,
      "grad_norm": 6.536427974700928,
      "learning_rate": 4.74011588275392e-05,
      "loss": 1.0826,
      "step": 1720
    },
    {
      "epoch": 0.2886701151343234,
      "grad_norm": 4.567477703094482,
      "learning_rate": 4.737985685071575e-05,
      "loss": 0.6673,
      "step": 1730
    },
    {
      "epoch": 0.2903387285166027,
      "grad_norm": 10.086455345153809,
      "learning_rate": 4.73585548738923e-05,
      "loss": 0.9971,
      "step": 1740
    },
    {
      "epoch": 0.29200734189888206,
      "grad_norm": 5.867030620574951,
      "learning_rate": 4.733725289706885e-05,
      "loss": 0.8847,
      "step": 1750
    },
    {
      "epoch": 0.29367595528116136,
      "grad_norm": 9.277796745300293,
      "learning_rate": 4.73159509202454e-05,
      "loss": 0.6552,
      "step": 1760
    },
    {
      "epoch": 0.29534456866344067,
      "grad_norm": 10.306794166564941,
      "learning_rate": 4.729464894342195e-05,
      "loss": 0.6757,
      "step": 1770
    },
    {
      "epoch": 0.29701318204572,
      "grad_norm": 15.923295974731445,
      "learning_rate": 4.7273346966598505e-05,
      "loss": 0.7507,
      "step": 1780
    },
    {
      "epoch": 0.29868179542799933,
      "grad_norm": 10.33800220489502,
      "learning_rate": 4.725204498977505e-05,
      "loss": 1.019,
      "step": 1790
    },
    {
      "epoch": 0.30035040881027864,
      "grad_norm": 6.398563385009766,
      "learning_rate": 4.723074301295161e-05,
      "loss": 1.0343,
      "step": 1800
    },
    {
      "epoch": 0.302019022192558,
      "grad_norm": 9.485482215881348,
      "learning_rate": 4.720944103612815e-05,
      "loss": 0.7798,
      "step": 1810
    },
    {
      "epoch": 0.3036876355748373,
      "grad_norm": 12.45145034790039,
      "learning_rate": 4.71881390593047e-05,
      "loss": 0.7365,
      "step": 1820
    },
    {
      "epoch": 0.30535624895711666,
      "grad_norm": 11.77038860321045,
      "learning_rate": 4.7166837082481255e-05,
      "loss": 0.5596,
      "step": 1830
    },
    {
      "epoch": 0.30702486233939597,
      "grad_norm": 8.677770614624023,
      "learning_rate": 4.7145535105657806e-05,
      "loss": 1.013,
      "step": 1840
    },
    {
      "epoch": 0.30869347572167527,
      "grad_norm": 9.020999908447266,
      "learning_rate": 4.7124233128834364e-05,
      "loss": 0.8081,
      "step": 1850
    },
    {
      "epoch": 0.31036208910395463,
      "grad_norm": 3.7962541580200195,
      "learning_rate": 4.710293115201091e-05,
      "loss": 0.8799,
      "step": 1860
    },
    {
      "epoch": 0.31203070248623394,
      "grad_norm": 4.856635570526123,
      "learning_rate": 4.708162917518746e-05,
      "loss": 0.8808,
      "step": 1870
    },
    {
      "epoch": 0.31369931586851324,
      "grad_norm": 4.366225242614746,
      "learning_rate": 4.706032719836401e-05,
      "loss": 0.7278,
      "step": 1880
    },
    {
      "epoch": 0.3153679292507926,
      "grad_norm": 8.835206031799316,
      "learning_rate": 4.703902522154056e-05,
      "loss": 0.6885,
      "step": 1890
    },
    {
      "epoch": 0.3170365426330719,
      "grad_norm": 4.946151256561279,
      "learning_rate": 4.701772324471711e-05,
      "loss": 0.9954,
      "step": 1900
    },
    {
      "epoch": 0.31870515601535127,
      "grad_norm": 7.9252190589904785,
      "learning_rate": 4.6996421267893665e-05,
      "loss": 0.8228,
      "step": 1910
    },
    {
      "epoch": 0.32037376939763057,
      "grad_norm": 7.7471923828125,
      "learning_rate": 4.6975119291070217e-05,
      "loss": 0.7838,
      "step": 1920
    },
    {
      "epoch": 0.3220423827799099,
      "grad_norm": 7.640753269195557,
      "learning_rate": 4.695381731424676e-05,
      "loss": 0.9746,
      "step": 1930
    },
    {
      "epoch": 0.32371099616218924,
      "grad_norm": 10.363265037536621,
      "learning_rate": 4.693251533742332e-05,
      "loss": 1.0445,
      "step": 1940
    },
    {
      "epoch": 0.32537960954446854,
      "grad_norm": 6.390927791595459,
      "learning_rate": 4.6911213360599864e-05,
      "loss": 0.7316,
      "step": 1950
    },
    {
      "epoch": 0.3270482229267479,
      "grad_norm": 3.888888120651245,
      "learning_rate": 4.688991138377642e-05,
      "loss": 0.6778,
      "step": 1960
    },
    {
      "epoch": 0.3287168363090272,
      "grad_norm": 1.3898848295211792,
      "learning_rate": 4.6868609406952966e-05,
      "loss": 0.5201,
      "step": 1970
    },
    {
      "epoch": 0.3303854496913065,
      "grad_norm": 5.108023643493652,
      "learning_rate": 4.684730743012952e-05,
      "loss": 1.215,
      "step": 1980
    },
    {
      "epoch": 0.33205406307358587,
      "grad_norm": 3.7681901454925537,
      "learning_rate": 4.682600545330607e-05,
      "loss": 0.6188,
      "step": 1990
    },
    {
      "epoch": 0.3337226764558652,
      "grad_norm": 5.549030303955078,
      "learning_rate": 4.680470347648262e-05,
      "loss": 0.7019,
      "step": 2000
    },
    {
      "epoch": 0.3353912898381445,
      "grad_norm": 11.484082221984863,
      "learning_rate": 4.678340149965917e-05,
      "loss": 0.8456,
      "step": 2010
    },
    {
      "epoch": 0.33705990322042384,
      "grad_norm": 6.844860553741455,
      "learning_rate": 4.676209952283572e-05,
      "loss": 0.7103,
      "step": 2020
    },
    {
      "epoch": 0.33872851660270314,
      "grad_norm": 7.066591262817383,
      "learning_rate": 4.6740797546012274e-05,
      "loss": 0.6699,
      "step": 2030
    },
    {
      "epoch": 0.3403971299849825,
      "grad_norm": 10.624295234680176,
      "learning_rate": 4.671949556918882e-05,
      "loss": 0.798,
      "step": 2040
    },
    {
      "epoch": 0.3420657433672618,
      "grad_norm": 6.141763210296631,
      "learning_rate": 4.669819359236538e-05,
      "loss": 0.7647,
      "step": 2050
    },
    {
      "epoch": 0.3437343567495411,
      "grad_norm": 7.789971828460693,
      "learning_rate": 4.667689161554192e-05,
      "loss": 0.8635,
      "step": 2060
    },
    {
      "epoch": 0.3454029701318205,
      "grad_norm": 6.480897426605225,
      "learning_rate": 4.665558963871848e-05,
      "loss": 0.6378,
      "step": 2070
    },
    {
      "epoch": 0.3470715835140998,
      "grad_norm": 3.795684576034546,
      "learning_rate": 4.6634287661895024e-05,
      "loss": 0.8532,
      "step": 2080
    },
    {
      "epoch": 0.3487401968963791,
      "grad_norm": 10.762843132019043,
      "learning_rate": 4.6612985685071576e-05,
      "loss": 0.6584,
      "step": 2090
    },
    {
      "epoch": 0.35040881027865844,
      "grad_norm": 4.735290050506592,
      "learning_rate": 4.659168370824813e-05,
      "loss": 0.6932,
      "step": 2100
    },
    {
      "epoch": 0.35207742366093775,
      "grad_norm": 13.710530281066895,
      "learning_rate": 4.657038173142468e-05,
      "loss": 1.0869,
      "step": 2110
    },
    {
      "epoch": 0.3537460370432171,
      "grad_norm": 5.3069047927856445,
      "learning_rate": 4.654907975460123e-05,
      "loss": 0.7804,
      "step": 2120
    },
    {
      "epoch": 0.3554146504254964,
      "grad_norm": 10.247106552124023,
      "learning_rate": 4.652777777777778e-05,
      "loss": 0.6502,
      "step": 2130
    },
    {
      "epoch": 0.3570832638077757,
      "grad_norm": 0.7661415934562683,
      "learning_rate": 4.650647580095433e-05,
      "loss": 0.6462,
      "step": 2140
    },
    {
      "epoch": 0.3587518771900551,
      "grad_norm": 7.576444625854492,
      "learning_rate": 4.6485173824130884e-05,
      "loss": 0.779,
      "step": 2150
    },
    {
      "epoch": 0.3604204905723344,
      "grad_norm": 6.489376544952393,
      "learning_rate": 4.6463871847307435e-05,
      "loss": 0.8445,
      "step": 2160
    },
    {
      "epoch": 0.3620891039546137,
      "grad_norm": 8.402504920959473,
      "learning_rate": 4.644256987048398e-05,
      "loss": 0.9178,
      "step": 2170
    },
    {
      "epoch": 0.36375771733689305,
      "grad_norm": 10.369796752929688,
      "learning_rate": 4.642126789366054e-05,
      "loss": 0.7305,
      "step": 2180
    },
    {
      "epoch": 0.36542633071917235,
      "grad_norm": 7.1052141189575195,
      "learning_rate": 4.639996591683708e-05,
      "loss": 0.8199,
      "step": 2190
    },
    {
      "epoch": 0.3670949441014517,
      "grad_norm": 4.7416605949401855,
      "learning_rate": 4.637866394001363e-05,
      "loss": 0.7041,
      "step": 2200
    },
    {
      "epoch": 0.368763557483731,
      "grad_norm": 3.7465391159057617,
      "learning_rate": 4.6357361963190185e-05,
      "loss": 0.6012,
      "step": 2210
    },
    {
      "epoch": 0.3704321708660103,
      "grad_norm": 7.266491889953613,
      "learning_rate": 4.6336059986366736e-05,
      "loss": 0.7317,
      "step": 2220
    },
    {
      "epoch": 0.3721007842482897,
      "grad_norm": 3.5904736518859863,
      "learning_rate": 4.631475800954329e-05,
      "loss": 0.6366,
      "step": 2230
    },
    {
      "epoch": 0.373769397630569,
      "grad_norm": 7.939891815185547,
      "learning_rate": 4.629345603271984e-05,
      "loss": 0.9024,
      "step": 2240
    },
    {
      "epoch": 0.37543801101284835,
      "grad_norm": 5.7376627922058105,
      "learning_rate": 4.627215405589639e-05,
      "loss": 0.682,
      "step": 2250
    },
    {
      "epoch": 0.37710662439512765,
      "grad_norm": 5.6247239112854,
      "learning_rate": 4.625085207907294e-05,
      "loss": 0.6612,
      "step": 2260
    },
    {
      "epoch": 0.37877523777740696,
      "grad_norm": 4.2794623374938965,
      "learning_rate": 4.622955010224949e-05,
      "loss": 0.7075,
      "step": 2270
    },
    {
      "epoch": 0.3804438511596863,
      "grad_norm": 3.1080405712127686,
      "learning_rate": 4.620824812542604e-05,
      "loss": 1.0935,
      "step": 2280
    },
    {
      "epoch": 0.3821124645419656,
      "grad_norm": 8.822911262512207,
      "learning_rate": 4.6186946148602595e-05,
      "loss": 0.5237,
      "step": 2290
    },
    {
      "epoch": 0.38378107792424493,
      "grad_norm": 4.422133445739746,
      "learning_rate": 4.616564417177914e-05,
      "loss": 0.651,
      "step": 2300
    },
    {
      "epoch": 0.3854496913065243,
      "grad_norm": 4.939207553863525,
      "learning_rate": 4.614434219495569e-05,
      "loss": 0.5488,
      "step": 2310
    },
    {
      "epoch": 0.3871183046888036,
      "grad_norm": 5.294416427612305,
      "learning_rate": 4.612304021813225e-05,
      "loss": 0.6721,
      "step": 2320
    },
    {
      "epoch": 0.38878691807108295,
      "grad_norm": 6.780736446380615,
      "learning_rate": 4.6101738241308794e-05,
      "loss": 0.8376,
      "step": 2330
    },
    {
      "epoch": 0.39045553145336226,
      "grad_norm": 7.609031677246094,
      "learning_rate": 4.6080436264485345e-05,
      "loss": 0.6816,
      "step": 2340
    },
    {
      "epoch": 0.39212414483564156,
      "grad_norm": 4.133094310760498,
      "learning_rate": 4.6059134287661897e-05,
      "loss": 0.7729,
      "step": 2350
    },
    {
      "epoch": 0.3937927582179209,
      "grad_norm": 8.204477310180664,
      "learning_rate": 4.603783231083845e-05,
      "loss": 1.0267,
      "step": 2360
    },
    {
      "epoch": 0.39546137160020023,
      "grad_norm": 17.35120964050293,
      "learning_rate": 4.6016530334015e-05,
      "loss": 0.8972,
      "step": 2370
    },
    {
      "epoch": 0.39712998498247953,
      "grad_norm": 5.44019889831543,
      "learning_rate": 4.599522835719155e-05,
      "loss": 1.0079,
      "step": 2380
    },
    {
      "epoch": 0.3987985983647589,
      "grad_norm": 4.769240379333496,
      "learning_rate": 4.59739263803681e-05,
      "loss": 0.7596,
      "step": 2390
    },
    {
      "epoch": 0.4004672117470382,
      "grad_norm": 7.464847564697266,
      "learning_rate": 4.595262440354465e-05,
      "loss": 0.704,
      "step": 2400
    },
    {
      "epoch": 0.40213582512931756,
      "grad_norm": 10.745905876159668,
      "learning_rate": 4.5931322426721205e-05,
      "loss": 0.5582,
      "step": 2410
    },
    {
      "epoch": 0.40380443851159686,
      "grad_norm": 7.3920159339904785,
      "learning_rate": 4.591002044989775e-05,
      "loss": 0.7664,
      "step": 2420
    },
    {
      "epoch": 0.40547305189387617,
      "grad_norm": 8.339971542358398,
      "learning_rate": 4.588871847307431e-05,
      "loss": 0.9273,
      "step": 2430
    },
    {
      "epoch": 0.40714166527615553,
      "grad_norm": 10.794351577758789,
      "learning_rate": 4.586741649625085e-05,
      "loss": 0.9445,
      "step": 2440
    },
    {
      "epoch": 0.40881027865843483,
      "grad_norm": 11.286408424377441,
      "learning_rate": 4.584611451942741e-05,
      "loss": 0.966,
      "step": 2450
    },
    {
      "epoch": 0.4104788920407142,
      "grad_norm": 6.3461408615112305,
      "learning_rate": 4.5824812542603954e-05,
      "loss": 0.8339,
      "step": 2460
    },
    {
      "epoch": 0.4121475054229935,
      "grad_norm": 6.5962910652160645,
      "learning_rate": 4.5803510565780506e-05,
      "loss": 0.8017,
      "step": 2470
    },
    {
      "epoch": 0.4138161188052728,
      "grad_norm": 7.828488349914551,
      "learning_rate": 4.578220858895706e-05,
      "loss": 0.7322,
      "step": 2480
    },
    {
      "epoch": 0.41548473218755216,
      "grad_norm": 8.07767105102539,
      "learning_rate": 4.576090661213361e-05,
      "loss": 0.6047,
      "step": 2490
    },
    {
      "epoch": 0.41715334556983147,
      "grad_norm": 1.8017735481262207,
      "learning_rate": 4.573960463531016e-05,
      "loss": 0.8606,
      "step": 2500
    },
    {
      "epoch": 0.4188219589521108,
      "grad_norm": 2.70247220993042,
      "learning_rate": 4.571830265848671e-05,
      "loss": 0.6885,
      "step": 2510
    },
    {
      "epoch": 0.42049057233439013,
      "grad_norm": 7.9918904304504395,
      "learning_rate": 4.569700068166326e-05,
      "loss": 0.8898,
      "step": 2520
    },
    {
      "epoch": 0.42215918571666944,
      "grad_norm": 5.703439235687256,
      "learning_rate": 4.567569870483981e-05,
      "loss": 0.9081,
      "step": 2530
    },
    {
      "epoch": 0.4238277990989488,
      "grad_norm": 4.583669662475586,
      "learning_rate": 4.5654396728016365e-05,
      "loss": 0.9924,
      "step": 2540
    },
    {
      "epoch": 0.4254964124812281,
      "grad_norm": 15.184752464294434,
      "learning_rate": 4.563309475119291e-05,
      "loss": 0.9082,
      "step": 2550
    },
    {
      "epoch": 0.4271650258635074,
      "grad_norm": 7.087944507598877,
      "learning_rate": 4.561179277436947e-05,
      "loss": 0.8636,
      "step": 2560
    },
    {
      "epoch": 0.42883363924578677,
      "grad_norm": 16.176801681518555,
      "learning_rate": 4.559049079754601e-05,
      "loss": 0.9713,
      "step": 2570
    },
    {
      "epoch": 0.4305022526280661,
      "grad_norm": 7.49072265625,
      "learning_rate": 4.5569188820722564e-05,
      "loss": 0.8582,
      "step": 2580
    },
    {
      "epoch": 0.4321708660103454,
      "grad_norm": 6.530885696411133,
      "learning_rate": 4.5547886843899115e-05,
      "loss": 0.6697,
      "step": 2590
    },
    {
      "epoch": 0.43383947939262474,
      "grad_norm": 2.5926287174224854,
      "learning_rate": 4.5526584867075666e-05,
      "loss": 0.8,
      "step": 2600
    },
    {
      "epoch": 0.43550809277490404,
      "grad_norm": 8.863929748535156,
      "learning_rate": 4.550528289025222e-05,
      "loss": 0.9377,
      "step": 2610
    },
    {
      "epoch": 0.4371767061571834,
      "grad_norm": 9.06806468963623,
      "learning_rate": 4.548398091342877e-05,
      "loss": 0.8037,
      "step": 2620
    },
    {
      "epoch": 0.4388453195394627,
      "grad_norm": 4.179878234863281,
      "learning_rate": 4.546267893660532e-05,
      "loss": 0.7673,
      "step": 2630
    },
    {
      "epoch": 0.440513932921742,
      "grad_norm": 6.408902168273926,
      "learning_rate": 4.5441376959781865e-05,
      "loss": 0.8541,
      "step": 2640
    },
    {
      "epoch": 0.4421825463040214,
      "grad_norm": 5.477489471435547,
      "learning_rate": 4.542007498295842e-05,
      "loss": 0.5573,
      "step": 2650
    },
    {
      "epoch": 0.4438511596863007,
      "grad_norm": 5.637913227081299,
      "learning_rate": 4.539877300613497e-05,
      "loss": 0.768,
      "step": 2660
    },
    {
      "epoch": 0.44551977306858,
      "grad_norm": 1.1066867113113403,
      "learning_rate": 4.5377471029311525e-05,
      "loss": 0.6381,
      "step": 2670
    },
    {
      "epoch": 0.44718838645085934,
      "grad_norm": 9.95750904083252,
      "learning_rate": 4.535616905248807e-05,
      "loss": 1.0243,
      "step": 2680
    },
    {
      "epoch": 0.44885699983313865,
      "grad_norm": 13.113813400268555,
      "learning_rate": 4.533486707566462e-05,
      "loss": 0.5726,
      "step": 2690
    },
    {
      "epoch": 0.450525613215418,
      "grad_norm": 7.13749885559082,
      "learning_rate": 4.531356509884118e-05,
      "loss": 0.8445,
      "step": 2700
    },
    {
      "epoch": 0.4521942265976973,
      "grad_norm": 5.429177761077881,
      "learning_rate": 4.5292263122017724e-05,
      "loss": 1.0661,
      "step": 2710
    },
    {
      "epoch": 0.4538628399799766,
      "grad_norm": 10.41071605682373,
      "learning_rate": 4.5270961145194275e-05,
      "loss": 0.7712,
      "step": 2720
    },
    {
      "epoch": 0.455531453362256,
      "grad_norm": 3.5462491512298584,
      "learning_rate": 4.524965916837083e-05,
      "loss": 1.3715,
      "step": 2730
    },
    {
      "epoch": 0.4572000667445353,
      "grad_norm": 5.9825029373168945,
      "learning_rate": 4.522835719154738e-05,
      "loss": 0.7204,
      "step": 2740
    },
    {
      "epoch": 0.45886868012681464,
      "grad_norm": 5.247767448425293,
      "learning_rate": 4.520705521472393e-05,
      "loss": 0.9851,
      "step": 2750
    },
    {
      "epoch": 0.46053729350909395,
      "grad_norm": 10.903671264648438,
      "learning_rate": 4.518575323790048e-05,
      "loss": 0.7053,
      "step": 2760
    },
    {
      "epoch": 0.46220590689137325,
      "grad_norm": 5.295341968536377,
      "learning_rate": 4.516445126107703e-05,
      "loss": 0.6541,
      "step": 2770
    },
    {
      "epoch": 0.4638745202736526,
      "grad_norm": 7.6296844482421875,
      "learning_rate": 4.514314928425358e-05,
      "loss": 0.7307,
      "step": 2780
    },
    {
      "epoch": 0.4655431336559319,
      "grad_norm": 9.838134765625,
      "learning_rate": 4.5121847307430135e-05,
      "loss": 1.0544,
      "step": 2790
    },
    {
      "epoch": 0.4672117470382112,
      "grad_norm": 14.287303924560547,
      "learning_rate": 4.510054533060668e-05,
      "loss": 1.1315,
      "step": 2800
    },
    {
      "epoch": 0.4688803604204906,
      "grad_norm": 23.80323028564453,
      "learning_rate": 4.507924335378324e-05,
      "loss": 0.586,
      "step": 2810
    },
    {
      "epoch": 0.4705489738027699,
      "grad_norm": 10.448858261108398,
      "learning_rate": 4.505794137695978e-05,
      "loss": 0.8833,
      "step": 2820
    },
    {
      "epoch": 0.47221758718504925,
      "grad_norm": 15.47439956665039,
      "learning_rate": 4.503663940013633e-05,
      "loss": 1.1943,
      "step": 2830
    },
    {
      "epoch": 0.47388620056732855,
      "grad_norm": 11.220212936401367,
      "learning_rate": 4.5015337423312885e-05,
      "loss": 0.6328,
      "step": 2840
    },
    {
      "epoch": 0.47555481394960786,
      "grad_norm": 7.154460906982422,
      "learning_rate": 4.4994035446489436e-05,
      "loss": 0.685,
      "step": 2850
    },
    {
      "epoch": 0.4772234273318872,
      "grad_norm": 1.9077551364898682,
      "learning_rate": 4.497273346966599e-05,
      "loss": 0.527,
      "step": 2860
    },
    {
      "epoch": 0.4788920407141665,
      "grad_norm": 5.975729942321777,
      "learning_rate": 4.495143149284254e-05,
      "loss": 0.9553,
      "step": 2870
    },
    {
      "epoch": 0.4805606540964458,
      "grad_norm": 7.26579475402832,
      "learning_rate": 4.493012951601909e-05,
      "loss": 0.7634,
      "step": 2880
    },
    {
      "epoch": 0.4822292674787252,
      "grad_norm": 9.807287216186523,
      "learning_rate": 4.490882753919564e-05,
      "loss": 0.8687,
      "step": 2890
    },
    {
      "epoch": 0.4838978808610045,
      "grad_norm": 3.80379581451416,
      "learning_rate": 4.488752556237219e-05,
      "loss": 0.625,
      "step": 2900
    },
    {
      "epoch": 0.48556649424328385,
      "grad_norm": 6.512378692626953,
      "learning_rate": 4.486622358554874e-05,
      "loss": 0.5747,
      "step": 2910
    },
    {
      "epoch": 0.48723510762556316,
      "grad_norm": 8.924501419067383,
      "learning_rate": 4.4844921608725295e-05,
      "loss": 0.9141,
      "step": 2920
    },
    {
      "epoch": 0.48890372100784246,
      "grad_norm": 4.610739231109619,
      "learning_rate": 4.482361963190184e-05,
      "loss": 0.6844,
      "step": 2930
    },
    {
      "epoch": 0.4905723343901218,
      "grad_norm": 7.242586612701416,
      "learning_rate": 4.480231765507839e-05,
      "loss": 0.5807,
      "step": 2940
    },
    {
      "epoch": 0.4922409477724011,
      "grad_norm": 7.00779390335083,
      "learning_rate": 4.478101567825494e-05,
      "loss": 1.1259,
      "step": 2950
    },
    {
      "epoch": 0.4939095611546805,
      "grad_norm": 5.875826358795166,
      "learning_rate": 4.4759713701431494e-05,
      "loss": 0.7203,
      "step": 2960
    },
    {
      "epoch": 0.4955781745369598,
      "grad_norm": 12.084908485412598,
      "learning_rate": 4.4738411724608045e-05,
      "loss": 0.9004,
      "step": 2970
    },
    {
      "epoch": 0.4972467879192391,
      "grad_norm": 9.334860801696777,
      "learning_rate": 4.4717109747784596e-05,
      "loss": 0.5229,
      "step": 2980
    },
    {
      "epoch": 0.49891540130151846,
      "grad_norm": 6.018208026885986,
      "learning_rate": 4.469580777096115e-05,
      "loss": 0.7381,
      "step": 2990
    },
    {
      "epoch": 0.5005840146837978,
      "grad_norm": 8.85694408416748,
      "learning_rate": 4.46745057941377e-05,
      "loss": 0.8259,
      "step": 3000
    },
    {
      "epoch": 0.5022526280660771,
      "grad_norm": 4.89293909072876,
      "learning_rate": 4.465320381731425e-05,
      "loss": 0.6567,
      "step": 3010
    },
    {
      "epoch": 0.5039212414483564,
      "grad_norm": 5.356273651123047,
      "learning_rate": 4.4631901840490795e-05,
      "loss": 0.8368,
      "step": 3020
    },
    {
      "epoch": 0.5055898548306358,
      "grad_norm": 3.4905364513397217,
      "learning_rate": 4.461059986366735e-05,
      "loss": 0.7724,
      "step": 3030
    },
    {
      "epoch": 0.5072584682129151,
      "grad_norm": 4.61712121963501,
      "learning_rate": 4.45892978868439e-05,
      "loss": 0.7514,
      "step": 3040
    },
    {
      "epoch": 0.5089270815951944,
      "grad_norm": 4.594651699066162,
      "learning_rate": 4.4567995910020456e-05,
      "loss": 0.8799,
      "step": 3050
    },
    {
      "epoch": 0.5105956949774737,
      "grad_norm": 3.086862802505493,
      "learning_rate": 4.4546693933197e-05,
      "loss": 0.5932,
      "step": 3060
    },
    {
      "epoch": 0.512264308359753,
      "grad_norm": 6.6793670654296875,
      "learning_rate": 4.452539195637355e-05,
      "loss": 0.6143,
      "step": 3070
    },
    {
      "epoch": 0.5139329217420324,
      "grad_norm": 7.795259952545166,
      "learning_rate": 4.450408997955011e-05,
      "loss": 0.9016,
      "step": 3080
    },
    {
      "epoch": 0.5156015351243117,
      "grad_norm": 8.311861991882324,
      "learning_rate": 4.4482788002726654e-05,
      "loss": 0.6561,
      "step": 3090
    },
    {
      "epoch": 0.517270148506591,
      "grad_norm": 5.69581413269043,
      "learning_rate": 4.4461486025903206e-05,
      "loss": 0.7683,
      "step": 3100
    },
    {
      "epoch": 0.5189387618888703,
      "grad_norm": 5.7239670753479,
      "learning_rate": 4.444018404907976e-05,
      "loss": 0.7579,
      "step": 3110
    },
    {
      "epoch": 0.5206073752711496,
      "grad_norm": 9.00308895111084,
      "learning_rate": 4.441888207225631e-05,
      "loss": 0.7257,
      "step": 3120
    },
    {
      "epoch": 0.522275988653429,
      "grad_norm": 5.245102405548096,
      "learning_rate": 4.439758009543285e-05,
      "loss": 0.8876,
      "step": 3130
    },
    {
      "epoch": 0.5239446020357084,
      "grad_norm": 6.678910255432129,
      "learning_rate": 4.437627811860941e-05,
      "loss": 0.5614,
      "step": 3140
    },
    {
      "epoch": 0.5256132154179877,
      "grad_norm": 3.526228904724121,
      "learning_rate": 4.435497614178596e-05,
      "loss": 0.5574,
      "step": 3150
    },
    {
      "epoch": 0.527281828800267,
      "grad_norm": 7.789218425750732,
      "learning_rate": 4.4333674164962513e-05,
      "loss": 0.648,
      "step": 3160
    },
    {
      "epoch": 0.5289504421825463,
      "grad_norm": 8.854560852050781,
      "learning_rate": 4.4312372188139065e-05,
      "loss": 0.8562,
      "step": 3170
    },
    {
      "epoch": 0.5306190555648256,
      "grad_norm": 3.8859331607818604,
      "learning_rate": 4.429107021131561e-05,
      "loss": 0.814,
      "step": 3180
    },
    {
      "epoch": 0.532287668947105,
      "grad_norm": 2.1650381088256836,
      "learning_rate": 4.426976823449217e-05,
      "loss": 0.8992,
      "step": 3190
    },
    {
      "epoch": 0.5339562823293843,
      "grad_norm": 4.191407203674316,
      "learning_rate": 4.424846625766871e-05,
      "loss": 0.7409,
      "step": 3200
    },
    {
      "epoch": 0.5356248957116636,
      "grad_norm": 8.881800651550293,
      "learning_rate": 4.422716428084526e-05,
      "loss": 0.8351,
      "step": 3210
    },
    {
      "epoch": 0.5372935090939429,
      "grad_norm": 23.771503448486328,
      "learning_rate": 4.4205862304021815e-05,
      "loss": 0.6544,
      "step": 3220
    },
    {
      "epoch": 0.5389621224762222,
      "grad_norm": 4.4939866065979,
      "learning_rate": 4.4184560327198366e-05,
      "loss": 0.7578,
      "step": 3230
    },
    {
      "epoch": 0.5406307358585016,
      "grad_norm": 4.12946081161499,
      "learning_rate": 4.416325835037492e-05,
      "loss": 0.738,
      "step": 3240
    },
    {
      "epoch": 0.5422993492407809,
      "grad_norm": 7.04296350479126,
      "learning_rate": 4.414195637355147e-05,
      "loss": 0.7179,
      "step": 3250
    },
    {
      "epoch": 0.5439679626230602,
      "grad_norm": 10.70803451538086,
      "learning_rate": 4.412065439672802e-05,
      "loss": 0.6522,
      "step": 3260
    },
    {
      "epoch": 0.5456365760053395,
      "grad_norm": 5.622879505157471,
      "learning_rate": 4.409935241990457e-05,
      "loss": 0.5527,
      "step": 3270
    },
    {
      "epoch": 0.5473051893876189,
      "grad_norm": 5.373890399932861,
      "learning_rate": 4.407805044308112e-05,
      "loss": 0.6073,
      "step": 3280
    },
    {
      "epoch": 0.5489738027698983,
      "grad_norm": 3.2258732318878174,
      "learning_rate": 4.405674846625767e-05,
      "loss": 0.9545,
      "step": 3290
    },
    {
      "epoch": 0.5506424161521776,
      "grad_norm": 2.4356701374053955,
      "learning_rate": 4.4035446489434225e-05,
      "loss": 0.5894,
      "step": 3300
    },
    {
      "epoch": 0.5523110295344569,
      "grad_norm": 5.7462029457092285,
      "learning_rate": 4.401414451261077e-05,
      "loss": 0.6606,
      "step": 3310
    },
    {
      "epoch": 0.5539796429167362,
      "grad_norm": 9.400675773620605,
      "learning_rate": 4.399284253578732e-05,
      "loss": 0.5878,
      "step": 3320
    },
    {
      "epoch": 0.5556482562990155,
      "grad_norm": 0.8794354200363159,
      "learning_rate": 4.397154055896387e-05,
      "loss": 0.5402,
      "step": 3330
    },
    {
      "epoch": 0.5573168696812948,
      "grad_norm": 10.784392356872559,
      "learning_rate": 4.3950238582140424e-05,
      "loss": 0.7054,
      "step": 3340
    },
    {
      "epoch": 0.5589854830635742,
      "grad_norm": 4.964269161224365,
      "learning_rate": 4.3928936605316975e-05,
      "loss": 0.5962,
      "step": 3350
    },
    {
      "epoch": 0.5606540964458535,
      "grad_norm": 1.5154563188552856,
      "learning_rate": 4.3907634628493527e-05,
      "loss": 0.779,
      "step": 3360
    },
    {
      "epoch": 0.5623227098281328,
      "grad_norm": 4.975042819976807,
      "learning_rate": 4.388633265167008e-05,
      "loss": 0.4746,
      "step": 3370
    },
    {
      "epoch": 0.5639913232104121,
      "grad_norm": 4.829031944274902,
      "learning_rate": 4.386503067484663e-05,
      "loss": 0.8684,
      "step": 3380
    },
    {
      "epoch": 0.5656599365926914,
      "grad_norm": 10.773123741149902,
      "learning_rate": 4.384372869802318e-05,
      "loss": 0.7846,
      "step": 3390
    },
    {
      "epoch": 0.5673285499749708,
      "grad_norm": 8.267843246459961,
      "learning_rate": 4.3822426721199725e-05,
      "loss": 0.8021,
      "step": 3400
    },
    {
      "epoch": 0.5689971633572501,
      "grad_norm": 6.336283206939697,
      "learning_rate": 4.380112474437628e-05,
      "loss": 0.8208,
      "step": 3410
    },
    {
      "epoch": 0.5706657767395295,
      "grad_norm": 9.285051345825195,
      "learning_rate": 4.377982276755283e-05,
      "loss": 0.791,
      "step": 3420
    },
    {
      "epoch": 0.5723343901218088,
      "grad_norm": 4.062178611755371,
      "learning_rate": 4.375852079072938e-05,
      "loss": 0.6316,
      "step": 3430
    },
    {
      "epoch": 0.5740030035040881,
      "grad_norm": 5.078421115875244,
      "learning_rate": 4.373721881390593e-05,
      "loss": 0.7186,
      "step": 3440
    },
    {
      "epoch": 0.5756716168863675,
      "grad_norm": 4.903096675872803,
      "learning_rate": 4.371591683708248e-05,
      "loss": 0.8297,
      "step": 3450
    },
    {
      "epoch": 0.5773402302686468,
      "grad_norm": 9.287599563598633,
      "learning_rate": 4.369461486025904e-05,
      "loss": 0.959,
      "step": 3460
    },
    {
      "epoch": 0.5790088436509261,
      "grad_norm": 6.266707420349121,
      "learning_rate": 4.3673312883435584e-05,
      "loss": 0.4504,
      "step": 3470
    },
    {
      "epoch": 0.5806774570332054,
      "grad_norm": 6.000196933746338,
      "learning_rate": 4.3652010906612136e-05,
      "loss": 1.0367,
      "step": 3480
    },
    {
      "epoch": 0.5823460704154847,
      "grad_norm": 13.49028205871582,
      "learning_rate": 4.363070892978869e-05,
      "loss": 1.0699,
      "step": 3490
    },
    {
      "epoch": 0.5840146837977641,
      "grad_norm": 1.3922760486602783,
      "learning_rate": 4.360940695296524e-05,
      "loss": 0.7977,
      "step": 3500
    },
    {
      "epoch": 0.5856832971800434,
      "grad_norm": 10.190385818481445,
      "learning_rate": 4.358810497614178e-05,
      "loss": 0.6358,
      "step": 3510
    },
    {
      "epoch": 0.5873519105623227,
      "grad_norm": 12.609272956848145,
      "learning_rate": 4.356680299931834e-05,
      "loss": 0.6616,
      "step": 3520
    },
    {
      "epoch": 0.589020523944602,
      "grad_norm": 10.369815826416016,
      "learning_rate": 4.354550102249489e-05,
      "loss": 0.4658,
      "step": 3530
    },
    {
      "epoch": 0.5906891373268813,
      "grad_norm": 5.325717449188232,
      "learning_rate": 4.352419904567144e-05,
      "loss": 0.9338,
      "step": 3540
    },
    {
      "epoch": 0.5923577507091606,
      "grad_norm": 7.492704391479492,
      "learning_rate": 4.3502897068847995e-05,
      "loss": 0.8601,
      "step": 3550
    },
    {
      "epoch": 0.59402636409144,
      "grad_norm": 8.332467079162598,
      "learning_rate": 4.348159509202454e-05,
      "loss": 0.7151,
      "step": 3560
    },
    {
      "epoch": 0.5956949774737194,
      "grad_norm": 1.8067209720611572,
      "learning_rate": 4.34602931152011e-05,
      "loss": 0.711,
      "step": 3570
    },
    {
      "epoch": 0.5973635908559987,
      "grad_norm": 9.219263076782227,
      "learning_rate": 4.343899113837764e-05,
      "loss": 0.5708,
      "step": 3580
    },
    {
      "epoch": 0.599032204238278,
      "grad_norm": 13.367205619812012,
      "learning_rate": 4.3417689161554194e-05,
      "loss": 0.7734,
      "step": 3590
    },
    {
      "epoch": 0.6007008176205573,
      "grad_norm": 7.960381507873535,
      "learning_rate": 4.3396387184730745e-05,
      "loss": 0.481,
      "step": 3600
    },
    {
      "epoch": 0.6023694310028367,
      "grad_norm": 3.48646879196167,
      "learning_rate": 4.3375085207907296e-05,
      "loss": 0.4676,
      "step": 3610
    },
    {
      "epoch": 0.604038044385116,
      "grad_norm": 8.932222366333008,
      "learning_rate": 4.335378323108385e-05,
      "loss": 0.744,
      "step": 3620
    },
    {
      "epoch": 0.6057066577673953,
      "grad_norm": 1.437004566192627,
      "learning_rate": 4.33324812542604e-05,
      "loss": 0.5757,
      "step": 3630
    },
    {
      "epoch": 0.6073752711496746,
      "grad_norm": 16.81715965270996,
      "learning_rate": 4.331117927743695e-05,
      "loss": 0.9272,
      "step": 3640
    },
    {
      "epoch": 0.6090438845319539,
      "grad_norm": 7.365987777709961,
      "learning_rate": 4.32898773006135e-05,
      "loss": 0.9693,
      "step": 3650
    },
    {
      "epoch": 0.6107124979142333,
      "grad_norm": 2.937911033630371,
      "learning_rate": 4.326857532379005e-05,
      "loss": 0.6983,
      "step": 3660
    },
    {
      "epoch": 0.6123811112965126,
      "grad_norm": 3.4766414165496826,
      "learning_rate": 4.32472733469666e-05,
      "loss": 0.8442,
      "step": 3670
    },
    {
      "epoch": 0.6140497246787919,
      "grad_norm": 7.140987396240234,
      "learning_rate": 4.3225971370143155e-05,
      "loss": 0.8965,
      "step": 3680
    },
    {
      "epoch": 0.6157183380610712,
      "grad_norm": 2.846816301345825,
      "learning_rate": 4.32046693933197e-05,
      "loss": 0.593,
      "step": 3690
    },
    {
      "epoch": 0.6173869514433505,
      "grad_norm": 5.269775867462158,
      "learning_rate": 4.318336741649625e-05,
      "loss": 0.7344,
      "step": 3700
    },
    {
      "epoch": 0.61905556482563,
      "grad_norm": 7.564129829406738,
      "learning_rate": 4.31620654396728e-05,
      "loss": 1.1109,
      "step": 3710
    },
    {
      "epoch": 0.6207241782079093,
      "grad_norm": 4.115617752075195,
      "learning_rate": 4.3140763462849354e-05,
      "loss": 0.807,
      "step": 3720
    },
    {
      "epoch": 0.6223927915901886,
      "grad_norm": 8.914811134338379,
      "learning_rate": 4.3119461486025905e-05,
      "loss": 0.7274,
      "step": 3730
    },
    {
      "epoch": 0.6240614049724679,
      "grad_norm": 6.307037830352783,
      "learning_rate": 4.309815950920246e-05,
      "loss": 0.6101,
      "step": 3740
    },
    {
      "epoch": 0.6257300183547472,
      "grad_norm": 6.693923473358154,
      "learning_rate": 4.307685753237901e-05,
      "loss": 0.7246,
      "step": 3750
    },
    {
      "epoch": 0.6273986317370265,
      "grad_norm": 7.183480262756348,
      "learning_rate": 4.305555555555556e-05,
      "loss": 0.6983,
      "step": 3760
    },
    {
      "epoch": 0.6290672451193059,
      "grad_norm": 4.5037713050842285,
      "learning_rate": 4.303425357873211e-05,
      "loss": 0.7726,
      "step": 3770
    },
    {
      "epoch": 0.6307358585015852,
      "grad_norm": 6.928258419036865,
      "learning_rate": 4.3012951601908655e-05,
      "loss": 0.8078,
      "step": 3780
    },
    {
      "epoch": 0.6324044718838645,
      "grad_norm": 8.762860298156738,
      "learning_rate": 4.299164962508521e-05,
      "loss": 0.7574,
      "step": 3790
    },
    {
      "epoch": 0.6340730852661438,
      "grad_norm": 3.7122573852539062,
      "learning_rate": 4.297034764826176e-05,
      "loss": 1.113,
      "step": 3800
    },
    {
      "epoch": 0.6357416986484231,
      "grad_norm": 4.502765655517578,
      "learning_rate": 4.294904567143831e-05,
      "loss": 0.6806,
      "step": 3810
    },
    {
      "epoch": 0.6374103120307025,
      "grad_norm": 4.965606689453125,
      "learning_rate": 4.292774369461486e-05,
      "loss": 0.501,
      "step": 3820
    },
    {
      "epoch": 0.6390789254129818,
      "grad_norm": 3.083747148513794,
      "learning_rate": 4.290644171779141e-05,
      "loss": 0.538,
      "step": 3830
    },
    {
      "epoch": 0.6407475387952611,
      "grad_norm": 6.130108833312988,
      "learning_rate": 4.288513974096796e-05,
      "loss": 0.9588,
      "step": 3840
    },
    {
      "epoch": 0.6424161521775404,
      "grad_norm": 11.183204650878906,
      "learning_rate": 4.2863837764144514e-05,
      "loss": 0.7925,
      "step": 3850
    },
    {
      "epoch": 0.6440847655598197,
      "grad_norm": 9.033961296081543,
      "learning_rate": 4.2842535787321066e-05,
      "loss": 0.5568,
      "step": 3860
    },
    {
      "epoch": 0.6457533789420992,
      "grad_norm": 4.446171283721924,
      "learning_rate": 4.282123381049762e-05,
      "loss": 0.7081,
      "step": 3870
    },
    {
      "epoch": 0.6474219923243785,
      "grad_norm": 6.688575267791748,
      "learning_rate": 4.279993183367417e-05,
      "loss": 0.8001,
      "step": 3880
    },
    {
      "epoch": 0.6490906057066578,
      "grad_norm": 6.0021491050720215,
      "learning_rate": 4.277862985685071e-05,
      "loss": 0.608,
      "step": 3890
    },
    {
      "epoch": 0.6507592190889371,
      "grad_norm": 9.344532012939453,
      "learning_rate": 4.275732788002727e-05,
      "loss": 0.7972,
      "step": 3900
    },
    {
      "epoch": 0.6524278324712164,
      "grad_norm": 5.105352401733398,
      "learning_rate": 4.2736025903203816e-05,
      "loss": 0.6866,
      "step": 3910
    },
    {
      "epoch": 0.6540964458534958,
      "grad_norm": 0.667101263999939,
      "learning_rate": 4.271472392638037e-05,
      "loss": 0.5994,
      "step": 3920
    },
    {
      "epoch": 0.6557650592357751,
      "grad_norm": 8.293266296386719,
      "learning_rate": 4.2693421949556925e-05,
      "loss": 0.6765,
      "step": 3930
    },
    {
      "epoch": 0.6574336726180544,
      "grad_norm": 6.091841220855713,
      "learning_rate": 4.267211997273347e-05,
      "loss": 0.7459,
      "step": 3940
    },
    {
      "epoch": 0.6591022860003337,
      "grad_norm": 6.039409160614014,
      "learning_rate": 4.265081799591003e-05,
      "loss": 0.7607,
      "step": 3950
    },
    {
      "epoch": 0.660770899382613,
      "grad_norm": 2.564216375350952,
      "learning_rate": 4.262951601908657e-05,
      "loss": 0.6541,
      "step": 3960
    },
    {
      "epoch": 0.6624395127648923,
      "grad_norm": 2.593445301055908,
      "learning_rate": 4.2608214042263124e-05,
      "loss": 0.5377,
      "step": 3970
    },
    {
      "epoch": 0.6641081261471717,
      "grad_norm": 8.44690990447998,
      "learning_rate": 4.2586912065439675e-05,
      "loss": 1.0081,
      "step": 3980
    },
    {
      "epoch": 0.665776739529451,
      "grad_norm": 6.10532808303833,
      "learning_rate": 4.2565610088616226e-05,
      "loss": 0.7588,
      "step": 3990
    },
    {
      "epoch": 0.6674453529117303,
      "grad_norm": 6.348032474517822,
      "learning_rate": 4.254430811179278e-05,
      "loss": 0.949,
      "step": 4000
    },
    {
      "epoch": 0.6691139662940097,
      "grad_norm": 8.885832786560059,
      "learning_rate": 4.252300613496933e-05,
      "loss": 0.5312,
      "step": 4010
    },
    {
      "epoch": 0.670782579676289,
      "grad_norm": 6.259112358093262,
      "learning_rate": 4.250170415814588e-05,
      "loss": 0.8495,
      "step": 4020
    },
    {
      "epoch": 0.6724511930585684,
      "grad_norm": 3.0387065410614014,
      "learning_rate": 4.2480402181322425e-05,
      "loss": 0.6002,
      "step": 4030
    },
    {
      "epoch": 0.6741198064408477,
      "grad_norm": 5.885565280914307,
      "learning_rate": 4.245910020449898e-05,
      "loss": 0.6737,
      "step": 4040
    },
    {
      "epoch": 0.675788419823127,
      "grad_norm": 11.289076805114746,
      "learning_rate": 4.243779822767553e-05,
      "loss": 1.1575,
      "step": 4050
    },
    {
      "epoch": 0.6774570332054063,
      "grad_norm": 9.999051094055176,
      "learning_rate": 4.2416496250852086e-05,
      "loss": 0.7094,
      "step": 4060
    },
    {
      "epoch": 0.6791256465876856,
      "grad_norm": 7.9299235343933105,
      "learning_rate": 4.239519427402863e-05,
      "loss": 0.7829,
      "step": 4070
    },
    {
      "epoch": 0.680794259969965,
      "grad_norm": 9.301661491394043,
      "learning_rate": 4.237389229720518e-05,
      "loss": 0.9628,
      "step": 4080
    },
    {
      "epoch": 0.6824628733522443,
      "grad_norm": 11.437853813171387,
      "learning_rate": 4.235259032038173e-05,
      "loss": 0.9998,
      "step": 4090
    },
    {
      "epoch": 0.6841314867345236,
      "grad_norm": 4.55493688583374,
      "learning_rate": 4.2331288343558284e-05,
      "loss": 0.4362,
      "step": 4100
    },
    {
      "epoch": 0.6858001001168029,
      "grad_norm": 7.243223190307617,
      "learning_rate": 4.2309986366734835e-05,
      "loss": 0.6433,
      "step": 4110
    },
    {
      "epoch": 0.6874687134990822,
      "grad_norm": 2.93525767326355,
      "learning_rate": 4.228868438991139e-05,
      "loss": 0.5778,
      "step": 4120
    },
    {
      "epoch": 0.6891373268813615,
      "grad_norm": 8.642040252685547,
      "learning_rate": 4.226738241308794e-05,
      "loss": 0.8699,
      "step": 4130
    },
    {
      "epoch": 0.690805940263641,
      "grad_norm": 1.8188085556030273,
      "learning_rate": 4.224608043626448e-05,
      "loss": 0.8268,
      "step": 4140
    },
    {
      "epoch": 0.6924745536459203,
      "grad_norm": 7.2352752685546875,
      "learning_rate": 4.222477845944104e-05,
      "loss": 0.4464,
      "step": 4150
    },
    {
      "epoch": 0.6941431670281996,
      "grad_norm": 8.987089157104492,
      "learning_rate": 4.2203476482617585e-05,
      "loss": 0.5024,
      "step": 4160
    },
    {
      "epoch": 0.6958117804104789,
      "grad_norm": 12.73311996459961,
      "learning_rate": 4.2182174505794143e-05,
      "loss": 0.9632,
      "step": 4170
    },
    {
      "epoch": 0.6974803937927582,
      "grad_norm": 9.871585845947266,
      "learning_rate": 4.216087252897069e-05,
      "loss": 0.7035,
      "step": 4180
    },
    {
      "epoch": 0.6991490071750376,
      "grad_norm": 7.942930221557617,
      "learning_rate": 4.213957055214724e-05,
      "loss": 0.6375,
      "step": 4190
    },
    {
      "epoch": 0.7008176205573169,
      "grad_norm": 6.049046993255615,
      "learning_rate": 4.211826857532379e-05,
      "loss": 0.6483,
      "step": 4200
    },
    {
      "epoch": 0.7024862339395962,
      "grad_norm": 9.923908233642578,
      "learning_rate": 4.209696659850034e-05,
      "loss": 0.8694,
      "step": 4210
    },
    {
      "epoch": 0.7041548473218755,
      "grad_norm": 5.461172580718994,
      "learning_rate": 4.207566462167689e-05,
      "loss": 0.5718,
      "step": 4220
    },
    {
      "epoch": 0.7058234607041548,
      "grad_norm": 10.776086807250977,
      "learning_rate": 4.2054362644853445e-05,
      "loss": 0.8369,
      "step": 4230
    },
    {
      "epoch": 0.7074920740864342,
      "grad_norm": 4.959886074066162,
      "learning_rate": 4.2033060668029996e-05,
      "loss": 0.6308,
      "step": 4240
    },
    {
      "epoch": 0.7091606874687135,
      "grad_norm": 15.118078231811523,
      "learning_rate": 4.201175869120655e-05,
      "loss": 0.5623,
      "step": 4250
    },
    {
      "epoch": 0.7108293008509928,
      "grad_norm": 8.131327629089355,
      "learning_rate": 4.19904567143831e-05,
      "loss": 0.7075,
      "step": 4260
    },
    {
      "epoch": 0.7124979142332721,
      "grad_norm": 9.716422080993652,
      "learning_rate": 4.196915473755964e-05,
      "loss": 0.6262,
      "step": 4270
    },
    {
      "epoch": 0.7141665276155514,
      "grad_norm": 3.214151382446289,
      "learning_rate": 4.19478527607362e-05,
      "loss": 0.6034,
      "step": 4280
    },
    {
      "epoch": 0.7158351409978309,
      "grad_norm": 4.074402332305908,
      "learning_rate": 4.1926550783912746e-05,
      "loss": 0.7989,
      "step": 4290
    },
    {
      "epoch": 0.7175037543801102,
      "grad_norm": 7.163739204406738,
      "learning_rate": 4.19052488070893e-05,
      "loss": 0.9275,
      "step": 4300
    },
    {
      "epoch": 0.7191723677623895,
      "grad_norm": 7.367880821228027,
      "learning_rate": 4.1883946830265855e-05,
      "loss": 0.5448,
      "step": 4310
    },
    {
      "epoch": 0.7208409811446688,
      "grad_norm": 8.09970760345459,
      "learning_rate": 4.18626448534424e-05,
      "loss": 0.5303,
      "step": 4320
    },
    {
      "epoch": 0.7225095945269481,
      "grad_norm": 6.714642524719238,
      "learning_rate": 4.184134287661895e-05,
      "loss": 0.5531,
      "step": 4330
    },
    {
      "epoch": 0.7241782079092274,
      "grad_norm": 1.1687126159667969,
      "learning_rate": 4.18200408997955e-05,
      "loss": 0.6571,
      "step": 4340
    },
    {
      "epoch": 0.7258468212915068,
      "grad_norm": 6.26352071762085,
      "learning_rate": 4.1798738922972054e-05,
      "loss": 0.6732,
      "step": 4350
    },
    {
      "epoch": 0.7275154346737861,
      "grad_norm": 10.937356948852539,
      "learning_rate": 4.1777436946148605e-05,
      "loss": 0.608,
      "step": 4360
    },
    {
      "epoch": 0.7291840480560654,
      "grad_norm": 4.903808116912842,
      "learning_rate": 4.1756134969325156e-05,
      "loss": 0.6646,
      "step": 4370
    },
    {
      "epoch": 0.7308526614383447,
      "grad_norm": 6.324450492858887,
      "learning_rate": 4.173483299250171e-05,
      "loss": 0.5736,
      "step": 4380
    },
    {
      "epoch": 0.732521274820624,
      "grad_norm": 6.476178169250488,
      "learning_rate": 4.171353101567826e-05,
      "loss": 0.5545,
      "step": 4390
    },
    {
      "epoch": 0.7341898882029034,
      "grad_norm": 2.108445882797241,
      "learning_rate": 4.169222903885481e-05,
      "loss": 0.5225,
      "step": 4400
    },
    {
      "epoch": 0.7358585015851827,
      "grad_norm": 8.852609634399414,
      "learning_rate": 4.1670927062031355e-05,
      "loss": 0.4368,
      "step": 4410
    },
    {
      "epoch": 0.737527114967462,
      "grad_norm": 4.862251281738281,
      "learning_rate": 4.164962508520791e-05,
      "loss": 0.3635,
      "step": 4420
    },
    {
      "epoch": 0.7391957283497413,
      "grad_norm": 12.884478569030762,
      "learning_rate": 4.162832310838446e-05,
      "loss": 0.8591,
      "step": 4430
    },
    {
      "epoch": 0.7408643417320206,
      "grad_norm": 8.639510154724121,
      "learning_rate": 4.160702113156101e-05,
      "loss": 0.7237,
      "step": 4440
    },
    {
      "epoch": 0.7425329551143001,
      "grad_norm": 5.25611686706543,
      "learning_rate": 4.158571915473756e-05,
      "loss": 1.0857,
      "step": 4450
    },
    {
      "epoch": 0.7442015684965794,
      "grad_norm": 6.877534866333008,
      "learning_rate": 4.156441717791411e-05,
      "loss": 0.4412,
      "step": 4460
    },
    {
      "epoch": 0.7458701818788587,
      "grad_norm": 9.823124885559082,
      "learning_rate": 4.154311520109066e-05,
      "loss": 0.5941,
      "step": 4470
    },
    {
      "epoch": 0.747538795261138,
      "grad_norm": 8.539118766784668,
      "learning_rate": 4.1521813224267214e-05,
      "loss": 0.8642,
      "step": 4480
    },
    {
      "epoch": 0.7492074086434173,
      "grad_norm": 8.372551918029785,
      "learning_rate": 4.1500511247443766e-05,
      "loss": 0.941,
      "step": 4490
    },
    {
      "epoch": 0.7508760220256967,
      "grad_norm": 3.806669235229492,
      "learning_rate": 4.147920927062032e-05,
      "loss": 0.6955,
      "step": 4500
    },
    {
      "epoch": 0.752544635407976,
      "grad_norm": 4.872559547424316,
      "learning_rate": 4.145790729379687e-05,
      "loss": 0.7113,
      "step": 4510
    },
    {
      "epoch": 0.7542132487902553,
      "grad_norm": 6.39990758895874,
      "learning_rate": 4.143660531697341e-05,
      "loss": 0.5752,
      "step": 4520
    },
    {
      "epoch": 0.7558818621725346,
      "grad_norm": 9.073878288269043,
      "learning_rate": 4.141530334014997e-05,
      "loss": 0.8966,
      "step": 4530
    },
    {
      "epoch": 0.7575504755548139,
      "grad_norm": 8.259525299072266,
      "learning_rate": 4.1394001363326516e-05,
      "loss": 0.7544,
      "step": 4540
    },
    {
      "epoch": 0.7592190889370932,
      "grad_norm": 9.095061302185059,
      "learning_rate": 4.1372699386503074e-05,
      "loss": 0.6377,
      "step": 4550
    },
    {
      "epoch": 0.7608877023193726,
      "grad_norm": 3.3842735290527344,
      "learning_rate": 4.135139740967962e-05,
      "loss": 0.4586,
      "step": 4560
    },
    {
      "epoch": 0.7625563157016519,
      "grad_norm": 11.09359073638916,
      "learning_rate": 4.133009543285617e-05,
      "loss": 0.8225,
      "step": 4570
    },
    {
      "epoch": 0.7642249290839312,
      "grad_norm": 7.516799449920654,
      "learning_rate": 4.130879345603272e-05,
      "loss": 0.9417,
      "step": 4580
    },
    {
      "epoch": 0.7658935424662106,
      "grad_norm": 8.702359199523926,
      "learning_rate": 4.128749147920927e-05,
      "loss": 0.8059,
      "step": 4590
    },
    {
      "epoch": 0.7675621558484899,
      "grad_norm": 4.871837139129639,
      "learning_rate": 4.1266189502385823e-05,
      "loss": 0.6167,
      "step": 4600
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 5.978969573974609,
      "learning_rate": 4.1244887525562375e-05,
      "loss": 0.6297,
      "step": 4610
    },
    {
      "epoch": 0.7708993826130486,
      "grad_norm": 7.267699241638184,
      "learning_rate": 4.1223585548738926e-05,
      "loss": 0.5319,
      "step": 4620
    },
    {
      "epoch": 0.7725679959953279,
      "grad_norm": 5.294400691986084,
      "learning_rate": 4.120228357191547e-05,
      "loss": 0.9719,
      "step": 4630
    },
    {
      "epoch": 0.7742366093776072,
      "grad_norm": 7.456960201263428,
      "learning_rate": 4.118098159509203e-05,
      "loss": 0.8657,
      "step": 4640
    },
    {
      "epoch": 0.7759052227598865,
      "grad_norm": 7.910400390625,
      "learning_rate": 4.115967961826857e-05,
      "loss": 0.8676,
      "step": 4650
    },
    {
      "epoch": 0.7775738361421659,
      "grad_norm": 4.210155963897705,
      "learning_rate": 4.113837764144513e-05,
      "loss": 0.6633,
      "step": 4660
    },
    {
      "epoch": 0.7792424495244452,
      "grad_norm": 7.547813892364502,
      "learning_rate": 4.1117075664621676e-05,
      "loss": 0.75,
      "step": 4670
    },
    {
      "epoch": 0.7809110629067245,
      "grad_norm": 6.9306440353393555,
      "learning_rate": 4.109577368779823e-05,
      "loss": 0.6064,
      "step": 4680
    },
    {
      "epoch": 0.7825796762890038,
      "grad_norm": 4.675894260406494,
      "learning_rate": 4.1074471710974785e-05,
      "loss": 0.4711,
      "step": 4690
    },
    {
      "epoch": 0.7842482896712831,
      "grad_norm": 12.16272258758545,
      "learning_rate": 4.105316973415133e-05,
      "loss": 0.5497,
      "step": 4700
    },
    {
      "epoch": 0.7859169030535625,
      "grad_norm": 16.51823616027832,
      "learning_rate": 4.103186775732788e-05,
      "loss": 0.7037,
      "step": 4710
    },
    {
      "epoch": 0.7875855164358418,
      "grad_norm": 5.109891414642334,
      "learning_rate": 4.101056578050443e-05,
      "loss": 0.721,
      "step": 4720
    },
    {
      "epoch": 0.7892541298181212,
      "grad_norm": 6.841188907623291,
      "learning_rate": 4.0989263803680984e-05,
      "loss": 0.6291,
      "step": 4730
    },
    {
      "epoch": 0.7909227432004005,
      "grad_norm": 9.411490440368652,
      "learning_rate": 4.096796182685753e-05,
      "loss": 0.826,
      "step": 4740
    },
    {
      "epoch": 0.7925913565826798,
      "grad_norm": 6.792606353759766,
      "learning_rate": 4.094665985003409e-05,
      "loss": 0.4422,
      "step": 4750
    },
    {
      "epoch": 0.7942599699649591,
      "grad_norm": 10.627891540527344,
      "learning_rate": 4.092535787321064e-05,
      "loss": 0.8627,
      "step": 4760
    },
    {
      "epoch": 0.7959285833472385,
      "grad_norm": 3.5424792766571045,
      "learning_rate": 4.090405589638719e-05,
      "loss": 0.5445,
      "step": 4770
    },
    {
      "epoch": 0.7975971967295178,
      "grad_norm": 7.913875579833984,
      "learning_rate": 4.088275391956374e-05,
      "loss": 0.4995,
      "step": 4780
    },
    {
      "epoch": 0.7992658101117971,
      "grad_norm": 4.588155746459961,
      "learning_rate": 4.0861451942740285e-05,
      "loss": 0.7042,
      "step": 4790
    },
    {
      "epoch": 0.8009344234940764,
      "grad_norm": 2.9795498847961426,
      "learning_rate": 4.084014996591684e-05,
      "loss": 0.4652,
      "step": 4800
    },
    {
      "epoch": 0.8026030368763557,
      "grad_norm": 6.137686729431152,
      "learning_rate": 4.081884798909339e-05,
      "loss": 0.6991,
      "step": 4810
    },
    {
      "epoch": 0.8042716502586351,
      "grad_norm": 4.010180473327637,
      "learning_rate": 4.079754601226994e-05,
      "loss": 0.6801,
      "step": 4820
    },
    {
      "epoch": 0.8059402636409144,
      "grad_norm": 4.369078636169434,
      "learning_rate": 4.077624403544649e-05,
      "loss": 0.8245,
      "step": 4830
    },
    {
      "epoch": 0.8076088770231937,
      "grad_norm": 11.5368013381958,
      "learning_rate": 4.075494205862304e-05,
      "loss": 1.1635,
      "step": 4840
    },
    {
      "epoch": 0.809277490405473,
      "grad_norm": 6.361441612243652,
      "learning_rate": 4.073364008179959e-05,
      "loss": 0.2785,
      "step": 4850
    },
    {
      "epoch": 0.8109461037877523,
      "grad_norm": 1.2545968294143677,
      "learning_rate": 4.0712338104976144e-05,
      "loss": 0.6861,
      "step": 4860
    },
    {
      "epoch": 0.8126147171700318,
      "grad_norm": 8.083144187927246,
      "learning_rate": 4.0691036128152696e-05,
      "loss": 0.7574,
      "step": 4870
    },
    {
      "epoch": 0.8142833305523111,
      "grad_norm": 7.553082466125488,
      "learning_rate": 4.066973415132925e-05,
      "loss": 0.6912,
      "step": 4880
    },
    {
      "epoch": 0.8159519439345904,
      "grad_norm": 5.209771156311035,
      "learning_rate": 4.06484321745058e-05,
      "loss": 0.7128,
      "step": 4890
    },
    {
      "epoch": 0.8176205573168697,
      "grad_norm": 13.643183708190918,
      "learning_rate": 4.062713019768234e-05,
      "loss": 0.6429,
      "step": 4900
    },
    {
      "epoch": 0.819289170699149,
      "grad_norm": 13.913156509399414,
      "learning_rate": 4.06058282208589e-05,
      "loss": 0.7242,
      "step": 4910
    },
    {
      "epoch": 0.8209577840814284,
      "grad_norm": 5.303826808929443,
      "learning_rate": 4.0584526244035446e-05,
      "loss": 0.766,
      "step": 4920
    },
    {
      "epoch": 0.8226263974637077,
      "grad_norm": 3.849189281463623,
      "learning_rate": 4.0563224267212e-05,
      "loss": 0.5202,
      "step": 4930
    },
    {
      "epoch": 0.824295010845987,
      "grad_norm": 5.480501651763916,
      "learning_rate": 4.054192229038855e-05,
      "loss": 0.6775,
      "step": 4940
    },
    {
      "epoch": 0.8259636242282663,
      "grad_norm": 7.440640449523926,
      "learning_rate": 4.05206203135651e-05,
      "loss": 0.5223,
      "step": 4950
    },
    {
      "epoch": 0.8276322376105456,
      "grad_norm": 6.773004055023193,
      "learning_rate": 4.049931833674165e-05,
      "loss": 0.6429,
      "step": 4960
    },
    {
      "epoch": 0.8293008509928249,
      "grad_norm": 17.210622787475586,
      "learning_rate": 4.04780163599182e-05,
      "loss": 0.78,
      "step": 4970
    },
    {
      "epoch": 0.8309694643751043,
      "grad_norm": 9.461005210876465,
      "learning_rate": 4.0456714383094754e-05,
      "loss": 0.8105,
      "step": 4980
    },
    {
      "epoch": 0.8326380777573836,
      "grad_norm": 6.6932549476623535,
      "learning_rate": 4.0435412406271305e-05,
      "loss": 1.1653,
      "step": 4990
    },
    {
      "epoch": 0.8343066911396629,
      "grad_norm": 9.994537353515625,
      "learning_rate": 4.0414110429447856e-05,
      "loss": 0.8045,
      "step": 5000
    },
    {
      "epoch": 0.8359753045219422,
      "grad_norm": 6.114248752593994,
      "learning_rate": 4.03928084526244e-05,
      "loss": 0.8358,
      "step": 5010
    },
    {
      "epoch": 0.8376439179042215,
      "grad_norm": 3.5686943531036377,
      "learning_rate": 4.037150647580096e-05,
      "loss": 0.5322,
      "step": 5020
    },
    {
      "epoch": 0.839312531286501,
      "grad_norm": 3.305602550506592,
      "learning_rate": 4.0350204498977503e-05,
      "loss": 0.6466,
      "step": 5030
    },
    {
      "epoch": 0.8409811446687803,
      "grad_norm": 6.408198356628418,
      "learning_rate": 4.0328902522154055e-05,
      "loss": 0.6449,
      "step": 5040
    },
    {
      "epoch": 0.8426497580510596,
      "grad_norm": 13.212977409362793,
      "learning_rate": 4.0307600545330606e-05,
      "loss": 0.7199,
      "step": 5050
    },
    {
      "epoch": 0.8443183714333389,
      "grad_norm": 7.085546493530273,
      "learning_rate": 4.028629856850716e-05,
      "loss": 0.8435,
      "step": 5060
    },
    {
      "epoch": 0.8459869848156182,
      "grad_norm": 7.736124515533447,
      "learning_rate": 4.0264996591683716e-05,
      "loss": 1.1025,
      "step": 5070
    },
    {
      "epoch": 0.8476555981978976,
      "grad_norm": 4.315603733062744,
      "learning_rate": 4.024369461486026e-05,
      "loss": 0.7415,
      "step": 5080
    },
    {
      "epoch": 0.8493242115801769,
      "grad_norm": 5.228132247924805,
      "learning_rate": 4.022239263803681e-05,
      "loss": 0.6567,
      "step": 5090
    },
    {
      "epoch": 0.8509928249624562,
      "grad_norm": 9.190413475036621,
      "learning_rate": 4.020109066121336e-05,
      "loss": 0.7975,
      "step": 5100
    },
    {
      "epoch": 0.8526614383447355,
      "grad_norm": 5.6962385177612305,
      "learning_rate": 4.0179788684389914e-05,
      "loss": 0.6476,
      "step": 5110
    },
    {
      "epoch": 0.8543300517270148,
      "grad_norm": 2.631312847137451,
      "learning_rate": 4.015848670756646e-05,
      "loss": 0.5019,
      "step": 5120
    },
    {
      "epoch": 0.8559986651092941,
      "grad_norm": 10.998701095581055,
      "learning_rate": 4.013718473074302e-05,
      "loss": 0.8213,
      "step": 5130
    },
    {
      "epoch": 0.8576672784915735,
      "grad_norm": 4.476869106292725,
      "learning_rate": 4.011588275391957e-05,
      "loss": 0.7319,
      "step": 5140
    },
    {
      "epoch": 0.8593358918738528,
      "grad_norm": 9.150187492370605,
      "learning_rate": 4.009458077709612e-05,
      "loss": 0.5819,
      "step": 5150
    },
    {
      "epoch": 0.8610045052561321,
      "grad_norm": 7.1300177574157715,
      "learning_rate": 4.007327880027267e-05,
      "loss": 0.5257,
      "step": 5160
    },
    {
      "epoch": 0.8626731186384115,
      "grad_norm": 6.205604553222656,
      "learning_rate": 4.0051976823449215e-05,
      "loss": 0.9618,
      "step": 5170
    },
    {
      "epoch": 0.8643417320206908,
      "grad_norm": 8.86750316619873,
      "learning_rate": 4.0030674846625773e-05,
      "loss": 0.8152,
      "step": 5180
    },
    {
      "epoch": 0.8660103454029702,
      "grad_norm": 7.690610885620117,
      "learning_rate": 4.000937286980232e-05,
      "loss": 0.68,
      "step": 5190
    },
    {
      "epoch": 0.8676789587852495,
      "grad_norm": 3.9835286140441895,
      "learning_rate": 3.998807089297887e-05,
      "loss": 0.7588,
      "step": 5200
    },
    {
      "epoch": 0.8693475721675288,
      "grad_norm": 2.502793073654175,
      "learning_rate": 3.996676891615542e-05,
      "loss": 0.5734,
      "step": 5210
    },
    {
      "epoch": 0.8710161855498081,
      "grad_norm": 3.6077799797058105,
      "learning_rate": 3.994546693933197e-05,
      "loss": 0.7394,
      "step": 5220
    },
    {
      "epoch": 0.8726847989320874,
      "grad_norm": 4.495758056640625,
      "learning_rate": 3.992416496250852e-05,
      "loss": 0.5086,
      "step": 5230
    },
    {
      "epoch": 0.8743534123143668,
      "grad_norm": 5.819901943206787,
      "learning_rate": 3.9902862985685075e-05,
      "loss": 0.4372,
      "step": 5240
    },
    {
      "epoch": 0.8760220256966461,
      "grad_norm": 9.174017906188965,
      "learning_rate": 3.9881561008861626e-05,
      "loss": 0.5426,
      "step": 5250
    },
    {
      "epoch": 0.8776906390789254,
      "grad_norm": 5.728267669677734,
      "learning_rate": 3.986025903203818e-05,
      "loss": 0.6011,
      "step": 5260
    },
    {
      "epoch": 0.8793592524612047,
      "grad_norm": 11.243270874023438,
      "learning_rate": 3.983895705521473e-05,
      "loss": 0.7131,
      "step": 5270
    },
    {
      "epoch": 0.881027865843484,
      "grad_norm": 7.2624077796936035,
      "learning_rate": 3.981765507839127e-05,
      "loss": 0.837,
      "step": 5280
    },
    {
      "epoch": 0.8826964792257634,
      "grad_norm": 15.410677909851074,
      "learning_rate": 3.979635310156783e-05,
      "loss": 0.7819,
      "step": 5290
    },
    {
      "epoch": 0.8843650926080427,
      "grad_norm": 4.9948201179504395,
      "learning_rate": 3.9775051124744376e-05,
      "loss": 0.4872,
      "step": 5300
    },
    {
      "epoch": 0.886033705990322,
      "grad_norm": 11.277363777160645,
      "learning_rate": 3.975374914792093e-05,
      "loss": 0.9607,
      "step": 5310
    },
    {
      "epoch": 0.8877023193726014,
      "grad_norm": 9.392916679382324,
      "learning_rate": 3.973244717109748e-05,
      "loss": 0.8722,
      "step": 5320
    },
    {
      "epoch": 0.8893709327548807,
      "grad_norm": 4.632662296295166,
      "learning_rate": 3.971114519427403e-05,
      "loss": 0.583,
      "step": 5330
    },
    {
      "epoch": 0.89103954613716,
      "grad_norm": 12.589158058166504,
      "learning_rate": 3.968984321745058e-05,
      "loss": 0.8729,
      "step": 5340
    },
    {
      "epoch": 0.8927081595194394,
      "grad_norm": 7.155453681945801,
      "learning_rate": 3.966854124062713e-05,
      "loss": 0.6203,
      "step": 5350
    },
    {
      "epoch": 0.8943767729017187,
      "grad_norm": 9.711152076721191,
      "learning_rate": 3.9647239263803684e-05,
      "loss": 0.7692,
      "step": 5360
    },
    {
      "epoch": 0.896045386283998,
      "grad_norm": 8.618765830993652,
      "learning_rate": 3.9625937286980235e-05,
      "loss": 0.9834,
      "step": 5370
    },
    {
      "epoch": 0.8977139996662773,
      "grad_norm": 21.52099609375,
      "learning_rate": 3.9604635310156786e-05,
      "loss": 0.5869,
      "step": 5380
    },
    {
      "epoch": 0.8993826130485566,
      "grad_norm": 8.747952461242676,
      "learning_rate": 3.958333333333333e-05,
      "loss": 0.8227,
      "step": 5390
    },
    {
      "epoch": 0.901051226430836,
      "grad_norm": 10.506210327148438,
      "learning_rate": 3.956203135650989e-05,
      "loss": 1.0179,
      "step": 5400
    },
    {
      "epoch": 0.9027198398131153,
      "grad_norm": 6.565392971038818,
      "learning_rate": 3.9540729379686434e-05,
      "loss": 0.5993,
      "step": 5410
    },
    {
      "epoch": 0.9043884531953946,
      "grad_norm": 4.1620869636535645,
      "learning_rate": 3.9519427402862985e-05,
      "loss": 0.7142,
      "step": 5420
    },
    {
      "epoch": 0.9060570665776739,
      "grad_norm": 4.8562750816345215,
      "learning_rate": 3.9498125426039536e-05,
      "loss": 0.4364,
      "step": 5430
    },
    {
      "epoch": 0.9077256799599532,
      "grad_norm": 5.589602470397949,
      "learning_rate": 3.947682344921609e-05,
      "loss": 0.5838,
      "step": 5440
    },
    {
      "epoch": 0.9093942933422327,
      "grad_norm": 9.907262802124023,
      "learning_rate": 3.9455521472392646e-05,
      "loss": 0.5153,
      "step": 5450
    },
    {
      "epoch": 0.911062906724512,
      "grad_norm": 3.6757144927978516,
      "learning_rate": 3.943421949556919e-05,
      "loss": 0.6815,
      "step": 5460
    },
    {
      "epoch": 0.9127315201067913,
      "grad_norm": 5.992738246917725,
      "learning_rate": 3.941291751874574e-05,
      "loss": 0.611,
      "step": 5470
    },
    {
      "epoch": 0.9144001334890706,
      "grad_norm": 5.381848335266113,
      "learning_rate": 3.939161554192229e-05,
      "loss": 0.7277,
      "step": 5480
    },
    {
      "epoch": 0.9160687468713499,
      "grad_norm": 10.144418716430664,
      "learning_rate": 3.9370313565098844e-05,
      "loss": 0.6102,
      "step": 5490
    },
    {
      "epoch": 0.9177373602536293,
      "grad_norm": 8.351442337036133,
      "learning_rate": 3.934901158827539e-05,
      "loss": 0.8789,
      "step": 5500
    },
    {
      "epoch": 0.9194059736359086,
      "grad_norm": 6.370941638946533,
      "learning_rate": 3.932770961145195e-05,
      "loss": 0.7821,
      "step": 5510
    },
    {
      "epoch": 0.9210745870181879,
      "grad_norm": 6.09891939163208,
      "learning_rate": 3.930640763462849e-05,
      "loss": 0.6984,
      "step": 5520
    },
    {
      "epoch": 0.9227432004004672,
      "grad_norm": 7.602884292602539,
      "learning_rate": 3.928510565780504e-05,
      "loss": 0.5258,
      "step": 5530
    },
    {
      "epoch": 0.9244118137827465,
      "grad_norm": 4.333096027374268,
      "learning_rate": 3.92638036809816e-05,
      "loss": 0.4684,
      "step": 5540
    },
    {
      "epoch": 0.9260804271650258,
      "grad_norm": 8.45220947265625,
      "learning_rate": 3.9242501704158145e-05,
      "loss": 0.7005,
      "step": 5550
    },
    {
      "epoch": 0.9277490405473052,
      "grad_norm": 5.317202568054199,
      "learning_rate": 3.9221199727334704e-05,
      "loss": 0.4434,
      "step": 5560
    },
    {
      "epoch": 0.9294176539295845,
      "grad_norm": 6.002959251403809,
      "learning_rate": 3.919989775051125e-05,
      "loss": 0.5697,
      "step": 5570
    },
    {
      "epoch": 0.9310862673118638,
      "grad_norm": 11.944580078125,
      "learning_rate": 3.91785957736878e-05,
      "loss": 0.7272,
      "step": 5580
    },
    {
      "epoch": 0.9327548806941431,
      "grad_norm": 2.909165859222412,
      "learning_rate": 3.915729379686435e-05,
      "loss": 0.4679,
      "step": 5590
    },
    {
      "epoch": 0.9344234940764224,
      "grad_norm": 8.003212928771973,
      "learning_rate": 3.91359918200409e-05,
      "loss": 0.657,
      "step": 5600
    },
    {
      "epoch": 0.9360921074587019,
      "grad_norm": 8.912395477294922,
      "learning_rate": 3.9114689843217453e-05,
      "loss": 0.8196,
      "step": 5610
    },
    {
      "epoch": 0.9377607208409812,
      "grad_norm": 10.56026554107666,
      "learning_rate": 3.9093387866394005e-05,
      "loss": 0.8723,
      "step": 5620
    },
    {
      "epoch": 0.9394293342232605,
      "grad_norm": 3.2825167179107666,
      "learning_rate": 3.9072085889570556e-05,
      "loss": 0.6074,
      "step": 5630
    },
    {
      "epoch": 0.9410979476055398,
      "grad_norm": 7.866597652435303,
      "learning_rate": 3.905078391274711e-05,
      "loss": 0.6997,
      "step": 5640
    },
    {
      "epoch": 0.9427665609878191,
      "grad_norm": 3.4545888900756836,
      "learning_rate": 3.902948193592366e-05,
      "loss": 0.6029,
      "step": 5650
    },
    {
      "epoch": 0.9444351743700985,
      "grad_norm": 6.406834125518799,
      "learning_rate": 3.90081799591002e-05,
      "loss": 0.5674,
      "step": 5660
    },
    {
      "epoch": 0.9461037877523778,
      "grad_norm": 8.456024169921875,
      "learning_rate": 3.898687798227676e-05,
      "loss": 1.0087,
      "step": 5670
    },
    {
      "epoch": 0.9477724011346571,
      "grad_norm": 2.2167649269104004,
      "learning_rate": 3.8965576005453306e-05,
      "loss": 0.5554,
      "step": 5680
    },
    {
      "epoch": 0.9494410145169364,
      "grad_norm": 4.261198043823242,
      "learning_rate": 3.894427402862986e-05,
      "loss": 0.6524,
      "step": 5690
    },
    {
      "epoch": 0.9511096278992157,
      "grad_norm": 8.01386547088623,
      "learning_rate": 3.892297205180641e-05,
      "loss": 0.9691,
      "step": 5700
    },
    {
      "epoch": 0.9527782412814951,
      "grad_norm": 8.178125381469727,
      "learning_rate": 3.890167007498296e-05,
      "loss": 0.7116,
      "step": 5710
    },
    {
      "epoch": 0.9544468546637744,
      "grad_norm": 6.532522201538086,
      "learning_rate": 3.888036809815951e-05,
      "loss": 0.624,
      "step": 5720
    },
    {
      "epoch": 0.9561154680460537,
      "grad_norm": 9.305240631103516,
      "learning_rate": 3.885906612133606e-05,
      "loss": 0.5837,
      "step": 5730
    },
    {
      "epoch": 0.957784081428333,
      "grad_norm": 5.13653039932251,
      "learning_rate": 3.8837764144512614e-05,
      "loss": 0.5712,
      "step": 5740
    },
    {
      "epoch": 0.9594526948106123,
      "grad_norm": 4.876650333404541,
      "learning_rate": 3.8816462167689165e-05,
      "loss": 0.5474,
      "step": 5750
    },
    {
      "epoch": 0.9611213081928917,
      "grad_norm": 13.566899299621582,
      "learning_rate": 3.8795160190865717e-05,
      "loss": 0.5989,
      "step": 5760
    },
    {
      "epoch": 0.9627899215751711,
      "grad_norm": 5.612605094909668,
      "learning_rate": 3.877385821404226e-05,
      "loss": 0.6628,
      "step": 5770
    },
    {
      "epoch": 0.9644585349574504,
      "grad_norm": 7.087528228759766,
      "learning_rate": 3.875255623721882e-05,
      "loss": 0.7394,
      "step": 5780
    },
    {
      "epoch": 0.9661271483397297,
      "grad_norm": 5.69182825088501,
      "learning_rate": 3.8731254260395364e-05,
      "loss": 0.6527,
      "step": 5790
    },
    {
      "epoch": 0.967795761722009,
      "grad_norm": 7.981171131134033,
      "learning_rate": 3.8709952283571915e-05,
      "loss": 1.0885,
      "step": 5800
    },
    {
      "epoch": 0.9694643751042883,
      "grad_norm": 7.01986837387085,
      "learning_rate": 3.8688650306748466e-05,
      "loss": 0.7263,
      "step": 5810
    },
    {
      "epoch": 0.9711329884865677,
      "grad_norm": 6.18464469909668,
      "learning_rate": 3.866734832992502e-05,
      "loss": 0.6154,
      "step": 5820
    },
    {
      "epoch": 0.972801601868847,
      "grad_norm": 7.219038963317871,
      "learning_rate": 3.864604635310157e-05,
      "loss": 0.8784,
      "step": 5830
    },
    {
      "epoch": 0.9744702152511263,
      "grad_norm": 7.147895336151123,
      "learning_rate": 3.862474437627812e-05,
      "loss": 0.6445,
      "step": 5840
    },
    {
      "epoch": 0.9761388286334056,
      "grad_norm": 1.3653048276901245,
      "learning_rate": 3.860344239945467e-05,
      "loss": 0.5937,
      "step": 5850
    },
    {
      "epoch": 0.9778074420156849,
      "grad_norm": 2.871269702911377,
      "learning_rate": 3.858214042263122e-05,
      "loss": 0.4439,
      "step": 5860
    },
    {
      "epoch": 0.9794760553979643,
      "grad_norm": 6.522500991821289,
      "learning_rate": 3.8560838445807774e-05,
      "loss": 0.6028,
      "step": 5870
    },
    {
      "epoch": 0.9811446687802436,
      "grad_norm": 11.192880630493164,
      "learning_rate": 3.853953646898432e-05,
      "loss": 0.4032,
      "step": 5880
    },
    {
      "epoch": 0.982813282162523,
      "grad_norm": 6.832179069519043,
      "learning_rate": 3.851823449216088e-05,
      "loss": 0.6175,
      "step": 5890
    },
    {
      "epoch": 0.9844818955448023,
      "grad_norm": 5.334899425506592,
      "learning_rate": 3.849693251533742e-05,
      "loss": 0.7307,
      "step": 5900
    },
    {
      "epoch": 0.9861505089270816,
      "grad_norm": 4.785776138305664,
      "learning_rate": 3.847563053851397e-05,
      "loss": 0.4224,
      "step": 5910
    },
    {
      "epoch": 0.987819122309361,
      "grad_norm": 4.659121990203857,
      "learning_rate": 3.845432856169053e-05,
      "loss": 0.5516,
      "step": 5920
    },
    {
      "epoch": 0.9894877356916403,
      "grad_norm": 4.3518805503845215,
      "learning_rate": 3.8433026584867076e-05,
      "loss": 0.6912,
      "step": 5930
    },
    {
      "epoch": 0.9911563490739196,
      "grad_norm": 11.588605880737305,
      "learning_rate": 3.8411724608043634e-05,
      "loss": 0.8729,
      "step": 5940
    },
    {
      "epoch": 0.9928249624561989,
      "grad_norm": 2.8313825130462646,
      "learning_rate": 3.839042263122018e-05,
      "loss": 0.4936,
      "step": 5950
    },
    {
      "epoch": 0.9944935758384782,
      "grad_norm": 1.295936942100525,
      "learning_rate": 3.836912065439673e-05,
      "loss": 1.0575,
      "step": 5960
    },
    {
      "epoch": 0.9961621892207575,
      "grad_norm": 5.885469913482666,
      "learning_rate": 3.834781867757328e-05,
      "loss": 0.8524,
      "step": 5970
    },
    {
      "epoch": 0.9978308026030369,
      "grad_norm": 5.300264835357666,
      "learning_rate": 3.832651670074983e-05,
      "loss": 0.9004,
      "step": 5980
    },
    {
      "epoch": 0.9994994159853162,
      "grad_norm": 4.336697578430176,
      "learning_rate": 3.8305214723926384e-05,
      "loss": 0.7755,
      "step": 5990
    },
    {
      "epoch": 1.0011680293675955,
      "grad_norm": 5.374946594238281,
      "learning_rate": 3.8283912747102935e-05,
      "loss": 1.0092,
      "step": 6000
    },
    {
      "epoch": 1.002836642749875,
      "grad_norm": 13.538224220275879,
      "learning_rate": 3.8262610770279486e-05,
      "loss": 0.8447,
      "step": 6010
    },
    {
      "epoch": 1.0045052561321541,
      "grad_norm": 7.171322345733643,
      "learning_rate": 3.824130879345603e-05,
      "loss": 0.7054,
      "step": 6020
    },
    {
      "epoch": 1.0061738695144335,
      "grad_norm": 9.475341796875,
      "learning_rate": 3.822000681663259e-05,
      "loss": 0.7357,
      "step": 6030
    },
    {
      "epoch": 1.0078424828967127,
      "grad_norm": 1.9368295669555664,
      "learning_rate": 3.8198704839809133e-05,
      "loss": 0.7679,
      "step": 6040
    },
    {
      "epoch": 1.0095110962789922,
      "grad_norm": 1.81779944896698,
      "learning_rate": 3.817740286298569e-05,
      "loss": 0.8321,
      "step": 6050
    },
    {
      "epoch": 1.0111797096612716,
      "grad_norm": 4.569530010223389,
      "learning_rate": 3.8156100886162236e-05,
      "loss": 0.4538,
      "step": 6060
    },
    {
      "epoch": 1.0128483230435508,
      "grad_norm": 4.245853900909424,
      "learning_rate": 3.813479890933879e-05,
      "loss": 0.5643,
      "step": 6070
    },
    {
      "epoch": 1.0145169364258302,
      "grad_norm": 8.67273235321045,
      "learning_rate": 3.811349693251534e-05,
      "loss": 0.726,
      "step": 6080
    },
    {
      "epoch": 1.0161855498081094,
      "grad_norm": 0.696869969367981,
      "learning_rate": 3.809219495569189e-05,
      "loss": 0.3949,
      "step": 6090
    },
    {
      "epoch": 1.0178541631903888,
      "grad_norm": 1.8328641653060913,
      "learning_rate": 3.807089297886844e-05,
      "loss": 0.5064,
      "step": 6100
    },
    {
      "epoch": 1.0195227765726682,
      "grad_norm": 5.915022373199463,
      "learning_rate": 3.804959100204499e-05,
      "loss": 0.8124,
      "step": 6110
    },
    {
      "epoch": 1.0211913899549474,
      "grad_norm": 9.905023574829102,
      "learning_rate": 3.8028289025221544e-05,
      "loss": 0.9459,
      "step": 6120
    },
    {
      "epoch": 1.0228600033372268,
      "grad_norm": 8.825831413269043,
      "learning_rate": 3.800698704839809e-05,
      "loss": 0.8078,
      "step": 6130
    },
    {
      "epoch": 1.024528616719506,
      "grad_norm": 4.524229526519775,
      "learning_rate": 3.798568507157465e-05,
      "loss": 0.5991,
      "step": 6140
    },
    {
      "epoch": 1.0261972301017854,
      "grad_norm": 7.027403831481934,
      "learning_rate": 3.796438309475119e-05,
      "loss": 0.5608,
      "step": 6150
    },
    {
      "epoch": 1.0278658434840648,
      "grad_norm": 13.857187271118164,
      "learning_rate": 3.794308111792775e-05,
      "loss": 0.6976,
      "step": 6160
    },
    {
      "epoch": 1.029534456866344,
      "grad_norm": 1.990322470664978,
      "learning_rate": 3.7921779141104294e-05,
      "loss": 0.5526,
      "step": 6170
    },
    {
      "epoch": 1.0312030702486235,
      "grad_norm": 7.5649895668029785,
      "learning_rate": 3.7900477164280845e-05,
      "loss": 0.5831,
      "step": 6180
    },
    {
      "epoch": 1.0328716836309026,
      "grad_norm": 4.529258728027344,
      "learning_rate": 3.78791751874574e-05,
      "loss": 0.6738,
      "step": 6190
    },
    {
      "epoch": 1.034540297013182,
      "grad_norm": 4.342246055603027,
      "learning_rate": 3.785787321063395e-05,
      "loss": 0.6826,
      "step": 6200
    },
    {
      "epoch": 1.0362089103954615,
      "grad_norm": 8.65554141998291,
      "learning_rate": 3.78365712338105e-05,
      "loss": 0.7767,
      "step": 6210
    },
    {
      "epoch": 1.0378775237777407,
      "grad_norm": 3.967540740966797,
      "learning_rate": 3.781526925698705e-05,
      "loss": 0.8327,
      "step": 6220
    },
    {
      "epoch": 1.03954613716002,
      "grad_norm": 4.833505153656006,
      "learning_rate": 3.77939672801636e-05,
      "loss": 0.5086,
      "step": 6230
    },
    {
      "epoch": 1.0412147505422993,
      "grad_norm": 5.758260250091553,
      "learning_rate": 3.777266530334015e-05,
      "loss": 0.7085,
      "step": 6240
    },
    {
      "epoch": 1.0428833639245787,
      "grad_norm": 8.68689250946045,
      "learning_rate": 3.7751363326516705e-05,
      "loss": 0.7104,
      "step": 6250
    },
    {
      "epoch": 1.044551977306858,
      "grad_norm": 1.2792319059371948,
      "learning_rate": 3.773006134969325e-05,
      "loss": 0.3728,
      "step": 6260
    },
    {
      "epoch": 1.0462205906891373,
      "grad_norm": 3.806483268737793,
      "learning_rate": 3.770875937286981e-05,
      "loss": 0.5215,
      "step": 6270
    },
    {
      "epoch": 1.0478892040714167,
      "grad_norm": 4.537534236907959,
      "learning_rate": 3.768745739604635e-05,
      "loss": 0.7684,
      "step": 6280
    },
    {
      "epoch": 1.049557817453696,
      "grad_norm": 9.518585205078125,
      "learning_rate": 3.76661554192229e-05,
      "loss": 0.5682,
      "step": 6290
    },
    {
      "epoch": 1.0512264308359753,
      "grad_norm": 3.418015241622925,
      "learning_rate": 3.764485344239946e-05,
      "loss": 0.6903,
      "step": 6300
    },
    {
      "epoch": 1.0528950442182545,
      "grad_norm": 11.803902626037598,
      "learning_rate": 3.7623551465576006e-05,
      "loss": 0.5303,
      "step": 6310
    },
    {
      "epoch": 1.054563657600534,
      "grad_norm": 3.404094934463501,
      "learning_rate": 3.760224948875256e-05,
      "loss": 0.6294,
      "step": 6320
    },
    {
      "epoch": 1.0562322709828134,
      "grad_norm": 15.93364143371582,
      "learning_rate": 3.758094751192911e-05,
      "loss": 0.6061,
      "step": 6330
    },
    {
      "epoch": 1.0579008843650926,
      "grad_norm": 8.045159339904785,
      "learning_rate": 3.755964553510566e-05,
      "loss": 0.6405,
      "step": 6340
    },
    {
      "epoch": 1.059569497747372,
      "grad_norm": 7.330000400543213,
      "learning_rate": 3.753834355828221e-05,
      "loss": 0.5606,
      "step": 6350
    },
    {
      "epoch": 1.0612381111296512,
      "grad_norm": 12.553983688354492,
      "learning_rate": 3.751704158145876e-05,
      "loss": 0.4008,
      "step": 6360
    },
    {
      "epoch": 1.0629067245119306,
      "grad_norm": 3.549842596054077,
      "learning_rate": 3.7495739604635314e-05,
      "loss": 0.5925,
      "step": 6370
    },
    {
      "epoch": 1.06457533789421,
      "grad_norm": 10.390632629394531,
      "learning_rate": 3.7474437627811865e-05,
      "loss": 0.406,
      "step": 6380
    },
    {
      "epoch": 1.0662439512764892,
      "grad_norm": 8.135400772094727,
      "learning_rate": 3.7453135650988416e-05,
      "loss": 0.4865,
      "step": 6390
    },
    {
      "epoch": 1.0679125646587686,
      "grad_norm": 4.331161975860596,
      "learning_rate": 3.743183367416496e-05,
      "loss": 0.6061,
      "step": 6400
    },
    {
      "epoch": 1.0695811780410478,
      "grad_norm": 17.440366744995117,
      "learning_rate": 3.741053169734152e-05,
      "loss": 0.4884,
      "step": 6410
    },
    {
      "epoch": 1.0712497914233272,
      "grad_norm": 4.943343162536621,
      "learning_rate": 3.7389229720518064e-05,
      "loss": 0.7891,
      "step": 6420
    },
    {
      "epoch": 1.0729184048056066,
      "grad_norm": 14.76405143737793,
      "learning_rate": 3.7367927743694615e-05,
      "loss": 0.5094,
      "step": 6430
    },
    {
      "epoch": 1.0745870181878858,
      "grad_norm": 5.039114475250244,
      "learning_rate": 3.7346625766871166e-05,
      "loss": 0.4866,
      "step": 6440
    },
    {
      "epoch": 1.0762556315701652,
      "grad_norm": 4.9691290855407715,
      "learning_rate": 3.732532379004772e-05,
      "loss": 0.5368,
      "step": 6450
    },
    {
      "epoch": 1.0779242449524444,
      "grad_norm": 6.873760223388672,
      "learning_rate": 3.730402181322427e-05,
      "loss": 0.6677,
      "step": 6460
    },
    {
      "epoch": 1.0795928583347238,
      "grad_norm": 9.760710716247559,
      "learning_rate": 3.728271983640082e-05,
      "loss": 0.9027,
      "step": 6470
    },
    {
      "epoch": 1.0812614717170033,
      "grad_norm": 3.5461392402648926,
      "learning_rate": 3.726141785957737e-05,
      "loss": 0.6164,
      "step": 6480
    },
    {
      "epoch": 1.0829300850992825,
      "grad_norm": 7.976288795471191,
      "learning_rate": 3.724011588275392e-05,
      "loss": 0.4679,
      "step": 6490
    },
    {
      "epoch": 1.0845986984815619,
      "grad_norm": 4.073061466217041,
      "learning_rate": 3.7218813905930474e-05,
      "loss": 0.5063,
      "step": 6500
    },
    {
      "epoch": 1.086267311863841,
      "grad_norm": 6.462550640106201,
      "learning_rate": 3.719751192910702e-05,
      "loss": 0.7184,
      "step": 6510
    },
    {
      "epoch": 1.0879359252461205,
      "grad_norm": 11.96576976776123,
      "learning_rate": 3.717620995228358e-05,
      "loss": 0.6945,
      "step": 6520
    },
    {
      "epoch": 1.0896045386284,
      "grad_norm": 13.607446670532227,
      "learning_rate": 3.715490797546012e-05,
      "loss": 0.8052,
      "step": 6530
    },
    {
      "epoch": 1.091273152010679,
      "grad_norm": 9.588977813720703,
      "learning_rate": 3.713360599863668e-05,
      "loss": 0.6373,
      "step": 6540
    },
    {
      "epoch": 1.0929417653929585,
      "grad_norm": 1.755293846130371,
      "learning_rate": 3.7112304021813224e-05,
      "loss": 0.3134,
      "step": 6550
    },
    {
      "epoch": 1.0946103787752377,
      "grad_norm": 7.734462261199951,
      "learning_rate": 3.7091002044989775e-05,
      "loss": 0.6569,
      "step": 6560
    },
    {
      "epoch": 1.0962789921575171,
      "grad_norm": 1.383083462715149,
      "learning_rate": 3.706970006816633e-05,
      "loss": 0.2354,
      "step": 6570
    },
    {
      "epoch": 1.0979476055397965,
      "grad_norm": 10.910091400146484,
      "learning_rate": 3.704839809134288e-05,
      "loss": 0.9163,
      "step": 6580
    },
    {
      "epoch": 1.0996162189220757,
      "grad_norm": 14.028646469116211,
      "learning_rate": 3.702709611451943e-05,
      "loss": 0.3814,
      "step": 6590
    },
    {
      "epoch": 1.1012848323043551,
      "grad_norm": 5.5066609382629395,
      "learning_rate": 3.700579413769598e-05,
      "loss": 0.4891,
      "step": 6600
    },
    {
      "epoch": 1.1029534456866343,
      "grad_norm": 6.57949686050415,
      "learning_rate": 3.698449216087253e-05,
      "loss": 0.4059,
      "step": 6610
    },
    {
      "epoch": 1.1046220590689138,
      "grad_norm": 7.122279167175293,
      "learning_rate": 3.696319018404908e-05,
      "loss": 0.8008,
      "step": 6620
    },
    {
      "epoch": 1.106290672451193,
      "grad_norm": 7.192483901977539,
      "learning_rate": 3.6941888207225635e-05,
      "loss": 0.6814,
      "step": 6630
    },
    {
      "epoch": 1.1079592858334724,
      "grad_norm": 6.323932647705078,
      "learning_rate": 3.692058623040218e-05,
      "loss": 0.3882,
      "step": 6640
    },
    {
      "epoch": 1.1096278992157518,
      "grad_norm": 8.028552055358887,
      "learning_rate": 3.689928425357874e-05,
      "loss": 0.8305,
      "step": 6650
    },
    {
      "epoch": 1.111296512598031,
      "grad_norm": 4.735127925872803,
      "learning_rate": 3.687798227675528e-05,
      "loss": 0.5609,
      "step": 6660
    },
    {
      "epoch": 1.1129651259803104,
      "grad_norm": 5.254373550415039,
      "learning_rate": 3.685668029993183e-05,
      "loss": 0.7171,
      "step": 6670
    },
    {
      "epoch": 1.1146337393625898,
      "grad_norm": 4.408944606781006,
      "learning_rate": 3.683537832310839e-05,
      "loss": 0.6458,
      "step": 6680
    },
    {
      "epoch": 1.116302352744869,
      "grad_norm": 4.268215179443359,
      "learning_rate": 3.6814076346284936e-05,
      "loss": 0.4308,
      "step": 6690
    },
    {
      "epoch": 1.1179709661271484,
      "grad_norm": 4.247426509857178,
      "learning_rate": 3.679277436946149e-05,
      "loss": 0.5246,
      "step": 6700
    },
    {
      "epoch": 1.1196395795094276,
      "grad_norm": 7.157942771911621,
      "learning_rate": 3.677147239263804e-05,
      "loss": 0.4986,
      "step": 6710
    },
    {
      "epoch": 1.121308192891707,
      "grad_norm": 4.990433692932129,
      "learning_rate": 3.675017041581459e-05,
      "loss": 0.5936,
      "step": 6720
    },
    {
      "epoch": 1.1229768062739862,
      "grad_norm": 12.001702308654785,
      "learning_rate": 3.6728868438991134e-05,
      "loss": 0.7533,
      "step": 6730
    },
    {
      "epoch": 1.1246454196562656,
      "grad_norm": 7.522315979003906,
      "learning_rate": 3.670756646216769e-05,
      "loss": 0.6657,
      "step": 6740
    },
    {
      "epoch": 1.126314033038545,
      "grad_norm": 9.230464935302734,
      "learning_rate": 3.6686264485344244e-05,
      "loss": 0.6489,
      "step": 6750
    },
    {
      "epoch": 1.1279826464208242,
      "grad_norm": 1.2969410419464111,
      "learning_rate": 3.6664962508520795e-05,
      "loss": 0.5905,
      "step": 6760
    },
    {
      "epoch": 1.1296512598031037,
      "grad_norm": 8.823436737060547,
      "learning_rate": 3.6643660531697347e-05,
      "loss": 0.5623,
      "step": 6770
    },
    {
      "epoch": 1.1313198731853829,
      "grad_norm": 2.039334297180176,
      "learning_rate": 3.662235855487389e-05,
      "loss": 0.5531,
      "step": 6780
    },
    {
      "epoch": 1.1329884865676623,
      "grad_norm": 9.40267562866211,
      "learning_rate": 3.660105657805045e-05,
      "loss": 0.8879,
      "step": 6790
    },
    {
      "epoch": 1.1346570999499417,
      "grad_norm": 5.656665802001953,
      "learning_rate": 3.6579754601226994e-05,
      "loss": 0.4651,
      "step": 6800
    },
    {
      "epoch": 1.1363257133322209,
      "grad_norm": 7.052081108093262,
      "learning_rate": 3.6558452624403545e-05,
      "loss": 0.4042,
      "step": 6810
    },
    {
      "epoch": 1.1379943267145003,
      "grad_norm": 7.350648880004883,
      "learning_rate": 3.6537150647580096e-05,
      "loss": 0.9515,
      "step": 6820
    },
    {
      "epoch": 1.1396629400967795,
      "grad_norm": 7.639624118804932,
      "learning_rate": 3.651584867075665e-05,
      "loss": 0.8204,
      "step": 6830
    },
    {
      "epoch": 1.141331553479059,
      "grad_norm": 4.469156265258789,
      "learning_rate": 3.64945466939332e-05,
      "loss": 0.7851,
      "step": 6840
    },
    {
      "epoch": 1.1430001668613383,
      "grad_norm": 4.416633605957031,
      "learning_rate": 3.647324471710975e-05,
      "loss": 0.5788,
      "step": 6850
    },
    {
      "epoch": 1.1446687802436175,
      "grad_norm": 5.527399063110352,
      "learning_rate": 3.64519427402863e-05,
      "loss": 0.7662,
      "step": 6860
    },
    {
      "epoch": 1.146337393625897,
      "grad_norm": 9.548369407653809,
      "learning_rate": 3.643064076346285e-05,
      "loss": 0.7932,
      "step": 6870
    },
    {
      "epoch": 1.1480060070081761,
      "grad_norm": 2.7713897228240967,
      "learning_rate": 3.6409338786639404e-05,
      "loss": 0.498,
      "step": 6880
    },
    {
      "epoch": 1.1496746203904555,
      "grad_norm": 5.374054908752441,
      "learning_rate": 3.638803680981595e-05,
      "loss": 0.4535,
      "step": 6890
    },
    {
      "epoch": 1.151343233772735,
      "grad_norm": 2.4161317348480225,
      "learning_rate": 3.636673483299251e-05,
      "loss": 0.6984,
      "step": 6900
    },
    {
      "epoch": 1.1530118471550141,
      "grad_norm": 3.794311761856079,
      "learning_rate": 3.634543285616905e-05,
      "loss": 0.7508,
      "step": 6910
    },
    {
      "epoch": 1.1546804605372936,
      "grad_norm": 9.70964241027832,
      "learning_rate": 3.63241308793456e-05,
      "loss": 0.6453,
      "step": 6920
    },
    {
      "epoch": 1.1563490739195728,
      "grad_norm": 5.058757781982422,
      "learning_rate": 3.6302828902522154e-05,
      "loss": 0.461,
      "step": 6930
    },
    {
      "epoch": 1.1580176873018522,
      "grad_norm": 5.127359867095947,
      "learning_rate": 3.6281526925698706e-05,
      "loss": 0.7034,
      "step": 6940
    },
    {
      "epoch": 1.1596863006841316,
      "grad_norm": 5.916182518005371,
      "learning_rate": 3.626022494887526e-05,
      "loss": 0.6677,
      "step": 6950
    },
    {
      "epoch": 1.1613549140664108,
      "grad_norm": 6.05897331237793,
      "learning_rate": 3.623892297205181e-05,
      "loss": 0.9871,
      "step": 6960
    },
    {
      "epoch": 1.1630235274486902,
      "grad_norm": 2.5839531421661377,
      "learning_rate": 3.621762099522836e-05,
      "loss": 0.457,
      "step": 6970
    },
    {
      "epoch": 1.1646921408309694,
      "grad_norm": 3.7286715507507324,
      "learning_rate": 3.619631901840491e-05,
      "loss": 0.5693,
      "step": 6980
    },
    {
      "epoch": 1.1663607542132488,
      "grad_norm": 1.9645737409591675,
      "learning_rate": 3.617501704158146e-05,
      "loss": 0.6683,
      "step": 6990
    },
    {
      "epoch": 1.168029367595528,
      "grad_norm": 4.315593719482422,
      "learning_rate": 3.615371506475801e-05,
      "loss": 0.6747,
      "step": 7000
    },
    {
      "epoch": 1.1696979809778074,
      "grad_norm": 11.413714408874512,
      "learning_rate": 3.6132413087934565e-05,
      "loss": 0.7119,
      "step": 7010
    },
    {
      "epoch": 1.1713665943600868,
      "grad_norm": 7.082180500030518,
      "learning_rate": 3.611111111111111e-05,
      "loss": 0.5657,
      "step": 7020
    },
    {
      "epoch": 1.173035207742366,
      "grad_norm": 11.14974594116211,
      "learning_rate": 3.608980913428766e-05,
      "loss": 0.5988,
      "step": 7030
    },
    {
      "epoch": 1.1747038211246454,
      "grad_norm": 4.396084785461426,
      "learning_rate": 3.606850715746421e-05,
      "loss": 0.6484,
      "step": 7040
    },
    {
      "epoch": 1.1763724345069249,
      "grad_norm": 6.6631035804748535,
      "learning_rate": 3.6047205180640763e-05,
      "loss": 0.5979,
      "step": 7050
    },
    {
      "epoch": 1.178041047889204,
      "grad_norm": 10.596138954162598,
      "learning_rate": 3.602590320381732e-05,
      "loss": 0.599,
      "step": 7060
    },
    {
      "epoch": 1.1797096612714835,
      "grad_norm": 8.649216651916504,
      "learning_rate": 3.6004601226993866e-05,
      "loss": 1.0748,
      "step": 7070
    },
    {
      "epoch": 1.1813782746537627,
      "grad_norm": 10.33381175994873,
      "learning_rate": 3.598329925017042e-05,
      "loss": 0.6896,
      "step": 7080
    },
    {
      "epoch": 1.183046888036042,
      "grad_norm": 5.234814643859863,
      "learning_rate": 3.596199727334697e-05,
      "loss": 0.5335,
      "step": 7090
    },
    {
      "epoch": 1.1847155014183213,
      "grad_norm": 8.948088645935059,
      "learning_rate": 3.594069529652352e-05,
      "loss": 0.6576,
      "step": 7100
    },
    {
      "epoch": 1.1863841148006007,
      "grad_norm": 10.271075248718262,
      "learning_rate": 3.5919393319700065e-05,
      "loss": 0.676,
      "step": 7110
    },
    {
      "epoch": 1.18805272818288,
      "grad_norm": 3.508049249649048,
      "learning_rate": 3.589809134287662e-05,
      "loss": 0.62,
      "step": 7120
    },
    {
      "epoch": 1.1897213415651593,
      "grad_norm": 5.7778401374816895,
      "learning_rate": 3.587678936605317e-05,
      "loss": 0.7665,
      "step": 7130
    },
    {
      "epoch": 1.1913899549474387,
      "grad_norm": 7.086795806884766,
      "learning_rate": 3.5855487389229725e-05,
      "loss": 0.8002,
      "step": 7140
    },
    {
      "epoch": 1.1930585683297181,
      "grad_norm": 4.585603713989258,
      "learning_rate": 3.583418541240628e-05,
      "loss": 0.6344,
      "step": 7150
    },
    {
      "epoch": 1.1947271817119973,
      "grad_norm": 10.239252090454102,
      "learning_rate": 3.581288343558282e-05,
      "loss": 0.4321,
      "step": 7160
    },
    {
      "epoch": 1.1963957950942767,
      "grad_norm": 9.314529418945312,
      "learning_rate": 3.579158145875938e-05,
      "loss": 0.7614,
      "step": 7170
    },
    {
      "epoch": 1.198064408476556,
      "grad_norm": 1.0419179201126099,
      "learning_rate": 3.5770279481935924e-05,
      "loss": 0.5,
      "step": 7180
    },
    {
      "epoch": 1.1997330218588353,
      "grad_norm": 4.463251113891602,
      "learning_rate": 3.5748977505112475e-05,
      "loss": 0.7678,
      "step": 7190
    }
  ],
  "logging_steps": 10,
  "max_steps": 23972,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 2398,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.386513178502144e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
