{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 16858,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.931901767706727e-05,
      "grad_norm": 18.21153450012207,
      "learning_rate": 1.1862396204033216e-08,
      "loss": 1.5562,
      "step": 1
    },
    {
      "epoch": 0.00011863803535413454,
      "grad_norm": 60.55733871459961,
      "learning_rate": 2.3724792408066433e-08,
      "loss": 4.3784,
      "step": 2
    },
    {
      "epoch": 0.00017795705303120182,
      "grad_norm": 23.13866424560547,
      "learning_rate": 3.5587188612099644e-08,
      "loss": 1.0293,
      "step": 3
    },
    {
      "epoch": 0.00023727607070826907,
      "grad_norm": 19.787689208984375,
      "learning_rate": 4.7449584816132866e-08,
      "loss": 0.5862,
      "step": 4
    },
    {
      "epoch": 0.00029659508838533635,
      "grad_norm": 42.488956451416016,
      "learning_rate": 5.931198102016608e-08,
      "loss": 0.9095,
      "step": 5
    },
    {
      "epoch": 0.00035591410606240363,
      "grad_norm": 39.30983352661133,
      "learning_rate": 7.117437722419929e-08,
      "loss": 1.9888,
      "step": 6
    },
    {
      "epoch": 0.00041523312373947086,
      "grad_norm": 51.29161834716797,
      "learning_rate": 8.30367734282325e-08,
      "loss": 1.8357,
      "step": 7
    },
    {
      "epoch": 0.00047455214141653814,
      "grad_norm": 78.7551498413086,
      "learning_rate": 9.489916963226573e-08,
      "loss": 2.282,
      "step": 8
    },
    {
      "epoch": 0.0005338711590936054,
      "grad_norm": 15.863694190979004,
      "learning_rate": 1.0676156583629895e-07,
      "loss": 2.2656,
      "step": 9
    },
    {
      "epoch": 0.0005931901767706727,
      "grad_norm": 89.81600189208984,
      "learning_rate": 1.1862396204033216e-07,
      "loss": 1.8711,
      "step": 10
    },
    {
      "epoch": 0.0006525091944477399,
      "grad_norm": 26.953248977661133,
      "learning_rate": 1.3048635824436538e-07,
      "loss": 1.6096,
      "step": 11
    },
    {
      "epoch": 0.0007118282121248073,
      "grad_norm": 32.546722412109375,
      "learning_rate": 1.4234875444839858e-07,
      "loss": 1.4163,
      "step": 12
    },
    {
      "epoch": 0.0007711472298018745,
      "grad_norm": 67.22864532470703,
      "learning_rate": 1.542111506524318e-07,
      "loss": 2.1648,
      "step": 13
    },
    {
      "epoch": 0.0008304662474789417,
      "grad_norm": 32.48191833496094,
      "learning_rate": 1.66073546856465e-07,
      "loss": 0.9824,
      "step": 14
    },
    {
      "epoch": 0.000889785265156009,
      "grad_norm": 45.35607147216797,
      "learning_rate": 1.7793594306049826e-07,
      "loss": 3.1515,
      "step": 15
    },
    {
      "epoch": 0.0009491042828330763,
      "grad_norm": 49.304046630859375,
      "learning_rate": 1.8979833926453146e-07,
      "loss": 1.6586,
      "step": 16
    },
    {
      "epoch": 0.0010084233005101435,
      "grad_norm": 77.31291198730469,
      "learning_rate": 2.0166073546856466e-07,
      "loss": 3.3181,
      "step": 17
    },
    {
      "epoch": 0.0010677423181872107,
      "grad_norm": 77.35077667236328,
      "learning_rate": 2.135231316725979e-07,
      "loss": 1.5873,
      "step": 18
    },
    {
      "epoch": 0.0011270613358642782,
      "grad_norm": 101.73736572265625,
      "learning_rate": 2.253855278766311e-07,
      "loss": 2.8063,
      "step": 19
    },
    {
      "epoch": 0.0011863803535413454,
      "grad_norm": 22.593318939208984,
      "learning_rate": 2.3724792408066432e-07,
      "loss": 1.5909,
      "step": 20
    },
    {
      "epoch": 0.0012456993712184126,
      "grad_norm": 18.1798152923584,
      "learning_rate": 2.4911032028469755e-07,
      "loss": 1.1987,
      "step": 21
    },
    {
      "epoch": 0.0013050183888954799,
      "grad_norm": 20.846908569335938,
      "learning_rate": 2.6097271648873075e-07,
      "loss": 1.7476,
      "step": 22
    },
    {
      "epoch": 0.001364337406572547,
      "grad_norm": 68.06765747070312,
      "learning_rate": 2.7283511269276395e-07,
      "loss": 1.951,
      "step": 23
    },
    {
      "epoch": 0.0014236564242496145,
      "grad_norm": 93.73208618164062,
      "learning_rate": 2.8469750889679715e-07,
      "loss": 3.2063,
      "step": 24
    },
    {
      "epoch": 0.0014829754419266818,
      "grad_norm": 86.34806823730469,
      "learning_rate": 2.965599051008304e-07,
      "loss": 2.5356,
      "step": 25
    },
    {
      "epoch": 0.001542294459603749,
      "grad_norm": 89.12501525878906,
      "learning_rate": 3.084223013048636e-07,
      "loss": 2.6026,
      "step": 26
    },
    {
      "epoch": 0.0016016134772808162,
      "grad_norm": 48.73095703125,
      "learning_rate": 3.202846975088968e-07,
      "loss": 1.2887,
      "step": 27
    },
    {
      "epoch": 0.0016609324949578834,
      "grad_norm": 74.59615325927734,
      "learning_rate": 3.3214709371293e-07,
      "loss": 5.6495,
      "step": 28
    },
    {
      "epoch": 0.0017202515126349507,
      "grad_norm": 72.9882583618164,
      "learning_rate": 3.4400948991696327e-07,
      "loss": 1.8125,
      "step": 29
    },
    {
      "epoch": 0.001779570530312018,
      "grad_norm": 50.05543518066406,
      "learning_rate": 3.558718861209965e-07,
      "loss": 1.2885,
      "step": 30
    },
    {
      "epoch": 0.0018388895479890853,
      "grad_norm": 110.28607940673828,
      "learning_rate": 3.6773428232502967e-07,
      "loss": 3.5049,
      "step": 31
    },
    {
      "epoch": 0.0018982085656661526,
      "grad_norm": 49.59636306762695,
      "learning_rate": 3.795966785290629e-07,
      "loss": 2.0352,
      "step": 32
    },
    {
      "epoch": 0.00195752758334322,
      "grad_norm": 34.76351547241211,
      "learning_rate": 3.914590747330961e-07,
      "loss": 1.123,
      "step": 33
    },
    {
      "epoch": 0.002016846601020287,
      "grad_norm": 49.948875427246094,
      "learning_rate": 4.0332147093712933e-07,
      "loss": 2.1645,
      "step": 34
    },
    {
      "epoch": 0.0020761656186973542,
      "grad_norm": 42.01350402832031,
      "learning_rate": 4.1518386714116253e-07,
      "loss": 0.9738,
      "step": 35
    },
    {
      "epoch": 0.0021354846363744215,
      "grad_norm": 81.60076904296875,
      "learning_rate": 4.270462633451958e-07,
      "loss": 2.0477,
      "step": 36
    },
    {
      "epoch": 0.0021948036540514887,
      "grad_norm": 99.7342300415039,
      "learning_rate": 4.3890865954922893e-07,
      "loss": 2.2333,
      "step": 37
    },
    {
      "epoch": 0.0022541226717285564,
      "grad_norm": 69.1491470336914,
      "learning_rate": 4.507710557532622e-07,
      "loss": 2.1741,
      "step": 38
    },
    {
      "epoch": 0.0023134416894056236,
      "grad_norm": 38.881248474121094,
      "learning_rate": 4.626334519572954e-07,
      "loss": 0.7099,
      "step": 39
    },
    {
      "epoch": 0.002372760707082691,
      "grad_norm": 54.75040054321289,
      "learning_rate": 4.7449584816132864e-07,
      "loss": 2.1992,
      "step": 40
    },
    {
      "epoch": 0.002432079724759758,
      "grad_norm": 68.22157287597656,
      "learning_rate": 4.863582443653619e-07,
      "loss": 2.2203,
      "step": 41
    },
    {
      "epoch": 0.0024913987424368253,
      "grad_norm": 32.87198257446289,
      "learning_rate": 4.982206405693951e-07,
      "loss": 0.8024,
      "step": 42
    },
    {
      "epoch": 0.0025507177601138925,
      "grad_norm": 31.768178939819336,
      "learning_rate": 5.100830367734283e-07,
      "loss": 3.3163,
      "step": 43
    },
    {
      "epoch": 0.0026100367777909597,
      "grad_norm": 71.38982391357422,
      "learning_rate": 5.219454329774615e-07,
      "loss": 2.6593,
      "step": 44
    },
    {
      "epoch": 0.002669355795468027,
      "grad_norm": 99.39778900146484,
      "learning_rate": 5.338078291814947e-07,
      "loss": 3.1923,
      "step": 45
    },
    {
      "epoch": 0.002728674813145094,
      "grad_norm": 65.34956359863281,
      "learning_rate": 5.456702253855279e-07,
      "loss": 1.1707,
      "step": 46
    },
    {
      "epoch": 0.0027879938308221614,
      "grad_norm": 37.90747833251953,
      "learning_rate": 5.575326215895611e-07,
      "loss": 2.2722,
      "step": 47
    },
    {
      "epoch": 0.002847312848499229,
      "grad_norm": 50.04475402832031,
      "learning_rate": 5.693950177935943e-07,
      "loss": 1.62,
      "step": 48
    },
    {
      "epoch": 0.0029066318661762963,
      "grad_norm": 37.20331954956055,
      "learning_rate": 5.812574139976276e-07,
      "loss": 1.0425,
      "step": 49
    },
    {
      "epoch": 0.0029659508838533635,
      "grad_norm": 51.78990936279297,
      "learning_rate": 5.931198102016608e-07,
      "loss": 2.641,
      "step": 50
    },
    {
      "epoch": 0.0030252699015304307,
      "grad_norm": 105.18022155761719,
      "learning_rate": 6.04982206405694e-07,
      "loss": 1.9288,
      "step": 51
    },
    {
      "epoch": 0.003084588919207498,
      "grad_norm": 94.53858184814453,
      "learning_rate": 6.168446026097272e-07,
      "loss": 1.6381,
      "step": 52
    },
    {
      "epoch": 0.003143907936884565,
      "grad_norm": 76.86193084716797,
      "learning_rate": 6.287069988137605e-07,
      "loss": 1.8284,
      "step": 53
    },
    {
      "epoch": 0.0032032269545616324,
      "grad_norm": 72.60234832763672,
      "learning_rate": 6.405693950177936e-07,
      "loss": 2.1931,
      "step": 54
    },
    {
      "epoch": 0.0032625459722386996,
      "grad_norm": 53.2988166809082,
      "learning_rate": 6.524317912218268e-07,
      "loss": 1.2328,
      "step": 55
    },
    {
      "epoch": 0.003321864989915767,
      "grad_norm": 83.8056640625,
      "learning_rate": 6.6429418742586e-07,
      "loss": 1.4645,
      "step": 56
    },
    {
      "epoch": 0.003381184007592834,
      "grad_norm": 51.68008041381836,
      "learning_rate": 6.761565836298933e-07,
      "loss": 1.4716,
      "step": 57
    },
    {
      "epoch": 0.0034405030252699013,
      "grad_norm": 52.028282165527344,
      "learning_rate": 6.880189798339265e-07,
      "loss": 1.3537,
      "step": 58
    },
    {
      "epoch": 0.003499822042946969,
      "grad_norm": 90.3622817993164,
      "learning_rate": 6.998813760379597e-07,
      "loss": 2.3241,
      "step": 59
    },
    {
      "epoch": 0.003559141060624036,
      "grad_norm": 51.33265686035156,
      "learning_rate": 7.11743772241993e-07,
      "loss": 2.4135,
      "step": 60
    },
    {
      "epoch": 0.0036184600783011034,
      "grad_norm": 109.73255157470703,
      "learning_rate": 7.236061684460261e-07,
      "loss": 1.727,
      "step": 61
    },
    {
      "epoch": 0.0036777790959781707,
      "grad_norm": 65.5224380493164,
      "learning_rate": 7.354685646500593e-07,
      "loss": 2.0379,
      "step": 62
    },
    {
      "epoch": 0.003737098113655238,
      "grad_norm": 68.57380676269531,
      "learning_rate": 7.473309608540925e-07,
      "loss": 2.0604,
      "step": 63
    },
    {
      "epoch": 0.003796417131332305,
      "grad_norm": 46.95387649536133,
      "learning_rate": 7.591933570581258e-07,
      "loss": 2.3004,
      "step": 64
    },
    {
      "epoch": 0.0038557361490093723,
      "grad_norm": 80.76876068115234,
      "learning_rate": 7.71055753262159e-07,
      "loss": 1.6454,
      "step": 65
    },
    {
      "epoch": 0.00391505516668644,
      "grad_norm": 40.535743713378906,
      "learning_rate": 7.829181494661923e-07,
      "loss": 2.2061,
      "step": 66
    },
    {
      "epoch": 0.003974374184363507,
      "grad_norm": 41.85569381713867,
      "learning_rate": 7.947805456702253e-07,
      "loss": 0.7279,
      "step": 67
    },
    {
      "epoch": 0.004033693202040574,
      "grad_norm": 81.51060485839844,
      "learning_rate": 8.066429418742587e-07,
      "loss": 2.7386,
      "step": 68
    },
    {
      "epoch": 0.004093012219717642,
      "grad_norm": 116.39146423339844,
      "learning_rate": 8.185053380782919e-07,
      "loss": 3.7165,
      "step": 69
    },
    {
      "epoch": 0.0041523312373947085,
      "grad_norm": 50.37773513793945,
      "learning_rate": 8.303677342823251e-07,
      "loss": 2.8676,
      "step": 70
    },
    {
      "epoch": 0.004211650255071776,
      "grad_norm": 17.810115814208984,
      "learning_rate": 8.422301304863584e-07,
      "loss": 0.3161,
      "step": 71
    },
    {
      "epoch": 0.004270969272748843,
      "grad_norm": 101.27669525146484,
      "learning_rate": 8.540925266903916e-07,
      "loss": 2.4632,
      "step": 72
    },
    {
      "epoch": 0.004330288290425911,
      "grad_norm": 177.4308319091797,
      "learning_rate": 8.659549228944248e-07,
      "loss": 2.7872,
      "step": 73
    },
    {
      "epoch": 0.004389607308102977,
      "grad_norm": 52.13441467285156,
      "learning_rate": 8.778173190984579e-07,
      "loss": 1.2523,
      "step": 74
    },
    {
      "epoch": 0.004448926325780045,
      "grad_norm": 15.817767143249512,
      "learning_rate": 8.896797153024913e-07,
      "loss": 0.5112,
      "step": 75
    },
    {
      "epoch": 0.004508245343457113,
      "grad_norm": 32.692054748535156,
      "learning_rate": 9.015421115065244e-07,
      "loss": 1.0485,
      "step": 76
    },
    {
      "epoch": 0.0045675643611341795,
      "grad_norm": 26.497270584106445,
      "learning_rate": 9.134045077105576e-07,
      "loss": 1.5465,
      "step": 77
    },
    {
      "epoch": 0.004626883378811247,
      "grad_norm": 23.131364822387695,
      "learning_rate": 9.252669039145908e-07,
      "loss": 0.4174,
      "step": 78
    },
    {
      "epoch": 0.004686202396488314,
      "grad_norm": 76.77631378173828,
      "learning_rate": 9.371293001186241e-07,
      "loss": 0.6882,
      "step": 79
    },
    {
      "epoch": 0.004745521414165382,
      "grad_norm": 32.91665267944336,
      "learning_rate": 9.489916963226573e-07,
      "loss": 0.622,
      "step": 80
    },
    {
      "epoch": 0.004804840431842448,
      "grad_norm": 53.5190315246582,
      "learning_rate": 9.608540925266905e-07,
      "loss": 1.678,
      "step": 81
    },
    {
      "epoch": 0.004864159449519516,
      "grad_norm": 47.63593292236328,
      "learning_rate": 9.727164887307238e-07,
      "loss": 1.6328,
      "step": 82
    },
    {
      "epoch": 0.004923478467196583,
      "grad_norm": 46.98574447631836,
      "learning_rate": 9.845788849347569e-07,
      "loss": 1.3039,
      "step": 83
    },
    {
      "epoch": 0.0049827974848736505,
      "grad_norm": 32.09832000732422,
      "learning_rate": 9.964412811387902e-07,
      "loss": 0.7703,
      "step": 84
    },
    {
      "epoch": 0.005042116502550718,
      "grad_norm": 14.068093299865723,
      "learning_rate": 1.0083036773428233e-06,
      "loss": 0.9673,
      "step": 85
    },
    {
      "epoch": 0.005101435520227785,
      "grad_norm": 109.47574615478516,
      "learning_rate": 1.0201660735468566e-06,
      "loss": 0.8631,
      "step": 86
    },
    {
      "epoch": 0.005160754537904853,
      "grad_norm": 25.765417098999023,
      "learning_rate": 1.0320284697508897e-06,
      "loss": 0.3716,
      "step": 87
    },
    {
      "epoch": 0.005220073555581919,
      "grad_norm": 332.5910339355469,
      "learning_rate": 1.043890865954923e-06,
      "loss": 1.702,
      "step": 88
    },
    {
      "epoch": 0.005279392573258987,
      "grad_norm": 14.339134216308594,
      "learning_rate": 1.055753262158956e-06,
      "loss": 0.2289,
      "step": 89
    },
    {
      "epoch": 0.005338711590936054,
      "grad_norm": 21.796384811401367,
      "learning_rate": 1.0676156583629894e-06,
      "loss": 0.2974,
      "step": 90
    },
    {
      "epoch": 0.0053980306086131215,
      "grad_norm": 56.36151123046875,
      "learning_rate": 1.0794780545670227e-06,
      "loss": 1.0407,
      "step": 91
    },
    {
      "epoch": 0.005457349626290188,
      "grad_norm": 69.94447326660156,
      "learning_rate": 1.0913404507710558e-06,
      "loss": 0.2829,
      "step": 92
    },
    {
      "epoch": 0.005516668643967256,
      "grad_norm": 10.895770072937012,
      "learning_rate": 1.1032028469750891e-06,
      "loss": 0.6561,
      "step": 93
    },
    {
      "epoch": 0.005575987661644323,
      "grad_norm": 30.37158966064453,
      "learning_rate": 1.1150652431791222e-06,
      "loss": 0.6053,
      "step": 94
    },
    {
      "epoch": 0.0056353066793213905,
      "grad_norm": 29.332706451416016,
      "learning_rate": 1.1269276393831555e-06,
      "loss": 0.6045,
      "step": 95
    },
    {
      "epoch": 0.005694625696998458,
      "grad_norm": 24.956544876098633,
      "learning_rate": 1.1387900355871886e-06,
      "loss": 0.6386,
      "step": 96
    },
    {
      "epoch": 0.005753944714675525,
      "grad_norm": 16.534542083740234,
      "learning_rate": 1.150652431791222e-06,
      "loss": 0.4756,
      "step": 97
    },
    {
      "epoch": 0.005813263732352593,
      "grad_norm": 76.67335510253906,
      "learning_rate": 1.1625148279952552e-06,
      "loss": 2.2155,
      "step": 98
    },
    {
      "epoch": 0.005872582750029659,
      "grad_norm": 32.78414535522461,
      "learning_rate": 1.1743772241992883e-06,
      "loss": 0.5853,
      "step": 99
    },
    {
      "epoch": 0.005931901767706727,
      "grad_norm": 40.033470153808594,
      "learning_rate": 1.1862396204033216e-06,
      "loss": 0.2807,
      "step": 100
    },
    {
      "epoch": 0.005991220785383794,
      "grad_norm": 61.65553665161133,
      "learning_rate": 1.1981020166073547e-06,
      "loss": 0.6524,
      "step": 101
    },
    {
      "epoch": 0.0060505398030608615,
      "grad_norm": 20.528127670288086,
      "learning_rate": 1.209964412811388e-06,
      "loss": 0.9628,
      "step": 102
    },
    {
      "epoch": 0.006109858820737928,
      "grad_norm": 18.94948959350586,
      "learning_rate": 1.2218268090154211e-06,
      "loss": 0.5905,
      "step": 103
    },
    {
      "epoch": 0.006169177838414996,
      "grad_norm": 60.77953338623047,
      "learning_rate": 1.2336892052194544e-06,
      "loss": 1.4975,
      "step": 104
    },
    {
      "epoch": 0.006228496856092063,
      "grad_norm": 15.832735061645508,
      "learning_rate": 1.2455516014234877e-06,
      "loss": 0.3097,
      "step": 105
    },
    {
      "epoch": 0.00628781587376913,
      "grad_norm": 28.50030517578125,
      "learning_rate": 1.257413997627521e-06,
      "loss": 0.5964,
      "step": 106
    },
    {
      "epoch": 0.006347134891446198,
      "grad_norm": 21.516468048095703,
      "learning_rate": 1.2692763938315541e-06,
      "loss": 0.6704,
      "step": 107
    },
    {
      "epoch": 0.006406453909123265,
      "grad_norm": 28.318147659301758,
      "learning_rate": 1.2811387900355872e-06,
      "loss": 0.5377,
      "step": 108
    },
    {
      "epoch": 0.0064657729268003325,
      "grad_norm": 13.896384239196777,
      "learning_rate": 1.2930011862396206e-06,
      "loss": 0.3127,
      "step": 109
    },
    {
      "epoch": 0.006525091944477399,
      "grad_norm": 7.5415263175964355,
      "learning_rate": 1.3048635824436536e-06,
      "loss": 0.4258,
      "step": 110
    },
    {
      "epoch": 0.006584410962154467,
      "grad_norm": 32.90008544921875,
      "learning_rate": 1.316725978647687e-06,
      "loss": 0.6629,
      "step": 111
    },
    {
      "epoch": 0.006643729979831534,
      "grad_norm": 27.36944007873535,
      "learning_rate": 1.32858837485172e-06,
      "loss": 0.7083,
      "step": 112
    },
    {
      "epoch": 0.006703048997508601,
      "grad_norm": 22.981767654418945,
      "learning_rate": 1.3404507710557536e-06,
      "loss": 0.7959,
      "step": 113
    },
    {
      "epoch": 0.006762368015185668,
      "grad_norm": 63.309547424316406,
      "learning_rate": 1.3523131672597867e-06,
      "loss": 0.4014,
      "step": 114
    },
    {
      "epoch": 0.006821687032862736,
      "grad_norm": 32.34077453613281,
      "learning_rate": 1.3641755634638198e-06,
      "loss": 1.0936,
      "step": 115
    },
    {
      "epoch": 0.006881006050539803,
      "grad_norm": 14.484752655029297,
      "learning_rate": 1.376037959667853e-06,
      "loss": 0.4515,
      "step": 116
    },
    {
      "epoch": 0.00694032506821687,
      "grad_norm": 6.370797157287598,
      "learning_rate": 1.3879003558718862e-06,
      "loss": 0.0635,
      "step": 117
    },
    {
      "epoch": 0.006999644085893938,
      "grad_norm": 188.53309631347656,
      "learning_rate": 1.3997627520759195e-06,
      "loss": 0.8154,
      "step": 118
    },
    {
      "epoch": 0.007058963103571005,
      "grad_norm": 51.5035400390625,
      "learning_rate": 1.4116251482799526e-06,
      "loss": 0.8029,
      "step": 119
    },
    {
      "epoch": 0.007118282121248072,
      "grad_norm": 20.599512100219727,
      "learning_rate": 1.423487544483986e-06,
      "loss": 0.7136,
      "step": 120
    },
    {
      "epoch": 0.007177601138925139,
      "grad_norm": 35.200252532958984,
      "learning_rate": 1.4353499406880192e-06,
      "loss": 0.1694,
      "step": 121
    },
    {
      "epoch": 0.007236920156602207,
      "grad_norm": 47.10051345825195,
      "learning_rate": 1.4472123368920523e-06,
      "loss": 1.007,
      "step": 122
    },
    {
      "epoch": 0.007296239174279274,
      "grad_norm": 35.89066696166992,
      "learning_rate": 1.4590747330960856e-06,
      "loss": 0.8836,
      "step": 123
    },
    {
      "epoch": 0.007355558191956341,
      "grad_norm": 19.53022575378418,
      "learning_rate": 1.4709371293001187e-06,
      "loss": 1.0838,
      "step": 124
    },
    {
      "epoch": 0.007414877209633408,
      "grad_norm": 17.390295028686523,
      "learning_rate": 1.482799525504152e-06,
      "loss": 0.7298,
      "step": 125
    },
    {
      "epoch": 0.007474196227310476,
      "grad_norm": 40.79446029663086,
      "learning_rate": 1.494661921708185e-06,
      "loss": 0.833,
      "step": 126
    },
    {
      "epoch": 0.007533515244987543,
      "grad_norm": 42.40686798095703,
      "learning_rate": 1.5065243179122182e-06,
      "loss": 1.1949,
      "step": 127
    },
    {
      "epoch": 0.00759283426266461,
      "grad_norm": 13.021488189697266,
      "learning_rate": 1.5183867141162517e-06,
      "loss": 0.427,
      "step": 128
    },
    {
      "epoch": 0.007652153280341678,
      "grad_norm": 93.64767456054688,
      "learning_rate": 1.5302491103202848e-06,
      "loss": 0.45,
      "step": 129
    },
    {
      "epoch": 0.007711472298018745,
      "grad_norm": 26.62034797668457,
      "learning_rate": 1.542111506524318e-06,
      "loss": 1.4897,
      "step": 130
    },
    {
      "epoch": 0.007770791315695812,
      "grad_norm": 5.791799545288086,
      "learning_rate": 1.5539739027283512e-06,
      "loss": 0.0789,
      "step": 131
    },
    {
      "epoch": 0.00783011033337288,
      "grad_norm": 45.0703010559082,
      "learning_rate": 1.5658362989323845e-06,
      "loss": 0.8315,
      "step": 132
    },
    {
      "epoch": 0.007889429351049946,
      "grad_norm": 19.701461791992188,
      "learning_rate": 1.5776986951364176e-06,
      "loss": 1.6172,
      "step": 133
    },
    {
      "epoch": 0.007948748368727014,
      "grad_norm": 17.200759887695312,
      "learning_rate": 1.5895610913404507e-06,
      "loss": 0.1106,
      "step": 134
    },
    {
      "epoch": 0.008008067386404081,
      "grad_norm": 49.57864761352539,
      "learning_rate": 1.6014234875444842e-06,
      "loss": 0.4637,
      "step": 135
    },
    {
      "epoch": 0.008067386404081148,
      "grad_norm": 8.914223670959473,
      "learning_rate": 1.6132858837485173e-06,
      "loss": 0.3755,
      "step": 136
    },
    {
      "epoch": 0.008126705421758215,
      "grad_norm": 32.548248291015625,
      "learning_rate": 1.6251482799525506e-06,
      "loss": 0.1224,
      "step": 137
    },
    {
      "epoch": 0.008186024439435283,
      "grad_norm": 9.139509201049805,
      "learning_rate": 1.6370106761565837e-06,
      "loss": 0.1059,
      "step": 138
    },
    {
      "epoch": 0.00824534345711235,
      "grad_norm": 61.039878845214844,
      "learning_rate": 1.648873072360617e-06,
      "loss": 1.2518,
      "step": 139
    },
    {
      "epoch": 0.008304662474789417,
      "grad_norm": 10.652982711791992,
      "learning_rate": 1.6607354685646501e-06,
      "loss": 1.2194,
      "step": 140
    },
    {
      "epoch": 0.008363981492466485,
      "grad_norm": 22.739835739135742,
      "learning_rate": 1.6725978647686832e-06,
      "loss": 0.3085,
      "step": 141
    },
    {
      "epoch": 0.008423300510143552,
      "grad_norm": 39.32793045043945,
      "learning_rate": 1.6844602609727167e-06,
      "loss": 0.9252,
      "step": 142
    },
    {
      "epoch": 0.008482619527820619,
      "grad_norm": 23.002059936523438,
      "learning_rate": 1.69632265717675e-06,
      "loss": 0.3482,
      "step": 143
    },
    {
      "epoch": 0.008541938545497686,
      "grad_norm": 24.187681198120117,
      "learning_rate": 1.7081850533807831e-06,
      "loss": 0.3614,
      "step": 144
    },
    {
      "epoch": 0.008601257563174754,
      "grad_norm": 13.541705131530762,
      "learning_rate": 1.7200474495848162e-06,
      "loss": 0.1397,
      "step": 145
    },
    {
      "epoch": 0.008660576580851821,
      "grad_norm": 21.693809509277344,
      "learning_rate": 1.7319098457888495e-06,
      "loss": 0.3884,
      "step": 146
    },
    {
      "epoch": 0.008719895598528888,
      "grad_norm": 36.69486618041992,
      "learning_rate": 1.7437722419928826e-06,
      "loss": 0.4732,
      "step": 147
    },
    {
      "epoch": 0.008779214616205955,
      "grad_norm": 66.3919906616211,
      "learning_rate": 1.7556346381969157e-06,
      "loss": 1.2716,
      "step": 148
    },
    {
      "epoch": 0.008838533633883023,
      "grad_norm": 2.669985294342041,
      "learning_rate": 1.7674970344009492e-06,
      "loss": 0.0197,
      "step": 149
    },
    {
      "epoch": 0.00889785265156009,
      "grad_norm": 17.826412200927734,
      "learning_rate": 1.7793594306049826e-06,
      "loss": 0.4452,
      "step": 150
    },
    {
      "epoch": 0.008957171669237157,
      "grad_norm": 46.85899353027344,
      "learning_rate": 1.7912218268090156e-06,
      "loss": 1.4407,
      "step": 151
    },
    {
      "epoch": 0.009016490686914225,
      "grad_norm": 29.015804290771484,
      "learning_rate": 1.8030842230130487e-06,
      "loss": 0.8162,
      "step": 152
    },
    {
      "epoch": 0.009075809704591292,
      "grad_norm": 22.666688919067383,
      "learning_rate": 1.814946619217082e-06,
      "loss": 0.103,
      "step": 153
    },
    {
      "epoch": 0.009135128722268359,
      "grad_norm": 15.232190132141113,
      "learning_rate": 1.8268090154211151e-06,
      "loss": 0.1729,
      "step": 154
    },
    {
      "epoch": 0.009194447739945426,
      "grad_norm": 20.400596618652344,
      "learning_rate": 1.8386714116251482e-06,
      "loss": 0.3859,
      "step": 155
    },
    {
      "epoch": 0.009253766757622494,
      "grad_norm": 10.00393009185791,
      "learning_rate": 1.8505338078291815e-06,
      "loss": 0.2085,
      "step": 156
    },
    {
      "epoch": 0.009313085775299561,
      "grad_norm": 74.92560577392578,
      "learning_rate": 1.862396204033215e-06,
      "loss": 0.8395,
      "step": 157
    },
    {
      "epoch": 0.009372404792976628,
      "grad_norm": 16.837371826171875,
      "learning_rate": 1.8742586002372482e-06,
      "loss": 0.4283,
      "step": 158
    },
    {
      "epoch": 0.009431723810653695,
      "grad_norm": 16.395610809326172,
      "learning_rate": 1.8861209964412813e-06,
      "loss": 0.2252,
      "step": 159
    },
    {
      "epoch": 0.009491042828330763,
      "grad_norm": 30.830352783203125,
      "learning_rate": 1.8979833926453146e-06,
      "loss": 0.5286,
      "step": 160
    },
    {
      "epoch": 0.00955036184600783,
      "grad_norm": 13.937146186828613,
      "learning_rate": 1.909845788849348e-06,
      "loss": 0.2031,
      "step": 161
    },
    {
      "epoch": 0.009609680863684897,
      "grad_norm": 35.293121337890625,
      "learning_rate": 1.921708185053381e-06,
      "loss": 0.8141,
      "step": 162
    },
    {
      "epoch": 0.009668999881361965,
      "grad_norm": 25.00118064880371,
      "learning_rate": 1.933570581257414e-06,
      "loss": 0.4485,
      "step": 163
    },
    {
      "epoch": 0.009728318899039032,
      "grad_norm": 14.270784378051758,
      "learning_rate": 1.9454329774614476e-06,
      "loss": 0.4613,
      "step": 164
    },
    {
      "epoch": 0.009787637916716099,
      "grad_norm": 29.038301467895508,
      "learning_rate": 1.9572953736654807e-06,
      "loss": 0.81,
      "step": 165
    },
    {
      "epoch": 0.009846956934393166,
      "grad_norm": 9.776226997375488,
      "learning_rate": 1.9691577698695138e-06,
      "loss": 0.1892,
      "step": 166
    },
    {
      "epoch": 0.009906275952070234,
      "grad_norm": 1.7161364555358887,
      "learning_rate": 1.981020166073547e-06,
      "loss": 0.0226,
      "step": 167
    },
    {
      "epoch": 0.009965594969747301,
      "grad_norm": 24.420392990112305,
      "learning_rate": 1.9928825622775804e-06,
      "loss": 0.3319,
      "step": 168
    },
    {
      "epoch": 0.010024913987424368,
      "grad_norm": 36.88396453857422,
      "learning_rate": 2.0047449584816135e-06,
      "loss": 0.4658,
      "step": 169
    },
    {
      "epoch": 0.010084233005101436,
      "grad_norm": 29.969589233398438,
      "learning_rate": 2.0166073546856466e-06,
      "loss": 0.2696,
      "step": 170
    },
    {
      "epoch": 0.010143552022778503,
      "grad_norm": 18.385299682617188,
      "learning_rate": 2.02846975088968e-06,
      "loss": 0.3636,
      "step": 171
    },
    {
      "epoch": 0.01020287104045557,
      "grad_norm": 31.880414962768555,
      "learning_rate": 2.040332147093713e-06,
      "loss": 0.3482,
      "step": 172
    },
    {
      "epoch": 0.010262190058132637,
      "grad_norm": 28.632469177246094,
      "learning_rate": 2.0521945432977463e-06,
      "loss": 0.5212,
      "step": 173
    },
    {
      "epoch": 0.010321509075809705,
      "grad_norm": 46.48494338989258,
      "learning_rate": 2.0640569395017794e-06,
      "loss": 0.609,
      "step": 174
    },
    {
      "epoch": 0.010380828093486772,
      "grad_norm": 17.78241539001465,
      "learning_rate": 2.075919335705813e-06,
      "loss": 0.1559,
      "step": 175
    },
    {
      "epoch": 0.010440147111163839,
      "grad_norm": 53.983882904052734,
      "learning_rate": 2.087781731909846e-06,
      "loss": 2.5247,
      "step": 176
    },
    {
      "epoch": 0.010499466128840906,
      "grad_norm": 35.81573486328125,
      "learning_rate": 2.099644128113879e-06,
      "loss": 0.7034,
      "step": 177
    },
    {
      "epoch": 0.010558785146517974,
      "grad_norm": 20.41644287109375,
      "learning_rate": 2.111506524317912e-06,
      "loss": 0.6194,
      "step": 178
    },
    {
      "epoch": 0.010618104164195041,
      "grad_norm": 36.88861846923828,
      "learning_rate": 2.1233689205219457e-06,
      "loss": 0.5353,
      "step": 179
    },
    {
      "epoch": 0.010677423181872108,
      "grad_norm": 2.2670767307281494,
      "learning_rate": 2.135231316725979e-06,
      "loss": 0.0316,
      "step": 180
    },
    {
      "epoch": 0.010736742199549176,
      "grad_norm": 5.573067665100098,
      "learning_rate": 2.147093712930012e-06,
      "loss": 0.1052,
      "step": 181
    },
    {
      "epoch": 0.010796061217226243,
      "grad_norm": 19.03733253479004,
      "learning_rate": 2.1589561091340454e-06,
      "loss": 0.1763,
      "step": 182
    },
    {
      "epoch": 0.01085538023490331,
      "grad_norm": 15.619942665100098,
      "learning_rate": 2.1708185053380785e-06,
      "loss": 0.1793,
      "step": 183
    },
    {
      "epoch": 0.010914699252580377,
      "grad_norm": 32.225074768066406,
      "learning_rate": 2.1826809015421116e-06,
      "loss": 0.1697,
      "step": 184
    },
    {
      "epoch": 0.010974018270257445,
      "grad_norm": 16.86585235595703,
      "learning_rate": 2.1945432977461447e-06,
      "loss": 0.3968,
      "step": 185
    },
    {
      "epoch": 0.011033337287934512,
      "grad_norm": 3.2731096744537354,
      "learning_rate": 2.2064056939501782e-06,
      "loss": 0.0371,
      "step": 186
    },
    {
      "epoch": 0.011092656305611579,
      "grad_norm": 60.51643371582031,
      "learning_rate": 2.2182680901542113e-06,
      "loss": 0.656,
      "step": 187
    },
    {
      "epoch": 0.011151975323288646,
      "grad_norm": 32.551273345947266,
      "learning_rate": 2.2301304863582444e-06,
      "loss": 0.3008,
      "step": 188
    },
    {
      "epoch": 0.011211294340965714,
      "grad_norm": 26.363264083862305,
      "learning_rate": 2.241992882562278e-06,
      "loss": 0.4331,
      "step": 189
    },
    {
      "epoch": 0.011270613358642781,
      "grad_norm": 35.42939376831055,
      "learning_rate": 2.253855278766311e-06,
      "loss": 0.406,
      "step": 190
    },
    {
      "epoch": 0.011329932376319848,
      "grad_norm": 25.44184684753418,
      "learning_rate": 2.265717674970344e-06,
      "loss": 0.499,
      "step": 191
    },
    {
      "epoch": 0.011389251393996916,
      "grad_norm": 11.333423614501953,
      "learning_rate": 2.2775800711743772e-06,
      "loss": 0.2562,
      "step": 192
    },
    {
      "epoch": 0.011448570411673983,
      "grad_norm": 5.15677547454834,
      "learning_rate": 2.2894424673784107e-06,
      "loss": 0.0469,
      "step": 193
    },
    {
      "epoch": 0.01150788942935105,
      "grad_norm": 76.04222869873047,
      "learning_rate": 2.301304863582444e-06,
      "loss": 0.6752,
      "step": 194
    },
    {
      "epoch": 0.011567208447028117,
      "grad_norm": 1.8089264631271362,
      "learning_rate": 2.313167259786477e-06,
      "loss": 0.0234,
      "step": 195
    },
    {
      "epoch": 0.011626527464705185,
      "grad_norm": 61.26433563232422,
      "learning_rate": 2.3250296559905105e-06,
      "loss": 1.7952,
      "step": 196
    },
    {
      "epoch": 0.011685846482382252,
      "grad_norm": 25.42932891845703,
      "learning_rate": 2.3368920521945436e-06,
      "loss": 0.165,
      "step": 197
    },
    {
      "epoch": 0.011745165500059319,
      "grad_norm": 2.3779232501983643,
      "learning_rate": 2.3487544483985766e-06,
      "loss": 0.0298,
      "step": 198
    },
    {
      "epoch": 0.011804484517736386,
      "grad_norm": 21.06014060974121,
      "learning_rate": 2.3606168446026097e-06,
      "loss": 0.3358,
      "step": 199
    },
    {
      "epoch": 0.011863803535413454,
      "grad_norm": 56.88042449951172,
      "learning_rate": 2.3724792408066433e-06,
      "loss": 0.7482,
      "step": 200
    },
    {
      "epoch": 0.01192312255309052,
      "grad_norm": 27.384723663330078,
      "learning_rate": 2.3843416370106764e-06,
      "loss": 0.9022,
      "step": 201
    },
    {
      "epoch": 0.011982441570767588,
      "grad_norm": 27.021595001220703,
      "learning_rate": 2.3962040332147095e-06,
      "loss": 0.5832,
      "step": 202
    },
    {
      "epoch": 0.012041760588444656,
      "grad_norm": 19.63344955444336,
      "learning_rate": 2.408066429418743e-06,
      "loss": 0.1846,
      "step": 203
    },
    {
      "epoch": 0.012101079606121723,
      "grad_norm": 20.44239044189453,
      "learning_rate": 2.419928825622776e-06,
      "loss": 0.1031,
      "step": 204
    },
    {
      "epoch": 0.01216039862379879,
      "grad_norm": 10.51576042175293,
      "learning_rate": 2.431791221826809e-06,
      "loss": 0.314,
      "step": 205
    },
    {
      "epoch": 0.012219717641475857,
      "grad_norm": 24.19548225402832,
      "learning_rate": 2.4436536180308423e-06,
      "loss": 0.3095,
      "step": 206
    },
    {
      "epoch": 0.012279036659152925,
      "grad_norm": 84.45732116699219,
      "learning_rate": 2.4555160142348754e-06,
      "loss": 1.3594,
      "step": 207
    },
    {
      "epoch": 0.012338355676829992,
      "grad_norm": 5.653714179992676,
      "learning_rate": 2.467378410438909e-06,
      "loss": 0.083,
      "step": 208
    },
    {
      "epoch": 0.012397674694507059,
      "grad_norm": 2.0013551712036133,
      "learning_rate": 2.479240806642942e-06,
      "loss": 0.0182,
      "step": 209
    },
    {
      "epoch": 0.012456993712184125,
      "grad_norm": 1.34891939163208,
      "learning_rate": 2.4911032028469755e-06,
      "loss": 0.0126,
      "step": 210
    },
    {
      "epoch": 0.012516312729861194,
      "grad_norm": 2.7314023971557617,
      "learning_rate": 2.5029655990510086e-06,
      "loss": 0.0605,
      "step": 211
    },
    {
      "epoch": 0.01257563174753826,
      "grad_norm": 24.924911499023438,
      "learning_rate": 2.514827995255042e-06,
      "loss": 0.1376,
      "step": 212
    },
    {
      "epoch": 0.012634950765215328,
      "grad_norm": 35.85737609863281,
      "learning_rate": 2.526690391459075e-06,
      "loss": 0.0892,
      "step": 213
    },
    {
      "epoch": 0.012694269782892396,
      "grad_norm": 27.998605728149414,
      "learning_rate": 2.5385527876631083e-06,
      "loss": 0.6387,
      "step": 214
    },
    {
      "epoch": 0.012753588800569463,
      "grad_norm": 33.4176139831543,
      "learning_rate": 2.5504151838671414e-06,
      "loss": 0.704,
      "step": 215
    },
    {
      "epoch": 0.01281290781824653,
      "grad_norm": 28.455434799194336,
      "learning_rate": 2.5622775800711745e-06,
      "loss": 0.4288,
      "step": 216
    },
    {
      "epoch": 0.012872226835923596,
      "grad_norm": 18.30112648010254,
      "learning_rate": 2.574139976275208e-06,
      "loss": 0.1971,
      "step": 217
    },
    {
      "epoch": 0.012931545853600665,
      "grad_norm": 1.3666890859603882,
      "learning_rate": 2.586002372479241e-06,
      "loss": 0.0172,
      "step": 218
    },
    {
      "epoch": 0.012990864871277732,
      "grad_norm": 36.8421630859375,
      "learning_rate": 2.597864768683274e-06,
      "loss": 1.2668,
      "step": 219
    },
    {
      "epoch": 0.013050183888954799,
      "grad_norm": 16.2437801361084,
      "learning_rate": 2.6097271648873073e-06,
      "loss": 0.2747,
      "step": 220
    },
    {
      "epoch": 0.013109502906631865,
      "grad_norm": 12.883844375610352,
      "learning_rate": 2.6215895610913404e-06,
      "loss": 0.7401,
      "step": 221
    },
    {
      "epoch": 0.013168821924308934,
      "grad_norm": 33.96721267700195,
      "learning_rate": 2.633451957295374e-06,
      "loss": 0.9313,
      "step": 222
    },
    {
      "epoch": 0.013228140941986,
      "grad_norm": 61.47676086425781,
      "learning_rate": 2.645314353499407e-06,
      "loss": 2.9222,
      "step": 223
    },
    {
      "epoch": 0.013287459959663067,
      "grad_norm": 3.9019455909729004,
      "learning_rate": 2.65717674970344e-06,
      "loss": 0.0332,
      "step": 224
    },
    {
      "epoch": 0.013346778977340136,
      "grad_norm": 12.74038028717041,
      "learning_rate": 2.669039145907473e-06,
      "loss": 0.2131,
      "step": 225
    },
    {
      "epoch": 0.013406097995017203,
      "grad_norm": 41.14720916748047,
      "learning_rate": 2.680901542111507e-06,
      "loss": 1.7224,
      "step": 226
    },
    {
      "epoch": 0.01346541701269427,
      "grad_norm": 30.8498477935791,
      "learning_rate": 2.6927639383155402e-06,
      "loss": 0.3343,
      "step": 227
    },
    {
      "epoch": 0.013524736030371336,
      "grad_norm": 4.7135910987854,
      "learning_rate": 2.7046263345195733e-06,
      "loss": 0.05,
      "step": 228
    },
    {
      "epoch": 0.013584055048048405,
      "grad_norm": 31.424684524536133,
      "learning_rate": 2.7164887307236064e-06,
      "loss": 0.6413,
      "step": 229
    },
    {
      "epoch": 0.013643374065725472,
      "grad_norm": 23.154830932617188,
      "learning_rate": 2.7283511269276395e-06,
      "loss": 0.1569,
      "step": 230
    },
    {
      "epoch": 0.013702693083402539,
      "grad_norm": 43.15333557128906,
      "learning_rate": 2.740213523131673e-06,
      "loss": 0.5052,
      "step": 231
    },
    {
      "epoch": 0.013762012101079605,
      "grad_norm": 47.13294219970703,
      "learning_rate": 2.752075919335706e-06,
      "loss": 0.2459,
      "step": 232
    },
    {
      "epoch": 0.013821331118756674,
      "grad_norm": 12.980045318603516,
      "learning_rate": 2.7639383155397392e-06,
      "loss": 0.2657,
      "step": 233
    },
    {
      "epoch": 0.01388065013643374,
      "grad_norm": 36.940128326416016,
      "learning_rate": 2.7758007117437723e-06,
      "loss": 0.6207,
      "step": 234
    },
    {
      "epoch": 0.013939969154110807,
      "grad_norm": 16.513761520385742,
      "learning_rate": 2.7876631079478054e-06,
      "loss": 0.2994,
      "step": 235
    },
    {
      "epoch": 0.013999288171787876,
      "grad_norm": 75.68594360351562,
      "learning_rate": 2.799525504151839e-06,
      "loss": 0.7756,
      "step": 236
    },
    {
      "epoch": 0.014058607189464943,
      "grad_norm": 89.40553283691406,
      "learning_rate": 2.811387900355872e-06,
      "loss": 0.8364,
      "step": 237
    },
    {
      "epoch": 0.01411792620714201,
      "grad_norm": 22.8454532623291,
      "learning_rate": 2.823250296559905e-06,
      "loss": 0.3833,
      "step": 238
    },
    {
      "epoch": 0.014177245224819076,
      "grad_norm": 33.39584732055664,
      "learning_rate": 2.8351126927639382e-06,
      "loss": 0.3642,
      "step": 239
    },
    {
      "epoch": 0.014236564242496145,
      "grad_norm": 9.252045631408691,
      "learning_rate": 2.846975088967972e-06,
      "loss": 0.1105,
      "step": 240
    },
    {
      "epoch": 0.014295883260173212,
      "grad_norm": 26.20060157775879,
      "learning_rate": 2.8588374851720053e-06,
      "loss": 1.181,
      "step": 241
    },
    {
      "epoch": 0.014355202277850278,
      "grad_norm": 24.104169845581055,
      "learning_rate": 2.8706998813760384e-06,
      "loss": 0.9153,
      "step": 242
    },
    {
      "epoch": 0.014414521295527345,
      "grad_norm": 11.22342300415039,
      "learning_rate": 2.8825622775800715e-06,
      "loss": 0.0622,
      "step": 243
    },
    {
      "epoch": 0.014473840313204414,
      "grad_norm": 25.888505935668945,
      "learning_rate": 2.8944246737841046e-06,
      "loss": 0.8295,
      "step": 244
    },
    {
      "epoch": 0.01453315933088148,
      "grad_norm": 33.810585021972656,
      "learning_rate": 2.906287069988138e-06,
      "loss": 0.6895,
      "step": 245
    },
    {
      "epoch": 0.014592478348558547,
      "grad_norm": 26.957345962524414,
      "learning_rate": 2.918149466192171e-06,
      "loss": 0.4937,
      "step": 246
    },
    {
      "epoch": 0.014651797366235616,
      "grad_norm": 15.080723762512207,
      "learning_rate": 2.9300118623962043e-06,
      "loss": 0.4153,
      "step": 247
    },
    {
      "epoch": 0.014711116383912683,
      "grad_norm": 5.338090896606445,
      "learning_rate": 2.9418742586002374e-06,
      "loss": 0.0371,
      "step": 248
    },
    {
      "epoch": 0.01477043540158975,
      "grad_norm": 5.7739973068237305,
      "learning_rate": 2.9537366548042705e-06,
      "loss": 0.0639,
      "step": 249
    },
    {
      "epoch": 0.014829754419266816,
      "grad_norm": 39.10357666015625,
      "learning_rate": 2.965599051008304e-06,
      "loss": 0.3755,
      "step": 250
    },
    {
      "epoch": 0.014889073436943885,
      "grad_norm": 19.85245132446289,
      "learning_rate": 2.977461447212337e-06,
      "loss": 0.1217,
      "step": 251
    },
    {
      "epoch": 0.014948392454620952,
      "grad_norm": 1.926372766494751,
      "learning_rate": 2.98932384341637e-06,
      "loss": 0.018,
      "step": 252
    },
    {
      "epoch": 0.015007711472298018,
      "grad_norm": 19.442176818847656,
      "learning_rate": 3.0011862396204033e-06,
      "loss": 0.2821,
      "step": 253
    },
    {
      "epoch": 0.015067030489975085,
      "grad_norm": 113.26595306396484,
      "learning_rate": 3.0130486358244364e-06,
      "loss": 2.7842,
      "step": 254
    },
    {
      "epoch": 0.015126349507652154,
      "grad_norm": 17.0638484954834,
      "learning_rate": 3.0249110320284703e-06,
      "loss": 0.1368,
      "step": 255
    },
    {
      "epoch": 0.01518566852532922,
      "grad_norm": 11.766704559326172,
      "learning_rate": 3.0367734282325034e-06,
      "loss": 0.0689,
      "step": 256
    },
    {
      "epoch": 0.015244987543006287,
      "grad_norm": 3.803536891937256,
      "learning_rate": 3.0486358244365365e-06,
      "loss": 0.0511,
      "step": 257
    },
    {
      "epoch": 0.015304306560683356,
      "grad_norm": 51.72078323364258,
      "learning_rate": 3.0604982206405696e-06,
      "loss": 1.0352,
      "step": 258
    },
    {
      "epoch": 0.015363625578360423,
      "grad_norm": 21.064504623413086,
      "learning_rate": 3.072360616844603e-06,
      "loss": 1.5483,
      "step": 259
    },
    {
      "epoch": 0.01542294459603749,
      "grad_norm": 10.774333000183105,
      "learning_rate": 3.084223013048636e-06,
      "loss": 0.0444,
      "step": 260
    },
    {
      "epoch": 0.015482263613714556,
      "grad_norm": 15.908637046813965,
      "learning_rate": 3.0960854092526693e-06,
      "loss": 0.2588,
      "step": 261
    },
    {
      "epoch": 0.015541582631391625,
      "grad_norm": 37.355289459228516,
      "learning_rate": 3.1079478054567024e-06,
      "loss": 0.6238,
      "step": 262
    },
    {
      "epoch": 0.015600901649068692,
      "grad_norm": 80.33399200439453,
      "learning_rate": 3.1198102016607355e-06,
      "loss": 0.468,
      "step": 263
    },
    {
      "epoch": 0.01566022066674576,
      "grad_norm": 61.06782150268555,
      "learning_rate": 3.131672597864769e-06,
      "loss": 0.7477,
      "step": 264
    },
    {
      "epoch": 0.015719539684422825,
      "grad_norm": 16.136411666870117,
      "learning_rate": 3.143534994068802e-06,
      "loss": 0.1311,
      "step": 265
    },
    {
      "epoch": 0.015778858702099892,
      "grad_norm": 38.80807113647461,
      "learning_rate": 3.155397390272835e-06,
      "loss": 0.6732,
      "step": 266
    },
    {
      "epoch": 0.015838177719776962,
      "grad_norm": 1.432082176208496,
      "learning_rate": 3.1672597864768683e-06,
      "loss": 0.0107,
      "step": 267
    },
    {
      "epoch": 0.01589749673745403,
      "grad_norm": 10.857145309448242,
      "learning_rate": 3.1791221826809014e-06,
      "loss": 0.1299,
      "step": 268
    },
    {
      "epoch": 0.015956815755131096,
      "grad_norm": 3.3091769218444824,
      "learning_rate": 3.1909845788849353e-06,
      "loss": 0.0305,
      "step": 269
    },
    {
      "epoch": 0.016016134772808163,
      "grad_norm": 3.513911008834839,
      "learning_rate": 3.2028469750889684e-06,
      "loss": 0.0341,
      "step": 270
    },
    {
      "epoch": 0.01607545379048523,
      "grad_norm": 10.538867950439453,
      "learning_rate": 3.2147093712930015e-06,
      "loss": 0.1392,
      "step": 271
    },
    {
      "epoch": 0.016134772808162296,
      "grad_norm": 4.503777503967285,
      "learning_rate": 3.2265717674970346e-06,
      "loss": 0.0286,
      "step": 272
    },
    {
      "epoch": 0.016194091825839363,
      "grad_norm": 59.96050262451172,
      "learning_rate": 3.238434163701068e-06,
      "loss": 0.7089,
      "step": 273
    },
    {
      "epoch": 0.01625341084351643,
      "grad_norm": 37.533531188964844,
      "learning_rate": 3.2502965599051012e-06,
      "loss": 0.7658,
      "step": 274
    },
    {
      "epoch": 0.0163127298611935,
      "grad_norm": 41.40412139892578,
      "learning_rate": 3.2621589561091343e-06,
      "loss": 0.5386,
      "step": 275
    },
    {
      "epoch": 0.016372048878870567,
      "grad_norm": 11.515114784240723,
      "learning_rate": 3.2740213523131674e-06,
      "loss": 0.4656,
      "step": 276
    },
    {
      "epoch": 0.016431367896547634,
      "grad_norm": 16.591602325439453,
      "learning_rate": 3.2858837485172005e-06,
      "loss": 0.441,
      "step": 277
    },
    {
      "epoch": 0.0164906869142247,
      "grad_norm": 11.709247589111328,
      "learning_rate": 3.297746144721234e-06,
      "loss": 1.147,
      "step": 278
    },
    {
      "epoch": 0.016550005931901767,
      "grad_norm": 5.741352081298828,
      "learning_rate": 3.309608540925267e-06,
      "loss": 0.0794,
      "step": 279
    },
    {
      "epoch": 0.016609324949578834,
      "grad_norm": 4.3433146476745605,
      "learning_rate": 3.3214709371293002e-06,
      "loss": 0.0383,
      "step": 280
    },
    {
      "epoch": 0.0166686439672559,
      "grad_norm": 18.72660255432129,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.5869,
      "step": 281
    },
    {
      "epoch": 0.01672796298493297,
      "grad_norm": 5.562717914581299,
      "learning_rate": 3.3451957295373664e-06,
      "loss": 0.0383,
      "step": 282
    },
    {
      "epoch": 0.016787282002610038,
      "grad_norm": 36.744285583496094,
      "learning_rate": 3.3570581257414e-06,
      "loss": 0.6589,
      "step": 283
    },
    {
      "epoch": 0.016846601020287105,
      "grad_norm": 30.9134521484375,
      "learning_rate": 3.3689205219454335e-06,
      "loss": 0.6273,
      "step": 284
    },
    {
      "epoch": 0.01690592003796417,
      "grad_norm": 13.87418270111084,
      "learning_rate": 3.3807829181494666e-06,
      "loss": 0.15,
      "step": 285
    },
    {
      "epoch": 0.016965239055641238,
      "grad_norm": 21.795852661132812,
      "learning_rate": 3.3926453143535e-06,
      "loss": 0.4788,
      "step": 286
    },
    {
      "epoch": 0.017024558073318305,
      "grad_norm": 33.53510284423828,
      "learning_rate": 3.404507710557533e-06,
      "loss": 0.2789,
      "step": 287
    },
    {
      "epoch": 0.017083877090995372,
      "grad_norm": 48.63550567626953,
      "learning_rate": 3.4163701067615663e-06,
      "loss": 0.7778,
      "step": 288
    },
    {
      "epoch": 0.017143196108672442,
      "grad_norm": 27.542850494384766,
      "learning_rate": 3.4282325029655994e-06,
      "loss": 0.4126,
      "step": 289
    },
    {
      "epoch": 0.01720251512634951,
      "grad_norm": 9.147525787353516,
      "learning_rate": 3.4400948991696325e-06,
      "loss": 0.1297,
      "step": 290
    },
    {
      "epoch": 0.017261834144026576,
      "grad_norm": 13.290396690368652,
      "learning_rate": 3.4519572953736656e-06,
      "loss": 0.2147,
      "step": 291
    },
    {
      "epoch": 0.017321153161703642,
      "grad_norm": 14.49785327911377,
      "learning_rate": 3.463819691577699e-06,
      "loss": 0.0737,
      "step": 292
    },
    {
      "epoch": 0.01738047217938071,
      "grad_norm": 49.71638488769531,
      "learning_rate": 3.475682087781732e-06,
      "loss": 0.5189,
      "step": 293
    },
    {
      "epoch": 0.017439791197057776,
      "grad_norm": 43.69709777832031,
      "learning_rate": 3.4875444839857653e-06,
      "loss": 0.5232,
      "step": 294
    },
    {
      "epoch": 0.017499110214734843,
      "grad_norm": 16.400053024291992,
      "learning_rate": 3.4994068801897984e-06,
      "loss": 0.4424,
      "step": 295
    },
    {
      "epoch": 0.01755842923241191,
      "grad_norm": 44.083168029785156,
      "learning_rate": 3.5112692763938315e-06,
      "loss": 0.2941,
      "step": 296
    },
    {
      "epoch": 0.01761774825008898,
      "grad_norm": 16.044960021972656,
      "learning_rate": 3.523131672597865e-06,
      "loss": 0.3248,
      "step": 297
    },
    {
      "epoch": 0.017677067267766047,
      "grad_norm": 13.611616134643555,
      "learning_rate": 3.5349940688018985e-06,
      "loss": 0.5154,
      "step": 298
    },
    {
      "epoch": 0.017736386285443113,
      "grad_norm": 3.828232526779175,
      "learning_rate": 3.5468564650059316e-06,
      "loss": 0.0546,
      "step": 299
    },
    {
      "epoch": 0.01779570530312018,
      "grad_norm": 15.169906616210938,
      "learning_rate": 3.558718861209965e-06,
      "loss": 0.2607,
      "step": 300
    },
    {
      "epoch": 0.017855024320797247,
      "grad_norm": 1.344543695449829,
      "learning_rate": 3.570581257413998e-06,
      "loss": 0.0091,
      "step": 301
    },
    {
      "epoch": 0.017914343338474314,
      "grad_norm": 38.31380844116211,
      "learning_rate": 3.5824436536180313e-06,
      "loss": 1.5884,
      "step": 302
    },
    {
      "epoch": 0.01797366235615138,
      "grad_norm": 36.779361724853516,
      "learning_rate": 3.5943060498220644e-06,
      "loss": 0.272,
      "step": 303
    },
    {
      "epoch": 0.01803298137382845,
      "grad_norm": 31.5524959564209,
      "learning_rate": 3.6061684460260975e-06,
      "loss": 0.4616,
      "step": 304
    },
    {
      "epoch": 0.018092300391505518,
      "grad_norm": 99.38426208496094,
      "learning_rate": 3.6180308422301306e-06,
      "loss": 1.6149,
      "step": 305
    },
    {
      "epoch": 0.018151619409182584,
      "grad_norm": 27.373435974121094,
      "learning_rate": 3.629893238434164e-06,
      "loss": 0.5038,
      "step": 306
    },
    {
      "epoch": 0.01821093842685965,
      "grad_norm": 24.156408309936523,
      "learning_rate": 3.641755634638197e-06,
      "loss": 0.7945,
      "step": 307
    },
    {
      "epoch": 0.018270257444536718,
      "grad_norm": 11.020200729370117,
      "learning_rate": 3.6536180308422303e-06,
      "loss": 0.333,
      "step": 308
    },
    {
      "epoch": 0.018329576462213785,
      "grad_norm": 13.830069541931152,
      "learning_rate": 3.6654804270462634e-06,
      "loss": 0.2732,
      "step": 309
    },
    {
      "epoch": 0.01838889547989085,
      "grad_norm": 27.35219955444336,
      "learning_rate": 3.6773428232502965e-06,
      "loss": 1.0108,
      "step": 310
    },
    {
      "epoch": 0.018448214497567922,
      "grad_norm": 14.183393478393555,
      "learning_rate": 3.68920521945433e-06,
      "loss": 0.4616,
      "step": 311
    },
    {
      "epoch": 0.01850753351524499,
      "grad_norm": 22.015954971313477,
      "learning_rate": 3.701067615658363e-06,
      "loss": 0.3403,
      "step": 312
    },
    {
      "epoch": 0.018566852532922055,
      "grad_norm": 20.875816345214844,
      "learning_rate": 3.7129300118623966e-06,
      "loss": 1.3939,
      "step": 313
    },
    {
      "epoch": 0.018626171550599122,
      "grad_norm": 0.5591548681259155,
      "learning_rate": 3.72479240806643e-06,
      "loss": 0.0118,
      "step": 314
    },
    {
      "epoch": 0.01868549056827619,
      "grad_norm": 19.980257034301758,
      "learning_rate": 3.7366548042704632e-06,
      "loss": 0.4552,
      "step": 315
    },
    {
      "epoch": 0.018744809585953256,
      "grad_norm": 1.2171714305877686,
      "learning_rate": 3.7485172004744963e-06,
      "loss": 0.0158,
      "step": 316
    },
    {
      "epoch": 0.018804128603630323,
      "grad_norm": 21.071542739868164,
      "learning_rate": 3.7603795966785294e-06,
      "loss": 0.2359,
      "step": 317
    },
    {
      "epoch": 0.01886344762130739,
      "grad_norm": 10.512090682983398,
      "learning_rate": 3.7722419928825625e-06,
      "loss": 0.25,
      "step": 318
    },
    {
      "epoch": 0.01892276663898446,
      "grad_norm": 24.257400512695312,
      "learning_rate": 3.784104389086596e-06,
      "loss": 0.258,
      "step": 319
    },
    {
      "epoch": 0.018982085656661526,
      "grad_norm": 25.846656799316406,
      "learning_rate": 3.795966785290629e-06,
      "loss": 0.1953,
      "step": 320
    },
    {
      "epoch": 0.019041404674338593,
      "grad_norm": 18.676658630371094,
      "learning_rate": 3.8078291814946622e-06,
      "loss": 0.3095,
      "step": 321
    },
    {
      "epoch": 0.01910072369201566,
      "grad_norm": 21.771339416503906,
      "learning_rate": 3.819691577698696e-06,
      "loss": 0.6922,
      "step": 322
    },
    {
      "epoch": 0.019160042709692727,
      "grad_norm": 1.901534080505371,
      "learning_rate": 3.831553973902728e-06,
      "loss": 0.0317,
      "step": 323
    },
    {
      "epoch": 0.019219361727369794,
      "grad_norm": 50.81045150756836,
      "learning_rate": 3.843416370106762e-06,
      "loss": 0.7865,
      "step": 324
    },
    {
      "epoch": 0.01927868074504686,
      "grad_norm": 5.654763221740723,
      "learning_rate": 3.855278766310795e-06,
      "loss": 0.0723,
      "step": 325
    },
    {
      "epoch": 0.01933799976272393,
      "grad_norm": 30.57217025756836,
      "learning_rate": 3.867141162514828e-06,
      "loss": 0.3189,
      "step": 326
    },
    {
      "epoch": 0.019397318780400997,
      "grad_norm": 0.913116991519928,
      "learning_rate": 3.879003558718862e-06,
      "loss": 0.0158,
      "step": 327
    },
    {
      "epoch": 0.019456637798078064,
      "grad_norm": 23.236278533935547,
      "learning_rate": 3.890865954922895e-06,
      "loss": 0.1286,
      "step": 328
    },
    {
      "epoch": 0.01951595681575513,
      "grad_norm": 53.033050537109375,
      "learning_rate": 3.902728351126928e-06,
      "loss": 0.2703,
      "step": 329
    },
    {
      "epoch": 0.019575275833432198,
      "grad_norm": 6.1879563331604,
      "learning_rate": 3.914590747330961e-06,
      "loss": 0.1885,
      "step": 330
    },
    {
      "epoch": 0.019634594851109265,
      "grad_norm": 13.236085891723633,
      "learning_rate": 3.926453143534995e-06,
      "loss": 0.2333,
      "step": 331
    },
    {
      "epoch": 0.01969391386878633,
      "grad_norm": 43.68854522705078,
      "learning_rate": 3.9383155397390276e-06,
      "loss": 1.0965,
      "step": 332
    },
    {
      "epoch": 0.0197532328864634,
      "grad_norm": 1.2685322761535645,
      "learning_rate": 3.950177935943061e-06,
      "loss": 0.0158,
      "step": 333
    },
    {
      "epoch": 0.01981255190414047,
      "grad_norm": 8.670794486999512,
      "learning_rate": 3.962040332147094e-06,
      "loss": 0.0994,
      "step": 334
    },
    {
      "epoch": 0.019871870921817535,
      "grad_norm": 7.495683670043945,
      "learning_rate": 3.973902728351127e-06,
      "loss": 0.0712,
      "step": 335
    },
    {
      "epoch": 0.019931189939494602,
      "grad_norm": 23.613725662231445,
      "learning_rate": 3.985765124555161e-06,
      "loss": 0.4037,
      "step": 336
    },
    {
      "epoch": 0.01999050895717167,
      "grad_norm": 3.2578365802764893,
      "learning_rate": 3.9976275207591935e-06,
      "loss": 0.0189,
      "step": 337
    },
    {
      "epoch": 0.020049827974848736,
      "grad_norm": 22.93348503112793,
      "learning_rate": 4.009489916963227e-06,
      "loss": 0.5356,
      "step": 338
    },
    {
      "epoch": 0.020109146992525802,
      "grad_norm": 40.78229904174805,
      "learning_rate": 4.02135231316726e-06,
      "loss": 0.5034,
      "step": 339
    },
    {
      "epoch": 0.020168466010202873,
      "grad_norm": 3.311279535293579,
      "learning_rate": 4.033214709371293e-06,
      "loss": 0.0254,
      "step": 340
    },
    {
      "epoch": 0.02022778502787994,
      "grad_norm": 36.30038070678711,
      "learning_rate": 4.045077105575327e-06,
      "loss": 0.8259,
      "step": 341
    },
    {
      "epoch": 0.020287104045557006,
      "grad_norm": 100.17850494384766,
      "learning_rate": 4.05693950177936e-06,
      "loss": 0.6997,
      "step": 342
    },
    {
      "epoch": 0.020346423063234073,
      "grad_norm": 31.999422073364258,
      "learning_rate": 4.068801897983393e-06,
      "loss": 0.3901,
      "step": 343
    },
    {
      "epoch": 0.02040574208091114,
      "grad_norm": 14.074980735778809,
      "learning_rate": 4.080664294187426e-06,
      "loss": 0.1819,
      "step": 344
    },
    {
      "epoch": 0.020465061098588207,
      "grad_norm": 3.4235565662384033,
      "learning_rate": 4.09252669039146e-06,
      "loss": 0.029,
      "step": 345
    },
    {
      "epoch": 0.020524380116265274,
      "grad_norm": 3.3697216510772705,
      "learning_rate": 4.104389086595493e-06,
      "loss": 0.0228,
      "step": 346
    },
    {
      "epoch": 0.02058369913394234,
      "grad_norm": 36.917118072509766,
      "learning_rate": 4.116251482799526e-06,
      "loss": 0.4915,
      "step": 347
    },
    {
      "epoch": 0.02064301815161941,
      "grad_norm": 79.53916931152344,
      "learning_rate": 4.128113879003559e-06,
      "loss": 1.3515,
      "step": 348
    },
    {
      "epoch": 0.020702337169296477,
      "grad_norm": 12.419602394104004,
      "learning_rate": 4.139976275207592e-06,
      "loss": 0.2074,
      "step": 349
    },
    {
      "epoch": 0.020761656186973544,
      "grad_norm": 56.59999465942383,
      "learning_rate": 4.151838671411626e-06,
      "loss": 0.3049,
      "step": 350
    },
    {
      "epoch": 0.02082097520465061,
      "grad_norm": 15.864811897277832,
      "learning_rate": 4.1637010676156585e-06,
      "loss": 0.9252,
      "step": 351
    },
    {
      "epoch": 0.020880294222327678,
      "grad_norm": 50.469215393066406,
      "learning_rate": 4.175563463819692e-06,
      "loss": 0.3773,
      "step": 352
    },
    {
      "epoch": 0.020939613240004745,
      "grad_norm": 14.335256576538086,
      "learning_rate": 4.187425860023725e-06,
      "loss": 0.3383,
      "step": 353
    },
    {
      "epoch": 0.02099893225768181,
      "grad_norm": 1.4576228857040405,
      "learning_rate": 4.199288256227758e-06,
      "loss": 0.013,
      "step": 354
    },
    {
      "epoch": 0.02105825127535888,
      "grad_norm": 11.569210052490234,
      "learning_rate": 4.211150652431792e-06,
      "loss": 1.0119,
      "step": 355
    },
    {
      "epoch": 0.02111757029303595,
      "grad_norm": 2.7433581352233887,
      "learning_rate": 4.223013048635824e-06,
      "loss": 0.0207,
      "step": 356
    },
    {
      "epoch": 0.021176889310713015,
      "grad_norm": 4.296839714050293,
      "learning_rate": 4.234875444839858e-06,
      "loss": 0.0413,
      "step": 357
    },
    {
      "epoch": 0.021236208328390082,
      "grad_norm": 43.312950134277344,
      "learning_rate": 4.2467378410438914e-06,
      "loss": 0.7749,
      "step": 358
    },
    {
      "epoch": 0.02129552734606715,
      "grad_norm": 25.598430633544922,
      "learning_rate": 4.258600237247925e-06,
      "loss": 1.2024,
      "step": 359
    },
    {
      "epoch": 0.021354846363744216,
      "grad_norm": 35.993343353271484,
      "learning_rate": 4.270462633451958e-06,
      "loss": 0.2212,
      "step": 360
    },
    {
      "epoch": 0.021414165381421282,
      "grad_norm": 4.499322414398193,
      "learning_rate": 4.282325029655991e-06,
      "loss": 0.0322,
      "step": 361
    },
    {
      "epoch": 0.021473484399098353,
      "grad_norm": 52.19636917114258,
      "learning_rate": 4.294187425860024e-06,
      "loss": 0.9175,
      "step": 362
    },
    {
      "epoch": 0.02153280341677542,
      "grad_norm": 563.0819091796875,
      "learning_rate": 4.306049822064057e-06,
      "loss": 0.6958,
      "step": 363
    },
    {
      "epoch": 0.021592122434452486,
      "grad_norm": 1.6662224531173706,
      "learning_rate": 4.317912218268091e-06,
      "loss": 0.0151,
      "step": 364
    },
    {
      "epoch": 0.021651441452129553,
      "grad_norm": 50.47195053100586,
      "learning_rate": 4.3297746144721235e-06,
      "loss": 1.4061,
      "step": 365
    },
    {
      "epoch": 0.02171076046980662,
      "grad_norm": 22.977746963500977,
      "learning_rate": 4.341637010676157e-06,
      "loss": 0.7272,
      "step": 366
    },
    {
      "epoch": 0.021770079487483687,
      "grad_norm": 42.62785339355469,
      "learning_rate": 4.35349940688019e-06,
      "loss": 1.2326,
      "step": 367
    },
    {
      "epoch": 0.021829398505160753,
      "grad_norm": 0.8876022100448608,
      "learning_rate": 4.365361803084223e-06,
      "loss": 0.0065,
      "step": 368
    },
    {
      "epoch": 0.02188871752283782,
      "grad_norm": 58.492164611816406,
      "learning_rate": 4.377224199288257e-06,
      "loss": 0.1667,
      "step": 369
    },
    {
      "epoch": 0.02194803654051489,
      "grad_norm": 26.588428497314453,
      "learning_rate": 4.389086595492289e-06,
      "loss": 0.2713,
      "step": 370
    },
    {
      "epoch": 0.022007355558191957,
      "grad_norm": 41.60142517089844,
      "learning_rate": 4.400948991696323e-06,
      "loss": 0.2405,
      "step": 371
    },
    {
      "epoch": 0.022066674575869024,
      "grad_norm": 23.66971206665039,
      "learning_rate": 4.4128113879003565e-06,
      "loss": 0.2179,
      "step": 372
    },
    {
      "epoch": 0.02212599359354609,
      "grad_norm": 8.879677772521973,
      "learning_rate": 4.42467378410439e-06,
      "loss": 0.0409,
      "step": 373
    },
    {
      "epoch": 0.022185312611223158,
      "grad_norm": 2.4198482036590576,
      "learning_rate": 4.436536180308423e-06,
      "loss": 0.0263,
      "step": 374
    },
    {
      "epoch": 0.022244631628900224,
      "grad_norm": 18.61821746826172,
      "learning_rate": 4.448398576512456e-06,
      "loss": 0.0844,
      "step": 375
    },
    {
      "epoch": 0.02230395064657729,
      "grad_norm": 0.2476583570241928,
      "learning_rate": 4.460260972716489e-06,
      "loss": 0.0025,
      "step": 376
    },
    {
      "epoch": 0.02236326966425436,
      "grad_norm": 7.290757656097412,
      "learning_rate": 4.472123368920522e-06,
      "loss": 0.0934,
      "step": 377
    },
    {
      "epoch": 0.022422588681931428,
      "grad_norm": 11.085472106933594,
      "learning_rate": 4.483985765124556e-06,
      "loss": 0.2579,
      "step": 378
    },
    {
      "epoch": 0.022481907699608495,
      "grad_norm": 98.82109069824219,
      "learning_rate": 4.4958481613285886e-06,
      "loss": 1.0618,
      "step": 379
    },
    {
      "epoch": 0.022541226717285562,
      "grad_norm": 29.299882888793945,
      "learning_rate": 4.507710557532622e-06,
      "loss": 0.5959,
      "step": 380
    },
    {
      "epoch": 0.02260054573496263,
      "grad_norm": 0.863355815410614,
      "learning_rate": 4.519572953736655e-06,
      "loss": 0.0079,
      "step": 381
    },
    {
      "epoch": 0.022659864752639695,
      "grad_norm": 11.506941795349121,
      "learning_rate": 4.531435349940688e-06,
      "loss": 0.3151,
      "step": 382
    },
    {
      "epoch": 0.022719183770316762,
      "grad_norm": 0.7523003816604614,
      "learning_rate": 4.543297746144722e-06,
      "loss": 0.0043,
      "step": 383
    },
    {
      "epoch": 0.022778502787993832,
      "grad_norm": 27.391460418701172,
      "learning_rate": 4.5551601423487545e-06,
      "loss": 0.5575,
      "step": 384
    },
    {
      "epoch": 0.0228378218056709,
      "grad_norm": 27.681787490844727,
      "learning_rate": 4.567022538552788e-06,
      "loss": 0.389,
      "step": 385
    },
    {
      "epoch": 0.022897140823347966,
      "grad_norm": 23.04844093322754,
      "learning_rate": 4.5788849347568215e-06,
      "loss": 0.2498,
      "step": 386
    },
    {
      "epoch": 0.022956459841025033,
      "grad_norm": 24.591554641723633,
      "learning_rate": 4.590747330960855e-06,
      "loss": 0.3716,
      "step": 387
    },
    {
      "epoch": 0.0230157788587021,
      "grad_norm": 86.09770965576172,
      "learning_rate": 4.602609727164888e-06,
      "loss": 0.9713,
      "step": 388
    },
    {
      "epoch": 0.023075097876379166,
      "grad_norm": 54.55867004394531,
      "learning_rate": 4.614472123368921e-06,
      "loss": 2.038,
      "step": 389
    },
    {
      "epoch": 0.023134416894056233,
      "grad_norm": 11.225473403930664,
      "learning_rate": 4.626334519572954e-06,
      "loss": 0.0836,
      "step": 390
    },
    {
      "epoch": 0.0231937359117333,
      "grad_norm": 7.734654903411865,
      "learning_rate": 4.638196915776987e-06,
      "loss": 0.0619,
      "step": 391
    },
    {
      "epoch": 0.02325305492941037,
      "grad_norm": 6.840951919555664,
      "learning_rate": 4.650059311981021e-06,
      "loss": 0.056,
      "step": 392
    },
    {
      "epoch": 0.023312373947087437,
      "grad_norm": 28.903472900390625,
      "learning_rate": 4.661921708185054e-06,
      "loss": 0.1628,
      "step": 393
    },
    {
      "epoch": 0.023371692964764504,
      "grad_norm": 23.15361976623535,
      "learning_rate": 4.673784104389087e-06,
      "loss": 1.7242,
      "step": 394
    },
    {
      "epoch": 0.02343101198244157,
      "grad_norm": 51.580074310302734,
      "learning_rate": 4.68564650059312e-06,
      "loss": 0.2953,
      "step": 395
    },
    {
      "epoch": 0.023490331000118637,
      "grad_norm": 28.856813430786133,
      "learning_rate": 4.697508896797153e-06,
      "loss": 0.7261,
      "step": 396
    },
    {
      "epoch": 0.023549650017795704,
      "grad_norm": 13.548829078674316,
      "learning_rate": 4.709371293001187e-06,
      "loss": 0.0966,
      "step": 397
    },
    {
      "epoch": 0.02360896903547277,
      "grad_norm": 17.42716407775879,
      "learning_rate": 4.7212336892052195e-06,
      "loss": 0.0746,
      "step": 398
    },
    {
      "epoch": 0.02366828805314984,
      "grad_norm": 37.84424591064453,
      "learning_rate": 4.733096085409253e-06,
      "loss": 0.3589,
      "step": 399
    },
    {
      "epoch": 0.023727607070826908,
      "grad_norm": 10.89127254486084,
      "learning_rate": 4.7449584816132865e-06,
      "loss": 0.0619,
      "step": 400
    },
    {
      "epoch": 0.023786926088503975,
      "grad_norm": 0.48342201113700867,
      "learning_rate": 4.75682087781732e-06,
      "loss": 0.005,
      "step": 401
    },
    {
      "epoch": 0.02384624510618104,
      "grad_norm": 8.16068172454834,
      "learning_rate": 4.768683274021353e-06,
      "loss": 0.0798,
      "step": 402
    },
    {
      "epoch": 0.02390556412385811,
      "grad_norm": 1.5532094240188599,
      "learning_rate": 4.780545670225386e-06,
      "loss": 0.0147,
      "step": 403
    },
    {
      "epoch": 0.023964883141535175,
      "grad_norm": 91.38591766357422,
      "learning_rate": 4.792408066429419e-06,
      "loss": 1.778,
      "step": 404
    },
    {
      "epoch": 0.024024202159212242,
      "grad_norm": 27.30093002319336,
      "learning_rate": 4.8042704626334524e-06,
      "loss": 0.4091,
      "step": 405
    },
    {
      "epoch": 0.024083521176889312,
      "grad_norm": 19.575464248657227,
      "learning_rate": 4.816132858837486e-06,
      "loss": 0.0848,
      "step": 406
    },
    {
      "epoch": 0.02414284019456638,
      "grad_norm": 0.28234443068504333,
      "learning_rate": 4.827995255041519e-06,
      "loss": 0.0046,
      "step": 407
    },
    {
      "epoch": 0.024202159212243446,
      "grad_norm": 89.24227142333984,
      "learning_rate": 4.839857651245552e-06,
      "loss": 1.4643,
      "step": 408
    },
    {
      "epoch": 0.024261478229920513,
      "grad_norm": 27.388225555419922,
      "learning_rate": 4.851720047449585e-06,
      "loss": 0.3584,
      "step": 409
    },
    {
      "epoch": 0.02432079724759758,
      "grad_norm": 3.933063507080078,
      "learning_rate": 4.863582443653618e-06,
      "loss": 0.0294,
      "step": 410
    },
    {
      "epoch": 0.024380116265274646,
      "grad_norm": 15.265995979309082,
      "learning_rate": 4.875444839857652e-06,
      "loss": 0.2139,
      "step": 411
    },
    {
      "epoch": 0.024439435282951713,
      "grad_norm": 16.251354217529297,
      "learning_rate": 4.8873072360616845e-06,
      "loss": 0.1984,
      "step": 412
    },
    {
      "epoch": 0.02449875430062878,
      "grad_norm": 2.8407113552093506,
      "learning_rate": 4.899169632265718e-06,
      "loss": 0.0199,
      "step": 413
    },
    {
      "epoch": 0.02455807331830585,
      "grad_norm": 28.828147888183594,
      "learning_rate": 4.911032028469751e-06,
      "loss": 0.3343,
      "step": 414
    },
    {
      "epoch": 0.024617392335982917,
      "grad_norm": 38.379539489746094,
      "learning_rate": 4.922894424673785e-06,
      "loss": 0.1045,
      "step": 415
    },
    {
      "epoch": 0.024676711353659984,
      "grad_norm": 16.21827507019043,
      "learning_rate": 4.934756820877818e-06,
      "loss": 1.4535,
      "step": 416
    },
    {
      "epoch": 0.02473603037133705,
      "grad_norm": 7.460943698883057,
      "learning_rate": 4.946619217081851e-06,
      "loss": 0.2359,
      "step": 417
    },
    {
      "epoch": 0.024795349389014117,
      "grad_norm": 14.497017860412598,
      "learning_rate": 4.958481613285884e-06,
      "loss": 0.4507,
      "step": 418
    },
    {
      "epoch": 0.024854668406691184,
      "grad_norm": 53.220062255859375,
      "learning_rate": 4.9703440094899175e-06,
      "loss": 0.364,
      "step": 419
    },
    {
      "epoch": 0.02491398742436825,
      "grad_norm": 18.87822914123535,
      "learning_rate": 4.982206405693951e-06,
      "loss": 0.1927,
      "step": 420
    },
    {
      "epoch": 0.02497330644204532,
      "grad_norm": 19.281494140625,
      "learning_rate": 4.994068801897984e-06,
      "loss": 0.0955,
      "step": 421
    },
    {
      "epoch": 0.025032625459722388,
      "grad_norm": 35.270748138427734,
      "learning_rate": 5.005931198102017e-06,
      "loss": 0.2354,
      "step": 422
    },
    {
      "epoch": 0.025091944477399455,
      "grad_norm": 4.161923885345459,
      "learning_rate": 5.017793594306051e-06,
      "loss": 0.0182,
      "step": 423
    },
    {
      "epoch": 0.02515126349507652,
      "grad_norm": 34.13665771484375,
      "learning_rate": 5.029655990510084e-06,
      "loss": 1.4643,
      "step": 424
    },
    {
      "epoch": 0.02521058251275359,
      "grad_norm": 0.37689685821533203,
      "learning_rate": 5.041518386714117e-06,
      "loss": 0.0044,
      "step": 425
    },
    {
      "epoch": 0.025269901530430655,
      "grad_norm": 0.7206357717514038,
      "learning_rate": 5.05338078291815e-06,
      "loss": 0.0091,
      "step": 426
    },
    {
      "epoch": 0.025329220548107722,
      "grad_norm": 43.16693115234375,
      "learning_rate": 5.065243179122183e-06,
      "loss": 0.1187,
      "step": 427
    },
    {
      "epoch": 0.025388539565784792,
      "grad_norm": 38.01136016845703,
      "learning_rate": 5.077105575326217e-06,
      "loss": 0.344,
      "step": 428
    },
    {
      "epoch": 0.02544785858346186,
      "grad_norm": 5.614851474761963,
      "learning_rate": 5.08896797153025e-06,
      "loss": 0.0622,
      "step": 429
    },
    {
      "epoch": 0.025507177601138926,
      "grad_norm": 26.903339385986328,
      "learning_rate": 5.100830367734283e-06,
      "loss": 0.6652,
      "step": 430
    },
    {
      "epoch": 0.025566496618815993,
      "grad_norm": 4.11208438873291,
      "learning_rate": 5.112692763938316e-06,
      "loss": 0.0375,
      "step": 431
    },
    {
      "epoch": 0.02562581563649306,
      "grad_norm": 6.739086627960205,
      "learning_rate": 5.124555160142349e-06,
      "loss": 0.1061,
      "step": 432
    },
    {
      "epoch": 0.025685134654170126,
      "grad_norm": 69.28042602539062,
      "learning_rate": 5.1364175563463825e-06,
      "loss": 1.5632,
      "step": 433
    },
    {
      "epoch": 0.025744453671847193,
      "grad_norm": 3.1042397022247314,
      "learning_rate": 5.148279952550416e-06,
      "loss": 0.103,
      "step": 434
    },
    {
      "epoch": 0.025803772689524263,
      "grad_norm": 10.203184127807617,
      "learning_rate": 5.160142348754449e-06,
      "loss": 0.1756,
      "step": 435
    },
    {
      "epoch": 0.02586309170720133,
      "grad_norm": 19.857433319091797,
      "learning_rate": 5.172004744958482e-06,
      "loss": 0.2326,
      "step": 436
    },
    {
      "epoch": 0.025922410724878397,
      "grad_norm": 2.7567594051361084,
      "learning_rate": 5.183867141162515e-06,
      "loss": 0.0278,
      "step": 437
    },
    {
      "epoch": 0.025981729742555464,
      "grad_norm": 30.444719314575195,
      "learning_rate": 5.195729537366548e-06,
      "loss": 0.2391,
      "step": 438
    },
    {
      "epoch": 0.02604104876023253,
      "grad_norm": 79.04061889648438,
      "learning_rate": 5.207591933570582e-06,
      "loss": 0.6306,
      "step": 439
    },
    {
      "epoch": 0.026100367777909597,
      "grad_norm": 24.096309661865234,
      "learning_rate": 5.219454329774615e-06,
      "loss": 0.1968,
      "step": 440
    },
    {
      "epoch": 0.026159686795586664,
      "grad_norm": 42.54764938354492,
      "learning_rate": 5.231316725978648e-06,
      "loss": 0.2969,
      "step": 441
    },
    {
      "epoch": 0.02621900581326373,
      "grad_norm": 27.4951171875,
      "learning_rate": 5.243179122182681e-06,
      "loss": 0.3914,
      "step": 442
    },
    {
      "epoch": 0.0262783248309408,
      "grad_norm": 67.53387451171875,
      "learning_rate": 5.255041518386714e-06,
      "loss": 0.5784,
      "step": 443
    },
    {
      "epoch": 0.026337643848617868,
      "grad_norm": 1.667177438735962,
      "learning_rate": 5.266903914590748e-06,
      "loss": 0.0105,
      "step": 444
    },
    {
      "epoch": 0.026396962866294935,
      "grad_norm": 12.531370162963867,
      "learning_rate": 5.2787663107947805e-06,
      "loss": 0.1507,
      "step": 445
    },
    {
      "epoch": 0.026456281883972,
      "grad_norm": 4.362466812133789,
      "learning_rate": 5.290628706998814e-06,
      "loss": 0.0455,
      "step": 446
    },
    {
      "epoch": 0.026515600901649068,
      "grad_norm": 11.447038650512695,
      "learning_rate": 5.302491103202847e-06,
      "loss": 0.1925,
      "step": 447
    },
    {
      "epoch": 0.026574919919326135,
      "grad_norm": 42.80162811279297,
      "learning_rate": 5.31435349940688e-06,
      "loss": 0.2744,
      "step": 448
    },
    {
      "epoch": 0.026634238937003202,
      "grad_norm": 3.3882386684417725,
      "learning_rate": 5.326215895610914e-06,
      "loss": 0.0217,
      "step": 449
    },
    {
      "epoch": 0.026693557954680272,
      "grad_norm": 1.1061683893203735,
      "learning_rate": 5.338078291814946e-06,
      "loss": 0.0108,
      "step": 450
    },
    {
      "epoch": 0.02675287697235734,
      "grad_norm": 61.4359245300293,
      "learning_rate": 5.349940688018981e-06,
      "loss": 0.449,
      "step": 451
    },
    {
      "epoch": 0.026812195990034406,
      "grad_norm": 5.2446818351745605,
      "learning_rate": 5.361803084223014e-06,
      "loss": 0.0655,
      "step": 452
    },
    {
      "epoch": 0.026871515007711472,
      "grad_norm": 16.501888275146484,
      "learning_rate": 5.373665480427047e-06,
      "loss": 1.9903,
      "step": 453
    },
    {
      "epoch": 0.02693083402538854,
      "grad_norm": 0.6132614612579346,
      "learning_rate": 5.3855278766310805e-06,
      "loss": 0.0058,
      "step": 454
    },
    {
      "epoch": 0.026990153043065606,
      "grad_norm": 3.248063325881958,
      "learning_rate": 5.397390272835113e-06,
      "loss": 0.0358,
      "step": 455
    },
    {
      "epoch": 0.027049472060742673,
      "grad_norm": 144.2313995361328,
      "learning_rate": 5.409252669039147e-06,
      "loss": 0.6238,
      "step": 456
    },
    {
      "epoch": 0.027108791078419743,
      "grad_norm": 2.10817551612854,
      "learning_rate": 5.42111506524318e-06,
      "loss": 0.0194,
      "step": 457
    },
    {
      "epoch": 0.02716811009609681,
      "grad_norm": 27.03932762145996,
      "learning_rate": 5.432977461447213e-06,
      "loss": 0.6017,
      "step": 458
    },
    {
      "epoch": 0.027227429113773877,
      "grad_norm": 80.41546630859375,
      "learning_rate": 5.444839857651246e-06,
      "loss": 1.1224,
      "step": 459
    },
    {
      "epoch": 0.027286748131450943,
      "grad_norm": 5.565119743347168,
      "learning_rate": 5.456702253855279e-06,
      "loss": 0.0311,
      "step": 460
    },
    {
      "epoch": 0.02734606714912801,
      "grad_norm": 16.207368850708008,
      "learning_rate": 5.4685646500593126e-06,
      "loss": 0.273,
      "step": 461
    },
    {
      "epoch": 0.027405386166805077,
      "grad_norm": 15.337684631347656,
      "learning_rate": 5.480427046263346e-06,
      "loss": 0.0987,
      "step": 462
    },
    {
      "epoch": 0.027464705184482144,
      "grad_norm": 39.43831253051758,
      "learning_rate": 5.492289442467379e-06,
      "loss": 0.6719,
      "step": 463
    },
    {
      "epoch": 0.02752402420215921,
      "grad_norm": 45.23306655883789,
      "learning_rate": 5.504151838671412e-06,
      "loss": 0.5731,
      "step": 464
    },
    {
      "epoch": 0.02758334321983628,
      "grad_norm": 11.618595123291016,
      "learning_rate": 5.516014234875445e-06,
      "loss": 0.171,
      "step": 465
    },
    {
      "epoch": 0.027642662237513348,
      "grad_norm": 3.571790933609009,
      "learning_rate": 5.5278766310794785e-06,
      "loss": 0.019,
      "step": 466
    },
    {
      "epoch": 0.027701981255190414,
      "grad_norm": 58.88029479980469,
      "learning_rate": 5.539739027283512e-06,
      "loss": 0.6387,
      "step": 467
    },
    {
      "epoch": 0.02776130027286748,
      "grad_norm": 0.9503989219665527,
      "learning_rate": 5.551601423487545e-06,
      "loss": 0.0079,
      "step": 468
    },
    {
      "epoch": 0.027820619290544548,
      "grad_norm": 8.97628402709961,
      "learning_rate": 5.563463819691578e-06,
      "loss": 0.2937,
      "step": 469
    },
    {
      "epoch": 0.027879938308221615,
      "grad_norm": 56.35631561279297,
      "learning_rate": 5.575326215895611e-06,
      "loss": 1.724,
      "step": 470
    },
    {
      "epoch": 0.02793925732589868,
      "grad_norm": 0.7859665751457214,
      "learning_rate": 5.587188612099644e-06,
      "loss": 0.0061,
      "step": 471
    },
    {
      "epoch": 0.027998576343575752,
      "grad_norm": 5.7547430992126465,
      "learning_rate": 5.599051008303678e-06,
      "loss": 0.0578,
      "step": 472
    },
    {
      "epoch": 0.02805789536125282,
      "grad_norm": 6.784146785736084,
      "learning_rate": 5.6109134045077106e-06,
      "loss": 0.0899,
      "step": 473
    },
    {
      "epoch": 0.028117214378929885,
      "grad_norm": 13.41358757019043,
      "learning_rate": 5.622775800711744e-06,
      "loss": 0.068,
      "step": 474
    },
    {
      "epoch": 0.028176533396606952,
      "grad_norm": 1.4162429571151733,
      "learning_rate": 5.634638196915777e-06,
      "loss": 0.0055,
      "step": 475
    },
    {
      "epoch": 0.02823585241428402,
      "grad_norm": 11.567426681518555,
      "learning_rate": 5.64650059311981e-06,
      "loss": 0.2956,
      "step": 476
    },
    {
      "epoch": 0.028295171431961086,
      "grad_norm": 39.92967224121094,
      "learning_rate": 5.658362989323844e-06,
      "loss": 0.5062,
      "step": 477
    },
    {
      "epoch": 0.028354490449638153,
      "grad_norm": 2.0051004886627197,
      "learning_rate": 5.6702253855278765e-06,
      "loss": 0.0148,
      "step": 478
    },
    {
      "epoch": 0.028413809467315223,
      "grad_norm": 59.80725860595703,
      "learning_rate": 5.68208778173191e-06,
      "loss": 2.1171,
      "step": 479
    },
    {
      "epoch": 0.02847312848499229,
      "grad_norm": 34.02106857299805,
      "learning_rate": 5.693950177935944e-06,
      "loss": 0.5772,
      "step": 480
    },
    {
      "epoch": 0.028532447502669357,
      "grad_norm": 13.271178245544434,
      "learning_rate": 5.705812574139977e-06,
      "loss": 0.6776,
      "step": 481
    },
    {
      "epoch": 0.028591766520346423,
      "grad_norm": 47.57286834716797,
      "learning_rate": 5.7176749703440105e-06,
      "loss": 0.4492,
      "step": 482
    },
    {
      "epoch": 0.02865108553802349,
      "grad_norm": 24.322189331054688,
      "learning_rate": 5.729537366548043e-06,
      "loss": 0.1445,
      "step": 483
    },
    {
      "epoch": 0.028710404555700557,
      "grad_norm": 70.58203887939453,
      "learning_rate": 5.741399762752077e-06,
      "loss": 1.8687,
      "step": 484
    },
    {
      "epoch": 0.028769723573377624,
      "grad_norm": 11.68777084350586,
      "learning_rate": 5.75326215895611e-06,
      "loss": 0.889,
      "step": 485
    },
    {
      "epoch": 0.02882904259105469,
      "grad_norm": 1.5925242900848389,
      "learning_rate": 5.765124555160143e-06,
      "loss": 0.0081,
      "step": 486
    },
    {
      "epoch": 0.02888836160873176,
      "grad_norm": 13.196725845336914,
      "learning_rate": 5.7769869513641764e-06,
      "loss": 0.1634,
      "step": 487
    },
    {
      "epoch": 0.028947680626408828,
      "grad_norm": 14.901154518127441,
      "learning_rate": 5.788849347568209e-06,
      "loss": 0.3209,
      "step": 488
    },
    {
      "epoch": 0.029006999644085894,
      "grad_norm": 90.0256118774414,
      "learning_rate": 5.800711743772243e-06,
      "loss": 2.2225,
      "step": 489
    },
    {
      "epoch": 0.02906631866176296,
      "grad_norm": 20.48738670349121,
      "learning_rate": 5.812574139976276e-06,
      "loss": 0.3111,
      "step": 490
    },
    {
      "epoch": 0.029125637679440028,
      "grad_norm": 30.302928924560547,
      "learning_rate": 5.824436536180309e-06,
      "loss": 0.7738,
      "step": 491
    },
    {
      "epoch": 0.029184956697117095,
      "grad_norm": 60.763954162597656,
      "learning_rate": 5.836298932384342e-06,
      "loss": 0.3535,
      "step": 492
    },
    {
      "epoch": 0.02924427571479416,
      "grad_norm": 0.7529153823852539,
      "learning_rate": 5.848161328588375e-06,
      "loss": 0.0074,
      "step": 493
    },
    {
      "epoch": 0.029303594732471232,
      "grad_norm": 15.407999992370605,
      "learning_rate": 5.8600237247924085e-06,
      "loss": 0.0898,
      "step": 494
    },
    {
      "epoch": 0.0293629137501483,
      "grad_norm": 16.342559814453125,
      "learning_rate": 5.871886120996442e-06,
      "loss": 0.2782,
      "step": 495
    },
    {
      "epoch": 0.029422232767825365,
      "grad_norm": 34.81489944458008,
      "learning_rate": 5.883748517200475e-06,
      "loss": 0.3509,
      "step": 496
    },
    {
      "epoch": 0.029481551785502432,
      "grad_norm": 58.58232116699219,
      "learning_rate": 5.895610913404508e-06,
      "loss": 1.5476,
      "step": 497
    },
    {
      "epoch": 0.0295408708031795,
      "grad_norm": 27.615598678588867,
      "learning_rate": 5.907473309608541e-06,
      "loss": 0.2685,
      "step": 498
    },
    {
      "epoch": 0.029600189820856566,
      "grad_norm": 0.6218074560165405,
      "learning_rate": 5.9193357058125744e-06,
      "loss": 0.0048,
      "step": 499
    },
    {
      "epoch": 0.029659508838533633,
      "grad_norm": 2.0886263847351074,
      "learning_rate": 5.931198102016608e-06,
      "loss": 0.0142,
      "step": 500
    },
    {
      "epoch": 0.029718827856210703,
      "grad_norm": 32.145626068115234,
      "learning_rate": 5.943060498220641e-06,
      "loss": 0.4246,
      "step": 501
    },
    {
      "epoch": 0.02977814687388777,
      "grad_norm": 25.664382934570312,
      "learning_rate": 5.954922894424674e-06,
      "loss": 1.0177,
      "step": 502
    },
    {
      "epoch": 0.029837465891564836,
      "grad_norm": 18.669567108154297,
      "learning_rate": 5.966785290628707e-06,
      "loss": 0.3633,
      "step": 503
    },
    {
      "epoch": 0.029896784909241903,
      "grad_norm": 46.1468391418457,
      "learning_rate": 5.97864768683274e-06,
      "loss": 1.5601,
      "step": 504
    },
    {
      "epoch": 0.02995610392691897,
      "grad_norm": 13.371537208557129,
      "learning_rate": 5.990510083036774e-06,
      "loss": 0.2941,
      "step": 505
    },
    {
      "epoch": 0.030015422944596037,
      "grad_norm": 2.451674222946167,
      "learning_rate": 6.0023724792408065e-06,
      "loss": 0.0194,
      "step": 506
    },
    {
      "epoch": 0.030074741962273104,
      "grad_norm": 32.10176086425781,
      "learning_rate": 6.01423487544484e-06,
      "loss": 0.8468,
      "step": 507
    },
    {
      "epoch": 0.03013406097995017,
      "grad_norm": 34.78166961669922,
      "learning_rate": 6.026097271648873e-06,
      "loss": 0.2432,
      "step": 508
    },
    {
      "epoch": 0.03019337999762724,
      "grad_norm": 4.358023643493652,
      "learning_rate": 6.037959667852907e-06,
      "loss": 0.0427,
      "step": 509
    },
    {
      "epoch": 0.030252699015304307,
      "grad_norm": 3.6387369632720947,
      "learning_rate": 6.049822064056941e-06,
      "loss": 0.0418,
      "step": 510
    },
    {
      "epoch": 0.030312018032981374,
      "grad_norm": 32.75173568725586,
      "learning_rate": 6.061684460260973e-06,
      "loss": 0.3172,
      "step": 511
    },
    {
      "epoch": 0.03037133705065844,
      "grad_norm": 5.468038082122803,
      "learning_rate": 6.073546856465007e-06,
      "loss": 0.0243,
      "step": 512
    },
    {
      "epoch": 0.030430656068335508,
      "grad_norm": 22.59092140197754,
      "learning_rate": 6.08540925266904e-06,
      "loss": 0.1823,
      "step": 513
    },
    {
      "epoch": 0.030489975086012575,
      "grad_norm": 18.085132598876953,
      "learning_rate": 6.097271648873073e-06,
      "loss": 0.2731,
      "step": 514
    },
    {
      "epoch": 0.03054929410368964,
      "grad_norm": 14.785921096801758,
      "learning_rate": 6.1091340450771065e-06,
      "loss": 0.6697,
      "step": 515
    },
    {
      "epoch": 0.03060861312136671,
      "grad_norm": 23.78458023071289,
      "learning_rate": 6.120996441281139e-06,
      "loss": 0.4963,
      "step": 516
    },
    {
      "epoch": 0.03066793213904378,
      "grad_norm": 0.24468249082565308,
      "learning_rate": 6.132858837485173e-06,
      "loss": 0.0026,
      "step": 517
    },
    {
      "epoch": 0.030727251156720845,
      "grad_norm": 23.85887336730957,
      "learning_rate": 6.144721233689206e-06,
      "loss": 0.5052,
      "step": 518
    },
    {
      "epoch": 0.030786570174397912,
      "grad_norm": 14.31017017364502,
      "learning_rate": 6.156583629893239e-06,
      "loss": 0.3632,
      "step": 519
    },
    {
      "epoch": 0.03084588919207498,
      "grad_norm": 0.08873153477907181,
      "learning_rate": 6.168446026097272e-06,
      "loss": 0.0016,
      "step": 520
    },
    {
      "epoch": 0.030905208209752046,
      "grad_norm": 13.749438285827637,
      "learning_rate": 6.180308422301305e-06,
      "loss": 0.0851,
      "step": 521
    },
    {
      "epoch": 0.030964527227429112,
      "grad_norm": 26.48379135131836,
      "learning_rate": 6.192170818505339e-06,
      "loss": 0.3618,
      "step": 522
    },
    {
      "epoch": 0.031023846245106183,
      "grad_norm": 22.272207260131836,
      "learning_rate": 6.204033214709372e-06,
      "loss": 0.7964,
      "step": 523
    },
    {
      "epoch": 0.03108316526278325,
      "grad_norm": 11.380992889404297,
      "learning_rate": 6.215895610913405e-06,
      "loss": 0.1358,
      "step": 524
    },
    {
      "epoch": 0.031142484280460316,
      "grad_norm": 20.790430068969727,
      "learning_rate": 6.227758007117438e-06,
      "loss": 0.2589,
      "step": 525
    },
    {
      "epoch": 0.031201803298137383,
      "grad_norm": 42.938575744628906,
      "learning_rate": 6.239620403321471e-06,
      "loss": 0.6157,
      "step": 526
    },
    {
      "epoch": 0.03126112231581445,
      "grad_norm": 77.5995101928711,
      "learning_rate": 6.2514827995255045e-06,
      "loss": 0.3481,
      "step": 527
    },
    {
      "epoch": 0.03132044133349152,
      "grad_norm": 12.254205703735352,
      "learning_rate": 6.263345195729538e-06,
      "loss": 0.3122,
      "step": 528
    },
    {
      "epoch": 0.03137976035116859,
      "grad_norm": 1.2098002433776855,
      "learning_rate": 6.275207591933571e-06,
      "loss": 0.0107,
      "step": 529
    },
    {
      "epoch": 0.03143907936884565,
      "grad_norm": 25.904346466064453,
      "learning_rate": 6.287069988137604e-06,
      "loss": 0.1683,
      "step": 530
    },
    {
      "epoch": 0.03149839838652272,
      "grad_norm": 25.032089233398438,
      "learning_rate": 6.298932384341637e-06,
      "loss": 0.0838,
      "step": 531
    },
    {
      "epoch": 0.031557717404199784,
      "grad_norm": 14.226330757141113,
      "learning_rate": 6.31079478054567e-06,
      "loss": 0.3432,
      "step": 532
    },
    {
      "epoch": 0.031617036421876854,
      "grad_norm": 4.383443355560303,
      "learning_rate": 6.322657176749704e-06,
      "loss": 0.0164,
      "step": 533
    },
    {
      "epoch": 0.031676355439553924,
      "grad_norm": 1.4674363136291504,
      "learning_rate": 6.334519572953737e-06,
      "loss": 0.0141,
      "step": 534
    },
    {
      "epoch": 0.03173567445723099,
      "grad_norm": 0.10709460079669952,
      "learning_rate": 6.34638196915777e-06,
      "loss": 0.0019,
      "step": 535
    },
    {
      "epoch": 0.03179499347490806,
      "grad_norm": 26.73877716064453,
      "learning_rate": 6.358244365361803e-06,
      "loss": 1.0931,
      "step": 536
    },
    {
      "epoch": 0.03185431249258512,
      "grad_norm": 0.46972495317459106,
      "learning_rate": 6.370106761565836e-06,
      "loss": 0.0033,
      "step": 537
    },
    {
      "epoch": 0.03191363151026219,
      "grad_norm": 10.007389068603516,
      "learning_rate": 6.381969157769871e-06,
      "loss": 0.0363,
      "step": 538
    },
    {
      "epoch": 0.031972950527939255,
      "grad_norm": 1.743033528327942,
      "learning_rate": 6.393831553973904e-06,
      "loss": 0.0109,
      "step": 539
    },
    {
      "epoch": 0.032032269545616325,
      "grad_norm": 118.57125854492188,
      "learning_rate": 6.405693950177937e-06,
      "loss": 1.4501,
      "step": 540
    },
    {
      "epoch": 0.032091588563293395,
      "grad_norm": 1.8559935092926025,
      "learning_rate": 6.41755634638197e-06,
      "loss": 0.0166,
      "step": 541
    },
    {
      "epoch": 0.03215090758097046,
      "grad_norm": 319.94891357421875,
      "learning_rate": 6.429418742586003e-06,
      "loss": 0.6142,
      "step": 542
    },
    {
      "epoch": 0.03221022659864753,
      "grad_norm": 47.4030876159668,
      "learning_rate": 6.4412811387900366e-06,
      "loss": 0.1861,
      "step": 543
    },
    {
      "epoch": 0.03226954561632459,
      "grad_norm": 4.000736236572266,
      "learning_rate": 6.453143534994069e-06,
      "loss": 0.037,
      "step": 544
    },
    {
      "epoch": 0.03232886463400166,
      "grad_norm": 5.937483310699463,
      "learning_rate": 6.465005931198103e-06,
      "loss": 0.027,
      "step": 545
    },
    {
      "epoch": 0.032388183651678726,
      "grad_norm": 13.473496437072754,
      "learning_rate": 6.476868327402136e-06,
      "loss": 0.0827,
      "step": 546
    },
    {
      "epoch": 0.032447502669355796,
      "grad_norm": 8.410700798034668,
      "learning_rate": 6.488730723606169e-06,
      "loss": 0.0788,
      "step": 547
    },
    {
      "epoch": 0.03250682168703286,
      "grad_norm": 14.92020034790039,
      "learning_rate": 6.5005931198102025e-06,
      "loss": 0.1129,
      "step": 548
    },
    {
      "epoch": 0.03256614070470993,
      "grad_norm": 31.521621704101562,
      "learning_rate": 6.512455516014235e-06,
      "loss": 0.2728,
      "step": 549
    },
    {
      "epoch": 0.032625459722387,
      "grad_norm": 9.112065315246582,
      "learning_rate": 6.524317912218269e-06,
      "loss": 0.0785,
      "step": 550
    },
    {
      "epoch": 0.03268477874006406,
      "grad_norm": 26.495683670043945,
      "learning_rate": 6.536180308422302e-06,
      "loss": 0.3832,
      "step": 551
    },
    {
      "epoch": 0.032744097757741134,
      "grad_norm": 25.934003829956055,
      "learning_rate": 6.548042704626335e-06,
      "loss": 0.6167,
      "step": 552
    },
    {
      "epoch": 0.0328034167754182,
      "grad_norm": 13.694177627563477,
      "learning_rate": 6.559905100830368e-06,
      "loss": 0.2437,
      "step": 553
    },
    {
      "epoch": 0.03286273579309527,
      "grad_norm": 13.91048526763916,
      "learning_rate": 6.571767497034401e-06,
      "loss": 0.1258,
      "step": 554
    },
    {
      "epoch": 0.03292205481077233,
      "grad_norm": 24.44048500061035,
      "learning_rate": 6.5836298932384346e-06,
      "loss": 1.0382,
      "step": 555
    },
    {
      "epoch": 0.0329813738284494,
      "grad_norm": 9.146708488464355,
      "learning_rate": 6.595492289442468e-06,
      "loss": 0.2057,
      "step": 556
    },
    {
      "epoch": 0.03304069284612647,
      "grad_norm": 77.26551818847656,
      "learning_rate": 6.607354685646501e-06,
      "loss": 1.65,
      "step": 557
    },
    {
      "epoch": 0.033100011863803534,
      "grad_norm": 1.4736500978469849,
      "learning_rate": 6.619217081850534e-06,
      "loss": 0.0114,
      "step": 558
    },
    {
      "epoch": 0.033159330881480605,
      "grad_norm": 55.7794189453125,
      "learning_rate": 6.631079478054567e-06,
      "loss": 0.4553,
      "step": 559
    },
    {
      "epoch": 0.03321864989915767,
      "grad_norm": 41.61618423461914,
      "learning_rate": 6.6429418742586005e-06,
      "loss": 0.0773,
      "step": 560
    },
    {
      "epoch": 0.03327796891683474,
      "grad_norm": 8.870129585266113,
      "learning_rate": 6.654804270462634e-06,
      "loss": 0.0793,
      "step": 561
    },
    {
      "epoch": 0.0333372879345118,
      "grad_norm": 9.174796104431152,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0865,
      "step": 562
    },
    {
      "epoch": 0.03339660695218887,
      "grad_norm": 32.07326889038086,
      "learning_rate": 6.6785290628707e-06,
      "loss": 0.404,
      "step": 563
    },
    {
      "epoch": 0.03345592596986594,
      "grad_norm": 12.44846248626709,
      "learning_rate": 6.690391459074733e-06,
      "loss": 0.0825,
      "step": 564
    },
    {
      "epoch": 0.033515244987543005,
      "grad_norm": 3.018965005874634,
      "learning_rate": 6.702253855278766e-06,
      "loss": 0.0272,
      "step": 565
    },
    {
      "epoch": 0.033574564005220076,
      "grad_norm": 63.912086486816406,
      "learning_rate": 6.7141162514828e-06,
      "loss": 0.8736,
      "step": 566
    },
    {
      "epoch": 0.03363388302289714,
      "grad_norm": 5.909724235534668,
      "learning_rate": 6.725978647686834e-06,
      "loss": 0.0399,
      "step": 567
    },
    {
      "epoch": 0.03369320204057421,
      "grad_norm": 9.065934181213379,
      "learning_rate": 6.737841043890867e-06,
      "loss": 0.0391,
      "step": 568
    },
    {
      "epoch": 0.03375252105825127,
      "grad_norm": 21.517475128173828,
      "learning_rate": 6.7497034400949004e-06,
      "loss": 0.1714,
      "step": 569
    },
    {
      "epoch": 0.03381184007592834,
      "grad_norm": 3.174170732498169,
      "learning_rate": 6.761565836298933e-06,
      "loss": 0.0188,
      "step": 570
    },
    {
      "epoch": 0.03387115909360541,
      "grad_norm": 83.66744232177734,
      "learning_rate": 6.773428232502967e-06,
      "loss": 1.1353,
      "step": 571
    },
    {
      "epoch": 0.033930478111282476,
      "grad_norm": 12.04195785522461,
      "learning_rate": 6.785290628707e-06,
      "loss": 0.7466,
      "step": 572
    },
    {
      "epoch": 0.03398979712895955,
      "grad_norm": 13.937100410461426,
      "learning_rate": 6.797153024911033e-06,
      "loss": 0.167,
      "step": 573
    },
    {
      "epoch": 0.03404911614663661,
      "grad_norm": 21.24671173095703,
      "learning_rate": 6.809015421115066e-06,
      "loss": 0.1093,
      "step": 574
    },
    {
      "epoch": 0.03410843516431368,
      "grad_norm": 15.625717163085938,
      "learning_rate": 6.820877817319099e-06,
      "loss": 0.079,
      "step": 575
    },
    {
      "epoch": 0.034167754181990743,
      "grad_norm": 26.08768081665039,
      "learning_rate": 6.8327402135231325e-06,
      "loss": 0.7419,
      "step": 576
    },
    {
      "epoch": 0.034227073199667814,
      "grad_norm": 15.016480445861816,
      "learning_rate": 6.844602609727165e-06,
      "loss": 0.2981,
      "step": 577
    },
    {
      "epoch": 0.034286392217344884,
      "grad_norm": 37.7904052734375,
      "learning_rate": 6.856465005931199e-06,
      "loss": 1.571,
      "step": 578
    },
    {
      "epoch": 0.03434571123502195,
      "grad_norm": 0.6501741409301758,
      "learning_rate": 6.868327402135232e-06,
      "loss": 0.0045,
      "step": 579
    },
    {
      "epoch": 0.03440503025269902,
      "grad_norm": 2.831965684890747,
      "learning_rate": 6.880189798339265e-06,
      "loss": 0.0392,
      "step": 580
    },
    {
      "epoch": 0.03446434927037608,
      "grad_norm": 65.36515045166016,
      "learning_rate": 6.8920521945432984e-06,
      "loss": 1.5449,
      "step": 581
    },
    {
      "epoch": 0.03452366828805315,
      "grad_norm": 15.28355598449707,
      "learning_rate": 6.903914590747331e-06,
      "loss": 0.387,
      "step": 582
    },
    {
      "epoch": 0.034582987305730215,
      "grad_norm": 15.43011474609375,
      "learning_rate": 6.915776986951365e-06,
      "loss": 0.5571,
      "step": 583
    },
    {
      "epoch": 0.034642306323407285,
      "grad_norm": 22.471908569335938,
      "learning_rate": 6.927639383155398e-06,
      "loss": 0.615,
      "step": 584
    },
    {
      "epoch": 0.034701625341084355,
      "grad_norm": 138.518310546875,
      "learning_rate": 6.939501779359431e-06,
      "loss": 1.3301,
      "step": 585
    },
    {
      "epoch": 0.03476094435876142,
      "grad_norm": 28.936952590942383,
      "learning_rate": 6.951364175563464e-06,
      "loss": 0.2442,
      "step": 586
    },
    {
      "epoch": 0.03482026337643849,
      "grad_norm": 0.91312575340271,
      "learning_rate": 6.963226571767497e-06,
      "loss": 0.0055,
      "step": 587
    },
    {
      "epoch": 0.03487958239411555,
      "grad_norm": 7.8998894691467285,
      "learning_rate": 6.9750889679715305e-06,
      "loss": 0.1763,
      "step": 588
    },
    {
      "epoch": 0.03493890141179262,
      "grad_norm": 11.277544021606445,
      "learning_rate": 6.986951364175564e-06,
      "loss": 0.1441,
      "step": 589
    },
    {
      "epoch": 0.034998220429469686,
      "grad_norm": 0.6486137509346008,
      "learning_rate": 6.998813760379597e-06,
      "loss": 0.0065,
      "step": 590
    },
    {
      "epoch": 0.035057539447146756,
      "grad_norm": 17.797426223754883,
      "learning_rate": 7.01067615658363e-06,
      "loss": 0.3192,
      "step": 591
    },
    {
      "epoch": 0.03511685846482382,
      "grad_norm": 14.91891860961914,
      "learning_rate": 7.022538552787663e-06,
      "loss": 0.3691,
      "step": 592
    },
    {
      "epoch": 0.03517617748250089,
      "grad_norm": 73.55413055419922,
      "learning_rate": 7.034400948991696e-06,
      "loss": 0.8677,
      "step": 593
    },
    {
      "epoch": 0.03523549650017796,
      "grad_norm": 17.64323616027832,
      "learning_rate": 7.04626334519573e-06,
      "loss": 0.3899,
      "step": 594
    },
    {
      "epoch": 0.03529481551785502,
      "grad_norm": 64.40029907226562,
      "learning_rate": 7.058125741399763e-06,
      "loss": 1.5063,
      "step": 595
    },
    {
      "epoch": 0.03535413453553209,
      "grad_norm": 2.762934923171997,
      "learning_rate": 7.069988137603797e-06,
      "loss": 0.0176,
      "step": 596
    },
    {
      "epoch": 0.03541345355320916,
      "grad_norm": 8.762001991271973,
      "learning_rate": 7.0818505338078305e-06,
      "loss": 0.0934,
      "step": 597
    },
    {
      "epoch": 0.03547277257088623,
      "grad_norm": 16.56723403930664,
      "learning_rate": 7.093712930011863e-06,
      "loss": 0.4287,
      "step": 598
    },
    {
      "epoch": 0.03553209158856329,
      "grad_norm": 0.13016295433044434,
      "learning_rate": 7.105575326215897e-06,
      "loss": 0.0015,
      "step": 599
    },
    {
      "epoch": 0.03559141060624036,
      "grad_norm": 17.690706253051758,
      "learning_rate": 7.11743772241993e-06,
      "loss": 0.152,
      "step": 600
    },
    {
      "epoch": 0.03565072962391743,
      "grad_norm": 0.38170596957206726,
      "learning_rate": 7.129300118623963e-06,
      "loss": 0.0028,
      "step": 601
    },
    {
      "epoch": 0.035710048641594494,
      "grad_norm": 2.481839895248413,
      "learning_rate": 7.141162514827996e-06,
      "loss": 0.0174,
      "step": 602
    },
    {
      "epoch": 0.035769367659271564,
      "grad_norm": 5.18834924697876,
      "learning_rate": 7.153024911032029e-06,
      "loss": 0.0273,
      "step": 603
    },
    {
      "epoch": 0.03582868667694863,
      "grad_norm": 16.89133071899414,
      "learning_rate": 7.164887307236063e-06,
      "loss": 0.2458,
      "step": 604
    },
    {
      "epoch": 0.0358880056946257,
      "grad_norm": 16.47635841369629,
      "learning_rate": 7.176749703440096e-06,
      "loss": 0.0624,
      "step": 605
    },
    {
      "epoch": 0.03594732471230276,
      "grad_norm": 1.945164680480957,
      "learning_rate": 7.188612099644129e-06,
      "loss": 0.0127,
      "step": 606
    },
    {
      "epoch": 0.03600664372997983,
      "grad_norm": 21.27509307861328,
      "learning_rate": 7.200474495848162e-06,
      "loss": 0.5869,
      "step": 607
    },
    {
      "epoch": 0.0360659627476569,
      "grad_norm": 16.15771484375,
      "learning_rate": 7.212336892052195e-06,
      "loss": 0.6334,
      "step": 608
    },
    {
      "epoch": 0.036125281765333965,
      "grad_norm": 7.321718215942383,
      "learning_rate": 7.2241992882562285e-06,
      "loss": 0.1188,
      "step": 609
    },
    {
      "epoch": 0.036184600783011035,
      "grad_norm": 2.6607465744018555,
      "learning_rate": 7.236061684460261e-06,
      "loss": 0.0234,
      "step": 610
    },
    {
      "epoch": 0.0362439198006881,
      "grad_norm": 15.613584518432617,
      "learning_rate": 7.247924080664295e-06,
      "loss": 0.3484,
      "step": 611
    },
    {
      "epoch": 0.03630323881836517,
      "grad_norm": 34.32089614868164,
      "learning_rate": 7.259786476868328e-06,
      "loss": 0.5635,
      "step": 612
    },
    {
      "epoch": 0.03636255783604223,
      "grad_norm": 49.01021957397461,
      "learning_rate": 7.271648873072361e-06,
      "loss": 0.0736,
      "step": 613
    },
    {
      "epoch": 0.0364218768537193,
      "grad_norm": 2.1086905002593994,
      "learning_rate": 7.283511269276394e-06,
      "loss": 0.0108,
      "step": 614
    },
    {
      "epoch": 0.03648119587139637,
      "grad_norm": 10.799666404724121,
      "learning_rate": 7.295373665480427e-06,
      "loss": 0.0777,
      "step": 615
    },
    {
      "epoch": 0.036540514889073436,
      "grad_norm": 0.3843843638896942,
      "learning_rate": 7.307236061684461e-06,
      "loss": 0.0025,
      "step": 616
    },
    {
      "epoch": 0.036599833906750506,
      "grad_norm": 0.18714800477027893,
      "learning_rate": 7.319098457888494e-06,
      "loss": 0.0016,
      "step": 617
    },
    {
      "epoch": 0.03665915292442757,
      "grad_norm": 22.517414093017578,
      "learning_rate": 7.330960854092527e-06,
      "loss": 0.4379,
      "step": 618
    },
    {
      "epoch": 0.03671847194210464,
      "grad_norm": 69.37561798095703,
      "learning_rate": 7.34282325029656e-06,
      "loss": 2.7413,
      "step": 619
    },
    {
      "epoch": 0.0367777909597817,
      "grad_norm": 23.13831901550293,
      "learning_rate": 7.354685646500593e-06,
      "loss": 0.161,
      "step": 620
    },
    {
      "epoch": 0.03683710997745877,
      "grad_norm": 28.334495544433594,
      "learning_rate": 7.3665480427046265e-06,
      "loss": 0.3435,
      "step": 621
    },
    {
      "epoch": 0.036896428995135844,
      "grad_norm": 44.19321823120117,
      "learning_rate": 7.37841043890866e-06,
      "loss": 0.6866,
      "step": 622
    },
    {
      "epoch": 0.03695574801281291,
      "grad_norm": 1.45368492603302,
      "learning_rate": 7.390272835112693e-06,
      "loss": 0.0107,
      "step": 623
    },
    {
      "epoch": 0.03701506703048998,
      "grad_norm": 15.82340145111084,
      "learning_rate": 7.402135231316726e-06,
      "loss": 0.356,
      "step": 624
    },
    {
      "epoch": 0.03707438604816704,
      "grad_norm": 5.290409564971924,
      "learning_rate": 7.4139976275207606e-06,
      "loss": 0.0556,
      "step": 625
    },
    {
      "epoch": 0.03713370506584411,
      "grad_norm": 16.669511795043945,
      "learning_rate": 7.425860023724793e-06,
      "loss": 0.0421,
      "step": 626
    },
    {
      "epoch": 0.037193024083521174,
      "grad_norm": 38.86491775512695,
      "learning_rate": 7.437722419928827e-06,
      "loss": 0.5087,
      "step": 627
    },
    {
      "epoch": 0.037252343101198244,
      "grad_norm": 0.4353680908679962,
      "learning_rate": 7.44958481613286e-06,
      "loss": 0.0051,
      "step": 628
    },
    {
      "epoch": 0.037311662118875315,
      "grad_norm": 0.2570100426673889,
      "learning_rate": 7.461447212336893e-06,
      "loss": 0.0036,
      "step": 629
    },
    {
      "epoch": 0.03737098113655238,
      "grad_norm": 15.117358207702637,
      "learning_rate": 7.4733096085409265e-06,
      "loss": 0.311,
      "step": 630
    },
    {
      "epoch": 0.03743030015422945,
      "grad_norm": 10.541757583618164,
      "learning_rate": 7.485172004744959e-06,
      "loss": 0.0582,
      "step": 631
    },
    {
      "epoch": 0.03748961917190651,
      "grad_norm": 29.22658920288086,
      "learning_rate": 7.497034400948993e-06,
      "loss": 0.1824,
      "step": 632
    },
    {
      "epoch": 0.03754893818958358,
      "grad_norm": 106.69937896728516,
      "learning_rate": 7.508896797153026e-06,
      "loss": 1.04,
      "step": 633
    },
    {
      "epoch": 0.037608257207260645,
      "grad_norm": 124.40401458740234,
      "learning_rate": 7.520759193357059e-06,
      "loss": 2.7493,
      "step": 634
    },
    {
      "epoch": 0.037667576224937716,
      "grad_norm": 13.450066566467285,
      "learning_rate": 7.532621589561092e-06,
      "loss": 0.132,
      "step": 635
    },
    {
      "epoch": 0.03772689524261478,
      "grad_norm": 17.956396102905273,
      "learning_rate": 7.544483985765125e-06,
      "loss": 0.2659,
      "step": 636
    },
    {
      "epoch": 0.03778621426029185,
      "grad_norm": 27.713830947875977,
      "learning_rate": 7.5563463819691586e-06,
      "loss": 0.4564,
      "step": 637
    },
    {
      "epoch": 0.03784553327796892,
      "grad_norm": 0.6121253967285156,
      "learning_rate": 7.568208778173192e-06,
      "loss": 0.0049,
      "step": 638
    },
    {
      "epoch": 0.03790485229564598,
      "grad_norm": 8.77171802520752,
      "learning_rate": 7.580071174377225e-06,
      "loss": 0.0675,
      "step": 639
    },
    {
      "epoch": 0.03796417131332305,
      "grad_norm": 8.929503440856934,
      "learning_rate": 7.591933570581258e-06,
      "loss": 0.0399,
      "step": 640
    },
    {
      "epoch": 0.038023490331000116,
      "grad_norm": 3.237545967102051,
      "learning_rate": 7.603795966785291e-06,
      "loss": 0.0212,
      "step": 641
    },
    {
      "epoch": 0.03808280934867719,
      "grad_norm": 6.148073673248291,
      "learning_rate": 7.6156583629893245e-06,
      "loss": 0.0313,
      "step": 642
    },
    {
      "epoch": 0.03814212836635425,
      "grad_norm": 55.05499267578125,
      "learning_rate": 7.627520759193357e-06,
      "loss": 1.2853,
      "step": 643
    },
    {
      "epoch": 0.03820144738403132,
      "grad_norm": 25.3015079498291,
      "learning_rate": 7.639383155397391e-06,
      "loss": 0.3391,
      "step": 644
    },
    {
      "epoch": 0.03826076640170839,
      "grad_norm": 11.769736289978027,
      "learning_rate": 7.651245551601423e-06,
      "loss": 0.1808,
      "step": 645
    },
    {
      "epoch": 0.038320085419385454,
      "grad_norm": 6.463439464569092,
      "learning_rate": 7.663107947805457e-06,
      "loss": 0.0256,
      "step": 646
    },
    {
      "epoch": 0.038379404437062524,
      "grad_norm": 0.16575264930725098,
      "learning_rate": 7.67497034400949e-06,
      "loss": 0.0017,
      "step": 647
    },
    {
      "epoch": 0.03843872345473959,
      "grad_norm": 3.7176740169525146,
      "learning_rate": 7.686832740213524e-06,
      "loss": 0.0388,
      "step": 648
    },
    {
      "epoch": 0.03849804247241666,
      "grad_norm": 80.80826568603516,
      "learning_rate": 7.698695136417557e-06,
      "loss": 1.9867,
      "step": 649
    },
    {
      "epoch": 0.03855736149009372,
      "grad_norm": 0.8623340725898743,
      "learning_rate": 7.71055753262159e-06,
      "loss": 0.0043,
      "step": 650
    },
    {
      "epoch": 0.03861668050777079,
      "grad_norm": 11.536831855773926,
      "learning_rate": 7.722419928825623e-06,
      "loss": 0.1636,
      "step": 651
    },
    {
      "epoch": 0.03867599952544786,
      "grad_norm": 27.25775909423828,
      "learning_rate": 7.734282325029656e-06,
      "loss": 0.3095,
      "step": 652
    },
    {
      "epoch": 0.038735318543124925,
      "grad_norm": 41.42608642578125,
      "learning_rate": 7.74614472123369e-06,
      "loss": 0.2338,
      "step": 653
    },
    {
      "epoch": 0.038794637560801995,
      "grad_norm": 24.221435546875,
      "learning_rate": 7.758007117437723e-06,
      "loss": 0.1977,
      "step": 654
    },
    {
      "epoch": 0.03885395657847906,
      "grad_norm": 29.01109504699707,
      "learning_rate": 7.769869513641757e-06,
      "loss": 0.6873,
      "step": 655
    },
    {
      "epoch": 0.03891327559615613,
      "grad_norm": 40.28892135620117,
      "learning_rate": 7.78173190984579e-06,
      "loss": 0.3059,
      "step": 656
    },
    {
      "epoch": 0.03897259461383319,
      "grad_norm": 13.635993957519531,
      "learning_rate": 7.793594306049824e-06,
      "loss": 0.1361,
      "step": 657
    },
    {
      "epoch": 0.03903191363151026,
      "grad_norm": 11.890140533447266,
      "learning_rate": 7.805456702253856e-06,
      "loss": 0.046,
      "step": 658
    },
    {
      "epoch": 0.03909123264918733,
      "grad_norm": 0.34017428755760193,
      "learning_rate": 7.81731909845789e-06,
      "loss": 0.0053,
      "step": 659
    },
    {
      "epoch": 0.039150551666864396,
      "grad_norm": 13.004120826721191,
      "learning_rate": 7.829181494661923e-06,
      "loss": 0.0944,
      "step": 660
    },
    {
      "epoch": 0.039209870684541466,
      "grad_norm": 48.25987243652344,
      "learning_rate": 7.841043890865956e-06,
      "loss": 1.1219,
      "step": 661
    },
    {
      "epoch": 0.03926918970221853,
      "grad_norm": 4.135448932647705,
      "learning_rate": 7.85290628706999e-06,
      "loss": 0.0325,
      "step": 662
    },
    {
      "epoch": 0.0393285087198956,
      "grad_norm": 30.09149169921875,
      "learning_rate": 7.864768683274022e-06,
      "loss": 0.376,
      "step": 663
    },
    {
      "epoch": 0.03938782773757266,
      "grad_norm": 5.216513156890869,
      "learning_rate": 7.876631079478055e-06,
      "loss": 0.0984,
      "step": 664
    },
    {
      "epoch": 0.03944714675524973,
      "grad_norm": 31.890317916870117,
      "learning_rate": 7.888493475682089e-06,
      "loss": 0.6261,
      "step": 665
    },
    {
      "epoch": 0.0395064657729268,
      "grad_norm": 5.630151271820068,
      "learning_rate": 7.900355871886122e-06,
      "loss": 0.0415,
      "step": 666
    },
    {
      "epoch": 0.03956578479060387,
      "grad_norm": 7.972771644592285,
      "learning_rate": 7.912218268090156e-06,
      "loss": 0.041,
      "step": 667
    },
    {
      "epoch": 0.03962510380828094,
      "grad_norm": 10.900495529174805,
      "learning_rate": 7.924080664294187e-06,
      "loss": 0.0971,
      "step": 668
    },
    {
      "epoch": 0.039684422825958,
      "grad_norm": 3.5389742851257324,
      "learning_rate": 7.935943060498221e-06,
      "loss": 0.0315,
      "step": 669
    },
    {
      "epoch": 0.03974374184363507,
      "grad_norm": 3.237287759780884,
      "learning_rate": 7.947805456702255e-06,
      "loss": 0.0276,
      "step": 670
    },
    {
      "epoch": 0.039803060861312134,
      "grad_norm": 12.628244400024414,
      "learning_rate": 7.959667852906288e-06,
      "loss": 0.0406,
      "step": 671
    },
    {
      "epoch": 0.039862379878989204,
      "grad_norm": 3.7026195526123047,
      "learning_rate": 7.971530249110322e-06,
      "loss": 0.0224,
      "step": 672
    },
    {
      "epoch": 0.039921698896666274,
      "grad_norm": 27.74074935913086,
      "learning_rate": 7.983392645314353e-06,
      "loss": 0.42,
      "step": 673
    },
    {
      "epoch": 0.03998101791434334,
      "grad_norm": 12.265288352966309,
      "learning_rate": 7.995255041518387e-06,
      "loss": 0.0881,
      "step": 674
    },
    {
      "epoch": 0.04004033693202041,
      "grad_norm": 9.398446083068848,
      "learning_rate": 8.00711743772242e-06,
      "loss": 0.0708,
      "step": 675
    },
    {
      "epoch": 0.04009965594969747,
      "grad_norm": 4.8679280281066895,
      "learning_rate": 8.018979833926454e-06,
      "loss": 0.0495,
      "step": 676
    },
    {
      "epoch": 0.04015897496737454,
      "grad_norm": 241.45542907714844,
      "learning_rate": 8.030842230130487e-06,
      "loss": 1.5581,
      "step": 677
    },
    {
      "epoch": 0.040218293985051605,
      "grad_norm": 42.05617904663086,
      "learning_rate": 8.04270462633452e-06,
      "loss": 0.3672,
      "step": 678
    },
    {
      "epoch": 0.040277613002728675,
      "grad_norm": 8.976506233215332,
      "learning_rate": 8.054567022538553e-06,
      "loss": 0.0688,
      "step": 679
    },
    {
      "epoch": 0.040336932020405745,
      "grad_norm": 2.501288414001465,
      "learning_rate": 8.066429418742586e-06,
      "loss": 0.0187,
      "step": 680
    },
    {
      "epoch": 0.04039625103808281,
      "grad_norm": 3.9058713912963867,
      "learning_rate": 8.07829181494662e-06,
      "loss": 0.0313,
      "step": 681
    },
    {
      "epoch": 0.04045557005575988,
      "grad_norm": 1.798220157623291,
      "learning_rate": 8.090154211150653e-06,
      "loss": 0.013,
      "step": 682
    },
    {
      "epoch": 0.04051488907343694,
      "grad_norm": 24.623504638671875,
      "learning_rate": 8.102016607354685e-06,
      "loss": 0.1378,
      "step": 683
    },
    {
      "epoch": 0.04057420809111401,
      "grad_norm": 70.70077514648438,
      "learning_rate": 8.11387900355872e-06,
      "loss": 0.502,
      "step": 684
    },
    {
      "epoch": 0.040633527108791076,
      "grad_norm": 42.39970016479492,
      "learning_rate": 8.125741399762754e-06,
      "loss": 0.2395,
      "step": 685
    },
    {
      "epoch": 0.040692846126468146,
      "grad_norm": 0.3163612186908722,
      "learning_rate": 8.137603795966786e-06,
      "loss": 0.0031,
      "step": 686
    },
    {
      "epoch": 0.04075216514414521,
      "grad_norm": 1.7792351245880127,
      "learning_rate": 8.14946619217082e-06,
      "loss": 0.0068,
      "step": 687
    },
    {
      "epoch": 0.04081148416182228,
      "grad_norm": 10.890973091125488,
      "learning_rate": 8.161328588374853e-06,
      "loss": 0.118,
      "step": 688
    },
    {
      "epoch": 0.04087080317949935,
      "grad_norm": 8.056952476501465,
      "learning_rate": 8.173190984578886e-06,
      "loss": 0.0153,
      "step": 689
    },
    {
      "epoch": 0.04093012219717641,
      "grad_norm": 31.073698043823242,
      "learning_rate": 8.18505338078292e-06,
      "loss": 1.0099,
      "step": 690
    },
    {
      "epoch": 0.040989441214853484,
      "grad_norm": 36.81930160522461,
      "learning_rate": 8.196915776986952e-06,
      "loss": 1.003,
      "step": 691
    },
    {
      "epoch": 0.04104876023253055,
      "grad_norm": 3.0140466690063477,
      "learning_rate": 8.208778173190985e-06,
      "loss": 0.0196,
      "step": 692
    },
    {
      "epoch": 0.04110807925020762,
      "grad_norm": 0.6654105186462402,
      "learning_rate": 8.220640569395019e-06,
      "loss": 0.0032,
      "step": 693
    },
    {
      "epoch": 0.04116739826788468,
      "grad_norm": 42.92753601074219,
      "learning_rate": 8.232502965599052e-06,
      "loss": 0.8502,
      "step": 694
    },
    {
      "epoch": 0.04122671728556175,
      "grad_norm": 4.848782062530518,
      "learning_rate": 8.244365361803086e-06,
      "loss": 0.0213,
      "step": 695
    },
    {
      "epoch": 0.04128603630323882,
      "grad_norm": 19.889726638793945,
      "learning_rate": 8.256227758007118e-06,
      "loss": 0.0828,
      "step": 696
    },
    {
      "epoch": 0.041345355320915884,
      "grad_norm": 84.79753112792969,
      "learning_rate": 8.268090154211151e-06,
      "loss": 0.8874,
      "step": 697
    },
    {
      "epoch": 0.041404674338592955,
      "grad_norm": 5.100963115692139,
      "learning_rate": 8.279952550415185e-06,
      "loss": 0.0421,
      "step": 698
    },
    {
      "epoch": 0.04146399335627002,
      "grad_norm": 14.32669734954834,
      "learning_rate": 8.291814946619218e-06,
      "loss": 0.4117,
      "step": 699
    },
    {
      "epoch": 0.04152331237394709,
      "grad_norm": 20.12917137145996,
      "learning_rate": 8.303677342823252e-06,
      "loss": 0.1961,
      "step": 700
    },
    {
      "epoch": 0.04158263139162415,
      "grad_norm": 18.835294723510742,
      "learning_rate": 8.315539739027283e-06,
      "loss": 0.4809,
      "step": 701
    },
    {
      "epoch": 0.04164195040930122,
      "grad_norm": 0.2161027491092682,
      "learning_rate": 8.327402135231317e-06,
      "loss": 0.0029,
      "step": 702
    },
    {
      "epoch": 0.04170126942697829,
      "grad_norm": 8.784311294555664,
      "learning_rate": 8.33926453143535e-06,
      "loss": 0.0101,
      "step": 703
    },
    {
      "epoch": 0.041760588444655355,
      "grad_norm": 24.180673599243164,
      "learning_rate": 8.351126927639384e-06,
      "loss": 1.0418,
      "step": 704
    },
    {
      "epoch": 0.041819907462332426,
      "grad_norm": 5.245011806488037,
      "learning_rate": 8.362989323843418e-06,
      "loss": 0.0293,
      "step": 705
    },
    {
      "epoch": 0.04187922648000949,
      "grad_norm": 52.665382385253906,
      "learning_rate": 8.37485172004745e-06,
      "loss": 1.6497,
      "step": 706
    },
    {
      "epoch": 0.04193854549768656,
      "grad_norm": 0.3399477005004883,
      "learning_rate": 8.386714116251483e-06,
      "loss": 0.0034,
      "step": 707
    },
    {
      "epoch": 0.04199786451536362,
      "grad_norm": 4.636553764343262,
      "learning_rate": 8.398576512455516e-06,
      "loss": 0.0229,
      "step": 708
    },
    {
      "epoch": 0.04205718353304069,
      "grad_norm": 39.8346061706543,
      "learning_rate": 8.41043890865955e-06,
      "loss": 2.6167,
      "step": 709
    },
    {
      "epoch": 0.04211650255071776,
      "grad_norm": 33.05677795410156,
      "learning_rate": 8.422301304863583e-06,
      "loss": 0.2782,
      "step": 710
    },
    {
      "epoch": 0.042175821568394826,
      "grad_norm": 0.8372069597244263,
      "learning_rate": 8.434163701067615e-06,
      "loss": 0.0072,
      "step": 711
    },
    {
      "epoch": 0.0422351405860719,
      "grad_norm": 23.25339698791504,
      "learning_rate": 8.446026097271649e-06,
      "loss": 0.743,
      "step": 712
    },
    {
      "epoch": 0.04229445960374896,
      "grad_norm": 5.428773403167725,
      "learning_rate": 8.457888493475684e-06,
      "loss": 0.0833,
      "step": 713
    },
    {
      "epoch": 0.04235377862142603,
      "grad_norm": 30.969778060913086,
      "learning_rate": 8.469750889679716e-06,
      "loss": 0.776,
      "step": 714
    },
    {
      "epoch": 0.042413097639103094,
      "grad_norm": 27.32459831237793,
      "learning_rate": 8.48161328588375e-06,
      "loss": 0.2691,
      "step": 715
    },
    {
      "epoch": 0.042472416656780164,
      "grad_norm": 19.78827667236328,
      "learning_rate": 8.493475682087783e-06,
      "loss": 0.1584,
      "step": 716
    },
    {
      "epoch": 0.042531735674457234,
      "grad_norm": 9.620295524597168,
      "learning_rate": 8.505338078291816e-06,
      "loss": 1.2862,
      "step": 717
    },
    {
      "epoch": 0.0425910546921343,
      "grad_norm": 30.16031265258789,
      "learning_rate": 8.51720047449585e-06,
      "loss": 0.1809,
      "step": 718
    },
    {
      "epoch": 0.04265037370981137,
      "grad_norm": 0.49280041456222534,
      "learning_rate": 8.529062870699882e-06,
      "loss": 0.0037,
      "step": 719
    },
    {
      "epoch": 0.04270969272748843,
      "grad_norm": 15.601734161376953,
      "learning_rate": 8.540925266903915e-06,
      "loss": 0.4419,
      "step": 720
    },
    {
      "epoch": 0.0427690117451655,
      "grad_norm": 0.2725735902786255,
      "learning_rate": 8.552787663107949e-06,
      "loss": 0.004,
      "step": 721
    },
    {
      "epoch": 0.042828330762842565,
      "grad_norm": 7.299377918243408,
      "learning_rate": 8.564650059311982e-06,
      "loss": 0.072,
      "step": 722
    },
    {
      "epoch": 0.042887649780519635,
      "grad_norm": 133.84869384765625,
      "learning_rate": 8.576512455516016e-06,
      "loss": 0.1614,
      "step": 723
    },
    {
      "epoch": 0.042946968798196705,
      "grad_norm": 23.382909774780273,
      "learning_rate": 8.588374851720048e-06,
      "loss": 0.0456,
      "step": 724
    },
    {
      "epoch": 0.04300628781587377,
      "grad_norm": 21.97574234008789,
      "learning_rate": 8.600237247924081e-06,
      "loss": 0.0504,
      "step": 725
    },
    {
      "epoch": 0.04306560683355084,
      "grad_norm": 25.026670455932617,
      "learning_rate": 8.612099644128115e-06,
      "loss": 1.0046,
      "step": 726
    },
    {
      "epoch": 0.0431249258512279,
      "grad_norm": 0.6980884075164795,
      "learning_rate": 8.623962040332148e-06,
      "loss": 0.0023,
      "step": 727
    },
    {
      "epoch": 0.04318424486890497,
      "grad_norm": 34.39231872558594,
      "learning_rate": 8.635824436536182e-06,
      "loss": 0.1498,
      "step": 728
    },
    {
      "epoch": 0.043243563886582036,
      "grad_norm": 5.918300151824951,
      "learning_rate": 8.647686832740214e-06,
      "loss": 0.042,
      "step": 729
    },
    {
      "epoch": 0.043302882904259106,
      "grad_norm": 0.7783824801445007,
      "learning_rate": 8.659549228944247e-06,
      "loss": 0.0051,
      "step": 730
    },
    {
      "epoch": 0.04336220192193617,
      "grad_norm": 20.845651626586914,
      "learning_rate": 8.67141162514828e-06,
      "loss": 0.1943,
      "step": 731
    },
    {
      "epoch": 0.04342152093961324,
      "grad_norm": 2.902158737182617,
      "learning_rate": 8.683274021352314e-06,
      "loss": 0.0203,
      "step": 732
    },
    {
      "epoch": 0.04348083995729031,
      "grad_norm": 21.435888290405273,
      "learning_rate": 8.695136417556348e-06,
      "loss": 0.4202,
      "step": 733
    },
    {
      "epoch": 0.04354015897496737,
      "grad_norm": 24.025035858154297,
      "learning_rate": 8.70699881376038e-06,
      "loss": 1.2793,
      "step": 734
    },
    {
      "epoch": 0.04359947799264444,
      "grad_norm": 80.78585052490234,
      "learning_rate": 8.718861209964413e-06,
      "loss": 0.4517,
      "step": 735
    },
    {
      "epoch": 0.04365879701032151,
      "grad_norm": 12.758453369140625,
      "learning_rate": 8.730723606168446e-06,
      "loss": 0.0628,
      "step": 736
    },
    {
      "epoch": 0.04371811602799858,
      "grad_norm": 19.541767120361328,
      "learning_rate": 8.74258600237248e-06,
      "loss": 0.1875,
      "step": 737
    },
    {
      "epoch": 0.04377743504567564,
      "grad_norm": 13.864410400390625,
      "learning_rate": 8.754448398576513e-06,
      "loss": 0.0821,
      "step": 738
    },
    {
      "epoch": 0.04383675406335271,
      "grad_norm": 40.70596694946289,
      "learning_rate": 8.766310794780545e-06,
      "loss": 1.3377,
      "step": 739
    },
    {
      "epoch": 0.04389607308102978,
      "grad_norm": 29.64586639404297,
      "learning_rate": 8.778173190984579e-06,
      "loss": 0.4093,
      "step": 740
    },
    {
      "epoch": 0.043955392098706844,
      "grad_norm": 18.975603103637695,
      "learning_rate": 8.790035587188612e-06,
      "loss": 0.4944,
      "step": 741
    },
    {
      "epoch": 0.044014711116383914,
      "grad_norm": 54.60427474975586,
      "learning_rate": 8.801897983392646e-06,
      "loss": 0.2447,
      "step": 742
    },
    {
      "epoch": 0.04407403013406098,
      "grad_norm": 61.67592239379883,
      "learning_rate": 8.81376037959668e-06,
      "loss": 1.0987,
      "step": 743
    },
    {
      "epoch": 0.04413334915173805,
      "grad_norm": 25.218774795532227,
      "learning_rate": 8.825622775800713e-06,
      "loss": 0.1724,
      "step": 744
    },
    {
      "epoch": 0.04419266816941511,
      "grad_norm": 49.26459503173828,
      "learning_rate": 8.837485172004746e-06,
      "loss": 1.4766,
      "step": 745
    },
    {
      "epoch": 0.04425198718709218,
      "grad_norm": 24.970417022705078,
      "learning_rate": 8.84934756820878e-06,
      "loss": 0.1768,
      "step": 746
    },
    {
      "epoch": 0.04431130620476925,
      "grad_norm": 51.5588264465332,
      "learning_rate": 8.861209964412812e-06,
      "loss": 1.0591,
      "step": 747
    },
    {
      "epoch": 0.044370625222446315,
      "grad_norm": 27.942705154418945,
      "learning_rate": 8.873072360616845e-06,
      "loss": 0.4986,
      "step": 748
    },
    {
      "epoch": 0.044429944240123385,
      "grad_norm": 62.245338439941406,
      "learning_rate": 8.884934756820879e-06,
      "loss": 0.8757,
      "step": 749
    },
    {
      "epoch": 0.04448926325780045,
      "grad_norm": 20.391864776611328,
      "learning_rate": 8.896797153024912e-06,
      "loss": 0.1296,
      "step": 750
    },
    {
      "epoch": 0.04454858227547752,
      "grad_norm": 9.212031364440918,
      "learning_rate": 8.908659549228946e-06,
      "loss": 0.0832,
      "step": 751
    },
    {
      "epoch": 0.04460790129315458,
      "grad_norm": 39.5468635559082,
      "learning_rate": 8.920521945432978e-06,
      "loss": 0.0413,
      "step": 752
    },
    {
      "epoch": 0.04466722031083165,
      "grad_norm": 26.318767547607422,
      "learning_rate": 8.932384341637011e-06,
      "loss": 0.3616,
      "step": 753
    },
    {
      "epoch": 0.04472653932850872,
      "grad_norm": 1.3068032264709473,
      "learning_rate": 8.944246737841045e-06,
      "loss": 0.0101,
      "step": 754
    },
    {
      "epoch": 0.044785858346185786,
      "grad_norm": 7.105989456176758,
      "learning_rate": 8.956109134045078e-06,
      "loss": 0.0251,
      "step": 755
    },
    {
      "epoch": 0.044845177363862856,
      "grad_norm": 23.823932647705078,
      "learning_rate": 8.967971530249112e-06,
      "loss": 0.4416,
      "step": 756
    },
    {
      "epoch": 0.04490449638153992,
      "grad_norm": 22.42474365234375,
      "learning_rate": 8.979833926453144e-06,
      "loss": 0.1435,
      "step": 757
    },
    {
      "epoch": 0.04496381539921699,
      "grad_norm": 25.977075576782227,
      "learning_rate": 8.991696322657177e-06,
      "loss": 0.0796,
      "step": 758
    },
    {
      "epoch": 0.04502313441689405,
      "grad_norm": 33.07231140136719,
      "learning_rate": 9.00355871886121e-06,
      "loss": 0.1721,
      "step": 759
    },
    {
      "epoch": 0.045082453434571124,
      "grad_norm": 36.801856994628906,
      "learning_rate": 9.015421115065244e-06,
      "loss": 0.2849,
      "step": 760
    },
    {
      "epoch": 0.045141772452248194,
      "grad_norm": 14.680794715881348,
      "learning_rate": 9.027283511269278e-06,
      "loss": 0.11,
      "step": 761
    },
    {
      "epoch": 0.04520109146992526,
      "grad_norm": 33.11042022705078,
      "learning_rate": 9.03914590747331e-06,
      "loss": 1.3755,
      "step": 762
    },
    {
      "epoch": 0.04526041048760233,
      "grad_norm": 14.911454200744629,
      "learning_rate": 9.051008303677343e-06,
      "loss": 0.1171,
      "step": 763
    },
    {
      "epoch": 0.04531972950527939,
      "grad_norm": 307.574462890625,
      "learning_rate": 9.062870699881377e-06,
      "loss": 0.5444,
      "step": 764
    },
    {
      "epoch": 0.04537904852295646,
      "grad_norm": 25.81522560119629,
      "learning_rate": 9.07473309608541e-06,
      "loss": 0.1124,
      "step": 765
    },
    {
      "epoch": 0.045438367540633524,
      "grad_norm": 49.93372344970703,
      "learning_rate": 9.086595492289444e-06,
      "loss": 0.6058,
      "step": 766
    },
    {
      "epoch": 0.045497686558310595,
      "grad_norm": 28.964420318603516,
      "learning_rate": 9.098457888493475e-06,
      "loss": 0.0772,
      "step": 767
    },
    {
      "epoch": 0.045557005575987665,
      "grad_norm": 3.2547757625579834,
      "learning_rate": 9.110320284697509e-06,
      "loss": 0.0304,
      "step": 768
    },
    {
      "epoch": 0.04561632459366473,
      "grad_norm": 21.786407470703125,
      "learning_rate": 9.122182680901542e-06,
      "loss": 0.2354,
      "step": 769
    },
    {
      "epoch": 0.0456756436113418,
      "grad_norm": 24.739620208740234,
      "learning_rate": 9.134045077105576e-06,
      "loss": 0.2956,
      "step": 770
    },
    {
      "epoch": 0.04573496262901886,
      "grad_norm": 11.691837310791016,
      "learning_rate": 9.14590747330961e-06,
      "loss": 0.2249,
      "step": 771
    },
    {
      "epoch": 0.04579428164669593,
      "grad_norm": 0.6380642056465149,
      "learning_rate": 9.157769869513643e-06,
      "loss": 0.0044,
      "step": 772
    },
    {
      "epoch": 0.045853600664372995,
      "grad_norm": 76.87090301513672,
      "learning_rate": 9.169632265717677e-06,
      "loss": 1.4134,
      "step": 773
    },
    {
      "epoch": 0.045912919682050066,
      "grad_norm": 68.49305725097656,
      "learning_rate": 9.18149466192171e-06,
      "loss": 0.2335,
      "step": 774
    },
    {
      "epoch": 0.045972238699727136,
      "grad_norm": 17.85025405883789,
      "learning_rate": 9.193357058125742e-06,
      "loss": 0.1013,
      "step": 775
    },
    {
      "epoch": 0.0460315577174042,
      "grad_norm": 1.6760845184326172,
      "learning_rate": 9.205219454329775e-06,
      "loss": 0.0221,
      "step": 776
    },
    {
      "epoch": 0.04609087673508127,
      "grad_norm": 2.498687744140625,
      "learning_rate": 9.217081850533809e-06,
      "loss": 0.016,
      "step": 777
    },
    {
      "epoch": 0.04615019575275833,
      "grad_norm": 0.5918596386909485,
      "learning_rate": 9.228944246737842e-06,
      "loss": 0.0066,
      "step": 778
    },
    {
      "epoch": 0.0462095147704354,
      "grad_norm": 22.599138259887695,
      "learning_rate": 9.240806642941876e-06,
      "loss": 0.5691,
      "step": 779
    },
    {
      "epoch": 0.046268833788112466,
      "grad_norm": 3.529221296310425,
      "learning_rate": 9.252669039145908e-06,
      "loss": 0.0456,
      "step": 780
    },
    {
      "epoch": 0.04632815280578954,
      "grad_norm": 45.79658889770508,
      "learning_rate": 9.264531435349941e-06,
      "loss": 1.0673,
      "step": 781
    },
    {
      "epoch": 0.0463874718234666,
      "grad_norm": 5.142307758331299,
      "learning_rate": 9.276393831553975e-06,
      "loss": 0.0251,
      "step": 782
    },
    {
      "epoch": 0.04644679084114367,
      "grad_norm": 0.4891352355480194,
      "learning_rate": 9.288256227758008e-06,
      "loss": 0.0031,
      "step": 783
    },
    {
      "epoch": 0.04650610985882074,
      "grad_norm": 5.78629207611084,
      "learning_rate": 9.300118623962042e-06,
      "loss": 0.0809,
      "step": 784
    },
    {
      "epoch": 0.046565428876497804,
      "grad_norm": 10.061049461364746,
      "learning_rate": 9.311981020166074e-06,
      "loss": 0.1097,
      "step": 785
    },
    {
      "epoch": 0.046624747894174874,
      "grad_norm": 21.80876922607422,
      "learning_rate": 9.323843416370107e-06,
      "loss": 1.0082,
      "step": 786
    },
    {
      "epoch": 0.04668406691185194,
      "grad_norm": 2.6491408348083496,
      "learning_rate": 9.33570581257414e-06,
      "loss": 0.0195,
      "step": 787
    },
    {
      "epoch": 0.04674338592952901,
      "grad_norm": 33.79179382324219,
      "learning_rate": 9.347568208778174e-06,
      "loss": 0.2097,
      "step": 788
    },
    {
      "epoch": 0.04680270494720607,
      "grad_norm": 11.839632034301758,
      "learning_rate": 9.359430604982208e-06,
      "loss": 0.2663,
      "step": 789
    },
    {
      "epoch": 0.04686202396488314,
      "grad_norm": 45.06708908081055,
      "learning_rate": 9.37129300118624e-06,
      "loss": 0.9288,
      "step": 790
    },
    {
      "epoch": 0.04692134298256021,
      "grad_norm": 14.91472339630127,
      "learning_rate": 9.383155397390273e-06,
      "loss": 0.0745,
      "step": 791
    },
    {
      "epoch": 0.046980662000237275,
      "grad_norm": 0.5310548543930054,
      "learning_rate": 9.395017793594307e-06,
      "loss": 0.0048,
      "step": 792
    },
    {
      "epoch": 0.047039981017914345,
      "grad_norm": 8.152522087097168,
      "learning_rate": 9.40688018979834e-06,
      "loss": 0.06,
      "step": 793
    },
    {
      "epoch": 0.04709930003559141,
      "grad_norm": 16.505725860595703,
      "learning_rate": 9.418742586002374e-06,
      "loss": 0.0513,
      "step": 794
    },
    {
      "epoch": 0.04715861905326848,
      "grad_norm": 2.7966485023498535,
      "learning_rate": 9.430604982206405e-06,
      "loss": 0.0192,
      "step": 795
    },
    {
      "epoch": 0.04721793807094554,
      "grad_norm": 29.612550735473633,
      "learning_rate": 9.442467378410439e-06,
      "loss": 0.0808,
      "step": 796
    },
    {
      "epoch": 0.04727725708862261,
      "grad_norm": 27.459535598754883,
      "learning_rate": 9.454329774614472e-06,
      "loss": 0.3538,
      "step": 797
    },
    {
      "epoch": 0.04733657610629968,
      "grad_norm": 24.624967575073242,
      "learning_rate": 9.466192170818506e-06,
      "loss": 0.4023,
      "step": 798
    },
    {
      "epoch": 0.047395895123976746,
      "grad_norm": 6.4704179763793945,
      "learning_rate": 9.47805456702254e-06,
      "loss": 0.0382,
      "step": 799
    },
    {
      "epoch": 0.047455214141653816,
      "grad_norm": 24.134374618530273,
      "learning_rate": 9.489916963226573e-06,
      "loss": 0.05,
      "step": 800
    },
    {
      "epoch": 0.04751453315933088,
      "grad_norm": 110.41009521484375,
      "learning_rate": 9.501779359430607e-06,
      "loss": 0.659,
      "step": 801
    },
    {
      "epoch": 0.04757385217700795,
      "grad_norm": 28.885698318481445,
      "learning_rate": 9.51364175563464e-06,
      "loss": 2.0588,
      "step": 802
    },
    {
      "epoch": 0.04763317119468501,
      "grad_norm": 10.667218208312988,
      "learning_rate": 9.525504151838672e-06,
      "loss": 0.2735,
      "step": 803
    },
    {
      "epoch": 0.04769249021236208,
      "grad_norm": 11.483024597167969,
      "learning_rate": 9.537366548042705e-06,
      "loss": 0.0574,
      "step": 804
    },
    {
      "epoch": 0.047751809230039154,
      "grad_norm": 35.85350036621094,
      "learning_rate": 9.549228944246739e-06,
      "loss": 0.388,
      "step": 805
    },
    {
      "epoch": 0.04781112824771622,
      "grad_norm": 13.471258163452148,
      "learning_rate": 9.561091340450772e-06,
      "loss": 0.0405,
      "step": 806
    },
    {
      "epoch": 0.04787044726539329,
      "grad_norm": 17.730636596679688,
      "learning_rate": 9.572953736654806e-06,
      "loss": 0.2056,
      "step": 807
    },
    {
      "epoch": 0.04792976628307035,
      "grad_norm": 2.3427841663360596,
      "learning_rate": 9.584816132858838e-06,
      "loss": 0.0088,
      "step": 808
    },
    {
      "epoch": 0.04798908530074742,
      "grad_norm": 8.981420516967773,
      "learning_rate": 9.596678529062871e-06,
      "loss": 0.1786,
      "step": 809
    },
    {
      "epoch": 0.048048404318424484,
      "grad_norm": 1.7298816442489624,
      "learning_rate": 9.608540925266905e-06,
      "loss": 0.0094,
      "step": 810
    },
    {
      "epoch": 0.048107723336101554,
      "grad_norm": 8.489082336425781,
      "learning_rate": 9.620403321470938e-06,
      "loss": 0.6462,
      "step": 811
    },
    {
      "epoch": 0.048167042353778625,
      "grad_norm": 0.3342575430870056,
      "learning_rate": 9.632265717674972e-06,
      "loss": 0.0025,
      "step": 812
    },
    {
      "epoch": 0.04822636137145569,
      "grad_norm": 17.98828125,
      "learning_rate": 9.644128113879004e-06,
      "loss": 0.4819,
      "step": 813
    },
    {
      "epoch": 0.04828568038913276,
      "grad_norm": 17.288305282592773,
      "learning_rate": 9.655990510083037e-06,
      "loss": 0.1618,
      "step": 814
    },
    {
      "epoch": 0.04834499940680982,
      "grad_norm": 0.07694462686777115,
      "learning_rate": 9.66785290628707e-06,
      "loss": 0.0007,
      "step": 815
    },
    {
      "epoch": 0.04840431842448689,
      "grad_norm": 20.668710708618164,
      "learning_rate": 9.679715302491104e-06,
      "loss": 0.1436,
      "step": 816
    },
    {
      "epoch": 0.048463637442163955,
      "grad_norm": 1.3192903995513916,
      "learning_rate": 9.691577698695138e-06,
      "loss": 0.0042,
      "step": 817
    },
    {
      "epoch": 0.048522956459841025,
      "grad_norm": 10.429515838623047,
      "learning_rate": 9.70344009489917e-06,
      "loss": 0.0257,
      "step": 818
    },
    {
      "epoch": 0.048582275477518096,
      "grad_norm": 0.5979418158531189,
      "learning_rate": 9.715302491103203e-06,
      "loss": 0.006,
      "step": 819
    },
    {
      "epoch": 0.04864159449519516,
      "grad_norm": 10.240522384643555,
      "learning_rate": 9.727164887307237e-06,
      "loss": 0.0314,
      "step": 820
    },
    {
      "epoch": 0.04870091351287223,
      "grad_norm": 19.857187271118164,
      "learning_rate": 9.73902728351127e-06,
      "loss": 0.1498,
      "step": 821
    },
    {
      "epoch": 0.04876023253054929,
      "grad_norm": 6.680696487426758,
      "learning_rate": 9.750889679715304e-06,
      "loss": 0.0218,
      "step": 822
    },
    {
      "epoch": 0.04881955154822636,
      "grad_norm": 17.226591110229492,
      "learning_rate": 9.762752075919336e-06,
      "loss": 0.6234,
      "step": 823
    },
    {
      "epoch": 0.048878870565903426,
      "grad_norm": 19.541484832763672,
      "learning_rate": 9.774614472123369e-06,
      "loss": 0.1609,
      "step": 824
    },
    {
      "epoch": 0.048938189583580496,
      "grad_norm": 46.395599365234375,
      "learning_rate": 9.786476868327403e-06,
      "loss": 0.2078,
      "step": 825
    },
    {
      "epoch": 0.04899750860125756,
      "grad_norm": 24.150651931762695,
      "learning_rate": 9.798339264531436e-06,
      "loss": 0.1417,
      "step": 826
    },
    {
      "epoch": 0.04905682761893463,
      "grad_norm": 0.1326362043619156,
      "learning_rate": 9.81020166073547e-06,
      "loss": 0.0023,
      "step": 827
    },
    {
      "epoch": 0.0491161466366117,
      "grad_norm": 76.5613784790039,
      "learning_rate": 9.822064056939501e-06,
      "loss": 0.5314,
      "step": 828
    },
    {
      "epoch": 0.049175465654288764,
      "grad_norm": 8.506689071655273,
      "learning_rate": 9.833926453143537e-06,
      "loss": 0.0464,
      "step": 829
    },
    {
      "epoch": 0.049234784671965834,
      "grad_norm": 22.201995849609375,
      "learning_rate": 9.84578884934757e-06,
      "loss": 0.4057,
      "step": 830
    },
    {
      "epoch": 0.0492941036896429,
      "grad_norm": 0.27395954728126526,
      "learning_rate": 9.857651245551602e-06,
      "loss": 0.0017,
      "step": 831
    },
    {
      "epoch": 0.04935342270731997,
      "grad_norm": 9.031987190246582,
      "learning_rate": 9.869513641755635e-06,
      "loss": 0.2443,
      "step": 832
    },
    {
      "epoch": 0.04941274172499703,
      "grad_norm": 1.484173059463501,
      "learning_rate": 9.881376037959669e-06,
      "loss": 0.0126,
      "step": 833
    },
    {
      "epoch": 0.0494720607426741,
      "grad_norm": 0.5021127462387085,
      "learning_rate": 9.893238434163703e-06,
      "loss": 0.0076,
      "step": 834
    },
    {
      "epoch": 0.04953137976035117,
      "grad_norm": 23.8610897064209,
      "learning_rate": 9.905100830367736e-06,
      "loss": 0.0769,
      "step": 835
    },
    {
      "epoch": 0.049590698778028235,
      "grad_norm": 4.6731414794921875,
      "learning_rate": 9.916963226571768e-06,
      "loss": 0.0846,
      "step": 836
    },
    {
      "epoch": 0.049650017795705305,
      "grad_norm": 1.5037034749984741,
      "learning_rate": 9.928825622775801e-06,
      "loss": 0.0124,
      "step": 837
    },
    {
      "epoch": 0.04970933681338237,
      "grad_norm": 18.679290771484375,
      "learning_rate": 9.940688018979835e-06,
      "loss": 0.0771,
      "step": 838
    },
    {
      "epoch": 0.04976865583105944,
      "grad_norm": 18.829063415527344,
      "learning_rate": 9.952550415183868e-06,
      "loss": 0.4064,
      "step": 839
    },
    {
      "epoch": 0.0498279748487365,
      "grad_norm": 3.988823175430298,
      "learning_rate": 9.964412811387902e-06,
      "loss": 0.0251,
      "step": 840
    },
    {
      "epoch": 0.04988729386641357,
      "grad_norm": 0.3949398994445801,
      "learning_rate": 9.976275207591934e-06,
      "loss": 0.0038,
      "step": 841
    },
    {
      "epoch": 0.04994661288409064,
      "grad_norm": 6.787082195281982,
      "learning_rate": 9.988137603795967e-06,
      "loss": 0.0404,
      "step": 842
    },
    {
      "epoch": 0.050005931901767706,
      "grad_norm": 30.504274368286133,
      "learning_rate": 1e-05,
      "loss": 0.4323,
      "step": 843
    },
    {
      "epoch": 0.050065250919444776,
      "grad_norm": 15.882794380187988,
      "learning_rate": 1.0011862396204034e-05,
      "loss": 0.3883,
      "step": 844
    },
    {
      "epoch": 0.05012456993712184,
      "grad_norm": 23.94886016845703,
      "learning_rate": 1.0023724792408068e-05,
      "loss": 0.4492,
      "step": 845
    },
    {
      "epoch": 0.05018388895479891,
      "grad_norm": 3.9921133518218994,
      "learning_rate": 1.0035587188612101e-05,
      "loss": 0.0327,
      "step": 846
    },
    {
      "epoch": 0.05024320797247597,
      "grad_norm": 25.73537826538086,
      "learning_rate": 1.0047449584816133e-05,
      "loss": 0.1866,
      "step": 847
    },
    {
      "epoch": 0.05030252699015304,
      "grad_norm": 91.80765533447266,
      "learning_rate": 1.0059311981020168e-05,
      "loss": 0.601,
      "step": 848
    },
    {
      "epoch": 0.05036184600783011,
      "grad_norm": 30.08064842224121,
      "learning_rate": 1.00711743772242e-05,
      "loss": 0.2625,
      "step": 849
    },
    {
      "epoch": 0.05042116502550718,
      "grad_norm": 0.8778267502784729,
      "learning_rate": 1.0083036773428234e-05,
      "loss": 0.0065,
      "step": 850
    },
    {
      "epoch": 0.05048048404318425,
      "grad_norm": 21.25672721862793,
      "learning_rate": 1.0094899169632266e-05,
      "loss": 0.2005,
      "step": 851
    },
    {
      "epoch": 0.05053980306086131,
      "grad_norm": 0.21478280425071716,
      "learning_rate": 1.01067615658363e-05,
      "loss": 0.0023,
      "step": 852
    },
    {
      "epoch": 0.05059912207853838,
      "grad_norm": 40.69270324707031,
      "learning_rate": 1.0118623962040333e-05,
      "loss": 1.0537,
      "step": 853
    },
    {
      "epoch": 0.050658441096215444,
      "grad_norm": 57.49634552001953,
      "learning_rate": 1.0130486358244366e-05,
      "loss": 0.6056,
      "step": 854
    },
    {
      "epoch": 0.050717760113892514,
      "grad_norm": 0.3839806914329529,
      "learning_rate": 1.01423487544484e-05,
      "loss": 0.0035,
      "step": 855
    },
    {
      "epoch": 0.050777079131569584,
      "grad_norm": 0.9462630748748779,
      "learning_rate": 1.0154211150652433e-05,
      "loss": 0.0061,
      "step": 856
    },
    {
      "epoch": 0.05083639814924665,
      "grad_norm": 6.799269676208496,
      "learning_rate": 1.0166073546856465e-05,
      "loss": 0.062,
      "step": 857
    },
    {
      "epoch": 0.05089571716692372,
      "grad_norm": 41.322574615478516,
      "learning_rate": 1.01779359430605e-05,
      "loss": 0.6828,
      "step": 858
    },
    {
      "epoch": 0.05095503618460078,
      "grad_norm": 33.78376388549805,
      "learning_rate": 1.0189798339264532e-05,
      "loss": 0.7522,
      "step": 859
    },
    {
      "epoch": 0.05101435520227785,
      "grad_norm": 3.7466797828674316,
      "learning_rate": 1.0201660735468566e-05,
      "loss": 0.0269,
      "step": 860
    },
    {
      "epoch": 0.051073674219954915,
      "grad_norm": 4.425155162811279,
      "learning_rate": 1.0213523131672597e-05,
      "loss": 0.0388,
      "step": 861
    },
    {
      "epoch": 0.051132993237631985,
      "grad_norm": 9.139689445495605,
      "learning_rate": 1.0225385527876633e-05,
      "loss": 0.0565,
      "step": 862
    },
    {
      "epoch": 0.051192312255309055,
      "grad_norm": 83.28683471679688,
      "learning_rate": 1.0237247924080664e-05,
      "loss": 1.216,
      "step": 863
    },
    {
      "epoch": 0.05125163127298612,
      "grad_norm": 122.18856811523438,
      "learning_rate": 1.0249110320284698e-05,
      "loss": 0.283,
      "step": 864
    },
    {
      "epoch": 0.05131095029066319,
      "grad_norm": 24.61338996887207,
      "learning_rate": 1.0260972716488731e-05,
      "loss": 0.1057,
      "step": 865
    },
    {
      "epoch": 0.05137026930834025,
      "grad_norm": 0.1422336846590042,
      "learning_rate": 1.0272835112692765e-05,
      "loss": 0.0014,
      "step": 866
    },
    {
      "epoch": 0.05142958832601732,
      "grad_norm": 20.569591522216797,
      "learning_rate": 1.0284697508896797e-05,
      "loss": 0.0588,
      "step": 867
    },
    {
      "epoch": 0.051488907343694386,
      "grad_norm": 0.1580682098865509,
      "learning_rate": 1.0296559905100832e-05,
      "loss": 0.0028,
      "step": 868
    },
    {
      "epoch": 0.051548226361371456,
      "grad_norm": 0.8620279431343079,
      "learning_rate": 1.0308422301304864e-05,
      "loss": 0.0051,
      "step": 869
    },
    {
      "epoch": 0.051607545379048526,
      "grad_norm": 6.585638046264648,
      "learning_rate": 1.0320284697508897e-05,
      "loss": 0.0305,
      "step": 870
    },
    {
      "epoch": 0.05166686439672559,
      "grad_norm": 75.3847885131836,
      "learning_rate": 1.033214709371293e-05,
      "loss": 1.5384,
      "step": 871
    },
    {
      "epoch": 0.05172618341440266,
      "grad_norm": 1.1435441970825195,
      "learning_rate": 1.0344009489916964e-05,
      "loss": 0.0091,
      "step": 872
    },
    {
      "epoch": 0.05178550243207972,
      "grad_norm": 34.62624740600586,
      "learning_rate": 1.0355871886120998e-05,
      "loss": 1.0466,
      "step": 873
    },
    {
      "epoch": 0.051844821449756794,
      "grad_norm": 12.504073143005371,
      "learning_rate": 1.036773428232503e-05,
      "loss": 0.5376,
      "step": 874
    },
    {
      "epoch": 0.05190414046743386,
      "grad_norm": 0.9891764521598816,
      "learning_rate": 1.0379596678529065e-05,
      "loss": 0.0065,
      "step": 875
    },
    {
      "epoch": 0.05196345948511093,
      "grad_norm": 0.33230772614479065,
      "learning_rate": 1.0391459074733097e-05,
      "loss": 0.0025,
      "step": 876
    },
    {
      "epoch": 0.05202277850278799,
      "grad_norm": 0.28564363718032837,
      "learning_rate": 1.040332147093713e-05,
      "loss": 0.0018,
      "step": 877
    },
    {
      "epoch": 0.05208209752046506,
      "grad_norm": 8.986251831054688,
      "learning_rate": 1.0415183867141164e-05,
      "loss": 0.0822,
      "step": 878
    },
    {
      "epoch": 0.05214141653814213,
      "grad_norm": 28.941326141357422,
      "learning_rate": 1.0427046263345197e-05,
      "loss": 0.37,
      "step": 879
    },
    {
      "epoch": 0.052200735555819194,
      "grad_norm": 0.29156944155693054,
      "learning_rate": 1.043890865954923e-05,
      "loss": 0.0029,
      "step": 880
    },
    {
      "epoch": 0.052260054573496265,
      "grad_norm": 18.322315216064453,
      "learning_rate": 1.0450771055753264e-05,
      "loss": 0.107,
      "step": 881
    },
    {
      "epoch": 0.05231937359117333,
      "grad_norm": 7.973185062408447,
      "learning_rate": 1.0462633451957296e-05,
      "loss": 0.0772,
      "step": 882
    },
    {
      "epoch": 0.0523786926088504,
      "grad_norm": 198.51380920410156,
      "learning_rate": 1.047449584816133e-05,
      "loss": 0.4144,
      "step": 883
    },
    {
      "epoch": 0.05243801162652746,
      "grad_norm": 0.22183959186077118,
      "learning_rate": 1.0486358244365362e-05,
      "loss": 0.0021,
      "step": 884
    },
    {
      "epoch": 0.05249733064420453,
      "grad_norm": 56.79983139038086,
      "learning_rate": 1.0498220640569397e-05,
      "loss": 0.8753,
      "step": 885
    },
    {
      "epoch": 0.0525566496618816,
      "grad_norm": 3.440328359603882,
      "learning_rate": 1.0510083036773429e-05,
      "loss": 0.0177,
      "step": 886
    },
    {
      "epoch": 0.052615968679558665,
      "grad_norm": 9.61678409576416,
      "learning_rate": 1.0521945432977462e-05,
      "loss": 0.0644,
      "step": 887
    },
    {
      "epoch": 0.052675287697235736,
      "grad_norm": 0.03253112733364105,
      "learning_rate": 1.0533807829181496e-05,
      "loss": 0.0005,
      "step": 888
    },
    {
      "epoch": 0.0527346067149128,
      "grad_norm": 9.023521423339844,
      "learning_rate": 1.0545670225385529e-05,
      "loss": 0.0484,
      "step": 889
    },
    {
      "epoch": 0.05279392573258987,
      "grad_norm": 0.7013326287269592,
      "learning_rate": 1.0557532621589561e-05,
      "loss": 0.0048,
      "step": 890
    },
    {
      "epoch": 0.05285324475026693,
      "grad_norm": 33.02549362182617,
      "learning_rate": 1.0569395017793596e-05,
      "loss": 0.1552,
      "step": 891
    },
    {
      "epoch": 0.052912563767944,
      "grad_norm": 0.8775694966316223,
      "learning_rate": 1.0581257413997628e-05,
      "loss": 0.0054,
      "step": 892
    },
    {
      "epoch": 0.05297188278562107,
      "grad_norm": 11.554401397705078,
      "learning_rate": 1.0593119810201662e-05,
      "loss": 0.0615,
      "step": 893
    },
    {
      "epoch": 0.053031201803298136,
      "grad_norm": 44.71805953979492,
      "learning_rate": 1.0604982206405693e-05,
      "loss": 0.29,
      "step": 894
    },
    {
      "epoch": 0.05309052082097521,
      "grad_norm": 15.68670654296875,
      "learning_rate": 1.0616844602609729e-05,
      "loss": 0.4706,
      "step": 895
    },
    {
      "epoch": 0.05314983983865227,
      "grad_norm": 47.51082229614258,
      "learning_rate": 1.062870699881376e-05,
      "loss": 0.7414,
      "step": 896
    },
    {
      "epoch": 0.05320915885632934,
      "grad_norm": 39.706851959228516,
      "learning_rate": 1.0640569395017794e-05,
      "loss": 0.2821,
      "step": 897
    },
    {
      "epoch": 0.053268477874006404,
      "grad_norm": 9.89735221862793,
      "learning_rate": 1.0652431791221827e-05,
      "loss": 0.0497,
      "step": 898
    },
    {
      "epoch": 0.053327796891683474,
      "grad_norm": 5.79826021194458,
      "learning_rate": 1.0664294187425861e-05,
      "loss": 0.0278,
      "step": 899
    },
    {
      "epoch": 0.053387115909360544,
      "grad_norm": 31.471208572387695,
      "learning_rate": 1.0676156583629893e-05,
      "loss": 0.1812,
      "step": 900
    },
    {
      "epoch": 0.05344643492703761,
      "grad_norm": 0.06478448212146759,
      "learning_rate": 1.0688018979833928e-05,
      "loss": 0.0007,
      "step": 901
    },
    {
      "epoch": 0.05350575394471468,
      "grad_norm": 12.399961471557617,
      "learning_rate": 1.0699881376037962e-05,
      "loss": 0.2796,
      "step": 902
    },
    {
      "epoch": 0.05356507296239174,
      "grad_norm": 9.849668502807617,
      "learning_rate": 1.0711743772241993e-05,
      "loss": 0.0322,
      "step": 903
    },
    {
      "epoch": 0.05362439198006881,
      "grad_norm": 0.47581997513771057,
      "learning_rate": 1.0723606168446029e-05,
      "loss": 0.0021,
      "step": 904
    },
    {
      "epoch": 0.053683710997745875,
      "grad_norm": 10.531790733337402,
      "learning_rate": 1.073546856465006e-05,
      "loss": 0.0392,
      "step": 905
    },
    {
      "epoch": 0.053743030015422945,
      "grad_norm": 15.624112129211426,
      "learning_rate": 1.0747330960854094e-05,
      "loss": 0.1033,
      "step": 906
    },
    {
      "epoch": 0.053802349033100015,
      "grad_norm": 0.1516224443912506,
      "learning_rate": 1.0759193357058126e-05,
      "loss": 0.0015,
      "step": 907
    },
    {
      "epoch": 0.05386166805077708,
      "grad_norm": 0.03600407764315605,
      "learning_rate": 1.0771055753262161e-05,
      "loss": 0.0007,
      "step": 908
    },
    {
      "epoch": 0.05392098706845415,
      "grad_norm": 18.71119499206543,
      "learning_rate": 1.0782918149466193e-05,
      "loss": 0.7524,
      "step": 909
    },
    {
      "epoch": 0.05398030608613121,
      "grad_norm": 1.6667531728744507,
      "learning_rate": 1.0794780545670226e-05,
      "loss": 0.0062,
      "step": 910
    },
    {
      "epoch": 0.05403962510380828,
      "grad_norm": 0.366011381149292,
      "learning_rate": 1.080664294187426e-05,
      "loss": 0.002,
      "step": 911
    },
    {
      "epoch": 0.054098944121485346,
      "grad_norm": 0.006559840403497219,
      "learning_rate": 1.0818505338078293e-05,
      "loss": 0.0001,
      "step": 912
    },
    {
      "epoch": 0.054158263139162416,
      "grad_norm": 10.740619659423828,
      "learning_rate": 1.0830367734282325e-05,
      "loss": 0.1112,
      "step": 913
    },
    {
      "epoch": 0.054217582156839486,
      "grad_norm": 2.9949276447296143,
      "learning_rate": 1.084223013048636e-05,
      "loss": 0.0151,
      "step": 914
    },
    {
      "epoch": 0.05427690117451655,
      "grad_norm": 9.473036766052246,
      "learning_rate": 1.0854092526690392e-05,
      "loss": 0.0517,
      "step": 915
    },
    {
      "epoch": 0.05433622019219362,
      "grad_norm": 50.79595947265625,
      "learning_rate": 1.0865954922894426e-05,
      "loss": 0.6555,
      "step": 916
    },
    {
      "epoch": 0.05439553920987068,
      "grad_norm": 24.756601333618164,
      "learning_rate": 1.0877817319098458e-05,
      "loss": 0.184,
      "step": 917
    },
    {
      "epoch": 0.05445485822754775,
      "grad_norm": 0.015882911160588264,
      "learning_rate": 1.0889679715302493e-05,
      "loss": 0.0002,
      "step": 918
    },
    {
      "epoch": 0.05451417724522482,
      "grad_norm": 24.90085792541504,
      "learning_rate": 1.0901542111506525e-05,
      "loss": 1.0863,
      "step": 919
    },
    {
      "epoch": 0.05457349626290189,
      "grad_norm": 109.80657196044922,
      "learning_rate": 1.0913404507710558e-05,
      "loss": 0.4578,
      "step": 920
    },
    {
      "epoch": 0.05463281528057895,
      "grad_norm": 2.7340619564056396,
      "learning_rate": 1.0925266903914592e-05,
      "loss": 0.0129,
      "step": 921
    },
    {
      "epoch": 0.05469213429825602,
      "grad_norm": 2.6813716888427734,
      "learning_rate": 1.0937129300118625e-05,
      "loss": 0.0035,
      "step": 922
    },
    {
      "epoch": 0.05475145331593309,
      "grad_norm": 8.673164367675781,
      "learning_rate": 1.0948991696322657e-05,
      "loss": 0.0228,
      "step": 923
    },
    {
      "epoch": 0.054810772333610154,
      "grad_norm": 3.1165523529052734,
      "learning_rate": 1.0960854092526692e-05,
      "loss": 0.0332,
      "step": 924
    },
    {
      "epoch": 0.054870091351287224,
      "grad_norm": 21.537979125976562,
      "learning_rate": 1.0972716488730724e-05,
      "loss": 1.1462,
      "step": 925
    },
    {
      "epoch": 0.05492941036896429,
      "grad_norm": 0.36030688881874084,
      "learning_rate": 1.0984578884934757e-05,
      "loss": 0.0023,
      "step": 926
    },
    {
      "epoch": 0.05498872938664136,
      "grad_norm": 7.915945053100586,
      "learning_rate": 1.099644128113879e-05,
      "loss": 0.0208,
      "step": 927
    },
    {
      "epoch": 0.05504804840431842,
      "grad_norm": 101.720458984375,
      "learning_rate": 1.1008303677342825e-05,
      "loss": 2.1627,
      "step": 928
    },
    {
      "epoch": 0.05510736742199549,
      "grad_norm": 2.6518144607543945,
      "learning_rate": 1.1020166073546856e-05,
      "loss": 0.0213,
      "step": 929
    },
    {
      "epoch": 0.05516668643967256,
      "grad_norm": 0.18704870343208313,
      "learning_rate": 1.103202846975089e-05,
      "loss": 0.0016,
      "step": 930
    },
    {
      "epoch": 0.055226005457349625,
      "grad_norm": 50.66997528076172,
      "learning_rate": 1.1043890865954925e-05,
      "loss": 0.6668,
      "step": 931
    },
    {
      "epoch": 0.055285324475026695,
      "grad_norm": 0.24111083149909973,
      "learning_rate": 1.1055753262158957e-05,
      "loss": 0.0025,
      "step": 932
    },
    {
      "epoch": 0.05534464349270376,
      "grad_norm": 54.04998016357422,
      "learning_rate": 1.106761565836299e-05,
      "loss": 0.1175,
      "step": 933
    },
    {
      "epoch": 0.05540396251038083,
      "grad_norm": 0.016624270007014275,
      "learning_rate": 1.1079478054567024e-05,
      "loss": 0.0002,
      "step": 934
    },
    {
      "epoch": 0.05546328152805789,
      "grad_norm": 0.879493236541748,
      "learning_rate": 1.1091340450771057e-05,
      "loss": 0.0097,
      "step": 935
    },
    {
      "epoch": 0.05552260054573496,
      "grad_norm": 30.72482681274414,
      "learning_rate": 1.110320284697509e-05,
      "loss": 0.2442,
      "step": 936
    },
    {
      "epoch": 0.05558191956341203,
      "grad_norm": 32.08201599121094,
      "learning_rate": 1.1115065243179125e-05,
      "loss": 0.2026,
      "step": 937
    },
    {
      "epoch": 0.055641238581089096,
      "grad_norm": 0.026063187047839165,
      "learning_rate": 1.1126927639383156e-05,
      "loss": 0.0004,
      "step": 938
    },
    {
      "epoch": 0.055700557598766166,
      "grad_norm": 7.0774827003479,
      "learning_rate": 1.113879003558719e-05,
      "loss": 0.0373,
      "step": 939
    },
    {
      "epoch": 0.05575987661644323,
      "grad_norm": 11.6552152633667,
      "learning_rate": 1.1150652431791222e-05,
      "loss": 0.1523,
      "step": 940
    },
    {
      "epoch": 0.0558191956341203,
      "grad_norm": 0.7160587310791016,
      "learning_rate": 1.1162514827995257e-05,
      "loss": 0.0035,
      "step": 941
    },
    {
      "epoch": 0.05587851465179736,
      "grad_norm": 0.4723298251628876,
      "learning_rate": 1.1174377224199289e-05,
      "loss": 0.0042,
      "step": 942
    },
    {
      "epoch": 0.055937833669474434,
      "grad_norm": 5.42296838760376,
      "learning_rate": 1.1186239620403322e-05,
      "loss": 0.0204,
      "step": 943
    },
    {
      "epoch": 0.055997152687151504,
      "grad_norm": 2.9554128646850586,
      "learning_rate": 1.1198102016607356e-05,
      "loss": 0.0283,
      "step": 944
    },
    {
      "epoch": 0.05605647170482857,
      "grad_norm": 30.550735473632812,
      "learning_rate": 1.120996441281139e-05,
      "loss": 1.9377,
      "step": 945
    },
    {
      "epoch": 0.05611579072250564,
      "grad_norm": 53.35728454589844,
      "learning_rate": 1.1221826809015421e-05,
      "loss": 0.3738,
      "step": 946
    },
    {
      "epoch": 0.0561751097401827,
      "grad_norm": 45.512264251708984,
      "learning_rate": 1.1233689205219456e-05,
      "loss": 0.7352,
      "step": 947
    },
    {
      "epoch": 0.05623442875785977,
      "grad_norm": 0.21939876675605774,
      "learning_rate": 1.1245551601423488e-05,
      "loss": 0.0021,
      "step": 948
    },
    {
      "epoch": 0.056293747775536834,
      "grad_norm": 0.011403790675103664,
      "learning_rate": 1.1257413997627522e-05,
      "loss": 0.0003,
      "step": 949
    },
    {
      "epoch": 0.056353066793213905,
      "grad_norm": 0.11560017615556717,
      "learning_rate": 1.1269276393831553e-05,
      "loss": 0.0015,
      "step": 950
    },
    {
      "epoch": 0.056412385810890975,
      "grad_norm": 18.93577003479004,
      "learning_rate": 1.1281138790035589e-05,
      "loss": 0.1438,
      "step": 951
    },
    {
      "epoch": 0.05647170482856804,
      "grad_norm": 10.565010070800781,
      "learning_rate": 1.129300118623962e-05,
      "loss": 0.1635,
      "step": 952
    },
    {
      "epoch": 0.05653102384624511,
      "grad_norm": 1.1205800771713257,
      "learning_rate": 1.1304863582443654e-05,
      "loss": 0.0089,
      "step": 953
    },
    {
      "epoch": 0.05659034286392217,
      "grad_norm": 12.748688697814941,
      "learning_rate": 1.1316725978647688e-05,
      "loss": 0.1231,
      "step": 954
    },
    {
      "epoch": 0.05664966188159924,
      "grad_norm": 60.690216064453125,
      "learning_rate": 1.1328588374851721e-05,
      "loss": 1.0453,
      "step": 955
    },
    {
      "epoch": 0.056708980899276305,
      "grad_norm": 1.13016676902771,
      "learning_rate": 1.1340450771055753e-05,
      "loss": 0.0078,
      "step": 956
    },
    {
      "epoch": 0.056768299916953376,
      "grad_norm": 0.035989709198474884,
      "learning_rate": 1.1352313167259788e-05,
      "loss": 0.0008,
      "step": 957
    },
    {
      "epoch": 0.056827618934630446,
      "grad_norm": 2.2857511043548584,
      "learning_rate": 1.136417556346382e-05,
      "loss": 0.0147,
      "step": 958
    },
    {
      "epoch": 0.05688693795230751,
      "grad_norm": 15.498078346252441,
      "learning_rate": 1.1376037959667853e-05,
      "loss": 0.5,
      "step": 959
    },
    {
      "epoch": 0.05694625696998458,
      "grad_norm": 33.62834930419922,
      "learning_rate": 1.1387900355871889e-05,
      "loss": 0.4053,
      "step": 960
    },
    {
      "epoch": 0.05700557598766164,
      "grad_norm": 7.894740581512451,
      "learning_rate": 1.139976275207592e-05,
      "loss": 0.0501,
      "step": 961
    },
    {
      "epoch": 0.05706489500533871,
      "grad_norm": 1.8257237672805786,
      "learning_rate": 1.1411625148279954e-05,
      "loss": 0.0059,
      "step": 962
    },
    {
      "epoch": 0.057124214023015776,
      "grad_norm": 6.751984596252441,
      "learning_rate": 1.1423487544483986e-05,
      "loss": 0.0617,
      "step": 963
    },
    {
      "epoch": 0.05718353304069285,
      "grad_norm": 39.34041213989258,
      "learning_rate": 1.1435349940688021e-05,
      "loss": 0.3156,
      "step": 964
    },
    {
      "epoch": 0.05724285205836992,
      "grad_norm": 0.052190106362104416,
      "learning_rate": 1.1447212336892053e-05,
      "loss": 0.0005,
      "step": 965
    },
    {
      "epoch": 0.05730217107604698,
      "grad_norm": 64.17741394042969,
      "learning_rate": 1.1459074733096086e-05,
      "loss": 0.4081,
      "step": 966
    },
    {
      "epoch": 0.05736149009372405,
      "grad_norm": 8.884902954101562,
      "learning_rate": 1.147093712930012e-05,
      "loss": 0.03,
      "step": 967
    },
    {
      "epoch": 0.057420809111401114,
      "grad_norm": 15.809819221496582,
      "learning_rate": 1.1482799525504153e-05,
      "loss": 0.2382,
      "step": 968
    },
    {
      "epoch": 0.057480128129078184,
      "grad_norm": 2.1742067337036133,
      "learning_rate": 1.1494661921708185e-05,
      "loss": 0.0089,
      "step": 969
    },
    {
      "epoch": 0.05753944714675525,
      "grad_norm": 21.3780460357666,
      "learning_rate": 1.150652431791222e-05,
      "loss": 0.2041,
      "step": 970
    },
    {
      "epoch": 0.05759876616443232,
      "grad_norm": 0.023162508383393288,
      "learning_rate": 1.1518386714116252e-05,
      "loss": 0.0003,
      "step": 971
    },
    {
      "epoch": 0.05765808518210938,
      "grad_norm": 13.812826156616211,
      "learning_rate": 1.1530249110320286e-05,
      "loss": 0.098,
      "step": 972
    },
    {
      "epoch": 0.05771740419978645,
      "grad_norm": 43.100257873535156,
      "learning_rate": 1.1542111506524318e-05,
      "loss": 0.2688,
      "step": 973
    },
    {
      "epoch": 0.05777672321746352,
      "grad_norm": 7.965233325958252,
      "learning_rate": 1.1553973902728353e-05,
      "loss": 0.0491,
      "step": 974
    },
    {
      "epoch": 0.057836042235140585,
      "grad_norm": 34.10211944580078,
      "learning_rate": 1.1565836298932385e-05,
      "loss": 0.1002,
      "step": 975
    },
    {
      "epoch": 0.057895361252817655,
      "grad_norm": 13.35275936126709,
      "learning_rate": 1.1577698695136418e-05,
      "loss": 0.1359,
      "step": 976
    },
    {
      "epoch": 0.05795468027049472,
      "grad_norm": 1.6243833303451538,
      "learning_rate": 1.1589561091340452e-05,
      "loss": 0.0098,
      "step": 977
    },
    {
      "epoch": 0.05801399928817179,
      "grad_norm": 31.581626892089844,
      "learning_rate": 1.1601423487544485e-05,
      "loss": 0.461,
      "step": 978
    },
    {
      "epoch": 0.05807331830584885,
      "grad_norm": 5.176648139953613,
      "learning_rate": 1.1613285883748517e-05,
      "loss": 0.1049,
      "step": 979
    },
    {
      "epoch": 0.05813263732352592,
      "grad_norm": 0.15664337575435638,
      "learning_rate": 1.1625148279952552e-05,
      "loss": 0.0017,
      "step": 980
    },
    {
      "epoch": 0.05819195634120299,
      "grad_norm": 7.0908966064453125,
      "learning_rate": 1.1637010676156584e-05,
      "loss": 0.0294,
      "step": 981
    },
    {
      "epoch": 0.058251275358880056,
      "grad_norm": 0.6312547922134399,
      "learning_rate": 1.1648873072360618e-05,
      "loss": 0.0043,
      "step": 982
    },
    {
      "epoch": 0.058310594376557126,
      "grad_norm": 9.637360572814941,
      "learning_rate": 1.166073546856465e-05,
      "loss": 0.0392,
      "step": 983
    },
    {
      "epoch": 0.05836991339423419,
      "grad_norm": 56.40428924560547,
      "learning_rate": 1.1672597864768685e-05,
      "loss": 1.3541,
      "step": 984
    },
    {
      "epoch": 0.05842923241191126,
      "grad_norm": 15.249167442321777,
      "learning_rate": 1.1684460260972716e-05,
      "loss": 0.6683,
      "step": 985
    },
    {
      "epoch": 0.05848855142958832,
      "grad_norm": 26.16333770751953,
      "learning_rate": 1.169632265717675e-05,
      "loss": 0.2215,
      "step": 986
    },
    {
      "epoch": 0.05854787044726539,
      "grad_norm": 36.34090042114258,
      "learning_rate": 1.1708185053380784e-05,
      "loss": 0.9517,
      "step": 987
    },
    {
      "epoch": 0.058607189464942464,
      "grad_norm": 11.266629219055176,
      "learning_rate": 1.1720047449584817e-05,
      "loss": 0.1038,
      "step": 988
    },
    {
      "epoch": 0.05866650848261953,
      "grad_norm": 12.892695426940918,
      "learning_rate": 1.173190984578885e-05,
      "loss": 0.0371,
      "step": 989
    },
    {
      "epoch": 0.0587258275002966,
      "grad_norm": 53.75881576538086,
      "learning_rate": 1.1743772241992884e-05,
      "loss": 2.5139,
      "step": 990
    },
    {
      "epoch": 0.05878514651797366,
      "grad_norm": 12.117039680480957,
      "learning_rate": 1.1755634638196918e-05,
      "loss": 0.0515,
      "step": 991
    },
    {
      "epoch": 0.05884446553565073,
      "grad_norm": 26.41986656188965,
      "learning_rate": 1.176749703440095e-05,
      "loss": 0.2704,
      "step": 992
    },
    {
      "epoch": 0.058903784553327794,
      "grad_norm": 23.246074676513672,
      "learning_rate": 1.1779359430604985e-05,
      "loss": 0.1043,
      "step": 993
    },
    {
      "epoch": 0.058963103571004864,
      "grad_norm": 0.008642852306365967,
      "learning_rate": 1.1791221826809016e-05,
      "loss": 0.0002,
      "step": 994
    },
    {
      "epoch": 0.059022422588681935,
      "grad_norm": 16.78977394104004,
      "learning_rate": 1.180308422301305e-05,
      "loss": 0.0555,
      "step": 995
    },
    {
      "epoch": 0.059081741606359,
      "grad_norm": 50.80305480957031,
      "learning_rate": 1.1814946619217082e-05,
      "loss": 0.735,
      "step": 996
    },
    {
      "epoch": 0.05914106062403607,
      "grad_norm": 5.545618057250977,
      "learning_rate": 1.1826809015421117e-05,
      "loss": 0.0353,
      "step": 997
    },
    {
      "epoch": 0.05920037964171313,
      "grad_norm": 1.0744234323501587,
      "learning_rate": 1.1838671411625149e-05,
      "loss": 0.0105,
      "step": 998
    },
    {
      "epoch": 0.0592596986593902,
      "grad_norm": 0.2211807668209076,
      "learning_rate": 1.1850533807829182e-05,
      "loss": 0.0022,
      "step": 999
    },
    {
      "epoch": 0.059319017677067265,
      "grad_norm": 9.163850784301758,
      "learning_rate": 1.1862396204033216e-05,
      "loss": 0.0899,
      "step": 1000
    },
    {
      "epoch": 0.059378336694744335,
      "grad_norm": 5.665236949920654,
      "learning_rate": 1.187425860023725e-05,
      "loss": 0.0202,
      "step": 1001
    },
    {
      "epoch": 0.059437655712421406,
      "grad_norm": 26.701602935791016,
      "learning_rate": 1.1886120996441281e-05,
      "loss": 0.2624,
      "step": 1002
    },
    {
      "epoch": 0.05949697473009847,
      "grad_norm": 14.2296781539917,
      "learning_rate": 1.1897983392645316e-05,
      "loss": 0.1586,
      "step": 1003
    },
    {
      "epoch": 0.05955629374777554,
      "grad_norm": 53.828407287597656,
      "learning_rate": 1.1909845788849348e-05,
      "loss": 0.1429,
      "step": 1004
    },
    {
      "epoch": 0.0596156127654526,
      "grad_norm": 91.11255645751953,
      "learning_rate": 1.1921708185053382e-05,
      "loss": 0.6445,
      "step": 1005
    },
    {
      "epoch": 0.05967493178312967,
      "grad_norm": 42.85197067260742,
      "learning_rate": 1.1933570581257414e-05,
      "loss": 0.5227,
      "step": 1006
    },
    {
      "epoch": 0.059734250800806736,
      "grad_norm": 19.597469329833984,
      "learning_rate": 1.1945432977461449e-05,
      "loss": 0.5809,
      "step": 1007
    },
    {
      "epoch": 0.059793569818483806,
      "grad_norm": 65.0315933227539,
      "learning_rate": 1.195729537366548e-05,
      "loss": 0.4938,
      "step": 1008
    },
    {
      "epoch": 0.05985288883616088,
      "grad_norm": 1.7445578575134277,
      "learning_rate": 1.1969157769869514e-05,
      "loss": 0.0051,
      "step": 1009
    },
    {
      "epoch": 0.05991220785383794,
      "grad_norm": 0.7483154535293579,
      "learning_rate": 1.1981020166073548e-05,
      "loss": 0.0054,
      "step": 1010
    },
    {
      "epoch": 0.05997152687151501,
      "grad_norm": 8.005128860473633,
      "learning_rate": 1.1992882562277581e-05,
      "loss": 0.0584,
      "step": 1011
    },
    {
      "epoch": 0.060030845889192073,
      "grad_norm": 25.236547470092773,
      "learning_rate": 1.2004744958481613e-05,
      "loss": 0.4249,
      "step": 1012
    },
    {
      "epoch": 0.060090164906869144,
      "grad_norm": 0.22090274095535278,
      "learning_rate": 1.2016607354685648e-05,
      "loss": 0.0017,
      "step": 1013
    },
    {
      "epoch": 0.06014948392454621,
      "grad_norm": 1.0172638893127441,
      "learning_rate": 1.202846975088968e-05,
      "loss": 0.0112,
      "step": 1014
    },
    {
      "epoch": 0.06020880294222328,
      "grad_norm": 0.011793326586484909,
      "learning_rate": 1.2040332147093714e-05,
      "loss": 0.0002,
      "step": 1015
    },
    {
      "epoch": 0.06026812195990034,
      "grad_norm": 36.72350311279297,
      "learning_rate": 1.2052194543297745e-05,
      "loss": 0.5601,
      "step": 1016
    },
    {
      "epoch": 0.06032744097757741,
      "grad_norm": 14.741311073303223,
      "learning_rate": 1.206405693950178e-05,
      "loss": 0.0887,
      "step": 1017
    },
    {
      "epoch": 0.06038675999525448,
      "grad_norm": 0.5092244148254395,
      "learning_rate": 1.2075919335705814e-05,
      "loss": 0.0083,
      "step": 1018
    },
    {
      "epoch": 0.060446079012931545,
      "grad_norm": 18.82623291015625,
      "learning_rate": 1.2087781731909846e-05,
      "loss": 0.3753,
      "step": 1019
    },
    {
      "epoch": 0.060505398030608615,
      "grad_norm": 9.548155784606934,
      "learning_rate": 1.2099644128113881e-05,
      "loss": 0.1023,
      "step": 1020
    },
    {
      "epoch": 0.06056471704828568,
      "grad_norm": 6.780745029449463,
      "learning_rate": 1.2111506524317913e-05,
      "loss": 0.094,
      "step": 1021
    },
    {
      "epoch": 0.06062403606596275,
      "grad_norm": 1.386809229850769,
      "learning_rate": 1.2123368920521947e-05,
      "loss": 0.0073,
      "step": 1022
    },
    {
      "epoch": 0.06068335508363981,
      "grad_norm": 9.406003952026367,
      "learning_rate": 1.213523131672598e-05,
      "loss": 0.0376,
      "step": 1023
    },
    {
      "epoch": 0.06074267410131688,
      "grad_norm": 41.38134002685547,
      "learning_rate": 1.2147093712930014e-05,
      "loss": 0.7135,
      "step": 1024
    },
    {
      "epoch": 0.06080199311899395,
      "grad_norm": 20.247323989868164,
      "learning_rate": 1.2158956109134045e-05,
      "loss": 0.1733,
      "step": 1025
    },
    {
      "epoch": 0.060861312136671016,
      "grad_norm": 19.915969848632812,
      "learning_rate": 1.217081850533808e-05,
      "loss": 0.3197,
      "step": 1026
    },
    {
      "epoch": 0.060920631154348086,
      "grad_norm": 0.2774864435195923,
      "learning_rate": 1.2182680901542112e-05,
      "loss": 0.0033,
      "step": 1027
    },
    {
      "epoch": 0.06097995017202515,
      "grad_norm": 14.444863319396973,
      "learning_rate": 1.2194543297746146e-05,
      "loss": 0.0885,
      "step": 1028
    },
    {
      "epoch": 0.06103926918970222,
      "grad_norm": 4.182670593261719,
      "learning_rate": 1.2206405693950178e-05,
      "loss": 0.4011,
      "step": 1029
    },
    {
      "epoch": 0.06109858820737928,
      "grad_norm": 44.770477294921875,
      "learning_rate": 1.2218268090154213e-05,
      "loss": 0.8739,
      "step": 1030
    },
    {
      "epoch": 0.06115790722505635,
      "grad_norm": 21.466562271118164,
      "learning_rate": 1.2230130486358245e-05,
      "loss": 1.2953,
      "step": 1031
    },
    {
      "epoch": 0.06121722624273342,
      "grad_norm": 41.90333938598633,
      "learning_rate": 1.2241992882562278e-05,
      "loss": 0.2982,
      "step": 1032
    },
    {
      "epoch": 0.06127654526041049,
      "grad_norm": 0.2753341495990753,
      "learning_rate": 1.2253855278766312e-05,
      "loss": 0.0019,
      "step": 1033
    },
    {
      "epoch": 0.06133586427808756,
      "grad_norm": 50.61421585083008,
      "learning_rate": 1.2265717674970345e-05,
      "loss": 1.7491,
      "step": 1034
    },
    {
      "epoch": 0.06139518329576462,
      "grad_norm": 0.03458680212497711,
      "learning_rate": 1.2277580071174377e-05,
      "loss": 0.0007,
      "step": 1035
    },
    {
      "epoch": 0.06145450231344169,
      "grad_norm": 54.12687683105469,
      "learning_rate": 1.2289442467378412e-05,
      "loss": 1.9447,
      "step": 1036
    },
    {
      "epoch": 0.061513821331118754,
      "grad_norm": 13.222217559814453,
      "learning_rate": 1.2301304863582444e-05,
      "loss": 0.1312,
      "step": 1037
    },
    {
      "epoch": 0.061573140348795824,
      "grad_norm": 1.0223848819732666,
      "learning_rate": 1.2313167259786478e-05,
      "loss": 0.0067,
      "step": 1038
    },
    {
      "epoch": 0.061632459366472894,
      "grad_norm": 12.285061836242676,
      "learning_rate": 1.232502965599051e-05,
      "loss": 0.0299,
      "step": 1039
    },
    {
      "epoch": 0.06169177838414996,
      "grad_norm": 25.306915283203125,
      "learning_rate": 1.2336892052194545e-05,
      "loss": 0.3429,
      "step": 1040
    },
    {
      "epoch": 0.06175109740182703,
      "grad_norm": 10.674539566040039,
      "learning_rate": 1.2348754448398577e-05,
      "loss": 0.0829,
      "step": 1041
    },
    {
      "epoch": 0.06181041641950409,
      "grad_norm": 35.54343032836914,
      "learning_rate": 1.236061684460261e-05,
      "loss": 0.1105,
      "step": 1042
    },
    {
      "epoch": 0.06186973543718116,
      "grad_norm": 0.5902915596961975,
      "learning_rate": 1.2372479240806644e-05,
      "loss": 0.005,
      "step": 1043
    },
    {
      "epoch": 0.061929054454858225,
      "grad_norm": 46.11483383178711,
      "learning_rate": 1.2384341637010677e-05,
      "loss": 0.2172,
      "step": 1044
    },
    {
      "epoch": 0.061988373472535295,
      "grad_norm": 35.632415771484375,
      "learning_rate": 1.2396204033214709e-05,
      "loss": 0.7607,
      "step": 1045
    },
    {
      "epoch": 0.062047692490212365,
      "grad_norm": 3.7063684463500977,
      "learning_rate": 1.2408066429418744e-05,
      "loss": 0.009,
      "step": 1046
    },
    {
      "epoch": 0.06210701150788943,
      "grad_norm": 1.391041874885559,
      "learning_rate": 1.2419928825622778e-05,
      "loss": 0.0068,
      "step": 1047
    },
    {
      "epoch": 0.0621663305255665,
      "grad_norm": 0.2538388669490814,
      "learning_rate": 1.243179122182681e-05,
      "loss": 0.0015,
      "step": 1048
    },
    {
      "epoch": 0.06222564954324356,
      "grad_norm": 1.3726153373718262,
      "learning_rate": 1.2443653618030845e-05,
      "loss": 0.0081,
      "step": 1049
    },
    {
      "epoch": 0.06228496856092063,
      "grad_norm": 12.223569869995117,
      "learning_rate": 1.2455516014234877e-05,
      "loss": 0.1319,
      "step": 1050
    },
    {
      "epoch": 0.062344287578597696,
      "grad_norm": 19.387954711914062,
      "learning_rate": 1.246737841043891e-05,
      "loss": 0.2251,
      "step": 1051
    },
    {
      "epoch": 0.062403606596274766,
      "grad_norm": 27.30116081237793,
      "learning_rate": 1.2479240806642942e-05,
      "loss": 0.1092,
      "step": 1052
    },
    {
      "epoch": 0.062462925613951836,
      "grad_norm": 3.317941188812256,
      "learning_rate": 1.2491103202846977e-05,
      "loss": 0.0266,
      "step": 1053
    },
    {
      "epoch": 0.0625222446316289,
      "grad_norm": 0.028310786932706833,
      "learning_rate": 1.2502965599051009e-05,
      "loss": 0.0004,
      "step": 1054
    },
    {
      "epoch": 0.06258156364930596,
      "grad_norm": 7.222072601318359,
      "learning_rate": 1.2514827995255042e-05,
      "loss": 0.0556,
      "step": 1055
    },
    {
      "epoch": 0.06264088266698303,
      "grad_norm": 14.044188499450684,
      "learning_rate": 1.2526690391459076e-05,
      "loss": 0.3898,
      "step": 1056
    },
    {
      "epoch": 0.0627002016846601,
      "grad_norm": 0.5088880062103271,
      "learning_rate": 1.253855278766311e-05,
      "loss": 0.0035,
      "step": 1057
    },
    {
      "epoch": 0.06275952070233717,
      "grad_norm": 0.031241117045283318,
      "learning_rate": 1.2550415183867141e-05,
      "loss": 0.0004,
      "step": 1058
    },
    {
      "epoch": 0.06281883972001423,
      "grad_norm": 36.38539505004883,
      "learning_rate": 1.2562277580071177e-05,
      "loss": 0.3869,
      "step": 1059
    },
    {
      "epoch": 0.0628781587376913,
      "grad_norm": 8.546703338623047,
      "learning_rate": 1.2574139976275208e-05,
      "loss": 0.2214,
      "step": 1060
    },
    {
      "epoch": 0.06293747775536837,
      "grad_norm": 9.405561447143555,
      "learning_rate": 1.2586002372479242e-05,
      "loss": 0.0482,
      "step": 1061
    },
    {
      "epoch": 0.06299679677304544,
      "grad_norm": 26.552871704101562,
      "learning_rate": 1.2597864768683274e-05,
      "loss": 0.435,
      "step": 1062
    },
    {
      "epoch": 0.06305611579072251,
      "grad_norm": 8.75198745727539,
      "learning_rate": 1.2609727164887309e-05,
      "loss": 0.1086,
      "step": 1063
    },
    {
      "epoch": 0.06311543480839957,
      "grad_norm": 0.41411057114601135,
      "learning_rate": 1.262158956109134e-05,
      "loss": 0.0018,
      "step": 1064
    },
    {
      "epoch": 0.06317475382607664,
      "grad_norm": 42.52467727661133,
      "learning_rate": 1.2633451957295374e-05,
      "loss": 0.2618,
      "step": 1065
    },
    {
      "epoch": 0.06323407284375371,
      "grad_norm": 21.919998168945312,
      "learning_rate": 1.2645314353499408e-05,
      "loss": 0.6509,
      "step": 1066
    },
    {
      "epoch": 0.06329339186143078,
      "grad_norm": 6.686143398284912,
      "learning_rate": 1.2657176749703441e-05,
      "loss": 0.1554,
      "step": 1067
    },
    {
      "epoch": 0.06335271087910785,
      "grad_norm": 0.19598717987537384,
      "learning_rate": 1.2669039145907473e-05,
      "loss": 0.0013,
      "step": 1068
    },
    {
      "epoch": 0.0634120298967849,
      "grad_norm": 70.27210998535156,
      "learning_rate": 1.2680901542111508e-05,
      "loss": 1.3208,
      "step": 1069
    },
    {
      "epoch": 0.06347134891446198,
      "grad_norm": 1.2961064577102661,
      "learning_rate": 1.269276393831554e-05,
      "loss": 0.0064,
      "step": 1070
    },
    {
      "epoch": 0.06353066793213905,
      "grad_norm": 22.706878662109375,
      "learning_rate": 1.2704626334519574e-05,
      "loss": 0.2325,
      "step": 1071
    },
    {
      "epoch": 0.06358998694981612,
      "grad_norm": 0.47221705317497253,
      "learning_rate": 1.2716488730723606e-05,
      "loss": 0.0029,
      "step": 1072
    },
    {
      "epoch": 0.06364930596749317,
      "grad_norm": 2.8553061485290527,
      "learning_rate": 1.272835112692764e-05,
      "loss": 0.011,
      "step": 1073
    },
    {
      "epoch": 0.06370862498517024,
      "grad_norm": 65.05521392822266,
      "learning_rate": 1.2740213523131673e-05,
      "loss": 2.0549,
      "step": 1074
    },
    {
      "epoch": 0.06376794400284731,
      "grad_norm": 1.3543545007705688,
      "learning_rate": 1.2752075919335706e-05,
      "loss": 0.0037,
      "step": 1075
    },
    {
      "epoch": 0.06382726302052438,
      "grad_norm": 33.82251739501953,
      "learning_rate": 1.2763938315539741e-05,
      "loss": 0.4239,
      "step": 1076
    },
    {
      "epoch": 0.06388658203820145,
      "grad_norm": 0.18449833989143372,
      "learning_rate": 1.2775800711743773e-05,
      "loss": 0.0007,
      "step": 1077
    },
    {
      "epoch": 0.06394590105587851,
      "grad_norm": 5.264753818511963,
      "learning_rate": 1.2787663107947808e-05,
      "loss": 0.0824,
      "step": 1078
    },
    {
      "epoch": 0.06400522007355558,
      "grad_norm": 16.152793884277344,
      "learning_rate": 1.279952550415184e-05,
      "loss": 0.1587,
      "step": 1079
    },
    {
      "epoch": 0.06406453909123265,
      "grad_norm": 0.07442248612642288,
      "learning_rate": 1.2811387900355874e-05,
      "loss": 0.0003,
      "step": 1080
    },
    {
      "epoch": 0.06412385810890972,
      "grad_norm": 29.42265510559082,
      "learning_rate": 1.2823250296559906e-05,
      "loss": 0.7723,
      "step": 1081
    },
    {
      "epoch": 0.06418317712658679,
      "grad_norm": 10.678155899047852,
      "learning_rate": 1.283511269276394e-05,
      "loss": 0.1483,
      "step": 1082
    },
    {
      "epoch": 0.06424249614426385,
      "grad_norm": 13.05994701385498,
      "learning_rate": 1.2846975088967973e-05,
      "loss": 0.3819,
      "step": 1083
    },
    {
      "epoch": 0.06430181516194092,
      "grad_norm": 17.808639526367188,
      "learning_rate": 1.2858837485172006e-05,
      "loss": 0.0662,
      "step": 1084
    },
    {
      "epoch": 0.06436113417961799,
      "grad_norm": 11.28715991973877,
      "learning_rate": 1.2870699881376038e-05,
      "loss": 0.0478,
      "step": 1085
    },
    {
      "epoch": 0.06442045319729506,
      "grad_norm": 2.0546176433563232,
      "learning_rate": 1.2882562277580073e-05,
      "loss": 0.0147,
      "step": 1086
    },
    {
      "epoch": 0.06447977221497211,
      "grad_norm": 2.3910436630249023,
      "learning_rate": 1.2894424673784105e-05,
      "loss": 0.0245,
      "step": 1087
    },
    {
      "epoch": 0.06453909123264918,
      "grad_norm": 49.98996353149414,
      "learning_rate": 1.2906287069988138e-05,
      "loss": 1.1902,
      "step": 1088
    },
    {
      "epoch": 0.06459841025032625,
      "grad_norm": 14.734504699707031,
      "learning_rate": 1.2918149466192172e-05,
      "loss": 0.0976,
      "step": 1089
    },
    {
      "epoch": 0.06465772926800332,
      "grad_norm": 88.35468292236328,
      "learning_rate": 1.2930011862396206e-05,
      "loss": 1.886,
      "step": 1090
    },
    {
      "epoch": 0.0647170482856804,
      "grad_norm": 7.738844871520996,
      "learning_rate": 1.2941874258600237e-05,
      "loss": 0.0475,
      "step": 1091
    },
    {
      "epoch": 0.06477636730335745,
      "grad_norm": 0.12414203584194183,
      "learning_rate": 1.2953736654804273e-05,
      "loss": 0.0014,
      "step": 1092
    },
    {
      "epoch": 0.06483568632103452,
      "grad_norm": 14.184544563293457,
      "learning_rate": 1.2965599051008304e-05,
      "loss": 0.3693,
      "step": 1093
    },
    {
      "epoch": 0.06489500533871159,
      "grad_norm": 18.179821014404297,
      "learning_rate": 1.2977461447212338e-05,
      "loss": 0.1369,
      "step": 1094
    },
    {
      "epoch": 0.06495432435638866,
      "grad_norm": 0.05091811344027519,
      "learning_rate": 1.298932384341637e-05,
      "loss": 0.0008,
      "step": 1095
    },
    {
      "epoch": 0.06501364337406572,
      "grad_norm": 0.7354139089584351,
      "learning_rate": 1.3001186239620405e-05,
      "loss": 0.0075,
      "step": 1096
    },
    {
      "epoch": 0.06507296239174279,
      "grad_norm": 17.20938491821289,
      "learning_rate": 1.3013048635824437e-05,
      "loss": 0.3154,
      "step": 1097
    },
    {
      "epoch": 0.06513228140941986,
      "grad_norm": 2.4011805057525635,
      "learning_rate": 1.302491103202847e-05,
      "loss": 0.0091,
      "step": 1098
    },
    {
      "epoch": 0.06519160042709693,
      "grad_norm": 5.734222888946533,
      "learning_rate": 1.3036773428232504e-05,
      "loss": 0.0331,
      "step": 1099
    },
    {
      "epoch": 0.065250919444774,
      "grad_norm": 0.5543069839477539,
      "learning_rate": 1.3048635824436537e-05,
      "loss": 0.0033,
      "step": 1100
    },
    {
      "epoch": 0.06531023846245106,
      "grad_norm": 0.026419125497341156,
      "learning_rate": 1.3060498220640569e-05,
      "loss": 0.0003,
      "step": 1101
    },
    {
      "epoch": 0.06536955748012813,
      "grad_norm": 0.5263641476631165,
      "learning_rate": 1.3072360616844604e-05,
      "loss": 0.0027,
      "step": 1102
    },
    {
      "epoch": 0.0654288764978052,
      "grad_norm": 10.538402557373047,
      "learning_rate": 1.3084223013048636e-05,
      "loss": 0.0614,
      "step": 1103
    },
    {
      "epoch": 0.06548819551548227,
      "grad_norm": 4.559321880340576,
      "learning_rate": 1.309608540925267e-05,
      "loss": 0.0539,
      "step": 1104
    },
    {
      "epoch": 0.06554751453315934,
      "grad_norm": 97.12171936035156,
      "learning_rate": 1.3107947805456705e-05,
      "loss": 2.1584,
      "step": 1105
    },
    {
      "epoch": 0.0656068335508364,
      "grad_norm": 41.39286422729492,
      "learning_rate": 1.3119810201660737e-05,
      "loss": 0.7612,
      "step": 1106
    },
    {
      "epoch": 0.06566615256851346,
      "grad_norm": 38.488773345947266,
      "learning_rate": 1.313167259786477e-05,
      "loss": 0.9165,
      "step": 1107
    },
    {
      "epoch": 0.06572547158619053,
      "grad_norm": 5.535702705383301,
      "learning_rate": 1.3143534994068802e-05,
      "loss": 0.0135,
      "step": 1108
    },
    {
      "epoch": 0.0657847906038676,
      "grad_norm": 11.785985946655273,
      "learning_rate": 1.3155397390272837e-05,
      "loss": 0.1864,
      "step": 1109
    },
    {
      "epoch": 0.06584410962154466,
      "grad_norm": 71.10602569580078,
      "learning_rate": 1.3167259786476869e-05,
      "loss": 0.268,
      "step": 1110
    },
    {
      "epoch": 0.06590342863922173,
      "grad_norm": 23.46035385131836,
      "learning_rate": 1.3179122182680904e-05,
      "loss": 1.0346,
      "step": 1111
    },
    {
      "epoch": 0.0659627476568988,
      "grad_norm": 58.64242935180664,
      "learning_rate": 1.3190984578884936e-05,
      "loss": 0.7725,
      "step": 1112
    },
    {
      "epoch": 0.06602206667457587,
      "grad_norm": 2.8226747512817383,
      "learning_rate": 1.320284697508897e-05,
      "loss": 0.0114,
      "step": 1113
    },
    {
      "epoch": 0.06608138569225294,
      "grad_norm": 1.7100204229354858,
      "learning_rate": 1.3214709371293001e-05,
      "loss": 0.0077,
      "step": 1114
    },
    {
      "epoch": 0.06614070470993,
      "grad_norm": 24.421493530273438,
      "learning_rate": 1.3226571767497037e-05,
      "loss": 0.5949,
      "step": 1115
    },
    {
      "epoch": 0.06620002372760707,
      "grad_norm": 30.718549728393555,
      "learning_rate": 1.3238434163701069e-05,
      "loss": 0.2156,
      "step": 1116
    },
    {
      "epoch": 0.06625934274528414,
      "grad_norm": 46.977264404296875,
      "learning_rate": 1.3250296559905102e-05,
      "loss": 0.3582,
      "step": 1117
    },
    {
      "epoch": 0.06631866176296121,
      "grad_norm": 20.542280197143555,
      "learning_rate": 1.3262158956109134e-05,
      "loss": 0.372,
      "step": 1118
    },
    {
      "epoch": 0.06637798078063828,
      "grad_norm": 25.435266494750977,
      "learning_rate": 1.3274021352313169e-05,
      "loss": 0.1983,
      "step": 1119
    },
    {
      "epoch": 0.06643729979831534,
      "grad_norm": 0.009741134010255337,
      "learning_rate": 1.3285883748517201e-05,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 0.0664966188159924,
      "grad_norm": 1.224016785621643,
      "learning_rate": 1.3297746144721234e-05,
      "loss": 0.005,
      "step": 1121
    },
    {
      "epoch": 0.06655593783366948,
      "grad_norm": 4.937636375427246,
      "learning_rate": 1.3309608540925268e-05,
      "loss": 0.0301,
      "step": 1122
    },
    {
      "epoch": 0.06661525685134655,
      "grad_norm": 9.79858112335205,
      "learning_rate": 1.3321470937129301e-05,
      "loss": 0.08,
      "step": 1123
    },
    {
      "epoch": 0.0666745758690236,
      "grad_norm": 0.3364149034023285,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0017,
      "step": 1124
    },
    {
      "epoch": 0.06673389488670067,
      "grad_norm": 36.0853157043457,
      "learning_rate": 1.3345195729537369e-05,
      "loss": 0.7784,
      "step": 1125
    },
    {
      "epoch": 0.06679321390437774,
      "grad_norm": 0.04374495521187782,
      "learning_rate": 1.33570581257414e-05,
      "loss": 0.0009,
      "step": 1126
    },
    {
      "epoch": 0.06685253292205481,
      "grad_norm": 4.915780067443848,
      "learning_rate": 1.3368920521945434e-05,
      "loss": 0.0389,
      "step": 1127
    },
    {
      "epoch": 0.06691185193973188,
      "grad_norm": 21.67680549621582,
      "learning_rate": 1.3380782918149466e-05,
      "loss": 0.3018,
      "step": 1128
    },
    {
      "epoch": 0.06697117095740894,
      "grad_norm": 0.025487391278147697,
      "learning_rate": 1.3392645314353501e-05,
      "loss": 0.0004,
      "step": 1129
    },
    {
      "epoch": 0.06703048997508601,
      "grad_norm": 31.76581382751465,
      "learning_rate": 1.3404507710557533e-05,
      "loss": 0.2004,
      "step": 1130
    },
    {
      "epoch": 0.06708980899276308,
      "grad_norm": 32.86215591430664,
      "learning_rate": 1.3416370106761566e-05,
      "loss": 0.7539,
      "step": 1131
    },
    {
      "epoch": 0.06714912801044015,
      "grad_norm": 2.6647191047668457,
      "learning_rate": 1.34282325029656e-05,
      "loss": 0.0102,
      "step": 1132
    },
    {
      "epoch": 0.06720844702811721,
      "grad_norm": 1.4695531129837036,
      "learning_rate": 1.3440094899169633e-05,
      "loss": 0.0086,
      "step": 1133
    },
    {
      "epoch": 0.06726776604579428,
      "grad_norm": 31.924362182617188,
      "learning_rate": 1.3451957295373668e-05,
      "loss": 0.8739,
      "step": 1134
    },
    {
      "epoch": 0.06732708506347135,
      "grad_norm": 30.37970733642578,
      "learning_rate": 1.34638196915777e-05,
      "loss": 0.8539,
      "step": 1135
    },
    {
      "epoch": 0.06738640408114842,
      "grad_norm": 19.332502365112305,
      "learning_rate": 1.3475682087781734e-05,
      "loss": 0.4385,
      "step": 1136
    },
    {
      "epoch": 0.06744572309882549,
      "grad_norm": 12.895374298095703,
      "learning_rate": 1.3487544483985766e-05,
      "loss": 0.425,
      "step": 1137
    },
    {
      "epoch": 0.06750504211650254,
      "grad_norm": 0.16020239889621735,
      "learning_rate": 1.3499406880189801e-05,
      "loss": 0.0014,
      "step": 1138
    },
    {
      "epoch": 0.06756436113417962,
      "grad_norm": 28.946962356567383,
      "learning_rate": 1.3511269276393833e-05,
      "loss": 0.4264,
      "step": 1139
    },
    {
      "epoch": 0.06762368015185669,
      "grad_norm": 0.2207198292016983,
      "learning_rate": 1.3523131672597866e-05,
      "loss": 0.0017,
      "step": 1140
    },
    {
      "epoch": 0.06768299916953376,
      "grad_norm": 0.11091805249452591,
      "learning_rate": 1.3534994068801898e-05,
      "loss": 0.0009,
      "step": 1141
    },
    {
      "epoch": 0.06774231818721083,
      "grad_norm": 35.636817932128906,
      "learning_rate": 1.3546856465005933e-05,
      "loss": 1.2244,
      "step": 1142
    },
    {
      "epoch": 0.06780163720488788,
      "grad_norm": 18.466856002807617,
      "learning_rate": 1.3558718861209965e-05,
      "loss": 0.0634,
      "step": 1143
    },
    {
      "epoch": 0.06786095622256495,
      "grad_norm": 2.399308681488037,
      "learning_rate": 1.3570581257414e-05,
      "loss": 0.0158,
      "step": 1144
    },
    {
      "epoch": 0.06792027524024202,
      "grad_norm": 2.2688610553741455,
      "learning_rate": 1.3582443653618032e-05,
      "loss": 0.0094,
      "step": 1145
    },
    {
      "epoch": 0.0679795942579191,
      "grad_norm": 18.918787002563477,
      "learning_rate": 1.3594306049822066e-05,
      "loss": 0.7667,
      "step": 1146
    },
    {
      "epoch": 0.06803891327559615,
      "grad_norm": 55.25878143310547,
      "learning_rate": 1.3606168446026097e-05,
      "loss": 0.4689,
      "step": 1147
    },
    {
      "epoch": 0.06809823229327322,
      "grad_norm": 1.4306855201721191,
      "learning_rate": 1.3618030842230133e-05,
      "loss": 0.0082,
      "step": 1148
    },
    {
      "epoch": 0.06815755131095029,
      "grad_norm": 29.1612606048584,
      "learning_rate": 1.3629893238434164e-05,
      "loss": 0.0673,
      "step": 1149
    },
    {
      "epoch": 0.06821687032862736,
      "grad_norm": 0.31273481249809265,
      "learning_rate": 1.3641755634638198e-05,
      "loss": 0.002,
      "step": 1150
    },
    {
      "epoch": 0.06827618934630443,
      "grad_norm": 26.352834701538086,
      "learning_rate": 1.365361803084223e-05,
      "loss": 0.1531,
      "step": 1151
    },
    {
      "epoch": 0.06833550836398149,
      "grad_norm": 13.8046293258667,
      "learning_rate": 1.3665480427046265e-05,
      "loss": 0.3559,
      "step": 1152
    },
    {
      "epoch": 0.06839482738165856,
      "grad_norm": 19.30605125427246,
      "learning_rate": 1.3677342823250297e-05,
      "loss": 0.3072,
      "step": 1153
    },
    {
      "epoch": 0.06845414639933563,
      "grad_norm": 15.266265869140625,
      "learning_rate": 1.368920521945433e-05,
      "loss": 0.3141,
      "step": 1154
    },
    {
      "epoch": 0.0685134654170127,
      "grad_norm": 9.313015937805176,
      "learning_rate": 1.3701067615658364e-05,
      "loss": 0.0663,
      "step": 1155
    },
    {
      "epoch": 0.06857278443468977,
      "grad_norm": 0.7865702509880066,
      "learning_rate": 1.3712930011862397e-05,
      "loss": 0.0049,
      "step": 1156
    },
    {
      "epoch": 0.06863210345236682,
      "grad_norm": 74.43518829345703,
      "learning_rate": 1.372479240806643e-05,
      "loss": 1.025,
      "step": 1157
    },
    {
      "epoch": 0.0686914224700439,
      "grad_norm": 1.6650134325027466,
      "learning_rate": 1.3736654804270464e-05,
      "loss": 0.0122,
      "step": 1158
    },
    {
      "epoch": 0.06875074148772096,
      "grad_norm": 7.033146381378174,
      "learning_rate": 1.3748517200474496e-05,
      "loss": 0.1625,
      "step": 1159
    },
    {
      "epoch": 0.06881006050539804,
      "grad_norm": 35.98696517944336,
      "learning_rate": 1.376037959667853e-05,
      "loss": 0.8348,
      "step": 1160
    },
    {
      "epoch": 0.06886937952307509,
      "grad_norm": 7.075418949127197,
      "learning_rate": 1.3772241992882562e-05,
      "loss": 0.1267,
      "step": 1161
    },
    {
      "epoch": 0.06892869854075216,
      "grad_norm": 30.811878204345703,
      "learning_rate": 1.3784104389086597e-05,
      "loss": 0.3946,
      "step": 1162
    },
    {
      "epoch": 0.06898801755842923,
      "grad_norm": 38.13654708862305,
      "learning_rate": 1.379596678529063e-05,
      "loss": 0.1162,
      "step": 1163
    },
    {
      "epoch": 0.0690473365761063,
      "grad_norm": 11.084602355957031,
      "learning_rate": 1.3807829181494662e-05,
      "loss": 0.2628,
      "step": 1164
    },
    {
      "epoch": 0.06910665559378337,
      "grad_norm": 70.57081604003906,
      "learning_rate": 1.3819691577698697e-05,
      "loss": 0.4732,
      "step": 1165
    },
    {
      "epoch": 0.06916597461146043,
      "grad_norm": 17.11402130126953,
      "learning_rate": 1.383155397390273e-05,
      "loss": 0.4614,
      "step": 1166
    },
    {
      "epoch": 0.0692252936291375,
      "grad_norm": 0.1747501641511917,
      "learning_rate": 1.3843416370106764e-05,
      "loss": 0.0023,
      "step": 1167
    },
    {
      "epoch": 0.06928461264681457,
      "grad_norm": 13.279068946838379,
      "learning_rate": 1.3855278766310796e-05,
      "loss": 0.0965,
      "step": 1168
    },
    {
      "epoch": 0.06934393166449164,
      "grad_norm": 12.943321228027344,
      "learning_rate": 1.386714116251483e-05,
      "loss": 0.1925,
      "step": 1169
    },
    {
      "epoch": 0.06940325068216871,
      "grad_norm": 33.74226760864258,
      "learning_rate": 1.3879003558718862e-05,
      "loss": 0.3467,
      "step": 1170
    },
    {
      "epoch": 0.06946256969984577,
      "grad_norm": 19.861425399780273,
      "learning_rate": 1.3890865954922897e-05,
      "loss": 0.6685,
      "step": 1171
    },
    {
      "epoch": 0.06952188871752284,
      "grad_norm": 0.026700694113969803,
      "learning_rate": 1.3902728351126929e-05,
      "loss": 0.0006,
      "step": 1172
    },
    {
      "epoch": 0.06958120773519991,
      "grad_norm": 7.246057033538818,
      "learning_rate": 1.3914590747330962e-05,
      "loss": 0.0521,
      "step": 1173
    },
    {
      "epoch": 0.06964052675287698,
      "grad_norm": 54.509971618652344,
      "learning_rate": 1.3926453143534994e-05,
      "loss": 0.4507,
      "step": 1174
    },
    {
      "epoch": 0.06969984577055403,
      "grad_norm": 17.391643524169922,
      "learning_rate": 1.393831553973903e-05,
      "loss": 0.7704,
      "step": 1175
    },
    {
      "epoch": 0.0697591647882311,
      "grad_norm": 8.638718605041504,
      "learning_rate": 1.3950177935943061e-05,
      "loss": 0.0348,
      "step": 1176
    },
    {
      "epoch": 0.06981848380590817,
      "grad_norm": 21.639057159423828,
      "learning_rate": 1.3962040332147096e-05,
      "loss": 0.3427,
      "step": 1177
    },
    {
      "epoch": 0.06987780282358524,
      "grad_norm": 0.2944852113723755,
      "learning_rate": 1.3973902728351128e-05,
      "loss": 0.0016,
      "step": 1178
    },
    {
      "epoch": 0.06993712184126231,
      "grad_norm": 15.193737030029297,
      "learning_rate": 1.3985765124555162e-05,
      "loss": 0.3846,
      "step": 1179
    },
    {
      "epoch": 0.06999644085893937,
      "grad_norm": 5.137587070465088,
      "learning_rate": 1.3997627520759193e-05,
      "loss": 0.0691,
      "step": 1180
    },
    {
      "epoch": 0.07005575987661644,
      "grad_norm": 20.324914932250977,
      "learning_rate": 1.4009489916963229e-05,
      "loss": 0.3418,
      "step": 1181
    },
    {
      "epoch": 0.07011507889429351,
      "grad_norm": 2.5594515800476074,
      "learning_rate": 1.402135231316726e-05,
      "loss": 0.0298,
      "step": 1182
    },
    {
      "epoch": 0.07017439791197058,
      "grad_norm": 12.176438331604004,
      "learning_rate": 1.4033214709371294e-05,
      "loss": 0.275,
      "step": 1183
    },
    {
      "epoch": 0.07023371692964764,
      "grad_norm": 47.56638717651367,
      "learning_rate": 1.4045077105575326e-05,
      "loss": 3.167,
      "step": 1184
    },
    {
      "epoch": 0.07029303594732471,
      "grad_norm": 42.5908317565918,
      "learning_rate": 1.4056939501779361e-05,
      "loss": 0.453,
      "step": 1185
    },
    {
      "epoch": 0.07035235496500178,
      "grad_norm": 18.918556213378906,
      "learning_rate": 1.4068801897983393e-05,
      "loss": 0.1249,
      "step": 1186
    },
    {
      "epoch": 0.07041167398267885,
      "grad_norm": 2.2635624408721924,
      "learning_rate": 1.4080664294187426e-05,
      "loss": 0.0146,
      "step": 1187
    },
    {
      "epoch": 0.07047099300035592,
      "grad_norm": 2.3133206367492676,
      "learning_rate": 1.409252669039146e-05,
      "loss": 0.0208,
      "step": 1188
    },
    {
      "epoch": 0.07053031201803298,
      "grad_norm": 21.78610610961914,
      "learning_rate": 1.4104389086595493e-05,
      "loss": 0.243,
      "step": 1189
    },
    {
      "epoch": 0.07058963103571005,
      "grad_norm": 41.196189880371094,
      "learning_rate": 1.4116251482799525e-05,
      "loss": 0.2771,
      "step": 1190
    },
    {
      "epoch": 0.07064895005338712,
      "grad_norm": 24.24260139465332,
      "learning_rate": 1.412811387900356e-05,
      "loss": 0.2599,
      "step": 1191
    },
    {
      "epoch": 0.07070826907106419,
      "grad_norm": 4.9162421226501465,
      "learning_rate": 1.4139976275207594e-05,
      "loss": 0.0574,
      "step": 1192
    },
    {
      "epoch": 0.07076758808874126,
      "grad_norm": 29.07131004333496,
      "learning_rate": 1.4151838671411626e-05,
      "loss": 0.3784,
      "step": 1193
    },
    {
      "epoch": 0.07082690710641831,
      "grad_norm": 7.597085952758789,
      "learning_rate": 1.4163701067615661e-05,
      "loss": 0.7278,
      "step": 1194
    },
    {
      "epoch": 0.07088622612409538,
      "grad_norm": 23.768644332885742,
      "learning_rate": 1.4175563463819693e-05,
      "loss": 0.4455,
      "step": 1195
    },
    {
      "epoch": 0.07094554514177245,
      "grad_norm": 1.4908325672149658,
      "learning_rate": 1.4187425860023726e-05,
      "loss": 0.0087,
      "step": 1196
    },
    {
      "epoch": 0.07100486415944952,
      "grad_norm": 2.9982380867004395,
      "learning_rate": 1.4199288256227758e-05,
      "loss": 0.0294,
      "step": 1197
    },
    {
      "epoch": 0.07106418317712658,
      "grad_norm": 6.2091193199157715,
      "learning_rate": 1.4211150652431793e-05,
      "loss": 0.0727,
      "step": 1198
    },
    {
      "epoch": 0.07112350219480365,
      "grad_norm": 0.15154658257961273,
      "learning_rate": 1.4223013048635825e-05,
      "loss": 0.0022,
      "step": 1199
    },
    {
      "epoch": 0.07118282121248072,
      "grad_norm": 9.691481590270996,
      "learning_rate": 1.423487544483986e-05,
      "loss": 0.1278,
      "step": 1200
    },
    {
      "epoch": 0.07124214023015779,
      "grad_norm": 0.4294542968273163,
      "learning_rate": 1.4246737841043892e-05,
      "loss": 0.0029,
      "step": 1201
    },
    {
      "epoch": 0.07130145924783486,
      "grad_norm": 10.641602516174316,
      "learning_rate": 1.4258600237247926e-05,
      "loss": 0.2386,
      "step": 1202
    },
    {
      "epoch": 0.07136077826551192,
      "grad_norm": 13.761210441589355,
      "learning_rate": 1.4270462633451958e-05,
      "loss": 0.2122,
      "step": 1203
    },
    {
      "epoch": 0.07142009728318899,
      "grad_norm": 1.3764088153839111,
      "learning_rate": 1.4282325029655993e-05,
      "loss": 0.012,
      "step": 1204
    },
    {
      "epoch": 0.07147941630086606,
      "grad_norm": 14.673005104064941,
      "learning_rate": 1.4294187425860025e-05,
      "loss": 0.2434,
      "step": 1205
    },
    {
      "epoch": 0.07153873531854313,
      "grad_norm": 0.11755573004484177,
      "learning_rate": 1.4306049822064058e-05,
      "loss": 0.0014,
      "step": 1206
    },
    {
      "epoch": 0.0715980543362202,
      "grad_norm": 2.8179852962493896,
      "learning_rate": 1.431791221826809e-05,
      "loss": 0.0153,
      "step": 1207
    },
    {
      "epoch": 0.07165737335389726,
      "grad_norm": 14.966882705688477,
      "learning_rate": 1.4329774614472125e-05,
      "loss": 0.0662,
      "step": 1208
    },
    {
      "epoch": 0.07171669237157433,
      "grad_norm": 13.370076179504395,
      "learning_rate": 1.4341637010676157e-05,
      "loss": 0.0711,
      "step": 1209
    },
    {
      "epoch": 0.0717760113892514,
      "grad_norm": 3.6105270385742188,
      "learning_rate": 1.4353499406880192e-05,
      "loss": 0.0066,
      "step": 1210
    },
    {
      "epoch": 0.07183533040692847,
      "grad_norm": 33.99266815185547,
      "learning_rate": 1.4365361803084224e-05,
      "loss": 0.9107,
      "step": 1211
    },
    {
      "epoch": 0.07189464942460552,
      "grad_norm": 0.32129889726638794,
      "learning_rate": 1.4377224199288258e-05,
      "loss": 0.0036,
      "step": 1212
    },
    {
      "epoch": 0.07195396844228259,
      "grad_norm": 4.407817840576172,
      "learning_rate": 1.438908659549229e-05,
      "loss": 0.0232,
      "step": 1213
    },
    {
      "epoch": 0.07201328745995966,
      "grad_norm": 27.925962448120117,
      "learning_rate": 1.4400948991696325e-05,
      "loss": 0.1493,
      "step": 1214
    },
    {
      "epoch": 0.07207260647763673,
      "grad_norm": 32.5975227355957,
      "learning_rate": 1.4412811387900356e-05,
      "loss": 0.144,
      "step": 1215
    },
    {
      "epoch": 0.0721319254953138,
      "grad_norm": 0.28401467204093933,
      "learning_rate": 1.442467378410439e-05,
      "loss": 0.0023,
      "step": 1216
    },
    {
      "epoch": 0.07219124451299086,
      "grad_norm": 2.159151554107666,
      "learning_rate": 1.4436536180308422e-05,
      "loss": 0.0189,
      "step": 1217
    },
    {
      "epoch": 0.07225056353066793,
      "grad_norm": 7.5704426765441895,
      "learning_rate": 1.4448398576512457e-05,
      "loss": 0.1183,
      "step": 1218
    },
    {
      "epoch": 0.072309882548345,
      "grad_norm": 1.086067795753479,
      "learning_rate": 1.4460260972716489e-05,
      "loss": 0.0045,
      "step": 1219
    },
    {
      "epoch": 0.07236920156602207,
      "grad_norm": 0.9133253693580627,
      "learning_rate": 1.4472123368920522e-05,
      "loss": 0.0067,
      "step": 1220
    },
    {
      "epoch": 0.07242852058369914,
      "grad_norm": 0.1508202850818634,
      "learning_rate": 1.4483985765124558e-05,
      "loss": 0.002,
      "step": 1221
    },
    {
      "epoch": 0.0724878396013762,
      "grad_norm": 0.5536344647407532,
      "learning_rate": 1.449584816132859e-05,
      "loss": 0.0064,
      "step": 1222
    },
    {
      "epoch": 0.07254715861905327,
      "grad_norm": 18.906814575195312,
      "learning_rate": 1.4507710557532625e-05,
      "loss": 0.3975,
      "step": 1223
    },
    {
      "epoch": 0.07260647763673034,
      "grad_norm": 13.05229377746582,
      "learning_rate": 1.4519572953736656e-05,
      "loss": 0.1706,
      "step": 1224
    },
    {
      "epoch": 0.07266579665440741,
      "grad_norm": 3.419961929321289,
      "learning_rate": 1.453143534994069e-05,
      "loss": 0.0319,
      "step": 1225
    },
    {
      "epoch": 0.07272511567208446,
      "grad_norm": 2.4905848503112793,
      "learning_rate": 1.4543297746144722e-05,
      "loss": 0.0197,
      "step": 1226
    },
    {
      "epoch": 0.07278443468976153,
      "grad_norm": 0.05550121143460274,
      "learning_rate": 1.4555160142348757e-05,
      "loss": 0.001,
      "step": 1227
    },
    {
      "epoch": 0.0728437537074386,
      "grad_norm": 51.9495849609375,
      "learning_rate": 1.4567022538552789e-05,
      "loss": 1.05,
      "step": 1228
    },
    {
      "epoch": 0.07290307272511568,
      "grad_norm": 0.9373720288276672,
      "learning_rate": 1.4578884934756822e-05,
      "loss": 0.0042,
      "step": 1229
    },
    {
      "epoch": 0.07296239174279275,
      "grad_norm": 22.950876235961914,
      "learning_rate": 1.4590747330960854e-05,
      "loss": 0.3772,
      "step": 1230
    },
    {
      "epoch": 0.0730217107604698,
      "grad_norm": 24.57500457763672,
      "learning_rate": 1.460260972716489e-05,
      "loss": 0.4983,
      "step": 1231
    },
    {
      "epoch": 0.07308102977814687,
      "grad_norm": 63.34393310546875,
      "learning_rate": 1.4614472123368921e-05,
      "loss": 1.8531,
      "step": 1232
    },
    {
      "epoch": 0.07314034879582394,
      "grad_norm": 28.009387969970703,
      "learning_rate": 1.4626334519572956e-05,
      "loss": 0.4707,
      "step": 1233
    },
    {
      "epoch": 0.07319966781350101,
      "grad_norm": 6.492431163787842,
      "learning_rate": 1.4638196915776988e-05,
      "loss": 0.0248,
      "step": 1234
    },
    {
      "epoch": 0.07325898683117807,
      "grad_norm": 0.03460098057985306,
      "learning_rate": 1.4650059311981022e-05,
      "loss": 0.0004,
      "step": 1235
    },
    {
      "epoch": 0.07331830584885514,
      "grad_norm": 32.09788131713867,
      "learning_rate": 1.4661921708185054e-05,
      "loss": 0.1245,
      "step": 1236
    },
    {
      "epoch": 0.07337762486653221,
      "grad_norm": 1.3260977268218994,
      "learning_rate": 1.4673784104389089e-05,
      "loss": 0.0113,
      "step": 1237
    },
    {
      "epoch": 0.07343694388420928,
      "grad_norm": 18.662446975708008,
      "learning_rate": 1.468564650059312e-05,
      "loss": 0.228,
      "step": 1238
    },
    {
      "epoch": 0.07349626290188635,
      "grad_norm": 12.030985832214355,
      "learning_rate": 1.4697508896797154e-05,
      "loss": 0.3566,
      "step": 1239
    },
    {
      "epoch": 0.0735555819195634,
      "grad_norm": 15.130560874938965,
      "learning_rate": 1.4709371293001186e-05,
      "loss": 0.3652,
      "step": 1240
    },
    {
      "epoch": 0.07361490093724048,
      "grad_norm": 3.0091843605041504,
      "learning_rate": 1.4721233689205221e-05,
      "loss": 0.007,
      "step": 1241
    },
    {
      "epoch": 0.07367421995491755,
      "grad_norm": 8.641072273254395,
      "learning_rate": 1.4733096085409253e-05,
      "loss": 0.0388,
      "step": 1242
    },
    {
      "epoch": 0.07373353897259462,
      "grad_norm": 0.15007099509239197,
      "learning_rate": 1.4744958481613288e-05,
      "loss": 0.001,
      "step": 1243
    },
    {
      "epoch": 0.07379285799027169,
      "grad_norm": 27.703744888305664,
      "learning_rate": 1.475682087781732e-05,
      "loss": 0.1293,
      "step": 1244
    },
    {
      "epoch": 0.07385217700794874,
      "grad_norm": 53.598976135253906,
      "learning_rate": 1.4768683274021354e-05,
      "loss": 0.7767,
      "step": 1245
    },
    {
      "epoch": 0.07391149602562581,
      "grad_norm": 30.8078670501709,
      "learning_rate": 1.4780545670225385e-05,
      "loss": 3.1509,
      "step": 1246
    },
    {
      "epoch": 0.07397081504330288,
      "grad_norm": 13.666648864746094,
      "learning_rate": 1.479240806642942e-05,
      "loss": 0.1048,
      "step": 1247
    },
    {
      "epoch": 0.07403013406097995,
      "grad_norm": 47.492366790771484,
      "learning_rate": 1.4804270462633452e-05,
      "loss": 1.2951,
      "step": 1248
    },
    {
      "epoch": 0.07408945307865701,
      "grad_norm": 20.63587760925293,
      "learning_rate": 1.4816132858837486e-05,
      "loss": 0.0525,
      "step": 1249
    },
    {
      "epoch": 0.07414877209633408,
      "grad_norm": 0.1464616060256958,
      "learning_rate": 1.4827995255041521e-05,
      "loss": 0.0011,
      "step": 1250
    },
    {
      "epoch": 0.07420809111401115,
      "grad_norm": 21.72698402404785,
      "learning_rate": 1.4839857651245553e-05,
      "loss": 0.2136,
      "step": 1251
    },
    {
      "epoch": 0.07426741013168822,
      "grad_norm": 0.6801286935806274,
      "learning_rate": 1.4851720047449586e-05,
      "loss": 0.0043,
      "step": 1252
    },
    {
      "epoch": 0.07432672914936529,
      "grad_norm": 5.9513773918151855,
      "learning_rate": 1.4863582443653618e-05,
      "loss": 0.0566,
      "step": 1253
    },
    {
      "epoch": 0.07438604816704235,
      "grad_norm": 33.964412689208984,
      "learning_rate": 1.4875444839857654e-05,
      "loss": 0.433,
      "step": 1254
    },
    {
      "epoch": 0.07444536718471942,
      "grad_norm": 0.04784053936600685,
      "learning_rate": 1.4887307236061685e-05,
      "loss": 0.0007,
      "step": 1255
    },
    {
      "epoch": 0.07450468620239649,
      "grad_norm": 6.907476425170898,
      "learning_rate": 1.489916963226572e-05,
      "loss": 0.0439,
      "step": 1256
    },
    {
      "epoch": 0.07456400522007356,
      "grad_norm": 25.305925369262695,
      "learning_rate": 1.4911032028469752e-05,
      "loss": 0.6256,
      "step": 1257
    },
    {
      "epoch": 0.07462332423775063,
      "grad_norm": 2.9289157390594482,
      "learning_rate": 1.4922894424673786e-05,
      "loss": 0.0178,
      "step": 1258
    },
    {
      "epoch": 0.07468264325542769,
      "grad_norm": 0.3703809678554535,
      "learning_rate": 1.4934756820877818e-05,
      "loss": 0.0022,
      "step": 1259
    },
    {
      "epoch": 0.07474196227310476,
      "grad_norm": 17.28885269165039,
      "learning_rate": 1.4946619217081853e-05,
      "loss": 0.3104,
      "step": 1260
    },
    {
      "epoch": 0.07480128129078183,
      "grad_norm": 6.777275085449219,
      "learning_rate": 1.4958481613285885e-05,
      "loss": 0.0562,
      "step": 1261
    },
    {
      "epoch": 0.0748606003084589,
      "grad_norm": 8.243762969970703,
      "learning_rate": 1.4970344009489918e-05,
      "loss": 0.0416,
      "step": 1262
    },
    {
      "epoch": 0.07491991932613595,
      "grad_norm": 13.416831970214844,
      "learning_rate": 1.498220640569395e-05,
      "loss": 0.1524,
      "step": 1263
    },
    {
      "epoch": 0.07497923834381302,
      "grad_norm": 9.723966598510742,
      "learning_rate": 1.4994068801897985e-05,
      "loss": 0.1255,
      "step": 1264
    },
    {
      "epoch": 0.0750385573614901,
      "grad_norm": 38.358909606933594,
      "learning_rate": 1.5005931198102017e-05,
      "loss": 0.211,
      "step": 1265
    },
    {
      "epoch": 0.07509787637916716,
      "grad_norm": 53.683982849121094,
      "learning_rate": 1.5017793594306052e-05,
      "loss": 0.208,
      "step": 1266
    },
    {
      "epoch": 0.07515719539684423,
      "grad_norm": 1.2907249927520752,
      "learning_rate": 1.5029655990510084e-05,
      "loss": 0.0106,
      "step": 1267
    },
    {
      "epoch": 0.07521651441452129,
      "grad_norm": 16.85954475402832,
      "learning_rate": 1.5041518386714118e-05,
      "loss": 0.1699,
      "step": 1268
    },
    {
      "epoch": 0.07527583343219836,
      "grad_norm": 32.080631256103516,
      "learning_rate": 1.505338078291815e-05,
      "loss": 0.2798,
      "step": 1269
    },
    {
      "epoch": 0.07533515244987543,
      "grad_norm": 12.638262748718262,
      "learning_rate": 1.5065243179122185e-05,
      "loss": 0.0788,
      "step": 1270
    },
    {
      "epoch": 0.0753944714675525,
      "grad_norm": 3.1483259201049805,
      "learning_rate": 1.5077105575326217e-05,
      "loss": 0.0112,
      "step": 1271
    },
    {
      "epoch": 0.07545379048522956,
      "grad_norm": 2.6410415172576904,
      "learning_rate": 1.508896797153025e-05,
      "loss": 0.0288,
      "step": 1272
    },
    {
      "epoch": 0.07551310950290663,
      "grad_norm": 40.959774017333984,
      "learning_rate": 1.5100830367734282e-05,
      "loss": 0.5087,
      "step": 1273
    },
    {
      "epoch": 0.0755724285205837,
      "grad_norm": 8.112497329711914,
      "learning_rate": 1.5112692763938317e-05,
      "loss": 0.073,
      "step": 1274
    },
    {
      "epoch": 0.07563174753826077,
      "grad_norm": 0.02300712838768959,
      "learning_rate": 1.5124555160142349e-05,
      "loss": 0.0003,
      "step": 1275
    },
    {
      "epoch": 0.07569106655593784,
      "grad_norm": 0.11022944748401642,
      "learning_rate": 1.5136417556346384e-05,
      "loss": 0.0012,
      "step": 1276
    },
    {
      "epoch": 0.0757503855736149,
      "grad_norm": 32.57449722290039,
      "learning_rate": 1.5148279952550416e-05,
      "loss": 0.2738,
      "step": 1277
    },
    {
      "epoch": 0.07580970459129197,
      "grad_norm": 0.059677161276340485,
      "learning_rate": 1.516014234875445e-05,
      "loss": 0.0009,
      "step": 1278
    },
    {
      "epoch": 0.07586902360896904,
      "grad_norm": 0.11898139119148254,
      "learning_rate": 1.5172004744958481e-05,
      "loss": 0.0019,
      "step": 1279
    },
    {
      "epoch": 0.0759283426266461,
      "grad_norm": 19.906143188476562,
      "learning_rate": 1.5183867141162517e-05,
      "loss": 0.8108,
      "step": 1280
    },
    {
      "epoch": 0.07598766164432318,
      "grad_norm": 48.81956100463867,
      "learning_rate": 1.519572953736655e-05,
      "loss": 0.8844,
      "step": 1281
    },
    {
      "epoch": 0.07604698066200023,
      "grad_norm": 0.058698419481515884,
      "learning_rate": 1.5207591933570582e-05,
      "loss": 0.0014,
      "step": 1282
    },
    {
      "epoch": 0.0761062996796773,
      "grad_norm": 0.31658056378364563,
      "learning_rate": 1.5219454329774617e-05,
      "loss": 0.0033,
      "step": 1283
    },
    {
      "epoch": 0.07616561869735437,
      "grad_norm": 30.506547927856445,
      "learning_rate": 1.5231316725978649e-05,
      "loss": 0.6108,
      "step": 1284
    },
    {
      "epoch": 0.07622493771503144,
      "grad_norm": 2.7121076583862305,
      "learning_rate": 1.5243179122182682e-05,
      "loss": 0.0164,
      "step": 1285
    },
    {
      "epoch": 0.0762842567327085,
      "grad_norm": 6.341916561126709,
      "learning_rate": 1.5255041518386714e-05,
      "loss": 0.0446,
      "step": 1286
    },
    {
      "epoch": 0.07634357575038557,
      "grad_norm": 27.696849822998047,
      "learning_rate": 1.526690391459075e-05,
      "loss": 2.4432,
      "step": 1287
    },
    {
      "epoch": 0.07640289476806264,
      "grad_norm": 3.4660208225250244,
      "learning_rate": 1.5278766310794783e-05,
      "loss": 0.0198,
      "step": 1288
    },
    {
      "epoch": 0.07646221378573971,
      "grad_norm": 0.7649022936820984,
      "learning_rate": 1.5290628706998817e-05,
      "loss": 0.0054,
      "step": 1289
    },
    {
      "epoch": 0.07652153280341678,
      "grad_norm": 22.172121047973633,
      "learning_rate": 1.5302491103202847e-05,
      "loss": 0.5822,
      "step": 1290
    },
    {
      "epoch": 0.07658085182109384,
      "grad_norm": 33.457237243652344,
      "learning_rate": 1.5314353499406884e-05,
      "loss": 1.4996,
      "step": 1291
    },
    {
      "epoch": 0.07664017083877091,
      "grad_norm": 9.875329971313477,
      "learning_rate": 1.5326215895610914e-05,
      "loss": 0.0236,
      "step": 1292
    },
    {
      "epoch": 0.07669948985644798,
      "grad_norm": 15.106829643249512,
      "learning_rate": 1.5338078291814947e-05,
      "loss": 0.15,
      "step": 1293
    },
    {
      "epoch": 0.07675880887412505,
      "grad_norm": 20.3529052734375,
      "learning_rate": 1.534994068801898e-05,
      "loss": 0.1923,
      "step": 1294
    },
    {
      "epoch": 0.07681812789180212,
      "grad_norm": 11.930947303771973,
      "learning_rate": 1.5361803084223014e-05,
      "loss": 0.2043,
      "step": 1295
    },
    {
      "epoch": 0.07687744690947917,
      "grad_norm": 23.845746994018555,
      "learning_rate": 1.5373665480427048e-05,
      "loss": 0.6127,
      "step": 1296
    },
    {
      "epoch": 0.07693676592715624,
      "grad_norm": 19.01056480407715,
      "learning_rate": 1.538552787663108e-05,
      "loss": 0.8448,
      "step": 1297
    },
    {
      "epoch": 0.07699608494483332,
      "grad_norm": 1.2873464822769165,
      "learning_rate": 1.5397390272835115e-05,
      "loss": 0.0095,
      "step": 1298
    },
    {
      "epoch": 0.07705540396251039,
      "grad_norm": 59.970638275146484,
      "learning_rate": 1.540925266903915e-05,
      "loss": 0.9174,
      "step": 1299
    },
    {
      "epoch": 0.07711472298018744,
      "grad_norm": 21.17597770690918,
      "learning_rate": 1.542111506524318e-05,
      "loss": 0.2616,
      "step": 1300
    },
    {
      "epoch": 0.07717404199786451,
      "grad_norm": 0.47597113251686096,
      "learning_rate": 1.5432977461447215e-05,
      "loss": 0.0042,
      "step": 1301
    },
    {
      "epoch": 0.07723336101554158,
      "grad_norm": 40.908653259277344,
      "learning_rate": 1.5444839857651245e-05,
      "loss": 0.4106,
      "step": 1302
    },
    {
      "epoch": 0.07729268003321865,
      "grad_norm": 38.855995178222656,
      "learning_rate": 1.545670225385528e-05,
      "loss": 0.5717,
      "step": 1303
    },
    {
      "epoch": 0.07735199905089572,
      "grad_norm": 12.362601280212402,
      "learning_rate": 1.5468564650059313e-05,
      "loss": 0.212,
      "step": 1304
    },
    {
      "epoch": 0.07741131806857278,
      "grad_norm": 5.099349021911621,
      "learning_rate": 1.5480427046263346e-05,
      "loss": 0.0095,
      "step": 1305
    },
    {
      "epoch": 0.07747063708624985,
      "grad_norm": 64.48108673095703,
      "learning_rate": 1.549228944246738e-05,
      "loss": 0.8937,
      "step": 1306
    },
    {
      "epoch": 0.07752995610392692,
      "grad_norm": 1.6135669946670532,
      "learning_rate": 1.5504151838671413e-05,
      "loss": 0.0094,
      "step": 1307
    },
    {
      "epoch": 0.07758927512160399,
      "grad_norm": 24.235734939575195,
      "learning_rate": 1.5516014234875447e-05,
      "loss": 0.2981,
      "step": 1308
    },
    {
      "epoch": 0.07764859413928106,
      "grad_norm": 15.651697158813477,
      "learning_rate": 1.552787663107948e-05,
      "loss": 0.2443,
      "step": 1309
    },
    {
      "epoch": 0.07770791315695812,
      "grad_norm": 4.259941101074219,
      "learning_rate": 1.5539739027283514e-05,
      "loss": 0.2556,
      "step": 1310
    },
    {
      "epoch": 0.07776723217463519,
      "grad_norm": 1.929581642150879,
      "learning_rate": 1.5551601423487547e-05,
      "loss": 0.01,
      "step": 1311
    },
    {
      "epoch": 0.07782655119231226,
      "grad_norm": 36.721736907958984,
      "learning_rate": 1.556346381969158e-05,
      "loss": 0.8798,
      "step": 1312
    },
    {
      "epoch": 0.07788587020998933,
      "grad_norm": 5.359382629394531,
      "learning_rate": 1.557532621589561e-05,
      "loss": 0.0477,
      "step": 1313
    },
    {
      "epoch": 0.07794518922766638,
      "grad_norm": 1.2580050230026245,
      "learning_rate": 1.5587188612099648e-05,
      "loss": 0.0076,
      "step": 1314
    },
    {
      "epoch": 0.07800450824534345,
      "grad_norm": 26.761337280273438,
      "learning_rate": 1.5599051008303678e-05,
      "loss": 0.6661,
      "step": 1315
    },
    {
      "epoch": 0.07806382726302052,
      "grad_norm": 23.205562591552734,
      "learning_rate": 1.561091340450771e-05,
      "loss": 0.2623,
      "step": 1316
    },
    {
      "epoch": 0.0781231462806976,
      "grad_norm": 16.657752990722656,
      "learning_rate": 1.5622775800711745e-05,
      "loss": 0.1799,
      "step": 1317
    },
    {
      "epoch": 0.07818246529837466,
      "grad_norm": 11.744302749633789,
      "learning_rate": 1.563463819691578e-05,
      "loss": 0.3734,
      "step": 1318
    },
    {
      "epoch": 0.07824178431605172,
      "grad_norm": 0.03563367575407028,
      "learning_rate": 1.5646500593119812e-05,
      "loss": 0.0006,
      "step": 1319
    },
    {
      "epoch": 0.07830110333372879,
      "grad_norm": 77.43659973144531,
      "learning_rate": 1.5658362989323845e-05,
      "loss": 1.0697,
      "step": 1320
    },
    {
      "epoch": 0.07836042235140586,
      "grad_norm": 12.180349349975586,
      "learning_rate": 1.567022538552788e-05,
      "loss": 0.3492,
      "step": 1321
    },
    {
      "epoch": 0.07841974136908293,
      "grad_norm": 0.2501111924648285,
      "learning_rate": 1.5682087781731912e-05,
      "loss": 0.0016,
      "step": 1322
    },
    {
      "epoch": 0.07847906038675999,
      "grad_norm": 4.796742916107178,
      "learning_rate": 1.5693950177935943e-05,
      "loss": 0.025,
      "step": 1323
    },
    {
      "epoch": 0.07853837940443706,
      "grad_norm": 29.180137634277344,
      "learning_rate": 1.570581257413998e-05,
      "loss": 1.5159,
      "step": 1324
    },
    {
      "epoch": 0.07859769842211413,
      "grad_norm": 0.3324487805366516,
      "learning_rate": 1.571767497034401e-05,
      "loss": 0.0037,
      "step": 1325
    },
    {
      "epoch": 0.0786570174397912,
      "grad_norm": 7.7234296798706055,
      "learning_rate": 1.5729537366548043e-05,
      "loss": 0.0614,
      "step": 1326
    },
    {
      "epoch": 0.07871633645746827,
      "grad_norm": 23.98431968688965,
      "learning_rate": 1.5741399762752077e-05,
      "loss": 0.459,
      "step": 1327
    },
    {
      "epoch": 0.07877565547514533,
      "grad_norm": 15.544511795043945,
      "learning_rate": 1.575326215895611e-05,
      "loss": 0.0726,
      "step": 1328
    },
    {
      "epoch": 0.0788349744928224,
      "grad_norm": 16.368793487548828,
      "learning_rate": 1.5765124555160144e-05,
      "loss": 1.2675,
      "step": 1329
    },
    {
      "epoch": 0.07889429351049947,
      "grad_norm": 0.44685786962509155,
      "learning_rate": 1.5776986951364177e-05,
      "loss": 0.0026,
      "step": 1330
    },
    {
      "epoch": 0.07895361252817654,
      "grad_norm": 37.221744537353516,
      "learning_rate": 1.578884934756821e-05,
      "loss": 0.2644,
      "step": 1331
    },
    {
      "epoch": 0.0790129315458536,
      "grad_norm": 0.2915516495704651,
      "learning_rate": 1.5800711743772244e-05,
      "loss": 0.0054,
      "step": 1332
    },
    {
      "epoch": 0.07907225056353066,
      "grad_norm": 1.5015426874160767,
      "learning_rate": 1.5812574139976274e-05,
      "loss": 0.0127,
      "step": 1333
    },
    {
      "epoch": 0.07913156958120773,
      "grad_norm": 46.326988220214844,
      "learning_rate": 1.582443653618031e-05,
      "loss": 0.321,
      "step": 1334
    },
    {
      "epoch": 0.0791908885988848,
      "grad_norm": 17.6676025390625,
      "learning_rate": 1.583629893238434e-05,
      "loss": 0.4164,
      "step": 1335
    },
    {
      "epoch": 0.07925020761656187,
      "grad_norm": 3.7917258739471436,
      "learning_rate": 1.5848161328588375e-05,
      "loss": 0.0328,
      "step": 1336
    },
    {
      "epoch": 0.07930952663423893,
      "grad_norm": 0.2841365933418274,
      "learning_rate": 1.586002372479241e-05,
      "loss": 0.0038,
      "step": 1337
    },
    {
      "epoch": 0.079368845651916,
      "grad_norm": 30.840700149536133,
      "learning_rate": 1.5871886120996442e-05,
      "loss": 0.069,
      "step": 1338
    },
    {
      "epoch": 0.07942816466959307,
      "grad_norm": 0.12397275120019913,
      "learning_rate": 1.5883748517200476e-05,
      "loss": 0.002,
      "step": 1339
    },
    {
      "epoch": 0.07948748368727014,
      "grad_norm": 16.876747131347656,
      "learning_rate": 1.589561091340451e-05,
      "loss": 0.5535,
      "step": 1340
    },
    {
      "epoch": 0.07954680270494721,
      "grad_norm": 15.828529357910156,
      "learning_rate": 1.5907473309608543e-05,
      "loss": 0.0983,
      "step": 1341
    },
    {
      "epoch": 0.07960612172262427,
      "grad_norm": 56.72171401977539,
      "learning_rate": 1.5919335705812576e-05,
      "loss": 0.275,
      "step": 1342
    },
    {
      "epoch": 0.07966544074030134,
      "grad_norm": 0.08106275647878647,
      "learning_rate": 1.593119810201661e-05,
      "loss": 0.0008,
      "step": 1343
    },
    {
      "epoch": 0.07972475975797841,
      "grad_norm": 14.11219596862793,
      "learning_rate": 1.5943060498220643e-05,
      "loss": 0.2733,
      "step": 1344
    },
    {
      "epoch": 0.07978407877565548,
      "grad_norm": 3.5140883922576904,
      "learning_rate": 1.5954922894424677e-05,
      "loss": 0.0297,
      "step": 1345
    },
    {
      "epoch": 0.07984339779333255,
      "grad_norm": 0.686621367931366,
      "learning_rate": 1.5966785290628707e-05,
      "loss": 0.0049,
      "step": 1346
    },
    {
      "epoch": 0.0799027168110096,
      "grad_norm": 1.1304664611816406,
      "learning_rate": 1.5978647686832744e-05,
      "loss": 0.0085,
      "step": 1347
    },
    {
      "epoch": 0.07996203582868668,
      "grad_norm": 0.03262392804026604,
      "learning_rate": 1.5990510083036774e-05,
      "loss": 0.0006,
      "step": 1348
    },
    {
      "epoch": 0.08002135484636375,
      "grad_norm": 8.81772518157959,
      "learning_rate": 1.6002372479240807e-05,
      "loss": 0.4071,
      "step": 1349
    },
    {
      "epoch": 0.08008067386404082,
      "grad_norm": 7.615694046020508,
      "learning_rate": 1.601423487544484e-05,
      "loss": 0.185,
      "step": 1350
    },
    {
      "epoch": 0.08013999288171787,
      "grad_norm": 0.2555987238883972,
      "learning_rate": 1.6026097271648874e-05,
      "loss": 0.0022,
      "step": 1351
    },
    {
      "epoch": 0.08019931189939494,
      "grad_norm": 5.536379337310791,
      "learning_rate": 1.6037959667852908e-05,
      "loss": 0.0348,
      "step": 1352
    },
    {
      "epoch": 0.08025863091707201,
      "grad_norm": 14.838717460632324,
      "learning_rate": 1.604982206405694e-05,
      "loss": 0.3475,
      "step": 1353
    },
    {
      "epoch": 0.08031794993474908,
      "grad_norm": 14.674931526184082,
      "learning_rate": 1.6061684460260975e-05,
      "loss": 0.7277,
      "step": 1354
    },
    {
      "epoch": 0.08037726895242615,
      "grad_norm": 0.6068735122680664,
      "learning_rate": 1.607354685646501e-05,
      "loss": 0.0061,
      "step": 1355
    },
    {
      "epoch": 0.08043658797010321,
      "grad_norm": 1.1393228769302368,
      "learning_rate": 1.608540925266904e-05,
      "loss": 0.0092,
      "step": 1356
    },
    {
      "epoch": 0.08049590698778028,
      "grad_norm": 10.069403648376465,
      "learning_rate": 1.6097271648873075e-05,
      "loss": 0.0308,
      "step": 1357
    },
    {
      "epoch": 0.08055522600545735,
      "grad_norm": 11.253527641296387,
      "learning_rate": 1.6109134045077106e-05,
      "loss": 0.1225,
      "step": 1358
    },
    {
      "epoch": 0.08061454502313442,
      "grad_norm": 0.3317014276981354,
      "learning_rate": 1.612099644128114e-05,
      "loss": 0.0032,
      "step": 1359
    },
    {
      "epoch": 0.08067386404081149,
      "grad_norm": 0.11758706718683243,
      "learning_rate": 1.6132858837485173e-05,
      "loss": 0.002,
      "step": 1360
    },
    {
      "epoch": 0.08073318305848855,
      "grad_norm": 33.58361053466797,
      "learning_rate": 1.6144721233689206e-05,
      "loss": 1.1691,
      "step": 1361
    },
    {
      "epoch": 0.08079250207616562,
      "grad_norm": 1.136061191558838,
      "learning_rate": 1.615658362989324e-05,
      "loss": 0.0085,
      "step": 1362
    },
    {
      "epoch": 0.08085182109384269,
      "grad_norm": 62.17837142944336,
      "learning_rate": 1.6168446026097273e-05,
      "loss": 0.3306,
      "step": 1363
    },
    {
      "epoch": 0.08091114011151976,
      "grad_norm": 36.586429595947266,
      "learning_rate": 1.6180308422301307e-05,
      "loss": 0.7473,
      "step": 1364
    },
    {
      "epoch": 0.08097045912919681,
      "grad_norm": 14.333422660827637,
      "learning_rate": 1.619217081850534e-05,
      "loss": 0.3276,
      "step": 1365
    },
    {
      "epoch": 0.08102977814687388,
      "grad_norm": 27.28018569946289,
      "learning_rate": 1.620403321470937e-05,
      "loss": 1.2975,
      "step": 1366
    },
    {
      "epoch": 0.08108909716455096,
      "grad_norm": 4.022741317749023,
      "learning_rate": 1.6215895610913407e-05,
      "loss": 0.0254,
      "step": 1367
    },
    {
      "epoch": 0.08114841618222803,
      "grad_norm": 11.384842872619629,
      "learning_rate": 1.622775800711744e-05,
      "loss": 0.149,
      "step": 1368
    },
    {
      "epoch": 0.0812077351999051,
      "grad_norm": 3.9177050590515137,
      "learning_rate": 1.623962040332147e-05,
      "loss": 0.0251,
      "step": 1369
    },
    {
      "epoch": 0.08126705421758215,
      "grad_norm": 22.706317901611328,
      "learning_rate": 1.6251482799525508e-05,
      "loss": 0.1312,
      "step": 1370
    },
    {
      "epoch": 0.08132637323525922,
      "grad_norm": 0.25760555267333984,
      "learning_rate": 1.6263345195729538e-05,
      "loss": 0.0042,
      "step": 1371
    },
    {
      "epoch": 0.08138569225293629,
      "grad_norm": 0.12682083249092102,
      "learning_rate": 1.627520759193357e-05,
      "loss": 0.0017,
      "step": 1372
    },
    {
      "epoch": 0.08144501127061336,
      "grad_norm": 0.4941398799419403,
      "learning_rate": 1.6287069988137605e-05,
      "loss": 0.0067,
      "step": 1373
    },
    {
      "epoch": 0.08150433028829042,
      "grad_norm": 0.3227140009403229,
      "learning_rate": 1.629893238434164e-05,
      "loss": 0.003,
      "step": 1374
    },
    {
      "epoch": 0.08156364930596749,
      "grad_norm": 30.722877502441406,
      "learning_rate": 1.6310794780545672e-05,
      "loss": 0.6072,
      "step": 1375
    },
    {
      "epoch": 0.08162296832364456,
      "grad_norm": 21.03399085998535,
      "learning_rate": 1.6322657176749706e-05,
      "loss": 0.4847,
      "step": 1376
    },
    {
      "epoch": 0.08168228734132163,
      "grad_norm": 10.967559814453125,
      "learning_rate": 1.633451957295374e-05,
      "loss": 0.0792,
      "step": 1377
    },
    {
      "epoch": 0.0817416063589987,
      "grad_norm": 6.243692398071289,
      "learning_rate": 1.6346381969157773e-05,
      "loss": 0.0413,
      "step": 1378
    },
    {
      "epoch": 0.08180092537667576,
      "grad_norm": 20.163318634033203,
      "learning_rate": 1.6358244365361803e-05,
      "loss": 0.1139,
      "step": 1379
    },
    {
      "epoch": 0.08186024439435283,
      "grad_norm": 55.12126159667969,
      "learning_rate": 1.637010676156584e-05,
      "loss": 1.173,
      "step": 1380
    },
    {
      "epoch": 0.0819195634120299,
      "grad_norm": 17.338436126708984,
      "learning_rate": 1.638196915776987e-05,
      "loss": 0.301,
      "step": 1381
    },
    {
      "epoch": 0.08197888242970697,
      "grad_norm": 29.925979614257812,
      "learning_rate": 1.6393831553973903e-05,
      "loss": 0.5851,
      "step": 1382
    },
    {
      "epoch": 0.08203820144738404,
      "grad_norm": 0.3071501553058624,
      "learning_rate": 1.6405693950177937e-05,
      "loss": 0.0035,
      "step": 1383
    },
    {
      "epoch": 0.0820975204650611,
      "grad_norm": 3.931917190551758,
      "learning_rate": 1.641755634638197e-05,
      "loss": 0.0233,
      "step": 1384
    },
    {
      "epoch": 0.08215683948273816,
      "grad_norm": 3.978389263153076,
      "learning_rate": 1.6429418742586004e-05,
      "loss": 0.0373,
      "step": 1385
    },
    {
      "epoch": 0.08221615850041523,
      "grad_norm": 0.1476312130689621,
      "learning_rate": 1.6441281138790037e-05,
      "loss": 0.0017,
      "step": 1386
    },
    {
      "epoch": 0.0822754775180923,
      "grad_norm": 0.12608087062835693,
      "learning_rate": 1.645314353499407e-05,
      "loss": 0.0025,
      "step": 1387
    },
    {
      "epoch": 0.08233479653576936,
      "grad_norm": 0.1761361062526703,
      "learning_rate": 1.6465005931198104e-05,
      "loss": 0.0011,
      "step": 1388
    },
    {
      "epoch": 0.08239411555344643,
      "grad_norm": 6.1986589431762695,
      "learning_rate": 1.6476868327402135e-05,
      "loss": 0.0724,
      "step": 1389
    },
    {
      "epoch": 0.0824534345711235,
      "grad_norm": 5.750641345977783,
      "learning_rate": 1.648873072360617e-05,
      "loss": 0.0622,
      "step": 1390
    },
    {
      "epoch": 0.08251275358880057,
      "grad_norm": 17.110126495361328,
      "learning_rate": 1.65005931198102e-05,
      "loss": 0.3679,
      "step": 1391
    },
    {
      "epoch": 0.08257207260647764,
      "grad_norm": 32.56341552734375,
      "learning_rate": 1.6512455516014235e-05,
      "loss": 1.4581,
      "step": 1392
    },
    {
      "epoch": 0.0826313916241547,
      "grad_norm": 38.118568420410156,
      "learning_rate": 1.652431791221827e-05,
      "loss": 1.1514,
      "step": 1393
    },
    {
      "epoch": 0.08269071064183177,
      "grad_norm": 0.21723169088363647,
      "learning_rate": 1.6536180308422302e-05,
      "loss": 0.002,
      "step": 1394
    },
    {
      "epoch": 0.08275002965950884,
      "grad_norm": 0.05001446604728699,
      "learning_rate": 1.6548042704626336e-05,
      "loss": 0.0008,
      "step": 1395
    },
    {
      "epoch": 0.08280934867718591,
      "grad_norm": 6.0511155128479,
      "learning_rate": 1.655990510083037e-05,
      "loss": 0.0501,
      "step": 1396
    },
    {
      "epoch": 0.08286866769486298,
      "grad_norm": 1.149936556816101,
      "learning_rate": 1.6571767497034403e-05,
      "loss": 0.0117,
      "step": 1397
    },
    {
      "epoch": 0.08292798671254004,
      "grad_norm": 13.991877555847168,
      "learning_rate": 1.6583629893238436e-05,
      "loss": 0.1983,
      "step": 1398
    },
    {
      "epoch": 0.0829873057302171,
      "grad_norm": 12.481038093566895,
      "learning_rate": 1.659549228944247e-05,
      "loss": 0.4337,
      "step": 1399
    },
    {
      "epoch": 0.08304662474789418,
      "grad_norm": 6.512905120849609,
      "learning_rate": 1.6607354685646503e-05,
      "loss": 0.0936,
      "step": 1400
    },
    {
      "epoch": 0.08310594376557125,
      "grad_norm": 4.430333614349365,
      "learning_rate": 1.6619217081850537e-05,
      "loss": 0.0658,
      "step": 1401
    },
    {
      "epoch": 0.0831652627832483,
      "grad_norm": 0.29709136486053467,
      "learning_rate": 1.6631079478054567e-05,
      "loss": 0.0041,
      "step": 1402
    },
    {
      "epoch": 0.08322458180092537,
      "grad_norm": 8.820489883422852,
      "learning_rate": 1.6642941874258604e-05,
      "loss": 0.1036,
      "step": 1403
    },
    {
      "epoch": 0.08328390081860244,
      "grad_norm": 10.66254997253418,
      "learning_rate": 1.6654804270462634e-05,
      "loss": 0.181,
      "step": 1404
    },
    {
      "epoch": 0.08334321983627951,
      "grad_norm": 19.5769100189209,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.2801,
      "step": 1405
    },
    {
      "epoch": 0.08340253885395658,
      "grad_norm": 77.5624771118164,
      "learning_rate": 1.66785290628707e-05,
      "loss": 1.9346,
      "step": 1406
    },
    {
      "epoch": 0.08346185787163364,
      "grad_norm": 3.0345728397369385,
      "learning_rate": 1.6690391459074735e-05,
      "loss": 0.0233,
      "step": 1407
    },
    {
      "epoch": 0.08352117688931071,
      "grad_norm": 0.46794891357421875,
      "learning_rate": 1.6702253855278768e-05,
      "loss": 0.0035,
      "step": 1408
    },
    {
      "epoch": 0.08358049590698778,
      "grad_norm": 0.012665621004998684,
      "learning_rate": 1.67141162514828e-05,
      "loss": 0.0002,
      "step": 1409
    },
    {
      "epoch": 0.08363981492466485,
      "grad_norm": 16.8698787689209,
      "learning_rate": 1.6725978647686835e-05,
      "loss": 0.4018,
      "step": 1410
    },
    {
      "epoch": 0.08369913394234192,
      "grad_norm": 0.02239040657877922,
      "learning_rate": 1.673784104389087e-05,
      "loss": 0.0006,
      "step": 1411
    },
    {
      "epoch": 0.08375845296001898,
      "grad_norm": 0.703155517578125,
      "learning_rate": 1.67497034400949e-05,
      "loss": 0.0056,
      "step": 1412
    },
    {
      "epoch": 0.08381777197769605,
      "grad_norm": 0.9392409324645996,
      "learning_rate": 1.6761565836298936e-05,
      "loss": 0.0035,
      "step": 1413
    },
    {
      "epoch": 0.08387709099537312,
      "grad_norm": 23.832542419433594,
      "learning_rate": 1.6773428232502966e-05,
      "loss": 0.3101,
      "step": 1414
    },
    {
      "epoch": 0.08393641001305019,
      "grad_norm": 6.020526885986328,
      "learning_rate": 1.6785290628707e-05,
      "loss": 0.4358,
      "step": 1415
    },
    {
      "epoch": 0.08399572903072725,
      "grad_norm": 15.8089599609375,
      "learning_rate": 1.6797153024911033e-05,
      "loss": 0.0908,
      "step": 1416
    },
    {
      "epoch": 0.08405504804840432,
      "grad_norm": 24.33116340637207,
      "learning_rate": 1.6809015421115066e-05,
      "loss": 0.2305,
      "step": 1417
    },
    {
      "epoch": 0.08411436706608139,
      "grad_norm": 0.23441648483276367,
      "learning_rate": 1.68208778173191e-05,
      "loss": 0.0038,
      "step": 1418
    },
    {
      "epoch": 0.08417368608375846,
      "grad_norm": 11.875021934509277,
      "learning_rate": 1.6832740213523133e-05,
      "loss": 0.1312,
      "step": 1419
    },
    {
      "epoch": 0.08423300510143553,
      "grad_norm": 7.752817630767822,
      "learning_rate": 1.6844602609727167e-05,
      "loss": 0.1018,
      "step": 1420
    },
    {
      "epoch": 0.08429232411911258,
      "grad_norm": 0.09054528176784515,
      "learning_rate": 1.68564650059312e-05,
      "loss": 0.0015,
      "step": 1421
    },
    {
      "epoch": 0.08435164313678965,
      "grad_norm": 31.19590950012207,
      "learning_rate": 1.686832740213523e-05,
      "loss": 0.4416,
      "step": 1422
    },
    {
      "epoch": 0.08441096215446672,
      "grad_norm": 3.9847586154937744,
      "learning_rate": 1.6880189798339267e-05,
      "loss": 0.0264,
      "step": 1423
    },
    {
      "epoch": 0.0844702811721438,
      "grad_norm": 39.647457122802734,
      "learning_rate": 1.6892052194543298e-05,
      "loss": 0.8452,
      "step": 1424
    },
    {
      "epoch": 0.08452960018982085,
      "grad_norm": 0.14843367040157318,
      "learning_rate": 1.690391459074733e-05,
      "loss": 0.0014,
      "step": 1425
    },
    {
      "epoch": 0.08458891920749792,
      "grad_norm": 17.47109603881836,
      "learning_rate": 1.6915776986951368e-05,
      "loss": 0.2771,
      "step": 1426
    },
    {
      "epoch": 0.08464823822517499,
      "grad_norm": 1.521654725074768,
      "learning_rate": 1.6927639383155398e-05,
      "loss": 0.0106,
      "step": 1427
    },
    {
      "epoch": 0.08470755724285206,
      "grad_norm": 11.617274284362793,
      "learning_rate": 1.693950177935943e-05,
      "loss": 0.0894,
      "step": 1428
    },
    {
      "epoch": 0.08476687626052913,
      "grad_norm": 0.08130993694067001,
      "learning_rate": 1.6951364175563465e-05,
      "loss": 0.0007,
      "step": 1429
    },
    {
      "epoch": 0.08482619527820619,
      "grad_norm": 0.9832998514175415,
      "learning_rate": 1.69632265717675e-05,
      "loss": 0.0072,
      "step": 1430
    },
    {
      "epoch": 0.08488551429588326,
      "grad_norm": 13.244735717773438,
      "learning_rate": 1.6975088967971532e-05,
      "loss": 0.3435,
      "step": 1431
    },
    {
      "epoch": 0.08494483331356033,
      "grad_norm": 1.7909623384475708,
      "learning_rate": 1.6986951364175566e-05,
      "loss": 0.0097,
      "step": 1432
    },
    {
      "epoch": 0.0850041523312374,
      "grad_norm": 17.142253875732422,
      "learning_rate": 1.69988137603796e-05,
      "loss": 0.0938,
      "step": 1433
    },
    {
      "epoch": 0.08506347134891447,
      "grad_norm": 0.48574191331863403,
      "learning_rate": 1.7010676156583633e-05,
      "loss": 0.0021,
      "step": 1434
    },
    {
      "epoch": 0.08512279036659152,
      "grad_norm": 21.268102645874023,
      "learning_rate": 1.7022538552787663e-05,
      "loss": 0.4579,
      "step": 1435
    },
    {
      "epoch": 0.0851821093842686,
      "grad_norm": 4.850008487701416,
      "learning_rate": 1.70344009489917e-05,
      "loss": 0.0713,
      "step": 1436
    },
    {
      "epoch": 0.08524142840194567,
      "grad_norm": 15.165351867675781,
      "learning_rate": 1.704626334519573e-05,
      "loss": 1.0853,
      "step": 1437
    },
    {
      "epoch": 0.08530074741962274,
      "grad_norm": 0.08300740271806717,
      "learning_rate": 1.7058125741399763e-05,
      "loss": 0.0011,
      "step": 1438
    },
    {
      "epoch": 0.08536006643729979,
      "grad_norm": 23.336362838745117,
      "learning_rate": 1.7069988137603797e-05,
      "loss": 0.3386,
      "step": 1439
    },
    {
      "epoch": 0.08541938545497686,
      "grad_norm": 172.85350036621094,
      "learning_rate": 1.708185053380783e-05,
      "loss": 0.8291,
      "step": 1440
    },
    {
      "epoch": 0.08547870447265393,
      "grad_norm": 8.309820175170898,
      "learning_rate": 1.7093712930011864e-05,
      "loss": 0.1871,
      "step": 1441
    },
    {
      "epoch": 0.085538023490331,
      "grad_norm": 4.5683183670043945,
      "learning_rate": 1.7105575326215898e-05,
      "loss": 0.1141,
      "step": 1442
    },
    {
      "epoch": 0.08559734250800807,
      "grad_norm": 11.291071891784668,
      "learning_rate": 1.711743772241993e-05,
      "loss": 0.1479,
      "step": 1443
    },
    {
      "epoch": 0.08565666152568513,
      "grad_norm": 0.807441234588623,
      "learning_rate": 1.7129300118623965e-05,
      "loss": 0.0078,
      "step": 1444
    },
    {
      "epoch": 0.0857159805433622,
      "grad_norm": 0.20232856273651123,
      "learning_rate": 1.7141162514827995e-05,
      "loss": 0.0016,
      "step": 1445
    },
    {
      "epoch": 0.08577529956103927,
      "grad_norm": 33.591949462890625,
      "learning_rate": 1.715302491103203e-05,
      "loss": 1.2988,
      "step": 1446
    },
    {
      "epoch": 0.08583461857871634,
      "grad_norm": 10.82215404510498,
      "learning_rate": 1.7164887307236062e-05,
      "loss": 0.2971,
      "step": 1447
    },
    {
      "epoch": 0.08589393759639341,
      "grad_norm": 0.049761101603507996,
      "learning_rate": 1.7176749703440095e-05,
      "loss": 0.001,
      "step": 1448
    },
    {
      "epoch": 0.08595325661407047,
      "grad_norm": 0.14870424568653107,
      "learning_rate": 1.718861209964413e-05,
      "loss": 0.0034,
      "step": 1449
    },
    {
      "epoch": 0.08601257563174754,
      "grad_norm": 30.798538208007812,
      "learning_rate": 1.7200474495848162e-05,
      "loss": 0.5554,
      "step": 1450
    },
    {
      "epoch": 0.08607189464942461,
      "grad_norm": 24.774812698364258,
      "learning_rate": 1.7212336892052196e-05,
      "loss": 0.2934,
      "step": 1451
    },
    {
      "epoch": 0.08613121366710168,
      "grad_norm": 17.81491470336914,
      "learning_rate": 1.722419928825623e-05,
      "loss": 0.1738,
      "step": 1452
    },
    {
      "epoch": 0.08619053268477873,
      "grad_norm": 56.667911529541016,
      "learning_rate": 1.7236061684460263e-05,
      "loss": 0.3297,
      "step": 1453
    },
    {
      "epoch": 0.0862498517024558,
      "grad_norm": 18.597761154174805,
      "learning_rate": 1.7247924080664296e-05,
      "loss": 1.3927,
      "step": 1454
    },
    {
      "epoch": 0.08630917072013287,
      "grad_norm": 2.8981130123138428,
      "learning_rate": 1.725978647686833e-05,
      "loss": 0.0119,
      "step": 1455
    },
    {
      "epoch": 0.08636848973780994,
      "grad_norm": 21.546859741210938,
      "learning_rate": 1.7271648873072363e-05,
      "loss": 1.2718,
      "step": 1456
    },
    {
      "epoch": 0.08642780875548702,
      "grad_norm": 4.238037586212158,
      "learning_rate": 1.7283511269276397e-05,
      "loss": 0.0268,
      "step": 1457
    },
    {
      "epoch": 0.08648712777316407,
      "grad_norm": 10.701045036315918,
      "learning_rate": 1.7295373665480427e-05,
      "loss": 0.3301,
      "step": 1458
    },
    {
      "epoch": 0.08654644679084114,
      "grad_norm": 15.507437705993652,
      "learning_rate": 1.7307236061684464e-05,
      "loss": 0.1971,
      "step": 1459
    },
    {
      "epoch": 0.08660576580851821,
      "grad_norm": 3.0848283767700195,
      "learning_rate": 1.7319098457888494e-05,
      "loss": 0.0419,
      "step": 1460
    },
    {
      "epoch": 0.08666508482619528,
      "grad_norm": 37.58503341674805,
      "learning_rate": 1.7330960854092528e-05,
      "loss": 1.9368,
      "step": 1461
    },
    {
      "epoch": 0.08672440384387234,
      "grad_norm": 7.260544776916504,
      "learning_rate": 1.734282325029656e-05,
      "loss": 0.1668,
      "step": 1462
    },
    {
      "epoch": 0.08678372286154941,
      "grad_norm": 1.2020487785339355,
      "learning_rate": 1.7354685646500595e-05,
      "loss": 0.0115,
      "step": 1463
    },
    {
      "epoch": 0.08684304187922648,
      "grad_norm": 1.5683385133743286,
      "learning_rate": 1.7366548042704628e-05,
      "loss": 0.0103,
      "step": 1464
    },
    {
      "epoch": 0.08690236089690355,
      "grad_norm": 2.7946743965148926,
      "learning_rate": 1.737841043890866e-05,
      "loss": 0.018,
      "step": 1465
    },
    {
      "epoch": 0.08696167991458062,
      "grad_norm": 6.198267936706543,
      "learning_rate": 1.7390272835112695e-05,
      "loss": 0.3223,
      "step": 1466
    },
    {
      "epoch": 0.08702099893225768,
      "grad_norm": 10.761144638061523,
      "learning_rate": 1.740213523131673e-05,
      "loss": 0.0915,
      "step": 1467
    },
    {
      "epoch": 0.08708031794993475,
      "grad_norm": 12.172670364379883,
      "learning_rate": 1.741399762752076e-05,
      "loss": 0.2899,
      "step": 1468
    },
    {
      "epoch": 0.08713963696761182,
      "grad_norm": 1.2943528890609741,
      "learning_rate": 1.7425860023724796e-05,
      "loss": 0.012,
      "step": 1469
    },
    {
      "epoch": 0.08719895598528889,
      "grad_norm": 0.2490861415863037,
      "learning_rate": 1.7437722419928826e-05,
      "loss": 0.004,
      "step": 1470
    },
    {
      "epoch": 0.08725827500296596,
      "grad_norm": 0.13737402856349945,
      "learning_rate": 1.744958481613286e-05,
      "loss": 0.0018,
      "step": 1471
    },
    {
      "epoch": 0.08731759402064301,
      "grad_norm": 0.014497684314846992,
      "learning_rate": 1.7461447212336893e-05,
      "loss": 0.0004,
      "step": 1472
    },
    {
      "epoch": 0.08737691303832008,
      "grad_norm": 28.442256927490234,
      "learning_rate": 1.7473309608540926e-05,
      "loss": 0.4808,
      "step": 1473
    },
    {
      "epoch": 0.08743623205599715,
      "grad_norm": 2.594871997833252,
      "learning_rate": 1.748517200474496e-05,
      "loss": 0.0265,
      "step": 1474
    },
    {
      "epoch": 0.08749555107367422,
      "grad_norm": 36.25309753417969,
      "learning_rate": 1.7497034400948993e-05,
      "loss": 1.3276,
      "step": 1475
    },
    {
      "epoch": 0.08755487009135128,
      "grad_norm": 5.467010021209717,
      "learning_rate": 1.7508896797153027e-05,
      "loss": 0.126,
      "step": 1476
    },
    {
      "epoch": 0.08761418910902835,
      "grad_norm": 11.147406578063965,
      "learning_rate": 1.752075919335706e-05,
      "loss": 0.1215,
      "step": 1477
    },
    {
      "epoch": 0.08767350812670542,
      "grad_norm": 18.546913146972656,
      "learning_rate": 1.753262158956109e-05,
      "loss": 0.1854,
      "step": 1478
    },
    {
      "epoch": 0.08773282714438249,
      "grad_norm": 29.768585205078125,
      "learning_rate": 1.7544483985765128e-05,
      "loss": 0.135,
      "step": 1479
    },
    {
      "epoch": 0.08779214616205956,
      "grad_norm": 39.18537902832031,
      "learning_rate": 1.7556346381969158e-05,
      "loss": 0.8275,
      "step": 1480
    },
    {
      "epoch": 0.08785146517973662,
      "grad_norm": 43.045440673828125,
      "learning_rate": 1.756820877817319e-05,
      "loss": 0.1975,
      "step": 1481
    },
    {
      "epoch": 0.08791078419741369,
      "grad_norm": 0.058604199439287186,
      "learning_rate": 1.7580071174377225e-05,
      "loss": 0.001,
      "step": 1482
    },
    {
      "epoch": 0.08797010321509076,
      "grad_norm": 7.131133556365967,
      "learning_rate": 1.7591933570581258e-05,
      "loss": 0.0337,
      "step": 1483
    },
    {
      "epoch": 0.08802942223276783,
      "grad_norm": 1.926883578300476,
      "learning_rate": 1.7603795966785292e-05,
      "loss": 0.0127,
      "step": 1484
    },
    {
      "epoch": 0.0880887412504449,
      "grad_norm": 10.195069313049316,
      "learning_rate": 1.7615658362989325e-05,
      "loss": 0.0924,
      "step": 1485
    },
    {
      "epoch": 0.08814806026812196,
      "grad_norm": 13.915552139282227,
      "learning_rate": 1.762752075919336e-05,
      "loss": 0.3916,
      "step": 1486
    },
    {
      "epoch": 0.08820737928579903,
      "grad_norm": 0.036177728325128555,
      "learning_rate": 1.7639383155397392e-05,
      "loss": 0.0009,
      "step": 1487
    },
    {
      "epoch": 0.0882666983034761,
      "grad_norm": 17.64438247680664,
      "learning_rate": 1.7651245551601426e-05,
      "loss": 0.377,
      "step": 1488
    },
    {
      "epoch": 0.08832601732115317,
      "grad_norm": 1.8000324964523315,
      "learning_rate": 1.766310794780546e-05,
      "loss": 0.0119,
      "step": 1489
    },
    {
      "epoch": 0.08838533633883022,
      "grad_norm": 3.939382791519165,
      "learning_rate": 1.7674970344009493e-05,
      "loss": 0.1319,
      "step": 1490
    },
    {
      "epoch": 0.08844465535650729,
      "grad_norm": 1.4927421808242798,
      "learning_rate": 1.7686832740213523e-05,
      "loss": 0.0171,
      "step": 1491
    },
    {
      "epoch": 0.08850397437418436,
      "grad_norm": 11.370841979980469,
      "learning_rate": 1.769869513641756e-05,
      "loss": 0.0978,
      "step": 1492
    },
    {
      "epoch": 0.08856329339186143,
      "grad_norm": 6.561331272125244,
      "learning_rate": 1.771055753262159e-05,
      "loss": 0.1126,
      "step": 1493
    },
    {
      "epoch": 0.0886226124095385,
      "grad_norm": 16.648529052734375,
      "learning_rate": 1.7722419928825624e-05,
      "loss": 0.7205,
      "step": 1494
    },
    {
      "epoch": 0.08868193142721556,
      "grad_norm": 24.68693733215332,
      "learning_rate": 1.7734282325029657e-05,
      "loss": 0.4554,
      "step": 1495
    },
    {
      "epoch": 0.08874125044489263,
      "grad_norm": 85.7117919921875,
      "learning_rate": 1.774614472123369e-05,
      "loss": 1.1654,
      "step": 1496
    },
    {
      "epoch": 0.0888005694625697,
      "grad_norm": 0.5174915194511414,
      "learning_rate": 1.7758007117437724e-05,
      "loss": 0.0067,
      "step": 1497
    },
    {
      "epoch": 0.08885988848024677,
      "grad_norm": 44.898345947265625,
      "learning_rate": 1.7769869513641758e-05,
      "loss": 0.4934,
      "step": 1498
    },
    {
      "epoch": 0.08891920749792384,
      "grad_norm": 8.671782493591309,
      "learning_rate": 1.778173190984579e-05,
      "loss": 0.0636,
      "step": 1499
    },
    {
      "epoch": 0.0889785265156009,
      "grad_norm": 10.578588485717773,
      "learning_rate": 1.7793594306049825e-05,
      "loss": 0.0745,
      "step": 1500
    },
    {
      "epoch": 0.08903784553327797,
      "grad_norm": 18.21291732788086,
      "learning_rate": 1.7805456702253855e-05,
      "loss": 0.6368,
      "step": 1501
    },
    {
      "epoch": 0.08909716455095504,
      "grad_norm": 1.0364267826080322,
      "learning_rate": 1.7817319098457892e-05,
      "loss": 0.0098,
      "step": 1502
    },
    {
      "epoch": 0.08915648356863211,
      "grad_norm": 0.22792945802211761,
      "learning_rate": 1.7829181494661922e-05,
      "loss": 0.0042,
      "step": 1503
    },
    {
      "epoch": 0.08921580258630916,
      "grad_norm": 9.437804222106934,
      "learning_rate": 1.7841043890865955e-05,
      "loss": 0.0224,
      "step": 1504
    },
    {
      "epoch": 0.08927512160398623,
      "grad_norm": 2.83115816116333,
      "learning_rate": 1.785290628706999e-05,
      "loss": 0.0196,
      "step": 1505
    },
    {
      "epoch": 0.0893344406216633,
      "grad_norm": 18.607574462890625,
      "learning_rate": 1.7864768683274022e-05,
      "loss": 1.3485,
      "step": 1506
    },
    {
      "epoch": 0.08939375963934038,
      "grad_norm": 25.58161163330078,
      "learning_rate": 1.7876631079478056e-05,
      "loss": 0.2837,
      "step": 1507
    },
    {
      "epoch": 0.08945307865701745,
      "grad_norm": 30.212848663330078,
      "learning_rate": 1.788849347568209e-05,
      "loss": 0.1528,
      "step": 1508
    },
    {
      "epoch": 0.0895123976746945,
      "grad_norm": 5.709510326385498,
      "learning_rate": 1.7900355871886123e-05,
      "loss": 0.22,
      "step": 1509
    },
    {
      "epoch": 0.08957171669237157,
      "grad_norm": 27.63766098022461,
      "learning_rate": 1.7912218268090156e-05,
      "loss": 0.1913,
      "step": 1510
    },
    {
      "epoch": 0.08963103571004864,
      "grad_norm": 3.076416254043579,
      "learning_rate": 1.7924080664294187e-05,
      "loss": 0.0371,
      "step": 1511
    },
    {
      "epoch": 0.08969035472772571,
      "grad_norm": 19.72402572631836,
      "learning_rate": 1.7935943060498224e-05,
      "loss": 1.2456,
      "step": 1512
    },
    {
      "epoch": 0.08974967374540277,
      "grad_norm": 16.93409538269043,
      "learning_rate": 1.7947805456702257e-05,
      "loss": 1.2878,
      "step": 1513
    },
    {
      "epoch": 0.08980899276307984,
      "grad_norm": 13.027085304260254,
      "learning_rate": 1.7959667852906287e-05,
      "loss": 0.0998,
      "step": 1514
    },
    {
      "epoch": 0.08986831178075691,
      "grad_norm": 1.9249799251556396,
      "learning_rate": 1.7971530249110324e-05,
      "loss": 0.0129,
      "step": 1515
    },
    {
      "epoch": 0.08992763079843398,
      "grad_norm": 25.725130081176758,
      "learning_rate": 1.7983392645314354e-05,
      "loss": 0.9077,
      "step": 1516
    },
    {
      "epoch": 0.08998694981611105,
      "grad_norm": 17.19769859313965,
      "learning_rate": 1.7995255041518388e-05,
      "loss": 0.0948,
      "step": 1517
    },
    {
      "epoch": 0.0900462688337881,
      "grad_norm": 12.85191822052002,
      "learning_rate": 1.800711743772242e-05,
      "loss": 1.1318,
      "step": 1518
    },
    {
      "epoch": 0.09010558785146518,
      "grad_norm": 4.928990364074707,
      "learning_rate": 1.8018979833926455e-05,
      "loss": 0.0594,
      "step": 1519
    },
    {
      "epoch": 0.09016490686914225,
      "grad_norm": 0.23634512722492218,
      "learning_rate": 1.8030842230130488e-05,
      "loss": 0.0035,
      "step": 1520
    },
    {
      "epoch": 0.09022422588681932,
      "grad_norm": 9.06618881225586,
      "learning_rate": 1.8042704626334522e-05,
      "loss": 0.0592,
      "step": 1521
    },
    {
      "epoch": 0.09028354490449639,
      "grad_norm": 0.3832463324069977,
      "learning_rate": 1.8054567022538555e-05,
      "loss": 0.0075,
      "step": 1522
    },
    {
      "epoch": 0.09034286392217344,
      "grad_norm": 24.251955032348633,
      "learning_rate": 1.806642941874259e-05,
      "loss": 0.1326,
      "step": 1523
    },
    {
      "epoch": 0.09040218293985051,
      "grad_norm": 1.8708393573760986,
      "learning_rate": 1.807829181494662e-05,
      "loss": 0.0118,
      "step": 1524
    },
    {
      "epoch": 0.09046150195752758,
      "grad_norm": 19.719892501831055,
      "learning_rate": 1.8090154211150656e-05,
      "loss": 0.1217,
      "step": 1525
    },
    {
      "epoch": 0.09052082097520465,
      "grad_norm": 0.025911465287208557,
      "learning_rate": 1.8102016607354686e-05,
      "loss": 0.0006,
      "step": 1526
    },
    {
      "epoch": 0.09058013999288171,
      "grad_norm": 8.005026817321777,
      "learning_rate": 1.811387900355872e-05,
      "loss": 0.5012,
      "step": 1527
    },
    {
      "epoch": 0.09063945901055878,
      "grad_norm": 0.8014708757400513,
      "learning_rate": 1.8125741399762753e-05,
      "loss": 0.0057,
      "step": 1528
    },
    {
      "epoch": 0.09069877802823585,
      "grad_norm": 17.997146606445312,
      "learning_rate": 1.8137603795966787e-05,
      "loss": 0.1513,
      "step": 1529
    },
    {
      "epoch": 0.09075809704591292,
      "grad_norm": 0.33291110396385193,
      "learning_rate": 1.814946619217082e-05,
      "loss": 0.0043,
      "step": 1530
    },
    {
      "epoch": 0.09081741606358999,
      "grad_norm": 15.016409873962402,
      "learning_rate": 1.8161328588374854e-05,
      "loss": 0.1004,
      "step": 1531
    },
    {
      "epoch": 0.09087673508126705,
      "grad_norm": 0.08719605952501297,
      "learning_rate": 1.8173190984578887e-05,
      "loss": 0.0014,
      "step": 1532
    },
    {
      "epoch": 0.09093605409894412,
      "grad_norm": 4.3764262199401855,
      "learning_rate": 1.818505338078292e-05,
      "loss": 0.0385,
      "step": 1533
    },
    {
      "epoch": 0.09099537311662119,
      "grad_norm": 6.816816329956055,
      "learning_rate": 1.819691577698695e-05,
      "loss": 0.2171,
      "step": 1534
    },
    {
      "epoch": 0.09105469213429826,
      "grad_norm": 0.01853402517735958,
      "learning_rate": 1.8208778173190988e-05,
      "loss": 0.0004,
      "step": 1535
    },
    {
      "epoch": 0.09111401115197533,
      "grad_norm": 11.167767524719238,
      "learning_rate": 1.8220640569395018e-05,
      "loss": 0.0877,
      "step": 1536
    },
    {
      "epoch": 0.09117333016965239,
      "grad_norm": 26.25453758239746,
      "learning_rate": 1.823250296559905e-05,
      "loss": 0.2009,
      "step": 1537
    },
    {
      "epoch": 0.09123264918732946,
      "grad_norm": 4.879428863525391,
      "learning_rate": 1.8244365361803085e-05,
      "loss": 0.0506,
      "step": 1538
    },
    {
      "epoch": 0.09129196820500653,
      "grad_norm": 44.720123291015625,
      "learning_rate": 1.825622775800712e-05,
      "loss": 1.5795,
      "step": 1539
    },
    {
      "epoch": 0.0913512872226836,
      "grad_norm": 0.845684826374054,
      "learning_rate": 1.8268090154211152e-05,
      "loss": 0.0092,
      "step": 1540
    },
    {
      "epoch": 0.09141060624036065,
      "grad_norm": 1.9723339080810547,
      "learning_rate": 1.8279952550415185e-05,
      "loss": 0.0067,
      "step": 1541
    },
    {
      "epoch": 0.09146992525803772,
      "grad_norm": 8.703948020935059,
      "learning_rate": 1.829181494661922e-05,
      "loss": 0.1101,
      "step": 1542
    },
    {
      "epoch": 0.0915292442757148,
      "grad_norm": 17.65921974182129,
      "learning_rate": 1.8303677342823252e-05,
      "loss": 0.2705,
      "step": 1543
    },
    {
      "epoch": 0.09158856329339186,
      "grad_norm": 18.65146255493164,
      "learning_rate": 1.8315539739027286e-05,
      "loss": 0.4243,
      "step": 1544
    },
    {
      "epoch": 0.09164788231106893,
      "grad_norm": 7.26701021194458,
      "learning_rate": 1.832740213523132e-05,
      "loss": 0.0618,
      "step": 1545
    },
    {
      "epoch": 0.09170720132874599,
      "grad_norm": 7.099400043487549,
      "learning_rate": 1.8339264531435353e-05,
      "loss": 0.4617,
      "step": 1546
    },
    {
      "epoch": 0.09176652034642306,
      "grad_norm": 27.3021297454834,
      "learning_rate": 1.8351126927639383e-05,
      "loss": 0.7189,
      "step": 1547
    },
    {
      "epoch": 0.09182583936410013,
      "grad_norm": 53.46974182128906,
      "learning_rate": 1.836298932384342e-05,
      "loss": 1.2494,
      "step": 1548
    },
    {
      "epoch": 0.0918851583817772,
      "grad_norm": 59.780879974365234,
      "learning_rate": 1.837485172004745e-05,
      "loss": 0.1985,
      "step": 1549
    },
    {
      "epoch": 0.09194447739945427,
      "grad_norm": 15.006464958190918,
      "learning_rate": 1.8386714116251484e-05,
      "loss": 0.0895,
      "step": 1550
    },
    {
      "epoch": 0.09200379641713133,
      "grad_norm": 0.03948763385415077,
      "learning_rate": 1.8398576512455517e-05,
      "loss": 0.0005,
      "step": 1551
    },
    {
      "epoch": 0.0920631154348084,
      "grad_norm": 4.914620399475098,
      "learning_rate": 1.841043890865955e-05,
      "loss": 0.0561,
      "step": 1552
    },
    {
      "epoch": 0.09212243445248547,
      "grad_norm": 11.49985122680664,
      "learning_rate": 1.8422301304863584e-05,
      "loss": 0.6105,
      "step": 1553
    },
    {
      "epoch": 0.09218175347016254,
      "grad_norm": 21.317747116088867,
      "learning_rate": 1.8434163701067618e-05,
      "loss": 0.36,
      "step": 1554
    },
    {
      "epoch": 0.0922410724878396,
      "grad_norm": 0.7502905130386353,
      "learning_rate": 1.844602609727165e-05,
      "loss": 0.0085,
      "step": 1555
    },
    {
      "epoch": 0.09230039150551667,
      "grad_norm": 1.0181519985198975,
      "learning_rate": 1.8457888493475685e-05,
      "loss": 0.0092,
      "step": 1556
    },
    {
      "epoch": 0.09235971052319374,
      "grad_norm": 0.3060894310474396,
      "learning_rate": 1.8469750889679715e-05,
      "loss": 0.0015,
      "step": 1557
    },
    {
      "epoch": 0.0924190295408708,
      "grad_norm": 0.6063419580459595,
      "learning_rate": 1.8481613285883752e-05,
      "loss": 0.0051,
      "step": 1558
    },
    {
      "epoch": 0.09247834855854788,
      "grad_norm": 0.1605157107114792,
      "learning_rate": 1.8493475682087782e-05,
      "loss": 0.002,
      "step": 1559
    },
    {
      "epoch": 0.09253766757622493,
      "grad_norm": 0.022661607712507248,
      "learning_rate": 1.8505338078291815e-05,
      "loss": 0.0004,
      "step": 1560
    },
    {
      "epoch": 0.092596986593902,
      "grad_norm": 10.64752197265625,
      "learning_rate": 1.851720047449585e-05,
      "loss": 0.0549,
      "step": 1561
    },
    {
      "epoch": 0.09265630561157907,
      "grad_norm": 8.957138061523438,
      "learning_rate": 1.8529062870699883e-05,
      "loss": 0.1014,
      "step": 1562
    },
    {
      "epoch": 0.09271562462925614,
      "grad_norm": 6.931691646575928,
      "learning_rate": 1.8540925266903916e-05,
      "loss": 0.0794,
      "step": 1563
    },
    {
      "epoch": 0.0927749436469332,
      "grad_norm": 57.1475944519043,
      "learning_rate": 1.855278766310795e-05,
      "loss": 1.1162,
      "step": 1564
    },
    {
      "epoch": 0.09283426266461027,
      "grad_norm": 5.147608757019043,
      "learning_rate": 1.8564650059311983e-05,
      "loss": 0.0419,
      "step": 1565
    },
    {
      "epoch": 0.09289358168228734,
      "grad_norm": 4.620843410491943,
      "learning_rate": 1.8576512455516017e-05,
      "loss": 0.6577,
      "step": 1566
    },
    {
      "epoch": 0.09295290069996441,
      "grad_norm": 35.42539596557617,
      "learning_rate": 1.8588374851720047e-05,
      "loss": 0.9987,
      "step": 1567
    },
    {
      "epoch": 0.09301221971764148,
      "grad_norm": 3.759934902191162,
      "learning_rate": 1.8600237247924084e-05,
      "loss": 0.0263,
      "step": 1568
    },
    {
      "epoch": 0.09307153873531854,
      "grad_norm": 2.2398123741149902,
      "learning_rate": 1.8612099644128114e-05,
      "loss": 0.0336,
      "step": 1569
    },
    {
      "epoch": 0.09313085775299561,
      "grad_norm": 16.99237632751465,
      "learning_rate": 1.8623962040332147e-05,
      "loss": 0.1866,
      "step": 1570
    },
    {
      "epoch": 0.09319017677067268,
      "grad_norm": 19.689361572265625,
      "learning_rate": 1.8635824436536184e-05,
      "loss": 0.4966,
      "step": 1571
    },
    {
      "epoch": 0.09324949578834975,
      "grad_norm": 37.55794906616211,
      "learning_rate": 1.8647686832740214e-05,
      "loss": 0.6085,
      "step": 1572
    },
    {
      "epoch": 0.09330881480602682,
      "grad_norm": 12.241118431091309,
      "learning_rate": 1.8659549228944248e-05,
      "loss": 0.1067,
      "step": 1573
    },
    {
      "epoch": 0.09336813382370387,
      "grad_norm": 0.16587364673614502,
      "learning_rate": 1.867141162514828e-05,
      "loss": 0.0029,
      "step": 1574
    },
    {
      "epoch": 0.09342745284138095,
      "grad_norm": 0.06950607895851135,
      "learning_rate": 1.8683274021352315e-05,
      "loss": 0.0012,
      "step": 1575
    },
    {
      "epoch": 0.09348677185905802,
      "grad_norm": 0.0612296536564827,
      "learning_rate": 1.869513641755635e-05,
      "loss": 0.0014,
      "step": 1576
    },
    {
      "epoch": 0.09354609087673509,
      "grad_norm": 7.7406392097473145,
      "learning_rate": 1.8706998813760382e-05,
      "loss": 0.0654,
      "step": 1577
    },
    {
      "epoch": 0.09360540989441214,
      "grad_norm": 36.7117805480957,
      "learning_rate": 1.8718861209964415e-05,
      "loss": 0.2059,
      "step": 1578
    },
    {
      "epoch": 0.09366472891208921,
      "grad_norm": 9.065834999084473,
      "learning_rate": 1.873072360616845e-05,
      "loss": 0.1695,
      "step": 1579
    },
    {
      "epoch": 0.09372404792976628,
      "grad_norm": 10.51366138458252,
      "learning_rate": 1.874258600237248e-05,
      "loss": 0.1288,
      "step": 1580
    },
    {
      "epoch": 0.09378336694744335,
      "grad_norm": 35.696876525878906,
      "learning_rate": 1.8754448398576516e-05,
      "loss": 0.1667,
      "step": 1581
    },
    {
      "epoch": 0.09384268596512042,
      "grad_norm": 30.858869552612305,
      "learning_rate": 1.8766310794780546e-05,
      "loss": 1.0975,
      "step": 1582
    },
    {
      "epoch": 0.09390200498279748,
      "grad_norm": 15.776329040527344,
      "learning_rate": 1.877817319098458e-05,
      "loss": 0.7294,
      "step": 1583
    },
    {
      "epoch": 0.09396132400047455,
      "grad_norm": 6.723967552185059,
      "learning_rate": 1.8790035587188613e-05,
      "loss": 0.3208,
      "step": 1584
    },
    {
      "epoch": 0.09402064301815162,
      "grad_norm": 168.49562072753906,
      "learning_rate": 1.8801897983392647e-05,
      "loss": 1.0311,
      "step": 1585
    },
    {
      "epoch": 0.09407996203582869,
      "grad_norm": 0.2647869288921356,
      "learning_rate": 1.881376037959668e-05,
      "loss": 0.0034,
      "step": 1586
    },
    {
      "epoch": 0.09413928105350576,
      "grad_norm": 12.385092735290527,
      "learning_rate": 1.8825622775800714e-05,
      "loss": 0.1777,
      "step": 1587
    },
    {
      "epoch": 0.09419860007118282,
      "grad_norm": 13.094401359558105,
      "learning_rate": 1.8837485172004747e-05,
      "loss": 0.196,
      "step": 1588
    },
    {
      "epoch": 0.09425791908885989,
      "grad_norm": 0.5262703895568848,
      "learning_rate": 1.884934756820878e-05,
      "loss": 0.0062,
      "step": 1589
    },
    {
      "epoch": 0.09431723810653696,
      "grad_norm": 16.74416160583496,
      "learning_rate": 1.886120996441281e-05,
      "loss": 0.2661,
      "step": 1590
    },
    {
      "epoch": 0.09437655712421403,
      "grad_norm": 3.3016414642333984,
      "learning_rate": 1.8873072360616848e-05,
      "loss": 0.0275,
      "step": 1591
    },
    {
      "epoch": 0.09443587614189108,
      "grad_norm": 17.263792037963867,
      "learning_rate": 1.8884934756820878e-05,
      "loss": 0.5009,
      "step": 1592
    },
    {
      "epoch": 0.09449519515956815,
      "grad_norm": 19.023380279541016,
      "learning_rate": 1.889679715302491e-05,
      "loss": 0.3926,
      "step": 1593
    },
    {
      "epoch": 0.09455451417724522,
      "grad_norm": 6.572348117828369,
      "learning_rate": 1.8908659549228945e-05,
      "loss": 0.1353,
      "step": 1594
    },
    {
      "epoch": 0.0946138331949223,
      "grad_norm": 3.662075996398926,
      "learning_rate": 1.892052194543298e-05,
      "loss": 0.0526,
      "step": 1595
    },
    {
      "epoch": 0.09467315221259937,
      "grad_norm": 18.64779281616211,
      "learning_rate": 1.8932384341637012e-05,
      "loss": 0.3974,
      "step": 1596
    },
    {
      "epoch": 0.09473247123027642,
      "grad_norm": 12.490171432495117,
      "learning_rate": 1.8944246737841046e-05,
      "loss": 0.2258,
      "step": 1597
    },
    {
      "epoch": 0.09479179024795349,
      "grad_norm": 12.94003677368164,
      "learning_rate": 1.895610913404508e-05,
      "loss": 0.0698,
      "step": 1598
    },
    {
      "epoch": 0.09485110926563056,
      "grad_norm": 0.49009066820144653,
      "learning_rate": 1.8967971530249113e-05,
      "loss": 0.0058,
      "step": 1599
    },
    {
      "epoch": 0.09491042828330763,
      "grad_norm": 12.673213958740234,
      "learning_rate": 1.8979833926453146e-05,
      "loss": 0.2495,
      "step": 1600
    },
    {
      "epoch": 0.0949697473009847,
      "grad_norm": 15.230789184570312,
      "learning_rate": 1.899169632265718e-05,
      "loss": 0.0807,
      "step": 1601
    },
    {
      "epoch": 0.09502906631866176,
      "grad_norm": 0.21257418394088745,
      "learning_rate": 1.9003558718861213e-05,
      "loss": 0.0021,
      "step": 1602
    },
    {
      "epoch": 0.09508838533633883,
      "grad_norm": 0.3535155951976776,
      "learning_rate": 1.9015421115065243e-05,
      "loss": 0.0039,
      "step": 1603
    },
    {
      "epoch": 0.0951477043540159,
      "grad_norm": 0.5232927203178406,
      "learning_rate": 1.902728351126928e-05,
      "loss": 0.0065,
      "step": 1604
    },
    {
      "epoch": 0.09520702337169297,
      "grad_norm": 4.338740825653076,
      "learning_rate": 1.903914590747331e-05,
      "loss": 0.0509,
      "step": 1605
    },
    {
      "epoch": 0.09526634238937003,
      "grad_norm": 9.972886085510254,
      "learning_rate": 1.9051008303677344e-05,
      "loss": 0.1548,
      "step": 1606
    },
    {
      "epoch": 0.0953256614070471,
      "grad_norm": 0.4020143151283264,
      "learning_rate": 1.9062870699881377e-05,
      "loss": 0.003,
      "step": 1607
    },
    {
      "epoch": 0.09538498042472417,
      "grad_norm": 2.2565982341766357,
      "learning_rate": 1.907473309608541e-05,
      "loss": 0.0159,
      "step": 1608
    },
    {
      "epoch": 0.09544429944240124,
      "grad_norm": 21.130401611328125,
      "learning_rate": 1.9086595492289444e-05,
      "loss": 0.6335,
      "step": 1609
    },
    {
      "epoch": 0.09550361846007831,
      "grad_norm": 19.788455963134766,
      "learning_rate": 1.9098457888493478e-05,
      "loss": 0.3522,
      "step": 1610
    },
    {
      "epoch": 0.09556293747775536,
      "grad_norm": 2.1954901218414307,
      "learning_rate": 1.911032028469751e-05,
      "loss": 0.0119,
      "step": 1611
    },
    {
      "epoch": 0.09562225649543243,
      "grad_norm": 1.7645670175552368,
      "learning_rate": 1.9122182680901545e-05,
      "loss": 0.0055,
      "step": 1612
    },
    {
      "epoch": 0.0956815755131095,
      "grad_norm": 7.163567543029785,
      "learning_rate": 1.9134045077105575e-05,
      "loss": 0.059,
      "step": 1613
    },
    {
      "epoch": 0.09574089453078657,
      "grad_norm": 38.13749313354492,
      "learning_rate": 1.9145907473309612e-05,
      "loss": 0.7208,
      "step": 1614
    },
    {
      "epoch": 0.09580021354846363,
      "grad_norm": 8.684967041015625,
      "learning_rate": 1.9157769869513642e-05,
      "loss": 0.119,
      "step": 1615
    },
    {
      "epoch": 0.0958595325661407,
      "grad_norm": 37.18331527709961,
      "learning_rate": 1.9169632265717676e-05,
      "loss": 0.3368,
      "step": 1616
    },
    {
      "epoch": 0.09591885158381777,
      "grad_norm": 0.04715137183666229,
      "learning_rate": 1.918149466192171e-05,
      "loss": 0.0008,
      "step": 1617
    },
    {
      "epoch": 0.09597817060149484,
      "grad_norm": 0.10006805509328842,
      "learning_rate": 1.9193357058125743e-05,
      "loss": 0.0026,
      "step": 1618
    },
    {
      "epoch": 0.09603748961917191,
      "grad_norm": 38.77457809448242,
      "learning_rate": 1.9205219454329776e-05,
      "loss": 1.2494,
      "step": 1619
    },
    {
      "epoch": 0.09609680863684897,
      "grad_norm": 41.89756774902344,
      "learning_rate": 1.921708185053381e-05,
      "loss": 0.1483,
      "step": 1620
    },
    {
      "epoch": 0.09615612765452604,
      "grad_norm": 31.30023193359375,
      "learning_rate": 1.9228944246737843e-05,
      "loss": 0.5688,
      "step": 1621
    },
    {
      "epoch": 0.09621544667220311,
      "grad_norm": 13.903547286987305,
      "learning_rate": 1.9240806642941877e-05,
      "loss": 0.054,
      "step": 1622
    },
    {
      "epoch": 0.09627476568988018,
      "grad_norm": 1.4389256238937378,
      "learning_rate": 1.9252669039145907e-05,
      "loss": 0.0083,
      "step": 1623
    },
    {
      "epoch": 0.09633408470755725,
      "grad_norm": 5.730507850646973,
      "learning_rate": 1.9264531435349944e-05,
      "loss": 0.0488,
      "step": 1624
    },
    {
      "epoch": 0.0963934037252343,
      "grad_norm": 0.6316882371902466,
      "learning_rate": 1.9276393831553974e-05,
      "loss": 0.0071,
      "step": 1625
    },
    {
      "epoch": 0.09645272274291138,
      "grad_norm": 39.49723815917969,
      "learning_rate": 1.9288256227758007e-05,
      "loss": 0.5726,
      "step": 1626
    },
    {
      "epoch": 0.09651204176058845,
      "grad_norm": 18.657114028930664,
      "learning_rate": 1.930011862396204e-05,
      "loss": 0.7822,
      "step": 1627
    },
    {
      "epoch": 0.09657136077826552,
      "grad_norm": 24.128414154052734,
      "learning_rate": 1.9311981020166074e-05,
      "loss": 0.407,
      "step": 1628
    },
    {
      "epoch": 0.09663067979594257,
      "grad_norm": 35.77015686035156,
      "learning_rate": 1.9323843416370108e-05,
      "loss": 0.9524,
      "step": 1629
    },
    {
      "epoch": 0.09668999881361964,
      "grad_norm": 2.350322961807251,
      "learning_rate": 1.933570581257414e-05,
      "loss": 0.0117,
      "step": 1630
    },
    {
      "epoch": 0.09674931783129671,
      "grad_norm": 18.030460357666016,
      "learning_rate": 1.9347568208778175e-05,
      "loss": 0.5604,
      "step": 1631
    },
    {
      "epoch": 0.09680863684897378,
      "grad_norm": 0.1336122751235962,
      "learning_rate": 1.935943060498221e-05,
      "loss": 0.0022,
      "step": 1632
    },
    {
      "epoch": 0.09686795586665085,
      "grad_norm": 0.13441821932792664,
      "learning_rate": 1.9371293001186242e-05,
      "loss": 0.0013,
      "step": 1633
    },
    {
      "epoch": 0.09692727488432791,
      "grad_norm": 34.24888229370117,
      "learning_rate": 1.9383155397390276e-05,
      "loss": 0.7477,
      "step": 1634
    },
    {
      "epoch": 0.09698659390200498,
      "grad_norm": 31.26367950439453,
      "learning_rate": 1.939501779359431e-05,
      "loss": 0.6627,
      "step": 1635
    },
    {
      "epoch": 0.09704591291968205,
      "grad_norm": 8.320521354675293,
      "learning_rate": 1.940688018979834e-05,
      "loss": 0.1652,
      "step": 1636
    },
    {
      "epoch": 0.09710523193735912,
      "grad_norm": 77.97953796386719,
      "learning_rate": 1.9418742586002376e-05,
      "loss": 1.1748,
      "step": 1637
    },
    {
      "epoch": 0.09716455095503619,
      "grad_norm": 2.319296360015869,
      "learning_rate": 1.9430604982206406e-05,
      "loss": 0.0154,
      "step": 1638
    },
    {
      "epoch": 0.09722386997271325,
      "grad_norm": 4.3137993812561035,
      "learning_rate": 1.944246737841044e-05,
      "loss": 0.0751,
      "step": 1639
    },
    {
      "epoch": 0.09728318899039032,
      "grad_norm": 10.239831924438477,
      "learning_rate": 1.9454329774614473e-05,
      "loss": 0.0782,
      "step": 1640
    },
    {
      "epoch": 0.09734250800806739,
      "grad_norm": 30.672439575195312,
      "learning_rate": 1.9466192170818507e-05,
      "loss": 0.0802,
      "step": 1641
    },
    {
      "epoch": 0.09740182702574446,
      "grad_norm": 40.17966079711914,
      "learning_rate": 1.947805456702254e-05,
      "loss": 1.1476,
      "step": 1642
    },
    {
      "epoch": 0.09746114604342151,
      "grad_norm": 7.1209187507629395,
      "learning_rate": 1.9489916963226574e-05,
      "loss": 0.0393,
      "step": 1643
    },
    {
      "epoch": 0.09752046506109859,
      "grad_norm": 35.256324768066406,
      "learning_rate": 1.9501779359430607e-05,
      "loss": 0.5326,
      "step": 1644
    },
    {
      "epoch": 0.09757978407877566,
      "grad_norm": 13.276054382324219,
      "learning_rate": 1.951364175563464e-05,
      "loss": 0.2911,
      "step": 1645
    },
    {
      "epoch": 0.09763910309645273,
      "grad_norm": 18.38847541809082,
      "learning_rate": 1.952550415183867e-05,
      "loss": 0.2489,
      "step": 1646
    },
    {
      "epoch": 0.0976984221141298,
      "grad_norm": 0.0691271647810936,
      "learning_rate": 1.9537366548042708e-05,
      "loss": 0.0011,
      "step": 1647
    },
    {
      "epoch": 0.09775774113180685,
      "grad_norm": 21.884414672851562,
      "learning_rate": 1.9549228944246738e-05,
      "loss": 0.8097,
      "step": 1648
    },
    {
      "epoch": 0.09781706014948392,
      "grad_norm": 1.2613375186920166,
      "learning_rate": 1.956109134045077e-05,
      "loss": 0.0043,
      "step": 1649
    },
    {
      "epoch": 0.09787637916716099,
      "grad_norm": 0.98648601770401,
      "learning_rate": 1.9572953736654805e-05,
      "loss": 0.0072,
      "step": 1650
    },
    {
      "epoch": 0.09793569818483806,
      "grad_norm": 0.3577084243297577,
      "learning_rate": 1.958481613285884e-05,
      "loss": 0.0037,
      "step": 1651
    },
    {
      "epoch": 0.09799501720251512,
      "grad_norm": 30.95888900756836,
      "learning_rate": 1.9596678529062872e-05,
      "loss": 0.2332,
      "step": 1652
    },
    {
      "epoch": 0.09805433622019219,
      "grad_norm": 8.981714248657227,
      "learning_rate": 1.9608540925266906e-05,
      "loss": 0.1494,
      "step": 1653
    },
    {
      "epoch": 0.09811365523786926,
      "grad_norm": 0.14130383729934692,
      "learning_rate": 1.962040332147094e-05,
      "loss": 0.0018,
      "step": 1654
    },
    {
      "epoch": 0.09817297425554633,
      "grad_norm": 13.03919792175293,
      "learning_rate": 1.9632265717674973e-05,
      "loss": 0.1305,
      "step": 1655
    },
    {
      "epoch": 0.0982322932732234,
      "grad_norm": 1.359484076499939,
      "learning_rate": 1.9644128113879003e-05,
      "loss": 0.0087,
      "step": 1656
    },
    {
      "epoch": 0.09829161229090046,
      "grad_norm": 27.384899139404297,
      "learning_rate": 1.965599051008304e-05,
      "loss": 0.4582,
      "step": 1657
    },
    {
      "epoch": 0.09835093130857753,
      "grad_norm": 7.5962395668029785,
      "learning_rate": 1.9667852906287073e-05,
      "loss": 0.2035,
      "step": 1658
    },
    {
      "epoch": 0.0984102503262546,
      "grad_norm": 6.316676139831543,
      "learning_rate": 1.9679715302491103e-05,
      "loss": 0.0564,
      "step": 1659
    },
    {
      "epoch": 0.09846956934393167,
      "grad_norm": 3.5953621864318848,
      "learning_rate": 1.969157769869514e-05,
      "loss": 0.0272,
      "step": 1660
    },
    {
      "epoch": 0.09852888836160874,
      "grad_norm": 26.724119186401367,
      "learning_rate": 1.970344009489917e-05,
      "loss": 0.3444,
      "step": 1661
    },
    {
      "epoch": 0.0985882073792858,
      "grad_norm": 0.7926079630851746,
      "learning_rate": 1.9715302491103204e-05,
      "loss": 0.0138,
      "step": 1662
    },
    {
      "epoch": 0.09864752639696286,
      "grad_norm": 0.09079133719205856,
      "learning_rate": 1.9727164887307237e-05,
      "loss": 0.0011,
      "step": 1663
    },
    {
      "epoch": 0.09870684541463993,
      "grad_norm": 8.96854019165039,
      "learning_rate": 1.973902728351127e-05,
      "loss": 0.2354,
      "step": 1664
    },
    {
      "epoch": 0.098766164432317,
      "grad_norm": 0.40886572003364563,
      "learning_rate": 1.9750889679715305e-05,
      "loss": 0.004,
      "step": 1665
    },
    {
      "epoch": 0.09882548344999406,
      "grad_norm": 33.21784210205078,
      "learning_rate": 1.9762752075919338e-05,
      "loss": 0.8915,
      "step": 1666
    },
    {
      "epoch": 0.09888480246767113,
      "grad_norm": 9.02245807647705,
      "learning_rate": 1.977461447212337e-05,
      "loss": 0.0914,
      "step": 1667
    },
    {
      "epoch": 0.0989441214853482,
      "grad_norm": 2.7627015113830566,
      "learning_rate": 1.9786476868327405e-05,
      "loss": 0.0243,
      "step": 1668
    },
    {
      "epoch": 0.09900344050302527,
      "grad_norm": 0.06227797269821167,
      "learning_rate": 1.9798339264531435e-05,
      "loss": 0.001,
      "step": 1669
    },
    {
      "epoch": 0.09906275952070234,
      "grad_norm": 0.18021513521671295,
      "learning_rate": 1.9810201660735472e-05,
      "loss": 0.0021,
      "step": 1670
    },
    {
      "epoch": 0.0991220785383794,
      "grad_norm": 8.076850891113281,
      "learning_rate": 1.9822064056939502e-05,
      "loss": 0.033,
      "step": 1671
    },
    {
      "epoch": 0.09918139755605647,
      "grad_norm": 0.5212966799736023,
      "learning_rate": 1.9833926453143536e-05,
      "loss": 0.0057,
      "step": 1672
    },
    {
      "epoch": 0.09924071657373354,
      "grad_norm": 14.180306434631348,
      "learning_rate": 1.984578884934757e-05,
      "loss": 0.1011,
      "step": 1673
    },
    {
      "epoch": 0.09930003559141061,
      "grad_norm": 1.6799087524414062,
      "learning_rate": 1.9857651245551603e-05,
      "loss": 0.0101,
      "step": 1674
    },
    {
      "epoch": 0.09935935460908768,
      "grad_norm": 33.6103401184082,
      "learning_rate": 1.9869513641755636e-05,
      "loss": 0.9522,
      "step": 1675
    },
    {
      "epoch": 0.09941867362676474,
      "grad_norm": 3.7950332164764404,
      "learning_rate": 1.988137603795967e-05,
      "loss": 0.0469,
      "step": 1676
    },
    {
      "epoch": 0.0994779926444418,
      "grad_norm": 37.28773880004883,
      "learning_rate": 1.9893238434163703e-05,
      "loss": 0.1533,
      "step": 1677
    },
    {
      "epoch": 0.09953731166211888,
      "grad_norm": 7.742271900177002,
      "learning_rate": 1.9905100830367737e-05,
      "loss": 0.038,
      "step": 1678
    },
    {
      "epoch": 0.09959663067979595,
      "grad_norm": 0.03470027446746826,
      "learning_rate": 1.9916963226571767e-05,
      "loss": 0.0008,
      "step": 1679
    },
    {
      "epoch": 0.099655949697473,
      "grad_norm": 0.40554627776145935,
      "learning_rate": 1.9928825622775804e-05,
      "loss": 0.0036,
      "step": 1680
    },
    {
      "epoch": 0.09971526871515007,
      "grad_norm": 25.975780487060547,
      "learning_rate": 1.9940688018979834e-05,
      "loss": 0.4039,
      "step": 1681
    },
    {
      "epoch": 0.09977458773282714,
      "grad_norm": 8.998363494873047,
      "learning_rate": 1.9952550415183868e-05,
      "loss": 0.1321,
      "step": 1682
    },
    {
      "epoch": 0.09983390675050421,
      "grad_norm": 12.284045219421387,
      "learning_rate": 1.99644128113879e-05,
      "loss": 0.0777,
      "step": 1683
    },
    {
      "epoch": 0.09989322576818128,
      "grad_norm": 37.73637008666992,
      "learning_rate": 1.9976275207591935e-05,
      "loss": 0.5216,
      "step": 1684
    },
    {
      "epoch": 0.09995254478585834,
      "grad_norm": 15.947797775268555,
      "learning_rate": 1.9988137603795968e-05,
      "loss": 0.5447,
      "step": 1685
    },
    {
      "epoch": 0.10001186380353541,
      "grad_norm": 0.4491789638996124,
      "learning_rate": 2e-05,
      "loss": 0.0041,
      "step": 1686
    },
    {
      "epoch": 0.10007118282121248,
      "grad_norm": 23.010095596313477,
      "learning_rate": 1.9998681782230428e-05,
      "loss": 0.0427,
      "step": 1687
    },
    {
      "epoch": 0.10013050183888955,
      "grad_norm": 2.1041717529296875,
      "learning_rate": 1.999736356446085e-05,
      "loss": 0.0085,
      "step": 1688
    },
    {
      "epoch": 0.10018982085656662,
      "grad_norm": 0.19603437185287476,
      "learning_rate": 1.9996045346691276e-05,
      "loss": 0.0019,
      "step": 1689
    },
    {
      "epoch": 0.10024913987424368,
      "grad_norm": 12.042930603027344,
      "learning_rate": 1.9994727128921702e-05,
      "loss": 0.2361,
      "step": 1690
    },
    {
      "epoch": 0.10030845889192075,
      "grad_norm": 14.96868896484375,
      "learning_rate": 1.9993408911152124e-05,
      "loss": 0.1692,
      "step": 1691
    },
    {
      "epoch": 0.10036777790959782,
      "grad_norm": 1.4282640218734741,
      "learning_rate": 1.999209069338255e-05,
      "loss": 0.0119,
      "step": 1692
    },
    {
      "epoch": 0.10042709692727489,
      "grad_norm": 9.787654876708984,
      "learning_rate": 1.9990772475612973e-05,
      "loss": 0.2278,
      "step": 1693
    },
    {
      "epoch": 0.10048641594495195,
      "grad_norm": 64.51529693603516,
      "learning_rate": 1.99894542578434e-05,
      "loss": 1.8736,
      "step": 1694
    },
    {
      "epoch": 0.10054573496262902,
      "grad_norm": 0.12196005135774612,
      "learning_rate": 1.998813604007382e-05,
      "loss": 0.0017,
      "step": 1695
    },
    {
      "epoch": 0.10060505398030609,
      "grad_norm": 3.0100817680358887,
      "learning_rate": 1.9986817822304247e-05,
      "loss": 0.0164,
      "step": 1696
    },
    {
      "epoch": 0.10066437299798316,
      "grad_norm": 24.990163803100586,
      "learning_rate": 1.998549960453467e-05,
      "loss": 0.661,
      "step": 1697
    },
    {
      "epoch": 0.10072369201566023,
      "grad_norm": 1.0910018682479858,
      "learning_rate": 1.9984181386765095e-05,
      "loss": 0.0062,
      "step": 1698
    },
    {
      "epoch": 0.10078301103333728,
      "grad_norm": 0.2790747880935669,
      "learning_rate": 1.9982863168995518e-05,
      "loss": 0.0019,
      "step": 1699
    },
    {
      "epoch": 0.10084233005101435,
      "grad_norm": 17.16112518310547,
      "learning_rate": 1.9981544951225944e-05,
      "loss": 0.1734,
      "step": 1700
    },
    {
      "epoch": 0.10090164906869142,
      "grad_norm": 22.926780700683594,
      "learning_rate": 1.998022673345637e-05,
      "loss": 0.2835,
      "step": 1701
    },
    {
      "epoch": 0.1009609680863685,
      "grad_norm": 31.924482345581055,
      "learning_rate": 1.9978908515686792e-05,
      "loss": 0.1919,
      "step": 1702
    },
    {
      "epoch": 0.10102028710404555,
      "grad_norm": 2.515512704849243,
      "learning_rate": 1.9977590297917218e-05,
      "loss": 0.0261,
      "step": 1703
    },
    {
      "epoch": 0.10107960612172262,
      "grad_norm": 0.3953113257884979,
      "learning_rate": 1.9976272080147644e-05,
      "loss": 0.0052,
      "step": 1704
    },
    {
      "epoch": 0.10113892513939969,
      "grad_norm": 14.12716007232666,
      "learning_rate": 1.9974953862378066e-05,
      "loss": 0.0793,
      "step": 1705
    },
    {
      "epoch": 0.10119824415707676,
      "grad_norm": 17.39898109436035,
      "learning_rate": 1.9973635644608492e-05,
      "loss": 0.1028,
      "step": 1706
    },
    {
      "epoch": 0.10125756317475383,
      "grad_norm": 26.088552474975586,
      "learning_rate": 1.9972317426838918e-05,
      "loss": 0.1402,
      "step": 1707
    },
    {
      "epoch": 0.10131688219243089,
      "grad_norm": 4.538229465484619,
      "learning_rate": 1.997099920906934e-05,
      "loss": 0.0234,
      "step": 1708
    },
    {
      "epoch": 0.10137620121010796,
      "grad_norm": 34.43851089477539,
      "learning_rate": 1.9969680991299763e-05,
      "loss": 0.644,
      "step": 1709
    },
    {
      "epoch": 0.10143552022778503,
      "grad_norm": 0.09676266461610794,
      "learning_rate": 1.996836277353019e-05,
      "loss": 0.0021,
      "step": 1710
    },
    {
      "epoch": 0.1014948392454621,
      "grad_norm": 5.2711262702941895,
      "learning_rate": 1.996704455576061e-05,
      "loss": 0.0268,
      "step": 1711
    },
    {
      "epoch": 0.10155415826313917,
      "grad_norm": 13.884523391723633,
      "learning_rate": 1.9965726337991037e-05,
      "loss": 0.2381,
      "step": 1712
    },
    {
      "epoch": 0.10161347728081623,
      "grad_norm": 18.467275619506836,
      "learning_rate": 1.996440812022146e-05,
      "loss": 0.2974,
      "step": 1713
    },
    {
      "epoch": 0.1016727962984933,
      "grad_norm": 2.9514031410217285,
      "learning_rate": 1.9963089902451886e-05,
      "loss": 0.0272,
      "step": 1714
    },
    {
      "epoch": 0.10173211531617037,
      "grad_norm": 9.983440399169922,
      "learning_rate": 1.996177168468231e-05,
      "loss": 0.1241,
      "step": 1715
    },
    {
      "epoch": 0.10179143433384744,
      "grad_norm": 0.6751769185066223,
      "learning_rate": 1.9960453466912734e-05,
      "loss": 0.0046,
      "step": 1716
    },
    {
      "epoch": 0.10185075335152449,
      "grad_norm": 7.9071197509765625,
      "learning_rate": 1.995913524914316e-05,
      "loss": 0.1045,
      "step": 1717
    },
    {
      "epoch": 0.10191007236920156,
      "grad_norm": 5.898563861846924,
      "learning_rate": 1.9957817031373586e-05,
      "loss": 0.0335,
      "step": 1718
    },
    {
      "epoch": 0.10196939138687863,
      "grad_norm": 5.486020565032959,
      "learning_rate": 1.9956498813604008e-05,
      "loss": 0.0247,
      "step": 1719
    },
    {
      "epoch": 0.1020287104045557,
      "grad_norm": 3.7670462131500244,
      "learning_rate": 1.9955180595834434e-05,
      "loss": 0.0141,
      "step": 1720
    },
    {
      "epoch": 0.10208802942223277,
      "grad_norm": 2.521373748779297,
      "learning_rate": 1.995386237806486e-05,
      "loss": 0.0157,
      "step": 1721
    },
    {
      "epoch": 0.10214734843990983,
      "grad_norm": 0.7598012089729309,
      "learning_rate": 1.9952544160295283e-05,
      "loss": 0.004,
      "step": 1722
    },
    {
      "epoch": 0.1022066674575869,
      "grad_norm": 1.218579888343811,
      "learning_rate": 1.995122594252571e-05,
      "loss": 0.0111,
      "step": 1723
    },
    {
      "epoch": 0.10226598647526397,
      "grad_norm": 27.425010681152344,
      "learning_rate": 1.994990772475613e-05,
      "loss": 1.0503,
      "step": 1724
    },
    {
      "epoch": 0.10232530549294104,
      "grad_norm": 0.11287716776132584,
      "learning_rate": 1.9948589506986557e-05,
      "loss": 0.0008,
      "step": 1725
    },
    {
      "epoch": 0.10238462451061811,
      "grad_norm": 21.652605056762695,
      "learning_rate": 1.994727128921698e-05,
      "loss": 0.1061,
      "step": 1726
    },
    {
      "epoch": 0.10244394352829517,
      "grad_norm": 22.011869430541992,
      "learning_rate": 1.9945953071447405e-05,
      "loss": 1.4206,
      "step": 1727
    },
    {
      "epoch": 0.10250326254597224,
      "grad_norm": 10.328645706176758,
      "learning_rate": 1.9944634853677828e-05,
      "loss": 0.1026,
      "step": 1728
    },
    {
      "epoch": 0.10256258156364931,
      "grad_norm": 3.4006736278533936,
      "learning_rate": 1.9943316635908254e-05,
      "loss": 0.0233,
      "step": 1729
    },
    {
      "epoch": 0.10262190058132638,
      "grad_norm": 1.3635032176971436,
      "learning_rate": 1.9941998418138676e-05,
      "loss": 0.007,
      "step": 1730
    },
    {
      "epoch": 0.10268121959900343,
      "grad_norm": 12.86635971069336,
      "learning_rate": 1.9940680200369102e-05,
      "loss": 0.8106,
      "step": 1731
    },
    {
      "epoch": 0.1027405386166805,
      "grad_norm": 17.894758224487305,
      "learning_rate": 1.9939361982599528e-05,
      "loss": 0.3847,
      "step": 1732
    },
    {
      "epoch": 0.10279985763435757,
      "grad_norm": 22.865337371826172,
      "learning_rate": 1.993804376482995e-05,
      "loss": 0.4537,
      "step": 1733
    },
    {
      "epoch": 0.10285917665203465,
      "grad_norm": 0.41756245493888855,
      "learning_rate": 1.9936725547060376e-05,
      "loss": 0.0039,
      "step": 1734
    },
    {
      "epoch": 0.10291849566971172,
      "grad_norm": 48.40582275390625,
      "learning_rate": 1.9935407329290802e-05,
      "loss": 0.2465,
      "step": 1735
    },
    {
      "epoch": 0.10297781468738877,
      "grad_norm": 8.10790729522705,
      "learning_rate": 1.9934089111521225e-05,
      "loss": 0.0701,
      "step": 1736
    },
    {
      "epoch": 0.10303713370506584,
      "grad_norm": 32.40191650390625,
      "learning_rate": 1.993277089375165e-05,
      "loss": 0.7542,
      "step": 1737
    },
    {
      "epoch": 0.10309645272274291,
      "grad_norm": 2.7689297199249268,
      "learning_rate": 1.9931452675982076e-05,
      "loss": 0.0253,
      "step": 1738
    },
    {
      "epoch": 0.10315577174041998,
      "grad_norm": 22.126367568969727,
      "learning_rate": 1.99301344582125e-05,
      "loss": 0.1422,
      "step": 1739
    },
    {
      "epoch": 0.10321509075809705,
      "grad_norm": 0.269359290599823,
      "learning_rate": 1.9928816240442925e-05,
      "loss": 0.004,
      "step": 1740
    },
    {
      "epoch": 0.10327440977577411,
      "grad_norm": 14.763608932495117,
      "learning_rate": 1.9927498022673347e-05,
      "loss": 0.3064,
      "step": 1741
    },
    {
      "epoch": 0.10333372879345118,
      "grad_norm": 14.117582321166992,
      "learning_rate": 1.992617980490377e-05,
      "loss": 0.1171,
      "step": 1742
    },
    {
      "epoch": 0.10339304781112825,
      "grad_norm": 11.64813232421875,
      "learning_rate": 1.9924861587134196e-05,
      "loss": 0.424,
      "step": 1743
    },
    {
      "epoch": 0.10345236682880532,
      "grad_norm": 2.3543248176574707,
      "learning_rate": 1.9923543369364618e-05,
      "loss": 0.0097,
      "step": 1744
    },
    {
      "epoch": 0.10351168584648238,
      "grad_norm": 17.154354095458984,
      "learning_rate": 1.9922225151595044e-05,
      "loss": 0.4289,
      "step": 1745
    },
    {
      "epoch": 0.10357100486415945,
      "grad_norm": 23.09157943725586,
      "learning_rate": 1.992090693382547e-05,
      "loss": 1.4948,
      "step": 1746
    },
    {
      "epoch": 0.10363032388183652,
      "grad_norm": 0.07694722712039948,
      "learning_rate": 1.9919588716055892e-05,
      "loss": 0.0016,
      "step": 1747
    },
    {
      "epoch": 0.10368964289951359,
      "grad_norm": 0.19600895047187805,
      "learning_rate": 1.9918270498286318e-05,
      "loss": 0.0017,
      "step": 1748
    },
    {
      "epoch": 0.10374896191719066,
      "grad_norm": 0.08407794684171677,
      "learning_rate": 1.9916952280516744e-05,
      "loss": 0.0015,
      "step": 1749
    },
    {
      "epoch": 0.10380828093486771,
      "grad_norm": 0.07424391806125641,
      "learning_rate": 1.9915634062747167e-05,
      "loss": 0.0013,
      "step": 1750
    },
    {
      "epoch": 0.10386759995254478,
      "grad_norm": 9.691080093383789,
      "learning_rate": 1.9914315844977592e-05,
      "loss": 0.0546,
      "step": 1751
    },
    {
      "epoch": 0.10392691897022185,
      "grad_norm": 22.57333755493164,
      "learning_rate": 1.991299762720802e-05,
      "loss": 0.2288,
      "step": 1752
    },
    {
      "epoch": 0.10398623798789892,
      "grad_norm": 1.0666528940200806,
      "learning_rate": 1.991167940943844e-05,
      "loss": 0.013,
      "step": 1753
    },
    {
      "epoch": 0.10404555700557598,
      "grad_norm": 16.606231689453125,
      "learning_rate": 1.9910361191668867e-05,
      "loss": 0.3303,
      "step": 1754
    },
    {
      "epoch": 0.10410487602325305,
      "grad_norm": 0.029582880437374115,
      "learning_rate": 1.990904297389929e-05,
      "loss": 0.0005,
      "step": 1755
    },
    {
      "epoch": 0.10416419504093012,
      "grad_norm": 0.10275774449110031,
      "learning_rate": 1.9907724756129715e-05,
      "loss": 0.0019,
      "step": 1756
    },
    {
      "epoch": 0.10422351405860719,
      "grad_norm": 1.37334144115448,
      "learning_rate": 1.9906406538360138e-05,
      "loss": 0.0124,
      "step": 1757
    },
    {
      "epoch": 0.10428283307628426,
      "grad_norm": 2.7454237937927246,
      "learning_rate": 1.9905088320590563e-05,
      "loss": 0.0255,
      "step": 1758
    },
    {
      "epoch": 0.10434215209396132,
      "grad_norm": 45.0133056640625,
      "learning_rate": 1.9903770102820986e-05,
      "loss": 0.3017,
      "step": 1759
    },
    {
      "epoch": 0.10440147111163839,
      "grad_norm": 25.851728439331055,
      "learning_rate": 1.9902451885051412e-05,
      "loss": 0.374,
      "step": 1760
    },
    {
      "epoch": 0.10446079012931546,
      "grad_norm": 1.459406852722168,
      "learning_rate": 1.9901133667281834e-05,
      "loss": 0.0188,
      "step": 1761
    },
    {
      "epoch": 0.10452010914699253,
      "grad_norm": 2.197798013687134,
      "learning_rate": 1.989981544951226e-05,
      "loss": 0.0148,
      "step": 1762
    },
    {
      "epoch": 0.1045794281646696,
      "grad_norm": 12.225265502929688,
      "learning_rate": 1.9898497231742686e-05,
      "loss": 0.1628,
      "step": 1763
    },
    {
      "epoch": 0.10463874718234666,
      "grad_norm": 4.319655895233154,
      "learning_rate": 1.989717901397311e-05,
      "loss": 0.0521,
      "step": 1764
    },
    {
      "epoch": 0.10469806620002373,
      "grad_norm": 23.78037452697754,
      "learning_rate": 1.9895860796203534e-05,
      "loss": 0.1988,
      "step": 1765
    },
    {
      "epoch": 0.1047573852177008,
      "grad_norm": 0.9272578358650208,
      "learning_rate": 1.989454257843396e-05,
      "loss": 0.0124,
      "step": 1766
    },
    {
      "epoch": 0.10481670423537787,
      "grad_norm": 8.76142692565918,
      "learning_rate": 1.9893224360664383e-05,
      "loss": 0.1669,
      "step": 1767
    },
    {
      "epoch": 0.10487602325305492,
      "grad_norm": 13.70595932006836,
      "learning_rate": 1.989190614289481e-05,
      "loss": 0.1137,
      "step": 1768
    },
    {
      "epoch": 0.104935342270732,
      "grad_norm": 1.016774296760559,
      "learning_rate": 1.9890587925125235e-05,
      "loss": 0.011,
      "step": 1769
    },
    {
      "epoch": 0.10499466128840906,
      "grad_norm": 1.9621285200119019,
      "learning_rate": 1.9889269707355657e-05,
      "loss": 0.0064,
      "step": 1770
    },
    {
      "epoch": 0.10505398030608613,
      "grad_norm": 11.744670867919922,
      "learning_rate": 1.9887951489586083e-05,
      "loss": 0.6245,
      "step": 1771
    },
    {
      "epoch": 0.1051132993237632,
      "grad_norm": 4.672901153564453,
      "learning_rate": 1.9886633271816505e-05,
      "loss": 0.0615,
      "step": 1772
    },
    {
      "epoch": 0.10517261834144026,
      "grad_norm": 16.419395446777344,
      "learning_rate": 1.988531505404693e-05,
      "loss": 0.1825,
      "step": 1773
    },
    {
      "epoch": 0.10523193735911733,
      "grad_norm": 4.933670997619629,
      "learning_rate": 1.9883996836277354e-05,
      "loss": 0.0136,
      "step": 1774
    },
    {
      "epoch": 0.1052912563767944,
      "grad_norm": 0.04479537159204483,
      "learning_rate": 1.988267861850778e-05,
      "loss": 0.0009,
      "step": 1775
    },
    {
      "epoch": 0.10535057539447147,
      "grad_norm": 0.05252082645893097,
      "learning_rate": 1.9881360400738202e-05,
      "loss": 0.0006,
      "step": 1776
    },
    {
      "epoch": 0.10540989441214854,
      "grad_norm": 0.6076812148094177,
      "learning_rate": 1.9880042182968628e-05,
      "loss": 0.0044,
      "step": 1777
    },
    {
      "epoch": 0.1054692134298256,
      "grad_norm": 42.138221740722656,
      "learning_rate": 1.987872396519905e-05,
      "loss": 0.3903,
      "step": 1778
    },
    {
      "epoch": 0.10552853244750267,
      "grad_norm": 7.173696517944336,
      "learning_rate": 1.9877405747429476e-05,
      "loss": 0.1433,
      "step": 1779
    },
    {
      "epoch": 0.10558785146517974,
      "grad_norm": 10.92909049987793,
      "learning_rate": 1.9876087529659902e-05,
      "loss": 0.1242,
      "step": 1780
    },
    {
      "epoch": 0.10564717048285681,
      "grad_norm": 5.557052135467529,
      "learning_rate": 1.9874769311890325e-05,
      "loss": 0.1127,
      "step": 1781
    },
    {
      "epoch": 0.10570648950053387,
      "grad_norm": 15.359785079956055,
      "learning_rate": 1.987345109412075e-05,
      "loss": 0.2122,
      "step": 1782
    },
    {
      "epoch": 0.10576580851821094,
      "grad_norm": 22.651464462280273,
      "learning_rate": 1.9872132876351177e-05,
      "loss": 0.6451,
      "step": 1783
    },
    {
      "epoch": 0.105825127535888,
      "grad_norm": 0.21800784766674042,
      "learning_rate": 1.98708146585816e-05,
      "loss": 0.0022,
      "step": 1784
    },
    {
      "epoch": 0.10588444655356508,
      "grad_norm": 0.03935680165886879,
      "learning_rate": 1.9869496440812025e-05,
      "loss": 0.0005,
      "step": 1785
    },
    {
      "epoch": 0.10594376557124215,
      "grad_norm": 0.839154064655304,
      "learning_rate": 1.9868178223042447e-05,
      "loss": 0.0085,
      "step": 1786
    },
    {
      "epoch": 0.1060030845889192,
      "grad_norm": 6.847257614135742,
      "learning_rate": 1.9866860005272873e-05,
      "loss": 0.1986,
      "step": 1787
    },
    {
      "epoch": 0.10606240360659627,
      "grad_norm": 7.2083916664123535,
      "learning_rate": 1.9865541787503296e-05,
      "loss": 0.3748,
      "step": 1788
    },
    {
      "epoch": 0.10612172262427334,
      "grad_norm": 36.09711456298828,
      "learning_rate": 1.9864223569733722e-05,
      "loss": 1.3668,
      "step": 1789
    },
    {
      "epoch": 0.10618104164195041,
      "grad_norm": 32.494361877441406,
      "learning_rate": 1.9862905351964144e-05,
      "loss": 0.9388,
      "step": 1790
    },
    {
      "epoch": 0.10624036065962747,
      "grad_norm": 0.1657538115978241,
      "learning_rate": 1.986158713419457e-05,
      "loss": 0.0017,
      "step": 1791
    },
    {
      "epoch": 0.10629967967730454,
      "grad_norm": 4.4232025146484375,
      "learning_rate": 1.9860268916424993e-05,
      "loss": 0.6456,
      "step": 1792
    },
    {
      "epoch": 0.10635899869498161,
      "grad_norm": 0.011130187660455704,
      "learning_rate": 1.985895069865542e-05,
      "loss": 0.0003,
      "step": 1793
    },
    {
      "epoch": 0.10641831771265868,
      "grad_norm": 13.137185096740723,
      "learning_rate": 1.9857632480885844e-05,
      "loss": 0.5985,
      "step": 1794
    },
    {
      "epoch": 0.10647763673033575,
      "grad_norm": 55.43513870239258,
      "learning_rate": 1.9856314263116267e-05,
      "loss": 0.6059,
      "step": 1795
    },
    {
      "epoch": 0.10653695574801281,
      "grad_norm": 17.917600631713867,
      "learning_rate": 1.9854996045346693e-05,
      "loss": 0.1797,
      "step": 1796
    },
    {
      "epoch": 0.10659627476568988,
      "grad_norm": 0.47782185673713684,
      "learning_rate": 1.985367782757712e-05,
      "loss": 0.0069,
      "step": 1797
    },
    {
      "epoch": 0.10665559378336695,
      "grad_norm": 0.005415050312876701,
      "learning_rate": 1.985235960980754e-05,
      "loss": 0.0001,
      "step": 1798
    },
    {
      "epoch": 0.10671491280104402,
      "grad_norm": 32.883235931396484,
      "learning_rate": 1.9851041392037967e-05,
      "loss": 0.9187,
      "step": 1799
    },
    {
      "epoch": 0.10677423181872109,
      "grad_norm": 13.310556411743164,
      "learning_rate": 1.9849723174268393e-05,
      "loss": 0.0961,
      "step": 1800
    },
    {
      "epoch": 0.10683355083639814,
      "grad_norm": 6.571265697479248,
      "learning_rate": 1.9848404956498815e-05,
      "loss": 0.0445,
      "step": 1801
    },
    {
      "epoch": 0.10689286985407521,
      "grad_norm": 0.5484558939933777,
      "learning_rate": 1.984708673872924e-05,
      "loss": 0.0056,
      "step": 1802
    },
    {
      "epoch": 0.10695218887175229,
      "grad_norm": 0.201209157705307,
      "learning_rate": 1.9845768520959664e-05,
      "loss": 0.0028,
      "step": 1803
    },
    {
      "epoch": 0.10701150788942936,
      "grad_norm": 16.960012435913086,
      "learning_rate": 1.984445030319009e-05,
      "loss": 0.6431,
      "step": 1804
    },
    {
      "epoch": 0.10707082690710641,
      "grad_norm": 10.042051315307617,
      "learning_rate": 1.9843132085420512e-05,
      "loss": 1.0169,
      "step": 1805
    },
    {
      "epoch": 0.10713014592478348,
      "grad_norm": 0.894257128238678,
      "learning_rate": 1.9841813867650938e-05,
      "loss": 0.0146,
      "step": 1806
    },
    {
      "epoch": 0.10718946494246055,
      "grad_norm": 103.31328582763672,
      "learning_rate": 1.984049564988136e-05,
      "loss": 0.9883,
      "step": 1807
    },
    {
      "epoch": 0.10724878396013762,
      "grad_norm": 0.1984342336654663,
      "learning_rate": 1.9839177432111786e-05,
      "loss": 0.0019,
      "step": 1808
    },
    {
      "epoch": 0.10730810297781469,
      "grad_norm": 14.100213050842285,
      "learning_rate": 1.983785921434221e-05,
      "loss": 0.202,
      "step": 1809
    },
    {
      "epoch": 0.10736742199549175,
      "grad_norm": 0.11815619468688965,
      "learning_rate": 1.9836540996572635e-05,
      "loss": 0.0025,
      "step": 1810
    },
    {
      "epoch": 0.10742674101316882,
      "grad_norm": 0.06766381114721298,
      "learning_rate": 1.983522277880306e-05,
      "loss": 0.0008,
      "step": 1811
    },
    {
      "epoch": 0.10748606003084589,
      "grad_norm": 13.119863510131836,
      "learning_rate": 1.9833904561033483e-05,
      "loss": 0.1211,
      "step": 1812
    },
    {
      "epoch": 0.10754537904852296,
      "grad_norm": 35.2301139831543,
      "learning_rate": 1.983258634326391e-05,
      "loss": 1.0547,
      "step": 1813
    },
    {
      "epoch": 0.10760469806620003,
      "grad_norm": 0.06288056075572968,
      "learning_rate": 1.9831268125494335e-05,
      "loss": 0.0011,
      "step": 1814
    },
    {
      "epoch": 0.10766401708387709,
      "grad_norm": 3.071992874145508,
      "learning_rate": 1.9829949907724757e-05,
      "loss": 0.0198,
      "step": 1815
    },
    {
      "epoch": 0.10772333610155416,
      "grad_norm": 9.138009071350098,
      "learning_rate": 1.9828631689955183e-05,
      "loss": 0.27,
      "step": 1816
    },
    {
      "epoch": 0.10778265511923123,
      "grad_norm": 13.693593978881836,
      "learning_rate": 1.982731347218561e-05,
      "loss": 0.3333,
      "step": 1817
    },
    {
      "epoch": 0.1078419741369083,
      "grad_norm": 26.90782928466797,
      "learning_rate": 1.982599525441603e-05,
      "loss": 0.8577,
      "step": 1818
    },
    {
      "epoch": 0.10790129315458535,
      "grad_norm": 4.585622787475586,
      "learning_rate": 1.9824677036646457e-05,
      "loss": 0.065,
      "step": 1819
    },
    {
      "epoch": 0.10796061217226242,
      "grad_norm": 7.663929462432861,
      "learning_rate": 1.982335881887688e-05,
      "loss": 0.0552,
      "step": 1820
    },
    {
      "epoch": 0.1080199311899395,
      "grad_norm": 2.9515626430511475,
      "learning_rate": 1.9822040601107302e-05,
      "loss": 0.0247,
      "step": 1821
    },
    {
      "epoch": 0.10807925020761656,
      "grad_norm": 1.0434576272964478,
      "learning_rate": 1.982072238333773e-05,
      "loss": 0.0213,
      "step": 1822
    },
    {
      "epoch": 0.10813856922529363,
      "grad_norm": 44.42057418823242,
      "learning_rate": 1.981940416556815e-05,
      "loss": 0.628,
      "step": 1823
    },
    {
      "epoch": 0.10819788824297069,
      "grad_norm": 18.72763442993164,
      "learning_rate": 1.9818085947798577e-05,
      "loss": 0.4041,
      "step": 1824
    },
    {
      "epoch": 0.10825720726064776,
      "grad_norm": 0.22971035540103912,
      "learning_rate": 1.9816767730029003e-05,
      "loss": 0.0044,
      "step": 1825
    },
    {
      "epoch": 0.10831652627832483,
      "grad_norm": 10.930180549621582,
      "learning_rate": 1.9815449512259425e-05,
      "loss": 0.1092,
      "step": 1826
    },
    {
      "epoch": 0.1083758452960019,
      "grad_norm": 17.770750045776367,
      "learning_rate": 1.981413129448985e-05,
      "loss": 0.638,
      "step": 1827
    },
    {
      "epoch": 0.10843516431367897,
      "grad_norm": 18.940858840942383,
      "learning_rate": 1.9812813076720277e-05,
      "loss": 0.5739,
      "step": 1828
    },
    {
      "epoch": 0.10849448333135603,
      "grad_norm": 1.948354721069336,
      "learning_rate": 1.98114948589507e-05,
      "loss": 0.0115,
      "step": 1829
    },
    {
      "epoch": 0.1085538023490331,
      "grad_norm": 36.222755432128906,
      "learning_rate": 1.9810176641181125e-05,
      "loss": 0.5019,
      "step": 1830
    },
    {
      "epoch": 0.10861312136671017,
      "grad_norm": 5.695863246917725,
      "learning_rate": 1.980885842341155e-05,
      "loss": 0.0635,
      "step": 1831
    },
    {
      "epoch": 0.10867244038438724,
      "grad_norm": 0.9582344889640808,
      "learning_rate": 1.9807540205641974e-05,
      "loss": 0.0077,
      "step": 1832
    },
    {
      "epoch": 0.1087317594020643,
      "grad_norm": 7.890334129333496,
      "learning_rate": 1.98062219878724e-05,
      "loss": 0.0522,
      "step": 1833
    },
    {
      "epoch": 0.10879107841974137,
      "grad_norm": 7.325939178466797,
      "learning_rate": 1.9804903770102822e-05,
      "loss": 0.0287,
      "step": 1834
    },
    {
      "epoch": 0.10885039743741844,
      "grad_norm": 25.002992630004883,
      "learning_rate": 1.9803585552333248e-05,
      "loss": 0.6705,
      "step": 1835
    },
    {
      "epoch": 0.1089097164550955,
      "grad_norm": 14.414714813232422,
      "learning_rate": 1.980226733456367e-05,
      "loss": 0.4787,
      "step": 1836
    },
    {
      "epoch": 0.10896903547277258,
      "grad_norm": 20.023597717285156,
      "learning_rate": 1.9800949116794096e-05,
      "loss": 0.1696,
      "step": 1837
    },
    {
      "epoch": 0.10902835449044963,
      "grad_norm": 13.11434268951416,
      "learning_rate": 1.979963089902452e-05,
      "loss": 0.3965,
      "step": 1838
    },
    {
      "epoch": 0.1090876735081267,
      "grad_norm": 8.773143768310547,
      "learning_rate": 1.9798312681254945e-05,
      "loss": 0.1301,
      "step": 1839
    },
    {
      "epoch": 0.10914699252580377,
      "grad_norm": 5.5529866218566895,
      "learning_rate": 1.9796994463485367e-05,
      "loss": 0.0431,
      "step": 1840
    },
    {
      "epoch": 0.10920631154348084,
      "grad_norm": 5.31469202041626,
      "learning_rate": 1.9795676245715793e-05,
      "loss": 0.0182,
      "step": 1841
    },
    {
      "epoch": 0.1092656305611579,
      "grad_norm": 35.149864196777344,
      "learning_rate": 1.979435802794622e-05,
      "loss": 0.1391,
      "step": 1842
    },
    {
      "epoch": 0.10932494957883497,
      "grad_norm": 25.296125411987305,
      "learning_rate": 1.979303981017664e-05,
      "loss": 1.4401,
      "step": 1843
    },
    {
      "epoch": 0.10938426859651204,
      "grad_norm": 4.9825119972229,
      "learning_rate": 1.9791721592407067e-05,
      "loss": 0.0276,
      "step": 1844
    },
    {
      "epoch": 0.10944358761418911,
      "grad_norm": 0.12059780210256577,
      "learning_rate": 1.9790403374637493e-05,
      "loss": 0.0025,
      "step": 1845
    },
    {
      "epoch": 0.10950290663186618,
      "grad_norm": 22.039396286010742,
      "learning_rate": 1.9789085156867916e-05,
      "loss": 0.381,
      "step": 1846
    },
    {
      "epoch": 0.10956222564954324,
      "grad_norm": 1.571239709854126,
      "learning_rate": 1.978776693909834e-05,
      "loss": 0.0155,
      "step": 1847
    },
    {
      "epoch": 0.10962154466722031,
      "grad_norm": 21.1003360748291,
      "learning_rate": 1.9786448721328767e-05,
      "loss": 0.2132,
      "step": 1848
    },
    {
      "epoch": 0.10968086368489738,
      "grad_norm": 0.9384000897407532,
      "learning_rate": 1.978513050355919e-05,
      "loss": 0.0058,
      "step": 1849
    },
    {
      "epoch": 0.10974018270257445,
      "grad_norm": 0.13931924104690552,
      "learning_rate": 1.9783812285789616e-05,
      "loss": 0.0016,
      "step": 1850
    },
    {
      "epoch": 0.10979950172025152,
      "grad_norm": 12.387277603149414,
      "learning_rate": 1.9782494068020038e-05,
      "loss": 0.3706,
      "step": 1851
    },
    {
      "epoch": 0.10985882073792858,
      "grad_norm": 0.8144074082374573,
      "learning_rate": 1.9781175850250464e-05,
      "loss": 0.0088,
      "step": 1852
    },
    {
      "epoch": 0.10991813975560565,
      "grad_norm": 0.030882127583026886,
      "learning_rate": 1.9779857632480887e-05,
      "loss": 0.0008,
      "step": 1853
    },
    {
      "epoch": 0.10997745877328272,
      "grad_norm": 0.09024783223867416,
      "learning_rate": 1.9778539414711313e-05,
      "loss": 0.0011,
      "step": 1854
    },
    {
      "epoch": 0.11003677779095979,
      "grad_norm": 37.99784469604492,
      "learning_rate": 1.9777221196941735e-05,
      "loss": 0.245,
      "step": 1855
    },
    {
      "epoch": 0.11009609680863684,
      "grad_norm": 29.462106704711914,
      "learning_rate": 1.977590297917216e-05,
      "loss": 1.7718,
      "step": 1856
    },
    {
      "epoch": 0.11015541582631391,
      "grad_norm": 3.517159938812256,
      "learning_rate": 1.9774584761402583e-05,
      "loss": 0.0223,
      "step": 1857
    },
    {
      "epoch": 0.11021473484399098,
      "grad_norm": 2.6893837451934814,
      "learning_rate": 1.977326654363301e-05,
      "loss": 0.0159,
      "step": 1858
    },
    {
      "epoch": 0.11027405386166805,
      "grad_norm": 0.16398406028747559,
      "learning_rate": 1.9771948325863435e-05,
      "loss": 0.0031,
      "step": 1859
    },
    {
      "epoch": 0.11033337287934512,
      "grad_norm": 18.237529754638672,
      "learning_rate": 1.9770630108093858e-05,
      "loss": 0.0568,
      "step": 1860
    },
    {
      "epoch": 0.11039269189702218,
      "grad_norm": 76.96703338623047,
      "learning_rate": 1.9769311890324284e-05,
      "loss": 1.1875,
      "step": 1861
    },
    {
      "epoch": 0.11045201091469925,
      "grad_norm": 11.23691463470459,
      "learning_rate": 1.976799367255471e-05,
      "loss": 0.0576,
      "step": 1862
    },
    {
      "epoch": 0.11051132993237632,
      "grad_norm": 23.283445358276367,
      "learning_rate": 1.9766675454785132e-05,
      "loss": 1.1597,
      "step": 1863
    },
    {
      "epoch": 0.11057064895005339,
      "grad_norm": 31.48837661743164,
      "learning_rate": 1.9765357237015558e-05,
      "loss": 0.4346,
      "step": 1864
    },
    {
      "epoch": 0.11062996796773046,
      "grad_norm": 0.03238557279109955,
      "learning_rate": 1.976403901924598e-05,
      "loss": 0.0006,
      "step": 1865
    },
    {
      "epoch": 0.11068928698540752,
      "grad_norm": 7.342925071716309,
      "learning_rate": 1.9762720801476406e-05,
      "loss": 0.3589,
      "step": 1866
    },
    {
      "epoch": 0.11074860600308459,
      "grad_norm": 22.72536849975586,
      "learning_rate": 1.976140258370683e-05,
      "loss": 0.6785,
      "step": 1867
    },
    {
      "epoch": 0.11080792502076166,
      "grad_norm": 0.6485218405723572,
      "learning_rate": 1.9760084365937255e-05,
      "loss": 0.0043,
      "step": 1868
    },
    {
      "epoch": 0.11086724403843873,
      "grad_norm": 0.13831542432308197,
      "learning_rate": 1.9758766148167677e-05,
      "loss": 0.0023,
      "step": 1869
    },
    {
      "epoch": 0.11092656305611578,
      "grad_norm": 0.522592306137085,
      "learning_rate": 1.9757447930398103e-05,
      "loss": 0.0012,
      "step": 1870
    },
    {
      "epoch": 0.11098588207379285,
      "grad_norm": 21.662397384643555,
      "learning_rate": 1.9756129712628525e-05,
      "loss": 1.1034,
      "step": 1871
    },
    {
      "epoch": 0.11104520109146993,
      "grad_norm": 2.7284841537475586,
      "learning_rate": 1.975481149485895e-05,
      "loss": 0.0208,
      "step": 1872
    },
    {
      "epoch": 0.111104520109147,
      "grad_norm": 11.913434028625488,
      "learning_rate": 1.9753493277089377e-05,
      "loss": 0.3357,
      "step": 1873
    },
    {
      "epoch": 0.11116383912682407,
      "grad_norm": 13.444726943969727,
      "learning_rate": 1.97521750593198e-05,
      "loss": 0.1352,
      "step": 1874
    },
    {
      "epoch": 0.11122315814450112,
      "grad_norm": 12.485007286071777,
      "learning_rate": 1.9750856841550226e-05,
      "loss": 0.4063,
      "step": 1875
    },
    {
      "epoch": 0.11128247716217819,
      "grad_norm": 4.7693023681640625,
      "learning_rate": 1.974953862378065e-05,
      "loss": 0.0613,
      "step": 1876
    },
    {
      "epoch": 0.11134179617985526,
      "grad_norm": 1.5877152681350708,
      "learning_rate": 1.9748220406011074e-05,
      "loss": 0.0123,
      "step": 1877
    },
    {
      "epoch": 0.11140111519753233,
      "grad_norm": 0.32147708535194397,
      "learning_rate": 1.97469021882415e-05,
      "loss": 0.0033,
      "step": 1878
    },
    {
      "epoch": 0.1114604342152094,
      "grad_norm": 10.938427925109863,
      "learning_rate": 1.9745583970471926e-05,
      "loss": 0.3647,
      "step": 1879
    },
    {
      "epoch": 0.11151975323288646,
      "grad_norm": 0.7734147906303406,
      "learning_rate": 1.9744265752702348e-05,
      "loss": 0.0083,
      "step": 1880
    },
    {
      "epoch": 0.11157907225056353,
      "grad_norm": 43.86785125732422,
      "learning_rate": 1.9742947534932774e-05,
      "loss": 1.6174,
      "step": 1881
    },
    {
      "epoch": 0.1116383912682406,
      "grad_norm": 12.622840881347656,
      "learning_rate": 1.9741629317163197e-05,
      "loss": 0.1778,
      "step": 1882
    },
    {
      "epoch": 0.11169771028591767,
      "grad_norm": 8.700052261352539,
      "learning_rate": 1.9740311099393622e-05,
      "loss": 0.2386,
      "step": 1883
    },
    {
      "epoch": 0.11175702930359473,
      "grad_norm": 3.9171411991119385,
      "learning_rate": 1.9738992881624045e-05,
      "loss": 0.0396,
      "step": 1884
    },
    {
      "epoch": 0.1118163483212718,
      "grad_norm": 0.5374526977539062,
      "learning_rate": 1.973767466385447e-05,
      "loss": 0.0057,
      "step": 1885
    },
    {
      "epoch": 0.11187566733894887,
      "grad_norm": 11.79708480834961,
      "learning_rate": 1.9736356446084893e-05,
      "loss": 0.137,
      "step": 1886
    },
    {
      "epoch": 0.11193498635662594,
      "grad_norm": 0.4277007281780243,
      "learning_rate": 1.973503822831532e-05,
      "loss": 0.0072,
      "step": 1887
    },
    {
      "epoch": 0.11199430537430301,
      "grad_norm": 9.800515174865723,
      "learning_rate": 1.973372001054574e-05,
      "loss": 0.4068,
      "step": 1888
    },
    {
      "epoch": 0.11205362439198006,
      "grad_norm": 39.50391387939453,
      "learning_rate": 1.9732401792776168e-05,
      "loss": 0.2765,
      "step": 1889
    },
    {
      "epoch": 0.11211294340965713,
      "grad_norm": 17.231861114501953,
      "learning_rate": 1.9731083575006593e-05,
      "loss": 0.0541,
      "step": 1890
    },
    {
      "epoch": 0.1121722624273342,
      "grad_norm": 0.25846412777900696,
      "learning_rate": 1.9729765357237016e-05,
      "loss": 0.0017,
      "step": 1891
    },
    {
      "epoch": 0.11223158144501127,
      "grad_norm": 0.032536573708057404,
      "learning_rate": 1.9728447139467442e-05,
      "loss": 0.0005,
      "step": 1892
    },
    {
      "epoch": 0.11229090046268833,
      "grad_norm": 7.073793411254883,
      "learning_rate": 1.9727128921697868e-05,
      "loss": 0.083,
      "step": 1893
    },
    {
      "epoch": 0.1123502194803654,
      "grad_norm": 16.308469772338867,
      "learning_rate": 1.972581070392829e-05,
      "loss": 0.3567,
      "step": 1894
    },
    {
      "epoch": 0.11240953849804247,
      "grad_norm": 5.303832054138184,
      "learning_rate": 1.9724492486158716e-05,
      "loss": 0.1943,
      "step": 1895
    },
    {
      "epoch": 0.11246885751571954,
      "grad_norm": 1.5656710863113403,
      "learning_rate": 1.9723174268389142e-05,
      "loss": 0.0135,
      "step": 1896
    },
    {
      "epoch": 0.11252817653339661,
      "grad_norm": 9.335254669189453,
      "learning_rate": 1.9721856050619564e-05,
      "loss": 0.127,
      "step": 1897
    },
    {
      "epoch": 0.11258749555107367,
      "grad_norm": 0.30872610211372375,
      "learning_rate": 1.9720537832849987e-05,
      "loss": 0.003,
      "step": 1898
    },
    {
      "epoch": 0.11264681456875074,
      "grad_norm": 0.01133439876139164,
      "learning_rate": 1.9719219615080413e-05,
      "loss": 0.0003,
      "step": 1899
    },
    {
      "epoch": 0.11270613358642781,
      "grad_norm": 12.156777381896973,
      "learning_rate": 1.9717901397310835e-05,
      "loss": 0.1654,
      "step": 1900
    },
    {
      "epoch": 0.11276545260410488,
      "grad_norm": 30.225528717041016,
      "learning_rate": 1.971658317954126e-05,
      "loss": 0.5596,
      "step": 1901
    },
    {
      "epoch": 0.11282477162178195,
      "grad_norm": 32.61360168457031,
      "learning_rate": 1.9715264961771687e-05,
      "loss": 0.7267,
      "step": 1902
    },
    {
      "epoch": 0.112884090639459,
      "grad_norm": 3.316751480102539,
      "learning_rate": 1.971394674400211e-05,
      "loss": 0.0459,
      "step": 1903
    },
    {
      "epoch": 0.11294340965713608,
      "grad_norm": 10.455100059509277,
      "learning_rate": 1.9712628526232535e-05,
      "loss": 0.3748,
      "step": 1904
    },
    {
      "epoch": 0.11300272867481315,
      "grad_norm": 7.621172904968262,
      "learning_rate": 1.9711310308462958e-05,
      "loss": 0.6545,
      "step": 1905
    },
    {
      "epoch": 0.11306204769249022,
      "grad_norm": 15.220565795898438,
      "learning_rate": 1.9709992090693384e-05,
      "loss": 0.1966,
      "step": 1906
    },
    {
      "epoch": 0.11312136671016727,
      "grad_norm": 0.16552533209323883,
      "learning_rate": 1.970867387292381e-05,
      "loss": 0.0013,
      "step": 1907
    },
    {
      "epoch": 0.11318068572784434,
      "grad_norm": 11.063081741333008,
      "learning_rate": 1.9707355655154232e-05,
      "loss": 0.4796,
      "step": 1908
    },
    {
      "epoch": 0.11324000474552141,
      "grad_norm": 7.707054615020752,
      "learning_rate": 1.9706037437384658e-05,
      "loss": 0.0399,
      "step": 1909
    },
    {
      "epoch": 0.11329932376319848,
      "grad_norm": 16.307113647460938,
      "learning_rate": 1.9704719219615084e-05,
      "loss": 0.585,
      "step": 1910
    },
    {
      "epoch": 0.11335864278087555,
      "grad_norm": 8.912778854370117,
      "learning_rate": 1.9703401001845506e-05,
      "loss": 0.3022,
      "step": 1911
    },
    {
      "epoch": 0.11341796179855261,
      "grad_norm": 1.354289174079895,
      "learning_rate": 1.9702082784075932e-05,
      "loss": 0.006,
      "step": 1912
    },
    {
      "epoch": 0.11347728081622968,
      "grad_norm": 33.81754684448242,
      "learning_rate": 1.9700764566306355e-05,
      "loss": 0.3198,
      "step": 1913
    },
    {
      "epoch": 0.11353659983390675,
      "grad_norm": 36.22502136230469,
      "learning_rate": 1.969944634853678e-05,
      "loss": 0.5299,
      "step": 1914
    },
    {
      "epoch": 0.11359591885158382,
      "grad_norm": 0.09147089719772339,
      "learning_rate": 1.9698128130767203e-05,
      "loss": 0.0007,
      "step": 1915
    },
    {
      "epoch": 0.11365523786926089,
      "grad_norm": 0.03974379599094391,
      "learning_rate": 1.969680991299763e-05,
      "loss": 0.0008,
      "step": 1916
    },
    {
      "epoch": 0.11371455688693795,
      "grad_norm": 28.739835739135742,
      "learning_rate": 1.969549169522805e-05,
      "loss": 1.0031,
      "step": 1917
    },
    {
      "epoch": 0.11377387590461502,
      "grad_norm": 0.050417460501194,
      "learning_rate": 1.9694173477458477e-05,
      "loss": 0.0013,
      "step": 1918
    },
    {
      "epoch": 0.11383319492229209,
      "grad_norm": 0.48366087675094604,
      "learning_rate": 1.9692855259688903e-05,
      "loss": 0.0052,
      "step": 1919
    },
    {
      "epoch": 0.11389251393996916,
      "grad_norm": 0.038164831697940826,
      "learning_rate": 1.9691537041919326e-05,
      "loss": 0.0006,
      "step": 1920
    },
    {
      "epoch": 0.11395183295764622,
      "grad_norm": 11.34743881225586,
      "learning_rate": 1.969021882414975e-05,
      "loss": 0.9882,
      "step": 1921
    },
    {
      "epoch": 0.11401115197532329,
      "grad_norm": 25.920440673828125,
      "learning_rate": 1.9688900606380174e-05,
      "loss": 0.7035,
      "step": 1922
    },
    {
      "epoch": 0.11407047099300036,
      "grad_norm": 2.639766216278076,
      "learning_rate": 1.96875823886106e-05,
      "loss": 0.043,
      "step": 1923
    },
    {
      "epoch": 0.11412979001067743,
      "grad_norm": 19.71025276184082,
      "learning_rate": 1.9686264170841026e-05,
      "loss": 0.2896,
      "step": 1924
    },
    {
      "epoch": 0.1141891090283545,
      "grad_norm": 23.29302215576172,
      "learning_rate": 1.968494595307145e-05,
      "loss": 0.7783,
      "step": 1925
    },
    {
      "epoch": 0.11424842804603155,
      "grad_norm": 13.164106369018555,
      "learning_rate": 1.9683627735301874e-05,
      "loss": 0.0729,
      "step": 1926
    },
    {
      "epoch": 0.11430774706370862,
      "grad_norm": 12.687636375427246,
      "learning_rate": 1.96823095175323e-05,
      "loss": 0.7643,
      "step": 1927
    },
    {
      "epoch": 0.1143670660813857,
      "grad_norm": 0.18089258670806885,
      "learning_rate": 1.9680991299762723e-05,
      "loss": 0.0015,
      "step": 1928
    },
    {
      "epoch": 0.11442638509906276,
      "grad_norm": 27.404972076416016,
      "learning_rate": 1.967967308199315e-05,
      "loss": 0.8286,
      "step": 1929
    },
    {
      "epoch": 0.11448570411673983,
      "grad_norm": 25.11716651916504,
      "learning_rate": 1.967835486422357e-05,
      "loss": 0.4729,
      "step": 1930
    },
    {
      "epoch": 0.11454502313441689,
      "grad_norm": 0.712995707988739,
      "learning_rate": 1.9677036646453997e-05,
      "loss": 0.0085,
      "step": 1931
    },
    {
      "epoch": 0.11460434215209396,
      "grad_norm": 7.897322654724121,
      "learning_rate": 1.967571842868442e-05,
      "loss": 0.0937,
      "step": 1932
    },
    {
      "epoch": 0.11466366116977103,
      "grad_norm": 35.83353805541992,
      "learning_rate": 1.9674400210914845e-05,
      "loss": 0.279,
      "step": 1933
    },
    {
      "epoch": 0.1147229801874481,
      "grad_norm": 1.8401942253112793,
      "learning_rate": 1.9673081993145268e-05,
      "loss": 0.0131,
      "step": 1934
    },
    {
      "epoch": 0.11478229920512516,
      "grad_norm": 9.189449310302734,
      "learning_rate": 1.9671763775375694e-05,
      "loss": 0.2136,
      "step": 1935
    },
    {
      "epoch": 0.11484161822280223,
      "grad_norm": 25.550628662109375,
      "learning_rate": 1.9670445557606116e-05,
      "loss": 0.4844,
      "step": 1936
    },
    {
      "epoch": 0.1149009372404793,
      "grad_norm": 0.9992272853851318,
      "learning_rate": 1.9669127339836542e-05,
      "loss": 0.0046,
      "step": 1937
    },
    {
      "epoch": 0.11496025625815637,
      "grad_norm": 0.39095431566238403,
      "learning_rate": 1.9667809122066968e-05,
      "loss": 0.0072,
      "step": 1938
    },
    {
      "epoch": 0.11501957527583344,
      "grad_norm": 10.338289260864258,
      "learning_rate": 1.966649090429739e-05,
      "loss": 0.1018,
      "step": 1939
    },
    {
      "epoch": 0.1150788942935105,
      "grad_norm": 0.3302549421787262,
      "learning_rate": 1.9665172686527816e-05,
      "loss": 0.0029,
      "step": 1940
    },
    {
      "epoch": 0.11513821331118756,
      "grad_norm": 7.665195941925049,
      "learning_rate": 1.9663854468758242e-05,
      "loss": 0.1422,
      "step": 1941
    },
    {
      "epoch": 0.11519753232886464,
      "grad_norm": 4.6472907066345215,
      "learning_rate": 1.9662536250988665e-05,
      "loss": 0.0414,
      "step": 1942
    },
    {
      "epoch": 0.1152568513465417,
      "grad_norm": 8.749403953552246,
      "learning_rate": 1.966121803321909e-05,
      "loss": 0.0999,
      "step": 1943
    },
    {
      "epoch": 0.11531617036421876,
      "grad_norm": 50.45165252685547,
      "learning_rate": 1.9659899815449513e-05,
      "loss": 0.2685,
      "step": 1944
    },
    {
      "epoch": 0.11537548938189583,
      "grad_norm": 22.837623596191406,
      "learning_rate": 1.965858159767994e-05,
      "loss": 0.5665,
      "step": 1945
    },
    {
      "epoch": 0.1154348083995729,
      "grad_norm": 5.288039684295654,
      "learning_rate": 1.965726337991036e-05,
      "loss": 0.0434,
      "step": 1946
    },
    {
      "epoch": 0.11549412741724997,
      "grad_norm": 16.295673370361328,
      "learning_rate": 1.9655945162140787e-05,
      "loss": 0.1352,
      "step": 1947
    },
    {
      "epoch": 0.11555344643492704,
      "grad_norm": 7.43202543258667,
      "learning_rate": 1.965462694437121e-05,
      "loss": 0.1049,
      "step": 1948
    },
    {
      "epoch": 0.1156127654526041,
      "grad_norm": 0.19842511415481567,
      "learning_rate": 1.9653308726601636e-05,
      "loss": 0.0027,
      "step": 1949
    },
    {
      "epoch": 0.11567208447028117,
      "grad_norm": 18.702621459960938,
      "learning_rate": 1.965199050883206e-05,
      "loss": 0.0671,
      "step": 1950
    },
    {
      "epoch": 0.11573140348795824,
      "grad_norm": 0.09706771373748779,
      "learning_rate": 1.9650672291062484e-05,
      "loss": 0.0014,
      "step": 1951
    },
    {
      "epoch": 0.11579072250563531,
      "grad_norm": 12.466496467590332,
      "learning_rate": 1.964935407329291e-05,
      "loss": 0.1722,
      "step": 1952
    },
    {
      "epoch": 0.11585004152331238,
      "grad_norm": 10.250978469848633,
      "learning_rate": 1.9648035855523332e-05,
      "loss": 0.0341,
      "step": 1953
    },
    {
      "epoch": 0.11590936054098944,
      "grad_norm": 17.295238494873047,
      "learning_rate": 1.964671763775376e-05,
      "loss": 0.3343,
      "step": 1954
    },
    {
      "epoch": 0.11596867955866651,
      "grad_norm": 94.49056243896484,
      "learning_rate": 1.9645399419984184e-05,
      "loss": 0.3037,
      "step": 1955
    },
    {
      "epoch": 0.11602799857634358,
      "grad_norm": 0.6339442729949951,
      "learning_rate": 1.9644081202214607e-05,
      "loss": 0.0052,
      "step": 1956
    },
    {
      "epoch": 0.11608731759402065,
      "grad_norm": 0.12446480244398117,
      "learning_rate": 1.9642762984445033e-05,
      "loss": 0.0018,
      "step": 1957
    },
    {
      "epoch": 0.1161466366116977,
      "grad_norm": 52.70362854003906,
      "learning_rate": 1.964144476667546e-05,
      "loss": 0.8719,
      "step": 1958
    },
    {
      "epoch": 0.11620595562937477,
      "grad_norm": 0.48156851530075073,
      "learning_rate": 1.964012654890588e-05,
      "loss": 0.0053,
      "step": 1959
    },
    {
      "epoch": 0.11626527464705184,
      "grad_norm": 34.35957336425781,
      "learning_rate": 1.9638808331136307e-05,
      "loss": 0.4146,
      "step": 1960
    },
    {
      "epoch": 0.11632459366472891,
      "grad_norm": 0.29466646909713745,
      "learning_rate": 1.963749011336673e-05,
      "loss": 0.0049,
      "step": 1961
    },
    {
      "epoch": 0.11638391268240598,
      "grad_norm": 31.79156494140625,
      "learning_rate": 1.9636171895597155e-05,
      "loss": 0.3692,
      "step": 1962
    },
    {
      "epoch": 0.11644323170008304,
      "grad_norm": 14.09549331665039,
      "learning_rate": 1.9634853677827578e-05,
      "loss": 0.042,
      "step": 1963
    },
    {
      "epoch": 0.11650255071776011,
      "grad_norm": 9.336103439331055,
      "learning_rate": 1.9633535460058004e-05,
      "loss": 0.5268,
      "step": 1964
    },
    {
      "epoch": 0.11656186973543718,
      "grad_norm": 0.8681945204734802,
      "learning_rate": 1.9632217242288426e-05,
      "loss": 0.0094,
      "step": 1965
    },
    {
      "epoch": 0.11662118875311425,
      "grad_norm": 5.833942413330078,
      "learning_rate": 1.9630899024518852e-05,
      "loss": 0.0486,
      "step": 1966
    },
    {
      "epoch": 0.11668050777079132,
      "grad_norm": 1.632191777229309,
      "learning_rate": 1.9629580806749278e-05,
      "loss": 0.0186,
      "step": 1967
    },
    {
      "epoch": 0.11673982678846838,
      "grad_norm": 6.464236736297607,
      "learning_rate": 1.96282625889797e-05,
      "loss": 0.085,
      "step": 1968
    },
    {
      "epoch": 0.11679914580614545,
      "grad_norm": 2.413914442062378,
      "learning_rate": 1.9626944371210126e-05,
      "loss": 0.0162,
      "step": 1969
    },
    {
      "epoch": 0.11685846482382252,
      "grad_norm": 23.787757873535156,
      "learning_rate": 1.962562615344055e-05,
      "loss": 1.423,
      "step": 1970
    },
    {
      "epoch": 0.11691778384149959,
      "grad_norm": 0.07586190849542618,
      "learning_rate": 1.9624307935670975e-05,
      "loss": 0.0017,
      "step": 1971
    },
    {
      "epoch": 0.11697710285917665,
      "grad_norm": 11.580215454101562,
      "learning_rate": 1.96229897179014e-05,
      "loss": 0.387,
      "step": 1972
    },
    {
      "epoch": 0.11703642187685372,
      "grad_norm": 3.2677230834960938,
      "learning_rate": 1.9621671500131823e-05,
      "loss": 0.0344,
      "step": 1973
    },
    {
      "epoch": 0.11709574089453079,
      "grad_norm": 13.316149711608887,
      "learning_rate": 1.962035328236225e-05,
      "loss": 0.0737,
      "step": 1974
    },
    {
      "epoch": 0.11715505991220786,
      "grad_norm": 27.447860717773438,
      "learning_rate": 1.9619035064592675e-05,
      "loss": 1.1275,
      "step": 1975
    },
    {
      "epoch": 0.11721437892988493,
      "grad_norm": 10.407122611999512,
      "learning_rate": 1.9617716846823097e-05,
      "loss": 0.3222,
      "step": 1976
    },
    {
      "epoch": 0.11727369794756198,
      "grad_norm": 44.94478225708008,
      "learning_rate": 1.961639862905352e-05,
      "loss": 0.3064,
      "step": 1977
    },
    {
      "epoch": 0.11733301696523905,
      "grad_norm": 5.912297248840332,
      "learning_rate": 1.9615080411283946e-05,
      "loss": 0.0419,
      "step": 1978
    },
    {
      "epoch": 0.11739233598291612,
      "grad_norm": 3.049668550491333,
      "learning_rate": 1.9613762193514368e-05,
      "loss": 0.0071,
      "step": 1979
    },
    {
      "epoch": 0.1174516550005932,
      "grad_norm": 4.94427490234375,
      "learning_rate": 1.9612443975744794e-05,
      "loss": 0.0301,
      "step": 1980
    },
    {
      "epoch": 0.11751097401827025,
      "grad_norm": 0.5343838930130005,
      "learning_rate": 1.961112575797522e-05,
      "loss": 0.0085,
      "step": 1981
    },
    {
      "epoch": 0.11757029303594732,
      "grad_norm": 3.4212138652801514,
      "learning_rate": 1.9609807540205642e-05,
      "loss": 0.0433,
      "step": 1982
    },
    {
      "epoch": 0.11762961205362439,
      "grad_norm": 20.160667419433594,
      "learning_rate": 1.9608489322436068e-05,
      "loss": 0.7225,
      "step": 1983
    },
    {
      "epoch": 0.11768893107130146,
      "grad_norm": 27.14240074157715,
      "learning_rate": 1.960717110466649e-05,
      "loss": 1.0877,
      "step": 1984
    },
    {
      "epoch": 0.11774825008897853,
      "grad_norm": 12.040621757507324,
      "learning_rate": 1.9605852886896917e-05,
      "loss": 0.167,
      "step": 1985
    },
    {
      "epoch": 0.11780756910665559,
      "grad_norm": 0.03045761026442051,
      "learning_rate": 1.9604534669127342e-05,
      "loss": 0.0005,
      "step": 1986
    },
    {
      "epoch": 0.11786688812433266,
      "grad_norm": 27.28318214416504,
      "learning_rate": 1.9603216451357765e-05,
      "loss": 0.8516,
      "step": 1987
    },
    {
      "epoch": 0.11792620714200973,
      "grad_norm": 0.12476493418216705,
      "learning_rate": 1.960189823358819e-05,
      "loss": 0.0017,
      "step": 1988
    },
    {
      "epoch": 0.1179855261596868,
      "grad_norm": 15.82370662689209,
      "learning_rate": 1.9600580015818617e-05,
      "loss": 1.1389,
      "step": 1989
    },
    {
      "epoch": 0.11804484517736387,
      "grad_norm": 2.3424153327941895,
      "learning_rate": 1.959926179804904e-05,
      "loss": 0.0147,
      "step": 1990
    },
    {
      "epoch": 0.11810416419504093,
      "grad_norm": 9.286168098449707,
      "learning_rate": 1.9597943580279465e-05,
      "loss": 0.1489,
      "step": 1991
    },
    {
      "epoch": 0.118163483212718,
      "grad_norm": 18.714187622070312,
      "learning_rate": 1.9596625362509888e-05,
      "loss": 0.8681,
      "step": 1992
    },
    {
      "epoch": 0.11822280223039507,
      "grad_norm": 7.7069315910339355,
      "learning_rate": 1.9595307144740313e-05,
      "loss": 0.1765,
      "step": 1993
    },
    {
      "epoch": 0.11828212124807214,
      "grad_norm": 10.289827346801758,
      "learning_rate": 1.9593988926970736e-05,
      "loss": 0.1406,
      "step": 1994
    },
    {
      "epoch": 0.11834144026574919,
      "grad_norm": 12.895035743713379,
      "learning_rate": 1.9592670709201162e-05,
      "loss": 0.8583,
      "step": 1995
    },
    {
      "epoch": 0.11840075928342626,
      "grad_norm": 11.169584274291992,
      "learning_rate": 1.9591352491431584e-05,
      "loss": 0.501,
      "step": 1996
    },
    {
      "epoch": 0.11846007830110333,
      "grad_norm": 1.055335521697998,
      "learning_rate": 1.959003427366201e-05,
      "loss": 0.0046,
      "step": 1997
    },
    {
      "epoch": 0.1185193973187804,
      "grad_norm": 14.395147323608398,
      "learning_rate": 1.9588716055892436e-05,
      "loss": 0.5786,
      "step": 1998
    },
    {
      "epoch": 0.11857871633645747,
      "grad_norm": 0.04430964216589928,
      "learning_rate": 1.958739783812286e-05,
      "loss": 0.0007,
      "step": 1999
    },
    {
      "epoch": 0.11863803535413453,
      "grad_norm": 5.966296672821045,
      "learning_rate": 1.9586079620353284e-05,
      "loss": 0.1503,
      "step": 2000
    },
    {
      "epoch": 0.1186973543718116,
      "grad_norm": 34.83024215698242,
      "learning_rate": 1.9584761402583707e-05,
      "loss": 1.454,
      "step": 2001
    },
    {
      "epoch": 0.11875667338948867,
      "grad_norm": 6.579766273498535,
      "learning_rate": 1.9583443184814133e-05,
      "loss": 0.1108,
      "step": 2002
    },
    {
      "epoch": 0.11881599240716574,
      "grad_norm": 12.038656234741211,
      "learning_rate": 1.958212496704456e-05,
      "loss": 0.2725,
      "step": 2003
    },
    {
      "epoch": 0.11887531142484281,
      "grad_norm": 22.36051368713379,
      "learning_rate": 1.958080674927498e-05,
      "loss": 1.1089,
      "step": 2004
    },
    {
      "epoch": 0.11893463044251987,
      "grad_norm": 7.42245626449585,
      "learning_rate": 1.9579488531505407e-05,
      "loss": 0.124,
      "step": 2005
    },
    {
      "epoch": 0.11899394946019694,
      "grad_norm": 23.626846313476562,
      "learning_rate": 1.9578170313735833e-05,
      "loss": 0.701,
      "step": 2006
    },
    {
      "epoch": 0.11905326847787401,
      "grad_norm": 1.8346400260925293,
      "learning_rate": 1.9576852095966255e-05,
      "loss": 0.0141,
      "step": 2007
    },
    {
      "epoch": 0.11911258749555108,
      "grad_norm": 0.05125083029270172,
      "learning_rate": 1.957553387819668e-05,
      "loss": 0.0011,
      "step": 2008
    },
    {
      "epoch": 0.11917190651322813,
      "grad_norm": 17.945446014404297,
      "learning_rate": 1.9574215660427104e-05,
      "loss": 0.1367,
      "step": 2009
    },
    {
      "epoch": 0.1192312255309052,
      "grad_norm": 5.670905113220215,
      "learning_rate": 1.9572897442657526e-05,
      "loss": 0.0782,
      "step": 2010
    },
    {
      "epoch": 0.11929054454858228,
      "grad_norm": 9.064034461975098,
      "learning_rate": 1.9571579224887952e-05,
      "loss": 0.26,
      "step": 2011
    },
    {
      "epoch": 0.11934986356625935,
      "grad_norm": 16.80436134338379,
      "learning_rate": 1.9570261007118378e-05,
      "loss": 0.3088,
      "step": 2012
    },
    {
      "epoch": 0.11940918258393642,
      "grad_norm": 76.43623352050781,
      "learning_rate": 1.95689427893488e-05,
      "loss": 2.8578,
      "step": 2013
    },
    {
      "epoch": 0.11946850160161347,
      "grad_norm": 0.23435276746749878,
      "learning_rate": 1.9567624571579226e-05,
      "loss": 0.0023,
      "step": 2014
    },
    {
      "epoch": 0.11952782061929054,
      "grad_norm": 5.118841648101807,
      "learning_rate": 1.9566306353809652e-05,
      "loss": 0.2112,
      "step": 2015
    },
    {
      "epoch": 0.11958713963696761,
      "grad_norm": 32.900970458984375,
      "learning_rate": 1.9564988136040075e-05,
      "loss": 0.5533,
      "step": 2016
    },
    {
      "epoch": 0.11964645865464468,
      "grad_norm": 7.22422981262207,
      "learning_rate": 1.95636699182705e-05,
      "loss": 0.0594,
      "step": 2017
    },
    {
      "epoch": 0.11970577767232175,
      "grad_norm": 4.6348090171813965,
      "learning_rate": 1.9562351700500923e-05,
      "loss": 0.0255,
      "step": 2018
    },
    {
      "epoch": 0.11976509668999881,
      "grad_norm": 10.90060806274414,
      "learning_rate": 1.956103348273135e-05,
      "loss": 0.4003,
      "step": 2019
    },
    {
      "epoch": 0.11982441570767588,
      "grad_norm": 1.5676908493041992,
      "learning_rate": 1.9559715264961775e-05,
      "loss": 0.0059,
      "step": 2020
    },
    {
      "epoch": 0.11988373472535295,
      "grad_norm": 20.704004287719727,
      "learning_rate": 1.9558397047192197e-05,
      "loss": 0.535,
      "step": 2021
    },
    {
      "epoch": 0.11994305374303002,
      "grad_norm": 19.124849319458008,
      "learning_rate": 1.9557078829422623e-05,
      "loss": 0.637,
      "step": 2022
    },
    {
      "epoch": 0.12000237276070708,
      "grad_norm": 3.9126596450805664,
      "learning_rate": 1.9555760611653046e-05,
      "loss": 0.0182,
      "step": 2023
    },
    {
      "epoch": 0.12006169177838415,
      "grad_norm": 0.6090683341026306,
      "learning_rate": 1.9554442393883472e-05,
      "loss": 0.0064,
      "step": 2024
    },
    {
      "epoch": 0.12012101079606122,
      "grad_norm": 0.8446335792541504,
      "learning_rate": 1.9553124176113894e-05,
      "loss": 0.0117,
      "step": 2025
    },
    {
      "epoch": 0.12018032981373829,
      "grad_norm": 0.12940888106822968,
      "learning_rate": 1.955180595834432e-05,
      "loss": 0.002,
      "step": 2026
    },
    {
      "epoch": 0.12023964883141536,
      "grad_norm": 16.438196182250977,
      "learning_rate": 1.9550487740574743e-05,
      "loss": 0.5014,
      "step": 2027
    },
    {
      "epoch": 0.12029896784909241,
      "grad_norm": 18.789194107055664,
      "learning_rate": 1.954916952280517e-05,
      "loss": 1.1592,
      "step": 2028
    },
    {
      "epoch": 0.12035828686676948,
      "grad_norm": 6.939211368560791,
      "learning_rate": 1.9547851305035594e-05,
      "loss": 0.097,
      "step": 2029
    },
    {
      "epoch": 0.12041760588444655,
      "grad_norm": 4.277002334594727,
      "learning_rate": 1.9546533087266017e-05,
      "loss": 0.0288,
      "step": 2030
    },
    {
      "epoch": 0.12047692490212362,
      "grad_norm": 10.090204238891602,
      "learning_rate": 1.9545214869496443e-05,
      "loss": 0.8032,
      "step": 2031
    },
    {
      "epoch": 0.12053624391980068,
      "grad_norm": 11.499403953552246,
      "learning_rate": 1.9543896651726865e-05,
      "loss": 0.2628,
      "step": 2032
    },
    {
      "epoch": 0.12059556293747775,
      "grad_norm": 3.5645670890808105,
      "learning_rate": 1.954257843395729e-05,
      "loss": 0.0712,
      "step": 2033
    },
    {
      "epoch": 0.12065488195515482,
      "grad_norm": 4.997496604919434,
      "learning_rate": 1.9541260216187717e-05,
      "loss": 0.1072,
      "step": 2034
    },
    {
      "epoch": 0.12071420097283189,
      "grad_norm": 0.7259389758110046,
      "learning_rate": 1.953994199841814e-05,
      "loss": 0.0093,
      "step": 2035
    },
    {
      "epoch": 0.12077351999050896,
      "grad_norm": 6.671255588531494,
      "learning_rate": 1.9538623780648565e-05,
      "loss": 0.0941,
      "step": 2036
    },
    {
      "epoch": 0.12083283900818602,
      "grad_norm": 16.618696212768555,
      "learning_rate": 1.953730556287899e-05,
      "loss": 0.3931,
      "step": 2037
    },
    {
      "epoch": 0.12089215802586309,
      "grad_norm": 2.212608575820923,
      "learning_rate": 1.9535987345109414e-05,
      "loss": 0.0215,
      "step": 2038
    },
    {
      "epoch": 0.12095147704354016,
      "grad_norm": 2.7774529457092285,
      "learning_rate": 1.953466912733984e-05,
      "loss": 0.0559,
      "step": 2039
    },
    {
      "epoch": 0.12101079606121723,
      "grad_norm": 4.841415882110596,
      "learning_rate": 1.9533350909570262e-05,
      "loss": 0.0671,
      "step": 2040
    },
    {
      "epoch": 0.1210701150788943,
      "grad_norm": 2.3370203971862793,
      "learning_rate": 1.9532032691800688e-05,
      "loss": 0.0351,
      "step": 2041
    },
    {
      "epoch": 0.12112943409657136,
      "grad_norm": 17.930158615112305,
      "learning_rate": 1.953071447403111e-05,
      "loss": 1.1333,
      "step": 2042
    },
    {
      "epoch": 0.12118875311424843,
      "grad_norm": 0.739870011806488,
      "learning_rate": 1.9529396256261536e-05,
      "loss": 0.0102,
      "step": 2043
    },
    {
      "epoch": 0.1212480721319255,
      "grad_norm": 0.7857604026794434,
      "learning_rate": 1.952807803849196e-05,
      "loss": 0.0038,
      "step": 2044
    },
    {
      "epoch": 0.12130739114960257,
      "grad_norm": 2.754485845565796,
      "learning_rate": 1.9526759820722385e-05,
      "loss": 0.0203,
      "step": 2045
    },
    {
      "epoch": 0.12136671016727962,
      "grad_norm": 8.855405807495117,
      "learning_rate": 1.952544160295281e-05,
      "loss": 0.1426,
      "step": 2046
    },
    {
      "epoch": 0.1214260291849567,
      "grad_norm": 0.6677206754684448,
      "learning_rate": 1.9524123385183233e-05,
      "loss": 0.0074,
      "step": 2047
    },
    {
      "epoch": 0.12148534820263376,
      "grad_norm": 1.1546399593353271,
      "learning_rate": 1.952280516741366e-05,
      "loss": 0.0124,
      "step": 2048
    },
    {
      "epoch": 0.12154466722031083,
      "grad_norm": 14.271228790283203,
      "learning_rate": 1.952148694964408e-05,
      "loss": 0.2836,
      "step": 2049
    },
    {
      "epoch": 0.1216039862379879,
      "grad_norm": 25.940956115722656,
      "learning_rate": 1.9520168731874507e-05,
      "loss": 0.2207,
      "step": 2050
    },
    {
      "epoch": 0.12166330525566496,
      "grad_norm": 0.28576940298080444,
      "learning_rate": 1.9518850514104933e-05,
      "loss": 0.0028,
      "step": 2051
    },
    {
      "epoch": 0.12172262427334203,
      "grad_norm": 16.73940658569336,
      "learning_rate": 1.9517532296335356e-05,
      "loss": 0.3313,
      "step": 2052
    },
    {
      "epoch": 0.1217819432910191,
      "grad_norm": 0.1735716015100479,
      "learning_rate": 1.951621407856578e-05,
      "loss": 0.0016,
      "step": 2053
    },
    {
      "epoch": 0.12184126230869617,
      "grad_norm": 0.1975754350423813,
      "learning_rate": 1.9514895860796204e-05,
      "loss": 0.003,
      "step": 2054
    },
    {
      "epoch": 0.12190058132637324,
      "grad_norm": 0.2153645008802414,
      "learning_rate": 1.951357764302663e-05,
      "loss": 0.0023,
      "step": 2055
    },
    {
      "epoch": 0.1219599003440503,
      "grad_norm": 7.070010662078857,
      "learning_rate": 1.9512259425257053e-05,
      "loss": 0.0843,
      "step": 2056
    },
    {
      "epoch": 0.12201921936172737,
      "grad_norm": 0.4929220378398895,
      "learning_rate": 1.951094120748748e-05,
      "loss": 0.005,
      "step": 2057
    },
    {
      "epoch": 0.12207853837940444,
      "grad_norm": 3.8399336338043213,
      "learning_rate": 1.95096229897179e-05,
      "loss": 0.0271,
      "step": 2058
    },
    {
      "epoch": 0.12213785739708151,
      "grad_norm": 41.329429626464844,
      "learning_rate": 1.9508304771948327e-05,
      "loss": 0.2956,
      "step": 2059
    },
    {
      "epoch": 0.12219717641475857,
      "grad_norm": 1.8904536962509155,
      "learning_rate": 1.9506986554178753e-05,
      "loss": 0.014,
      "step": 2060
    },
    {
      "epoch": 0.12225649543243564,
      "grad_norm": 0.39223596453666687,
      "learning_rate": 1.9505668336409175e-05,
      "loss": 0.0029,
      "step": 2061
    },
    {
      "epoch": 0.1223158144501127,
      "grad_norm": 26.00716781616211,
      "learning_rate": 1.95043501186396e-05,
      "loss": 0.4275,
      "step": 2062
    },
    {
      "epoch": 0.12237513346778978,
      "grad_norm": 12.494170188903809,
      "learning_rate": 1.9503031900870027e-05,
      "loss": 0.1295,
      "step": 2063
    },
    {
      "epoch": 0.12243445248546685,
      "grad_norm": 15.2223482131958,
      "learning_rate": 1.950171368310045e-05,
      "loss": 1.1252,
      "step": 2064
    },
    {
      "epoch": 0.1224937715031439,
      "grad_norm": 0.0942913144826889,
      "learning_rate": 1.9500395465330875e-05,
      "loss": 0.0025,
      "step": 2065
    },
    {
      "epoch": 0.12255309052082097,
      "grad_norm": 4.496825218200684,
      "learning_rate": 1.9499077247561298e-05,
      "loss": 0.0389,
      "step": 2066
    },
    {
      "epoch": 0.12261240953849804,
      "grad_norm": 12.087788581848145,
      "learning_rate": 1.9497759029791724e-05,
      "loss": 0.6007,
      "step": 2067
    },
    {
      "epoch": 0.12267172855617511,
      "grad_norm": 2.3284358978271484,
      "learning_rate": 1.949644081202215e-05,
      "loss": 0.0323,
      "step": 2068
    },
    {
      "epoch": 0.12273104757385218,
      "grad_norm": 1.2347863912582397,
      "learning_rate": 1.9495122594252572e-05,
      "loss": 0.0155,
      "step": 2069
    },
    {
      "epoch": 0.12279036659152924,
      "grad_norm": 6.415971755981445,
      "learning_rate": 1.9493804376482998e-05,
      "loss": 0.1865,
      "step": 2070
    },
    {
      "epoch": 0.12284968560920631,
      "grad_norm": 13.101306915283203,
      "learning_rate": 1.949248615871342e-05,
      "loss": 0.3185,
      "step": 2071
    },
    {
      "epoch": 0.12290900462688338,
      "grad_norm": 3.878769874572754,
      "learning_rate": 1.9491167940943846e-05,
      "loss": 0.0421,
      "step": 2072
    },
    {
      "epoch": 0.12296832364456045,
      "grad_norm": 17.749109268188477,
      "learning_rate": 1.948984972317427e-05,
      "loss": 0.4299,
      "step": 2073
    },
    {
      "epoch": 0.12302764266223751,
      "grad_norm": 13.38380241394043,
      "learning_rate": 1.9488531505404695e-05,
      "loss": 0.1296,
      "step": 2074
    },
    {
      "epoch": 0.12308696167991458,
      "grad_norm": 63.77975845336914,
      "learning_rate": 1.9487213287635117e-05,
      "loss": 0.5584,
      "step": 2075
    },
    {
      "epoch": 0.12314628069759165,
      "grad_norm": 0.055673062801361084,
      "learning_rate": 1.9485895069865543e-05,
      "loss": 0.001,
      "step": 2076
    },
    {
      "epoch": 0.12320559971526872,
      "grad_norm": 0.09388185292482376,
      "learning_rate": 1.948457685209597e-05,
      "loss": 0.001,
      "step": 2077
    },
    {
      "epoch": 0.12326491873294579,
      "grad_norm": 15.141138076782227,
      "learning_rate": 1.948325863432639e-05,
      "loss": 0.2837,
      "step": 2078
    },
    {
      "epoch": 0.12332423775062284,
      "grad_norm": 0.13058628141880035,
      "learning_rate": 1.9481940416556817e-05,
      "loss": 0.0023,
      "step": 2079
    },
    {
      "epoch": 0.12338355676829992,
      "grad_norm": 41.45913314819336,
      "learning_rate": 1.948062219878724e-05,
      "loss": 0.2687,
      "step": 2080
    },
    {
      "epoch": 0.12344287578597699,
      "grad_norm": 2.0514414310455322,
      "learning_rate": 1.9479303981017666e-05,
      "loss": 0.0217,
      "step": 2081
    },
    {
      "epoch": 0.12350219480365406,
      "grad_norm": 2.881429433822632,
      "learning_rate": 1.947798576324809e-05,
      "loss": 0.0279,
      "step": 2082
    },
    {
      "epoch": 0.12356151382133111,
      "grad_norm": 0.06684301048517227,
      "learning_rate": 1.9476667545478514e-05,
      "loss": 0.0011,
      "step": 2083
    },
    {
      "epoch": 0.12362083283900818,
      "grad_norm": 12.983064651489258,
      "learning_rate": 1.947534932770894e-05,
      "loss": 0.271,
      "step": 2084
    },
    {
      "epoch": 0.12368015185668525,
      "grad_norm": 7.096198558807373,
      "learning_rate": 1.9474031109939366e-05,
      "loss": 0.0346,
      "step": 2085
    },
    {
      "epoch": 0.12373947087436232,
      "grad_norm": 27.950260162353516,
      "learning_rate": 1.9472712892169788e-05,
      "loss": 0.3408,
      "step": 2086
    },
    {
      "epoch": 0.1237987898920394,
      "grad_norm": 0.4545310437679291,
      "learning_rate": 1.9471394674400214e-05,
      "loss": 0.0024,
      "step": 2087
    },
    {
      "epoch": 0.12385810890971645,
      "grad_norm": 29.82648277282715,
      "learning_rate": 1.9470076456630637e-05,
      "loss": 0.3978,
      "step": 2088
    },
    {
      "epoch": 0.12391742792739352,
      "grad_norm": 3.201427698135376,
      "learning_rate": 1.946875823886106e-05,
      "loss": 0.0356,
      "step": 2089
    },
    {
      "epoch": 0.12397674694507059,
      "grad_norm": 9.612330436706543,
      "learning_rate": 1.9467440021091485e-05,
      "loss": 0.0824,
      "step": 2090
    },
    {
      "epoch": 0.12403606596274766,
      "grad_norm": 16.196638107299805,
      "learning_rate": 1.946612180332191e-05,
      "loss": 0.7045,
      "step": 2091
    },
    {
      "epoch": 0.12409538498042473,
      "grad_norm": 3.123669385910034,
      "learning_rate": 1.9464803585552333e-05,
      "loss": 0.0264,
      "step": 2092
    },
    {
      "epoch": 0.12415470399810179,
      "grad_norm": 2.8576765060424805,
      "learning_rate": 1.946348536778276e-05,
      "loss": 0.0241,
      "step": 2093
    },
    {
      "epoch": 0.12421402301577886,
      "grad_norm": 0.09072139114141464,
      "learning_rate": 1.9462167150013185e-05,
      "loss": 0.0014,
      "step": 2094
    },
    {
      "epoch": 0.12427334203345593,
      "grad_norm": 6.4885077476501465,
      "learning_rate": 1.9460848932243608e-05,
      "loss": 0.1952,
      "step": 2095
    },
    {
      "epoch": 0.124332661051133,
      "grad_norm": 0.23482781648635864,
      "learning_rate": 1.9459530714474034e-05,
      "loss": 0.0033,
      "step": 2096
    },
    {
      "epoch": 0.12439198006881005,
      "grad_norm": 5.234538555145264,
      "learning_rate": 1.9458212496704456e-05,
      "loss": 0.0736,
      "step": 2097
    },
    {
      "epoch": 0.12445129908648712,
      "grad_norm": 5.500602722167969,
      "learning_rate": 1.9456894278934882e-05,
      "loss": 0.1137,
      "step": 2098
    },
    {
      "epoch": 0.1245106181041642,
      "grad_norm": 10.276457786560059,
      "learning_rate": 1.9455576061165308e-05,
      "loss": 0.5141,
      "step": 2099
    },
    {
      "epoch": 0.12456993712184126,
      "grad_norm": 2.184622049331665,
      "learning_rate": 1.945425784339573e-05,
      "loss": 0.0162,
      "step": 2100
    },
    {
      "epoch": 0.12462925613951834,
      "grad_norm": 0.23935182392597198,
      "learning_rate": 1.9452939625626156e-05,
      "loss": 0.0023,
      "step": 2101
    },
    {
      "epoch": 0.12468857515719539,
      "grad_norm": 32.76197052001953,
      "learning_rate": 1.945162140785658e-05,
      "loss": 1.325,
      "step": 2102
    },
    {
      "epoch": 0.12474789417487246,
      "grad_norm": 5.599207401275635,
      "learning_rate": 1.9450303190087005e-05,
      "loss": 0.2643,
      "step": 2103
    },
    {
      "epoch": 0.12480721319254953,
      "grad_norm": 19.441444396972656,
      "learning_rate": 1.9448984972317427e-05,
      "loss": 0.5247,
      "step": 2104
    },
    {
      "epoch": 0.1248665322102266,
      "grad_norm": 8.77446460723877,
      "learning_rate": 1.9447666754547853e-05,
      "loss": 0.108,
      "step": 2105
    },
    {
      "epoch": 0.12492585122790367,
      "grad_norm": 2.0323874950408936,
      "learning_rate": 1.9446348536778275e-05,
      "loss": 0.0163,
      "step": 2106
    },
    {
      "epoch": 0.12498517024558073,
      "grad_norm": 2.2242190837860107,
      "learning_rate": 1.94450303190087e-05,
      "loss": 0.0102,
      "step": 2107
    },
    {
      "epoch": 0.1250444892632578,
      "grad_norm": 8.624391555786133,
      "learning_rate": 1.9443712101239127e-05,
      "loss": 0.3346,
      "step": 2108
    },
    {
      "epoch": 0.12510380828093487,
      "grad_norm": 23.651256561279297,
      "learning_rate": 1.944239388346955e-05,
      "loss": 0.3791,
      "step": 2109
    },
    {
      "epoch": 0.12516312729861193,
      "grad_norm": 3.63736629486084,
      "learning_rate": 1.9441075665699976e-05,
      "loss": 0.04,
      "step": 2110
    },
    {
      "epoch": 0.125222446316289,
      "grad_norm": 15.098515510559082,
      "learning_rate": 1.94397574479304e-05,
      "loss": 0.5382,
      "step": 2111
    },
    {
      "epoch": 0.12528176533396607,
      "grad_norm": 0.25758281350135803,
      "learning_rate": 1.9438439230160824e-05,
      "loss": 0.0017,
      "step": 2112
    },
    {
      "epoch": 0.12534108435164315,
      "grad_norm": 0.03917287662625313,
      "learning_rate": 1.943712101239125e-05,
      "loss": 0.0007,
      "step": 2113
    },
    {
      "epoch": 0.1254004033693202,
      "grad_norm": 0.09576132148504257,
      "learning_rate": 1.9435802794621672e-05,
      "loss": 0.0017,
      "step": 2114
    },
    {
      "epoch": 0.12545972238699726,
      "grad_norm": 11.46845817565918,
      "learning_rate": 1.9434484576852098e-05,
      "loss": 0.1645,
      "step": 2115
    },
    {
      "epoch": 0.12551904140467435,
      "grad_norm": 4.835083484649658,
      "learning_rate": 1.9433166359082524e-05,
      "loss": 0.08,
      "step": 2116
    },
    {
      "epoch": 0.1255783604223514,
      "grad_norm": 3.6876673698425293,
      "learning_rate": 1.9431848141312947e-05,
      "loss": 0.0637,
      "step": 2117
    },
    {
      "epoch": 0.12563767944002846,
      "grad_norm": 0.616777777671814,
      "learning_rate": 1.9430529923543372e-05,
      "loss": 0.0026,
      "step": 2118
    },
    {
      "epoch": 0.12569699845770554,
      "grad_norm": 0.058802396059036255,
      "learning_rate": 1.9429211705773795e-05,
      "loss": 0.0011,
      "step": 2119
    },
    {
      "epoch": 0.1257563174753826,
      "grad_norm": 0.1578138917684555,
      "learning_rate": 1.942789348800422e-05,
      "loss": 0.0011,
      "step": 2120
    },
    {
      "epoch": 0.12581563649305968,
      "grad_norm": 24.72342872619629,
      "learning_rate": 1.9426575270234643e-05,
      "loss": 1.0116,
      "step": 2121
    },
    {
      "epoch": 0.12587495551073674,
      "grad_norm": 3.9252047538757324,
      "learning_rate": 1.942525705246507e-05,
      "loss": 0.0424,
      "step": 2122
    },
    {
      "epoch": 0.1259342745284138,
      "grad_norm": 18.146926879882812,
      "learning_rate": 1.942393883469549e-05,
      "loss": 0.0962,
      "step": 2123
    },
    {
      "epoch": 0.12599359354609088,
      "grad_norm": 1.8053840398788452,
      "learning_rate": 1.9422620616925918e-05,
      "loss": 0.0088,
      "step": 2124
    },
    {
      "epoch": 0.12605291256376794,
      "grad_norm": 0.04436132684350014,
      "learning_rate": 1.9421302399156343e-05,
      "loss": 0.0009,
      "step": 2125
    },
    {
      "epoch": 0.12611223158144502,
      "grad_norm": 2.1969165802001953,
      "learning_rate": 1.9419984181386766e-05,
      "loss": 0.0271,
      "step": 2126
    },
    {
      "epoch": 0.12617155059912208,
      "grad_norm": 16.55000114440918,
      "learning_rate": 1.9418665963617192e-05,
      "loss": 0.067,
      "step": 2127
    },
    {
      "epoch": 0.12623086961679914,
      "grad_norm": 0.05004937946796417,
      "learning_rate": 1.9417347745847614e-05,
      "loss": 0.0006,
      "step": 2128
    },
    {
      "epoch": 0.12629018863447622,
      "grad_norm": 5.256044387817383,
      "learning_rate": 1.941602952807804e-05,
      "loss": 0.4787,
      "step": 2129
    },
    {
      "epoch": 0.12634950765215328,
      "grad_norm": 32.4901237487793,
      "learning_rate": 1.9414711310308466e-05,
      "loss": 1.7888,
      "step": 2130
    },
    {
      "epoch": 0.12640882666983036,
      "grad_norm": 9.42674446105957,
      "learning_rate": 1.941339309253889e-05,
      "loss": 0.2718,
      "step": 2131
    },
    {
      "epoch": 0.12646814568750742,
      "grad_norm": 0.5628858804702759,
      "learning_rate": 1.9412074874769314e-05,
      "loss": 0.0056,
      "step": 2132
    },
    {
      "epoch": 0.12652746470518447,
      "grad_norm": 43.1642951965332,
      "learning_rate": 1.9410756656999737e-05,
      "loss": 0.5398,
      "step": 2133
    },
    {
      "epoch": 0.12658678372286156,
      "grad_norm": 54.50801086425781,
      "learning_rate": 1.9409438439230163e-05,
      "loss": 0.9617,
      "step": 2134
    },
    {
      "epoch": 0.1266461027405386,
      "grad_norm": 26.164222717285156,
      "learning_rate": 1.9408120221460585e-05,
      "loss": 0.1166,
      "step": 2135
    },
    {
      "epoch": 0.1267054217582157,
      "grad_norm": 0.04262497276067734,
      "learning_rate": 1.940680200369101e-05,
      "loss": 0.0006,
      "step": 2136
    },
    {
      "epoch": 0.12676474077589275,
      "grad_norm": 2.453559637069702,
      "learning_rate": 1.9405483785921434e-05,
      "loss": 0.0125,
      "step": 2137
    },
    {
      "epoch": 0.1268240597935698,
      "grad_norm": 13.491965293884277,
      "learning_rate": 1.940416556815186e-05,
      "loss": 0.2905,
      "step": 2138
    },
    {
      "epoch": 0.1268833788112469,
      "grad_norm": 8.745945930480957,
      "learning_rate": 1.9402847350382285e-05,
      "loss": 0.0533,
      "step": 2139
    },
    {
      "epoch": 0.12694269782892395,
      "grad_norm": 11.967945098876953,
      "learning_rate": 1.9401529132612708e-05,
      "loss": 0.1767,
      "step": 2140
    },
    {
      "epoch": 0.127002016846601,
      "grad_norm": 2.059772253036499,
      "learning_rate": 1.9400210914843134e-05,
      "loss": 0.0337,
      "step": 2141
    },
    {
      "epoch": 0.1270613358642781,
      "grad_norm": 40.0911865234375,
      "learning_rate": 1.939889269707356e-05,
      "loss": 1.8134,
      "step": 2142
    },
    {
      "epoch": 0.12712065488195515,
      "grad_norm": 32.55815505981445,
      "learning_rate": 1.9397574479303982e-05,
      "loss": 0.3566,
      "step": 2143
    },
    {
      "epoch": 0.12717997389963223,
      "grad_norm": 2.5483744144439697,
      "learning_rate": 1.9396256261534408e-05,
      "loss": 0.0534,
      "step": 2144
    },
    {
      "epoch": 0.1272392929173093,
      "grad_norm": 0.7000970840454102,
      "learning_rate": 1.939493804376483e-05,
      "loss": 0.0032,
      "step": 2145
    },
    {
      "epoch": 0.12729861193498634,
      "grad_norm": 2.6973209381103516,
      "learning_rate": 1.9393619825995256e-05,
      "loss": 0.0197,
      "step": 2146
    },
    {
      "epoch": 0.12735793095266343,
      "grad_norm": 0.37604159116744995,
      "learning_rate": 1.9392301608225682e-05,
      "loss": 0.0052,
      "step": 2147
    },
    {
      "epoch": 0.12741724997034048,
      "grad_norm": 32.11961364746094,
      "learning_rate": 1.9390983390456105e-05,
      "loss": 0.93,
      "step": 2148
    },
    {
      "epoch": 0.12747656898801757,
      "grad_norm": 0.15128955245018005,
      "learning_rate": 1.938966517268653e-05,
      "loss": 0.0023,
      "step": 2149
    },
    {
      "epoch": 0.12753588800569463,
      "grad_norm": 0.6347789764404297,
      "learning_rate": 1.9388346954916953e-05,
      "loss": 0.011,
      "step": 2150
    },
    {
      "epoch": 0.12759520702337168,
      "grad_norm": 18.683115005493164,
      "learning_rate": 1.938702873714738e-05,
      "loss": 0.3665,
      "step": 2151
    },
    {
      "epoch": 0.12765452604104877,
      "grad_norm": 15.76718521118164,
      "learning_rate": 1.93857105193778e-05,
      "loss": 0.3171,
      "step": 2152
    },
    {
      "epoch": 0.12771384505872582,
      "grad_norm": 8.115066528320312,
      "learning_rate": 1.9384392301608227e-05,
      "loss": 0.1005,
      "step": 2153
    },
    {
      "epoch": 0.1277731640764029,
      "grad_norm": 2.383885383605957,
      "learning_rate": 1.938307408383865e-05,
      "loss": 0.0364,
      "step": 2154
    },
    {
      "epoch": 0.12783248309407996,
      "grad_norm": 8.245038986206055,
      "learning_rate": 1.9381755866069076e-05,
      "loss": 0.0515,
      "step": 2155
    },
    {
      "epoch": 0.12789180211175702,
      "grad_norm": 13.583910942077637,
      "learning_rate": 1.9380437648299502e-05,
      "loss": 0.1947,
      "step": 2156
    },
    {
      "epoch": 0.1279511211294341,
      "grad_norm": 37.053653717041016,
      "learning_rate": 1.9379119430529924e-05,
      "loss": 0.208,
      "step": 2157
    },
    {
      "epoch": 0.12801044014711116,
      "grad_norm": 6.270635604858398,
      "learning_rate": 1.937780121276035e-05,
      "loss": 0.0983,
      "step": 2158
    },
    {
      "epoch": 0.12806975916478824,
      "grad_norm": 12.673685073852539,
      "learning_rate": 1.9376482994990776e-05,
      "loss": 0.1386,
      "step": 2159
    },
    {
      "epoch": 0.1281290781824653,
      "grad_norm": 0.18634696304798126,
      "learning_rate": 1.93751647772212e-05,
      "loss": 0.004,
      "step": 2160
    },
    {
      "epoch": 0.12818839720014236,
      "grad_norm": 0.0316181518137455,
      "learning_rate": 1.9373846559451624e-05,
      "loss": 0.0007,
      "step": 2161
    },
    {
      "epoch": 0.12824771621781944,
      "grad_norm": 29.25663948059082,
      "learning_rate": 1.9372528341682047e-05,
      "loss": 0.0442,
      "step": 2162
    },
    {
      "epoch": 0.1283070352354965,
      "grad_norm": 0.10448897629976273,
      "learning_rate": 1.9371210123912473e-05,
      "loss": 0.0013,
      "step": 2163
    },
    {
      "epoch": 0.12836635425317358,
      "grad_norm": 0.6694258451461792,
      "learning_rate": 1.93698919061429e-05,
      "loss": 0.0036,
      "step": 2164
    },
    {
      "epoch": 0.12842567327085064,
      "grad_norm": 8.453218460083008,
      "learning_rate": 1.936857368837332e-05,
      "loss": 0.5986,
      "step": 2165
    },
    {
      "epoch": 0.1284849922885277,
      "grad_norm": 0.08672237396240234,
      "learning_rate": 1.9367255470603744e-05,
      "loss": 0.0015,
      "step": 2166
    },
    {
      "epoch": 0.12854431130620478,
      "grad_norm": 13.0928316116333,
      "learning_rate": 1.936593725283417e-05,
      "loss": 0.4556,
      "step": 2167
    },
    {
      "epoch": 0.12860363032388183,
      "grad_norm": 10.296685218811035,
      "learning_rate": 1.9364619035064592e-05,
      "loss": 0.2581,
      "step": 2168
    },
    {
      "epoch": 0.1286629493415589,
      "grad_norm": 0.03220019489526749,
      "learning_rate": 1.9363300817295018e-05,
      "loss": 0.0003,
      "step": 2169
    },
    {
      "epoch": 0.12872226835923598,
      "grad_norm": 1.7821115255355835,
      "learning_rate": 1.9361982599525444e-05,
      "loss": 0.0283,
      "step": 2170
    },
    {
      "epoch": 0.12878158737691303,
      "grad_norm": 2.064622163772583,
      "learning_rate": 1.9360664381755866e-05,
      "loss": 0.0184,
      "step": 2171
    },
    {
      "epoch": 0.12884090639459012,
      "grad_norm": 6.13368034362793,
      "learning_rate": 1.9359346163986292e-05,
      "loss": 0.0458,
      "step": 2172
    },
    {
      "epoch": 0.12890022541226717,
      "grad_norm": 13.704392433166504,
      "learning_rate": 1.9358027946216718e-05,
      "loss": 0.0574,
      "step": 2173
    },
    {
      "epoch": 0.12895954442994423,
      "grad_norm": 0.04040496423840523,
      "learning_rate": 1.935670972844714e-05,
      "loss": 0.0004,
      "step": 2174
    },
    {
      "epoch": 0.1290188634476213,
      "grad_norm": 25.339128494262695,
      "learning_rate": 1.9355391510677566e-05,
      "loss": 0.4591,
      "step": 2175
    },
    {
      "epoch": 0.12907818246529837,
      "grad_norm": 2.6278796195983887,
      "learning_rate": 1.9354073292907992e-05,
      "loss": 0.0174,
      "step": 2176
    },
    {
      "epoch": 0.12913750148297545,
      "grad_norm": 0.7739210724830627,
      "learning_rate": 1.9352755075138415e-05,
      "loss": 0.0109,
      "step": 2177
    },
    {
      "epoch": 0.1291968205006525,
      "grad_norm": 0.5589236617088318,
      "learning_rate": 1.935143685736884e-05,
      "loss": 0.0028,
      "step": 2178
    },
    {
      "epoch": 0.12925613951832957,
      "grad_norm": 0.1658790558576584,
      "learning_rate": 1.9350118639599263e-05,
      "loss": 0.0025,
      "step": 2179
    },
    {
      "epoch": 0.12931545853600665,
      "grad_norm": 26.885759353637695,
      "learning_rate": 1.934880042182969e-05,
      "loss": 0.9455,
      "step": 2180
    },
    {
      "epoch": 0.1293747775536837,
      "grad_norm": 0.058465566486120224,
      "learning_rate": 1.934748220406011e-05,
      "loss": 0.0008,
      "step": 2181
    },
    {
      "epoch": 0.1294340965713608,
      "grad_norm": 15.009960174560547,
      "learning_rate": 1.9346163986290537e-05,
      "loss": 0.836,
      "step": 2182
    },
    {
      "epoch": 0.12949341558903785,
      "grad_norm": 81.20507049560547,
      "learning_rate": 1.934484576852096e-05,
      "loss": 0.0587,
      "step": 2183
    },
    {
      "epoch": 0.1295527346067149,
      "grad_norm": 21.16217803955078,
      "learning_rate": 1.9343527550751386e-05,
      "loss": 0.2062,
      "step": 2184
    },
    {
      "epoch": 0.129612053624392,
      "grad_norm": 10.519867897033691,
      "learning_rate": 1.9342209332981808e-05,
      "loss": 0.3391,
      "step": 2185
    },
    {
      "epoch": 0.12967137264206904,
      "grad_norm": 5.000918388366699,
      "learning_rate": 1.9340891115212234e-05,
      "loss": 0.0811,
      "step": 2186
    },
    {
      "epoch": 0.12973069165974613,
      "grad_norm": 14.22983455657959,
      "learning_rate": 1.933957289744266e-05,
      "loss": 0.2021,
      "step": 2187
    },
    {
      "epoch": 0.12979001067742318,
      "grad_norm": 56.69489288330078,
      "learning_rate": 1.9338254679673082e-05,
      "loss": 1.5626,
      "step": 2188
    },
    {
      "epoch": 0.12984932969510024,
      "grad_norm": 6.909758567810059,
      "learning_rate": 1.933693646190351e-05,
      "loss": 0.0187,
      "step": 2189
    },
    {
      "epoch": 0.12990864871277732,
      "grad_norm": 25.83112144470215,
      "learning_rate": 1.9335618244133934e-05,
      "loss": 0.5723,
      "step": 2190
    },
    {
      "epoch": 0.12996796773045438,
      "grad_norm": 23.7492733001709,
      "learning_rate": 1.9334300026364357e-05,
      "loss": 0.2191,
      "step": 2191
    },
    {
      "epoch": 0.13002728674813144,
      "grad_norm": 8.920785903930664,
      "learning_rate": 1.9332981808594783e-05,
      "loss": 0.4857,
      "step": 2192
    },
    {
      "epoch": 0.13008660576580852,
      "grad_norm": 3.77386212348938,
      "learning_rate": 1.9331663590825205e-05,
      "loss": 0.0336,
      "step": 2193
    },
    {
      "epoch": 0.13014592478348558,
      "grad_norm": 7.902388095855713,
      "learning_rate": 1.933034537305563e-05,
      "loss": 0.4147,
      "step": 2194
    },
    {
      "epoch": 0.13020524380116266,
      "grad_norm": 17.032052993774414,
      "learning_rate": 1.9329027155286057e-05,
      "loss": 0.15,
      "step": 2195
    },
    {
      "epoch": 0.13026456281883972,
      "grad_norm": 4.702345371246338,
      "learning_rate": 1.932770893751648e-05,
      "loss": 0.0938,
      "step": 2196
    },
    {
      "epoch": 0.13032388183651678,
      "grad_norm": 9.747482299804688,
      "learning_rate": 1.9326390719746905e-05,
      "loss": 0.0151,
      "step": 2197
    },
    {
      "epoch": 0.13038320085419386,
      "grad_norm": 12.237688064575195,
      "learning_rate": 1.9325072501977328e-05,
      "loss": 0.4357,
      "step": 2198
    },
    {
      "epoch": 0.13044251987187092,
      "grad_norm": 1.25326406955719,
      "learning_rate": 1.932375428420775e-05,
      "loss": 0.0163,
      "step": 2199
    },
    {
      "epoch": 0.130501838889548,
      "grad_norm": 0.015627318993210793,
      "learning_rate": 1.9322436066438176e-05,
      "loss": 0.0004,
      "step": 2200
    },
    {
      "epoch": 0.13056115790722506,
      "grad_norm": 7.25621223449707,
      "learning_rate": 1.9321117848668602e-05,
      "loss": 0.1242,
      "step": 2201
    },
    {
      "epoch": 0.1306204769249021,
      "grad_norm": 0.024979745969176292,
      "learning_rate": 1.9319799630899024e-05,
      "loss": 0.0004,
      "step": 2202
    },
    {
      "epoch": 0.1306797959425792,
      "grad_norm": 4.032281875610352,
      "learning_rate": 1.931848141312945e-05,
      "loss": 0.2009,
      "step": 2203
    },
    {
      "epoch": 0.13073911496025625,
      "grad_norm": 22.402587890625,
      "learning_rate": 1.9317163195359876e-05,
      "loss": 0.4226,
      "step": 2204
    },
    {
      "epoch": 0.13079843397793334,
      "grad_norm": 14.23377513885498,
      "learning_rate": 1.93158449775903e-05,
      "loss": 0.5939,
      "step": 2205
    },
    {
      "epoch": 0.1308577529956104,
      "grad_norm": 3.1040055751800537,
      "learning_rate": 1.9314526759820725e-05,
      "loss": 0.0129,
      "step": 2206
    },
    {
      "epoch": 0.13091707201328745,
      "grad_norm": 15.83682918548584,
      "learning_rate": 1.931320854205115e-05,
      "loss": 0.3385,
      "step": 2207
    },
    {
      "epoch": 0.13097639103096453,
      "grad_norm": 39.25847244262695,
      "learning_rate": 1.9311890324281573e-05,
      "loss": 0.4063,
      "step": 2208
    },
    {
      "epoch": 0.1310357100486416,
      "grad_norm": 7.118466377258301,
      "learning_rate": 1.9310572106512e-05,
      "loss": 0.0869,
      "step": 2209
    },
    {
      "epoch": 0.13109502906631867,
      "grad_norm": 5.256161689758301,
      "learning_rate": 1.930925388874242e-05,
      "loss": 0.0642,
      "step": 2210
    },
    {
      "epoch": 0.13115434808399573,
      "grad_norm": 0.14404182136058807,
      "learning_rate": 1.9307935670972847e-05,
      "loss": 0.0026,
      "step": 2211
    },
    {
      "epoch": 0.1312136671016728,
      "grad_norm": 2.7475674152374268,
      "learning_rate": 1.930661745320327e-05,
      "loss": 0.0229,
      "step": 2212
    },
    {
      "epoch": 0.13127298611934987,
      "grad_norm": 0.033690519630908966,
      "learning_rate": 1.9305299235433696e-05,
      "loss": 0.0005,
      "step": 2213
    },
    {
      "epoch": 0.13133230513702693,
      "grad_norm": 0.06591738015413284,
      "learning_rate": 1.9303981017664118e-05,
      "loss": 0.001,
      "step": 2214
    },
    {
      "epoch": 0.13139162415470398,
      "grad_norm": 15.434233665466309,
      "learning_rate": 1.9302662799894544e-05,
      "loss": 0.134,
      "step": 2215
    },
    {
      "epoch": 0.13145094317238107,
      "grad_norm": 3.0973527431488037,
      "learning_rate": 1.9301344582124966e-05,
      "loss": 0.0411,
      "step": 2216
    },
    {
      "epoch": 0.13151026219005812,
      "grad_norm": 15.563167572021484,
      "learning_rate": 1.9300026364355392e-05,
      "loss": 0.4032,
      "step": 2217
    },
    {
      "epoch": 0.1315695812077352,
      "grad_norm": 5.8891496658325195,
      "learning_rate": 1.9298708146585818e-05,
      "loss": 0.1127,
      "step": 2218
    },
    {
      "epoch": 0.13162890022541227,
      "grad_norm": 10.042019844055176,
      "learning_rate": 1.929738992881624e-05,
      "loss": 0.2859,
      "step": 2219
    },
    {
      "epoch": 0.13168821924308932,
      "grad_norm": 2.2175331115722656,
      "learning_rate": 1.9296071711046667e-05,
      "loss": 0.0195,
      "step": 2220
    },
    {
      "epoch": 0.1317475382607664,
      "grad_norm": 0.19136595726013184,
      "learning_rate": 1.9294753493277093e-05,
      "loss": 0.0009,
      "step": 2221
    },
    {
      "epoch": 0.13180685727844346,
      "grad_norm": 0.037546608597040176,
      "learning_rate": 1.9293435275507515e-05,
      "loss": 0.0008,
      "step": 2222
    },
    {
      "epoch": 0.13186617629612055,
      "grad_norm": 28.269350051879883,
      "learning_rate": 1.929211705773794e-05,
      "loss": 0.2097,
      "step": 2223
    },
    {
      "epoch": 0.1319254953137976,
      "grad_norm": 18.837636947631836,
      "learning_rate": 1.9290798839968367e-05,
      "loss": 0.2616,
      "step": 2224
    },
    {
      "epoch": 0.13198481433147466,
      "grad_norm": 5.658854007720947,
      "learning_rate": 1.928948062219879e-05,
      "loss": 0.0442,
      "step": 2225
    },
    {
      "epoch": 0.13204413334915174,
      "grad_norm": 13.210821151733398,
      "learning_rate": 1.9288162404429215e-05,
      "loss": 0.7794,
      "step": 2226
    },
    {
      "epoch": 0.1321034523668288,
      "grad_norm": 0.8359687924385071,
      "learning_rate": 1.9286844186659638e-05,
      "loss": 0.0154,
      "step": 2227
    },
    {
      "epoch": 0.13216277138450588,
      "grad_norm": 11.941085815429688,
      "learning_rate": 1.9285525968890064e-05,
      "loss": 0.2888,
      "step": 2228
    },
    {
      "epoch": 0.13222209040218294,
      "grad_norm": 12.660256385803223,
      "learning_rate": 1.9284207751120486e-05,
      "loss": 0.5782,
      "step": 2229
    },
    {
      "epoch": 0.13228140941986,
      "grad_norm": 3.840106725692749,
      "learning_rate": 1.9282889533350912e-05,
      "loss": 0.1916,
      "step": 2230
    },
    {
      "epoch": 0.13234072843753708,
      "grad_norm": 38.659236907958984,
      "learning_rate": 1.9281571315581334e-05,
      "loss": 0.8472,
      "step": 2231
    },
    {
      "epoch": 0.13240004745521414,
      "grad_norm": 20.477069854736328,
      "learning_rate": 1.928025309781176e-05,
      "loss": 0.4984,
      "step": 2232
    },
    {
      "epoch": 0.13245936647289122,
      "grad_norm": 4.611607074737549,
      "learning_rate": 1.9278934880042183e-05,
      "loss": 0.4298,
      "step": 2233
    },
    {
      "epoch": 0.13251868549056828,
      "grad_norm": 8.336904525756836,
      "learning_rate": 1.927761666227261e-05,
      "loss": 0.2552,
      "step": 2234
    },
    {
      "epoch": 0.13257800450824533,
      "grad_norm": 4.342036247253418,
      "learning_rate": 1.9276298444503035e-05,
      "loss": 0.0578,
      "step": 2235
    },
    {
      "epoch": 0.13263732352592242,
      "grad_norm": 25.76555824279785,
      "learning_rate": 1.9274980226733457e-05,
      "loss": 0.5709,
      "step": 2236
    },
    {
      "epoch": 0.13269664254359947,
      "grad_norm": 7.223270416259766,
      "learning_rate": 1.9273662008963883e-05,
      "loss": 0.0805,
      "step": 2237
    },
    {
      "epoch": 0.13275596156127656,
      "grad_norm": 8.138385772705078,
      "learning_rate": 1.927234379119431e-05,
      "loss": 0.3074,
      "step": 2238
    },
    {
      "epoch": 0.13281528057895362,
      "grad_norm": 0.060425128787755966,
      "learning_rate": 1.927102557342473e-05,
      "loss": 0.0006,
      "step": 2239
    },
    {
      "epoch": 0.13287459959663067,
      "grad_norm": 4.229936122894287,
      "learning_rate": 1.9269707355655157e-05,
      "loss": 0.0636,
      "step": 2240
    },
    {
      "epoch": 0.13293391861430776,
      "grad_norm": 0.2008826732635498,
      "learning_rate": 1.926838913788558e-05,
      "loss": 0.0024,
      "step": 2241
    },
    {
      "epoch": 0.1329932376319848,
      "grad_norm": 6.021299362182617,
      "learning_rate": 1.9267070920116006e-05,
      "loss": 0.0641,
      "step": 2242
    },
    {
      "epoch": 0.13305255664966187,
      "grad_norm": 1.6432580947875977,
      "learning_rate": 1.9265752702346428e-05,
      "loss": 0.0076,
      "step": 2243
    },
    {
      "epoch": 0.13311187566733895,
      "grad_norm": 5.497861385345459,
      "learning_rate": 1.9264434484576854e-05,
      "loss": 0.0845,
      "step": 2244
    },
    {
      "epoch": 0.133171194685016,
      "grad_norm": 6.513557434082031,
      "learning_rate": 1.9263116266807276e-05,
      "loss": 0.267,
      "step": 2245
    },
    {
      "epoch": 0.1332305137026931,
      "grad_norm": 10.118882179260254,
      "learning_rate": 1.9261798049037702e-05,
      "loss": 0.1278,
      "step": 2246
    },
    {
      "epoch": 0.13328983272037015,
      "grad_norm": 0.07488319277763367,
      "learning_rate": 1.9260479831268125e-05,
      "loss": 0.0014,
      "step": 2247
    },
    {
      "epoch": 0.1333491517380472,
      "grad_norm": 20.504873275756836,
      "learning_rate": 1.925916161349855e-05,
      "loss": 0.3872,
      "step": 2248
    },
    {
      "epoch": 0.1334084707557243,
      "grad_norm": 30.7465763092041,
      "learning_rate": 1.9257843395728977e-05,
      "loss": 0.5069,
      "step": 2249
    },
    {
      "epoch": 0.13346778977340135,
      "grad_norm": 47.13693618774414,
      "learning_rate": 1.92565251779594e-05,
      "loss": 0.5294,
      "step": 2250
    },
    {
      "epoch": 0.13352710879107843,
      "grad_norm": 47.79640579223633,
      "learning_rate": 1.9255206960189825e-05,
      "loss": 0.4055,
      "step": 2251
    },
    {
      "epoch": 0.1335864278087555,
      "grad_norm": 71.17813110351562,
      "learning_rate": 1.925388874242025e-05,
      "loss": 0.6406,
      "step": 2252
    },
    {
      "epoch": 0.13364574682643254,
      "grad_norm": 0.02438623458147049,
      "learning_rate": 1.9252570524650673e-05,
      "loss": 0.0007,
      "step": 2253
    },
    {
      "epoch": 0.13370506584410963,
      "grad_norm": 4.443113327026367,
      "learning_rate": 1.92512523068811e-05,
      "loss": 0.0526,
      "step": 2254
    },
    {
      "epoch": 0.13376438486178668,
      "grad_norm": 28.69581413269043,
      "learning_rate": 1.9249934089111525e-05,
      "loss": 0.2134,
      "step": 2255
    },
    {
      "epoch": 0.13382370387946377,
      "grad_norm": 4.945471286773682,
      "learning_rate": 1.9248615871341948e-05,
      "loss": 0.2761,
      "step": 2256
    },
    {
      "epoch": 0.13388302289714082,
      "grad_norm": 23.227188110351562,
      "learning_rate": 1.9247297653572373e-05,
      "loss": 0.2939,
      "step": 2257
    },
    {
      "epoch": 0.13394234191481788,
      "grad_norm": 6.07299280166626,
      "learning_rate": 1.9245979435802796e-05,
      "loss": 0.0724,
      "step": 2258
    },
    {
      "epoch": 0.13400166093249496,
      "grad_norm": 8.882505416870117,
      "learning_rate": 1.9244661218033222e-05,
      "loss": 0.3836,
      "step": 2259
    },
    {
      "epoch": 0.13406097995017202,
      "grad_norm": 25.214126586914062,
      "learning_rate": 1.9243343000263644e-05,
      "loss": 0.4521,
      "step": 2260
    },
    {
      "epoch": 0.1341202989678491,
      "grad_norm": 4.213747978210449,
      "learning_rate": 1.924202478249407e-05,
      "loss": 0.027,
      "step": 2261
    },
    {
      "epoch": 0.13417961798552616,
      "grad_norm": 0.7522255778312683,
      "learning_rate": 1.9240706564724493e-05,
      "loss": 0.0134,
      "step": 2262
    },
    {
      "epoch": 0.13423893700320322,
      "grad_norm": 0.12709252536296844,
      "learning_rate": 1.923938834695492e-05,
      "loss": 0.0023,
      "step": 2263
    },
    {
      "epoch": 0.1342982560208803,
      "grad_norm": 9.323092460632324,
      "learning_rate": 1.923807012918534e-05,
      "loss": 0.2883,
      "step": 2264
    },
    {
      "epoch": 0.13435757503855736,
      "grad_norm": 0.5279523134231567,
      "learning_rate": 1.9236751911415767e-05,
      "loss": 0.0058,
      "step": 2265
    },
    {
      "epoch": 0.13441689405623442,
      "grad_norm": 1.766650676727295,
      "learning_rate": 1.9235433693646193e-05,
      "loss": 0.008,
      "step": 2266
    },
    {
      "epoch": 0.1344762130739115,
      "grad_norm": 1.146599531173706,
      "learning_rate": 1.9234115475876615e-05,
      "loss": 0.0151,
      "step": 2267
    },
    {
      "epoch": 0.13453553209158856,
      "grad_norm": 2.1083076000213623,
      "learning_rate": 1.923279725810704e-05,
      "loss": 0.0189,
      "step": 2268
    },
    {
      "epoch": 0.13459485110926564,
      "grad_norm": 0.015559389255940914,
      "learning_rate": 1.9231479040337467e-05,
      "loss": 0.0005,
      "step": 2269
    },
    {
      "epoch": 0.1346541701269427,
      "grad_norm": 4.471551418304443,
      "learning_rate": 1.923016082256789e-05,
      "loss": 0.1108,
      "step": 2270
    },
    {
      "epoch": 0.13471348914461975,
      "grad_norm": 0.05477031692862511,
      "learning_rate": 1.9228842604798315e-05,
      "loss": 0.0009,
      "step": 2271
    },
    {
      "epoch": 0.13477280816229684,
      "grad_norm": 26.527713775634766,
      "learning_rate": 1.922752438702874e-05,
      "loss": 0.6435,
      "step": 2272
    },
    {
      "epoch": 0.1348321271799739,
      "grad_norm": 0.14132475852966309,
      "learning_rate": 1.9226206169259164e-05,
      "loss": 0.0023,
      "step": 2273
    },
    {
      "epoch": 0.13489144619765098,
      "grad_norm": 0.11560885608196259,
      "learning_rate": 1.922488795148959e-05,
      "loss": 0.0017,
      "step": 2274
    },
    {
      "epoch": 0.13495076521532803,
      "grad_norm": 6.141973972320557,
      "learning_rate": 1.9223569733720012e-05,
      "loss": 0.2454,
      "step": 2275
    },
    {
      "epoch": 0.1350100842330051,
      "grad_norm": 22.27594757080078,
      "learning_rate": 1.9222251515950438e-05,
      "loss": 0.2567,
      "step": 2276
    },
    {
      "epoch": 0.13506940325068217,
      "grad_norm": 1.0030096769332886,
      "learning_rate": 1.922093329818086e-05,
      "loss": 0.005,
      "step": 2277
    },
    {
      "epoch": 0.13512872226835923,
      "grad_norm": 6.115011215209961,
      "learning_rate": 1.9219615080411283e-05,
      "loss": 0.0737,
      "step": 2278
    },
    {
      "epoch": 0.13518804128603631,
      "grad_norm": 0.2622203826904297,
      "learning_rate": 1.921829686264171e-05,
      "loss": 0.0015,
      "step": 2279
    },
    {
      "epoch": 0.13524736030371337,
      "grad_norm": 9.890402793884277,
      "learning_rate": 1.9216978644872135e-05,
      "loss": 0.2598,
      "step": 2280
    },
    {
      "epoch": 0.13530667932139043,
      "grad_norm": 8.1327486038208,
      "learning_rate": 1.9215660427102557e-05,
      "loss": 0.0895,
      "step": 2281
    },
    {
      "epoch": 0.1353659983390675,
      "grad_norm": 28.70524024963379,
      "learning_rate": 1.9214342209332983e-05,
      "loss": 0.3171,
      "step": 2282
    },
    {
      "epoch": 0.13542531735674457,
      "grad_norm": 0.07031668722629547,
      "learning_rate": 1.921302399156341e-05,
      "loss": 0.001,
      "step": 2283
    },
    {
      "epoch": 0.13548463637442165,
      "grad_norm": 22.47334098815918,
      "learning_rate": 1.921170577379383e-05,
      "loss": 0.5853,
      "step": 2284
    },
    {
      "epoch": 0.1355439553920987,
      "grad_norm": 30.284215927124023,
      "learning_rate": 1.9210387556024257e-05,
      "loss": 1.046,
      "step": 2285
    },
    {
      "epoch": 0.13560327440977576,
      "grad_norm": 0.46800509095191956,
      "learning_rate": 1.9209069338254683e-05,
      "loss": 0.0072,
      "step": 2286
    },
    {
      "epoch": 0.13566259342745285,
      "grad_norm": 8.839098930358887,
      "learning_rate": 1.9207751120485106e-05,
      "loss": 0.1192,
      "step": 2287
    },
    {
      "epoch": 0.1357219124451299,
      "grad_norm": 0.44214707612991333,
      "learning_rate": 1.920643290271553e-05,
      "loss": 0.0046,
      "step": 2288
    },
    {
      "epoch": 0.135781231462807,
      "grad_norm": 0.01985551416873932,
      "learning_rate": 1.9205114684945954e-05,
      "loss": 0.0004,
      "step": 2289
    },
    {
      "epoch": 0.13584055048048405,
      "grad_norm": 0.17867380380630493,
      "learning_rate": 1.920379646717638e-05,
      "loss": 0.0017,
      "step": 2290
    },
    {
      "epoch": 0.1358998694981611,
      "grad_norm": 15.886948585510254,
      "learning_rate": 1.9202478249406803e-05,
      "loss": 0.3199,
      "step": 2291
    },
    {
      "epoch": 0.1359591885158382,
      "grad_norm": 4.147029399871826,
      "learning_rate": 1.920116003163723e-05,
      "loss": 0.0181,
      "step": 2292
    },
    {
      "epoch": 0.13601850753351524,
      "grad_norm": 5.573911666870117,
      "learning_rate": 1.919984181386765e-05,
      "loss": 0.2812,
      "step": 2293
    },
    {
      "epoch": 0.1360778265511923,
      "grad_norm": 18.51087760925293,
      "learning_rate": 1.9198523596098077e-05,
      "loss": 0.4091,
      "step": 2294
    },
    {
      "epoch": 0.13613714556886938,
      "grad_norm": 24.041440963745117,
      "learning_rate": 1.91972053783285e-05,
      "loss": 1.0857,
      "step": 2295
    },
    {
      "epoch": 0.13619646458654644,
      "grad_norm": 18.348608016967773,
      "learning_rate": 1.9195887160558925e-05,
      "loss": 0.6287,
      "step": 2296
    },
    {
      "epoch": 0.13625578360422352,
      "grad_norm": 1.4281597137451172,
      "learning_rate": 1.919456894278935e-05,
      "loss": 0.0161,
      "step": 2297
    },
    {
      "epoch": 0.13631510262190058,
      "grad_norm": 0.18600517511367798,
      "learning_rate": 1.9193250725019774e-05,
      "loss": 0.0037,
      "step": 2298
    },
    {
      "epoch": 0.13637442163957764,
      "grad_norm": 0.0359157957136631,
      "learning_rate": 1.91919325072502e-05,
      "loss": 0.0007,
      "step": 2299
    },
    {
      "epoch": 0.13643374065725472,
      "grad_norm": 1.5165413618087769,
      "learning_rate": 1.9190614289480625e-05,
      "loss": 0.0192,
      "step": 2300
    },
    {
      "epoch": 0.13649305967493178,
      "grad_norm": 19.9158935546875,
      "learning_rate": 1.9189296071711048e-05,
      "loss": 0.5367,
      "step": 2301
    },
    {
      "epoch": 0.13655237869260886,
      "grad_norm": 16.227144241333008,
      "learning_rate": 1.9187977853941474e-05,
      "loss": 0.6677,
      "step": 2302
    },
    {
      "epoch": 0.13661169771028592,
      "grad_norm": 0.23141694068908691,
      "learning_rate": 1.91866596361719e-05,
      "loss": 0.0027,
      "step": 2303
    },
    {
      "epoch": 0.13667101672796297,
      "grad_norm": 1.6017656326293945,
      "learning_rate": 1.9185341418402322e-05,
      "loss": 0.013,
      "step": 2304
    },
    {
      "epoch": 0.13673033574564006,
      "grad_norm": 1.860013484954834,
      "learning_rate": 1.9184023200632748e-05,
      "loss": 0.0244,
      "step": 2305
    },
    {
      "epoch": 0.13678965476331711,
      "grad_norm": 0.09079980850219727,
      "learning_rate": 1.918270498286317e-05,
      "loss": 0.0017,
      "step": 2306
    },
    {
      "epoch": 0.1368489737809942,
      "grad_norm": 6.519708633422852,
      "learning_rate": 1.9181386765093596e-05,
      "loss": 0.3145,
      "step": 2307
    },
    {
      "epoch": 0.13690829279867126,
      "grad_norm": 9.429365158081055,
      "learning_rate": 1.918006854732402e-05,
      "loss": 0.1625,
      "step": 2308
    },
    {
      "epoch": 0.1369676118163483,
      "grad_norm": 0.7906415462493896,
      "learning_rate": 1.9178750329554445e-05,
      "loss": 0.0127,
      "step": 2309
    },
    {
      "epoch": 0.1370269308340254,
      "grad_norm": 4.883070468902588,
      "learning_rate": 1.9177432111784867e-05,
      "loss": 0.1042,
      "step": 2310
    },
    {
      "epoch": 0.13708624985170245,
      "grad_norm": 30.907054901123047,
      "learning_rate": 1.9176113894015293e-05,
      "loss": 0.3667,
      "step": 2311
    },
    {
      "epoch": 0.13714556886937954,
      "grad_norm": 0.5303599238395691,
      "learning_rate": 1.9174795676245716e-05,
      "loss": 0.0027,
      "step": 2312
    },
    {
      "epoch": 0.1372048878870566,
      "grad_norm": 1.08794105052948,
      "learning_rate": 1.917347745847614e-05,
      "loss": 0.0065,
      "step": 2313
    },
    {
      "epoch": 0.13726420690473365,
      "grad_norm": 0.016713947057724,
      "learning_rate": 1.9172159240706567e-05,
      "loss": 0.0004,
      "step": 2314
    },
    {
      "epoch": 0.13732352592241073,
      "grad_norm": 38.759910583496094,
      "learning_rate": 1.917084102293699e-05,
      "loss": 0.9999,
      "step": 2315
    },
    {
      "epoch": 0.1373828449400878,
      "grad_norm": 0.54566490650177,
      "learning_rate": 1.9169522805167416e-05,
      "loss": 0.0063,
      "step": 2316
    },
    {
      "epoch": 0.13744216395776485,
      "grad_norm": 0.16900764405727386,
      "learning_rate": 1.916820458739784e-05,
      "loss": 0.0025,
      "step": 2317
    },
    {
      "epoch": 0.13750148297544193,
      "grad_norm": 0.008394360542297363,
      "learning_rate": 1.9166886369628264e-05,
      "loss": 0.0002,
      "step": 2318
    },
    {
      "epoch": 0.137560801993119,
      "grad_norm": 0.3882911801338196,
      "learning_rate": 1.916556815185869e-05,
      "loss": 0.004,
      "step": 2319
    },
    {
      "epoch": 0.13762012101079607,
      "grad_norm": 0.03919186443090439,
      "learning_rate": 1.9164249934089116e-05,
      "loss": 0.0009,
      "step": 2320
    },
    {
      "epoch": 0.13767944002847313,
      "grad_norm": 3.7284977436065674,
      "learning_rate": 1.916293171631954e-05,
      "loss": 0.1783,
      "step": 2321
    },
    {
      "epoch": 0.13773875904615018,
      "grad_norm": 0.31954193115234375,
      "learning_rate": 1.916161349854996e-05,
      "loss": 0.0016,
      "step": 2322
    },
    {
      "epoch": 0.13779807806382727,
      "grad_norm": 0.7585822343826294,
      "learning_rate": 1.9160295280780387e-05,
      "loss": 0.0047,
      "step": 2323
    },
    {
      "epoch": 0.13785739708150432,
      "grad_norm": 26.537826538085938,
      "learning_rate": 1.915897706301081e-05,
      "loss": 0.3345,
      "step": 2324
    },
    {
      "epoch": 0.1379167160991814,
      "grad_norm": 34.34189987182617,
      "learning_rate": 1.9157658845241235e-05,
      "loss": 1.0345,
      "step": 2325
    },
    {
      "epoch": 0.13797603511685846,
      "grad_norm": 0.0194797832518816,
      "learning_rate": 1.9156340627471658e-05,
      "loss": 0.0004,
      "step": 2326
    },
    {
      "epoch": 0.13803535413453552,
      "grad_norm": 21.33892822265625,
      "learning_rate": 1.9155022409702083e-05,
      "loss": 1.2605,
      "step": 2327
    },
    {
      "epoch": 0.1380946731522126,
      "grad_norm": 0.8547751903533936,
      "learning_rate": 1.915370419193251e-05,
      "loss": 0.0108,
      "step": 2328
    },
    {
      "epoch": 0.13815399216988966,
      "grad_norm": 23.923837661743164,
      "learning_rate": 1.9152385974162932e-05,
      "loss": 0.3973,
      "step": 2329
    },
    {
      "epoch": 0.13821331118756675,
      "grad_norm": 0.06560587137937546,
      "learning_rate": 1.9151067756393358e-05,
      "loss": 0.0013,
      "step": 2330
    },
    {
      "epoch": 0.1382726302052438,
      "grad_norm": 12.22252368927002,
      "learning_rate": 1.9149749538623784e-05,
      "loss": 0.8293,
      "step": 2331
    },
    {
      "epoch": 0.13833194922292086,
      "grad_norm": 0.7590052485466003,
      "learning_rate": 1.9148431320854206e-05,
      "loss": 0.0058,
      "step": 2332
    },
    {
      "epoch": 0.13839126824059794,
      "grad_norm": 5.120445728302002,
      "learning_rate": 1.9147113103084632e-05,
      "loss": 0.034,
      "step": 2333
    },
    {
      "epoch": 0.138450587258275,
      "grad_norm": 10.30722713470459,
      "learning_rate": 1.9145794885315058e-05,
      "loss": 0.0573,
      "step": 2334
    },
    {
      "epoch": 0.13850990627595208,
      "grad_norm": 15.493309020996094,
      "learning_rate": 1.914447666754548e-05,
      "loss": 1.0436,
      "step": 2335
    },
    {
      "epoch": 0.13856922529362914,
      "grad_norm": 36.32414245605469,
      "learning_rate": 1.9143158449775906e-05,
      "loss": 1.4579,
      "step": 2336
    },
    {
      "epoch": 0.1386285443113062,
      "grad_norm": 3.3246734142303467,
      "learning_rate": 1.914184023200633e-05,
      "loss": 0.0317,
      "step": 2337
    },
    {
      "epoch": 0.13868786332898328,
      "grad_norm": 9.072765350341797,
      "learning_rate": 1.9140522014236755e-05,
      "loss": 0.251,
      "step": 2338
    },
    {
      "epoch": 0.13874718234666034,
      "grad_norm": 10.47187328338623,
      "learning_rate": 1.9139203796467177e-05,
      "loss": 0.3057,
      "step": 2339
    },
    {
      "epoch": 0.13880650136433742,
      "grad_norm": 13.25755786895752,
      "learning_rate": 1.9137885578697603e-05,
      "loss": 0.2169,
      "step": 2340
    },
    {
      "epoch": 0.13886582038201448,
      "grad_norm": 8.463085174560547,
      "learning_rate": 1.9136567360928025e-05,
      "loss": 0.0521,
      "step": 2341
    },
    {
      "epoch": 0.13892513939969153,
      "grad_norm": 0.2713376581668854,
      "learning_rate": 1.913524914315845e-05,
      "loss": 0.0047,
      "step": 2342
    },
    {
      "epoch": 0.13898445841736862,
      "grad_norm": 3.540977954864502,
      "learning_rate": 1.9133930925388874e-05,
      "loss": 0.0478,
      "step": 2343
    },
    {
      "epoch": 0.13904377743504567,
      "grad_norm": 7.937143325805664,
      "learning_rate": 1.91326127076193e-05,
      "loss": 0.1948,
      "step": 2344
    },
    {
      "epoch": 0.13910309645272273,
      "grad_norm": 0.08129313588142395,
      "learning_rate": 1.9131294489849726e-05,
      "loss": 0.0016,
      "step": 2345
    },
    {
      "epoch": 0.13916241547039981,
      "grad_norm": 0.1516016274690628,
      "learning_rate": 1.9129976272080148e-05,
      "loss": 0.0022,
      "step": 2346
    },
    {
      "epoch": 0.13922173448807687,
      "grad_norm": 0.025352809578180313,
      "learning_rate": 1.9128658054310574e-05,
      "loss": 0.0007,
      "step": 2347
    },
    {
      "epoch": 0.13928105350575395,
      "grad_norm": 43.858524322509766,
      "learning_rate": 1.9127339836541e-05,
      "loss": 1.2186,
      "step": 2348
    },
    {
      "epoch": 0.139340372523431,
      "grad_norm": 4.251982688903809,
      "learning_rate": 1.9126021618771422e-05,
      "loss": 0.0977,
      "step": 2349
    },
    {
      "epoch": 0.13939969154110807,
      "grad_norm": 16.086395263671875,
      "learning_rate": 1.9124703401001848e-05,
      "loss": 0.2285,
      "step": 2350
    },
    {
      "epoch": 0.13945901055878515,
      "grad_norm": 13.079578399658203,
      "learning_rate": 1.9123385183232274e-05,
      "loss": 0.3089,
      "step": 2351
    },
    {
      "epoch": 0.1395183295764622,
      "grad_norm": 0.3198179006576538,
      "learning_rate": 1.9122066965462697e-05,
      "loss": 0.0061,
      "step": 2352
    },
    {
      "epoch": 0.1395776485941393,
      "grad_norm": 8.195053100585938,
      "learning_rate": 1.9120748747693122e-05,
      "loss": 0.1262,
      "step": 2353
    },
    {
      "epoch": 0.13963696761181635,
      "grad_norm": 7.066367149353027,
      "learning_rate": 1.9119430529923545e-05,
      "loss": 0.028,
      "step": 2354
    },
    {
      "epoch": 0.1396962866294934,
      "grad_norm": 3.1287002563476562,
      "learning_rate": 1.9118112312153967e-05,
      "loss": 0.0244,
      "step": 2355
    },
    {
      "epoch": 0.1397556056471705,
      "grad_norm": 1.8278356790542603,
      "learning_rate": 1.9116794094384393e-05,
      "loss": 0.0191,
      "step": 2356
    },
    {
      "epoch": 0.13981492466484755,
      "grad_norm": 2.803619384765625,
      "learning_rate": 1.9115475876614816e-05,
      "loss": 0.0704,
      "step": 2357
    },
    {
      "epoch": 0.13987424368252463,
      "grad_norm": 14.54263687133789,
      "learning_rate": 1.9114157658845242e-05,
      "loss": 0.0613,
      "step": 2358
    },
    {
      "epoch": 0.13993356270020169,
      "grad_norm": 3.484988212585449,
      "learning_rate": 1.9112839441075668e-05,
      "loss": 0.0933,
      "step": 2359
    },
    {
      "epoch": 0.13999288171787874,
      "grad_norm": 0.0220864899456501,
      "learning_rate": 1.911152122330609e-05,
      "loss": 0.0008,
      "step": 2360
    },
    {
      "epoch": 0.14005220073555583,
      "grad_norm": 35.00946044921875,
      "learning_rate": 1.9110203005536516e-05,
      "loss": 0.3921,
      "step": 2361
    },
    {
      "epoch": 0.14011151975323288,
      "grad_norm": 15.74392318725586,
      "learning_rate": 1.9108884787766942e-05,
      "loss": 0.2714,
      "step": 2362
    },
    {
      "epoch": 0.14017083877090997,
      "grad_norm": 10.430472373962402,
      "learning_rate": 1.9107566569997364e-05,
      "loss": 0.0954,
      "step": 2363
    },
    {
      "epoch": 0.14023015778858702,
      "grad_norm": 1.2253687381744385,
      "learning_rate": 1.910624835222779e-05,
      "loss": 0.0142,
      "step": 2364
    },
    {
      "epoch": 0.14028947680626408,
      "grad_norm": 0.9906361103057861,
      "learning_rate": 1.9104930134458216e-05,
      "loss": 0.0082,
      "step": 2365
    },
    {
      "epoch": 0.14034879582394116,
      "grad_norm": 0.122122623026371,
      "learning_rate": 1.910361191668864e-05,
      "loss": 0.0032,
      "step": 2366
    },
    {
      "epoch": 0.14040811484161822,
      "grad_norm": 14.240453720092773,
      "learning_rate": 1.9102293698919064e-05,
      "loss": 0.4021,
      "step": 2367
    },
    {
      "epoch": 0.14046743385929528,
      "grad_norm": 0.15950673818588257,
      "learning_rate": 1.9100975481149487e-05,
      "loss": 0.0013,
      "step": 2368
    },
    {
      "epoch": 0.14052675287697236,
      "grad_norm": 6.634774684906006,
      "learning_rate": 1.9099657263379913e-05,
      "loss": 0.1236,
      "step": 2369
    },
    {
      "epoch": 0.14058607189464942,
      "grad_norm": 24.768648147583008,
      "learning_rate": 1.9098339045610335e-05,
      "loss": 0.5112,
      "step": 2370
    },
    {
      "epoch": 0.1406453909123265,
      "grad_norm": 0.474115788936615,
      "learning_rate": 1.909702082784076e-05,
      "loss": 0.0079,
      "step": 2371
    },
    {
      "epoch": 0.14070470993000356,
      "grad_norm": 0.7667646408081055,
      "learning_rate": 1.9095702610071184e-05,
      "loss": 0.0121,
      "step": 2372
    },
    {
      "epoch": 0.14076402894768061,
      "grad_norm": 20.338119506835938,
      "learning_rate": 1.909438439230161e-05,
      "loss": 0.3539,
      "step": 2373
    },
    {
      "epoch": 0.1408233479653577,
      "grad_norm": 0.4447215497493744,
      "learning_rate": 1.9093066174532032e-05,
      "loss": 0.0063,
      "step": 2374
    },
    {
      "epoch": 0.14088266698303475,
      "grad_norm": 23.151348114013672,
      "learning_rate": 1.9091747956762458e-05,
      "loss": 0.7425,
      "step": 2375
    },
    {
      "epoch": 0.14094198600071184,
      "grad_norm": 40.19961929321289,
      "learning_rate": 1.9090429738992884e-05,
      "loss": 0.9979,
      "step": 2376
    },
    {
      "epoch": 0.1410013050183889,
      "grad_norm": 14.199997901916504,
      "learning_rate": 1.9089111521223306e-05,
      "loss": 0.1334,
      "step": 2377
    },
    {
      "epoch": 0.14106062403606595,
      "grad_norm": 2.4738106727600098,
      "learning_rate": 1.9087793303453732e-05,
      "loss": 0.023,
      "step": 2378
    },
    {
      "epoch": 0.14111994305374304,
      "grad_norm": 19.77848243713379,
      "learning_rate": 1.9086475085684158e-05,
      "loss": 0.0543,
      "step": 2379
    },
    {
      "epoch": 0.1411792620714201,
      "grad_norm": 8.223210334777832,
      "learning_rate": 1.908515686791458e-05,
      "loss": 0.1538,
      "step": 2380
    },
    {
      "epoch": 0.14123858108909718,
      "grad_norm": 12.986451148986816,
      "learning_rate": 1.9083838650145006e-05,
      "loss": 0.5453,
      "step": 2381
    },
    {
      "epoch": 0.14129790010677423,
      "grad_norm": 15.913728713989258,
      "learning_rate": 1.9082520432375432e-05,
      "loss": 0.3642,
      "step": 2382
    },
    {
      "epoch": 0.1413572191244513,
      "grad_norm": 0.18268389999866486,
      "learning_rate": 1.9081202214605855e-05,
      "loss": 0.0021,
      "step": 2383
    },
    {
      "epoch": 0.14141653814212837,
      "grad_norm": 6.2362895011901855,
      "learning_rate": 1.907988399683628e-05,
      "loss": 0.2024,
      "step": 2384
    },
    {
      "epoch": 0.14147585715980543,
      "grad_norm": 19.74549674987793,
      "learning_rate": 1.9078565779066703e-05,
      "loss": 0.235,
      "step": 2385
    },
    {
      "epoch": 0.1415351761774825,
      "grad_norm": 16.90825653076172,
      "learning_rate": 1.907724756129713e-05,
      "loss": 1.3964,
      "step": 2386
    },
    {
      "epoch": 0.14159449519515957,
      "grad_norm": 29.21802520751953,
      "learning_rate": 1.907592934352755e-05,
      "loss": 0.0935,
      "step": 2387
    },
    {
      "epoch": 0.14165381421283663,
      "grad_norm": 10.377398490905762,
      "learning_rate": 1.9074611125757977e-05,
      "loss": 0.6395,
      "step": 2388
    },
    {
      "epoch": 0.1417131332305137,
      "grad_norm": 2.376676559448242,
      "learning_rate": 1.90732929079884e-05,
      "loss": 0.0497,
      "step": 2389
    },
    {
      "epoch": 0.14177245224819077,
      "grad_norm": 0.4632115364074707,
      "learning_rate": 1.9071974690218826e-05,
      "loss": 0.0032,
      "step": 2390
    },
    {
      "epoch": 0.14183177126586785,
      "grad_norm": 0.28465405106544495,
      "learning_rate": 1.907065647244925e-05,
      "loss": 0.0035,
      "step": 2391
    },
    {
      "epoch": 0.1418910902835449,
      "grad_norm": 14.022473335266113,
      "learning_rate": 1.9069338254679674e-05,
      "loss": 0.1326,
      "step": 2392
    },
    {
      "epoch": 0.14195040930122196,
      "grad_norm": 8.163444519042969,
      "learning_rate": 1.90680200369101e-05,
      "loss": 0.0598,
      "step": 2393
    },
    {
      "epoch": 0.14200972831889905,
      "grad_norm": 14.149965286254883,
      "learning_rate": 1.9066701819140523e-05,
      "loss": 0.2916,
      "step": 2394
    },
    {
      "epoch": 0.1420690473365761,
      "grad_norm": 3.0675582885742188,
      "learning_rate": 1.906538360137095e-05,
      "loss": 0.0452,
      "step": 2395
    },
    {
      "epoch": 0.14212836635425316,
      "grad_norm": 3.843672275543213,
      "learning_rate": 1.9064065383601374e-05,
      "loss": 0.0249,
      "step": 2396
    },
    {
      "epoch": 0.14218768537193024,
      "grad_norm": 2.158930778503418,
      "learning_rate": 1.9062747165831797e-05,
      "loss": 0.0064,
      "step": 2397
    },
    {
      "epoch": 0.1422470043896073,
      "grad_norm": 18.572145462036133,
      "learning_rate": 1.9061428948062223e-05,
      "loss": 0.533,
      "step": 2398
    },
    {
      "epoch": 0.14230632340728439,
      "grad_norm": 1.2363576889038086,
      "learning_rate": 1.9060110730292645e-05,
      "loss": 0.0143,
      "step": 2399
    },
    {
      "epoch": 0.14236564242496144,
      "grad_norm": 5.6805524826049805,
      "learning_rate": 1.905879251252307e-05,
      "loss": 0.0473,
      "step": 2400
    },
    {
      "epoch": 0.1424249614426385,
      "grad_norm": 17.996055603027344,
      "learning_rate": 1.9057474294753494e-05,
      "loss": 0.6943,
      "step": 2401
    },
    {
      "epoch": 0.14248428046031558,
      "grad_norm": 12.817514419555664,
      "learning_rate": 1.905615607698392e-05,
      "loss": 0.142,
      "step": 2402
    },
    {
      "epoch": 0.14254359947799264,
      "grad_norm": 7.666094779968262,
      "learning_rate": 1.9054837859214342e-05,
      "loss": 0.1336,
      "step": 2403
    },
    {
      "epoch": 0.14260291849566972,
      "grad_norm": 25.47317123413086,
      "learning_rate": 1.9053519641444768e-05,
      "loss": 0.1084,
      "step": 2404
    },
    {
      "epoch": 0.14266223751334678,
      "grad_norm": 36.71865463256836,
      "learning_rate": 1.905220142367519e-05,
      "loss": 0.7115,
      "step": 2405
    },
    {
      "epoch": 0.14272155653102384,
      "grad_norm": 5.443715572357178,
      "learning_rate": 1.9050883205905616e-05,
      "loss": 0.0443,
      "step": 2406
    },
    {
      "epoch": 0.14278087554870092,
      "grad_norm": 3.268362045288086,
      "learning_rate": 1.9049564988136042e-05,
      "loss": 0.0367,
      "step": 2407
    },
    {
      "epoch": 0.14284019456637798,
      "grad_norm": 10.181588172912598,
      "learning_rate": 1.9048246770366465e-05,
      "loss": 0.1105,
      "step": 2408
    },
    {
      "epoch": 0.14289951358405506,
      "grad_norm": 2.798424005508423,
      "learning_rate": 1.904692855259689e-05,
      "loss": 0.0735,
      "step": 2409
    },
    {
      "epoch": 0.14295883260173212,
      "grad_norm": 0.0523262582719326,
      "learning_rate": 1.9045610334827316e-05,
      "loss": 0.0005,
      "step": 2410
    },
    {
      "epoch": 0.14301815161940917,
      "grad_norm": 17.368440628051758,
      "learning_rate": 1.904429211705774e-05,
      "loss": 0.7335,
      "step": 2411
    },
    {
      "epoch": 0.14307747063708626,
      "grad_norm": 6.643744468688965,
      "learning_rate": 1.9042973899288165e-05,
      "loss": 0.1972,
      "step": 2412
    },
    {
      "epoch": 0.1431367896547633,
      "grad_norm": 9.38239574432373,
      "learning_rate": 1.904165568151859e-05,
      "loss": 0.2784,
      "step": 2413
    },
    {
      "epoch": 0.1431961086724404,
      "grad_norm": 2.1241252422332764,
      "learning_rate": 1.9040337463749013e-05,
      "loss": 0.0462,
      "step": 2414
    },
    {
      "epoch": 0.14325542769011745,
      "grad_norm": 145.0312957763672,
      "learning_rate": 1.903901924597944e-05,
      "loss": 1.4107,
      "step": 2415
    },
    {
      "epoch": 0.1433147467077945,
      "grad_norm": 4.179278373718262,
      "learning_rate": 1.903770102820986e-05,
      "loss": 0.1374,
      "step": 2416
    },
    {
      "epoch": 0.1433740657254716,
      "grad_norm": 5.136069297790527,
      "learning_rate": 1.9036382810440287e-05,
      "loss": 0.2274,
      "step": 2417
    },
    {
      "epoch": 0.14343338474314865,
      "grad_norm": 8.285266876220703,
      "learning_rate": 1.903506459267071e-05,
      "loss": 0.1737,
      "step": 2418
    },
    {
      "epoch": 0.1434927037608257,
      "grad_norm": 11.590242385864258,
      "learning_rate": 1.9033746374901136e-05,
      "loss": 0.1307,
      "step": 2419
    },
    {
      "epoch": 0.1435520227785028,
      "grad_norm": 1.5297467708587646,
      "learning_rate": 1.9032428157131558e-05,
      "loss": 0.0233,
      "step": 2420
    },
    {
      "epoch": 0.14361134179617985,
      "grad_norm": 22.019433975219727,
      "learning_rate": 1.9031109939361984e-05,
      "loss": 0.2931,
      "step": 2421
    },
    {
      "epoch": 0.14367066081385693,
      "grad_norm": 10.54574203491211,
      "learning_rate": 1.9029791721592407e-05,
      "loss": 0.1807,
      "step": 2422
    },
    {
      "epoch": 0.143729979831534,
      "grad_norm": 2.0821242332458496,
      "learning_rate": 1.9028473503822833e-05,
      "loss": 0.0215,
      "step": 2423
    },
    {
      "epoch": 0.14378929884921104,
      "grad_norm": 5.66672945022583,
      "learning_rate": 1.902715528605326e-05,
      "loss": 0.0781,
      "step": 2424
    },
    {
      "epoch": 0.14384861786688813,
      "grad_norm": 14.357341766357422,
      "learning_rate": 1.902583706828368e-05,
      "loss": 0.3851,
      "step": 2425
    },
    {
      "epoch": 0.14390793688456519,
      "grad_norm": 0.7168753147125244,
      "learning_rate": 1.9024518850514107e-05,
      "loss": 0.0095,
      "step": 2426
    },
    {
      "epoch": 0.14396725590224227,
      "grad_norm": 0.151190847158432,
      "learning_rate": 1.9023200632744533e-05,
      "loss": 0.0026,
      "step": 2427
    },
    {
      "epoch": 0.14402657491991933,
      "grad_norm": 7.080760955810547,
      "learning_rate": 1.9021882414974955e-05,
      "loss": 0.0322,
      "step": 2428
    },
    {
      "epoch": 0.14408589393759638,
      "grad_norm": 24.7580509185791,
      "learning_rate": 1.902056419720538e-05,
      "loss": 0.3364,
      "step": 2429
    },
    {
      "epoch": 0.14414521295527347,
      "grad_norm": 12.278056144714355,
      "learning_rate": 1.9019245979435807e-05,
      "loss": 0.2104,
      "step": 2430
    },
    {
      "epoch": 0.14420453197295052,
      "grad_norm": 0.6585758924484253,
      "learning_rate": 1.901792776166623e-05,
      "loss": 0.009,
      "step": 2431
    },
    {
      "epoch": 0.1442638509906276,
      "grad_norm": 4.213527679443359,
      "learning_rate": 1.9016609543896655e-05,
      "loss": 0.1086,
      "step": 2432
    },
    {
      "epoch": 0.14432317000830466,
      "grad_norm": 4.30472993850708,
      "learning_rate": 1.9015291326127078e-05,
      "loss": 0.0418,
      "step": 2433
    },
    {
      "epoch": 0.14438248902598172,
      "grad_norm": 3.886673927307129,
      "learning_rate": 1.90139731083575e-05,
      "loss": 0.0444,
      "step": 2434
    },
    {
      "epoch": 0.1444418080436588,
      "grad_norm": 3.7741191387176514,
      "learning_rate": 1.9012654890587926e-05,
      "loss": 0.1297,
      "step": 2435
    },
    {
      "epoch": 0.14450112706133586,
      "grad_norm": 14.021056175231934,
      "learning_rate": 1.901133667281835e-05,
      "loss": 1.2615,
      "step": 2436
    },
    {
      "epoch": 0.14456044607901294,
      "grad_norm": 9.030089378356934,
      "learning_rate": 1.9010018455048775e-05,
      "loss": 0.1549,
      "step": 2437
    },
    {
      "epoch": 0.14461976509669,
      "grad_norm": 0.018983833491802216,
      "learning_rate": 1.90087002372792e-05,
      "loss": 0.0005,
      "step": 2438
    },
    {
      "epoch": 0.14467908411436706,
      "grad_norm": 4.8393473625183105,
      "learning_rate": 1.9007382019509623e-05,
      "loss": 0.0315,
      "step": 2439
    },
    {
      "epoch": 0.14473840313204414,
      "grad_norm": 3.5899744033813477,
      "learning_rate": 1.900606380174005e-05,
      "loss": 0.1001,
      "step": 2440
    },
    {
      "epoch": 0.1447977221497212,
      "grad_norm": 15.201573371887207,
      "learning_rate": 1.9004745583970475e-05,
      "loss": 0.1773,
      "step": 2441
    },
    {
      "epoch": 0.14485704116739828,
      "grad_norm": 20.21936798095703,
      "learning_rate": 1.9003427366200897e-05,
      "loss": 0.2425,
      "step": 2442
    },
    {
      "epoch": 0.14491636018507534,
      "grad_norm": 2.315592050552368,
      "learning_rate": 1.9002109148431323e-05,
      "loss": 0.0261,
      "step": 2443
    },
    {
      "epoch": 0.1449756792027524,
      "grad_norm": 0.1756664663553238,
      "learning_rate": 1.900079093066175e-05,
      "loss": 0.0024,
      "step": 2444
    },
    {
      "epoch": 0.14503499822042948,
      "grad_norm": 6.5530877113342285,
      "learning_rate": 1.899947271289217e-05,
      "loss": 0.0893,
      "step": 2445
    },
    {
      "epoch": 0.14509431723810653,
      "grad_norm": 5.760462284088135,
      "learning_rate": 1.8998154495122597e-05,
      "loss": 0.1899,
      "step": 2446
    },
    {
      "epoch": 0.1451536362557836,
      "grad_norm": 6.971032619476318,
      "learning_rate": 1.899683627735302e-05,
      "loss": 0.0374,
      "step": 2447
    },
    {
      "epoch": 0.14521295527346068,
      "grad_norm": 43.32951354980469,
      "learning_rate": 1.8995518059583446e-05,
      "loss": 0.6059,
      "step": 2448
    },
    {
      "epoch": 0.14527227429113773,
      "grad_norm": 0.020725930109620094,
      "learning_rate": 1.8994199841813868e-05,
      "loss": 0.0007,
      "step": 2449
    },
    {
      "epoch": 0.14533159330881482,
      "grad_norm": 24.47785186767578,
      "learning_rate": 1.8992881624044294e-05,
      "loss": 1.1945,
      "step": 2450
    },
    {
      "epoch": 0.14539091232649187,
      "grad_norm": 10.356670379638672,
      "learning_rate": 1.8991563406274717e-05,
      "loss": 0.1071,
      "step": 2451
    },
    {
      "epoch": 0.14545023134416893,
      "grad_norm": 15.406338691711426,
      "learning_rate": 1.8990245188505142e-05,
      "loss": 0.8201,
      "step": 2452
    },
    {
      "epoch": 0.145509550361846,
      "grad_norm": 21.747652053833008,
      "learning_rate": 1.8988926970735565e-05,
      "loss": 0.5031,
      "step": 2453
    },
    {
      "epoch": 0.14556886937952307,
      "grad_norm": 0.4663105905056,
      "learning_rate": 1.898760875296599e-05,
      "loss": 0.0049,
      "step": 2454
    },
    {
      "epoch": 0.14562818839720015,
      "grad_norm": 0.3579923212528229,
      "learning_rate": 1.8986290535196417e-05,
      "loss": 0.0056,
      "step": 2455
    },
    {
      "epoch": 0.1456875074148772,
      "grad_norm": 0.3960130214691162,
      "learning_rate": 1.898497231742684e-05,
      "loss": 0.0037,
      "step": 2456
    },
    {
      "epoch": 0.14574682643255427,
      "grad_norm": 0.3001980483531952,
      "learning_rate": 1.8983654099657265e-05,
      "loss": 0.0022,
      "step": 2457
    },
    {
      "epoch": 0.14580614545023135,
      "grad_norm": 4.673454761505127,
      "learning_rate": 1.898233588188769e-05,
      "loss": 0.1217,
      "step": 2458
    },
    {
      "epoch": 0.1458654644679084,
      "grad_norm": 3.213456630706787,
      "learning_rate": 1.8981017664118113e-05,
      "loss": 0.035,
      "step": 2459
    },
    {
      "epoch": 0.1459247834855855,
      "grad_norm": 7.502070903778076,
      "learning_rate": 1.897969944634854e-05,
      "loss": 0.0592,
      "step": 2460
    },
    {
      "epoch": 0.14598410250326255,
      "grad_norm": 15.401369094848633,
      "learning_rate": 1.8978381228578965e-05,
      "loss": 1.4289,
      "step": 2461
    },
    {
      "epoch": 0.1460434215209396,
      "grad_norm": 0.31625646352767944,
      "learning_rate": 1.8977063010809388e-05,
      "loss": 0.0027,
      "step": 2462
    },
    {
      "epoch": 0.1461027405386167,
      "grad_norm": 11.913061141967773,
      "learning_rate": 1.8975744793039814e-05,
      "loss": 1.1724,
      "step": 2463
    },
    {
      "epoch": 0.14616205955629374,
      "grad_norm": 6.449497699737549,
      "learning_rate": 1.8974426575270236e-05,
      "loss": 0.1555,
      "step": 2464
    },
    {
      "epoch": 0.14622137857397083,
      "grad_norm": 14.774618148803711,
      "learning_rate": 1.8973108357500662e-05,
      "loss": 0.8308,
      "step": 2465
    },
    {
      "epoch": 0.14628069759164788,
      "grad_norm": 3.60650372505188,
      "learning_rate": 1.8971790139731084e-05,
      "loss": 0.0899,
      "step": 2466
    },
    {
      "epoch": 0.14634001660932494,
      "grad_norm": 10.808064460754395,
      "learning_rate": 1.8970471921961507e-05,
      "loss": 0.8418,
      "step": 2467
    },
    {
      "epoch": 0.14639933562700203,
      "grad_norm": 0.41014301776885986,
      "learning_rate": 1.8969153704191933e-05,
      "loss": 0.0049,
      "step": 2468
    },
    {
      "epoch": 0.14645865464467908,
      "grad_norm": 0.09419611096382141,
      "learning_rate": 1.896783548642236e-05,
      "loss": 0.0027,
      "step": 2469
    },
    {
      "epoch": 0.14651797366235614,
      "grad_norm": 1.2484033107757568,
      "learning_rate": 1.896651726865278e-05,
      "loss": 0.0067,
      "step": 2470
    },
    {
      "epoch": 0.14657729268003322,
      "grad_norm": 0.01634180173277855,
      "learning_rate": 1.8965199050883207e-05,
      "loss": 0.0006,
      "step": 2471
    },
    {
      "epoch": 0.14663661169771028,
      "grad_norm": 0.14751626551151276,
      "learning_rate": 1.8963880833113633e-05,
      "loss": 0.0024,
      "step": 2472
    },
    {
      "epoch": 0.14669593071538736,
      "grad_norm": 0.12164326757192612,
      "learning_rate": 1.8962562615344055e-05,
      "loss": 0.0021,
      "step": 2473
    },
    {
      "epoch": 0.14675524973306442,
      "grad_norm": 10.40164852142334,
      "learning_rate": 1.896124439757448e-05,
      "loss": 0.3814,
      "step": 2474
    },
    {
      "epoch": 0.14681456875074148,
      "grad_norm": 0.4700014591217041,
      "learning_rate": 1.8959926179804907e-05,
      "loss": 0.0038,
      "step": 2475
    },
    {
      "epoch": 0.14687388776841856,
      "grad_norm": 0.10434339195489883,
      "learning_rate": 1.895860796203533e-05,
      "loss": 0.0018,
      "step": 2476
    },
    {
      "epoch": 0.14693320678609562,
      "grad_norm": 8.892037391662598,
      "learning_rate": 1.8957289744265756e-05,
      "loss": 0.1869,
      "step": 2477
    },
    {
      "epoch": 0.1469925258037727,
      "grad_norm": 1.2325623035430908,
      "learning_rate": 1.8955971526496178e-05,
      "loss": 0.0292,
      "step": 2478
    },
    {
      "epoch": 0.14705184482144976,
      "grad_norm": 3.4302611351013184,
      "learning_rate": 1.8954653308726604e-05,
      "loss": 0.0415,
      "step": 2479
    },
    {
      "epoch": 0.1471111638391268,
      "grad_norm": 0.9198535680770874,
      "learning_rate": 1.8953335090957026e-05,
      "loss": 0.0066,
      "step": 2480
    },
    {
      "epoch": 0.1471704828568039,
      "grad_norm": 2.0582008361816406,
      "learning_rate": 1.8952016873187452e-05,
      "loss": 0.0426,
      "step": 2481
    },
    {
      "epoch": 0.14722980187448095,
      "grad_norm": 0.01046689972281456,
      "learning_rate": 1.8950698655417875e-05,
      "loss": 0.0003,
      "step": 2482
    },
    {
      "epoch": 0.14728912089215804,
      "grad_norm": 5.09159517288208,
      "learning_rate": 1.89493804376483e-05,
      "loss": 0.0479,
      "step": 2483
    },
    {
      "epoch": 0.1473484399098351,
      "grad_norm": 5.252228736877441,
      "learning_rate": 1.8948062219878723e-05,
      "loss": 0.0469,
      "step": 2484
    },
    {
      "epoch": 0.14740775892751215,
      "grad_norm": 0.7493062019348145,
      "learning_rate": 1.894674400210915e-05,
      "loss": 0.0084,
      "step": 2485
    },
    {
      "epoch": 0.14746707794518923,
      "grad_norm": 58.5173454284668,
      "learning_rate": 1.8945425784339575e-05,
      "loss": 1.6664,
      "step": 2486
    },
    {
      "epoch": 0.1475263969628663,
      "grad_norm": 4.521894931793213,
      "learning_rate": 1.8944107566569997e-05,
      "loss": 0.0267,
      "step": 2487
    },
    {
      "epoch": 0.14758571598054337,
      "grad_norm": 0.02985217794775963,
      "learning_rate": 1.8942789348800423e-05,
      "loss": 0.0007,
      "step": 2488
    },
    {
      "epoch": 0.14764503499822043,
      "grad_norm": 24.45555877685547,
      "learning_rate": 1.894147113103085e-05,
      "loss": 1.655,
      "step": 2489
    },
    {
      "epoch": 0.1477043540158975,
      "grad_norm": 1.080723762512207,
      "learning_rate": 1.894015291326127e-05,
      "loss": 0.0144,
      "step": 2490
    },
    {
      "epoch": 0.14776367303357457,
      "grad_norm": 10.074987411499023,
      "learning_rate": 1.8938834695491698e-05,
      "loss": 0.1427,
      "step": 2491
    },
    {
      "epoch": 0.14782299205125163,
      "grad_norm": 41.658935546875,
      "learning_rate": 1.8937516477722123e-05,
      "loss": 1.1017,
      "step": 2492
    },
    {
      "epoch": 0.1478823110689287,
      "grad_norm": 10.46479606628418,
      "learning_rate": 1.8936198259952546e-05,
      "loss": 0.0864,
      "step": 2493
    },
    {
      "epoch": 0.14794163008660577,
      "grad_norm": 19.45539093017578,
      "learning_rate": 1.8934880042182972e-05,
      "loss": 0.1001,
      "step": 2494
    },
    {
      "epoch": 0.14800094910428283,
      "grad_norm": 0.08376803249120712,
      "learning_rate": 1.8933561824413394e-05,
      "loss": 0.0016,
      "step": 2495
    },
    {
      "epoch": 0.1480602681219599,
      "grad_norm": 0.8745924234390259,
      "learning_rate": 1.893224360664382e-05,
      "loss": 0.0092,
      "step": 2496
    },
    {
      "epoch": 0.14811958713963697,
      "grad_norm": 9.347638130187988,
      "learning_rate": 1.8930925388874243e-05,
      "loss": 0.7342,
      "step": 2497
    },
    {
      "epoch": 0.14817890615731402,
      "grad_norm": 0.12619124352931976,
      "learning_rate": 1.892960717110467e-05,
      "loss": 0.0013,
      "step": 2498
    },
    {
      "epoch": 0.1482382251749911,
      "grad_norm": 0.07421071082353592,
      "learning_rate": 1.892828895333509e-05,
      "loss": 0.0009,
      "step": 2499
    },
    {
      "epoch": 0.14829754419266816,
      "grad_norm": 0.30739572644233704,
      "learning_rate": 1.8926970735565517e-05,
      "loss": 0.0038,
      "step": 2500
    },
    {
      "epoch": 0.14835686321034525,
      "grad_norm": 3.871317148208618,
      "learning_rate": 1.892565251779594e-05,
      "loss": 0.1269,
      "step": 2501
    },
    {
      "epoch": 0.1484161822280223,
      "grad_norm": 0.05593837797641754,
      "learning_rate": 1.8924334300026365e-05,
      "loss": 0.0014,
      "step": 2502
    },
    {
      "epoch": 0.14847550124569936,
      "grad_norm": 1.3726507425308228,
      "learning_rate": 1.892301608225679e-05,
      "loss": 0.0092,
      "step": 2503
    },
    {
      "epoch": 0.14853482026337644,
      "grad_norm": 13.326011657714844,
      "learning_rate": 1.8921697864487214e-05,
      "loss": 0.1397,
      "step": 2504
    },
    {
      "epoch": 0.1485941392810535,
      "grad_norm": 0.47241440415382385,
      "learning_rate": 1.892037964671764e-05,
      "loss": 0.005,
      "step": 2505
    },
    {
      "epoch": 0.14865345829873058,
      "grad_norm": 0.09413965791463852,
      "learning_rate": 1.8919061428948065e-05,
      "loss": 0.001,
      "step": 2506
    },
    {
      "epoch": 0.14871277731640764,
      "grad_norm": 10.100933074951172,
      "learning_rate": 1.8917743211178488e-05,
      "loss": 0.1994,
      "step": 2507
    },
    {
      "epoch": 0.1487720963340847,
      "grad_norm": 4.991982936859131,
      "learning_rate": 1.8916424993408914e-05,
      "loss": 0.0696,
      "step": 2508
    },
    {
      "epoch": 0.14883141535176178,
      "grad_norm": 0.17710450291633606,
      "learning_rate": 1.891510677563934e-05,
      "loss": 0.0027,
      "step": 2509
    },
    {
      "epoch": 0.14889073436943884,
      "grad_norm": 0.15255703032016754,
      "learning_rate": 1.8913788557869762e-05,
      "loss": 0.0024,
      "step": 2510
    },
    {
      "epoch": 0.14895005338711592,
      "grad_norm": 0.29190805554389954,
      "learning_rate": 1.8912470340100185e-05,
      "loss": 0.0042,
      "step": 2511
    },
    {
      "epoch": 0.14900937240479298,
      "grad_norm": 0.0892997607588768,
      "learning_rate": 1.891115212233061e-05,
      "loss": 0.0014,
      "step": 2512
    },
    {
      "epoch": 0.14906869142247003,
      "grad_norm": 40.589447021484375,
      "learning_rate": 1.8909833904561033e-05,
      "loss": 0.4797,
      "step": 2513
    },
    {
      "epoch": 0.14912801044014712,
      "grad_norm": 9.445919036865234,
      "learning_rate": 1.890851568679146e-05,
      "loss": 0.08,
      "step": 2514
    },
    {
      "epoch": 0.14918732945782417,
      "grad_norm": 10.433952331542969,
      "learning_rate": 1.890719746902188e-05,
      "loss": 0.0824,
      "step": 2515
    },
    {
      "epoch": 0.14924664847550126,
      "grad_norm": 0.6814785599708557,
      "learning_rate": 1.8905879251252307e-05,
      "loss": 0.0075,
      "step": 2516
    },
    {
      "epoch": 0.14930596749317832,
      "grad_norm": 31.79827117919922,
      "learning_rate": 1.8904561033482733e-05,
      "loss": 0.6517,
      "step": 2517
    },
    {
      "epoch": 0.14936528651085537,
      "grad_norm": 5.663547039031982,
      "learning_rate": 1.8903242815713156e-05,
      "loss": 0.0923,
      "step": 2518
    },
    {
      "epoch": 0.14942460552853246,
      "grad_norm": 0.009515715762972832,
      "learning_rate": 1.890192459794358e-05,
      "loss": 0.0002,
      "step": 2519
    },
    {
      "epoch": 0.1494839245462095,
      "grad_norm": 0.14280860126018524,
      "learning_rate": 1.8900606380174007e-05,
      "loss": 0.0018,
      "step": 2520
    },
    {
      "epoch": 0.14954324356388657,
      "grad_norm": 0.0838746726512909,
      "learning_rate": 1.889928816240443e-05,
      "loss": 0.0011,
      "step": 2521
    },
    {
      "epoch": 0.14960256258156365,
      "grad_norm": 2.5468318462371826,
      "learning_rate": 1.8897969944634856e-05,
      "loss": 0.0481,
      "step": 2522
    },
    {
      "epoch": 0.1496618815992407,
      "grad_norm": 6.4617838859558105,
      "learning_rate": 1.8896651726865282e-05,
      "loss": 0.2789,
      "step": 2523
    },
    {
      "epoch": 0.1497212006169178,
      "grad_norm": 3.742459297180176,
      "learning_rate": 1.8895333509095704e-05,
      "loss": 0.038,
      "step": 2524
    },
    {
      "epoch": 0.14978051963459485,
      "grad_norm": 20.499366760253906,
      "learning_rate": 1.889401529132613e-05,
      "loss": 0.306,
      "step": 2525
    },
    {
      "epoch": 0.1498398386522719,
      "grad_norm": 0.38384926319122314,
      "learning_rate": 1.8892697073556553e-05,
      "loss": 0.0046,
      "step": 2526
    },
    {
      "epoch": 0.149899157669949,
      "grad_norm": 9.378449440002441,
      "learning_rate": 1.889137885578698e-05,
      "loss": 0.3419,
      "step": 2527
    },
    {
      "epoch": 0.14995847668762605,
      "grad_norm": 0.2847352921962738,
      "learning_rate": 1.88900606380174e-05,
      "loss": 0.0064,
      "step": 2528
    },
    {
      "epoch": 0.15001779570530313,
      "grad_norm": 0.40393149852752686,
      "learning_rate": 1.8888742420247827e-05,
      "loss": 0.0032,
      "step": 2529
    },
    {
      "epoch": 0.1500771147229802,
      "grad_norm": 5.449664115905762,
      "learning_rate": 1.888742420247825e-05,
      "loss": 0.1393,
      "step": 2530
    },
    {
      "epoch": 0.15013643374065724,
      "grad_norm": 0.027748282998800278,
      "learning_rate": 1.8886105984708675e-05,
      "loss": 0.0007,
      "step": 2531
    },
    {
      "epoch": 0.15019575275833433,
      "grad_norm": 4.477126598358154,
      "learning_rate": 1.8884787766939098e-05,
      "loss": 0.0279,
      "step": 2532
    },
    {
      "epoch": 0.15025507177601138,
      "grad_norm": 2.2162046432495117,
      "learning_rate": 1.8883469549169524e-05,
      "loss": 0.0236,
      "step": 2533
    },
    {
      "epoch": 0.15031439079368847,
      "grad_norm": 0.10225415974855423,
      "learning_rate": 1.888215133139995e-05,
      "loss": 0.0018,
      "step": 2534
    },
    {
      "epoch": 0.15037370981136552,
      "grad_norm": 9.683077812194824,
      "learning_rate": 1.8880833113630372e-05,
      "loss": 0.0591,
      "step": 2535
    },
    {
      "epoch": 0.15043302882904258,
      "grad_norm": 3.315168619155884,
      "learning_rate": 1.8879514895860798e-05,
      "loss": 0.108,
      "step": 2536
    },
    {
      "epoch": 0.15049234784671967,
      "grad_norm": 3.238068103790283,
      "learning_rate": 1.8878196678091224e-05,
      "loss": 0.0275,
      "step": 2537
    },
    {
      "epoch": 0.15055166686439672,
      "grad_norm": 5.5352582931518555,
      "learning_rate": 1.8876878460321646e-05,
      "loss": 0.1632,
      "step": 2538
    },
    {
      "epoch": 0.1506109858820738,
      "grad_norm": 0.026013154536485672,
      "learning_rate": 1.8875560242552072e-05,
      "loss": 0.0007,
      "step": 2539
    },
    {
      "epoch": 0.15067030489975086,
      "grad_norm": 0.023814629763364792,
      "learning_rate": 1.8874242024782498e-05,
      "loss": 0.0008,
      "step": 2540
    },
    {
      "epoch": 0.15072962391742792,
      "grad_norm": 0.5356113910675049,
      "learning_rate": 1.887292380701292e-05,
      "loss": 0.0027,
      "step": 2541
    },
    {
      "epoch": 0.150788942935105,
      "grad_norm": 0.0889701321721077,
      "learning_rate": 1.8871605589243346e-05,
      "loss": 0.0019,
      "step": 2542
    },
    {
      "epoch": 0.15084826195278206,
      "grad_norm": 0.33440065383911133,
      "learning_rate": 1.887028737147377e-05,
      "loss": 0.0019,
      "step": 2543
    },
    {
      "epoch": 0.15090758097045912,
      "grad_norm": 0.04787455499172211,
      "learning_rate": 1.886896915370419e-05,
      "loss": 0.0008,
      "step": 2544
    },
    {
      "epoch": 0.1509668999881362,
      "grad_norm": 1.7542650699615479,
      "learning_rate": 1.8867650935934617e-05,
      "loss": 0.1039,
      "step": 2545
    },
    {
      "epoch": 0.15102621900581326,
      "grad_norm": 0.14875294268131256,
      "learning_rate": 1.886633271816504e-05,
      "loss": 0.0036,
      "step": 2546
    },
    {
      "epoch": 0.15108553802349034,
      "grad_norm": 3.903193950653076,
      "learning_rate": 1.8865014500395466e-05,
      "loss": 0.0516,
      "step": 2547
    },
    {
      "epoch": 0.1511448570411674,
      "grad_norm": 2.22652006149292,
      "learning_rate": 1.886369628262589e-05,
      "loss": 0.0143,
      "step": 2548
    },
    {
      "epoch": 0.15120417605884445,
      "grad_norm": 10.037541389465332,
      "learning_rate": 1.8862378064856314e-05,
      "loss": 0.1153,
      "step": 2549
    },
    {
      "epoch": 0.15126349507652154,
      "grad_norm": 0.04943614825606346,
      "learning_rate": 1.886105984708674e-05,
      "loss": 0.0007,
      "step": 2550
    },
    {
      "epoch": 0.1513228140941986,
      "grad_norm": 5.831139087677002,
      "learning_rate": 1.8859741629317166e-05,
      "loss": 0.0274,
      "step": 2551
    },
    {
      "epoch": 0.15138213311187568,
      "grad_norm": 13.030226707458496,
      "learning_rate": 1.8858423411547588e-05,
      "loss": 0.4004,
      "step": 2552
    },
    {
      "epoch": 0.15144145212955273,
      "grad_norm": 8.896125793457031,
      "learning_rate": 1.8857105193778014e-05,
      "loss": 0.041,
      "step": 2553
    },
    {
      "epoch": 0.1515007711472298,
      "grad_norm": 17.30299186706543,
      "learning_rate": 1.885578697600844e-05,
      "loss": 0.3798,
      "step": 2554
    },
    {
      "epoch": 0.15156009016490687,
      "grad_norm": 15.282581329345703,
      "learning_rate": 1.8854468758238862e-05,
      "loss": 0.9408,
      "step": 2555
    },
    {
      "epoch": 0.15161940918258393,
      "grad_norm": 0.0794733315706253,
      "learning_rate": 1.885315054046929e-05,
      "loss": 0.0014,
      "step": 2556
    },
    {
      "epoch": 0.15167872820026101,
      "grad_norm": 27.092153549194336,
      "learning_rate": 1.885183232269971e-05,
      "loss": 0.2271,
      "step": 2557
    },
    {
      "epoch": 0.15173804721793807,
      "grad_norm": 9.290254592895508,
      "learning_rate": 1.8850514104930137e-05,
      "loss": 0.1879,
      "step": 2558
    },
    {
      "epoch": 0.15179736623561513,
      "grad_norm": 0.00749787176027894,
      "learning_rate": 1.884919588716056e-05,
      "loss": 0.0002,
      "step": 2559
    },
    {
      "epoch": 0.1518566852532922,
      "grad_norm": 1.8765313625335693,
      "learning_rate": 1.8847877669390985e-05,
      "loss": 0.0182,
      "step": 2560
    },
    {
      "epoch": 0.15191600427096927,
      "grad_norm": 0.07537737488746643,
      "learning_rate": 1.8846559451621408e-05,
      "loss": 0.0015,
      "step": 2561
    },
    {
      "epoch": 0.15197532328864635,
      "grad_norm": 9.450915336608887,
      "learning_rate": 1.8845241233851833e-05,
      "loss": 0.0304,
      "step": 2562
    },
    {
      "epoch": 0.1520346423063234,
      "grad_norm": 4.153063774108887,
      "learning_rate": 1.8843923016082256e-05,
      "loss": 0.0433,
      "step": 2563
    },
    {
      "epoch": 0.15209396132400047,
      "grad_norm": 4.17598295211792,
      "learning_rate": 1.8842604798312682e-05,
      "loss": 0.0818,
      "step": 2564
    },
    {
      "epoch": 0.15215328034167755,
      "grad_norm": 56.15107345581055,
      "learning_rate": 1.8841286580543108e-05,
      "loss": 0.7132,
      "step": 2565
    },
    {
      "epoch": 0.1522125993593546,
      "grad_norm": 17.166048049926758,
      "learning_rate": 1.883996836277353e-05,
      "loss": 0.421,
      "step": 2566
    },
    {
      "epoch": 0.1522719183770317,
      "grad_norm": 0.44085395336151123,
      "learning_rate": 1.8838650145003956e-05,
      "loss": 0.0046,
      "step": 2567
    },
    {
      "epoch": 0.15233123739470875,
      "grad_norm": 1.4743692874908447,
      "learning_rate": 1.8837331927234382e-05,
      "loss": 0.0179,
      "step": 2568
    },
    {
      "epoch": 0.1523905564123858,
      "grad_norm": 24.243206024169922,
      "learning_rate": 1.8836013709464804e-05,
      "loss": 0.4852,
      "step": 2569
    },
    {
      "epoch": 0.1524498754300629,
      "grad_norm": 2.0794732570648193,
      "learning_rate": 1.883469549169523e-05,
      "loss": 0.0117,
      "step": 2570
    },
    {
      "epoch": 0.15250919444773994,
      "grad_norm": 16.677040100097656,
      "learning_rate": 1.8833377273925656e-05,
      "loss": 0.2223,
      "step": 2571
    },
    {
      "epoch": 0.152568513465417,
      "grad_norm": 0.09938021749258041,
      "learning_rate": 1.883205905615608e-05,
      "loss": 0.0016,
      "step": 2572
    },
    {
      "epoch": 0.15262783248309408,
      "grad_norm": 0.44635018706321716,
      "learning_rate": 1.8830740838386505e-05,
      "loss": 0.0036,
      "step": 2573
    },
    {
      "epoch": 0.15268715150077114,
      "grad_norm": 21.92803192138672,
      "learning_rate": 1.8829422620616927e-05,
      "loss": 0.409,
      "step": 2574
    },
    {
      "epoch": 0.15274647051844822,
      "grad_norm": 9.58051872253418,
      "learning_rate": 1.8828104402847353e-05,
      "loss": 0.2863,
      "step": 2575
    },
    {
      "epoch": 0.15280578953612528,
      "grad_norm": 3.5760791301727295,
      "learning_rate": 1.8826786185077775e-05,
      "loss": 0.1922,
      "step": 2576
    },
    {
      "epoch": 0.15286510855380234,
      "grad_norm": 6.876234531402588,
      "learning_rate": 1.88254679673082e-05,
      "loss": 0.0463,
      "step": 2577
    },
    {
      "epoch": 0.15292442757147942,
      "grad_norm": 1.2546682357788086,
      "learning_rate": 1.8824149749538624e-05,
      "loss": 0.0153,
      "step": 2578
    },
    {
      "epoch": 0.15298374658915648,
      "grad_norm": 6.675426483154297,
      "learning_rate": 1.882283153176905e-05,
      "loss": 0.2652,
      "step": 2579
    },
    {
      "epoch": 0.15304306560683356,
      "grad_norm": 8.582898139953613,
      "learning_rate": 1.8821513313999472e-05,
      "loss": 0.1263,
      "step": 2580
    },
    {
      "epoch": 0.15310238462451062,
      "grad_norm": 18.605581283569336,
      "learning_rate": 1.8820195096229898e-05,
      "loss": 0.1551,
      "step": 2581
    },
    {
      "epoch": 0.15316170364218767,
      "grad_norm": 13.484723091125488,
      "learning_rate": 1.8818876878460324e-05,
      "loss": 0.3727,
      "step": 2582
    },
    {
      "epoch": 0.15322102265986476,
      "grad_norm": 0.5873247385025024,
      "learning_rate": 1.8817558660690746e-05,
      "loss": 0.0071,
      "step": 2583
    },
    {
      "epoch": 0.15328034167754181,
      "grad_norm": 20.891267776489258,
      "learning_rate": 1.8816240442921172e-05,
      "loss": 0.2627,
      "step": 2584
    },
    {
      "epoch": 0.1533396606952189,
      "grad_norm": 0.6290441155433655,
      "learning_rate": 1.8814922225151598e-05,
      "loss": 0.0045,
      "step": 2585
    },
    {
      "epoch": 0.15339897971289596,
      "grad_norm": 0.11907438188791275,
      "learning_rate": 1.881360400738202e-05,
      "loss": 0.0024,
      "step": 2586
    },
    {
      "epoch": 0.153458298730573,
      "grad_norm": 0.04495972767472267,
      "learning_rate": 1.8812285789612447e-05,
      "loss": 0.001,
      "step": 2587
    },
    {
      "epoch": 0.1535176177482501,
      "grad_norm": 0.6020511388778687,
      "learning_rate": 1.8810967571842873e-05,
      "loss": 0.0091,
      "step": 2588
    },
    {
      "epoch": 0.15357693676592715,
      "grad_norm": 17.626792907714844,
      "learning_rate": 1.8809649354073295e-05,
      "loss": 0.2982,
      "step": 2589
    },
    {
      "epoch": 0.15363625578360424,
      "grad_norm": 29.235530853271484,
      "learning_rate": 1.8808331136303717e-05,
      "loss": 0.3157,
      "step": 2590
    },
    {
      "epoch": 0.1536955748012813,
      "grad_norm": 1.3984487056732178,
      "learning_rate": 1.8807012918534143e-05,
      "loss": 0.0276,
      "step": 2591
    },
    {
      "epoch": 0.15375489381895835,
      "grad_norm": 14.128662109375,
      "learning_rate": 1.8805694700764566e-05,
      "loss": 0.1515,
      "step": 2592
    },
    {
      "epoch": 0.15381421283663543,
      "grad_norm": 0.3045355975627899,
      "learning_rate": 1.8804376482994992e-05,
      "loss": 0.005,
      "step": 2593
    },
    {
      "epoch": 0.1538735318543125,
      "grad_norm": 23.77847671508789,
      "learning_rate": 1.8803058265225418e-05,
      "loss": 0.584,
      "step": 2594
    },
    {
      "epoch": 0.15393285087198955,
      "grad_norm": 0.5510661005973816,
      "learning_rate": 1.880174004745584e-05,
      "loss": 0.0066,
      "step": 2595
    },
    {
      "epoch": 0.15399216988966663,
      "grad_norm": 9.616832733154297,
      "learning_rate": 1.8800421829686266e-05,
      "loss": 0.0926,
      "step": 2596
    },
    {
      "epoch": 0.1540514889073437,
      "grad_norm": 7.267475605010986,
      "learning_rate": 1.879910361191669e-05,
      "loss": 0.1198,
      "step": 2597
    },
    {
      "epoch": 0.15411080792502077,
      "grad_norm": 8.947003364562988,
      "learning_rate": 1.8797785394147114e-05,
      "loss": 0.3027,
      "step": 2598
    },
    {
      "epoch": 0.15417012694269783,
      "grad_norm": 15.829460144042969,
      "learning_rate": 1.879646717637754e-05,
      "loss": 0.2735,
      "step": 2599
    },
    {
      "epoch": 0.15422944596037488,
      "grad_norm": 0.005865918006747961,
      "learning_rate": 1.8795148958607963e-05,
      "loss": 0.0002,
      "step": 2600
    },
    {
      "epoch": 0.15428876497805197,
      "grad_norm": 0.061316199600696564,
      "learning_rate": 1.879383074083839e-05,
      "loss": 0.001,
      "step": 2601
    },
    {
      "epoch": 0.15434808399572902,
      "grad_norm": 8.71391773223877,
      "learning_rate": 1.8792512523068815e-05,
      "loss": 0.0872,
      "step": 2602
    },
    {
      "epoch": 0.1544074030134061,
      "grad_norm": 0.5003318190574646,
      "learning_rate": 1.8791194305299237e-05,
      "loss": 0.0067,
      "step": 2603
    },
    {
      "epoch": 0.15446672203108316,
      "grad_norm": 1.5647205114364624,
      "learning_rate": 1.8789876087529663e-05,
      "loss": 0.0199,
      "step": 2604
    },
    {
      "epoch": 0.15452604104876022,
      "grad_norm": 28.772911071777344,
      "learning_rate": 1.8788557869760085e-05,
      "loss": 0.6774,
      "step": 2605
    },
    {
      "epoch": 0.1545853600664373,
      "grad_norm": 3.3953912258148193,
      "learning_rate": 1.878723965199051e-05,
      "loss": 0.06,
      "step": 2606
    },
    {
      "epoch": 0.15464467908411436,
      "grad_norm": 6.757011890411377,
      "learning_rate": 1.8785921434220934e-05,
      "loss": 0.0501,
      "step": 2607
    },
    {
      "epoch": 0.15470399810179145,
      "grad_norm": 15.450982093811035,
      "learning_rate": 1.878460321645136e-05,
      "loss": 0.5109,
      "step": 2608
    },
    {
      "epoch": 0.1547633171194685,
      "grad_norm": 21.816757202148438,
      "learning_rate": 1.8783284998681782e-05,
      "loss": 1.3492,
      "step": 2609
    },
    {
      "epoch": 0.15482263613714556,
      "grad_norm": 14.492304801940918,
      "learning_rate": 1.8781966780912208e-05,
      "loss": 0.6704,
      "step": 2610
    },
    {
      "epoch": 0.15488195515482264,
      "grad_norm": 38.68092727661133,
      "learning_rate": 1.878064856314263e-05,
      "loss": 0.1648,
      "step": 2611
    },
    {
      "epoch": 0.1549412741724997,
      "grad_norm": 3.6716506481170654,
      "learning_rate": 1.8779330345373056e-05,
      "loss": 0.0295,
      "step": 2612
    },
    {
      "epoch": 0.15500059319017678,
      "grad_norm": 0.04392576217651367,
      "learning_rate": 1.8778012127603482e-05,
      "loss": 0.0006,
      "step": 2613
    },
    {
      "epoch": 0.15505991220785384,
      "grad_norm": 0.007020953577011824,
      "learning_rate": 1.8776693909833905e-05,
      "loss": 0.0002,
      "step": 2614
    },
    {
      "epoch": 0.1551192312255309,
      "grad_norm": 22.61075210571289,
      "learning_rate": 1.877537569206433e-05,
      "loss": 1.154,
      "step": 2615
    },
    {
      "epoch": 0.15517855024320798,
      "grad_norm": 3.7548725605010986,
      "learning_rate": 1.8774057474294757e-05,
      "loss": 0.0383,
      "step": 2616
    },
    {
      "epoch": 0.15523786926088504,
      "grad_norm": 3.5182759761810303,
      "learning_rate": 1.877273925652518e-05,
      "loss": 0.0582,
      "step": 2617
    },
    {
      "epoch": 0.15529718827856212,
      "grad_norm": 12.180319786071777,
      "learning_rate": 1.8771421038755605e-05,
      "loss": 0.6411,
      "step": 2618
    },
    {
      "epoch": 0.15535650729623918,
      "grad_norm": 10.895018577575684,
      "learning_rate": 1.877010282098603e-05,
      "loss": 0.1025,
      "step": 2619
    },
    {
      "epoch": 0.15541582631391623,
      "grad_norm": 0.9156516790390015,
      "learning_rate": 1.8768784603216453e-05,
      "loss": 0.0054,
      "step": 2620
    },
    {
      "epoch": 0.15547514533159332,
      "grad_norm": 19.929210662841797,
      "learning_rate": 1.876746638544688e-05,
      "loss": 0.5937,
      "step": 2621
    },
    {
      "epoch": 0.15553446434927037,
      "grad_norm": 14.343207359313965,
      "learning_rate": 1.87661481676773e-05,
      "loss": 0.2339,
      "step": 2622
    },
    {
      "epoch": 0.15559378336694743,
      "grad_norm": 0.04142604395747185,
      "learning_rate": 1.8764829949907724e-05,
      "loss": 0.0008,
      "step": 2623
    },
    {
      "epoch": 0.15565310238462451,
      "grad_norm": 10.927425384521484,
      "learning_rate": 1.876351173213815e-05,
      "loss": 0.1449,
      "step": 2624
    },
    {
      "epoch": 0.15571242140230157,
      "grad_norm": 7.736593723297119,
      "learning_rate": 1.8762193514368576e-05,
      "loss": 0.4203,
      "step": 2625
    },
    {
      "epoch": 0.15577174041997865,
      "grad_norm": 7.139978885650635,
      "learning_rate": 1.8760875296599e-05,
      "loss": 0.1016,
      "step": 2626
    },
    {
      "epoch": 0.1558310594376557,
      "grad_norm": 8.69079303741455,
      "learning_rate": 1.8759557078829424e-05,
      "loss": 0.0582,
      "step": 2627
    },
    {
      "epoch": 0.15589037845533277,
      "grad_norm": 12.246451377868652,
      "learning_rate": 1.8758238861059847e-05,
      "loss": 0.0973,
      "step": 2628
    },
    {
      "epoch": 0.15594969747300985,
      "grad_norm": 1.2898035049438477,
      "learning_rate": 1.8756920643290273e-05,
      "loss": 0.0102,
      "step": 2629
    },
    {
      "epoch": 0.1560090164906869,
      "grad_norm": 13.282346725463867,
      "learning_rate": 1.87556024255207e-05,
      "loss": 0.1855,
      "step": 2630
    },
    {
      "epoch": 0.156068335508364,
      "grad_norm": 0.296505331993103,
      "learning_rate": 1.875428420775112e-05,
      "loss": 0.0031,
      "step": 2631
    },
    {
      "epoch": 0.15612765452604105,
      "grad_norm": 9.78968620300293,
      "learning_rate": 1.8752965989981547e-05,
      "loss": 0.1091,
      "step": 2632
    },
    {
      "epoch": 0.1561869735437181,
      "grad_norm": 0.021326756104826927,
      "learning_rate": 1.8751647772211973e-05,
      "loss": 0.0005,
      "step": 2633
    },
    {
      "epoch": 0.1562462925613952,
      "grad_norm": 3.893747091293335,
      "learning_rate": 1.8750329554442395e-05,
      "loss": 0.0385,
      "step": 2634
    },
    {
      "epoch": 0.15630561157907225,
      "grad_norm": 126.1454849243164,
      "learning_rate": 1.874901133667282e-05,
      "loss": 0.5474,
      "step": 2635
    },
    {
      "epoch": 0.15636493059674933,
      "grad_norm": 20.052974700927734,
      "learning_rate": 1.8747693118903244e-05,
      "loss": 1.1914,
      "step": 2636
    },
    {
      "epoch": 0.15642424961442639,
      "grad_norm": 13.815947532653809,
      "learning_rate": 1.874637490113367e-05,
      "loss": 0.1266,
      "step": 2637
    },
    {
      "epoch": 0.15648356863210344,
      "grad_norm": 29.61931610107422,
      "learning_rate": 1.8745056683364092e-05,
      "loss": 0.596,
      "step": 2638
    },
    {
      "epoch": 0.15654288764978053,
      "grad_norm": 8.440863609313965,
      "learning_rate": 1.8743738465594518e-05,
      "loss": 0.3844,
      "step": 2639
    },
    {
      "epoch": 0.15660220666745758,
      "grad_norm": 6.157824993133545,
      "learning_rate": 1.874242024782494e-05,
      "loss": 0.1412,
      "step": 2640
    },
    {
      "epoch": 0.15666152568513467,
      "grad_norm": 3.731924295425415,
      "learning_rate": 1.8741102030055366e-05,
      "loss": 0.1934,
      "step": 2641
    },
    {
      "epoch": 0.15672084470281172,
      "grad_norm": 24.434499740600586,
      "learning_rate": 1.8739783812285792e-05,
      "loss": 0.3204,
      "step": 2642
    },
    {
      "epoch": 0.15678016372048878,
      "grad_norm": 3.1319949626922607,
      "learning_rate": 1.8738465594516215e-05,
      "loss": 0.037,
      "step": 2643
    },
    {
      "epoch": 0.15683948273816586,
      "grad_norm": 6.439969539642334,
      "learning_rate": 1.873714737674664e-05,
      "loss": 0.0499,
      "step": 2644
    },
    {
      "epoch": 0.15689880175584292,
      "grad_norm": 1.2286542654037476,
      "learning_rate": 1.8735829158977063e-05,
      "loss": 0.0135,
      "step": 2645
    },
    {
      "epoch": 0.15695812077351998,
      "grad_norm": 0.4043717086315155,
      "learning_rate": 1.873451094120749e-05,
      "loss": 0.0025,
      "step": 2646
    },
    {
      "epoch": 0.15701743979119706,
      "grad_norm": 0.4018852710723877,
      "learning_rate": 1.8733192723437915e-05,
      "loss": 0.0069,
      "step": 2647
    },
    {
      "epoch": 0.15707675880887412,
      "grad_norm": 0.06399551033973694,
      "learning_rate": 1.8731874505668337e-05,
      "loss": 0.0007,
      "step": 2648
    },
    {
      "epoch": 0.1571360778265512,
      "grad_norm": 5.097866535186768,
      "learning_rate": 1.8730556287898763e-05,
      "loss": 0.0523,
      "step": 2649
    },
    {
      "epoch": 0.15719539684422826,
      "grad_norm": 65.37672424316406,
      "learning_rate": 1.872923807012919e-05,
      "loss": 1.6828,
      "step": 2650
    },
    {
      "epoch": 0.15725471586190531,
      "grad_norm": 0.09702915698289871,
      "learning_rate": 1.872791985235961e-05,
      "loss": 0.002,
      "step": 2651
    },
    {
      "epoch": 0.1573140348795824,
      "grad_norm": 7.457293510437012,
      "learning_rate": 1.8726601634590037e-05,
      "loss": 0.0299,
      "step": 2652
    },
    {
      "epoch": 0.15737335389725945,
      "grad_norm": 0.013199795968830585,
      "learning_rate": 1.872528341682046e-05,
      "loss": 0.0004,
      "step": 2653
    },
    {
      "epoch": 0.15743267291493654,
      "grad_norm": 9.369741439819336,
      "learning_rate": 1.8723965199050886e-05,
      "loss": 0.4944,
      "step": 2654
    },
    {
      "epoch": 0.1574919919326136,
      "grad_norm": 0.11433505266904831,
      "learning_rate": 1.8722646981281308e-05,
      "loss": 0.0012,
      "step": 2655
    },
    {
      "epoch": 0.15755131095029065,
      "grad_norm": 0.13747304677963257,
      "learning_rate": 1.8721328763511734e-05,
      "loss": 0.002,
      "step": 2656
    },
    {
      "epoch": 0.15761062996796774,
      "grad_norm": 0.2941323518753052,
      "learning_rate": 1.8720010545742157e-05,
      "loss": 0.0034,
      "step": 2657
    },
    {
      "epoch": 0.1576699489856448,
      "grad_norm": 29.42167091369629,
      "learning_rate": 1.8718692327972583e-05,
      "loss": 0.0578,
      "step": 2658
    },
    {
      "epoch": 0.15772926800332188,
      "grad_norm": 13.46019172668457,
      "learning_rate": 1.8717374110203005e-05,
      "loss": 0.9446,
      "step": 2659
    },
    {
      "epoch": 0.15778858702099893,
      "grad_norm": 2.3339250087738037,
      "learning_rate": 1.871605589243343e-05,
      "loss": 0.0264,
      "step": 2660
    },
    {
      "epoch": 0.157847906038676,
      "grad_norm": 101.85581970214844,
      "learning_rate": 1.8714737674663857e-05,
      "loss": 0.6804,
      "step": 2661
    },
    {
      "epoch": 0.15790722505635307,
      "grad_norm": 6.055649280548096,
      "learning_rate": 1.871341945689428e-05,
      "loss": 0.0295,
      "step": 2662
    },
    {
      "epoch": 0.15796654407403013,
      "grad_norm": 0.15403509140014648,
      "learning_rate": 1.8712101239124705e-05,
      "loss": 0.0028,
      "step": 2663
    },
    {
      "epoch": 0.1580258630917072,
      "grad_norm": 1.9699501991271973,
      "learning_rate": 1.871078302135513e-05,
      "loss": 0.026,
      "step": 2664
    },
    {
      "epoch": 0.15808518210938427,
      "grad_norm": 8.678177833557129,
      "learning_rate": 1.8709464803585554e-05,
      "loss": 0.0468,
      "step": 2665
    },
    {
      "epoch": 0.15814450112706133,
      "grad_norm": 3.0304532051086426,
      "learning_rate": 1.870814658581598e-05,
      "loss": 0.0233,
      "step": 2666
    },
    {
      "epoch": 0.1582038201447384,
      "grad_norm": 3.6357245445251465,
      "learning_rate": 1.8706828368046402e-05,
      "loss": 0.0302,
      "step": 2667
    },
    {
      "epoch": 0.15826313916241547,
      "grad_norm": 0.18178129196166992,
      "learning_rate": 1.8705510150276828e-05,
      "loss": 0.0028,
      "step": 2668
    },
    {
      "epoch": 0.15832245818009255,
      "grad_norm": 0.12430000305175781,
      "learning_rate": 1.870419193250725e-05,
      "loss": 0.0019,
      "step": 2669
    },
    {
      "epoch": 0.1583817771977696,
      "grad_norm": 83.57182312011719,
      "learning_rate": 1.8702873714737676e-05,
      "loss": 1.2473,
      "step": 2670
    },
    {
      "epoch": 0.15844109621544666,
      "grad_norm": 11.446667671203613,
      "learning_rate": 1.87015554969681e-05,
      "loss": 0.1058,
      "step": 2671
    },
    {
      "epoch": 0.15850041523312375,
      "grad_norm": 11.066258430480957,
      "learning_rate": 1.8700237279198525e-05,
      "loss": 0.3325,
      "step": 2672
    },
    {
      "epoch": 0.1585597342508008,
      "grad_norm": 4.66424036026001,
      "learning_rate": 1.869891906142895e-05,
      "loss": 0.0569,
      "step": 2673
    },
    {
      "epoch": 0.15861905326847786,
      "grad_norm": 0.017733467742800713,
      "learning_rate": 1.8697600843659373e-05,
      "loss": 0.0004,
      "step": 2674
    },
    {
      "epoch": 0.15867837228615495,
      "grad_norm": 0.03089788928627968,
      "learning_rate": 1.86962826258898e-05,
      "loss": 0.0004,
      "step": 2675
    },
    {
      "epoch": 0.158737691303832,
      "grad_norm": 2.999112844467163,
      "learning_rate": 1.869496440812022e-05,
      "loss": 0.0252,
      "step": 2676
    },
    {
      "epoch": 0.15879701032150909,
      "grad_norm": 54.15508270263672,
      "learning_rate": 1.8693646190350647e-05,
      "loss": 0.3275,
      "step": 2677
    },
    {
      "epoch": 0.15885632933918614,
      "grad_norm": 9.995081901550293,
      "learning_rate": 1.8692327972581073e-05,
      "loss": 0.2827,
      "step": 2678
    },
    {
      "epoch": 0.1589156483568632,
      "grad_norm": 5.5772881507873535,
      "learning_rate": 1.8691009754811496e-05,
      "loss": 0.0977,
      "step": 2679
    },
    {
      "epoch": 0.15897496737454028,
      "grad_norm": 8.219141006469727,
      "learning_rate": 1.868969153704192e-05,
      "loss": 0.0761,
      "step": 2680
    },
    {
      "epoch": 0.15903428639221734,
      "grad_norm": 12.07861328125,
      "learning_rate": 1.8688373319272347e-05,
      "loss": 1.1746,
      "step": 2681
    },
    {
      "epoch": 0.15909360540989442,
      "grad_norm": 3.889251947402954,
      "learning_rate": 1.868705510150277e-05,
      "loss": 0.1866,
      "step": 2682
    },
    {
      "epoch": 0.15915292442757148,
      "grad_norm": 8.887144088745117,
      "learning_rate": 1.8685736883733196e-05,
      "loss": 0.6698,
      "step": 2683
    },
    {
      "epoch": 0.15921224344524854,
      "grad_norm": 2.515194892883301,
      "learning_rate": 1.8684418665963618e-05,
      "loss": 0.0315,
      "step": 2684
    },
    {
      "epoch": 0.15927156246292562,
      "grad_norm": 0.11966541409492493,
      "learning_rate": 1.8683100448194044e-05,
      "loss": 0.0014,
      "step": 2685
    },
    {
      "epoch": 0.15933088148060268,
      "grad_norm": 7.1017022132873535,
      "learning_rate": 1.8681782230424467e-05,
      "loss": 0.1822,
      "step": 2686
    },
    {
      "epoch": 0.15939020049827976,
      "grad_norm": 7.805623531341553,
      "learning_rate": 1.8680464012654892e-05,
      "loss": 0.1383,
      "step": 2687
    },
    {
      "epoch": 0.15944951951595682,
      "grad_norm": 0.17679601907730103,
      "learning_rate": 1.8679145794885315e-05,
      "loss": 0.0017,
      "step": 2688
    },
    {
      "epoch": 0.15950883853363387,
      "grad_norm": 4.532641410827637,
      "learning_rate": 1.867782757711574e-05,
      "loss": 0.0382,
      "step": 2689
    },
    {
      "epoch": 0.15956815755131096,
      "grad_norm": 10.547765731811523,
      "learning_rate": 1.8676509359346167e-05,
      "loss": 0.5157,
      "step": 2690
    },
    {
      "epoch": 0.159627476568988,
      "grad_norm": 0.8140497207641602,
      "learning_rate": 1.867519114157659e-05,
      "loss": 0.0055,
      "step": 2691
    },
    {
      "epoch": 0.1596867955866651,
      "grad_norm": 15.585112571716309,
      "learning_rate": 1.8673872923807015e-05,
      "loss": 0.0939,
      "step": 2692
    },
    {
      "epoch": 0.15974611460434215,
      "grad_norm": 12.035078048706055,
      "learning_rate": 1.8672554706037438e-05,
      "loss": 0.1519,
      "step": 2693
    },
    {
      "epoch": 0.1598054336220192,
      "grad_norm": 37.82016372680664,
      "learning_rate": 1.8671236488267863e-05,
      "loss": 0.054,
      "step": 2694
    },
    {
      "epoch": 0.1598647526396963,
      "grad_norm": 0.140389546751976,
      "learning_rate": 1.866991827049829e-05,
      "loss": 0.0015,
      "step": 2695
    },
    {
      "epoch": 0.15992407165737335,
      "grad_norm": 9.208401679992676,
      "learning_rate": 1.8668600052728712e-05,
      "loss": 0.0813,
      "step": 2696
    },
    {
      "epoch": 0.1599833906750504,
      "grad_norm": 0.06341336667537689,
      "learning_rate": 1.8667281834959138e-05,
      "loss": 0.0014,
      "step": 2697
    },
    {
      "epoch": 0.1600427096927275,
      "grad_norm": 40.111839294433594,
      "learning_rate": 1.8665963617189564e-05,
      "loss": 0.1301,
      "step": 2698
    },
    {
      "epoch": 0.16010202871040455,
      "grad_norm": 1.3977614641189575,
      "learning_rate": 1.8664645399419986e-05,
      "loss": 0.0101,
      "step": 2699
    },
    {
      "epoch": 0.16016134772808163,
      "grad_norm": 4.142885208129883,
      "learning_rate": 1.866332718165041e-05,
      "loss": 0.0546,
      "step": 2700
    },
    {
      "epoch": 0.1602206667457587,
      "grad_norm": 48.48392105102539,
      "learning_rate": 1.8662008963880834e-05,
      "loss": 0.7084,
      "step": 2701
    },
    {
      "epoch": 0.16027998576343574,
      "grad_norm": 12.172256469726562,
      "learning_rate": 1.8660690746111257e-05,
      "loss": 0.2961,
      "step": 2702
    },
    {
      "epoch": 0.16033930478111283,
      "grad_norm": 11.986839294433594,
      "learning_rate": 1.8659372528341683e-05,
      "loss": 0.1639,
      "step": 2703
    },
    {
      "epoch": 0.16039862379878989,
      "grad_norm": 0.04592769593000412,
      "learning_rate": 1.865805431057211e-05,
      "loss": 0.0009,
      "step": 2704
    },
    {
      "epoch": 0.16045794281646697,
      "grad_norm": 3.375819444656372,
      "learning_rate": 1.865673609280253e-05,
      "loss": 0.036,
      "step": 2705
    },
    {
      "epoch": 0.16051726183414403,
      "grad_norm": 0.22476564347743988,
      "learning_rate": 1.8655417875032957e-05,
      "loss": 0.0023,
      "step": 2706
    },
    {
      "epoch": 0.16057658085182108,
      "grad_norm": 4.973838806152344,
      "learning_rate": 1.865409965726338e-05,
      "loss": 0.0454,
      "step": 2707
    },
    {
      "epoch": 0.16063589986949817,
      "grad_norm": 11.738927841186523,
      "learning_rate": 1.8652781439493805e-05,
      "loss": 0.0399,
      "step": 2708
    },
    {
      "epoch": 0.16069521888717522,
      "grad_norm": 14.39861011505127,
      "learning_rate": 1.865146322172423e-05,
      "loss": 0.5587,
      "step": 2709
    },
    {
      "epoch": 0.1607545379048523,
      "grad_norm": 20.676149368286133,
      "learning_rate": 1.8650145003954654e-05,
      "loss": 0.6519,
      "step": 2710
    },
    {
      "epoch": 0.16081385692252936,
      "grad_norm": 0.4055356979370117,
      "learning_rate": 1.864882678618508e-05,
      "loss": 0.0059,
      "step": 2711
    },
    {
      "epoch": 0.16087317594020642,
      "grad_norm": 12.436216354370117,
      "learning_rate": 1.8647508568415506e-05,
      "loss": 0.2228,
      "step": 2712
    },
    {
      "epoch": 0.1609324949578835,
      "grad_norm": 6.334934234619141,
      "learning_rate": 1.8646190350645928e-05,
      "loss": 0.1691,
      "step": 2713
    },
    {
      "epoch": 0.16099181397556056,
      "grad_norm": 11.616257667541504,
      "learning_rate": 1.8644872132876354e-05,
      "loss": 0.1925,
      "step": 2714
    },
    {
      "epoch": 0.16105113299323764,
      "grad_norm": 0.07604622840881348,
      "learning_rate": 1.8643553915106776e-05,
      "loss": 0.0015,
      "step": 2715
    },
    {
      "epoch": 0.1611104520109147,
      "grad_norm": 64.3044662475586,
      "learning_rate": 1.8642235697337202e-05,
      "loss": 1.4003,
      "step": 2716
    },
    {
      "epoch": 0.16116977102859176,
      "grad_norm": 6.85292387008667,
      "learning_rate": 1.8640917479567625e-05,
      "loss": 0.2432,
      "step": 2717
    },
    {
      "epoch": 0.16122909004626884,
      "grad_norm": 8.793305397033691,
      "learning_rate": 1.863959926179805e-05,
      "loss": 0.18,
      "step": 2718
    },
    {
      "epoch": 0.1612884090639459,
      "grad_norm": 6.571407794952393,
      "learning_rate": 1.8638281044028473e-05,
      "loss": 0.2317,
      "step": 2719
    },
    {
      "epoch": 0.16134772808162298,
      "grad_norm": 6.026641845703125,
      "learning_rate": 1.86369628262589e-05,
      "loss": 0.0904,
      "step": 2720
    },
    {
      "epoch": 0.16140704709930004,
      "grad_norm": 7.607062816619873,
      "learning_rate": 1.8635644608489325e-05,
      "loss": 0.0939,
      "step": 2721
    },
    {
      "epoch": 0.1614663661169771,
      "grad_norm": 0.5517156720161438,
      "learning_rate": 1.8634326390719747e-05,
      "loss": 0.0049,
      "step": 2722
    },
    {
      "epoch": 0.16152568513465418,
      "grad_norm": 15.703920364379883,
      "learning_rate": 1.8633008172950173e-05,
      "loss": 0.2378,
      "step": 2723
    },
    {
      "epoch": 0.16158500415233124,
      "grad_norm": 28.51719093322754,
      "learning_rate": 1.8631689955180596e-05,
      "loss": 2.6519,
      "step": 2724
    },
    {
      "epoch": 0.1616443231700083,
      "grad_norm": 17.777061462402344,
      "learning_rate": 1.8630371737411022e-05,
      "loss": 0.1411,
      "step": 2725
    },
    {
      "epoch": 0.16170364218768538,
      "grad_norm": 1.42033052444458,
      "learning_rate": 1.8629053519641448e-05,
      "loss": 0.0125,
      "step": 2726
    },
    {
      "epoch": 0.16176296120536243,
      "grad_norm": 29.958524703979492,
      "learning_rate": 1.862773530187187e-05,
      "loss": 0.1373,
      "step": 2727
    },
    {
      "epoch": 0.16182228022303952,
      "grad_norm": 1.8177144527435303,
      "learning_rate": 1.8626417084102296e-05,
      "loss": 0.0097,
      "step": 2728
    },
    {
      "epoch": 0.16188159924071657,
      "grad_norm": 2.309152364730835,
      "learning_rate": 1.8625098866332722e-05,
      "loss": 0.0129,
      "step": 2729
    },
    {
      "epoch": 0.16194091825839363,
      "grad_norm": 0.02484491840004921,
      "learning_rate": 1.8623780648563144e-05,
      "loss": 0.0005,
      "step": 2730
    },
    {
      "epoch": 0.1620002372760707,
      "grad_norm": 3.442666530609131,
      "learning_rate": 1.862246243079357e-05,
      "loss": 0.0407,
      "step": 2731
    },
    {
      "epoch": 0.16205955629374777,
      "grad_norm": 0.16869181394577026,
      "learning_rate": 1.8621144213023993e-05,
      "loss": 0.0028,
      "step": 2732
    },
    {
      "epoch": 0.16211887531142485,
      "grad_norm": 29.38944435119629,
      "learning_rate": 1.861982599525442e-05,
      "loss": 0.253,
      "step": 2733
    },
    {
      "epoch": 0.1621781943291019,
      "grad_norm": 25.40329933166504,
      "learning_rate": 1.861850777748484e-05,
      "loss": 0.5162,
      "step": 2734
    },
    {
      "epoch": 0.16223751334677897,
      "grad_norm": 38.70746612548828,
      "learning_rate": 1.8617189559715267e-05,
      "loss": 1.7037,
      "step": 2735
    },
    {
      "epoch": 0.16229683236445605,
      "grad_norm": 1.1242386102676392,
      "learning_rate": 1.861587134194569e-05,
      "loss": 0.0075,
      "step": 2736
    },
    {
      "epoch": 0.1623561513821331,
      "grad_norm": 27.114543914794922,
      "learning_rate": 1.8614553124176115e-05,
      "loss": 0.1306,
      "step": 2737
    },
    {
      "epoch": 0.1624154703998102,
      "grad_norm": 8.016250610351562,
      "learning_rate": 1.861323490640654e-05,
      "loss": 0.1166,
      "step": 2738
    },
    {
      "epoch": 0.16247478941748725,
      "grad_norm": 11.072344779968262,
      "learning_rate": 1.8611916688636964e-05,
      "loss": 0.6116,
      "step": 2739
    },
    {
      "epoch": 0.1625341084351643,
      "grad_norm": 22.58310317993164,
      "learning_rate": 1.861059847086739e-05,
      "loss": 0.5231,
      "step": 2740
    },
    {
      "epoch": 0.1625934274528414,
      "grad_norm": 21.816837310791016,
      "learning_rate": 1.8609280253097812e-05,
      "loss": 0.2635,
      "step": 2741
    },
    {
      "epoch": 0.16265274647051844,
      "grad_norm": 16.63417625427246,
      "learning_rate": 1.8607962035328238e-05,
      "loss": 0.2618,
      "step": 2742
    },
    {
      "epoch": 0.16271206548819553,
      "grad_norm": 16.902175903320312,
      "learning_rate": 1.8606643817558664e-05,
      "loss": 0.2942,
      "step": 2743
    },
    {
      "epoch": 0.16277138450587259,
      "grad_norm": 0.8541404604911804,
      "learning_rate": 1.8605325599789086e-05,
      "loss": 0.0118,
      "step": 2744
    },
    {
      "epoch": 0.16283070352354964,
      "grad_norm": 0.1263098120689392,
      "learning_rate": 1.8604007382019512e-05,
      "loss": 0.0021,
      "step": 2745
    },
    {
      "epoch": 0.16289002254122673,
      "grad_norm": 4.802679538726807,
      "learning_rate": 1.8602689164249935e-05,
      "loss": 0.0886,
      "step": 2746
    },
    {
      "epoch": 0.16294934155890378,
      "grad_norm": 9.951200485229492,
      "learning_rate": 1.860137094648036e-05,
      "loss": 0.4876,
      "step": 2747
    },
    {
      "epoch": 0.16300866057658084,
      "grad_norm": 3.823683261871338,
      "learning_rate": 1.8600052728710783e-05,
      "loss": 0.12,
      "step": 2748
    },
    {
      "epoch": 0.16306797959425792,
      "grad_norm": 0.8134573101997375,
      "learning_rate": 1.859873451094121e-05,
      "loss": 0.0085,
      "step": 2749
    },
    {
      "epoch": 0.16312729861193498,
      "grad_norm": 0.1823648065328598,
      "learning_rate": 1.859741629317163e-05,
      "loss": 0.0027,
      "step": 2750
    },
    {
      "epoch": 0.16318661762961206,
      "grad_norm": 1.3667519092559814,
      "learning_rate": 1.8596098075402057e-05,
      "loss": 0.0177,
      "step": 2751
    },
    {
      "epoch": 0.16324593664728912,
      "grad_norm": 6.250197410583496,
      "learning_rate": 1.8594779857632483e-05,
      "loss": 0.1081,
      "step": 2752
    },
    {
      "epoch": 0.16330525566496618,
      "grad_norm": 34.994285583496094,
      "learning_rate": 1.8593461639862906e-05,
      "loss": 1.0494,
      "step": 2753
    },
    {
      "epoch": 0.16336457468264326,
      "grad_norm": 0.07767829298973083,
      "learning_rate": 1.859214342209333e-05,
      "loss": 0.0024,
      "step": 2754
    },
    {
      "epoch": 0.16342389370032032,
      "grad_norm": 14.278491973876953,
      "learning_rate": 1.8590825204323754e-05,
      "loss": 0.7119,
      "step": 2755
    },
    {
      "epoch": 0.1634832127179974,
      "grad_norm": 11.035259246826172,
      "learning_rate": 1.858950698655418e-05,
      "loss": 0.3797,
      "step": 2756
    },
    {
      "epoch": 0.16354253173567446,
      "grad_norm": 0.8516969084739685,
      "learning_rate": 1.8588188768784606e-05,
      "loss": 0.0108,
      "step": 2757
    },
    {
      "epoch": 0.1636018507533515,
      "grad_norm": 0.49021628499031067,
      "learning_rate": 1.858687055101503e-05,
      "loss": 0.0047,
      "step": 2758
    },
    {
      "epoch": 0.1636611697710286,
      "grad_norm": 7.170541286468506,
      "learning_rate": 1.8585552333245454e-05,
      "loss": 0.6261,
      "step": 2759
    },
    {
      "epoch": 0.16372048878870565,
      "grad_norm": 0.09128531813621521,
      "learning_rate": 1.858423411547588e-05,
      "loss": 0.0022,
      "step": 2760
    },
    {
      "epoch": 0.16377980780638274,
      "grad_norm": 20.11260223388672,
      "learning_rate": 1.8582915897706303e-05,
      "loss": 0.3234,
      "step": 2761
    },
    {
      "epoch": 0.1638391268240598,
      "grad_norm": 0.5270931720733643,
      "learning_rate": 1.858159767993673e-05,
      "loss": 0.0044,
      "step": 2762
    },
    {
      "epoch": 0.16389844584173685,
      "grad_norm": 0.2350032478570938,
      "learning_rate": 1.858027946216715e-05,
      "loss": 0.0027,
      "step": 2763
    },
    {
      "epoch": 0.16395776485941393,
      "grad_norm": 71.22297668457031,
      "learning_rate": 1.8578961244397577e-05,
      "loss": 1.165,
      "step": 2764
    },
    {
      "epoch": 0.164017083877091,
      "grad_norm": 1.2276030778884888,
      "learning_rate": 1.8577643026628e-05,
      "loss": 0.0097,
      "step": 2765
    },
    {
      "epoch": 0.16407640289476808,
      "grad_norm": 20.189420700073242,
      "learning_rate": 1.8576324808858425e-05,
      "loss": 0.2854,
      "step": 2766
    },
    {
      "epoch": 0.16413572191244513,
      "grad_norm": 0.7301182746887207,
      "learning_rate": 1.8575006591088848e-05,
      "loss": 0.0077,
      "step": 2767
    },
    {
      "epoch": 0.1641950409301222,
      "grad_norm": 5.143401622772217,
      "learning_rate": 1.8573688373319274e-05,
      "loss": 0.0826,
      "step": 2768
    },
    {
      "epoch": 0.16425435994779927,
      "grad_norm": 0.33739086985588074,
      "learning_rate": 1.85723701555497e-05,
      "loss": 0.006,
      "step": 2769
    },
    {
      "epoch": 0.16431367896547633,
      "grad_norm": 6.474942684173584,
      "learning_rate": 1.8571051937780122e-05,
      "loss": 0.1092,
      "step": 2770
    },
    {
      "epoch": 0.1643729979831534,
      "grad_norm": 3.6755502223968506,
      "learning_rate": 1.8569733720010548e-05,
      "loss": 0.1322,
      "step": 2771
    },
    {
      "epoch": 0.16443231700083047,
      "grad_norm": 22.34489631652832,
      "learning_rate": 1.856841550224097e-05,
      "loss": 0.3254,
      "step": 2772
    },
    {
      "epoch": 0.16449163601850753,
      "grad_norm": 1.0033396482467651,
      "learning_rate": 1.8567097284471396e-05,
      "loss": 0.0157,
      "step": 2773
    },
    {
      "epoch": 0.1645509550361846,
      "grad_norm": 0.04168764129281044,
      "learning_rate": 1.8565779066701822e-05,
      "loss": 0.001,
      "step": 2774
    },
    {
      "epoch": 0.16461027405386167,
      "grad_norm": 13.68709945678711,
      "learning_rate": 1.8564460848932245e-05,
      "loss": 1.5087,
      "step": 2775
    },
    {
      "epoch": 0.16466959307153872,
      "grad_norm": 3.0099244117736816,
      "learning_rate": 1.856314263116267e-05,
      "loss": 0.0935,
      "step": 2776
    },
    {
      "epoch": 0.1647289120892158,
      "grad_norm": 0.09358029812574387,
      "learning_rate": 1.8561824413393096e-05,
      "loss": 0.0021,
      "step": 2777
    },
    {
      "epoch": 0.16478823110689286,
      "grad_norm": 2.8098671436309814,
      "learning_rate": 1.856050619562352e-05,
      "loss": 0.0288,
      "step": 2778
    },
    {
      "epoch": 0.16484755012456995,
      "grad_norm": 7.919418811798096,
      "learning_rate": 1.855918797785394e-05,
      "loss": 0.3661,
      "step": 2779
    },
    {
      "epoch": 0.164906869142247,
      "grad_norm": 3.7953457832336426,
      "learning_rate": 1.8557869760084367e-05,
      "loss": 0.1747,
      "step": 2780
    },
    {
      "epoch": 0.16496618815992406,
      "grad_norm": 11.459207534790039,
      "learning_rate": 1.855655154231479e-05,
      "loss": 0.157,
      "step": 2781
    },
    {
      "epoch": 0.16502550717760114,
      "grad_norm": 13.846277236938477,
      "learning_rate": 1.8555233324545216e-05,
      "loss": 0.4261,
      "step": 2782
    },
    {
      "epoch": 0.1650848261952782,
      "grad_norm": 11.946967124938965,
      "learning_rate": 1.855391510677564e-05,
      "loss": 0.0991,
      "step": 2783
    },
    {
      "epoch": 0.16514414521295528,
      "grad_norm": 1.0711725950241089,
      "learning_rate": 1.8552596889006064e-05,
      "loss": 0.0089,
      "step": 2784
    },
    {
      "epoch": 0.16520346423063234,
      "grad_norm": 3.9818942546844482,
      "learning_rate": 1.855127867123649e-05,
      "loss": 0.0277,
      "step": 2785
    },
    {
      "epoch": 0.1652627832483094,
      "grad_norm": 1.1177111864089966,
      "learning_rate": 1.8549960453466916e-05,
      "loss": 0.0266,
      "step": 2786
    },
    {
      "epoch": 0.16532210226598648,
      "grad_norm": 2.3056626319885254,
      "learning_rate": 1.8548642235697338e-05,
      "loss": 0.0233,
      "step": 2787
    },
    {
      "epoch": 0.16538142128366354,
      "grad_norm": 3.89555287361145,
      "learning_rate": 1.8547324017927764e-05,
      "loss": 0.028,
      "step": 2788
    },
    {
      "epoch": 0.16544074030134062,
      "grad_norm": 0.3237697184085846,
      "learning_rate": 1.8546005800158187e-05,
      "loss": 0.0044,
      "step": 2789
    },
    {
      "epoch": 0.16550005931901768,
      "grad_norm": 1.7303520441055298,
      "learning_rate": 1.8544687582388613e-05,
      "loss": 0.0122,
      "step": 2790
    },
    {
      "epoch": 0.16555937833669473,
      "grad_norm": 10.71975040435791,
      "learning_rate": 1.854336936461904e-05,
      "loss": 0.1255,
      "step": 2791
    },
    {
      "epoch": 0.16561869735437182,
      "grad_norm": 3.8293466567993164,
      "learning_rate": 1.854205114684946e-05,
      "loss": 0.0463,
      "step": 2792
    },
    {
      "epoch": 0.16567801637204888,
      "grad_norm": 19.151290893554688,
      "learning_rate": 1.8540732929079887e-05,
      "loss": 1.7158,
      "step": 2793
    },
    {
      "epoch": 0.16573733538972596,
      "grad_norm": 7.631503582000732,
      "learning_rate": 1.853941471131031e-05,
      "loss": 0.3889,
      "step": 2794
    },
    {
      "epoch": 0.16579665440740302,
      "grad_norm": 18.521772384643555,
      "learning_rate": 1.8538096493540735e-05,
      "loss": 0.2394,
      "step": 2795
    },
    {
      "epoch": 0.16585597342508007,
      "grad_norm": 9.193873405456543,
      "learning_rate": 1.8536778275771158e-05,
      "loss": 0.1126,
      "step": 2796
    },
    {
      "epoch": 0.16591529244275716,
      "grad_norm": 0.22333234548568726,
      "learning_rate": 1.8535460058001584e-05,
      "loss": 0.003,
      "step": 2797
    },
    {
      "epoch": 0.1659746114604342,
      "grad_norm": 0.026328900828957558,
      "learning_rate": 1.8534141840232006e-05,
      "loss": 0.0006,
      "step": 2798
    },
    {
      "epoch": 0.16603393047811127,
      "grad_norm": 3.6363942623138428,
      "learning_rate": 1.8532823622462432e-05,
      "loss": 0.0493,
      "step": 2799
    },
    {
      "epoch": 0.16609324949578835,
      "grad_norm": 9.420591354370117,
      "learning_rate": 1.8531505404692858e-05,
      "loss": 0.5898,
      "step": 2800
    },
    {
      "epoch": 0.1661525685134654,
      "grad_norm": 0.060819778591394424,
      "learning_rate": 1.853018718692328e-05,
      "loss": 0.0012,
      "step": 2801
    },
    {
      "epoch": 0.1662118875311425,
      "grad_norm": 5.279304504394531,
      "learning_rate": 1.8528868969153706e-05,
      "loss": 0.0358,
      "step": 2802
    },
    {
      "epoch": 0.16627120654881955,
      "grad_norm": 0.058629296720027924,
      "learning_rate": 1.8527550751384132e-05,
      "loss": 0.0014,
      "step": 2803
    },
    {
      "epoch": 0.1663305255664966,
      "grad_norm": 7.089720726013184,
      "learning_rate": 1.8526232533614555e-05,
      "loss": 0.0511,
      "step": 2804
    },
    {
      "epoch": 0.1663898445841737,
      "grad_norm": 10.282233238220215,
      "learning_rate": 1.852491431584498e-05,
      "loss": 0.3139,
      "step": 2805
    },
    {
      "epoch": 0.16644916360185075,
      "grad_norm": 9.216889381408691,
      "learning_rate": 1.8523596098075403e-05,
      "loss": 0.143,
      "step": 2806
    },
    {
      "epoch": 0.16650848261952783,
      "grad_norm": 0.5592378377914429,
      "learning_rate": 1.852227788030583e-05,
      "loss": 0.0082,
      "step": 2807
    },
    {
      "epoch": 0.1665678016372049,
      "grad_norm": 13.84334945678711,
      "learning_rate": 1.8520959662536255e-05,
      "loss": 0.4925,
      "step": 2808
    },
    {
      "epoch": 0.16662712065488194,
      "grad_norm": 0.04997619241476059,
      "learning_rate": 1.8519641444766677e-05,
      "loss": 0.0011,
      "step": 2809
    },
    {
      "epoch": 0.16668643967255903,
      "grad_norm": 6.1915788650512695,
      "learning_rate": 1.8518323226997103e-05,
      "loss": 0.0499,
      "step": 2810
    },
    {
      "epoch": 0.16674575869023608,
      "grad_norm": 0.6198403835296631,
      "learning_rate": 1.8517005009227526e-05,
      "loss": 0.0056,
      "step": 2811
    },
    {
      "epoch": 0.16680507770791317,
      "grad_norm": 0.28880396485328674,
      "learning_rate": 1.8515686791457948e-05,
      "loss": 0.0042,
      "step": 2812
    },
    {
      "epoch": 0.16686439672559022,
      "grad_norm": 1.2048100233078003,
      "learning_rate": 1.8514368573688374e-05,
      "loss": 0.0167,
      "step": 2813
    },
    {
      "epoch": 0.16692371574326728,
      "grad_norm": 11.52757453918457,
      "learning_rate": 1.85130503559188e-05,
      "loss": 0.3558,
      "step": 2814
    },
    {
      "epoch": 0.16698303476094437,
      "grad_norm": 0.19258782267570496,
      "learning_rate": 1.8511732138149222e-05,
      "loss": 0.0017,
      "step": 2815
    },
    {
      "epoch": 0.16704235377862142,
      "grad_norm": 5.5498480796813965,
      "learning_rate": 1.8510413920379648e-05,
      "loss": 0.0552,
      "step": 2816
    },
    {
      "epoch": 0.1671016727962985,
      "grad_norm": 0.025121185928583145,
      "learning_rate": 1.8509095702610074e-05,
      "loss": 0.0006,
      "step": 2817
    },
    {
      "epoch": 0.16716099181397556,
      "grad_norm": 0.2488357126712799,
      "learning_rate": 1.8507777484840497e-05,
      "loss": 0.004,
      "step": 2818
    },
    {
      "epoch": 0.16722031083165262,
      "grad_norm": 0.1557730883359909,
      "learning_rate": 1.8506459267070922e-05,
      "loss": 0.0033,
      "step": 2819
    },
    {
      "epoch": 0.1672796298493297,
      "grad_norm": 0.03761296719312668,
      "learning_rate": 1.8505141049301345e-05,
      "loss": 0.0009,
      "step": 2820
    },
    {
      "epoch": 0.16733894886700676,
      "grad_norm": 4.759670257568359,
      "learning_rate": 1.850382283153177e-05,
      "loss": 0.0691,
      "step": 2821
    },
    {
      "epoch": 0.16739826788468384,
      "grad_norm": 17.84522247314453,
      "learning_rate": 1.8502504613762197e-05,
      "loss": 1.0973,
      "step": 2822
    },
    {
      "epoch": 0.1674575869023609,
      "grad_norm": 23.889806747436523,
      "learning_rate": 1.850118639599262e-05,
      "loss": 1.0245,
      "step": 2823
    },
    {
      "epoch": 0.16751690592003796,
      "grad_norm": 4.440423011779785,
      "learning_rate": 1.8499868178223045e-05,
      "loss": 0.0179,
      "step": 2824
    },
    {
      "epoch": 0.16757622493771504,
      "grad_norm": 0.47784748673439026,
      "learning_rate": 1.8498549960453468e-05,
      "loss": 0.0055,
      "step": 2825
    },
    {
      "epoch": 0.1676355439553921,
      "grad_norm": 8.075528144836426,
      "learning_rate": 1.8497231742683893e-05,
      "loss": 0.1032,
      "step": 2826
    },
    {
      "epoch": 0.16769486297306915,
      "grad_norm": 11.564414024353027,
      "learning_rate": 1.8495913524914316e-05,
      "loss": 0.1372,
      "step": 2827
    },
    {
      "epoch": 0.16775418199074624,
      "grad_norm": 1.2793947458267212,
      "learning_rate": 1.8494595307144742e-05,
      "loss": 0.0066,
      "step": 2828
    },
    {
      "epoch": 0.1678135010084233,
      "grad_norm": 0.9567810893058777,
      "learning_rate": 1.8493277089375164e-05,
      "loss": 0.006,
      "step": 2829
    },
    {
      "epoch": 0.16787282002610038,
      "grad_norm": 35.42384338378906,
      "learning_rate": 1.849195887160559e-05,
      "loss": 0.4504,
      "step": 2830
    },
    {
      "epoch": 0.16793213904377743,
      "grad_norm": 0.10176027566194534,
      "learning_rate": 1.8490640653836016e-05,
      "loss": 0.0024,
      "step": 2831
    },
    {
      "epoch": 0.1679914580614545,
      "grad_norm": 0.009159309789538383,
      "learning_rate": 1.848932243606644e-05,
      "loss": 0.0002,
      "step": 2832
    },
    {
      "epoch": 0.16805077707913157,
      "grad_norm": 2.221970796585083,
      "learning_rate": 1.8488004218296864e-05,
      "loss": 0.0182,
      "step": 2833
    },
    {
      "epoch": 0.16811009609680863,
      "grad_norm": 27.809431076049805,
      "learning_rate": 1.848668600052729e-05,
      "loss": 0.0852,
      "step": 2834
    },
    {
      "epoch": 0.16816941511448572,
      "grad_norm": 6.734440326690674,
      "learning_rate": 1.8485367782757713e-05,
      "loss": 0.0762,
      "step": 2835
    },
    {
      "epoch": 0.16822873413216277,
      "grad_norm": 15.56156063079834,
      "learning_rate": 1.848404956498814e-05,
      "loss": 0.3082,
      "step": 2836
    },
    {
      "epoch": 0.16828805314983983,
      "grad_norm": 25.321060180664062,
      "learning_rate": 1.848273134721856e-05,
      "loss": 0.4836,
      "step": 2837
    },
    {
      "epoch": 0.1683473721675169,
      "grad_norm": 6.5861711502075195,
      "learning_rate": 1.8481413129448987e-05,
      "loss": 0.1432,
      "step": 2838
    },
    {
      "epoch": 0.16840669118519397,
      "grad_norm": 0.10404439270496368,
      "learning_rate": 1.8480094911679413e-05,
      "loss": 0.0016,
      "step": 2839
    },
    {
      "epoch": 0.16846601020287105,
      "grad_norm": 7.498697757720947,
      "learning_rate": 1.8478776693909835e-05,
      "loss": 0.3162,
      "step": 2840
    },
    {
      "epoch": 0.1685253292205481,
      "grad_norm": 0.4669839143753052,
      "learning_rate": 1.847745847614026e-05,
      "loss": 0.0045,
      "step": 2841
    },
    {
      "epoch": 0.16858464823822517,
      "grad_norm": 22.942733764648438,
      "learning_rate": 1.8476140258370684e-05,
      "loss": 0.4157,
      "step": 2842
    },
    {
      "epoch": 0.16864396725590225,
      "grad_norm": 14.548659324645996,
      "learning_rate": 1.847482204060111e-05,
      "loss": 0.5447,
      "step": 2843
    },
    {
      "epoch": 0.1687032862735793,
      "grad_norm": 5.349157810211182,
      "learning_rate": 1.8473503822831532e-05,
      "loss": 0.236,
      "step": 2844
    },
    {
      "epoch": 0.1687626052912564,
      "grad_norm": 9.16482925415039,
      "learning_rate": 1.8472185605061958e-05,
      "loss": 0.0667,
      "step": 2845
    },
    {
      "epoch": 0.16882192430893345,
      "grad_norm": 0.06487158685922623,
      "learning_rate": 1.847086738729238e-05,
      "loss": 0.0005,
      "step": 2846
    },
    {
      "epoch": 0.1688812433266105,
      "grad_norm": 0.20519044995307922,
      "learning_rate": 1.8469549169522806e-05,
      "loss": 0.0039,
      "step": 2847
    },
    {
      "epoch": 0.1689405623442876,
      "grad_norm": 0.4153966009616852,
      "learning_rate": 1.8468230951753232e-05,
      "loss": 0.0074,
      "step": 2848
    },
    {
      "epoch": 0.16899988136196464,
      "grad_norm": 4.128667831420898,
      "learning_rate": 1.8466912733983655e-05,
      "loss": 0.0621,
      "step": 2849
    },
    {
      "epoch": 0.1690592003796417,
      "grad_norm": 8.39908504486084,
      "learning_rate": 1.846559451621408e-05,
      "loss": 0.3045,
      "step": 2850
    },
    {
      "epoch": 0.16911851939731878,
      "grad_norm": 13.78971004486084,
      "learning_rate": 1.8464276298444507e-05,
      "loss": 0.7591,
      "step": 2851
    },
    {
      "epoch": 0.16917783841499584,
      "grad_norm": 0.0481291301548481,
      "learning_rate": 1.846295808067493e-05,
      "loss": 0.0007,
      "step": 2852
    },
    {
      "epoch": 0.16923715743267292,
      "grad_norm": 0.1108979806303978,
      "learning_rate": 1.8461639862905355e-05,
      "loss": 0.0016,
      "step": 2853
    },
    {
      "epoch": 0.16929647645034998,
      "grad_norm": 2.7996528148651123,
      "learning_rate": 1.8460321645135777e-05,
      "loss": 0.0245,
      "step": 2854
    },
    {
      "epoch": 0.16935579546802704,
      "grad_norm": 38.11765670776367,
      "learning_rate": 1.8459003427366203e-05,
      "loss": 0.6034,
      "step": 2855
    },
    {
      "epoch": 0.16941511448570412,
      "grad_norm": 0.008046452887356281,
      "learning_rate": 1.8457685209596626e-05,
      "loss": 0.0002,
      "step": 2856
    },
    {
      "epoch": 0.16947443350338118,
      "grad_norm": 7.803646564483643,
      "learning_rate": 1.845636699182705e-05,
      "loss": 0.1589,
      "step": 2857
    },
    {
      "epoch": 0.16953375252105826,
      "grad_norm": 0.0409233458340168,
      "learning_rate": 1.8455048774057474e-05,
      "loss": 0.001,
      "step": 2858
    },
    {
      "epoch": 0.16959307153873532,
      "grad_norm": 0.6878541111946106,
      "learning_rate": 1.84537305562879e-05,
      "loss": 0.0066,
      "step": 2859
    },
    {
      "epoch": 0.16965239055641237,
      "grad_norm": 14.08178424835205,
      "learning_rate": 1.8452412338518323e-05,
      "loss": 0.5707,
      "step": 2860
    },
    {
      "epoch": 0.16971170957408946,
      "grad_norm": 21.15452003479004,
      "learning_rate": 1.845109412074875e-05,
      "loss": 0.7162,
      "step": 2861
    },
    {
      "epoch": 0.16977102859176652,
      "grad_norm": 17.0068359375,
      "learning_rate": 1.8449775902979174e-05,
      "loss": 0.252,
      "step": 2862
    },
    {
      "epoch": 0.1698303476094436,
      "grad_norm": 2.126504421234131,
      "learning_rate": 1.8448457685209597e-05,
      "loss": 0.0169,
      "step": 2863
    },
    {
      "epoch": 0.16988966662712066,
      "grad_norm": 6.089209079742432,
      "learning_rate": 1.8447139467440023e-05,
      "loss": 0.0826,
      "step": 2864
    },
    {
      "epoch": 0.1699489856447977,
      "grad_norm": 2.550435781478882,
      "learning_rate": 1.844582124967045e-05,
      "loss": 0.0136,
      "step": 2865
    },
    {
      "epoch": 0.1700083046624748,
      "grad_norm": 2.142508029937744,
      "learning_rate": 1.844450303190087e-05,
      "loss": 0.0177,
      "step": 2866
    },
    {
      "epoch": 0.17006762368015185,
      "grad_norm": 0.08387661725282669,
      "learning_rate": 1.8443184814131297e-05,
      "loss": 0.0019,
      "step": 2867
    },
    {
      "epoch": 0.17012694269782894,
      "grad_norm": 2.06400990486145,
      "learning_rate": 1.844186659636172e-05,
      "loss": 0.0509,
      "step": 2868
    },
    {
      "epoch": 0.170186261715506,
      "grad_norm": 0.05719926208257675,
      "learning_rate": 1.8440548378592145e-05,
      "loss": 0.0012,
      "step": 2869
    },
    {
      "epoch": 0.17024558073318305,
      "grad_norm": 0.07772447913885117,
      "learning_rate": 1.843923016082257e-05,
      "loss": 0.001,
      "step": 2870
    },
    {
      "epoch": 0.17030489975086013,
      "grad_norm": 14.21430778503418,
      "learning_rate": 1.8437911943052994e-05,
      "loss": 1.0263,
      "step": 2871
    },
    {
      "epoch": 0.1703642187685372,
      "grad_norm": 6.140172958374023,
      "learning_rate": 1.843659372528342e-05,
      "loss": 0.0511,
      "step": 2872
    },
    {
      "epoch": 0.17042353778621425,
      "grad_norm": 2.939201593399048,
      "learning_rate": 1.8435275507513842e-05,
      "loss": 0.1425,
      "step": 2873
    },
    {
      "epoch": 0.17048285680389133,
      "grad_norm": 3.450399160385132,
      "learning_rate": 1.8433957289744268e-05,
      "loss": 0.0484,
      "step": 2874
    },
    {
      "epoch": 0.1705421758215684,
      "grad_norm": 10.058005332946777,
      "learning_rate": 1.843263907197469e-05,
      "loss": 0.4244,
      "step": 2875
    },
    {
      "epoch": 0.17060149483924547,
      "grad_norm": 0.8899358510971069,
      "learning_rate": 1.8431320854205116e-05,
      "loss": 0.0075,
      "step": 2876
    },
    {
      "epoch": 0.17066081385692253,
      "grad_norm": 0.061293572187423706,
      "learning_rate": 1.843000263643554e-05,
      "loss": 0.0012,
      "step": 2877
    },
    {
      "epoch": 0.17072013287459958,
      "grad_norm": 13.978028297424316,
      "learning_rate": 1.8428684418665965e-05,
      "loss": 0.6383,
      "step": 2878
    },
    {
      "epoch": 0.17077945189227667,
      "grad_norm": 16.666786193847656,
      "learning_rate": 1.842736620089639e-05,
      "loss": 0.3895,
      "step": 2879
    },
    {
      "epoch": 0.17083877090995372,
      "grad_norm": 3.911513328552246,
      "learning_rate": 1.8426047983126813e-05,
      "loss": 0.0958,
      "step": 2880
    },
    {
      "epoch": 0.1708980899276308,
      "grad_norm": 9.345977783203125,
      "learning_rate": 1.842472976535724e-05,
      "loss": 0.7057,
      "step": 2881
    },
    {
      "epoch": 0.17095740894530786,
      "grad_norm": 4.474913120269775,
      "learning_rate": 1.8423411547587665e-05,
      "loss": 0.1625,
      "step": 2882
    },
    {
      "epoch": 0.17101672796298492,
      "grad_norm": 3.6803271770477295,
      "learning_rate": 1.8422093329818087e-05,
      "loss": 0.0295,
      "step": 2883
    },
    {
      "epoch": 0.171076046980662,
      "grad_norm": 11.655462265014648,
      "learning_rate": 1.8420775112048513e-05,
      "loss": 0.7355,
      "step": 2884
    },
    {
      "epoch": 0.17113536599833906,
      "grad_norm": 18.54805564880371,
      "learning_rate": 1.8419456894278936e-05,
      "loss": 0.3251,
      "step": 2885
    },
    {
      "epoch": 0.17119468501601615,
      "grad_norm": 1.356032371520996,
      "learning_rate": 1.841813867650936e-05,
      "loss": 0.008,
      "step": 2886
    },
    {
      "epoch": 0.1712540040336932,
      "grad_norm": 0.24280112981796265,
      "learning_rate": 1.8416820458739787e-05,
      "loss": 0.0024,
      "step": 2887
    },
    {
      "epoch": 0.17131332305137026,
      "grad_norm": 2.313291072845459,
      "learning_rate": 1.841550224097021e-05,
      "loss": 0.0121,
      "step": 2888
    },
    {
      "epoch": 0.17137264206904734,
      "grad_norm": 1.2539138793945312,
      "learning_rate": 1.8414184023200636e-05,
      "loss": 0.0054,
      "step": 2889
    },
    {
      "epoch": 0.1714319610867244,
      "grad_norm": 1.6824002265930176,
      "learning_rate": 1.841286580543106e-05,
      "loss": 0.0107,
      "step": 2890
    },
    {
      "epoch": 0.17149128010440148,
      "grad_norm": 8.373640060424805,
      "learning_rate": 1.841154758766148e-05,
      "loss": 0.3934,
      "step": 2891
    },
    {
      "epoch": 0.17155059912207854,
      "grad_norm": 0.3168707489967346,
      "learning_rate": 1.8410229369891907e-05,
      "loss": 0.0044,
      "step": 2892
    },
    {
      "epoch": 0.1716099181397556,
      "grad_norm": 2.9001083374023438,
      "learning_rate": 1.8408911152122333e-05,
      "loss": 0.0124,
      "step": 2893
    },
    {
      "epoch": 0.17166923715743268,
      "grad_norm": 3.7953736782073975,
      "learning_rate": 1.8407592934352755e-05,
      "loss": 0.0208,
      "step": 2894
    },
    {
      "epoch": 0.17172855617510974,
      "grad_norm": 27.147615432739258,
      "learning_rate": 1.840627471658318e-05,
      "loss": 0.4473,
      "step": 2895
    },
    {
      "epoch": 0.17178787519278682,
      "grad_norm": 0.8871435523033142,
      "learning_rate": 1.8404956498813607e-05,
      "loss": 0.01,
      "step": 2896
    },
    {
      "epoch": 0.17184719421046388,
      "grad_norm": 11.896194458007812,
      "learning_rate": 1.840363828104403e-05,
      "loss": 0.2845,
      "step": 2897
    },
    {
      "epoch": 0.17190651322814093,
      "grad_norm": 18.36395835876465,
      "learning_rate": 1.8402320063274455e-05,
      "loss": 0.294,
      "step": 2898
    },
    {
      "epoch": 0.17196583224581802,
      "grad_norm": 5.099323272705078,
      "learning_rate": 1.840100184550488e-05,
      "loss": 0.1433,
      "step": 2899
    },
    {
      "epoch": 0.17202515126349507,
      "grad_norm": 7.719983100891113,
      "learning_rate": 1.8399683627735304e-05,
      "loss": 0.1514,
      "step": 2900
    },
    {
      "epoch": 0.17208447028117213,
      "grad_norm": 0.5742883682250977,
      "learning_rate": 1.839836540996573e-05,
      "loss": 0.0062,
      "step": 2901
    },
    {
      "epoch": 0.17214378929884921,
      "grad_norm": 7.473989486694336,
      "learning_rate": 1.8397047192196152e-05,
      "loss": 0.028,
      "step": 2902
    },
    {
      "epoch": 0.17220310831652627,
      "grad_norm": 15.604905128479004,
      "learning_rate": 1.8395728974426578e-05,
      "loss": 0.2089,
      "step": 2903
    },
    {
      "epoch": 0.17226242733420336,
      "grad_norm": 19.595867156982422,
      "learning_rate": 1.8394410756657e-05,
      "loss": 0.9326,
      "step": 2904
    },
    {
      "epoch": 0.1723217463518804,
      "grad_norm": 18.09929084777832,
      "learning_rate": 1.8393092538887426e-05,
      "loss": 1.3077,
      "step": 2905
    },
    {
      "epoch": 0.17238106536955747,
      "grad_norm": 8.39977741241455,
      "learning_rate": 1.839177432111785e-05,
      "loss": 0.3419,
      "step": 2906
    },
    {
      "epoch": 0.17244038438723455,
      "grad_norm": 0.038872044533491135,
      "learning_rate": 1.8390456103348275e-05,
      "loss": 0.0008,
      "step": 2907
    },
    {
      "epoch": 0.1724997034049116,
      "grad_norm": 0.03292107954621315,
      "learning_rate": 1.8389137885578697e-05,
      "loss": 0.0009,
      "step": 2908
    },
    {
      "epoch": 0.1725590224225887,
      "grad_norm": 27.273672103881836,
      "learning_rate": 1.8387819667809123e-05,
      "loss": 1.1753,
      "step": 2909
    },
    {
      "epoch": 0.17261834144026575,
      "grad_norm": 16.872600555419922,
      "learning_rate": 1.838650145003955e-05,
      "loss": 0.2912,
      "step": 2910
    },
    {
      "epoch": 0.1726776604579428,
      "grad_norm": 0.2886142134666443,
      "learning_rate": 1.838518323226997e-05,
      "loss": 0.0041,
      "step": 2911
    },
    {
      "epoch": 0.1727369794756199,
      "grad_norm": 10.787534713745117,
      "learning_rate": 1.8383865014500397e-05,
      "loss": 0.1718,
      "step": 2912
    },
    {
      "epoch": 0.17279629849329695,
      "grad_norm": 2.945895195007324,
      "learning_rate": 1.8382546796730823e-05,
      "loss": 0.0312,
      "step": 2913
    },
    {
      "epoch": 0.17285561751097403,
      "grad_norm": 6.184098243713379,
      "learning_rate": 1.8381228578961246e-05,
      "loss": 0.0755,
      "step": 2914
    },
    {
      "epoch": 0.1729149365286511,
      "grad_norm": 8.083976745605469,
      "learning_rate": 1.837991036119167e-05,
      "loss": 0.3185,
      "step": 2915
    },
    {
      "epoch": 0.17297425554632814,
      "grad_norm": 2.212860345840454,
      "learning_rate": 1.8378592143422094e-05,
      "loss": 0.0449,
      "step": 2916
    },
    {
      "epoch": 0.17303357456400523,
      "grad_norm": 9.669843673706055,
      "learning_rate": 1.837727392565252e-05,
      "loss": 0.0738,
      "step": 2917
    },
    {
      "epoch": 0.17309289358168228,
      "grad_norm": 14.354804039001465,
      "learning_rate": 1.8375955707882946e-05,
      "loss": 0.1212,
      "step": 2918
    },
    {
      "epoch": 0.17315221259935937,
      "grad_norm": 5.7802863121032715,
      "learning_rate": 1.8374637490113368e-05,
      "loss": 0.0245,
      "step": 2919
    },
    {
      "epoch": 0.17321153161703642,
      "grad_norm": 16.66920280456543,
      "learning_rate": 1.8373319272343794e-05,
      "loss": 0.0787,
      "step": 2920
    },
    {
      "epoch": 0.17327085063471348,
      "grad_norm": 3.3840253353118896,
      "learning_rate": 1.8372001054574217e-05,
      "loss": 0.0559,
      "step": 2921
    },
    {
      "epoch": 0.17333016965239056,
      "grad_norm": 16.244794845581055,
      "learning_rate": 1.8370682836804642e-05,
      "loss": 0.4407,
      "step": 2922
    },
    {
      "epoch": 0.17338948867006762,
      "grad_norm": 0.17513200640678406,
      "learning_rate": 1.8369364619035065e-05,
      "loss": 0.0016,
      "step": 2923
    },
    {
      "epoch": 0.17344880768774468,
      "grad_norm": 16.412757873535156,
      "learning_rate": 1.836804640126549e-05,
      "loss": 0.267,
      "step": 2924
    },
    {
      "epoch": 0.17350812670542176,
      "grad_norm": 35.758121490478516,
      "learning_rate": 1.8366728183495913e-05,
      "loss": 0.1315,
      "step": 2925
    },
    {
      "epoch": 0.17356744572309882,
      "grad_norm": 0.07093760371208191,
      "learning_rate": 1.836540996572634e-05,
      "loss": 0.0019,
      "step": 2926
    },
    {
      "epoch": 0.1736267647407759,
      "grad_norm": 0.37802550196647644,
      "learning_rate": 1.8364091747956765e-05,
      "loss": 0.0066,
      "step": 2927
    },
    {
      "epoch": 0.17368608375845296,
      "grad_norm": 39.96974563598633,
      "learning_rate": 1.8362773530187188e-05,
      "loss": 1.3828,
      "step": 2928
    },
    {
      "epoch": 0.17374540277613001,
      "grad_norm": 25.68241310119629,
      "learning_rate": 1.8361455312417613e-05,
      "loss": 1.198,
      "step": 2929
    },
    {
      "epoch": 0.1738047217938071,
      "grad_norm": 6.862629413604736,
      "learning_rate": 1.836013709464804e-05,
      "loss": 0.1698,
      "step": 2930
    },
    {
      "epoch": 0.17386404081148416,
      "grad_norm": 26.223648071289062,
      "learning_rate": 1.8358818876878462e-05,
      "loss": 1.296,
      "step": 2931
    },
    {
      "epoch": 0.17392335982916124,
      "grad_norm": 21.740962982177734,
      "learning_rate": 1.8357500659108888e-05,
      "loss": 0.8487,
      "step": 2932
    },
    {
      "epoch": 0.1739826788468383,
      "grad_norm": 10.956831932067871,
      "learning_rate": 1.835618244133931e-05,
      "loss": 0.2282,
      "step": 2933
    },
    {
      "epoch": 0.17404199786451535,
      "grad_norm": 0.4516242742538452,
      "learning_rate": 1.8354864223569736e-05,
      "loss": 0.0062,
      "step": 2934
    },
    {
      "epoch": 0.17410131688219244,
      "grad_norm": 16.97788429260254,
      "learning_rate": 1.835354600580016e-05,
      "loss": 0.1394,
      "step": 2935
    },
    {
      "epoch": 0.1741606358998695,
      "grad_norm": 17.260021209716797,
      "learning_rate": 1.8352227788030584e-05,
      "loss": 0.5835,
      "step": 2936
    },
    {
      "epoch": 0.17421995491754658,
      "grad_norm": 2.619493007659912,
      "learning_rate": 1.8350909570261007e-05,
      "loss": 0.0271,
      "step": 2937
    },
    {
      "epoch": 0.17427927393522363,
      "grad_norm": 0.9397082924842834,
      "learning_rate": 1.8349591352491433e-05,
      "loss": 0.0075,
      "step": 2938
    },
    {
      "epoch": 0.1743385929529007,
      "grad_norm": 2.5529463291168213,
      "learning_rate": 1.8348273134721855e-05,
      "loss": 0.0315,
      "step": 2939
    },
    {
      "epoch": 0.17439791197057777,
      "grad_norm": 10.706647872924805,
      "learning_rate": 1.834695491695228e-05,
      "loss": 0.1974,
      "step": 2940
    },
    {
      "epoch": 0.17445723098825483,
      "grad_norm": 12.98784065246582,
      "learning_rate": 1.8345636699182707e-05,
      "loss": 0.4808,
      "step": 2941
    },
    {
      "epoch": 0.17451655000593191,
      "grad_norm": 26.54852294921875,
      "learning_rate": 1.834431848141313e-05,
      "loss": 0.284,
      "step": 2942
    },
    {
      "epoch": 0.17457586902360897,
      "grad_norm": 0.14167974889278412,
      "learning_rate": 1.8343000263643555e-05,
      "loss": 0.0023,
      "step": 2943
    },
    {
      "epoch": 0.17463518804128603,
      "grad_norm": 7.1234235763549805,
      "learning_rate": 1.834168204587398e-05,
      "loss": 0.1933,
      "step": 2944
    },
    {
      "epoch": 0.1746945070589631,
      "grad_norm": 0.06497744470834732,
      "learning_rate": 1.8340363828104404e-05,
      "loss": 0.0015,
      "step": 2945
    },
    {
      "epoch": 0.17475382607664017,
      "grad_norm": 10.034181594848633,
      "learning_rate": 1.833904561033483e-05,
      "loss": 0.1563,
      "step": 2946
    },
    {
      "epoch": 0.17481314509431725,
      "grad_norm": 0.034646376967430115,
      "learning_rate": 1.8337727392565256e-05,
      "loss": 0.0009,
      "step": 2947
    },
    {
      "epoch": 0.1748724641119943,
      "grad_norm": 6.763491153717041,
      "learning_rate": 1.8336409174795678e-05,
      "loss": 0.0827,
      "step": 2948
    },
    {
      "epoch": 0.17493178312967136,
      "grad_norm": 0.15436650812625885,
      "learning_rate": 1.8335090957026104e-05,
      "loss": 0.002,
      "step": 2949
    },
    {
      "epoch": 0.17499110214734845,
      "grad_norm": 4.571141242980957,
      "learning_rate": 1.8333772739256526e-05,
      "loss": 0.041,
      "step": 2950
    },
    {
      "epoch": 0.1750504211650255,
      "grad_norm": 8.04759407043457,
      "learning_rate": 1.8332454521486952e-05,
      "loss": 0.1486,
      "step": 2951
    },
    {
      "epoch": 0.17510974018270256,
      "grad_norm": 3.4886386394500732,
      "learning_rate": 1.8331136303717375e-05,
      "loss": 0.0459,
      "step": 2952
    },
    {
      "epoch": 0.17516905920037965,
      "grad_norm": 0.1548352837562561,
      "learning_rate": 1.83298180859478e-05,
      "loss": 0.0034,
      "step": 2953
    },
    {
      "epoch": 0.1752283782180567,
      "grad_norm": 0.6652868390083313,
      "learning_rate": 1.8328499868178223e-05,
      "loss": 0.009,
      "step": 2954
    },
    {
      "epoch": 0.17528769723573379,
      "grad_norm": 9.412031173706055,
      "learning_rate": 1.832718165040865e-05,
      "loss": 0.2378,
      "step": 2955
    },
    {
      "epoch": 0.17534701625341084,
      "grad_norm": 1.9268243312835693,
      "learning_rate": 1.832586343263907e-05,
      "loss": 0.0111,
      "step": 2956
    },
    {
      "epoch": 0.1754063352710879,
      "grad_norm": 0.07170942425727844,
      "learning_rate": 1.8324545214869497e-05,
      "loss": 0.0016,
      "step": 2957
    },
    {
      "epoch": 0.17546565428876498,
      "grad_norm": 8.175857543945312,
      "learning_rate": 1.8323226997099923e-05,
      "loss": 0.4627,
      "step": 2958
    },
    {
      "epoch": 0.17552497330644204,
      "grad_norm": 3.7410264015197754,
      "learning_rate": 1.8321908779330346e-05,
      "loss": 0.0201,
      "step": 2959
    },
    {
      "epoch": 0.17558429232411912,
      "grad_norm": 28.900543212890625,
      "learning_rate": 1.8320590561560772e-05,
      "loss": 1.1572,
      "step": 2960
    },
    {
      "epoch": 0.17564361134179618,
      "grad_norm": 0.03943328186869621,
      "learning_rate": 1.8319272343791198e-05,
      "loss": 0.0009,
      "step": 2961
    },
    {
      "epoch": 0.17570293035947324,
      "grad_norm": 0.02836211770772934,
      "learning_rate": 1.831795412602162e-05,
      "loss": 0.0006,
      "step": 2962
    },
    {
      "epoch": 0.17576224937715032,
      "grad_norm": 0.874674379825592,
      "learning_rate": 1.8316635908252046e-05,
      "loss": 0.0081,
      "step": 2963
    },
    {
      "epoch": 0.17582156839482738,
      "grad_norm": 11.351701736450195,
      "learning_rate": 1.831531769048247e-05,
      "loss": 0.4184,
      "step": 2964
    },
    {
      "epoch": 0.17588088741250446,
      "grad_norm": 9.50793170928955,
      "learning_rate": 1.8313999472712894e-05,
      "loss": 0.1772,
      "step": 2965
    },
    {
      "epoch": 0.17594020643018152,
      "grad_norm": 0.40086039900779724,
      "learning_rate": 1.831268125494332e-05,
      "loss": 0.0059,
      "step": 2966
    },
    {
      "epoch": 0.17599952544785857,
      "grad_norm": 0.03715866804122925,
      "learning_rate": 1.8311363037173743e-05,
      "loss": 0.0007,
      "step": 2967
    },
    {
      "epoch": 0.17605884446553566,
      "grad_norm": 31.543642044067383,
      "learning_rate": 1.8310044819404165e-05,
      "loss": 0.3812,
      "step": 2968
    },
    {
      "epoch": 0.17611816348321271,
      "grad_norm": 0.2334275096654892,
      "learning_rate": 1.830872660163459e-05,
      "loss": 0.0024,
      "step": 2969
    },
    {
      "epoch": 0.1761774825008898,
      "grad_norm": 10.053565979003906,
      "learning_rate": 1.8307408383865014e-05,
      "loss": 0.227,
      "step": 2970
    },
    {
      "epoch": 0.17623680151856685,
      "grad_norm": 7.199882984161377,
      "learning_rate": 1.830609016609544e-05,
      "loss": 0.3674,
      "step": 2971
    },
    {
      "epoch": 0.1762961205362439,
      "grad_norm": 13.980989456176758,
      "learning_rate": 1.8304771948325865e-05,
      "loss": 0.1611,
      "step": 2972
    },
    {
      "epoch": 0.176355439553921,
      "grad_norm": 0.06157372519373894,
      "learning_rate": 1.8303453730556288e-05,
      "loss": 0.0017,
      "step": 2973
    },
    {
      "epoch": 0.17641475857159805,
      "grad_norm": 6.168224334716797,
      "learning_rate": 1.8302135512786714e-05,
      "loss": 0.2312,
      "step": 2974
    },
    {
      "epoch": 0.1764740775892751,
      "grad_norm": 23.6213321685791,
      "learning_rate": 1.830081729501714e-05,
      "loss": 0.4599,
      "step": 2975
    },
    {
      "epoch": 0.1765333966069522,
      "grad_norm": 4.171760559082031,
      "learning_rate": 1.8299499077247562e-05,
      "loss": 0.0096,
      "step": 2976
    },
    {
      "epoch": 0.17659271562462925,
      "grad_norm": 5.170891284942627,
      "learning_rate": 1.8298180859477988e-05,
      "loss": 0.1885,
      "step": 2977
    },
    {
      "epoch": 0.17665203464230633,
      "grad_norm": 5.932503700256348,
      "learning_rate": 1.8296862641708414e-05,
      "loss": 0.2125,
      "step": 2978
    },
    {
      "epoch": 0.1767113536599834,
      "grad_norm": 2.6497602462768555,
      "learning_rate": 1.8295544423938836e-05,
      "loss": 0.0198,
      "step": 2979
    },
    {
      "epoch": 0.17677067267766045,
      "grad_norm": 26.863037109375,
      "learning_rate": 1.8294226206169262e-05,
      "loss": 0.8885,
      "step": 2980
    },
    {
      "epoch": 0.17682999169533753,
      "grad_norm": 0.3040842115879059,
      "learning_rate": 1.8292907988399685e-05,
      "loss": 0.0017,
      "step": 2981
    },
    {
      "epoch": 0.17688931071301459,
      "grad_norm": 3.353341579437256,
      "learning_rate": 1.829158977063011e-05,
      "loss": 0.041,
      "step": 2982
    },
    {
      "epoch": 0.17694862973069167,
      "grad_norm": 0.6465622782707214,
      "learning_rate": 1.8290271552860533e-05,
      "loss": 0.003,
      "step": 2983
    },
    {
      "epoch": 0.17700794874836873,
      "grad_norm": 18.552745819091797,
      "learning_rate": 1.828895333509096e-05,
      "loss": 0.1162,
      "step": 2984
    },
    {
      "epoch": 0.17706726776604578,
      "grad_norm": 5.60910701751709,
      "learning_rate": 1.828763511732138e-05,
      "loss": 0.0811,
      "step": 2985
    },
    {
      "epoch": 0.17712658678372287,
      "grad_norm": 0.22945785522460938,
      "learning_rate": 1.8286316899551807e-05,
      "loss": 0.0028,
      "step": 2986
    },
    {
      "epoch": 0.17718590580139992,
      "grad_norm": 1.4709738492965698,
      "learning_rate": 1.828499868178223e-05,
      "loss": 0.0366,
      "step": 2987
    },
    {
      "epoch": 0.177245224819077,
      "grad_norm": 7.887404441833496,
      "learning_rate": 1.8283680464012656e-05,
      "loss": 0.2421,
      "step": 2988
    },
    {
      "epoch": 0.17730454383675406,
      "grad_norm": 1.0099865198135376,
      "learning_rate": 1.828236224624308e-05,
      "loss": 0.0107,
      "step": 2989
    },
    {
      "epoch": 0.17736386285443112,
      "grad_norm": 5.450201511383057,
      "learning_rate": 1.8281044028473504e-05,
      "loss": 0.2406,
      "step": 2990
    },
    {
      "epoch": 0.1774231818721082,
      "grad_norm": 8.975449562072754,
      "learning_rate": 1.827972581070393e-05,
      "loss": 0.126,
      "step": 2991
    },
    {
      "epoch": 0.17748250088978526,
      "grad_norm": 0.20388837158679962,
      "learning_rate": 1.8278407592934356e-05,
      "loss": 0.0029,
      "step": 2992
    },
    {
      "epoch": 0.17754181990746234,
      "grad_norm": 3.7458581924438477,
      "learning_rate": 1.827708937516478e-05,
      "loss": 0.0725,
      "step": 2993
    },
    {
      "epoch": 0.1776011389251394,
      "grad_norm": 0.09588733315467834,
      "learning_rate": 1.8275771157395204e-05,
      "loss": 0.0019,
      "step": 2994
    },
    {
      "epoch": 0.17766045794281646,
      "grad_norm": 24.2772274017334,
      "learning_rate": 1.827445293962563e-05,
      "loss": 0.8253,
      "step": 2995
    },
    {
      "epoch": 0.17771977696049354,
      "grad_norm": 0.037153229117393494,
      "learning_rate": 1.8273134721856053e-05,
      "loss": 0.001,
      "step": 2996
    },
    {
      "epoch": 0.1777790959781706,
      "grad_norm": 7.627035617828369,
      "learning_rate": 1.827181650408648e-05,
      "loss": 0.2129,
      "step": 2997
    },
    {
      "epoch": 0.17783841499584768,
      "grad_norm": 1.458943247795105,
      "learning_rate": 1.82704982863169e-05,
      "loss": 0.0143,
      "step": 2998
    },
    {
      "epoch": 0.17789773401352474,
      "grad_norm": 9.47538948059082,
      "learning_rate": 1.8269180068547327e-05,
      "loss": 0.14,
      "step": 2999
    },
    {
      "epoch": 0.1779570530312018,
      "grad_norm": 0.07351141422986984,
      "learning_rate": 1.826786185077775e-05,
      "loss": 0.0024,
      "step": 3000
    },
    {
      "epoch": 0.17801637204887888,
      "grad_norm": 14.856865882873535,
      "learning_rate": 1.8266543633008172e-05,
      "loss": 0.1945,
      "step": 3001
    },
    {
      "epoch": 0.17807569106655594,
      "grad_norm": 0.6979709267616272,
      "learning_rate": 1.8265225415238598e-05,
      "loss": 0.0105,
      "step": 3002
    },
    {
      "epoch": 0.178135010084233,
      "grad_norm": 3.0406501293182373,
      "learning_rate": 1.8263907197469024e-05,
      "loss": 0.0486,
      "step": 3003
    },
    {
      "epoch": 0.17819432910191008,
      "grad_norm": 10.730271339416504,
      "learning_rate": 1.8262588979699446e-05,
      "loss": 0.1434,
      "step": 3004
    },
    {
      "epoch": 0.17825364811958713,
      "grad_norm": 1.5232845544815063,
      "learning_rate": 1.8261270761929872e-05,
      "loss": 0.0115,
      "step": 3005
    },
    {
      "epoch": 0.17831296713726422,
      "grad_norm": 0.03258923068642616,
      "learning_rate": 1.8259952544160298e-05,
      "loss": 0.0007,
      "step": 3006
    },
    {
      "epoch": 0.17837228615494127,
      "grad_norm": 0.040022578090429306,
      "learning_rate": 1.825863432639072e-05,
      "loss": 0.0007,
      "step": 3007
    },
    {
      "epoch": 0.17843160517261833,
      "grad_norm": 32.89390563964844,
      "learning_rate": 1.8257316108621146e-05,
      "loss": 0.5619,
      "step": 3008
    },
    {
      "epoch": 0.1784909241902954,
      "grad_norm": 7.869905471801758,
      "learning_rate": 1.8255997890851572e-05,
      "loss": 0.1603,
      "step": 3009
    },
    {
      "epoch": 0.17855024320797247,
      "grad_norm": 0.057135988026857376,
      "learning_rate": 1.8254679673081995e-05,
      "loss": 0.0015,
      "step": 3010
    },
    {
      "epoch": 0.17860956222564955,
      "grad_norm": 0.23752275109291077,
      "learning_rate": 1.825336145531242e-05,
      "loss": 0.0043,
      "step": 3011
    },
    {
      "epoch": 0.1786688812433266,
      "grad_norm": 5.797214508056641,
      "learning_rate": 1.8252043237542843e-05,
      "loss": 0.1639,
      "step": 3012
    },
    {
      "epoch": 0.17872820026100367,
      "grad_norm": 17.928972244262695,
      "learning_rate": 1.825072501977327e-05,
      "loss": 0.5174,
      "step": 3013
    },
    {
      "epoch": 0.17878751927868075,
      "grad_norm": 18.296361923217773,
      "learning_rate": 1.824940680200369e-05,
      "loss": 0.6629,
      "step": 3014
    },
    {
      "epoch": 0.1788468382963578,
      "grad_norm": 0.15042012929916382,
      "learning_rate": 1.8248088584234117e-05,
      "loss": 0.0022,
      "step": 3015
    },
    {
      "epoch": 0.1789061573140349,
      "grad_norm": 0.9194031953811646,
      "learning_rate": 1.824677036646454e-05,
      "loss": 0.0112,
      "step": 3016
    },
    {
      "epoch": 0.17896547633171195,
      "grad_norm": 5.320298671722412,
      "learning_rate": 1.8245452148694966e-05,
      "loss": 0.0317,
      "step": 3017
    },
    {
      "epoch": 0.179024795349389,
      "grad_norm": 1.644760251045227,
      "learning_rate": 1.8244133930925388e-05,
      "loss": 0.0101,
      "step": 3018
    },
    {
      "epoch": 0.1790841143670661,
      "grad_norm": 1.4747912883758545,
      "learning_rate": 1.8242815713155814e-05,
      "loss": 0.0093,
      "step": 3019
    },
    {
      "epoch": 0.17914343338474314,
      "grad_norm": 39.93227005004883,
      "learning_rate": 1.824149749538624e-05,
      "loss": 0.402,
      "step": 3020
    },
    {
      "epoch": 0.17920275240242023,
      "grad_norm": 5.180537700653076,
      "learning_rate": 1.8240179277616662e-05,
      "loss": 0.1037,
      "step": 3021
    },
    {
      "epoch": 0.17926207142009729,
      "grad_norm": 0.24274124205112457,
      "learning_rate": 1.8238861059847088e-05,
      "loss": 0.0041,
      "step": 3022
    },
    {
      "epoch": 0.17932139043777434,
      "grad_norm": 1.3062862157821655,
      "learning_rate": 1.8237542842077514e-05,
      "loss": 0.0077,
      "step": 3023
    },
    {
      "epoch": 0.17938070945545143,
      "grad_norm": 0.13651011884212494,
      "learning_rate": 1.8236224624307937e-05,
      "loss": 0.003,
      "step": 3024
    },
    {
      "epoch": 0.17944002847312848,
      "grad_norm": 0.05107912793755531,
      "learning_rate": 1.8234906406538363e-05,
      "loss": 0.0011,
      "step": 3025
    },
    {
      "epoch": 0.17949934749080554,
      "grad_norm": 3.3109726905822754,
      "learning_rate": 1.823358818876879e-05,
      "loss": 0.0193,
      "step": 3026
    },
    {
      "epoch": 0.17955866650848262,
      "grad_norm": 4.6328535079956055,
      "learning_rate": 1.823226997099921e-05,
      "loss": 0.0827,
      "step": 3027
    },
    {
      "epoch": 0.17961798552615968,
      "grad_norm": 3.8238108158111572,
      "learning_rate": 1.8230951753229637e-05,
      "loss": 0.0827,
      "step": 3028
    },
    {
      "epoch": 0.17967730454383676,
      "grad_norm": 7.020920276641846,
      "learning_rate": 1.822963353546006e-05,
      "loss": 0.1313,
      "step": 3029
    },
    {
      "epoch": 0.17973662356151382,
      "grad_norm": 8.031659126281738,
      "learning_rate": 1.8228315317690485e-05,
      "loss": 0.1831,
      "step": 3030
    },
    {
      "epoch": 0.17979594257919088,
      "grad_norm": 0.007310525514185429,
      "learning_rate": 1.8226997099920908e-05,
      "loss": 0.0003,
      "step": 3031
    },
    {
      "epoch": 0.17985526159686796,
      "grad_norm": 48.9086799621582,
      "learning_rate": 1.8225678882151334e-05,
      "loss": 0.5363,
      "step": 3032
    },
    {
      "epoch": 0.17991458061454502,
      "grad_norm": 6.864792346954346,
      "learning_rate": 1.8224360664381756e-05,
      "loss": 0.0377,
      "step": 3033
    },
    {
      "epoch": 0.1799738996322221,
      "grad_norm": 0.07230240851640701,
      "learning_rate": 1.8223042446612182e-05,
      "loss": 0.0007,
      "step": 3034
    },
    {
      "epoch": 0.18003321864989916,
      "grad_norm": 0.024564700201153755,
      "learning_rate": 1.8221724228842604e-05,
      "loss": 0.0003,
      "step": 3035
    },
    {
      "epoch": 0.1800925376675762,
      "grad_norm": 1.6758865118026733,
      "learning_rate": 1.822040601107303e-05,
      "loss": 0.0094,
      "step": 3036
    },
    {
      "epoch": 0.1801518566852533,
      "grad_norm": 29.5509090423584,
      "learning_rate": 1.8219087793303456e-05,
      "loss": 0.3373,
      "step": 3037
    },
    {
      "epoch": 0.18021117570293035,
      "grad_norm": 9.707958221435547,
      "learning_rate": 1.821776957553388e-05,
      "loss": 0.0748,
      "step": 3038
    },
    {
      "epoch": 0.18027049472060744,
      "grad_norm": 1.670261263847351,
      "learning_rate": 1.8216451357764305e-05,
      "loss": 0.017,
      "step": 3039
    },
    {
      "epoch": 0.1803298137382845,
      "grad_norm": 2.0665464401245117,
      "learning_rate": 1.821513313999473e-05,
      "loss": 0.0122,
      "step": 3040
    },
    {
      "epoch": 0.18038913275596155,
      "grad_norm": 32.426631927490234,
      "learning_rate": 1.8213814922225153e-05,
      "loss": 2.483,
      "step": 3041
    },
    {
      "epoch": 0.18044845177363864,
      "grad_norm": 54.533905029296875,
      "learning_rate": 1.821249670445558e-05,
      "loss": 0.509,
      "step": 3042
    },
    {
      "epoch": 0.1805077707913157,
      "grad_norm": 5.881855487823486,
      "learning_rate": 1.8211178486686005e-05,
      "loss": 0.2559,
      "step": 3043
    },
    {
      "epoch": 0.18056708980899278,
      "grad_norm": 1.5875297784805298,
      "learning_rate": 1.8209860268916427e-05,
      "loss": 0.0052,
      "step": 3044
    },
    {
      "epoch": 0.18062640882666983,
      "grad_norm": 0.3208972215652466,
      "learning_rate": 1.820854205114685e-05,
      "loss": 0.0023,
      "step": 3045
    },
    {
      "epoch": 0.1806857278443469,
      "grad_norm": 0.5659656524658203,
      "learning_rate": 1.8207223833377276e-05,
      "loss": 0.0031,
      "step": 3046
    },
    {
      "epoch": 0.18074504686202397,
      "grad_norm": 8.03080940246582,
      "learning_rate": 1.8205905615607698e-05,
      "loss": 0.0607,
      "step": 3047
    },
    {
      "epoch": 0.18080436587970103,
      "grad_norm": 12.766935348510742,
      "learning_rate": 1.8204587397838124e-05,
      "loss": 0.0643,
      "step": 3048
    },
    {
      "epoch": 0.1808636848973781,
      "grad_norm": 0.07496665418148041,
      "learning_rate": 1.8203269180068546e-05,
      "loss": 0.001,
      "step": 3049
    },
    {
      "epoch": 0.18092300391505517,
      "grad_norm": 23.29660987854004,
      "learning_rate": 1.8201950962298972e-05,
      "loss": 0.2553,
      "step": 3050
    },
    {
      "epoch": 0.18098232293273223,
      "grad_norm": 20.98567008972168,
      "learning_rate": 1.8200632744529398e-05,
      "loss": 0.4167,
      "step": 3051
    },
    {
      "epoch": 0.1810416419504093,
      "grad_norm": 1.1865276098251343,
      "learning_rate": 1.819931452675982e-05,
      "loss": 0.0048,
      "step": 3052
    },
    {
      "epoch": 0.18110096096808637,
      "grad_norm": 45.61739730834961,
      "learning_rate": 1.8197996308990247e-05,
      "loss": 0.1328,
      "step": 3053
    },
    {
      "epoch": 0.18116027998576342,
      "grad_norm": 17.351030349731445,
      "learning_rate": 1.8196678091220672e-05,
      "loss": 1.1554,
      "step": 3054
    },
    {
      "epoch": 0.1812195990034405,
      "grad_norm": 0.00894036516547203,
      "learning_rate": 1.8195359873451095e-05,
      "loss": 0.0001,
      "step": 3055
    },
    {
      "epoch": 0.18127891802111756,
      "grad_norm": 5.129783630371094,
      "learning_rate": 1.819404165568152e-05,
      "loss": 0.0277,
      "step": 3056
    },
    {
      "epoch": 0.18133823703879465,
      "grad_norm": 0.018665123730897903,
      "learning_rate": 1.8192723437911947e-05,
      "loss": 0.0005,
      "step": 3057
    },
    {
      "epoch": 0.1813975560564717,
      "grad_norm": 12.991498947143555,
      "learning_rate": 1.819140522014237e-05,
      "loss": 0.1015,
      "step": 3058
    },
    {
      "epoch": 0.18145687507414876,
      "grad_norm": 6.49168586730957,
      "learning_rate": 1.8190087002372795e-05,
      "loss": 0.0781,
      "step": 3059
    },
    {
      "epoch": 0.18151619409182584,
      "grad_norm": 0.14577870070934296,
      "learning_rate": 1.8188768784603218e-05,
      "loss": 0.0024,
      "step": 3060
    },
    {
      "epoch": 0.1815755131095029,
      "grad_norm": 19.794662475585938,
      "learning_rate": 1.8187450566833643e-05,
      "loss": 0.4167,
      "step": 3061
    },
    {
      "epoch": 0.18163483212717998,
      "grad_norm": 1.1424161195755005,
      "learning_rate": 1.8186132349064066e-05,
      "loss": 0.0068,
      "step": 3062
    },
    {
      "epoch": 0.18169415114485704,
      "grad_norm": 12.532424926757812,
      "learning_rate": 1.8184814131294492e-05,
      "loss": 0.5194,
      "step": 3063
    },
    {
      "epoch": 0.1817534701625341,
      "grad_norm": 18.459728240966797,
      "learning_rate": 1.8183495913524914e-05,
      "loss": 0.4625,
      "step": 3064
    },
    {
      "epoch": 0.18181278918021118,
      "grad_norm": 26.35531997680664,
      "learning_rate": 1.818217769575534e-05,
      "loss": 2.0003,
      "step": 3065
    },
    {
      "epoch": 0.18187210819788824,
      "grad_norm": 0.008167000487446785,
      "learning_rate": 1.8180859477985763e-05,
      "loss": 0.0002,
      "step": 3066
    },
    {
      "epoch": 0.18193142721556532,
      "grad_norm": 7.9694342613220215,
      "learning_rate": 1.817954126021619e-05,
      "loss": 0.0869,
      "step": 3067
    },
    {
      "epoch": 0.18199074623324238,
      "grad_norm": 0.07471899688243866,
      "learning_rate": 1.8178223042446614e-05,
      "loss": 0.0014,
      "step": 3068
    },
    {
      "epoch": 0.18205006525091944,
      "grad_norm": 42.64321517944336,
      "learning_rate": 1.8176904824677037e-05,
      "loss": 0.785,
      "step": 3069
    },
    {
      "epoch": 0.18210938426859652,
      "grad_norm": 10.961688995361328,
      "learning_rate": 1.8175586606907463e-05,
      "loss": 0.1819,
      "step": 3070
    },
    {
      "epoch": 0.18216870328627358,
      "grad_norm": 3.295822858810425,
      "learning_rate": 1.817426838913789e-05,
      "loss": 0.063,
      "step": 3071
    },
    {
      "epoch": 0.18222802230395066,
      "grad_norm": 0.403158575296402,
      "learning_rate": 1.817295017136831e-05,
      "loss": 0.0038,
      "step": 3072
    },
    {
      "epoch": 0.18228734132162772,
      "grad_norm": 2.4652209281921387,
      "learning_rate": 1.8171631953598737e-05,
      "loss": 0.0259,
      "step": 3073
    },
    {
      "epoch": 0.18234666033930477,
      "grad_norm": 0.24660903215408325,
      "learning_rate": 1.8170313735829163e-05,
      "loss": 0.0046,
      "step": 3074
    },
    {
      "epoch": 0.18240597935698186,
      "grad_norm": 55.96663284301758,
      "learning_rate": 1.8168995518059585e-05,
      "loss": 0.3265,
      "step": 3075
    },
    {
      "epoch": 0.1824652983746589,
      "grad_norm": 21.10027313232422,
      "learning_rate": 1.816767730029001e-05,
      "loss": 0.7667,
      "step": 3076
    },
    {
      "epoch": 0.18252461739233597,
      "grad_norm": 0.006834839005023241,
      "learning_rate": 1.8166359082520434e-05,
      "loss": 0.0002,
      "step": 3077
    },
    {
      "epoch": 0.18258393641001305,
      "grad_norm": 11.061760902404785,
      "learning_rate": 1.816504086475086e-05,
      "loss": 0.3886,
      "step": 3078
    },
    {
      "epoch": 0.1826432554276901,
      "grad_norm": 7.289721965789795,
      "learning_rate": 1.8163722646981282e-05,
      "loss": 0.0225,
      "step": 3079
    },
    {
      "epoch": 0.1827025744453672,
      "grad_norm": 7.621547698974609,
      "learning_rate": 1.8162404429211705e-05,
      "loss": 0.154,
      "step": 3080
    },
    {
      "epoch": 0.18276189346304425,
      "grad_norm": 0.30190393328666687,
      "learning_rate": 1.816108621144213e-05,
      "loss": 0.002,
      "step": 3081
    },
    {
      "epoch": 0.1828212124807213,
      "grad_norm": 0.04217267408967018,
      "learning_rate": 1.8159767993672556e-05,
      "loss": 0.0007,
      "step": 3082
    },
    {
      "epoch": 0.1828805314983984,
      "grad_norm": 17.383926391601562,
      "learning_rate": 1.815844977590298e-05,
      "loss": 0.5416,
      "step": 3083
    },
    {
      "epoch": 0.18293985051607545,
      "grad_norm": 8.330094337463379,
      "learning_rate": 1.8157131558133405e-05,
      "loss": 0.1346,
      "step": 3084
    },
    {
      "epoch": 0.18299916953375253,
      "grad_norm": 0.019025083631277084,
      "learning_rate": 1.815581334036383e-05,
      "loss": 0.0006,
      "step": 3085
    },
    {
      "epoch": 0.1830584885514296,
      "grad_norm": 11.772575378417969,
      "learning_rate": 1.8154495122594253e-05,
      "loss": 0.2714,
      "step": 3086
    },
    {
      "epoch": 0.18311780756910664,
      "grad_norm": 25.38407325744629,
      "learning_rate": 1.815317690482468e-05,
      "loss": 0.1697,
      "step": 3087
    },
    {
      "epoch": 0.18317712658678373,
      "grad_norm": 0.2639903128147125,
      "learning_rate": 1.8151858687055105e-05,
      "loss": 0.0023,
      "step": 3088
    },
    {
      "epoch": 0.18323644560446078,
      "grad_norm": 13.08780574798584,
      "learning_rate": 1.8150540469285527e-05,
      "loss": 0.3693,
      "step": 3089
    },
    {
      "epoch": 0.18329576462213787,
      "grad_norm": 0.010232055559754372,
      "learning_rate": 1.8149222251515953e-05,
      "loss": 0.0002,
      "step": 3090
    },
    {
      "epoch": 0.18335508363981493,
      "grad_norm": 5.302673816680908,
      "learning_rate": 1.8147904033746376e-05,
      "loss": 0.076,
      "step": 3091
    },
    {
      "epoch": 0.18341440265749198,
      "grad_norm": 0.49546295404434204,
      "learning_rate": 1.8146585815976802e-05,
      "loss": 0.0069,
      "step": 3092
    },
    {
      "epoch": 0.18347372167516907,
      "grad_norm": 21.11577033996582,
      "learning_rate": 1.8145267598207224e-05,
      "loss": 0.1416,
      "step": 3093
    },
    {
      "epoch": 0.18353304069284612,
      "grad_norm": 0.09281943738460541,
      "learning_rate": 1.814394938043765e-05,
      "loss": 0.0011,
      "step": 3094
    },
    {
      "epoch": 0.1835923597105232,
      "grad_norm": 0.12283570319414139,
      "learning_rate": 1.8142631162668073e-05,
      "loss": 0.0022,
      "step": 3095
    },
    {
      "epoch": 0.18365167872820026,
      "grad_norm": 2.646247625350952,
      "learning_rate": 1.81413129448985e-05,
      "loss": 0.0379,
      "step": 3096
    },
    {
      "epoch": 0.18371099774587732,
      "grad_norm": 41.4331169128418,
      "learning_rate": 1.813999472712892e-05,
      "loss": 1.5276,
      "step": 3097
    },
    {
      "epoch": 0.1837703167635544,
      "grad_norm": 0.04047931730747223,
      "learning_rate": 1.8138676509359347e-05,
      "loss": 0.0013,
      "step": 3098
    },
    {
      "epoch": 0.18382963578123146,
      "grad_norm": 22.616697311401367,
      "learning_rate": 1.8137358291589773e-05,
      "loss": 0.3475,
      "step": 3099
    },
    {
      "epoch": 0.18388895479890854,
      "grad_norm": 0.29028570652008057,
      "learning_rate": 1.8136040073820195e-05,
      "loss": 0.0047,
      "step": 3100
    },
    {
      "epoch": 0.1839482738165856,
      "grad_norm": 0.022637424990534782,
      "learning_rate": 1.813472185605062e-05,
      "loss": 0.0007,
      "step": 3101
    },
    {
      "epoch": 0.18400759283426266,
      "grad_norm": 4.743149757385254,
      "learning_rate": 1.8133403638281047e-05,
      "loss": 0.0418,
      "step": 3102
    },
    {
      "epoch": 0.18406691185193974,
      "grad_norm": 21.17791748046875,
      "learning_rate": 1.813208542051147e-05,
      "loss": 0.1544,
      "step": 3103
    },
    {
      "epoch": 0.1841262308696168,
      "grad_norm": 36.804012298583984,
      "learning_rate": 1.8130767202741895e-05,
      "loss": 0.5591,
      "step": 3104
    },
    {
      "epoch": 0.18418554988729385,
      "grad_norm": 8.250218391418457,
      "learning_rate": 1.812944898497232e-05,
      "loss": 0.1398,
      "step": 3105
    },
    {
      "epoch": 0.18424486890497094,
      "grad_norm": 0.1143885999917984,
      "learning_rate": 1.8128130767202744e-05,
      "loss": 0.001,
      "step": 3106
    },
    {
      "epoch": 0.184304187922648,
      "grad_norm": 1.0886751413345337,
      "learning_rate": 1.812681254943317e-05,
      "loss": 0.0148,
      "step": 3107
    },
    {
      "epoch": 0.18436350694032508,
      "grad_norm": 20.547096252441406,
      "learning_rate": 1.8125494331663592e-05,
      "loss": 0.1233,
      "step": 3108
    },
    {
      "epoch": 0.18442282595800213,
      "grad_norm": 77.78324890136719,
      "learning_rate": 1.8124176113894018e-05,
      "loss": 2.4577,
      "step": 3109
    },
    {
      "epoch": 0.1844821449756792,
      "grad_norm": 5.248298168182373,
      "learning_rate": 1.812285789612444e-05,
      "loss": 0.13,
      "step": 3110
    },
    {
      "epoch": 0.18454146399335628,
      "grad_norm": 3.9341914653778076,
      "learning_rate": 1.8121539678354866e-05,
      "loss": 0.0254,
      "step": 3111
    },
    {
      "epoch": 0.18460078301103333,
      "grad_norm": 0.036924608051776886,
      "learning_rate": 1.812022146058529e-05,
      "loss": 0.0007,
      "step": 3112
    },
    {
      "epoch": 0.18466010202871042,
      "grad_norm": 13.785930633544922,
      "learning_rate": 1.8118903242815715e-05,
      "loss": 0.1632,
      "step": 3113
    },
    {
      "epoch": 0.18471942104638747,
      "grad_norm": 3.6571707725524902,
      "learning_rate": 1.8117585025046137e-05,
      "loss": 0.0208,
      "step": 3114
    },
    {
      "epoch": 0.18477874006406453,
      "grad_norm": 0.18358927965164185,
      "learning_rate": 1.8116266807276563e-05,
      "loss": 0.0025,
      "step": 3115
    },
    {
      "epoch": 0.1848380590817416,
      "grad_norm": 0.5533802509307861,
      "learning_rate": 1.811494858950699e-05,
      "loss": 0.0067,
      "step": 3116
    },
    {
      "epoch": 0.18489737809941867,
      "grad_norm": 0.033045798540115356,
      "learning_rate": 1.811363037173741e-05,
      "loss": 0.0007,
      "step": 3117
    },
    {
      "epoch": 0.18495669711709575,
      "grad_norm": 0.07731811702251434,
      "learning_rate": 1.8112312153967837e-05,
      "loss": 0.0018,
      "step": 3118
    },
    {
      "epoch": 0.1850160161347728,
      "grad_norm": 0.01992911845445633,
      "learning_rate": 1.8110993936198263e-05,
      "loss": 0.0004,
      "step": 3119
    },
    {
      "epoch": 0.18507533515244987,
      "grad_norm": 0.6697704195976257,
      "learning_rate": 1.8109675718428686e-05,
      "loss": 0.0055,
      "step": 3120
    },
    {
      "epoch": 0.18513465417012695,
      "grad_norm": 7.285688877105713,
      "learning_rate": 1.810835750065911e-05,
      "loss": 0.6159,
      "step": 3121
    },
    {
      "epoch": 0.185193973187804,
      "grad_norm": 1.0123015642166138,
      "learning_rate": 1.8107039282889537e-05,
      "loss": 0.0145,
      "step": 3122
    },
    {
      "epoch": 0.1852532922054811,
      "grad_norm": 0.8225608468055725,
      "learning_rate": 1.810572106511996e-05,
      "loss": 0.006,
      "step": 3123
    },
    {
      "epoch": 0.18531261122315815,
      "grad_norm": 2.5569324493408203,
      "learning_rate": 1.8104402847350382e-05,
      "loss": 0.0293,
      "step": 3124
    },
    {
      "epoch": 0.1853719302408352,
      "grad_norm": 9.058073997497559,
      "learning_rate": 1.810308462958081e-05,
      "loss": 0.0326,
      "step": 3125
    },
    {
      "epoch": 0.1854312492585123,
      "grad_norm": 2.270859956741333,
      "learning_rate": 1.810176641181123e-05,
      "loss": 0.0449,
      "step": 3126
    },
    {
      "epoch": 0.18549056827618934,
      "grad_norm": 0.009042182937264442,
      "learning_rate": 1.8100448194041657e-05,
      "loss": 0.0003,
      "step": 3127
    },
    {
      "epoch": 0.1855498872938664,
      "grad_norm": 18.80624771118164,
      "learning_rate": 1.809912997627208e-05,
      "loss": 0.4182,
      "step": 3128
    },
    {
      "epoch": 0.18560920631154348,
      "grad_norm": 3.0156359672546387,
      "learning_rate": 1.8097811758502505e-05,
      "loss": 0.032,
      "step": 3129
    },
    {
      "epoch": 0.18566852532922054,
      "grad_norm": 0.5486946105957031,
      "learning_rate": 1.809649354073293e-05,
      "loss": 0.0073,
      "step": 3130
    },
    {
      "epoch": 0.18572784434689762,
      "grad_norm": 4.320284366607666,
      "learning_rate": 1.8095175322963353e-05,
      "loss": 0.0549,
      "step": 3131
    },
    {
      "epoch": 0.18578716336457468,
      "grad_norm": 10.1475248336792,
      "learning_rate": 1.809385710519378e-05,
      "loss": 0.3137,
      "step": 3132
    },
    {
      "epoch": 0.18584648238225174,
      "grad_norm": 7.105892658233643,
      "learning_rate": 1.8092538887424205e-05,
      "loss": 0.2837,
      "step": 3133
    },
    {
      "epoch": 0.18590580139992882,
      "grad_norm": 0.03139251843094826,
      "learning_rate": 1.8091220669654628e-05,
      "loss": 0.0008,
      "step": 3134
    },
    {
      "epoch": 0.18596512041760588,
      "grad_norm": 0.5053955912590027,
      "learning_rate": 1.8089902451885054e-05,
      "loss": 0.005,
      "step": 3135
    },
    {
      "epoch": 0.18602443943528296,
      "grad_norm": 14.436129570007324,
      "learning_rate": 1.808858423411548e-05,
      "loss": 0.4014,
      "step": 3136
    },
    {
      "epoch": 0.18608375845296002,
      "grad_norm": 0.2847502827644348,
      "learning_rate": 1.8087266016345902e-05,
      "loss": 0.0043,
      "step": 3137
    },
    {
      "epoch": 0.18614307747063707,
      "grad_norm": 0.0028693689964711666,
      "learning_rate": 1.8085947798576328e-05,
      "loss": 0.0001,
      "step": 3138
    },
    {
      "epoch": 0.18620239648831416,
      "grad_norm": 4.894200801849365,
      "learning_rate": 1.808462958080675e-05,
      "loss": 0.0992,
      "step": 3139
    },
    {
      "epoch": 0.18626171550599122,
      "grad_norm": 7.3197021484375,
      "learning_rate": 1.8083311363037176e-05,
      "loss": 0.093,
      "step": 3140
    },
    {
      "epoch": 0.1863210345236683,
      "grad_norm": 0.61469566822052,
      "learning_rate": 1.80819931452676e-05,
      "loss": 0.0088,
      "step": 3141
    },
    {
      "epoch": 0.18638035354134536,
      "grad_norm": 1.211839199066162,
      "learning_rate": 1.8080674927498025e-05,
      "loss": 0.0073,
      "step": 3142
    },
    {
      "epoch": 0.1864396725590224,
      "grad_norm": 43.50532913208008,
      "learning_rate": 1.8079356709728447e-05,
      "loss": 1.4855,
      "step": 3143
    },
    {
      "epoch": 0.1864989915766995,
      "grad_norm": 0.10194773226976395,
      "learning_rate": 1.8078038491958873e-05,
      "loss": 0.002,
      "step": 3144
    },
    {
      "epoch": 0.18655831059437655,
      "grad_norm": 0.050717178732156754,
      "learning_rate": 1.8076720274189295e-05,
      "loss": 0.0012,
      "step": 3145
    },
    {
      "epoch": 0.18661762961205364,
      "grad_norm": 10.488219261169434,
      "learning_rate": 1.807540205641972e-05,
      "loss": 0.0926,
      "step": 3146
    },
    {
      "epoch": 0.1866769486297307,
      "grad_norm": 4.650278568267822,
      "learning_rate": 1.8074083838650147e-05,
      "loss": 0.065,
      "step": 3147
    },
    {
      "epoch": 0.18673626764740775,
      "grad_norm": 32.88347244262695,
      "learning_rate": 1.807276562088057e-05,
      "loss": 0.9781,
      "step": 3148
    },
    {
      "epoch": 0.18679558666508483,
      "grad_norm": 0.11202514171600342,
      "learning_rate": 1.8071447403110996e-05,
      "loss": 0.0019,
      "step": 3149
    },
    {
      "epoch": 0.1868549056827619,
      "grad_norm": 6.29433536529541,
      "learning_rate": 1.807012918534142e-05,
      "loss": 0.0314,
      "step": 3150
    },
    {
      "epoch": 0.18691422470043897,
      "grad_norm": 0.005313957575708628,
      "learning_rate": 1.8068810967571844e-05,
      "loss": 0.0002,
      "step": 3151
    },
    {
      "epoch": 0.18697354371811603,
      "grad_norm": 28.162260055541992,
      "learning_rate": 1.806749274980227e-05,
      "loss": 0.4136,
      "step": 3152
    },
    {
      "epoch": 0.1870328627357931,
      "grad_norm": 0.043954476714134216,
      "learning_rate": 1.8066174532032696e-05,
      "loss": 0.0011,
      "step": 3153
    },
    {
      "epoch": 0.18709218175347017,
      "grad_norm": 20.95368003845215,
      "learning_rate": 1.8064856314263118e-05,
      "loss": 0.4068,
      "step": 3154
    },
    {
      "epoch": 0.18715150077114723,
      "grad_norm": 4.842772960662842,
      "learning_rate": 1.8063538096493544e-05,
      "loss": 0.0846,
      "step": 3155
    },
    {
      "epoch": 0.18721081978882428,
      "grad_norm": 19.733423233032227,
      "learning_rate": 1.8062219878723967e-05,
      "loss": 0.3008,
      "step": 3156
    },
    {
      "epoch": 0.18727013880650137,
      "grad_norm": 0.011000256054103374,
      "learning_rate": 1.806090166095439e-05,
      "loss": 0.0002,
      "step": 3157
    },
    {
      "epoch": 0.18732945782417842,
      "grad_norm": 4.5226731300354,
      "learning_rate": 1.8059583443184815e-05,
      "loss": 0.0184,
      "step": 3158
    },
    {
      "epoch": 0.1873887768418555,
      "grad_norm": 0.04761524498462677,
      "learning_rate": 1.8058265225415237e-05,
      "loss": 0.0012,
      "step": 3159
    },
    {
      "epoch": 0.18744809585953257,
      "grad_norm": 2.398362398147583,
      "learning_rate": 1.8056947007645663e-05,
      "loss": 0.017,
      "step": 3160
    },
    {
      "epoch": 0.18750741487720962,
      "grad_norm": 13.542309761047363,
      "learning_rate": 1.805562878987609e-05,
      "loss": 1.112,
      "step": 3161
    },
    {
      "epoch": 0.1875667338948867,
      "grad_norm": 1.4392563104629517,
      "learning_rate": 1.8054310572106512e-05,
      "loss": 0.01,
      "step": 3162
    },
    {
      "epoch": 0.18762605291256376,
      "grad_norm": 4.065104007720947,
      "learning_rate": 1.8052992354336938e-05,
      "loss": 0.0673,
      "step": 3163
    },
    {
      "epoch": 0.18768537193024085,
      "grad_norm": 0.011388425715267658,
      "learning_rate": 1.8051674136567364e-05,
      "loss": 0.0002,
      "step": 3164
    },
    {
      "epoch": 0.1877446909479179,
      "grad_norm": 15.529675483703613,
      "learning_rate": 1.8050355918797786e-05,
      "loss": 0.299,
      "step": 3165
    },
    {
      "epoch": 0.18780400996559496,
      "grad_norm": 8.392434120178223,
      "learning_rate": 1.8049037701028212e-05,
      "loss": 0.3256,
      "step": 3166
    },
    {
      "epoch": 0.18786332898327204,
      "grad_norm": 25.61981964111328,
      "learning_rate": 1.8047719483258638e-05,
      "loss": 0.6872,
      "step": 3167
    },
    {
      "epoch": 0.1879226480009491,
      "grad_norm": 0.02633240818977356,
      "learning_rate": 1.804640126548906e-05,
      "loss": 0.0005,
      "step": 3168
    },
    {
      "epoch": 0.18798196701862618,
      "grad_norm": 23.901063919067383,
      "learning_rate": 1.8045083047719486e-05,
      "loss": 0.4056,
      "step": 3169
    },
    {
      "epoch": 0.18804128603630324,
      "grad_norm": 1.7935099601745605,
      "learning_rate": 1.804376482994991e-05,
      "loss": 0.0116,
      "step": 3170
    },
    {
      "epoch": 0.1881006050539803,
      "grad_norm": 70.95045471191406,
      "learning_rate": 1.8042446612180335e-05,
      "loss": 0.1731,
      "step": 3171
    },
    {
      "epoch": 0.18815992407165738,
      "grad_norm": 0.020405106246471405,
      "learning_rate": 1.8041128394410757e-05,
      "loss": 0.0005,
      "step": 3172
    },
    {
      "epoch": 0.18821924308933444,
      "grad_norm": 7.184200286865234,
      "learning_rate": 1.8039810176641183e-05,
      "loss": 0.0659,
      "step": 3173
    },
    {
      "epoch": 0.18827856210701152,
      "grad_norm": 0.05576006695628166,
      "learning_rate": 1.8038491958871605e-05,
      "loss": 0.0012,
      "step": 3174
    },
    {
      "epoch": 0.18833788112468858,
      "grad_norm": 8.507064819335938,
      "learning_rate": 1.803717374110203e-05,
      "loss": 0.3888,
      "step": 3175
    },
    {
      "epoch": 0.18839720014236563,
      "grad_norm": 0.05701259896159172,
      "learning_rate": 1.8035855523332454e-05,
      "loss": 0.0009,
      "step": 3176
    },
    {
      "epoch": 0.18845651916004272,
      "grad_norm": 21.467327117919922,
      "learning_rate": 1.803453730556288e-05,
      "loss": 1.6042,
      "step": 3177
    },
    {
      "epoch": 0.18851583817771977,
      "grad_norm": 39.38412857055664,
      "learning_rate": 1.8033219087793306e-05,
      "loss": 1.6896,
      "step": 3178
    },
    {
      "epoch": 0.18857515719539683,
      "grad_norm": 0.19004228711128235,
      "learning_rate": 1.8031900870023728e-05,
      "loss": 0.0028,
      "step": 3179
    },
    {
      "epoch": 0.18863447621307391,
      "grad_norm": 10.3740234375,
      "learning_rate": 1.8030582652254154e-05,
      "loss": 0.5915,
      "step": 3180
    },
    {
      "epoch": 0.18869379523075097,
      "grad_norm": 7.202060222625732,
      "learning_rate": 1.802926443448458e-05,
      "loss": 0.026,
      "step": 3181
    },
    {
      "epoch": 0.18875311424842806,
      "grad_norm": 0.022241443395614624,
      "learning_rate": 1.8027946216715002e-05,
      "loss": 0.0005,
      "step": 3182
    },
    {
      "epoch": 0.1888124332661051,
      "grad_norm": 18.45274543762207,
      "learning_rate": 1.8026627998945428e-05,
      "loss": 0.5017,
      "step": 3183
    },
    {
      "epoch": 0.18887175228378217,
      "grad_norm": 16.390871047973633,
      "learning_rate": 1.8025309781175854e-05,
      "loss": 0.6672,
      "step": 3184
    },
    {
      "epoch": 0.18893107130145925,
      "grad_norm": 1.0035449266433716,
      "learning_rate": 1.8023991563406277e-05,
      "loss": 0.027,
      "step": 3185
    },
    {
      "epoch": 0.1889903903191363,
      "grad_norm": 0.06839560717344284,
      "learning_rate": 1.8022673345636702e-05,
      "loss": 0.0018,
      "step": 3186
    },
    {
      "epoch": 0.1890497093368134,
      "grad_norm": 4.4421305656433105,
      "learning_rate": 1.8021355127867125e-05,
      "loss": 0.1456,
      "step": 3187
    },
    {
      "epoch": 0.18910902835449045,
      "grad_norm": 11.621294975280762,
      "learning_rate": 1.802003691009755e-05,
      "loss": 0.4106,
      "step": 3188
    },
    {
      "epoch": 0.1891683473721675,
      "grad_norm": 19.036273956298828,
      "learning_rate": 1.8018718692327973e-05,
      "loss": 0.3751,
      "step": 3189
    },
    {
      "epoch": 0.1892276663898446,
      "grad_norm": 10.54842472076416,
      "learning_rate": 1.80174004745584e-05,
      "loss": 0.9153,
      "step": 3190
    },
    {
      "epoch": 0.18928698540752165,
      "grad_norm": 1.4622411727905273,
      "learning_rate": 1.801608225678882e-05,
      "loss": 0.0066,
      "step": 3191
    },
    {
      "epoch": 0.18934630442519873,
      "grad_norm": 0.014497516676783562,
      "learning_rate": 1.8014764039019248e-05,
      "loss": 0.0004,
      "step": 3192
    },
    {
      "epoch": 0.1894056234428758,
      "grad_norm": 0.7419278025627136,
      "learning_rate": 1.801344582124967e-05,
      "loss": 0.0087,
      "step": 3193
    },
    {
      "epoch": 0.18946494246055284,
      "grad_norm": 3.354339122772217,
      "learning_rate": 1.8012127603480096e-05,
      "loss": 0.0377,
      "step": 3194
    },
    {
      "epoch": 0.18952426147822993,
      "grad_norm": 0.31832820177078247,
      "learning_rate": 1.8010809385710522e-05,
      "loss": 0.0023,
      "step": 3195
    },
    {
      "epoch": 0.18958358049590698,
      "grad_norm": 0.22836138308048248,
      "learning_rate": 1.8009491167940944e-05,
      "loss": 0.0043,
      "step": 3196
    },
    {
      "epoch": 0.18964289951358407,
      "grad_norm": 2.076568365097046,
      "learning_rate": 1.800817295017137e-05,
      "loss": 0.0212,
      "step": 3197
    },
    {
      "epoch": 0.18970221853126112,
      "grad_norm": 13.38390064239502,
      "learning_rate": 1.8006854732401796e-05,
      "loss": 0.1415,
      "step": 3198
    },
    {
      "epoch": 0.18976153754893818,
      "grad_norm": 25.111778259277344,
      "learning_rate": 1.800553651463222e-05,
      "loss": 0.2863,
      "step": 3199
    },
    {
      "epoch": 0.18982085656661526,
      "grad_norm": 0.6183156371116638,
      "learning_rate": 1.8004218296862644e-05,
      "loss": 0.0072,
      "step": 3200
    },
    {
      "epoch": 0.18988017558429232,
      "grad_norm": 0.31021803617477417,
      "learning_rate": 1.8002900079093067e-05,
      "loss": 0.0036,
      "step": 3201
    },
    {
      "epoch": 0.1899394946019694,
      "grad_norm": 2.051494598388672,
      "learning_rate": 1.8001581861323493e-05,
      "loss": 0.0172,
      "step": 3202
    },
    {
      "epoch": 0.18999881361964646,
      "grad_norm": 11.589944839477539,
      "learning_rate": 1.8000263643553915e-05,
      "loss": 0.1482,
      "step": 3203
    },
    {
      "epoch": 0.19005813263732352,
      "grad_norm": 4.166213035583496,
      "learning_rate": 1.799894542578434e-05,
      "loss": 0.1715,
      "step": 3204
    },
    {
      "epoch": 0.1901174516550006,
      "grad_norm": 4.598721981048584,
      "learning_rate": 1.7997627208014764e-05,
      "loss": 0.0457,
      "step": 3205
    },
    {
      "epoch": 0.19017677067267766,
      "grad_norm": 9.211336135864258,
      "learning_rate": 1.799630899024519e-05,
      "loss": 0.1675,
      "step": 3206
    },
    {
      "epoch": 0.19023608969035471,
      "grad_norm": 1.7286455631256104,
      "learning_rate": 1.7994990772475612e-05,
      "loss": 0.0038,
      "step": 3207
    },
    {
      "epoch": 0.1902954087080318,
      "grad_norm": 0.40196526050567627,
      "learning_rate": 1.7993672554706038e-05,
      "loss": 0.0063,
      "step": 3208
    },
    {
      "epoch": 0.19035472772570886,
      "grad_norm": 0.06302446126937866,
      "learning_rate": 1.7992354336936464e-05,
      "loss": 0.001,
      "step": 3209
    },
    {
      "epoch": 0.19041404674338594,
      "grad_norm": 16.37450408935547,
      "learning_rate": 1.7991036119166886e-05,
      "loss": 0.2951,
      "step": 3210
    },
    {
      "epoch": 0.190473365761063,
      "grad_norm": 16.190738677978516,
      "learning_rate": 1.7989717901397312e-05,
      "loss": 1.3642,
      "step": 3211
    },
    {
      "epoch": 0.19053268477874005,
      "grad_norm": 0.05643157660961151,
      "learning_rate": 1.7988399683627738e-05,
      "loss": 0.0014,
      "step": 3212
    },
    {
      "epoch": 0.19059200379641714,
      "grad_norm": 7.9836201667785645,
      "learning_rate": 1.798708146585816e-05,
      "loss": 0.0772,
      "step": 3213
    },
    {
      "epoch": 0.1906513228140942,
      "grad_norm": 3.0243518352508545,
      "learning_rate": 1.7985763248088586e-05,
      "loss": 0.291,
      "step": 3214
    },
    {
      "epoch": 0.19071064183177128,
      "grad_norm": 4.6888108253479,
      "learning_rate": 1.7984445030319012e-05,
      "loss": 0.1455,
      "step": 3215
    },
    {
      "epoch": 0.19076996084944833,
      "grad_norm": 4.990100860595703,
      "learning_rate": 1.7983126812549435e-05,
      "loss": 0.0342,
      "step": 3216
    },
    {
      "epoch": 0.1908292798671254,
      "grad_norm": 23.428205490112305,
      "learning_rate": 1.798180859477986e-05,
      "loss": 0.3087,
      "step": 3217
    },
    {
      "epoch": 0.19088859888480247,
      "grad_norm": 7.672694206237793,
      "learning_rate": 1.7980490377010283e-05,
      "loss": 0.0689,
      "step": 3218
    },
    {
      "epoch": 0.19094791790247953,
      "grad_norm": 13.969462394714355,
      "learning_rate": 1.797917215924071e-05,
      "loss": 0.1443,
      "step": 3219
    },
    {
      "epoch": 0.19100723692015661,
      "grad_norm": 0.2267874777317047,
      "learning_rate": 1.797785394147113e-05,
      "loss": 0.0024,
      "step": 3220
    },
    {
      "epoch": 0.19106655593783367,
      "grad_norm": 0.7534247040748596,
      "learning_rate": 1.7976535723701557e-05,
      "loss": 0.0053,
      "step": 3221
    },
    {
      "epoch": 0.19112587495551073,
      "grad_norm": 9.7234525680542,
      "learning_rate": 1.797521750593198e-05,
      "loss": 0.1211,
      "step": 3222
    },
    {
      "epoch": 0.1911851939731878,
      "grad_norm": 13.356449127197266,
      "learning_rate": 1.7973899288162406e-05,
      "loss": 0.3008,
      "step": 3223
    },
    {
      "epoch": 0.19124451299086487,
      "grad_norm": 26.06544303894043,
      "learning_rate": 1.7972581070392828e-05,
      "loss": 0.4609,
      "step": 3224
    },
    {
      "epoch": 0.19130383200854195,
      "grad_norm": 0.15241748094558716,
      "learning_rate": 1.7971262852623254e-05,
      "loss": 0.0017,
      "step": 3225
    },
    {
      "epoch": 0.191363151026219,
      "grad_norm": 5.477750301361084,
      "learning_rate": 1.796994463485368e-05,
      "loss": 0.6611,
      "step": 3226
    },
    {
      "epoch": 0.19142247004389606,
      "grad_norm": 6.491147041320801,
      "learning_rate": 1.7968626417084103e-05,
      "loss": 0.0662,
      "step": 3227
    },
    {
      "epoch": 0.19148178906157315,
      "grad_norm": 12.708555221557617,
      "learning_rate": 1.796730819931453e-05,
      "loss": 0.3429,
      "step": 3228
    },
    {
      "epoch": 0.1915411080792502,
      "grad_norm": 7.877652168273926,
      "learning_rate": 1.7965989981544954e-05,
      "loss": 0.0989,
      "step": 3229
    },
    {
      "epoch": 0.19160042709692726,
      "grad_norm": 0.225264772772789,
      "learning_rate": 1.7964671763775377e-05,
      "loss": 0.004,
      "step": 3230
    },
    {
      "epoch": 0.19165974611460435,
      "grad_norm": 3.856689453125,
      "learning_rate": 1.7963353546005803e-05,
      "loss": 0.0131,
      "step": 3231
    },
    {
      "epoch": 0.1917190651322814,
      "grad_norm": 13.300287246704102,
      "learning_rate": 1.796203532823623e-05,
      "loss": 0.0656,
      "step": 3232
    },
    {
      "epoch": 0.1917783841499585,
      "grad_norm": 7.821841716766357,
      "learning_rate": 1.796071711046665e-05,
      "loss": 0.1263,
      "step": 3233
    },
    {
      "epoch": 0.19183770316763554,
      "grad_norm": 0.13609901070594788,
      "learning_rate": 1.7959398892697077e-05,
      "loss": 0.0015,
      "step": 3234
    },
    {
      "epoch": 0.1918970221853126,
      "grad_norm": 19.304798126220703,
      "learning_rate": 1.79580806749275e-05,
      "loss": 0.2383,
      "step": 3235
    },
    {
      "epoch": 0.19195634120298968,
      "grad_norm": 37.49568176269531,
      "learning_rate": 1.7956762457157922e-05,
      "loss": 0.1269,
      "step": 3236
    },
    {
      "epoch": 0.19201566022066674,
      "grad_norm": 25.394180297851562,
      "learning_rate": 1.7955444239388348e-05,
      "loss": 0.586,
      "step": 3237
    },
    {
      "epoch": 0.19207497923834382,
      "grad_norm": 24.215490341186523,
      "learning_rate": 1.795412602161877e-05,
      "loss": 1.2892,
      "step": 3238
    },
    {
      "epoch": 0.19213429825602088,
      "grad_norm": 0.895746648311615,
      "learning_rate": 1.7952807803849196e-05,
      "loss": 0.0128,
      "step": 3239
    },
    {
      "epoch": 0.19219361727369794,
      "grad_norm": 1.9780514240264893,
      "learning_rate": 1.7951489586079622e-05,
      "loss": 0.0166,
      "step": 3240
    },
    {
      "epoch": 0.19225293629137502,
      "grad_norm": 0.06938763707876205,
      "learning_rate": 1.7950171368310045e-05,
      "loss": 0.0021,
      "step": 3241
    },
    {
      "epoch": 0.19231225530905208,
      "grad_norm": 0.04325404018163681,
      "learning_rate": 1.794885315054047e-05,
      "loss": 0.0012,
      "step": 3242
    },
    {
      "epoch": 0.19237157432672916,
      "grad_norm": 0.058611299842596054,
      "learning_rate": 1.7947534932770896e-05,
      "loss": 0.0013,
      "step": 3243
    },
    {
      "epoch": 0.19243089334440622,
      "grad_norm": 7.448526859283447,
      "learning_rate": 1.794621671500132e-05,
      "loss": 0.098,
      "step": 3244
    },
    {
      "epoch": 0.19249021236208327,
      "grad_norm": 9.749218940734863,
      "learning_rate": 1.7944898497231745e-05,
      "loss": 0.2475,
      "step": 3245
    },
    {
      "epoch": 0.19254953137976036,
      "grad_norm": 27.3529052734375,
      "learning_rate": 1.794358027946217e-05,
      "loss": 1.0468,
      "step": 3246
    },
    {
      "epoch": 0.19260885039743741,
      "grad_norm": 0.1892605423927307,
      "learning_rate": 1.7942262061692593e-05,
      "loss": 0.0018,
      "step": 3247
    },
    {
      "epoch": 0.1926681694151145,
      "grad_norm": 6.870548248291016,
      "learning_rate": 1.794094384392302e-05,
      "loss": 0.2002,
      "step": 3248
    },
    {
      "epoch": 0.19272748843279155,
      "grad_norm": 2.6911439895629883,
      "learning_rate": 1.793962562615344e-05,
      "loss": 0.0218,
      "step": 3249
    },
    {
      "epoch": 0.1927868074504686,
      "grad_norm": 24.12870979309082,
      "learning_rate": 1.7938307408383867e-05,
      "loss": 0.4285,
      "step": 3250
    },
    {
      "epoch": 0.1928461264681457,
      "grad_norm": 7.7533392906188965,
      "learning_rate": 1.793698919061429e-05,
      "loss": 0.1055,
      "step": 3251
    },
    {
      "epoch": 0.19290544548582275,
      "grad_norm": 9.305676460266113,
      "learning_rate": 1.7935670972844716e-05,
      "loss": 0.3998,
      "step": 3252
    },
    {
      "epoch": 0.1929647645034998,
      "grad_norm": 23.187314987182617,
      "learning_rate": 1.7934352755075138e-05,
      "loss": 0.2567,
      "step": 3253
    },
    {
      "epoch": 0.1930240835211769,
      "grad_norm": 17.095149993896484,
      "learning_rate": 1.7933034537305564e-05,
      "loss": 0.7313,
      "step": 3254
    },
    {
      "epoch": 0.19308340253885395,
      "grad_norm": 3.324972152709961,
      "learning_rate": 1.7931716319535987e-05,
      "loss": 0.2328,
      "step": 3255
    },
    {
      "epoch": 0.19314272155653103,
      "grad_norm": 11.32522201538086,
      "learning_rate": 1.7930398101766412e-05,
      "loss": 0.9415,
      "step": 3256
    },
    {
      "epoch": 0.1932020405742081,
      "grad_norm": 13.097846031188965,
      "learning_rate": 1.792907988399684e-05,
      "loss": 0.9492,
      "step": 3257
    },
    {
      "epoch": 0.19326135959188515,
      "grad_norm": 0.056193757802248,
      "learning_rate": 1.792776166622726e-05,
      "loss": 0.0008,
      "step": 3258
    },
    {
      "epoch": 0.19332067860956223,
      "grad_norm": 11.52550983428955,
      "learning_rate": 1.7926443448457687e-05,
      "loss": 0.1428,
      "step": 3259
    },
    {
      "epoch": 0.1933799976272393,
      "grad_norm": 8.121480941772461,
      "learning_rate": 1.7925125230688113e-05,
      "loss": 0.076,
      "step": 3260
    },
    {
      "epoch": 0.19343931664491637,
      "grad_norm": 0.8401545286178589,
      "learning_rate": 1.7923807012918535e-05,
      "loss": 0.0073,
      "step": 3261
    },
    {
      "epoch": 0.19349863566259343,
      "grad_norm": 0.6163913607597351,
      "learning_rate": 1.792248879514896e-05,
      "loss": 0.0059,
      "step": 3262
    },
    {
      "epoch": 0.19355795468027048,
      "grad_norm": 0.1014406755566597,
      "learning_rate": 1.7921170577379387e-05,
      "loss": 0.0016,
      "step": 3263
    },
    {
      "epoch": 0.19361727369794757,
      "grad_norm": 0.07032661885023117,
      "learning_rate": 1.791985235960981e-05,
      "loss": 0.0023,
      "step": 3264
    },
    {
      "epoch": 0.19367659271562462,
      "grad_norm": 0.05944683775305748,
      "learning_rate": 1.7918534141840235e-05,
      "loss": 0.0019,
      "step": 3265
    },
    {
      "epoch": 0.1937359117333017,
      "grad_norm": 33.81626892089844,
      "learning_rate": 1.7917215924070658e-05,
      "loss": 0.1809,
      "step": 3266
    },
    {
      "epoch": 0.19379523075097876,
      "grad_norm": 0.07797378301620483,
      "learning_rate": 1.7915897706301084e-05,
      "loss": 0.0014,
      "step": 3267
    },
    {
      "epoch": 0.19385454976865582,
      "grad_norm": 0.07417940348386765,
      "learning_rate": 1.7914579488531506e-05,
      "loss": 0.0027,
      "step": 3268
    },
    {
      "epoch": 0.1939138687863329,
      "grad_norm": 26.25480842590332,
      "learning_rate": 1.7913261270761932e-05,
      "loss": 0.2408,
      "step": 3269
    },
    {
      "epoch": 0.19397318780400996,
      "grad_norm": 7.863186836242676,
      "learning_rate": 1.7911943052992354e-05,
      "loss": 0.0638,
      "step": 3270
    },
    {
      "epoch": 0.19403250682168705,
      "grad_norm": 1.040420651435852,
      "learning_rate": 1.791062483522278e-05,
      "loss": 0.0179,
      "step": 3271
    },
    {
      "epoch": 0.1940918258393641,
      "grad_norm": 8.946833610534668,
      "learning_rate": 1.7909306617453203e-05,
      "loss": 0.3075,
      "step": 3272
    },
    {
      "epoch": 0.19415114485704116,
      "grad_norm": 0.04028651490807533,
      "learning_rate": 1.790798839968363e-05,
      "loss": 0.0007,
      "step": 3273
    },
    {
      "epoch": 0.19421046387471824,
      "grad_norm": 0.11838746070861816,
      "learning_rate": 1.7906670181914055e-05,
      "loss": 0.0018,
      "step": 3274
    },
    {
      "epoch": 0.1942697828923953,
      "grad_norm": 0.27888223528862,
      "learning_rate": 1.7905351964144477e-05,
      "loss": 0.0037,
      "step": 3275
    },
    {
      "epoch": 0.19432910191007238,
      "grad_norm": 0.4617763161659241,
      "learning_rate": 1.7904033746374903e-05,
      "loss": 0.0058,
      "step": 3276
    },
    {
      "epoch": 0.19438842092774944,
      "grad_norm": 3.0982160568237305,
      "learning_rate": 1.790271552860533e-05,
      "loss": 0.0292,
      "step": 3277
    },
    {
      "epoch": 0.1944477399454265,
      "grad_norm": 28.08856964111328,
      "learning_rate": 1.790139731083575e-05,
      "loss": 0.3505,
      "step": 3278
    },
    {
      "epoch": 0.19450705896310358,
      "grad_norm": 17.02985382080078,
      "learning_rate": 1.7900079093066177e-05,
      "loss": 0.9516,
      "step": 3279
    },
    {
      "epoch": 0.19456637798078064,
      "grad_norm": 0.15906473994255066,
      "learning_rate": 1.78987608752966e-05,
      "loss": 0.0021,
      "step": 3280
    },
    {
      "epoch": 0.1946256969984577,
      "grad_norm": 16.75497817993164,
      "learning_rate": 1.7897442657527026e-05,
      "loss": 0.2718,
      "step": 3281
    },
    {
      "epoch": 0.19468501601613478,
      "grad_norm": 0.8075032830238342,
      "learning_rate": 1.7896124439757448e-05,
      "loss": 0.014,
      "step": 3282
    },
    {
      "epoch": 0.19474433503381183,
      "grad_norm": 0.05736564099788666,
      "learning_rate": 1.7894806221987874e-05,
      "loss": 0.0007,
      "step": 3283
    },
    {
      "epoch": 0.19480365405148892,
      "grad_norm": 0.02936200238764286,
      "learning_rate": 1.7893488004218296e-05,
      "loss": 0.001,
      "step": 3284
    },
    {
      "epoch": 0.19486297306916597,
      "grad_norm": 10.899664878845215,
      "learning_rate": 1.7892169786448722e-05,
      "loss": 0.459,
      "step": 3285
    },
    {
      "epoch": 0.19492229208684303,
      "grad_norm": 7.177664756774902,
      "learning_rate": 1.7890851568679145e-05,
      "loss": 0.4353,
      "step": 3286
    },
    {
      "epoch": 0.19498161110452011,
      "grad_norm": 0.08522654324769974,
      "learning_rate": 1.788953335090957e-05,
      "loss": 0.0009,
      "step": 3287
    },
    {
      "epoch": 0.19504093012219717,
      "grad_norm": 0.945765495300293,
      "learning_rate": 1.7888215133139997e-05,
      "loss": 0.018,
      "step": 3288
    },
    {
      "epoch": 0.19510024913987425,
      "grad_norm": 16.879817962646484,
      "learning_rate": 1.788689691537042e-05,
      "loss": 1.0756,
      "step": 3289
    },
    {
      "epoch": 0.1951595681575513,
      "grad_norm": 3.550746202468872,
      "learning_rate": 1.7885578697600845e-05,
      "loss": 0.1342,
      "step": 3290
    },
    {
      "epoch": 0.19521888717522837,
      "grad_norm": 6.830029487609863,
      "learning_rate": 1.788426047983127e-05,
      "loss": 0.1455,
      "step": 3291
    },
    {
      "epoch": 0.19527820619290545,
      "grad_norm": 2.1331889629364014,
      "learning_rate": 1.7882942262061693e-05,
      "loss": 0.0647,
      "step": 3292
    },
    {
      "epoch": 0.1953375252105825,
      "grad_norm": 0.21015118062496185,
      "learning_rate": 1.788162404429212e-05,
      "loss": 0.0046,
      "step": 3293
    },
    {
      "epoch": 0.1953968442282596,
      "grad_norm": 0.22934144735336304,
      "learning_rate": 1.7880305826522545e-05,
      "loss": 0.0036,
      "step": 3294
    },
    {
      "epoch": 0.19545616324593665,
      "grad_norm": 0.669333815574646,
      "learning_rate": 1.7878987608752968e-05,
      "loss": 0.0082,
      "step": 3295
    },
    {
      "epoch": 0.1955154822636137,
      "grad_norm": 16.515962600708008,
      "learning_rate": 1.7877669390983393e-05,
      "loss": 0.1015,
      "step": 3296
    },
    {
      "epoch": 0.1955748012812908,
      "grad_norm": 20.34009552001953,
      "learning_rate": 1.7876351173213816e-05,
      "loss": 0.1062,
      "step": 3297
    },
    {
      "epoch": 0.19563412029896785,
      "grad_norm": 47.64055252075195,
      "learning_rate": 1.7875032955444242e-05,
      "loss": 0.6398,
      "step": 3298
    },
    {
      "epoch": 0.19569343931664493,
      "grad_norm": 0.30156832933425903,
      "learning_rate": 1.7873714737674664e-05,
      "loss": 0.0041,
      "step": 3299
    },
    {
      "epoch": 0.19575275833432199,
      "grad_norm": 12.06484317779541,
      "learning_rate": 1.787239651990509e-05,
      "loss": 0.5373,
      "step": 3300
    },
    {
      "epoch": 0.19581207735199904,
      "grad_norm": 1.5060291290283203,
      "learning_rate": 1.7871078302135513e-05,
      "loss": 0.0083,
      "step": 3301
    },
    {
      "epoch": 0.19587139636967613,
      "grad_norm": 14.467229843139648,
      "learning_rate": 1.786976008436594e-05,
      "loss": 0.3738,
      "step": 3302
    },
    {
      "epoch": 0.19593071538735318,
      "grad_norm": 0.058934081345796585,
      "learning_rate": 1.786844186659636e-05,
      "loss": 0.0007,
      "step": 3303
    },
    {
      "epoch": 0.19599003440503024,
      "grad_norm": 29.355432510375977,
      "learning_rate": 1.7867123648826787e-05,
      "loss": 0.2855,
      "step": 3304
    },
    {
      "epoch": 0.19604935342270732,
      "grad_norm": 5.960725784301758,
      "learning_rate": 1.7865805431057213e-05,
      "loss": 0.1972,
      "step": 3305
    },
    {
      "epoch": 0.19610867244038438,
      "grad_norm": 0.05560597404837608,
      "learning_rate": 1.7864487213287635e-05,
      "loss": 0.0013,
      "step": 3306
    },
    {
      "epoch": 0.19616799145806146,
      "grad_norm": 0.5552385449409485,
      "learning_rate": 1.786316899551806e-05,
      "loss": 0.0064,
      "step": 3307
    },
    {
      "epoch": 0.19622731047573852,
      "grad_norm": 0.06973055750131607,
      "learning_rate": 1.7861850777748487e-05,
      "loss": 0.0013,
      "step": 3308
    },
    {
      "epoch": 0.19628662949341558,
      "grad_norm": 0.29472091794013977,
      "learning_rate": 1.786053255997891e-05,
      "loss": 0.0048,
      "step": 3309
    },
    {
      "epoch": 0.19634594851109266,
      "grad_norm": 6.569924831390381,
      "learning_rate": 1.7859214342209335e-05,
      "loss": 0.1928,
      "step": 3310
    },
    {
      "epoch": 0.19640526752876972,
      "grad_norm": 0.06362652033567429,
      "learning_rate": 1.785789612443976e-05,
      "loss": 0.0007,
      "step": 3311
    },
    {
      "epoch": 0.1964645865464468,
      "grad_norm": 0.8033871054649353,
      "learning_rate": 1.7856577906670184e-05,
      "loss": 0.0111,
      "step": 3312
    },
    {
      "epoch": 0.19652390556412386,
      "grad_norm": 13.438543319702148,
      "learning_rate": 1.7855259688900606e-05,
      "loss": 0.1365,
      "step": 3313
    },
    {
      "epoch": 0.1965832245818009,
      "grad_norm": 1.3395109176635742,
      "learning_rate": 1.7853941471131032e-05,
      "loss": 0.0114,
      "step": 3314
    },
    {
      "epoch": 0.196642543599478,
      "grad_norm": 0.6074701547622681,
      "learning_rate": 1.7852623253361455e-05,
      "loss": 0.0058,
      "step": 3315
    },
    {
      "epoch": 0.19670186261715505,
      "grad_norm": 4.655011177062988,
      "learning_rate": 1.785130503559188e-05,
      "loss": 0.0547,
      "step": 3316
    },
    {
      "epoch": 0.19676118163483214,
      "grad_norm": 0.1003054827451706,
      "learning_rate": 1.7849986817822306e-05,
      "loss": 0.0013,
      "step": 3317
    },
    {
      "epoch": 0.1968205006525092,
      "grad_norm": 2.349648952484131,
      "learning_rate": 1.784866860005273e-05,
      "loss": 0.0154,
      "step": 3318
    },
    {
      "epoch": 0.19687981967018625,
      "grad_norm": 1.587725281715393,
      "learning_rate": 1.7847350382283155e-05,
      "loss": 0.0121,
      "step": 3319
    },
    {
      "epoch": 0.19693913868786334,
      "grad_norm": 14.52338695526123,
      "learning_rate": 1.7846032164513577e-05,
      "loss": 0.3388,
      "step": 3320
    },
    {
      "epoch": 0.1969984577055404,
      "grad_norm": 25.165674209594727,
      "learning_rate": 1.7844713946744003e-05,
      "loss": 0.0984,
      "step": 3321
    },
    {
      "epoch": 0.19705777672321748,
      "grad_norm": 6.871700763702393,
      "learning_rate": 1.784339572897443e-05,
      "loss": 0.045,
      "step": 3322
    },
    {
      "epoch": 0.19711709574089453,
      "grad_norm": 0.24778485298156738,
      "learning_rate": 1.784207751120485e-05,
      "loss": 0.005,
      "step": 3323
    },
    {
      "epoch": 0.1971764147585716,
      "grad_norm": 8.20863151550293,
      "learning_rate": 1.7840759293435277e-05,
      "loss": 0.0497,
      "step": 3324
    },
    {
      "epoch": 0.19723573377624867,
      "grad_norm": 6.996041774749756,
      "learning_rate": 1.7839441075665703e-05,
      "loss": 0.213,
      "step": 3325
    },
    {
      "epoch": 0.19729505279392573,
      "grad_norm": 3.2417023181915283,
      "learning_rate": 1.7838122857896126e-05,
      "loss": 0.3583,
      "step": 3326
    },
    {
      "epoch": 0.1973543718116028,
      "grad_norm": 6.472440719604492,
      "learning_rate": 1.7836804640126552e-05,
      "loss": 0.0805,
      "step": 3327
    },
    {
      "epoch": 0.19741369082927987,
      "grad_norm": 78.9117202758789,
      "learning_rate": 1.7835486422356974e-05,
      "loss": 0.5119,
      "step": 3328
    },
    {
      "epoch": 0.19747300984695693,
      "grad_norm": 0.04088618978857994,
      "learning_rate": 1.78341682045874e-05,
      "loss": 0.0009,
      "step": 3329
    },
    {
      "epoch": 0.197532328864634,
      "grad_norm": 0.16534681618213654,
      "learning_rate": 1.7832849986817823e-05,
      "loss": 0.0032,
      "step": 3330
    },
    {
      "epoch": 0.19759164788231107,
      "grad_norm": 4.917898178100586,
      "learning_rate": 1.783153176904825e-05,
      "loss": 0.049,
      "step": 3331
    },
    {
      "epoch": 0.19765096689998812,
      "grad_norm": 0.2880069613456726,
      "learning_rate": 1.783021355127867e-05,
      "loss": 0.0039,
      "step": 3332
    },
    {
      "epoch": 0.1977102859176652,
      "grad_norm": 14.071599006652832,
      "learning_rate": 1.7828895333509097e-05,
      "loss": 0.8195,
      "step": 3333
    },
    {
      "epoch": 0.19776960493534226,
      "grad_norm": 0.06888458132743835,
      "learning_rate": 1.782757711573952e-05,
      "loss": 0.0012,
      "step": 3334
    },
    {
      "epoch": 0.19782892395301935,
      "grad_norm": 28.86060905456543,
      "learning_rate": 1.7826258897969945e-05,
      "loss": 0.1499,
      "step": 3335
    },
    {
      "epoch": 0.1978882429706964,
      "grad_norm": 1.2066943645477295,
      "learning_rate": 1.782494068020037e-05,
      "loss": 0.0053,
      "step": 3336
    },
    {
      "epoch": 0.19794756198837346,
      "grad_norm": 6.231265068054199,
      "learning_rate": 1.7823622462430794e-05,
      "loss": 0.0887,
      "step": 3337
    },
    {
      "epoch": 0.19800688100605054,
      "grad_norm": 18.11928939819336,
      "learning_rate": 1.782230424466122e-05,
      "loss": 0.158,
      "step": 3338
    },
    {
      "epoch": 0.1980662000237276,
      "grad_norm": 0.014004616998136044,
      "learning_rate": 1.7820986026891645e-05,
      "loss": 0.0004,
      "step": 3339
    },
    {
      "epoch": 0.19812551904140469,
      "grad_norm": 4.801468849182129,
      "learning_rate": 1.7819667809122068e-05,
      "loss": 0.0236,
      "step": 3340
    },
    {
      "epoch": 0.19818483805908174,
      "grad_norm": 13.68934154510498,
      "learning_rate": 1.7818349591352494e-05,
      "loss": 0.0743,
      "step": 3341
    },
    {
      "epoch": 0.1982441570767588,
      "grad_norm": 7.670524597167969,
      "learning_rate": 1.781703137358292e-05,
      "loss": 0.096,
      "step": 3342
    },
    {
      "epoch": 0.19830347609443588,
      "grad_norm": 15.272104263305664,
      "learning_rate": 1.7815713155813342e-05,
      "loss": 0.1905,
      "step": 3343
    },
    {
      "epoch": 0.19836279511211294,
      "grad_norm": 2.2286148071289062,
      "learning_rate": 1.7814394938043768e-05,
      "loss": 0.0223,
      "step": 3344
    },
    {
      "epoch": 0.19842211412979002,
      "grad_norm": 4.26677942276001,
      "learning_rate": 1.781307672027419e-05,
      "loss": 0.0616,
      "step": 3345
    },
    {
      "epoch": 0.19848143314746708,
      "grad_norm": 1.4660110473632812,
      "learning_rate": 1.7811758502504613e-05,
      "loss": 0.0123,
      "step": 3346
    },
    {
      "epoch": 0.19854075216514414,
      "grad_norm": 3.355046033859253,
      "learning_rate": 1.781044028473504e-05,
      "loss": 0.0389,
      "step": 3347
    },
    {
      "epoch": 0.19860007118282122,
      "grad_norm": 1.519762635231018,
      "learning_rate": 1.7809122066965465e-05,
      "loss": 0.0206,
      "step": 3348
    },
    {
      "epoch": 0.19865939020049828,
      "grad_norm": 0.9196451902389526,
      "learning_rate": 1.7807803849195887e-05,
      "loss": 0.0067,
      "step": 3349
    },
    {
      "epoch": 0.19871870921817536,
      "grad_norm": 0.6946272850036621,
      "learning_rate": 1.7806485631426313e-05,
      "loss": 0.0079,
      "step": 3350
    },
    {
      "epoch": 0.19877802823585242,
      "grad_norm": 2.647221326828003,
      "learning_rate": 1.7805167413656736e-05,
      "loss": 0.0233,
      "step": 3351
    },
    {
      "epoch": 0.19883734725352947,
      "grad_norm": 6.0612664222717285,
      "learning_rate": 1.780384919588716e-05,
      "loss": 0.044,
      "step": 3352
    },
    {
      "epoch": 0.19889666627120656,
      "grad_norm": 0.744040310382843,
      "learning_rate": 1.7802530978117587e-05,
      "loss": 0.0094,
      "step": 3353
    },
    {
      "epoch": 0.1989559852888836,
      "grad_norm": 2.34493088722229,
      "learning_rate": 1.780121276034801e-05,
      "loss": 0.0172,
      "step": 3354
    },
    {
      "epoch": 0.19901530430656067,
      "grad_norm": 18.05284881591797,
      "learning_rate": 1.7799894542578436e-05,
      "loss": 0.7028,
      "step": 3355
    },
    {
      "epoch": 0.19907462332423775,
      "grad_norm": 21.74795150756836,
      "learning_rate": 1.779857632480886e-05,
      "loss": 0.3924,
      "step": 3356
    },
    {
      "epoch": 0.1991339423419148,
      "grad_norm": 7.499318599700928,
      "learning_rate": 1.7797258107039284e-05,
      "loss": 0.059,
      "step": 3357
    },
    {
      "epoch": 0.1991932613595919,
      "grad_norm": 0.09238778054714203,
      "learning_rate": 1.779593988926971e-05,
      "loss": 0.0017,
      "step": 3358
    },
    {
      "epoch": 0.19925258037726895,
      "grad_norm": 0.0069772833958268166,
      "learning_rate": 1.7794621671500133e-05,
      "loss": 0.0002,
      "step": 3359
    },
    {
      "epoch": 0.199311899394946,
      "grad_norm": 5.335641384124756,
      "learning_rate": 1.779330345373056e-05,
      "loss": 0.088,
      "step": 3360
    },
    {
      "epoch": 0.1993712184126231,
      "grad_norm": 0.09748389571905136,
      "learning_rate": 1.779198523596098e-05,
      "loss": 0.001,
      "step": 3361
    },
    {
      "epoch": 0.19943053743030015,
      "grad_norm": 0.07897605746984482,
      "learning_rate": 1.7790667018191407e-05,
      "loss": 0.0014,
      "step": 3362
    },
    {
      "epoch": 0.19948985644797723,
      "grad_norm": 1.5517518520355225,
      "learning_rate": 1.778934880042183e-05,
      "loss": 0.01,
      "step": 3363
    },
    {
      "epoch": 0.1995491754656543,
      "grad_norm": 0.02287081442773342,
      "learning_rate": 1.7788030582652255e-05,
      "loss": 0.0008,
      "step": 3364
    },
    {
      "epoch": 0.19960849448333134,
      "grad_norm": 1.5848007202148438,
      "learning_rate": 1.778671236488268e-05,
      "loss": 0.0162,
      "step": 3365
    },
    {
      "epoch": 0.19966781350100843,
      "grad_norm": 0.23165135085582733,
      "learning_rate": 1.7785394147113104e-05,
      "loss": 0.0031,
      "step": 3366
    },
    {
      "epoch": 0.19972713251868549,
      "grad_norm": 0.017455432564020157,
      "learning_rate": 1.778407592934353e-05,
      "loss": 0.0005,
      "step": 3367
    },
    {
      "epoch": 0.19978645153636257,
      "grad_norm": 10.841934204101562,
      "learning_rate": 1.7782757711573952e-05,
      "loss": 0.1333,
      "step": 3368
    },
    {
      "epoch": 0.19984577055403963,
      "grad_norm": 53.72563552856445,
      "learning_rate": 1.7781439493804378e-05,
      "loss": 1.5843,
      "step": 3369
    },
    {
      "epoch": 0.19990508957171668,
      "grad_norm": 35.54249572753906,
      "learning_rate": 1.7780121276034804e-05,
      "loss": 1.2262,
      "step": 3370
    },
    {
      "epoch": 0.19996440858939377,
      "grad_norm": 24.848249435424805,
      "learning_rate": 1.7778803058265226e-05,
      "loss": 0.3938,
      "step": 3371
    },
    {
      "epoch": 0.20002372760707082,
      "grad_norm": 0.06601978093385696,
      "learning_rate": 1.7777484840495652e-05,
      "loss": 0.0009,
      "step": 3372
    },
    {
      "epoch": 0.2000830466247479,
      "grad_norm": 4.792771816253662,
      "learning_rate": 1.7776166622726078e-05,
      "loss": 0.2505,
      "step": 3373
    },
    {
      "epoch": 0.20014236564242496,
      "grad_norm": 8.146503448486328,
      "learning_rate": 1.77748484049565e-05,
      "loss": 0.0283,
      "step": 3374
    },
    {
      "epoch": 0.20020168466010202,
      "grad_norm": 1.5052425861358643,
      "learning_rate": 1.7773530187186926e-05,
      "loss": 0.0176,
      "step": 3375
    },
    {
      "epoch": 0.2002610036777791,
      "grad_norm": 9.345966339111328,
      "learning_rate": 1.777221196941735e-05,
      "loss": 0.3007,
      "step": 3376
    },
    {
      "epoch": 0.20032032269545616,
      "grad_norm": 0.34178364276885986,
      "learning_rate": 1.7770893751647775e-05,
      "loss": 0.0034,
      "step": 3377
    },
    {
      "epoch": 0.20037964171313324,
      "grad_norm": 0.9722594618797302,
      "learning_rate": 1.7769575533878197e-05,
      "loss": 0.0074,
      "step": 3378
    },
    {
      "epoch": 0.2004389607308103,
      "grad_norm": 0.03546866774559021,
      "learning_rate": 1.7768257316108623e-05,
      "loss": 0.0006,
      "step": 3379
    },
    {
      "epoch": 0.20049827974848736,
      "grad_norm": 5.640877723693848,
      "learning_rate": 1.7766939098339046e-05,
      "loss": 0.0404,
      "step": 3380
    },
    {
      "epoch": 0.20055759876616444,
      "grad_norm": 8.000720977783203,
      "learning_rate": 1.776562088056947e-05,
      "loss": 0.2503,
      "step": 3381
    },
    {
      "epoch": 0.2006169177838415,
      "grad_norm": 0.01862841472029686,
      "learning_rate": 1.7764302662799894e-05,
      "loss": 0.0004,
      "step": 3382
    },
    {
      "epoch": 0.20067623680151855,
      "grad_norm": 11.006120681762695,
      "learning_rate": 1.776298444503032e-05,
      "loss": 0.0915,
      "step": 3383
    },
    {
      "epoch": 0.20073555581919564,
      "grad_norm": 0.9093401432037354,
      "learning_rate": 1.7761666227260746e-05,
      "loss": 0.0115,
      "step": 3384
    },
    {
      "epoch": 0.2007948748368727,
      "grad_norm": 7.702001094818115,
      "learning_rate": 1.7760348009491168e-05,
      "loss": 0.0966,
      "step": 3385
    },
    {
      "epoch": 0.20085419385454978,
      "grad_norm": 0.32082581520080566,
      "learning_rate": 1.7759029791721594e-05,
      "loss": 0.0022,
      "step": 3386
    },
    {
      "epoch": 0.20091351287222683,
      "grad_norm": 4.738193035125732,
      "learning_rate": 1.775771157395202e-05,
      "loss": 0.0531,
      "step": 3387
    },
    {
      "epoch": 0.2009728318899039,
      "grad_norm": 10.715174674987793,
      "learning_rate": 1.7756393356182442e-05,
      "loss": 0.123,
      "step": 3388
    },
    {
      "epoch": 0.20103215090758098,
      "grad_norm": 3.2139525413513184,
      "learning_rate": 1.7755075138412868e-05,
      "loss": 0.0164,
      "step": 3389
    },
    {
      "epoch": 0.20109146992525803,
      "grad_norm": 16.352787017822266,
      "learning_rate": 1.7753756920643294e-05,
      "loss": 0.3306,
      "step": 3390
    },
    {
      "epoch": 0.20115078894293512,
      "grad_norm": 0.5365690588951111,
      "learning_rate": 1.7752438702873717e-05,
      "loss": 0.0073,
      "step": 3391
    },
    {
      "epoch": 0.20121010796061217,
      "grad_norm": 11.350854873657227,
      "learning_rate": 1.775112048510414e-05,
      "loss": 0.4508,
      "step": 3392
    },
    {
      "epoch": 0.20126942697828923,
      "grad_norm": 24.763816833496094,
      "learning_rate": 1.7749802267334565e-05,
      "loss": 0.5976,
      "step": 3393
    },
    {
      "epoch": 0.2013287459959663,
      "grad_norm": 7.80361270904541,
      "learning_rate": 1.7748484049564988e-05,
      "loss": 0.0764,
      "step": 3394
    },
    {
      "epoch": 0.20138806501364337,
      "grad_norm": 13.358820915222168,
      "learning_rate": 1.7747165831795413e-05,
      "loss": 0.1754,
      "step": 3395
    },
    {
      "epoch": 0.20144738403132045,
      "grad_norm": 0.025881769135594368,
      "learning_rate": 1.774584761402584e-05,
      "loss": 0.0006,
      "step": 3396
    },
    {
      "epoch": 0.2015067030489975,
      "grad_norm": 20.25223731994629,
      "learning_rate": 1.7744529396256262e-05,
      "loss": 0.318,
      "step": 3397
    },
    {
      "epoch": 0.20156602206667457,
      "grad_norm": 9.217535972595215,
      "learning_rate": 1.7743211178486688e-05,
      "loss": 0.6,
      "step": 3398
    },
    {
      "epoch": 0.20162534108435165,
      "grad_norm": 3.255812883377075,
      "learning_rate": 1.774189296071711e-05,
      "loss": 0.0236,
      "step": 3399
    },
    {
      "epoch": 0.2016846601020287,
      "grad_norm": 6.1977009773254395,
      "learning_rate": 1.7740574742947536e-05,
      "loss": 0.0373,
      "step": 3400
    },
    {
      "epoch": 0.2017439791197058,
      "grad_norm": 16.335224151611328,
      "learning_rate": 1.7739256525177962e-05,
      "loss": 0.209,
      "step": 3401
    },
    {
      "epoch": 0.20180329813738285,
      "grad_norm": 10.191171646118164,
      "learning_rate": 1.7737938307408384e-05,
      "loss": 0.5562,
      "step": 3402
    },
    {
      "epoch": 0.2018626171550599,
      "grad_norm": 8.887433052062988,
      "learning_rate": 1.773662008963881e-05,
      "loss": 0.2151,
      "step": 3403
    },
    {
      "epoch": 0.201921936172737,
      "grad_norm": 0.18495161831378937,
      "learning_rate": 1.7735301871869236e-05,
      "loss": 0.0013,
      "step": 3404
    },
    {
      "epoch": 0.20198125519041404,
      "grad_norm": 0.005320371128618717,
      "learning_rate": 1.773398365409966e-05,
      "loss": 0.0002,
      "step": 3405
    },
    {
      "epoch": 0.2020405742080911,
      "grad_norm": 9.237968444824219,
      "learning_rate": 1.7732665436330085e-05,
      "loss": 0.1515,
      "step": 3406
    },
    {
      "epoch": 0.20209989322576818,
      "grad_norm": 2.0471580028533936,
      "learning_rate": 1.7731347218560507e-05,
      "loss": 0.0154,
      "step": 3407
    },
    {
      "epoch": 0.20215921224344524,
      "grad_norm": 0.04917817935347557,
      "learning_rate": 1.7730029000790933e-05,
      "loss": 0.0014,
      "step": 3408
    },
    {
      "epoch": 0.20221853126112233,
      "grad_norm": 34.134422302246094,
      "learning_rate": 1.7728710783021355e-05,
      "loss": 0.8654,
      "step": 3409
    },
    {
      "epoch": 0.20227785027879938,
      "grad_norm": 17.91155242919922,
      "learning_rate": 1.772739256525178e-05,
      "loss": 0.7167,
      "step": 3410
    },
    {
      "epoch": 0.20233716929647644,
      "grad_norm": 12.815993309020996,
      "learning_rate": 1.7726074347482204e-05,
      "loss": 0.8713,
      "step": 3411
    },
    {
      "epoch": 0.20239648831415352,
      "grad_norm": 6.852049827575684,
      "learning_rate": 1.772475612971263e-05,
      "loss": 1.0295,
      "step": 3412
    },
    {
      "epoch": 0.20245580733183058,
      "grad_norm": 4.500076770782471,
      "learning_rate": 1.7723437911943056e-05,
      "loss": 0.0679,
      "step": 3413
    },
    {
      "epoch": 0.20251512634950766,
      "grad_norm": 1.4660574197769165,
      "learning_rate": 1.7722119694173478e-05,
      "loss": 0.0223,
      "step": 3414
    },
    {
      "epoch": 0.20257444536718472,
      "grad_norm": 13.068744659423828,
      "learning_rate": 1.7720801476403904e-05,
      "loss": 0.629,
      "step": 3415
    },
    {
      "epoch": 0.20263376438486178,
      "grad_norm": 0.08148662000894547,
      "learning_rate": 1.7719483258634326e-05,
      "loss": 0.0007,
      "step": 3416
    },
    {
      "epoch": 0.20269308340253886,
      "grad_norm": 8.634344100952148,
      "learning_rate": 1.7718165040864752e-05,
      "loss": 0.0371,
      "step": 3417
    },
    {
      "epoch": 0.20275240242021592,
      "grad_norm": 0.16245809197425842,
      "learning_rate": 1.7716846823095178e-05,
      "loss": 0.0031,
      "step": 3418
    },
    {
      "epoch": 0.202811721437893,
      "grad_norm": 9.905913352966309,
      "learning_rate": 1.77155286053256e-05,
      "loss": 0.0919,
      "step": 3419
    },
    {
      "epoch": 0.20287104045557006,
      "grad_norm": 25.63430404663086,
      "learning_rate": 1.7714210387556027e-05,
      "loss": 0.7248,
      "step": 3420
    },
    {
      "epoch": 0.2029303594732471,
      "grad_norm": 1.235563039779663,
      "learning_rate": 1.7712892169786452e-05,
      "loss": 0.0111,
      "step": 3421
    },
    {
      "epoch": 0.2029896784909242,
      "grad_norm": 0.025914177298545837,
      "learning_rate": 1.7711573952016875e-05,
      "loss": 0.0009,
      "step": 3422
    },
    {
      "epoch": 0.20304899750860125,
      "grad_norm": 0.019347192719578743,
      "learning_rate": 1.77102557342473e-05,
      "loss": 0.0005,
      "step": 3423
    },
    {
      "epoch": 0.20310831652627834,
      "grad_norm": 1.002933382987976,
      "learning_rate": 1.7708937516477723e-05,
      "loss": 0.0145,
      "step": 3424
    },
    {
      "epoch": 0.2031676355439554,
      "grad_norm": 6.376986980438232,
      "learning_rate": 1.7707619298708146e-05,
      "loss": 0.117,
      "step": 3425
    },
    {
      "epoch": 0.20322695456163245,
      "grad_norm": 8.695415496826172,
      "learning_rate": 1.770630108093857e-05,
      "loss": 0.1133,
      "step": 3426
    },
    {
      "epoch": 0.20328627357930953,
      "grad_norm": 0.3336087465286255,
      "learning_rate": 1.7704982863168998e-05,
      "loss": 0.005,
      "step": 3427
    },
    {
      "epoch": 0.2033455925969866,
      "grad_norm": 0.21926423907279968,
      "learning_rate": 1.770366464539942e-05,
      "loss": 0.003,
      "step": 3428
    },
    {
      "epoch": 0.20340491161466367,
      "grad_norm": 1.5488145351409912,
      "learning_rate": 1.7702346427629846e-05,
      "loss": 0.0172,
      "step": 3429
    },
    {
      "epoch": 0.20346423063234073,
      "grad_norm": 31.502599716186523,
      "learning_rate": 1.770102820986027e-05,
      "loss": 0.4097,
      "step": 3430
    },
    {
      "epoch": 0.2035235496500178,
      "grad_norm": 10.207262992858887,
      "learning_rate": 1.7699709992090694e-05,
      "loss": 0.7511,
      "step": 3431
    },
    {
      "epoch": 0.20358286866769487,
      "grad_norm": 0.4924473166465759,
      "learning_rate": 1.769839177432112e-05,
      "loss": 0.0088,
      "step": 3432
    },
    {
      "epoch": 0.20364218768537193,
      "grad_norm": 15.519606590270996,
      "learning_rate": 1.7697073556551543e-05,
      "loss": 0.492,
      "step": 3433
    },
    {
      "epoch": 0.20370150670304898,
      "grad_norm": 3.3970577716827393,
      "learning_rate": 1.769575533878197e-05,
      "loss": 0.0356,
      "step": 3434
    },
    {
      "epoch": 0.20376082572072607,
      "grad_norm": 3.0759942531585693,
      "learning_rate": 1.7694437121012394e-05,
      "loss": 0.0176,
      "step": 3435
    },
    {
      "epoch": 0.20382014473840313,
      "grad_norm": 10.274324417114258,
      "learning_rate": 1.7693118903242817e-05,
      "loss": 0.5988,
      "step": 3436
    },
    {
      "epoch": 0.2038794637560802,
      "grad_norm": 3.5768258571624756,
      "learning_rate": 1.7691800685473243e-05,
      "loss": 0.0174,
      "step": 3437
    },
    {
      "epoch": 0.20393878277375727,
      "grad_norm": 3.600213050842285,
      "learning_rate": 1.7690482467703665e-05,
      "loss": 0.0205,
      "step": 3438
    },
    {
      "epoch": 0.20399810179143432,
      "grad_norm": 4.892149448394775,
      "learning_rate": 1.768916424993409e-05,
      "loss": 0.0324,
      "step": 3439
    },
    {
      "epoch": 0.2040574208091114,
      "grad_norm": 0.018556542694568634,
      "learning_rate": 1.7687846032164514e-05,
      "loss": 0.0007,
      "step": 3440
    },
    {
      "epoch": 0.20411673982678846,
      "grad_norm": 6.652209758758545,
      "learning_rate": 1.768652781439494e-05,
      "loss": 0.4077,
      "step": 3441
    },
    {
      "epoch": 0.20417605884446555,
      "grad_norm": 11.109580993652344,
      "learning_rate": 1.7685209596625362e-05,
      "loss": 0.1178,
      "step": 3442
    },
    {
      "epoch": 0.2042353778621426,
      "grad_norm": 4.014499664306641,
      "learning_rate": 1.7683891378855788e-05,
      "loss": 0.2884,
      "step": 3443
    },
    {
      "epoch": 0.20429469687981966,
      "grad_norm": 10.555499076843262,
      "learning_rate": 1.7682573161086214e-05,
      "loss": 0.0738,
      "step": 3444
    },
    {
      "epoch": 0.20435401589749674,
      "grad_norm": 5.190271377563477,
      "learning_rate": 1.7681254943316636e-05,
      "loss": 0.2468,
      "step": 3445
    },
    {
      "epoch": 0.2044133349151738,
      "grad_norm": 0.10534316301345825,
      "learning_rate": 1.7679936725547062e-05,
      "loss": 0.0013,
      "step": 3446
    },
    {
      "epoch": 0.20447265393285088,
      "grad_norm": 36.60418701171875,
      "learning_rate": 1.7678618507777485e-05,
      "loss": 0.8397,
      "step": 3447
    },
    {
      "epoch": 0.20453197295052794,
      "grad_norm": 0.6281349658966064,
      "learning_rate": 1.767730029000791e-05,
      "loss": 0.0069,
      "step": 3448
    },
    {
      "epoch": 0.204591291968205,
      "grad_norm": 34.39954376220703,
      "learning_rate": 1.7675982072238336e-05,
      "loss": 0.5332,
      "step": 3449
    },
    {
      "epoch": 0.20465061098588208,
      "grad_norm": 0.23145347833633423,
      "learning_rate": 1.767466385446876e-05,
      "loss": 0.0029,
      "step": 3450
    },
    {
      "epoch": 0.20470993000355914,
      "grad_norm": 23.3253231048584,
      "learning_rate": 1.7673345636699185e-05,
      "loss": 0.2447,
      "step": 3451
    },
    {
      "epoch": 0.20476924902123622,
      "grad_norm": 18.73990249633789,
      "learning_rate": 1.767202741892961e-05,
      "loss": 0.4567,
      "step": 3452
    },
    {
      "epoch": 0.20482856803891328,
      "grad_norm": 6.082090854644775,
      "learning_rate": 1.7670709201160033e-05,
      "loss": 0.5187,
      "step": 3453
    },
    {
      "epoch": 0.20488788705659033,
      "grad_norm": 1.3501274585723877,
      "learning_rate": 1.766939098339046e-05,
      "loss": 0.0183,
      "step": 3454
    },
    {
      "epoch": 0.20494720607426742,
      "grad_norm": 0.7855902910232544,
      "learning_rate": 1.766807276562088e-05,
      "loss": 0.0062,
      "step": 3455
    },
    {
      "epoch": 0.20500652509194447,
      "grad_norm": 0.062253180891275406,
      "learning_rate": 1.7666754547851307e-05,
      "loss": 0.0017,
      "step": 3456
    },
    {
      "epoch": 0.20506584410962153,
      "grad_norm": 0.8102713823318481,
      "learning_rate": 1.766543633008173e-05,
      "loss": 0.0062,
      "step": 3457
    },
    {
      "epoch": 0.20512516312729862,
      "grad_norm": 0.9228405356407166,
      "learning_rate": 1.7664118112312156e-05,
      "loss": 0.0102,
      "step": 3458
    },
    {
      "epoch": 0.20518448214497567,
      "grad_norm": 13.132257461547852,
      "learning_rate": 1.766279989454258e-05,
      "loss": 0.5106,
      "step": 3459
    },
    {
      "epoch": 0.20524380116265276,
      "grad_norm": 40.86936569213867,
      "learning_rate": 1.7661481676773004e-05,
      "loss": 1.3615,
      "step": 3460
    },
    {
      "epoch": 0.2053031201803298,
      "grad_norm": 30.582929611206055,
      "learning_rate": 1.766016345900343e-05,
      "loss": 0.446,
      "step": 3461
    },
    {
      "epoch": 0.20536243919800687,
      "grad_norm": 8.416409492492676,
      "learning_rate": 1.7658845241233853e-05,
      "loss": 0.382,
      "step": 3462
    },
    {
      "epoch": 0.20542175821568395,
      "grad_norm": 11.849455833435059,
      "learning_rate": 1.765752702346428e-05,
      "loss": 0.8316,
      "step": 3463
    },
    {
      "epoch": 0.205481077233361,
      "grad_norm": 0.006219511851668358,
      "learning_rate": 1.76562088056947e-05,
      "loss": 0.0002,
      "step": 3464
    },
    {
      "epoch": 0.2055403962510381,
      "grad_norm": 2.0676887035369873,
      "learning_rate": 1.7654890587925127e-05,
      "loss": 0.0302,
      "step": 3465
    },
    {
      "epoch": 0.20559971526871515,
      "grad_norm": 3.5018398761749268,
      "learning_rate": 1.7653572370155553e-05,
      "loss": 0.0478,
      "step": 3466
    },
    {
      "epoch": 0.2056590342863922,
      "grad_norm": 0.08811666071414948,
      "learning_rate": 1.7652254152385975e-05,
      "loss": 0.0014,
      "step": 3467
    },
    {
      "epoch": 0.2057183533040693,
      "grad_norm": 11.496223449707031,
      "learning_rate": 1.76509359346164e-05,
      "loss": 0.463,
      "step": 3468
    },
    {
      "epoch": 0.20577767232174635,
      "grad_norm": 21.881187438964844,
      "learning_rate": 1.7649617716846824e-05,
      "loss": 0.7639,
      "step": 3469
    },
    {
      "epoch": 0.20583699133942343,
      "grad_norm": 0.7738440036773682,
      "learning_rate": 1.764829949907725e-05,
      "loss": 0.01,
      "step": 3470
    },
    {
      "epoch": 0.2058963103571005,
      "grad_norm": 0.12670953571796417,
      "learning_rate": 1.7646981281307672e-05,
      "loss": 0.0017,
      "step": 3471
    },
    {
      "epoch": 0.20595562937477754,
      "grad_norm": 0.19899000227451324,
      "learning_rate": 1.7645663063538098e-05,
      "loss": 0.0024,
      "step": 3472
    },
    {
      "epoch": 0.20601494839245463,
      "grad_norm": 8.222702026367188,
      "learning_rate": 1.764434484576852e-05,
      "loss": 0.0989,
      "step": 3473
    },
    {
      "epoch": 0.20607426741013168,
      "grad_norm": 1.2871503829956055,
      "learning_rate": 1.7643026627998946e-05,
      "loss": 0.0237,
      "step": 3474
    },
    {
      "epoch": 0.20613358642780877,
      "grad_norm": 0.013482494279742241,
      "learning_rate": 1.7641708410229372e-05,
      "loss": 0.0005,
      "step": 3475
    },
    {
      "epoch": 0.20619290544548582,
      "grad_norm": 12.257950782775879,
      "learning_rate": 1.7640390192459795e-05,
      "loss": 0.1407,
      "step": 3476
    },
    {
      "epoch": 0.20625222446316288,
      "grad_norm": 5.383940696716309,
      "learning_rate": 1.763907197469022e-05,
      "loss": 0.1675,
      "step": 3477
    },
    {
      "epoch": 0.20631154348083997,
      "grad_norm": 10.422273635864258,
      "learning_rate": 1.7637753756920646e-05,
      "loss": 0.1121,
      "step": 3478
    },
    {
      "epoch": 0.20637086249851702,
      "grad_norm": 119.18788146972656,
      "learning_rate": 1.763643553915107e-05,
      "loss": 0.5513,
      "step": 3479
    },
    {
      "epoch": 0.2064301815161941,
      "grad_norm": 18.066173553466797,
      "learning_rate": 1.7635117321381495e-05,
      "loss": 0.9239,
      "step": 3480
    },
    {
      "epoch": 0.20648950053387116,
      "grad_norm": 9.648276329040527,
      "learning_rate": 1.7633799103611917e-05,
      "loss": 0.1709,
      "step": 3481
    },
    {
      "epoch": 0.20654881955154822,
      "grad_norm": 15.604493141174316,
      "learning_rate": 1.7632480885842343e-05,
      "loss": 0.4009,
      "step": 3482
    },
    {
      "epoch": 0.2066081385692253,
      "grad_norm": 1.2358170747756958,
      "learning_rate": 1.763116266807277e-05,
      "loss": 0.0111,
      "step": 3483
    },
    {
      "epoch": 0.20666745758690236,
      "grad_norm": 17.456283569335938,
      "learning_rate": 1.762984445030319e-05,
      "loss": 0.3508,
      "step": 3484
    },
    {
      "epoch": 0.20672677660457942,
      "grad_norm": 10.852232933044434,
      "learning_rate": 1.7628526232533617e-05,
      "loss": 0.2108,
      "step": 3485
    },
    {
      "epoch": 0.2067860956222565,
      "grad_norm": 33.73332977294922,
      "learning_rate": 1.762720801476404e-05,
      "loss": 0.7576,
      "step": 3486
    },
    {
      "epoch": 0.20684541463993356,
      "grad_norm": 14.690446853637695,
      "learning_rate": 1.7625889796994466e-05,
      "loss": 0.7095,
      "step": 3487
    },
    {
      "epoch": 0.20690473365761064,
      "grad_norm": 2.3359110355377197,
      "learning_rate": 1.7624571579224888e-05,
      "loss": 0.0184,
      "step": 3488
    },
    {
      "epoch": 0.2069640526752877,
      "grad_norm": 8.676222801208496,
      "learning_rate": 1.7623253361455314e-05,
      "loss": 0.1063,
      "step": 3489
    },
    {
      "epoch": 0.20702337169296475,
      "grad_norm": 12.829404830932617,
      "learning_rate": 1.7621935143685737e-05,
      "loss": 0.1763,
      "step": 3490
    },
    {
      "epoch": 0.20708269071064184,
      "grad_norm": 0.16517265141010284,
      "learning_rate": 1.7620616925916162e-05,
      "loss": 0.001,
      "step": 3491
    },
    {
      "epoch": 0.2071420097283189,
      "grad_norm": 9.08031940460205,
      "learning_rate": 1.761929870814659e-05,
      "loss": 0.2725,
      "step": 3492
    },
    {
      "epoch": 0.20720132874599598,
      "grad_norm": 0.5496971607208252,
      "learning_rate": 1.761798049037701e-05,
      "loss": 0.0084,
      "step": 3493
    },
    {
      "epoch": 0.20726064776367303,
      "grad_norm": 9.41535758972168,
      "learning_rate": 1.7616662272607437e-05,
      "loss": 0.5994,
      "step": 3494
    },
    {
      "epoch": 0.2073199667813501,
      "grad_norm": 25.991455078125,
      "learning_rate": 1.761534405483786e-05,
      "loss": 0.4949,
      "step": 3495
    },
    {
      "epoch": 0.20737928579902717,
      "grad_norm": 0.3730755150318146,
      "learning_rate": 1.7614025837068285e-05,
      "loss": 0.0039,
      "step": 3496
    },
    {
      "epoch": 0.20743860481670423,
      "grad_norm": 0.05491689220070839,
      "learning_rate": 1.761270761929871e-05,
      "loss": 0.0012,
      "step": 3497
    },
    {
      "epoch": 0.20749792383438131,
      "grad_norm": 9.618546485900879,
      "learning_rate": 1.7611389401529133e-05,
      "loss": 0.1963,
      "step": 3498
    },
    {
      "epoch": 0.20755724285205837,
      "grad_norm": 12.732294082641602,
      "learning_rate": 1.761007118375956e-05,
      "loss": 0.1505,
      "step": 3499
    },
    {
      "epoch": 0.20761656186973543,
      "grad_norm": 8.057024002075195,
      "learning_rate": 1.7608752965989985e-05,
      "loss": 0.0882,
      "step": 3500
    },
    {
      "epoch": 0.2076758808874125,
      "grad_norm": 0.049349863082170486,
      "learning_rate": 1.7607434748220408e-05,
      "loss": 0.0012,
      "step": 3501
    },
    {
      "epoch": 0.20773519990508957,
      "grad_norm": 8.44499683380127,
      "learning_rate": 1.760611653045083e-05,
      "loss": 0.136,
      "step": 3502
    },
    {
      "epoch": 0.20779451892276665,
      "grad_norm": 23.36975860595703,
      "learning_rate": 1.7604798312681256e-05,
      "loss": 0.3638,
      "step": 3503
    },
    {
      "epoch": 0.2078538379404437,
      "grad_norm": 0.9193611741065979,
      "learning_rate": 1.760348009491168e-05,
      "loss": 0.011,
      "step": 3504
    },
    {
      "epoch": 0.20791315695812077,
      "grad_norm": 0.19180473685264587,
      "learning_rate": 1.7602161877142104e-05,
      "loss": 0.0023,
      "step": 3505
    },
    {
      "epoch": 0.20797247597579785,
      "grad_norm": 1.241986632347107,
      "learning_rate": 1.760084365937253e-05,
      "loss": 0.0057,
      "step": 3506
    },
    {
      "epoch": 0.2080317949934749,
      "grad_norm": 0.026779010891914368,
      "learning_rate": 1.7599525441602953e-05,
      "loss": 0.0007,
      "step": 3507
    },
    {
      "epoch": 0.20809111401115196,
      "grad_norm": 0.273050457239151,
      "learning_rate": 1.759820722383338e-05,
      "loss": 0.0019,
      "step": 3508
    },
    {
      "epoch": 0.20815043302882905,
      "grad_norm": 26.471731185913086,
      "learning_rate": 1.7596889006063805e-05,
      "loss": 0.1914,
      "step": 3509
    },
    {
      "epoch": 0.2082097520465061,
      "grad_norm": 7.580449104309082,
      "learning_rate": 1.7595570788294227e-05,
      "loss": 0.0841,
      "step": 3510
    },
    {
      "epoch": 0.2082690710641832,
      "grad_norm": 0.4156653583049774,
      "learning_rate": 1.7594252570524653e-05,
      "loss": 0.0036,
      "step": 3511
    },
    {
      "epoch": 0.20832839008186024,
      "grad_norm": 10.269477844238281,
      "learning_rate": 1.7592934352755075e-05,
      "loss": 0.3865,
      "step": 3512
    },
    {
      "epoch": 0.2083877090995373,
      "grad_norm": 17.879104614257812,
      "learning_rate": 1.75916161349855e-05,
      "loss": 0.5788,
      "step": 3513
    },
    {
      "epoch": 0.20844702811721438,
      "grad_norm": 0.040455274283885956,
      "learning_rate": 1.7590297917215927e-05,
      "loss": 0.0008,
      "step": 3514
    },
    {
      "epoch": 0.20850634713489144,
      "grad_norm": 12.756084442138672,
      "learning_rate": 1.758897969944635e-05,
      "loss": 0.0774,
      "step": 3515
    },
    {
      "epoch": 0.20856566615256852,
      "grad_norm": 72.1214370727539,
      "learning_rate": 1.7587661481676776e-05,
      "loss": 0.4569,
      "step": 3516
    },
    {
      "epoch": 0.20862498517024558,
      "grad_norm": 11.106465339660645,
      "learning_rate": 1.7586343263907198e-05,
      "loss": 0.2086,
      "step": 3517
    },
    {
      "epoch": 0.20868430418792264,
      "grad_norm": 2.9143640995025635,
      "learning_rate": 1.7585025046137624e-05,
      "loss": 0.0249,
      "step": 3518
    },
    {
      "epoch": 0.20874362320559972,
      "grad_norm": 0.07631435245275497,
      "learning_rate": 1.7583706828368046e-05,
      "loss": 0.0026,
      "step": 3519
    },
    {
      "epoch": 0.20880294222327678,
      "grad_norm": 4.270875453948975,
      "learning_rate": 1.7582388610598472e-05,
      "loss": 0.0058,
      "step": 3520
    },
    {
      "epoch": 0.20886226124095386,
      "grad_norm": 2.0932633876800537,
      "learning_rate": 1.7581070392828895e-05,
      "loss": 0.0187,
      "step": 3521
    },
    {
      "epoch": 0.20892158025863092,
      "grad_norm": 9.332110404968262,
      "learning_rate": 1.757975217505932e-05,
      "loss": 0.082,
      "step": 3522
    },
    {
      "epoch": 0.20898089927630797,
      "grad_norm": 0.5423348546028137,
      "learning_rate": 1.7578433957289747e-05,
      "loss": 0.0039,
      "step": 3523
    },
    {
      "epoch": 0.20904021829398506,
      "grad_norm": 41.76075744628906,
      "learning_rate": 1.757711573952017e-05,
      "loss": 0.124,
      "step": 3524
    },
    {
      "epoch": 0.20909953731166211,
      "grad_norm": 0.0863637924194336,
      "learning_rate": 1.7575797521750595e-05,
      "loss": 0.0024,
      "step": 3525
    },
    {
      "epoch": 0.2091588563293392,
      "grad_norm": 2.570749282836914,
      "learning_rate": 1.757447930398102e-05,
      "loss": 0.0225,
      "step": 3526
    },
    {
      "epoch": 0.20921817534701626,
      "grad_norm": 26.063446044921875,
      "learning_rate": 1.7573161086211443e-05,
      "loss": 0.3504,
      "step": 3527
    },
    {
      "epoch": 0.2092774943646933,
      "grad_norm": 20.630464553833008,
      "learning_rate": 1.757184286844187e-05,
      "loss": 0.7524,
      "step": 3528
    },
    {
      "epoch": 0.2093368133823704,
      "grad_norm": 0.7418919205665588,
      "learning_rate": 1.7570524650672292e-05,
      "loss": 0.0119,
      "step": 3529
    },
    {
      "epoch": 0.20939613240004745,
      "grad_norm": 5.444119453430176,
      "learning_rate": 1.7569206432902718e-05,
      "loss": 0.2341,
      "step": 3530
    },
    {
      "epoch": 0.20945545141772454,
      "grad_norm": 19.057315826416016,
      "learning_rate": 1.7567888215133144e-05,
      "loss": 0.2541,
      "step": 3531
    },
    {
      "epoch": 0.2095147704354016,
      "grad_norm": 18.13307762145996,
      "learning_rate": 1.7566569997363566e-05,
      "loss": 0.1318,
      "step": 3532
    },
    {
      "epoch": 0.20957408945307865,
      "grad_norm": 0.4831653833389282,
      "learning_rate": 1.7565251779593992e-05,
      "loss": 0.0068,
      "step": 3533
    },
    {
      "epoch": 0.20963340847075573,
      "grad_norm": 0.018408723175525665,
      "learning_rate": 1.7563933561824414e-05,
      "loss": 0.0005,
      "step": 3534
    },
    {
      "epoch": 0.2096927274884328,
      "grad_norm": 7.862426280975342,
      "learning_rate": 1.756261534405484e-05,
      "loss": 0.0573,
      "step": 3535
    },
    {
      "epoch": 0.20975204650610985,
      "grad_norm": 0.11901035159826279,
      "learning_rate": 1.7561297126285263e-05,
      "loss": 0.0023,
      "step": 3536
    },
    {
      "epoch": 0.20981136552378693,
      "grad_norm": 1.3075449466705322,
      "learning_rate": 1.755997890851569e-05,
      "loss": 0.0145,
      "step": 3537
    },
    {
      "epoch": 0.209870684541464,
      "grad_norm": 41.47633361816406,
      "learning_rate": 1.755866069074611e-05,
      "loss": 2.5713,
      "step": 3538
    },
    {
      "epoch": 0.20993000355914107,
      "grad_norm": 4.2444024085998535,
      "learning_rate": 1.7557342472976537e-05,
      "loss": 0.1125,
      "step": 3539
    },
    {
      "epoch": 0.20998932257681813,
      "grad_norm": 7.508358955383301,
      "learning_rate": 1.7556024255206963e-05,
      "loss": 0.4031,
      "step": 3540
    },
    {
      "epoch": 0.21004864159449518,
      "grad_norm": 1.6476385593414307,
      "learning_rate": 1.7554706037437385e-05,
      "loss": 0.0208,
      "step": 3541
    },
    {
      "epoch": 0.21010796061217227,
      "grad_norm": 22.78648567199707,
      "learning_rate": 1.755338781966781e-05,
      "loss": 0.499,
      "step": 3542
    },
    {
      "epoch": 0.21016727962984932,
      "grad_norm": 1.1183743476867676,
      "learning_rate": 1.7552069601898234e-05,
      "loss": 0.0063,
      "step": 3543
    },
    {
      "epoch": 0.2102265986475264,
      "grad_norm": 8.226358413696289,
      "learning_rate": 1.755075138412866e-05,
      "loss": 0.4761,
      "step": 3544
    },
    {
      "epoch": 0.21028591766520346,
      "grad_norm": 0.2187545895576477,
      "learning_rate": 1.7549433166359086e-05,
      "loss": 0.0016,
      "step": 3545
    },
    {
      "epoch": 0.21034523668288052,
      "grad_norm": 15.163520812988281,
      "learning_rate": 1.7548114948589508e-05,
      "loss": 0.2087,
      "step": 3546
    },
    {
      "epoch": 0.2104045557005576,
      "grad_norm": 2.842169761657715,
      "learning_rate": 1.7546796730819934e-05,
      "loss": 0.0204,
      "step": 3547
    },
    {
      "epoch": 0.21046387471823466,
      "grad_norm": 12.949384689331055,
      "learning_rate": 1.7545478513050356e-05,
      "loss": 0.0878,
      "step": 3548
    },
    {
      "epoch": 0.21052319373591175,
      "grad_norm": 11.26627254486084,
      "learning_rate": 1.7544160295280782e-05,
      "loss": 0.3035,
      "step": 3549
    },
    {
      "epoch": 0.2105825127535888,
      "grad_norm": 10.617331504821777,
      "learning_rate": 1.7542842077511205e-05,
      "loss": 0.402,
      "step": 3550
    },
    {
      "epoch": 0.21064183177126586,
      "grad_norm": 16.541318893432617,
      "learning_rate": 1.754152385974163e-05,
      "loss": 0.134,
      "step": 3551
    },
    {
      "epoch": 0.21070115078894294,
      "grad_norm": 11.573843955993652,
      "learning_rate": 1.7540205641972053e-05,
      "loss": 0.0517,
      "step": 3552
    },
    {
      "epoch": 0.21076046980662,
      "grad_norm": 29.721704483032227,
      "learning_rate": 1.753888742420248e-05,
      "loss": 0.5721,
      "step": 3553
    },
    {
      "epoch": 0.21081978882429708,
      "grad_norm": 14.107161521911621,
      "learning_rate": 1.7537569206432905e-05,
      "loss": 0.2206,
      "step": 3554
    },
    {
      "epoch": 0.21087910784197414,
      "grad_norm": 0.07041297852993011,
      "learning_rate": 1.7536250988663327e-05,
      "loss": 0.0017,
      "step": 3555
    },
    {
      "epoch": 0.2109384268596512,
      "grad_norm": 0.3562193810939789,
      "learning_rate": 1.7534932770893753e-05,
      "loss": 0.0064,
      "step": 3556
    },
    {
      "epoch": 0.21099774587732828,
      "grad_norm": 0.20808961987495422,
      "learning_rate": 1.753361455312418e-05,
      "loss": 0.0031,
      "step": 3557
    },
    {
      "epoch": 0.21105706489500534,
      "grad_norm": 7.4608869552612305,
      "learning_rate": 1.75322963353546e-05,
      "loss": 0.1902,
      "step": 3558
    },
    {
      "epoch": 0.2111163839126824,
      "grad_norm": 10.659538269042969,
      "learning_rate": 1.7530978117585028e-05,
      "loss": 0.3043,
      "step": 3559
    },
    {
      "epoch": 0.21117570293035948,
      "grad_norm": 13.813658714294434,
      "learning_rate": 1.752965989981545e-05,
      "loss": 0.5413,
      "step": 3560
    },
    {
      "epoch": 0.21123502194803653,
      "grad_norm": 10.947230339050293,
      "learning_rate": 1.7528341682045876e-05,
      "loss": 0.7163,
      "step": 3561
    },
    {
      "epoch": 0.21129434096571362,
      "grad_norm": 12.554815292358398,
      "learning_rate": 1.7527023464276302e-05,
      "loss": 0.6535,
      "step": 3562
    },
    {
      "epoch": 0.21135365998339067,
      "grad_norm": 27.375030517578125,
      "learning_rate": 1.7525705246506724e-05,
      "loss": 0.5609,
      "step": 3563
    },
    {
      "epoch": 0.21141297900106773,
      "grad_norm": 4.462935447692871,
      "learning_rate": 1.752438702873715e-05,
      "loss": 0.1395,
      "step": 3564
    },
    {
      "epoch": 0.21147229801874481,
      "grad_norm": 2.8020787239074707,
      "learning_rate": 1.7523068810967573e-05,
      "loss": 0.0328,
      "step": 3565
    },
    {
      "epoch": 0.21153161703642187,
      "grad_norm": 1.25948166847229,
      "learning_rate": 1.7521750593198e-05,
      "loss": 0.0095,
      "step": 3566
    },
    {
      "epoch": 0.21159093605409895,
      "grad_norm": 7.831218242645264,
      "learning_rate": 1.752043237542842e-05,
      "loss": 0.4377,
      "step": 3567
    },
    {
      "epoch": 0.211650255071776,
      "grad_norm": 4.790523052215576,
      "learning_rate": 1.7519114157658847e-05,
      "loss": 0.0394,
      "step": 3568
    },
    {
      "epoch": 0.21170957408945307,
      "grad_norm": 0.1274624615907669,
      "learning_rate": 1.751779593988927e-05,
      "loss": 0.0019,
      "step": 3569
    },
    {
      "epoch": 0.21176889310713015,
      "grad_norm": 2.157252073287964,
      "learning_rate": 1.7516477722119695e-05,
      "loss": 0.0253,
      "step": 3570
    },
    {
      "epoch": 0.2118282121248072,
      "grad_norm": 7.853305816650391,
      "learning_rate": 1.751515950435012e-05,
      "loss": 0.0744,
      "step": 3571
    },
    {
      "epoch": 0.2118875311424843,
      "grad_norm": 3.270491361618042,
      "learning_rate": 1.7513841286580544e-05,
      "loss": 0.0303,
      "step": 3572
    },
    {
      "epoch": 0.21194685016016135,
      "grad_norm": 5.326467990875244,
      "learning_rate": 1.751252306881097e-05,
      "loss": 0.2359,
      "step": 3573
    },
    {
      "epoch": 0.2120061691778384,
      "grad_norm": 9.565014839172363,
      "learning_rate": 1.7511204851041395e-05,
      "loss": 0.1686,
      "step": 3574
    },
    {
      "epoch": 0.2120654881955155,
      "grad_norm": 36.44107437133789,
      "learning_rate": 1.7509886633271818e-05,
      "loss": 0.7488,
      "step": 3575
    },
    {
      "epoch": 0.21212480721319255,
      "grad_norm": 1.4407143592834473,
      "learning_rate": 1.7508568415502244e-05,
      "loss": 0.0165,
      "step": 3576
    },
    {
      "epoch": 0.21218412623086963,
      "grad_norm": 11.735971450805664,
      "learning_rate": 1.7507250197732666e-05,
      "loss": 0.7308,
      "step": 3577
    },
    {
      "epoch": 0.21224344524854669,
      "grad_norm": 51.285701751708984,
      "learning_rate": 1.7505931979963092e-05,
      "loss": 1.1562,
      "step": 3578
    },
    {
      "epoch": 0.21230276426622374,
      "grad_norm": 0.028828129172325134,
      "learning_rate": 1.7504613762193518e-05,
      "loss": 0.0008,
      "step": 3579
    },
    {
      "epoch": 0.21236208328390083,
      "grad_norm": 0.9421148300170898,
      "learning_rate": 1.750329554442394e-05,
      "loss": 0.0133,
      "step": 3580
    },
    {
      "epoch": 0.21242140230157788,
      "grad_norm": 0.23923476040363312,
      "learning_rate": 1.7501977326654363e-05,
      "loss": 0.0033,
      "step": 3581
    },
    {
      "epoch": 0.21248072131925494,
      "grad_norm": 0.13815937936306,
      "learning_rate": 1.750065910888479e-05,
      "loss": 0.0034,
      "step": 3582
    },
    {
      "epoch": 0.21254004033693202,
      "grad_norm": 5.872347831726074,
      "learning_rate": 1.749934089111521e-05,
      "loss": 0.0419,
      "step": 3583
    },
    {
      "epoch": 0.21259935935460908,
      "grad_norm": 14.959986686706543,
      "learning_rate": 1.7498022673345637e-05,
      "loss": 0.4172,
      "step": 3584
    },
    {
      "epoch": 0.21265867837228616,
      "grad_norm": 2.396949052810669,
      "learning_rate": 1.7496704455576063e-05,
      "loss": 0.0236,
      "step": 3585
    },
    {
      "epoch": 0.21271799738996322,
      "grad_norm": 26.446380615234375,
      "learning_rate": 1.7495386237806486e-05,
      "loss": 0.9676,
      "step": 3586
    },
    {
      "epoch": 0.21277731640764028,
      "grad_norm": 9.731740951538086,
      "learning_rate": 1.749406802003691e-05,
      "loss": 0.3486,
      "step": 3587
    },
    {
      "epoch": 0.21283663542531736,
      "grad_norm": 0.17872267961502075,
      "learning_rate": 1.7492749802267337e-05,
      "loss": 0.003,
      "step": 3588
    },
    {
      "epoch": 0.21289595444299442,
      "grad_norm": 31.36427116394043,
      "learning_rate": 1.749143158449776e-05,
      "loss": 0.2001,
      "step": 3589
    },
    {
      "epoch": 0.2129552734606715,
      "grad_norm": 0.02669457346200943,
      "learning_rate": 1.7490113366728186e-05,
      "loss": 0.0007,
      "step": 3590
    },
    {
      "epoch": 0.21301459247834856,
      "grad_norm": 15.970100402832031,
      "learning_rate": 1.7488795148958608e-05,
      "loss": 1.1289,
      "step": 3591
    },
    {
      "epoch": 0.21307391149602561,
      "grad_norm": 0.030941052362322807,
      "learning_rate": 1.7487476931189034e-05,
      "loss": 0.0006,
      "step": 3592
    },
    {
      "epoch": 0.2131332305137027,
      "grad_norm": 0.1207442581653595,
      "learning_rate": 1.748615871341946e-05,
      "loss": 0.0013,
      "step": 3593
    },
    {
      "epoch": 0.21319254953137975,
      "grad_norm": 2.0253775119781494,
      "learning_rate": 1.7484840495649883e-05,
      "loss": 0.0206,
      "step": 3594
    },
    {
      "epoch": 0.21325186854905684,
      "grad_norm": 1.7012470960617065,
      "learning_rate": 1.748352227788031e-05,
      "loss": 0.0179,
      "step": 3595
    },
    {
      "epoch": 0.2133111875667339,
      "grad_norm": 12.195453643798828,
      "learning_rate": 1.748220406011073e-05,
      "loss": 0.6091,
      "step": 3596
    },
    {
      "epoch": 0.21337050658441095,
      "grad_norm": 1.6228594779968262,
      "learning_rate": 1.7480885842341157e-05,
      "loss": 0.0168,
      "step": 3597
    },
    {
      "epoch": 0.21342982560208804,
      "grad_norm": 2.3601233959198,
      "learning_rate": 1.747956762457158e-05,
      "loss": 0.0232,
      "step": 3598
    },
    {
      "epoch": 0.2134891446197651,
      "grad_norm": 8.69034194946289,
      "learning_rate": 1.7478249406802005e-05,
      "loss": 0.4955,
      "step": 3599
    },
    {
      "epoch": 0.21354846363744218,
      "grad_norm": 4.287783622741699,
      "learning_rate": 1.7476931189032428e-05,
      "loss": 0.0709,
      "step": 3600
    },
    {
      "epoch": 0.21360778265511923,
      "grad_norm": 1.2813371419906616,
      "learning_rate": 1.7475612971262854e-05,
      "loss": 0.0152,
      "step": 3601
    },
    {
      "epoch": 0.2136671016727963,
      "grad_norm": 2.0804975032806396,
      "learning_rate": 1.747429475349328e-05,
      "loss": 0.0199,
      "step": 3602
    },
    {
      "epoch": 0.21372642069047337,
      "grad_norm": 0.40115731954574585,
      "learning_rate": 1.7472976535723702e-05,
      "loss": 0.005,
      "step": 3603
    },
    {
      "epoch": 0.21378573970815043,
      "grad_norm": 0.38335680961608887,
      "learning_rate": 1.7471658317954128e-05,
      "loss": 0.0042,
      "step": 3604
    },
    {
      "epoch": 0.2138450587258275,
      "grad_norm": 10.628254890441895,
      "learning_rate": 1.7470340100184554e-05,
      "loss": 0.8436,
      "step": 3605
    },
    {
      "epoch": 0.21390437774350457,
      "grad_norm": 14.522725105285645,
      "learning_rate": 1.7469021882414976e-05,
      "loss": 0.5994,
      "step": 3606
    },
    {
      "epoch": 0.21396369676118163,
      "grad_norm": 0.3352687656879425,
      "learning_rate": 1.7467703664645402e-05,
      "loss": 0.0053,
      "step": 3607
    },
    {
      "epoch": 0.2140230157788587,
      "grad_norm": 4.449919700622559,
      "learning_rate": 1.7466385446875825e-05,
      "loss": 0.105,
      "step": 3608
    },
    {
      "epoch": 0.21408233479653577,
      "grad_norm": 0.031121129170060158,
      "learning_rate": 1.746506722910625e-05,
      "loss": 0.0009,
      "step": 3609
    },
    {
      "epoch": 0.21414165381421282,
      "grad_norm": 7.3600664138793945,
      "learning_rate": 1.7463749011336676e-05,
      "loss": 0.7746,
      "step": 3610
    },
    {
      "epoch": 0.2142009728318899,
      "grad_norm": 0.5295065641403198,
      "learning_rate": 1.74624307935671e-05,
      "loss": 0.0043,
      "step": 3611
    },
    {
      "epoch": 0.21426029184956696,
      "grad_norm": 0.9553463459014893,
      "learning_rate": 1.7461112575797525e-05,
      "loss": 0.0081,
      "step": 3612
    },
    {
      "epoch": 0.21431961086724405,
      "grad_norm": 0.12055202573537827,
      "learning_rate": 1.7459794358027947e-05,
      "loss": 0.0025,
      "step": 3613
    },
    {
      "epoch": 0.2143789298849211,
      "grad_norm": 23.29337501525879,
      "learning_rate": 1.745847614025837e-05,
      "loss": 0.251,
      "step": 3614
    },
    {
      "epoch": 0.21443824890259816,
      "grad_norm": 23.954116821289062,
      "learning_rate": 1.7457157922488796e-05,
      "loss": 0.5674,
      "step": 3615
    },
    {
      "epoch": 0.21449756792027524,
      "grad_norm": 13.074515342712402,
      "learning_rate": 1.745583970471922e-05,
      "loss": 0.0289,
      "step": 3616
    },
    {
      "epoch": 0.2145568869379523,
      "grad_norm": 5.137783527374268,
      "learning_rate": 1.7454521486949644e-05,
      "loss": 0.116,
      "step": 3617
    },
    {
      "epoch": 0.21461620595562939,
      "grad_norm": 10.9149751663208,
      "learning_rate": 1.745320326918007e-05,
      "loss": 0.0401,
      "step": 3618
    },
    {
      "epoch": 0.21467552497330644,
      "grad_norm": 0.7109373807907104,
      "learning_rate": 1.7451885051410496e-05,
      "loss": 0.0103,
      "step": 3619
    },
    {
      "epoch": 0.2147348439909835,
      "grad_norm": 0.9470521211624146,
      "learning_rate": 1.7450566833640918e-05,
      "loss": 0.0125,
      "step": 3620
    },
    {
      "epoch": 0.21479416300866058,
      "grad_norm": 0.565338671207428,
      "learning_rate": 1.7449248615871344e-05,
      "loss": 0.0064,
      "step": 3621
    },
    {
      "epoch": 0.21485348202633764,
      "grad_norm": 6.373342037200928,
      "learning_rate": 1.744793039810177e-05,
      "loss": 0.0423,
      "step": 3622
    },
    {
      "epoch": 0.21491280104401472,
      "grad_norm": 0.03138073533773422,
      "learning_rate": 1.7446612180332192e-05,
      "loss": 0.0007,
      "step": 3623
    },
    {
      "epoch": 0.21497212006169178,
      "grad_norm": 11.153059959411621,
      "learning_rate": 1.744529396256262e-05,
      "loss": 0.1452,
      "step": 3624
    },
    {
      "epoch": 0.21503143907936884,
      "grad_norm": 0.05493492633104324,
      "learning_rate": 1.744397574479304e-05,
      "loss": 0.0006,
      "step": 3625
    },
    {
      "epoch": 0.21509075809704592,
      "grad_norm": 0.5497165322303772,
      "learning_rate": 1.7442657527023467e-05,
      "loss": 0.0074,
      "step": 3626
    },
    {
      "epoch": 0.21515007711472298,
      "grad_norm": 0.3223719596862793,
      "learning_rate": 1.744133930925389e-05,
      "loss": 0.0026,
      "step": 3627
    },
    {
      "epoch": 0.21520939613240006,
      "grad_norm": 6.4597554206848145,
      "learning_rate": 1.7440021091484315e-05,
      "loss": 0.1428,
      "step": 3628
    },
    {
      "epoch": 0.21526871515007712,
      "grad_norm": 11.88485050201416,
      "learning_rate": 1.7438702873714738e-05,
      "loss": 0.8617,
      "step": 3629
    },
    {
      "epoch": 0.21532803416775417,
      "grad_norm": 0.2096318006515503,
      "learning_rate": 1.7437384655945163e-05,
      "loss": 0.0033,
      "step": 3630
    },
    {
      "epoch": 0.21538735318543126,
      "grad_norm": 3.208432197570801,
      "learning_rate": 1.7436066438175586e-05,
      "loss": 0.0151,
      "step": 3631
    },
    {
      "epoch": 0.2154466722031083,
      "grad_norm": 1.8168810606002808,
      "learning_rate": 1.7434748220406012e-05,
      "loss": 0.0227,
      "step": 3632
    },
    {
      "epoch": 0.21550599122078537,
      "grad_norm": 2.746319055557251,
      "learning_rate": 1.7433430002636438e-05,
      "loss": 0.0147,
      "step": 3633
    },
    {
      "epoch": 0.21556531023846245,
      "grad_norm": 0.9271332025527954,
      "learning_rate": 1.743211178486686e-05,
      "loss": 0.0059,
      "step": 3634
    },
    {
      "epoch": 0.2156246292561395,
      "grad_norm": 17.887187957763672,
      "learning_rate": 1.7430793567097286e-05,
      "loss": 0.647,
      "step": 3635
    },
    {
      "epoch": 0.2156839482738166,
      "grad_norm": 24.2377986907959,
      "learning_rate": 1.7429475349327712e-05,
      "loss": 0.6013,
      "step": 3636
    },
    {
      "epoch": 0.21574326729149365,
      "grad_norm": 3.04111385345459,
      "learning_rate": 1.7428157131558134e-05,
      "loss": 0.0571,
      "step": 3637
    },
    {
      "epoch": 0.2158025863091707,
      "grad_norm": 4.067511081695557,
      "learning_rate": 1.742683891378856e-05,
      "loss": 0.0213,
      "step": 3638
    },
    {
      "epoch": 0.2158619053268478,
      "grad_norm": 1.5213146209716797,
      "learning_rate": 1.7425520696018983e-05,
      "loss": 0.011,
      "step": 3639
    },
    {
      "epoch": 0.21592122434452485,
      "grad_norm": 0.43403056263923645,
      "learning_rate": 1.742420247824941e-05,
      "loss": 0.0038,
      "step": 3640
    },
    {
      "epoch": 0.21598054336220193,
      "grad_norm": 2.5905771255493164,
      "learning_rate": 1.7422884260479835e-05,
      "loss": 0.037,
      "step": 3641
    },
    {
      "epoch": 0.216039862379879,
      "grad_norm": 1.1143473386764526,
      "learning_rate": 1.7421566042710257e-05,
      "loss": 0.0094,
      "step": 3642
    },
    {
      "epoch": 0.21609918139755604,
      "grad_norm": 9.17082405090332,
      "learning_rate": 1.7420247824940683e-05,
      "loss": 0.3224,
      "step": 3643
    },
    {
      "epoch": 0.21615850041523313,
      "grad_norm": 5.379824638366699,
      "learning_rate": 1.7418929607171105e-05,
      "loss": 0.1261,
      "step": 3644
    },
    {
      "epoch": 0.21621781943291019,
      "grad_norm": 0.10824029892683029,
      "learning_rate": 1.741761138940153e-05,
      "loss": 0.0024,
      "step": 3645
    },
    {
      "epoch": 0.21627713845058727,
      "grad_norm": 11.645341873168945,
      "learning_rate": 1.7416293171631954e-05,
      "loss": 0.551,
      "step": 3646
    },
    {
      "epoch": 0.21633645746826433,
      "grad_norm": 2.578706741333008,
      "learning_rate": 1.741497495386238e-05,
      "loss": 0.0131,
      "step": 3647
    },
    {
      "epoch": 0.21639577648594138,
      "grad_norm": 5.656957626342773,
      "learning_rate": 1.7413656736092802e-05,
      "loss": 0.0621,
      "step": 3648
    },
    {
      "epoch": 0.21645509550361847,
      "grad_norm": 0.08162123709917068,
      "learning_rate": 1.7412338518323228e-05,
      "loss": 0.0018,
      "step": 3649
    },
    {
      "epoch": 0.21651441452129552,
      "grad_norm": 16.520511627197266,
      "learning_rate": 1.7411020300553654e-05,
      "loss": 0.4884,
      "step": 3650
    },
    {
      "epoch": 0.2165737335389726,
      "grad_norm": 7.505498886108398,
      "learning_rate": 1.7409702082784076e-05,
      "loss": 0.248,
      "step": 3651
    },
    {
      "epoch": 0.21663305255664966,
      "grad_norm": 21.62251091003418,
      "learning_rate": 1.7408383865014502e-05,
      "loss": 0.5074,
      "step": 3652
    },
    {
      "epoch": 0.21669237157432672,
      "grad_norm": 3.1031556129455566,
      "learning_rate": 1.7407065647244928e-05,
      "loss": 0.1134,
      "step": 3653
    },
    {
      "epoch": 0.2167516905920038,
      "grad_norm": 6.330048561096191,
      "learning_rate": 1.740574742947535e-05,
      "loss": 0.2361,
      "step": 3654
    },
    {
      "epoch": 0.21681100960968086,
      "grad_norm": 1.3091139793395996,
      "learning_rate": 1.7404429211705777e-05,
      "loss": 0.0272,
      "step": 3655
    },
    {
      "epoch": 0.21687032862735794,
      "grad_norm": 0.15946875512599945,
      "learning_rate": 1.74031109939362e-05,
      "loss": 0.0024,
      "step": 3656
    },
    {
      "epoch": 0.216929647645035,
      "grad_norm": 8.631583213806152,
      "learning_rate": 1.7401792776166625e-05,
      "loss": 0.0901,
      "step": 3657
    },
    {
      "epoch": 0.21698896666271206,
      "grad_norm": 0.17851611971855164,
      "learning_rate": 1.7400474558397047e-05,
      "loss": 0.0031,
      "step": 3658
    },
    {
      "epoch": 0.21704828568038914,
      "grad_norm": 15.967376708984375,
      "learning_rate": 1.7399156340627473e-05,
      "loss": 0.3749,
      "step": 3659
    },
    {
      "epoch": 0.2171076046980662,
      "grad_norm": 0.49099189043045044,
      "learning_rate": 1.7397838122857896e-05,
      "loss": 0.0039,
      "step": 3660
    },
    {
      "epoch": 0.21716692371574325,
      "grad_norm": 10.259232521057129,
      "learning_rate": 1.7396519905088322e-05,
      "loss": 0.2372,
      "step": 3661
    },
    {
      "epoch": 0.21722624273342034,
      "grad_norm": 0.3294295072555542,
      "learning_rate": 1.7395201687318744e-05,
      "loss": 0.0035,
      "step": 3662
    },
    {
      "epoch": 0.2172855617510974,
      "grad_norm": 6.006886005401611,
      "learning_rate": 1.739388346954917e-05,
      "loss": 0.3513,
      "step": 3663
    },
    {
      "epoch": 0.21734488076877448,
      "grad_norm": 26.157995223999023,
      "learning_rate": 1.7392565251779596e-05,
      "loss": 1.1683,
      "step": 3664
    },
    {
      "epoch": 0.21740419978645154,
      "grad_norm": 0.10347332805395126,
      "learning_rate": 1.739124703401002e-05,
      "loss": 0.0018,
      "step": 3665
    },
    {
      "epoch": 0.2174635188041286,
      "grad_norm": 3.736074447631836,
      "learning_rate": 1.7389928816240444e-05,
      "loss": 0.0735,
      "step": 3666
    },
    {
      "epoch": 0.21752283782180568,
      "grad_norm": 2.0014305114746094,
      "learning_rate": 1.738861059847087e-05,
      "loss": 0.012,
      "step": 3667
    },
    {
      "epoch": 0.21758215683948273,
      "grad_norm": 6.807994842529297,
      "learning_rate": 1.7387292380701293e-05,
      "loss": 0.0818,
      "step": 3668
    },
    {
      "epoch": 0.21764147585715982,
      "grad_norm": 1.4081838130950928,
      "learning_rate": 1.738597416293172e-05,
      "loss": 0.0182,
      "step": 3669
    },
    {
      "epoch": 0.21770079487483687,
      "grad_norm": 7.081075191497803,
      "learning_rate": 1.7384655945162144e-05,
      "loss": 0.0896,
      "step": 3670
    },
    {
      "epoch": 0.21776011389251393,
      "grad_norm": 0.4619852900505066,
      "learning_rate": 1.7383337727392567e-05,
      "loss": 0.0058,
      "step": 3671
    },
    {
      "epoch": 0.217819432910191,
      "grad_norm": 0.02639567106962204,
      "learning_rate": 1.7382019509622993e-05,
      "loss": 0.0007,
      "step": 3672
    },
    {
      "epoch": 0.21787875192786807,
      "grad_norm": 2.3585944175720215,
      "learning_rate": 1.7380701291853415e-05,
      "loss": 0.0808,
      "step": 3673
    },
    {
      "epoch": 0.21793807094554515,
      "grad_norm": 16.889041900634766,
      "learning_rate": 1.737938307408384e-05,
      "loss": 0.7688,
      "step": 3674
    },
    {
      "epoch": 0.2179973899632222,
      "grad_norm": 0.041579436510801315,
      "learning_rate": 1.7378064856314264e-05,
      "loss": 0.0006,
      "step": 3675
    },
    {
      "epoch": 0.21805670898089927,
      "grad_norm": 27.66209602355957,
      "learning_rate": 1.737674663854469e-05,
      "loss": 0.8375,
      "step": 3676
    },
    {
      "epoch": 0.21811602799857635,
      "grad_norm": 13.109720230102539,
      "learning_rate": 1.7375428420775112e-05,
      "loss": 0.1316,
      "step": 3677
    },
    {
      "epoch": 0.2181753470162534,
      "grad_norm": 0.35309240221977234,
      "learning_rate": 1.7374110203005538e-05,
      "loss": 0.0029,
      "step": 3678
    },
    {
      "epoch": 0.2182346660339305,
      "grad_norm": 7.087173938751221,
      "learning_rate": 1.737279198523596e-05,
      "loss": 0.307,
      "step": 3679
    },
    {
      "epoch": 0.21829398505160755,
      "grad_norm": 0.13181795179843903,
      "learning_rate": 1.7371473767466386e-05,
      "loss": 0.0013,
      "step": 3680
    },
    {
      "epoch": 0.2183533040692846,
      "grad_norm": 31.92347526550293,
      "learning_rate": 1.7370155549696812e-05,
      "loss": 0.4511,
      "step": 3681
    },
    {
      "epoch": 0.2184126230869617,
      "grad_norm": 0.5546454191207886,
      "learning_rate": 1.7368837331927235e-05,
      "loss": 0.0083,
      "step": 3682
    },
    {
      "epoch": 0.21847194210463874,
      "grad_norm": 0.02224344201385975,
      "learning_rate": 1.736751911415766e-05,
      "loss": 0.0008,
      "step": 3683
    },
    {
      "epoch": 0.2185312611223158,
      "grad_norm": 9.497479438781738,
      "learning_rate": 1.7366200896388086e-05,
      "loss": 0.0745,
      "step": 3684
    },
    {
      "epoch": 0.21859058013999288,
      "grad_norm": 20.62884521484375,
      "learning_rate": 1.736488267861851e-05,
      "loss": 0.8962,
      "step": 3685
    },
    {
      "epoch": 0.21864989915766994,
      "grad_norm": 8.674654006958008,
      "learning_rate": 1.7363564460848935e-05,
      "loss": 0.1248,
      "step": 3686
    },
    {
      "epoch": 0.21870921817534703,
      "grad_norm": 13.279129981994629,
      "learning_rate": 1.7362246243079357e-05,
      "loss": 0.3796,
      "step": 3687
    },
    {
      "epoch": 0.21876853719302408,
      "grad_norm": 3.3074214458465576,
      "learning_rate": 1.7360928025309783e-05,
      "loss": 0.0357,
      "step": 3688
    },
    {
      "epoch": 0.21882785621070114,
      "grad_norm": 5.945619106292725,
      "learning_rate": 1.735960980754021e-05,
      "loss": 0.0475,
      "step": 3689
    },
    {
      "epoch": 0.21888717522837822,
      "grad_norm": 0.05059056356549263,
      "learning_rate": 1.735829158977063e-05,
      "loss": 0.0012,
      "step": 3690
    },
    {
      "epoch": 0.21894649424605528,
      "grad_norm": 7.025219917297363,
      "learning_rate": 1.7356973372001057e-05,
      "loss": 0.16,
      "step": 3691
    },
    {
      "epoch": 0.21900581326373236,
      "grad_norm": 12.552149772644043,
      "learning_rate": 1.735565515423148e-05,
      "loss": 0.2846,
      "step": 3692
    },
    {
      "epoch": 0.21906513228140942,
      "grad_norm": 8.099175453186035,
      "learning_rate": 1.7354336936461902e-05,
      "loss": 0.0591,
      "step": 3693
    },
    {
      "epoch": 0.21912445129908648,
      "grad_norm": 1.5552031993865967,
      "learning_rate": 1.735301871869233e-05,
      "loss": 0.0077,
      "step": 3694
    },
    {
      "epoch": 0.21918377031676356,
      "grad_norm": 0.037554990500211716,
      "learning_rate": 1.7351700500922754e-05,
      "loss": 0.0008,
      "step": 3695
    },
    {
      "epoch": 0.21924308933444062,
      "grad_norm": 0.060765452682971954,
      "learning_rate": 1.7350382283153177e-05,
      "loss": 0.001,
      "step": 3696
    },
    {
      "epoch": 0.2193024083521177,
      "grad_norm": 0.10174928605556488,
      "learning_rate": 1.7349064065383603e-05,
      "loss": 0.0015,
      "step": 3697
    },
    {
      "epoch": 0.21936172736979476,
      "grad_norm": 10.476298332214355,
      "learning_rate": 1.734774584761403e-05,
      "loss": 0.2005,
      "step": 3698
    },
    {
      "epoch": 0.2194210463874718,
      "grad_norm": 0.2962118983268738,
      "learning_rate": 1.734642762984445e-05,
      "loss": 0.0035,
      "step": 3699
    },
    {
      "epoch": 0.2194803654051489,
      "grad_norm": 35.36664962768555,
      "learning_rate": 1.7345109412074877e-05,
      "loss": 0.3466,
      "step": 3700
    },
    {
      "epoch": 0.21953968442282595,
      "grad_norm": 0.534848690032959,
      "learning_rate": 1.7343791194305303e-05,
      "loss": 0.0057,
      "step": 3701
    },
    {
      "epoch": 0.21959900344050304,
      "grad_norm": 2.84745454788208,
      "learning_rate": 1.7342472976535725e-05,
      "loss": 0.0314,
      "step": 3702
    },
    {
      "epoch": 0.2196583224581801,
      "grad_norm": 15.43644905090332,
      "learning_rate": 1.734115475876615e-05,
      "loss": 0.7861,
      "step": 3703
    },
    {
      "epoch": 0.21971764147585715,
      "grad_norm": 0.09232197701931,
      "learning_rate": 1.7339836540996574e-05,
      "loss": 0.0021,
      "step": 3704
    },
    {
      "epoch": 0.21977696049353423,
      "grad_norm": 1.488068699836731,
      "learning_rate": 1.7338518323227e-05,
      "loss": 0.0107,
      "step": 3705
    },
    {
      "epoch": 0.2198362795112113,
      "grad_norm": 0.07352574169635773,
      "learning_rate": 1.7337200105457422e-05,
      "loss": 0.0017,
      "step": 3706
    },
    {
      "epoch": 0.21989559852888838,
      "grad_norm": 7.1063055992126465,
      "learning_rate": 1.7335881887687848e-05,
      "loss": 0.1389,
      "step": 3707
    },
    {
      "epoch": 0.21995491754656543,
      "grad_norm": 8.387084007263184,
      "learning_rate": 1.733456366991827e-05,
      "loss": 0.2393,
      "step": 3708
    },
    {
      "epoch": 0.2200142365642425,
      "grad_norm": 2.809396743774414,
      "learning_rate": 1.7333245452148696e-05,
      "loss": 0.0671,
      "step": 3709
    },
    {
      "epoch": 0.22007355558191957,
      "grad_norm": 2.696725368499756,
      "learning_rate": 1.733192723437912e-05,
      "loss": 0.0164,
      "step": 3710
    },
    {
      "epoch": 0.22013287459959663,
      "grad_norm": 0.3665415048599243,
      "learning_rate": 1.7330609016609545e-05,
      "loss": 0.0038,
      "step": 3711
    },
    {
      "epoch": 0.22019219361727368,
      "grad_norm": 0.1495387852191925,
      "learning_rate": 1.732929079883997e-05,
      "loss": 0.0021,
      "step": 3712
    },
    {
      "epoch": 0.22025151263495077,
      "grad_norm": 0.03077649138867855,
      "learning_rate": 1.7327972581070393e-05,
      "loss": 0.0007,
      "step": 3713
    },
    {
      "epoch": 0.22031083165262783,
      "grad_norm": 9.676055908203125,
      "learning_rate": 1.732665436330082e-05,
      "loss": 0.2155,
      "step": 3714
    },
    {
      "epoch": 0.2203701506703049,
      "grad_norm": 0.16269917786121368,
      "learning_rate": 1.7325336145531245e-05,
      "loss": 0.0021,
      "step": 3715
    },
    {
      "epoch": 0.22042946968798197,
      "grad_norm": 23.638681411743164,
      "learning_rate": 1.7324017927761667e-05,
      "loss": 0.1744,
      "step": 3716
    },
    {
      "epoch": 0.22048878870565902,
      "grad_norm": 9.193931579589844,
      "learning_rate": 1.7322699709992093e-05,
      "loss": 0.2032,
      "step": 3717
    },
    {
      "epoch": 0.2205481077233361,
      "grad_norm": 9.329374313354492,
      "learning_rate": 1.732138149222252e-05,
      "loss": 0.1368,
      "step": 3718
    },
    {
      "epoch": 0.22060742674101316,
      "grad_norm": 16.61763572692871,
      "learning_rate": 1.732006327445294e-05,
      "loss": 0.4911,
      "step": 3719
    },
    {
      "epoch": 0.22066674575869025,
      "grad_norm": 0.06098698824644089,
      "learning_rate": 1.7318745056683367e-05,
      "loss": 0.001,
      "step": 3720
    },
    {
      "epoch": 0.2207260647763673,
      "grad_norm": 17.16614532470703,
      "learning_rate": 1.731742683891379e-05,
      "loss": 0.0895,
      "step": 3721
    },
    {
      "epoch": 0.22078538379404436,
      "grad_norm": 10.42975902557373,
      "learning_rate": 1.7316108621144216e-05,
      "loss": 0.2165,
      "step": 3722
    },
    {
      "epoch": 0.22084470281172144,
      "grad_norm": 0.2616317570209503,
      "learning_rate": 1.7314790403374638e-05,
      "loss": 0.0037,
      "step": 3723
    },
    {
      "epoch": 0.2209040218293985,
      "grad_norm": 17.80780792236328,
      "learning_rate": 1.7313472185605064e-05,
      "loss": 0.8878,
      "step": 3724
    },
    {
      "epoch": 0.22096334084707558,
      "grad_norm": 32.41586685180664,
      "learning_rate": 1.7312153967835487e-05,
      "loss": 1.4602,
      "step": 3725
    },
    {
      "epoch": 0.22102265986475264,
      "grad_norm": 13.240374565124512,
      "learning_rate": 1.7310835750065913e-05,
      "loss": 0.2726,
      "step": 3726
    },
    {
      "epoch": 0.2210819788824297,
      "grad_norm": 7.0872721672058105,
      "learning_rate": 1.7309517532296335e-05,
      "loss": 0.1696,
      "step": 3727
    },
    {
      "epoch": 0.22114129790010678,
      "grad_norm": 3.8783302307128906,
      "learning_rate": 1.730819931452676e-05,
      "loss": 0.0631,
      "step": 3728
    },
    {
      "epoch": 0.22120061691778384,
      "grad_norm": 61.199649810791016,
      "learning_rate": 1.7306881096757187e-05,
      "loss": 0.5372,
      "step": 3729
    },
    {
      "epoch": 0.22125993593546092,
      "grad_norm": 7.747065544128418,
      "learning_rate": 1.730556287898761e-05,
      "loss": 0.2046,
      "step": 3730
    },
    {
      "epoch": 0.22131925495313798,
      "grad_norm": 8.962252616882324,
      "learning_rate": 1.7304244661218035e-05,
      "loss": 0.68,
      "step": 3731
    },
    {
      "epoch": 0.22137857397081503,
      "grad_norm": 16.3196964263916,
      "learning_rate": 1.730292644344846e-05,
      "loss": 1.0535,
      "step": 3732
    },
    {
      "epoch": 0.22143789298849212,
      "grad_norm": 8.454564094543457,
      "learning_rate": 1.7301608225678884e-05,
      "loss": 0.1246,
      "step": 3733
    },
    {
      "epoch": 0.22149721200616918,
      "grad_norm": 0.012765087187290192,
      "learning_rate": 1.730029000790931e-05,
      "loss": 0.0003,
      "step": 3734
    },
    {
      "epoch": 0.22155653102384623,
      "grad_norm": 23.51006507873535,
      "learning_rate": 1.7298971790139735e-05,
      "loss": 0.5963,
      "step": 3735
    },
    {
      "epoch": 0.22161585004152332,
      "grad_norm": 16.205158233642578,
      "learning_rate": 1.7297653572370158e-05,
      "loss": 0.6159,
      "step": 3736
    },
    {
      "epoch": 0.22167516905920037,
      "grad_norm": 15.050658226013184,
      "learning_rate": 1.729633535460058e-05,
      "loss": 1.4346,
      "step": 3737
    },
    {
      "epoch": 0.22173448807687746,
      "grad_norm": 5.734360218048096,
      "learning_rate": 1.7295017136831006e-05,
      "loss": 0.307,
      "step": 3738
    },
    {
      "epoch": 0.2217938070945545,
      "grad_norm": 14.15830135345459,
      "learning_rate": 1.729369891906143e-05,
      "loss": 0.6834,
      "step": 3739
    },
    {
      "epoch": 0.22185312611223157,
      "grad_norm": 5.0178608894348145,
      "learning_rate": 1.7292380701291855e-05,
      "loss": 0.066,
      "step": 3740
    },
    {
      "epoch": 0.22191244512990865,
      "grad_norm": 11.366517066955566,
      "learning_rate": 1.7291062483522277e-05,
      "loss": 0.0921,
      "step": 3741
    },
    {
      "epoch": 0.2219717641475857,
      "grad_norm": 0.020180800929665565,
      "learning_rate": 1.7289744265752703e-05,
      "loss": 0.0007,
      "step": 3742
    },
    {
      "epoch": 0.2220310831652628,
      "grad_norm": 6.342565536499023,
      "learning_rate": 1.728842604798313e-05,
      "loss": 0.1987,
      "step": 3743
    },
    {
      "epoch": 0.22209040218293985,
      "grad_norm": 6.4444804191589355,
      "learning_rate": 1.728710783021355e-05,
      "loss": 0.2551,
      "step": 3744
    },
    {
      "epoch": 0.2221497212006169,
      "grad_norm": 0.04191581532359123,
      "learning_rate": 1.7285789612443977e-05,
      "loss": 0.001,
      "step": 3745
    },
    {
      "epoch": 0.222209040218294,
      "grad_norm": 8.58938980102539,
      "learning_rate": 1.7284471394674403e-05,
      "loss": 0.4121,
      "step": 3746
    },
    {
      "epoch": 0.22226835923597105,
      "grad_norm": 9.829320907592773,
      "learning_rate": 1.7283153176904826e-05,
      "loss": 0.2364,
      "step": 3747
    },
    {
      "epoch": 0.22232767825364813,
      "grad_norm": 0.48325443267822266,
      "learning_rate": 1.728183495913525e-05,
      "loss": 0.0051,
      "step": 3748
    },
    {
      "epoch": 0.2223869972713252,
      "grad_norm": 1.461945652961731,
      "learning_rate": 1.7280516741365677e-05,
      "loss": 0.0213,
      "step": 3749
    },
    {
      "epoch": 0.22244631628900224,
      "grad_norm": 1.0934821367263794,
      "learning_rate": 1.72791985235961e-05,
      "loss": 0.0221,
      "step": 3750
    },
    {
      "epoch": 0.22250563530667933,
      "grad_norm": 0.40765804052352905,
      "learning_rate": 1.7277880305826526e-05,
      "loss": 0.0045,
      "step": 3751
    },
    {
      "epoch": 0.22256495432435638,
      "grad_norm": 0.09457914531230927,
      "learning_rate": 1.7276562088056948e-05,
      "loss": 0.0021,
      "step": 3752
    },
    {
      "epoch": 0.22262427334203347,
      "grad_norm": 3.474679946899414,
      "learning_rate": 1.7275243870287374e-05,
      "loss": 0.0586,
      "step": 3753
    },
    {
      "epoch": 0.22268359235971052,
      "grad_norm": 0.07243563234806061,
      "learning_rate": 1.7273925652517797e-05,
      "loss": 0.0013,
      "step": 3754
    },
    {
      "epoch": 0.22274291137738758,
      "grad_norm": 4.912570953369141,
      "learning_rate": 1.7272607434748222e-05,
      "loss": 0.0246,
      "step": 3755
    },
    {
      "epoch": 0.22280223039506467,
      "grad_norm": 0.6809520125389099,
      "learning_rate": 1.7271289216978645e-05,
      "loss": 0.0113,
      "step": 3756
    },
    {
      "epoch": 0.22286154941274172,
      "grad_norm": 10.722684860229492,
      "learning_rate": 1.726997099920907e-05,
      "loss": 0.105,
      "step": 3757
    },
    {
      "epoch": 0.2229208684304188,
      "grad_norm": 3.432126998901367,
      "learning_rate": 1.7268652781439493e-05,
      "loss": 0.0306,
      "step": 3758
    },
    {
      "epoch": 0.22298018744809586,
      "grad_norm": 2.386640787124634,
      "learning_rate": 1.726733456366992e-05,
      "loss": 0.0145,
      "step": 3759
    },
    {
      "epoch": 0.22303950646577292,
      "grad_norm": 13.031554222106934,
      "learning_rate": 1.7266016345900345e-05,
      "loss": 0.2064,
      "step": 3760
    },
    {
      "epoch": 0.22309882548345,
      "grad_norm": 12.739422798156738,
      "learning_rate": 1.7264698128130768e-05,
      "loss": 0.3126,
      "step": 3761
    },
    {
      "epoch": 0.22315814450112706,
      "grad_norm": 11.369028091430664,
      "learning_rate": 1.7263379910361193e-05,
      "loss": 0.2457,
      "step": 3762
    },
    {
      "epoch": 0.22321746351880412,
      "grad_norm": 14.127604484558105,
      "learning_rate": 1.726206169259162e-05,
      "loss": 0.603,
      "step": 3763
    },
    {
      "epoch": 0.2232767825364812,
      "grad_norm": 14.3072509765625,
      "learning_rate": 1.7260743474822042e-05,
      "loss": 1.1896,
      "step": 3764
    },
    {
      "epoch": 0.22333610155415826,
      "grad_norm": 3.1584644317626953,
      "learning_rate": 1.7259425257052468e-05,
      "loss": 0.0213,
      "step": 3765
    },
    {
      "epoch": 0.22339542057183534,
      "grad_norm": 0.023141732439398766,
      "learning_rate": 1.7258107039282894e-05,
      "loss": 0.0009,
      "step": 3766
    },
    {
      "epoch": 0.2234547395895124,
      "grad_norm": 0.14783069491386414,
      "learning_rate": 1.7256788821513316e-05,
      "loss": 0.0027,
      "step": 3767
    },
    {
      "epoch": 0.22351405860718945,
      "grad_norm": 26.222881317138672,
      "learning_rate": 1.7255470603743742e-05,
      "loss": 1.2205,
      "step": 3768
    },
    {
      "epoch": 0.22357337762486654,
      "grad_norm": 0.38335445523262024,
      "learning_rate": 1.7254152385974164e-05,
      "loss": 0.0057,
      "step": 3769
    },
    {
      "epoch": 0.2236326966425436,
      "grad_norm": 0.048894528299570084,
      "learning_rate": 1.7252834168204587e-05,
      "loss": 0.0013,
      "step": 3770
    },
    {
      "epoch": 0.22369201566022068,
      "grad_norm": 1.2327337265014648,
      "learning_rate": 1.7251515950435013e-05,
      "loss": 0.0254,
      "step": 3771
    },
    {
      "epoch": 0.22375133467789773,
      "grad_norm": 0.25440797209739685,
      "learning_rate": 1.7250197732665435e-05,
      "loss": 0.0047,
      "step": 3772
    },
    {
      "epoch": 0.2238106536955748,
      "grad_norm": 4.272788047790527,
      "learning_rate": 1.724887951489586e-05,
      "loss": 0.065,
      "step": 3773
    },
    {
      "epoch": 0.22386997271325187,
      "grad_norm": 0.2093844711780548,
      "learning_rate": 1.7247561297126287e-05,
      "loss": 0.0035,
      "step": 3774
    },
    {
      "epoch": 0.22392929173092893,
      "grad_norm": 14.005566596984863,
      "learning_rate": 1.724624307935671e-05,
      "loss": 0.2177,
      "step": 3775
    },
    {
      "epoch": 0.22398861074860602,
      "grad_norm": 4.914725303649902,
      "learning_rate": 1.7244924861587135e-05,
      "loss": 0.1035,
      "step": 3776
    },
    {
      "epoch": 0.22404792976628307,
      "grad_norm": 1.9236910343170166,
      "learning_rate": 1.724360664381756e-05,
      "loss": 0.0463,
      "step": 3777
    },
    {
      "epoch": 0.22410724878396013,
      "grad_norm": 0.282034695148468,
      "learning_rate": 1.7242288426047984e-05,
      "loss": 0.0029,
      "step": 3778
    },
    {
      "epoch": 0.2241665678016372,
      "grad_norm": 16.488943099975586,
      "learning_rate": 1.724097020827841e-05,
      "loss": 0.1966,
      "step": 3779
    },
    {
      "epoch": 0.22422588681931427,
      "grad_norm": 8.784003257751465,
      "learning_rate": 1.7239651990508836e-05,
      "loss": 0.0808,
      "step": 3780
    },
    {
      "epoch": 0.22428520583699135,
      "grad_norm": 25.93168067932129,
      "learning_rate": 1.7238333772739258e-05,
      "loss": 0.0472,
      "step": 3781
    },
    {
      "epoch": 0.2243445248546684,
      "grad_norm": 1.6480706930160522,
      "learning_rate": 1.7237015554969684e-05,
      "loss": 0.0228,
      "step": 3782
    },
    {
      "epoch": 0.22440384387234547,
      "grad_norm": 3.296252965927124,
      "learning_rate": 1.7235697337200106e-05,
      "loss": 0.0302,
      "step": 3783
    },
    {
      "epoch": 0.22446316289002255,
      "grad_norm": 0.815872848033905,
      "learning_rate": 1.7234379119430532e-05,
      "loss": 0.0086,
      "step": 3784
    },
    {
      "epoch": 0.2245224819076996,
      "grad_norm": 9.410850524902344,
      "learning_rate": 1.7233060901660955e-05,
      "loss": 0.5385,
      "step": 3785
    },
    {
      "epoch": 0.22458180092537666,
      "grad_norm": 3.124556303024292,
      "learning_rate": 1.723174268389138e-05,
      "loss": 0.0809,
      "step": 3786
    },
    {
      "epoch": 0.22464111994305375,
      "grad_norm": 13.96263599395752,
      "learning_rate": 1.7230424466121803e-05,
      "loss": 0.2292,
      "step": 3787
    },
    {
      "epoch": 0.2247004389607308,
      "grad_norm": 0.39400291442871094,
      "learning_rate": 1.722910624835223e-05,
      "loss": 0.0059,
      "step": 3788
    },
    {
      "epoch": 0.2247597579784079,
      "grad_norm": 0.6183585524559021,
      "learning_rate": 1.722778803058265e-05,
      "loss": 0.0041,
      "step": 3789
    },
    {
      "epoch": 0.22481907699608494,
      "grad_norm": 0.01924489252269268,
      "learning_rate": 1.7226469812813077e-05,
      "loss": 0.0006,
      "step": 3790
    },
    {
      "epoch": 0.224878396013762,
      "grad_norm": 2.0749199390411377,
      "learning_rate": 1.7225151595043503e-05,
      "loss": 0.0817,
      "step": 3791
    },
    {
      "epoch": 0.22493771503143908,
      "grad_norm": 7.045210361480713,
      "learning_rate": 1.7223833377273926e-05,
      "loss": 0.18,
      "step": 3792
    },
    {
      "epoch": 0.22499703404911614,
      "grad_norm": 2.1451640129089355,
      "learning_rate": 1.722251515950435e-05,
      "loss": 0.022,
      "step": 3793
    },
    {
      "epoch": 0.22505635306679322,
      "grad_norm": 0.15150074660778046,
      "learning_rate": 1.7221196941734778e-05,
      "loss": 0.0033,
      "step": 3794
    },
    {
      "epoch": 0.22511567208447028,
      "grad_norm": 10.710055351257324,
      "learning_rate": 1.72198787239652e-05,
      "loss": 0.5218,
      "step": 3795
    },
    {
      "epoch": 0.22517499110214734,
      "grad_norm": 12.852681159973145,
      "learning_rate": 1.7218560506195626e-05,
      "loss": 0.5199,
      "step": 3796
    },
    {
      "epoch": 0.22523431011982442,
      "grad_norm": 0.030068978667259216,
      "learning_rate": 1.7217242288426052e-05,
      "loss": 0.0009,
      "step": 3797
    },
    {
      "epoch": 0.22529362913750148,
      "grad_norm": 5.610593795776367,
      "learning_rate": 1.7215924070656474e-05,
      "loss": 0.2088,
      "step": 3798
    },
    {
      "epoch": 0.22535294815517856,
      "grad_norm": 0.18748849630355835,
      "learning_rate": 1.72146058528869e-05,
      "loss": 0.0022,
      "step": 3799
    },
    {
      "epoch": 0.22541226717285562,
      "grad_norm": 0.3212868571281433,
      "learning_rate": 1.7213287635117323e-05,
      "loss": 0.0055,
      "step": 3800
    },
    {
      "epoch": 0.22547158619053267,
      "grad_norm": 16.31023597717285,
      "learning_rate": 1.721196941734775e-05,
      "loss": 0.4724,
      "step": 3801
    },
    {
      "epoch": 0.22553090520820976,
      "grad_norm": 10.153929710388184,
      "learning_rate": 1.721065119957817e-05,
      "loss": 0.2485,
      "step": 3802
    },
    {
      "epoch": 0.22559022422588682,
      "grad_norm": 2.4502198696136475,
      "learning_rate": 1.7209332981808594e-05,
      "loss": 0.0382,
      "step": 3803
    },
    {
      "epoch": 0.2256495432435639,
      "grad_norm": 0.640380322933197,
      "learning_rate": 1.720801476403902e-05,
      "loss": 0.008,
      "step": 3804
    },
    {
      "epoch": 0.22570886226124096,
      "grad_norm": 1.6150503158569336,
      "learning_rate": 1.7206696546269445e-05,
      "loss": 0.0171,
      "step": 3805
    },
    {
      "epoch": 0.225768181278918,
      "grad_norm": 11.238645553588867,
      "learning_rate": 1.7205378328499868e-05,
      "loss": 0.4135,
      "step": 3806
    },
    {
      "epoch": 0.2258275002965951,
      "grad_norm": 16.77764320373535,
      "learning_rate": 1.7204060110730294e-05,
      "loss": 0.4678,
      "step": 3807
    },
    {
      "epoch": 0.22588681931427215,
      "grad_norm": 7.5960469245910645,
      "learning_rate": 1.720274189296072e-05,
      "loss": 0.2472,
      "step": 3808
    },
    {
      "epoch": 0.22594613833194924,
      "grad_norm": 3.7226791381835938,
      "learning_rate": 1.7201423675191142e-05,
      "loss": 0.0237,
      "step": 3809
    },
    {
      "epoch": 0.2260054573496263,
      "grad_norm": 0.15672768652439117,
      "learning_rate": 1.7200105457421568e-05,
      "loss": 0.0025,
      "step": 3810
    },
    {
      "epoch": 0.22606477636730335,
      "grad_norm": 0.38968485593795776,
      "learning_rate": 1.7198787239651994e-05,
      "loss": 0.0039,
      "step": 3811
    },
    {
      "epoch": 0.22612409538498043,
      "grad_norm": 0.09595884382724762,
      "learning_rate": 1.7197469021882416e-05,
      "loss": 0.0011,
      "step": 3812
    },
    {
      "epoch": 0.2261834144026575,
      "grad_norm": 30.332712173461914,
      "learning_rate": 1.7196150804112842e-05,
      "loss": 0.7335,
      "step": 3813
    },
    {
      "epoch": 0.22624273342033455,
      "grad_norm": 4.270383358001709,
      "learning_rate": 1.7194832586343265e-05,
      "loss": 0.0857,
      "step": 3814
    },
    {
      "epoch": 0.22630205243801163,
      "grad_norm": 49.88263702392578,
      "learning_rate": 1.719351436857369e-05,
      "loss": 1.5845,
      "step": 3815
    },
    {
      "epoch": 0.2263613714556887,
      "grad_norm": 1.8329142332077026,
      "learning_rate": 1.7192196150804113e-05,
      "loss": 0.0401,
      "step": 3816
    },
    {
      "epoch": 0.22642069047336577,
      "grad_norm": 40.57870101928711,
      "learning_rate": 1.719087793303454e-05,
      "loss": 0.2258,
      "step": 3817
    },
    {
      "epoch": 0.22648000949104283,
      "grad_norm": 12.937183380126953,
      "learning_rate": 1.718955971526496e-05,
      "loss": 0.1419,
      "step": 3818
    },
    {
      "epoch": 0.22653932850871988,
      "grad_norm": 2.837660074234009,
      "learning_rate": 1.7188241497495387e-05,
      "loss": 0.0212,
      "step": 3819
    },
    {
      "epoch": 0.22659864752639697,
      "grad_norm": 0.06232687458395958,
      "learning_rate": 1.718692327972581e-05,
      "loss": 0.0007,
      "step": 3820
    },
    {
      "epoch": 0.22665796654407402,
      "grad_norm": 0.22799062728881836,
      "learning_rate": 1.7185605061956236e-05,
      "loss": 0.0017,
      "step": 3821
    },
    {
      "epoch": 0.2267172855617511,
      "grad_norm": 0.03042159602046013,
      "learning_rate": 1.718428684418666e-05,
      "loss": 0.0006,
      "step": 3822
    },
    {
      "epoch": 0.22677660457942816,
      "grad_norm": 1.6544970273971558,
      "learning_rate": 1.7182968626417084e-05,
      "loss": 0.0306,
      "step": 3823
    },
    {
      "epoch": 0.22683592359710522,
      "grad_norm": 15.266508102416992,
      "learning_rate": 1.718165040864751e-05,
      "loss": 1.1096,
      "step": 3824
    },
    {
      "epoch": 0.2268952426147823,
      "grad_norm": 9.257168769836426,
      "learning_rate": 1.7180332190877936e-05,
      "loss": 0.3677,
      "step": 3825
    },
    {
      "epoch": 0.22695456163245936,
      "grad_norm": 0.02320065349340439,
      "learning_rate": 1.717901397310836e-05,
      "loss": 0.0005,
      "step": 3826
    },
    {
      "epoch": 0.22701388065013645,
      "grad_norm": 0.4225113093852997,
      "learning_rate": 1.7177695755338784e-05,
      "loss": 0.0059,
      "step": 3827
    },
    {
      "epoch": 0.2270731996678135,
      "grad_norm": 0.6011914610862732,
      "learning_rate": 1.717637753756921e-05,
      "loss": 0.0034,
      "step": 3828
    },
    {
      "epoch": 0.22713251868549056,
      "grad_norm": 8.374170303344727,
      "learning_rate": 1.7175059319799633e-05,
      "loss": 0.0655,
      "step": 3829
    },
    {
      "epoch": 0.22719183770316764,
      "grad_norm": 0.1479329615831375,
      "learning_rate": 1.717374110203006e-05,
      "loss": 0.0015,
      "step": 3830
    },
    {
      "epoch": 0.2272511567208447,
      "grad_norm": 10.752314567565918,
      "learning_rate": 1.717242288426048e-05,
      "loss": 0.3674,
      "step": 3831
    },
    {
      "epoch": 0.22731047573852178,
      "grad_norm": 1.9678070545196533,
      "learning_rate": 1.7171104666490907e-05,
      "loss": 0.0177,
      "step": 3832
    },
    {
      "epoch": 0.22736979475619884,
      "grad_norm": 0.027722029015421867,
      "learning_rate": 1.716978644872133e-05,
      "loss": 0.001,
      "step": 3833
    },
    {
      "epoch": 0.2274291137738759,
      "grad_norm": 15.812859535217285,
      "learning_rate": 1.7168468230951755e-05,
      "loss": 0.4395,
      "step": 3834
    },
    {
      "epoch": 0.22748843279155298,
      "grad_norm": 0.3731220066547394,
      "learning_rate": 1.7167150013182178e-05,
      "loss": 0.0045,
      "step": 3835
    },
    {
      "epoch": 0.22754775180923004,
      "grad_norm": 0.7253081202507019,
      "learning_rate": 1.7165831795412604e-05,
      "loss": 0.0136,
      "step": 3836
    },
    {
      "epoch": 0.2276070708269071,
      "grad_norm": 9.579681396484375,
      "learning_rate": 1.7164513577643026e-05,
      "loss": 0.1984,
      "step": 3837
    },
    {
      "epoch": 0.22766638984458418,
      "grad_norm": 0.013226739130914211,
      "learning_rate": 1.7163195359873452e-05,
      "loss": 0.0005,
      "step": 3838
    },
    {
      "epoch": 0.22772570886226123,
      "grad_norm": 0.08743776381015778,
      "learning_rate": 1.7161877142103878e-05,
      "loss": 0.0012,
      "step": 3839
    },
    {
      "epoch": 0.22778502787993832,
      "grad_norm": 7.277756214141846,
      "learning_rate": 1.71605589243343e-05,
      "loss": 0.1259,
      "step": 3840
    },
    {
      "epoch": 0.22784434689761537,
      "grad_norm": 13.90405559539795,
      "learning_rate": 1.7159240706564726e-05,
      "loss": 0.1686,
      "step": 3841
    },
    {
      "epoch": 0.22790366591529243,
      "grad_norm": 0.8001110553741455,
      "learning_rate": 1.7157922488795152e-05,
      "loss": 0.0075,
      "step": 3842
    },
    {
      "epoch": 0.22796298493296951,
      "grad_norm": 0.2917449176311493,
      "learning_rate": 1.7156604271025575e-05,
      "loss": 0.0038,
      "step": 3843
    },
    {
      "epoch": 0.22802230395064657,
      "grad_norm": 6.428695201873779,
      "learning_rate": 1.7155286053256e-05,
      "loss": 0.044,
      "step": 3844
    },
    {
      "epoch": 0.22808162296832366,
      "grad_norm": 15.470190048217773,
      "learning_rate": 1.7153967835486426e-05,
      "loss": 0.5698,
      "step": 3845
    },
    {
      "epoch": 0.2281409419860007,
      "grad_norm": 53.039859771728516,
      "learning_rate": 1.715264961771685e-05,
      "loss": 0.7959,
      "step": 3846
    },
    {
      "epoch": 0.22820026100367777,
      "grad_norm": 12.292444229125977,
      "learning_rate": 1.715133139994727e-05,
      "loss": 0.1066,
      "step": 3847
    },
    {
      "epoch": 0.22825958002135485,
      "grad_norm": 0.2479078471660614,
      "learning_rate": 1.7150013182177697e-05,
      "loss": 0.0033,
      "step": 3848
    },
    {
      "epoch": 0.2283188990390319,
      "grad_norm": 6.329804420471191,
      "learning_rate": 1.714869496440812e-05,
      "loss": 0.1173,
      "step": 3849
    },
    {
      "epoch": 0.228378218056709,
      "grad_norm": 13.59050464630127,
      "learning_rate": 1.7147376746638546e-05,
      "loss": 0.1935,
      "step": 3850
    },
    {
      "epoch": 0.22843753707438605,
      "grad_norm": 0.5690146088600159,
      "learning_rate": 1.7146058528868968e-05,
      "loss": 0.0076,
      "step": 3851
    },
    {
      "epoch": 0.2284968560920631,
      "grad_norm": 15.945491790771484,
      "learning_rate": 1.7144740311099394e-05,
      "loss": 0.3043,
      "step": 3852
    },
    {
      "epoch": 0.2285561751097402,
      "grad_norm": 9.192132949829102,
      "learning_rate": 1.714342209332982e-05,
      "loss": 0.0815,
      "step": 3853
    },
    {
      "epoch": 0.22861549412741725,
      "grad_norm": 3.0541324615478516,
      "learning_rate": 1.7142103875560242e-05,
      "loss": 0.0171,
      "step": 3854
    },
    {
      "epoch": 0.22867481314509433,
      "grad_norm": 12.361806869506836,
      "learning_rate": 1.7140785657790668e-05,
      "loss": 0.2255,
      "step": 3855
    },
    {
      "epoch": 0.2287341321627714,
      "grad_norm": 7.033604145050049,
      "learning_rate": 1.7139467440021094e-05,
      "loss": 0.0768,
      "step": 3856
    },
    {
      "epoch": 0.22879345118044844,
      "grad_norm": 4.204773426055908,
      "learning_rate": 1.7138149222251517e-05,
      "loss": 0.1204,
      "step": 3857
    },
    {
      "epoch": 0.22885277019812553,
      "grad_norm": 3.7541773319244385,
      "learning_rate": 1.7136831004481942e-05,
      "loss": 0.0486,
      "step": 3858
    },
    {
      "epoch": 0.22891208921580258,
      "grad_norm": 3.796910047531128,
      "learning_rate": 1.713551278671237e-05,
      "loss": 0.0609,
      "step": 3859
    },
    {
      "epoch": 0.22897140823347967,
      "grad_norm": 30.97502899169922,
      "learning_rate": 1.713419456894279e-05,
      "loss": 0.7507,
      "step": 3860
    },
    {
      "epoch": 0.22903072725115672,
      "grad_norm": 7.422361373901367,
      "learning_rate": 1.7132876351173217e-05,
      "loss": 0.1569,
      "step": 3861
    },
    {
      "epoch": 0.22909004626883378,
      "grad_norm": 2.3464314937591553,
      "learning_rate": 1.713155813340364e-05,
      "loss": 0.0335,
      "step": 3862
    },
    {
      "epoch": 0.22914936528651086,
      "grad_norm": 1.7608249187469482,
      "learning_rate": 1.7130239915634065e-05,
      "loss": 0.0226,
      "step": 3863
    },
    {
      "epoch": 0.22920868430418792,
      "grad_norm": 0.14188475906848907,
      "learning_rate": 1.7128921697864488e-05,
      "loss": 0.0016,
      "step": 3864
    },
    {
      "epoch": 0.22926800332186498,
      "grad_norm": 0.543489933013916,
      "learning_rate": 1.7127603480094913e-05,
      "loss": 0.0041,
      "step": 3865
    },
    {
      "epoch": 0.22932732233954206,
      "grad_norm": 0.02305440977215767,
      "learning_rate": 1.7126285262325336e-05,
      "loss": 0.0007,
      "step": 3866
    },
    {
      "epoch": 0.22938664135721912,
      "grad_norm": 0.43916308879852295,
      "learning_rate": 1.7124967044555762e-05,
      "loss": 0.0066,
      "step": 3867
    },
    {
      "epoch": 0.2294459603748962,
      "grad_norm": 0.19872836768627167,
      "learning_rate": 1.7123648826786184e-05,
      "loss": 0.0034,
      "step": 3868
    },
    {
      "epoch": 0.22950527939257326,
      "grad_norm": 0.352098673582077,
      "learning_rate": 1.712233060901661e-05,
      "loss": 0.0024,
      "step": 3869
    },
    {
      "epoch": 0.22956459841025031,
      "grad_norm": 0.22303993999958038,
      "learning_rate": 1.7121012391247036e-05,
      "loss": 0.0051,
      "step": 3870
    },
    {
      "epoch": 0.2296239174279274,
      "grad_norm": 0.20573411881923676,
      "learning_rate": 1.711969417347746e-05,
      "loss": 0.0031,
      "step": 3871
    },
    {
      "epoch": 0.22968323644560446,
      "grad_norm": 0.010918286629021168,
      "learning_rate": 1.7118375955707884e-05,
      "loss": 0.0004,
      "step": 3872
    },
    {
      "epoch": 0.22974255546328154,
      "grad_norm": 41.290077209472656,
      "learning_rate": 1.711705773793831e-05,
      "loss": 0.48,
      "step": 3873
    },
    {
      "epoch": 0.2298018744809586,
      "grad_norm": 17.893199920654297,
      "learning_rate": 1.7115739520168733e-05,
      "loss": 1.0131,
      "step": 3874
    },
    {
      "epoch": 0.22986119349863565,
      "grad_norm": 7.96804141998291,
      "learning_rate": 1.711442130239916e-05,
      "loss": 0.1428,
      "step": 3875
    },
    {
      "epoch": 0.22992051251631274,
      "grad_norm": 21.47525978088379,
      "learning_rate": 1.7113103084629585e-05,
      "loss": 0.5166,
      "step": 3876
    },
    {
      "epoch": 0.2299798315339898,
      "grad_norm": 10.82821273803711,
      "learning_rate": 1.7111784866860007e-05,
      "loss": 0.4534,
      "step": 3877
    },
    {
      "epoch": 0.23003915055166688,
      "grad_norm": 4.805233478546143,
      "learning_rate": 1.7110466649090433e-05,
      "loss": 0.2894,
      "step": 3878
    },
    {
      "epoch": 0.23009846956934393,
      "grad_norm": 0.0639990046620369,
      "learning_rate": 1.7109148431320855e-05,
      "loss": 0.0016,
      "step": 3879
    },
    {
      "epoch": 0.230157788587021,
      "grad_norm": 0.1715659648180008,
      "learning_rate": 1.710783021355128e-05,
      "loss": 0.0023,
      "step": 3880
    },
    {
      "epoch": 0.23021710760469807,
      "grad_norm": 0.11980722844600677,
      "learning_rate": 1.7106511995781704e-05,
      "loss": 0.0017,
      "step": 3881
    },
    {
      "epoch": 0.23027642662237513,
      "grad_norm": 6.201712131500244,
      "learning_rate": 1.7105193778012126e-05,
      "loss": 0.0608,
      "step": 3882
    },
    {
      "epoch": 0.23033574564005221,
      "grad_norm": 3.930720090866089,
      "learning_rate": 1.7103875560242552e-05,
      "loss": 0.0242,
      "step": 3883
    },
    {
      "epoch": 0.23039506465772927,
      "grad_norm": 4.126214981079102,
      "learning_rate": 1.7102557342472978e-05,
      "loss": 0.0506,
      "step": 3884
    },
    {
      "epoch": 0.23045438367540633,
      "grad_norm": 0.23126333951950073,
      "learning_rate": 1.71012391247034e-05,
      "loss": 0.0031,
      "step": 3885
    },
    {
      "epoch": 0.2305137026930834,
      "grad_norm": 0.53997802734375,
      "learning_rate": 1.7099920906933826e-05,
      "loss": 0.0082,
      "step": 3886
    },
    {
      "epoch": 0.23057302171076047,
      "grad_norm": 5.82504415512085,
      "learning_rate": 1.7098602689164252e-05,
      "loss": 0.1488,
      "step": 3887
    },
    {
      "epoch": 0.23063234072843752,
      "grad_norm": 0.08244499564170837,
      "learning_rate": 1.7097284471394675e-05,
      "loss": 0.0013,
      "step": 3888
    },
    {
      "epoch": 0.2306916597461146,
      "grad_norm": 19.304264068603516,
      "learning_rate": 1.70959662536251e-05,
      "loss": 0.1907,
      "step": 3889
    },
    {
      "epoch": 0.23075097876379166,
      "grad_norm": 50.79423141479492,
      "learning_rate": 1.7094648035855527e-05,
      "loss": 0.1998,
      "step": 3890
    },
    {
      "epoch": 0.23081029778146875,
      "grad_norm": 1.5171838998794556,
      "learning_rate": 1.709332981808595e-05,
      "loss": 0.0092,
      "step": 3891
    },
    {
      "epoch": 0.2308696167991458,
      "grad_norm": 26.103700637817383,
      "learning_rate": 1.7092011600316375e-05,
      "loss": 0.5042,
      "step": 3892
    },
    {
      "epoch": 0.23092893581682286,
      "grad_norm": 3.23883318901062,
      "learning_rate": 1.7090693382546797e-05,
      "loss": 0.0306,
      "step": 3893
    },
    {
      "epoch": 0.23098825483449995,
      "grad_norm": 6.78486967086792,
      "learning_rate": 1.7089375164777223e-05,
      "loss": 0.0988,
      "step": 3894
    },
    {
      "epoch": 0.231047573852177,
      "grad_norm": 0.3873089551925659,
      "learning_rate": 1.7088056947007646e-05,
      "loss": 0.0039,
      "step": 3895
    },
    {
      "epoch": 0.23110689286985409,
      "grad_norm": 14.849346160888672,
      "learning_rate": 1.7086738729238072e-05,
      "loss": 0.4925,
      "step": 3896
    },
    {
      "epoch": 0.23116621188753114,
      "grad_norm": 14.662102699279785,
      "learning_rate": 1.7085420511468494e-05,
      "loss": 0.4458,
      "step": 3897
    },
    {
      "epoch": 0.2312255309052082,
      "grad_norm": 16.32541847229004,
      "learning_rate": 1.708410229369892e-05,
      "loss": 0.142,
      "step": 3898
    },
    {
      "epoch": 0.23128484992288528,
      "grad_norm": 0.5673711895942688,
      "learning_rate": 1.7082784075929343e-05,
      "loss": 0.0069,
      "step": 3899
    },
    {
      "epoch": 0.23134416894056234,
      "grad_norm": 0.013672662898898125,
      "learning_rate": 1.708146585815977e-05,
      "loss": 0.0006,
      "step": 3900
    },
    {
      "epoch": 0.23140348795823942,
      "grad_norm": 3.182697057723999,
      "learning_rate": 1.7080147640390194e-05,
      "loss": 0.0687,
      "step": 3901
    },
    {
      "epoch": 0.23146280697591648,
      "grad_norm": 17.476226806640625,
      "learning_rate": 1.7078829422620617e-05,
      "loss": 0.1043,
      "step": 3902
    },
    {
      "epoch": 0.23152212599359354,
      "grad_norm": 0.12157400697469711,
      "learning_rate": 1.7077511204851043e-05,
      "loss": 0.0026,
      "step": 3903
    },
    {
      "epoch": 0.23158144501127062,
      "grad_norm": 12.285022735595703,
      "learning_rate": 1.707619298708147e-05,
      "loss": 0.2134,
      "step": 3904
    },
    {
      "epoch": 0.23164076402894768,
      "grad_norm": 11.263211250305176,
      "learning_rate": 1.707487476931189e-05,
      "loss": 0.8987,
      "step": 3905
    },
    {
      "epoch": 0.23170008304662476,
      "grad_norm": 0.796760082244873,
      "learning_rate": 1.7073556551542317e-05,
      "loss": 0.0133,
      "step": 3906
    },
    {
      "epoch": 0.23175940206430182,
      "grad_norm": 0.3174178898334503,
      "learning_rate": 1.7072238333772743e-05,
      "loss": 0.0034,
      "step": 3907
    },
    {
      "epoch": 0.23181872108197887,
      "grad_norm": 21.599916458129883,
      "learning_rate": 1.7070920116003165e-05,
      "loss": 0.7374,
      "step": 3908
    },
    {
      "epoch": 0.23187804009965596,
      "grad_norm": 1.1882904767990112,
      "learning_rate": 1.706960189823359e-05,
      "loss": 0.0118,
      "step": 3909
    },
    {
      "epoch": 0.23193735911733301,
      "grad_norm": 0.03570536524057388,
      "learning_rate": 1.7068283680464014e-05,
      "loss": 0.0007,
      "step": 3910
    },
    {
      "epoch": 0.23199667813501007,
      "grad_norm": 0.06817019730806351,
      "learning_rate": 1.706696546269444e-05,
      "loss": 0.0011,
      "step": 3911
    },
    {
      "epoch": 0.23205599715268715,
      "grad_norm": 6.4567766189575195,
      "learning_rate": 1.7065647244924862e-05,
      "loss": 0.515,
      "step": 3912
    },
    {
      "epoch": 0.2321153161703642,
      "grad_norm": 0.08197644352912903,
      "learning_rate": 1.7064329027155288e-05,
      "loss": 0.002,
      "step": 3913
    },
    {
      "epoch": 0.2321746351880413,
      "grad_norm": 24.218896865844727,
      "learning_rate": 1.706301080938571e-05,
      "loss": 0.2472,
      "step": 3914
    },
    {
      "epoch": 0.23223395420571835,
      "grad_norm": 7.158286094665527,
      "learning_rate": 1.7061692591616136e-05,
      "loss": 0.2956,
      "step": 3915
    },
    {
      "epoch": 0.2322932732233954,
      "grad_norm": 8.229340553283691,
      "learning_rate": 1.706037437384656e-05,
      "loss": 0.0582,
      "step": 3916
    },
    {
      "epoch": 0.2323525922410725,
      "grad_norm": 1.7517553567886353,
      "learning_rate": 1.7059056156076985e-05,
      "loss": 0.0217,
      "step": 3917
    },
    {
      "epoch": 0.23241191125874955,
      "grad_norm": 0.04729578271508217,
      "learning_rate": 1.705773793830741e-05,
      "loss": 0.0011,
      "step": 3918
    },
    {
      "epoch": 0.23247123027642663,
      "grad_norm": 27.470813751220703,
      "learning_rate": 1.7056419720537833e-05,
      "loss": 1.0421,
      "step": 3919
    },
    {
      "epoch": 0.2325305492941037,
      "grad_norm": 38.02822494506836,
      "learning_rate": 1.705510150276826e-05,
      "loss": 0.9576,
      "step": 3920
    },
    {
      "epoch": 0.23258986831178075,
      "grad_norm": 14.646735191345215,
      "learning_rate": 1.7053783284998685e-05,
      "loss": 0.5458,
      "step": 3921
    },
    {
      "epoch": 0.23264918732945783,
      "grad_norm": 10.988197326660156,
      "learning_rate": 1.7052465067229107e-05,
      "loss": 0.0409,
      "step": 3922
    },
    {
      "epoch": 0.23270850634713489,
      "grad_norm": 0.09612585604190826,
      "learning_rate": 1.7051146849459533e-05,
      "loss": 0.0023,
      "step": 3923
    },
    {
      "epoch": 0.23276782536481197,
      "grad_norm": 0.10290621966123581,
      "learning_rate": 1.704982863168996e-05,
      "loss": 0.0015,
      "step": 3924
    },
    {
      "epoch": 0.23282714438248903,
      "grad_norm": 1.2086104154586792,
      "learning_rate": 1.704851041392038e-05,
      "loss": 0.012,
      "step": 3925
    },
    {
      "epoch": 0.23288646340016608,
      "grad_norm": 0.08410642296075821,
      "learning_rate": 1.7047192196150804e-05,
      "loss": 0.0014,
      "step": 3926
    },
    {
      "epoch": 0.23294578241784317,
      "grad_norm": 21.21012306213379,
      "learning_rate": 1.704587397838123e-05,
      "loss": 0.1548,
      "step": 3927
    },
    {
      "epoch": 0.23300510143552022,
      "grad_norm": 28.255712509155273,
      "learning_rate": 1.7044555760611653e-05,
      "loss": 0.2279,
      "step": 3928
    },
    {
      "epoch": 0.2330644204531973,
      "grad_norm": 0.036576323211193085,
      "learning_rate": 1.704323754284208e-05,
      "loss": 0.0005,
      "step": 3929
    },
    {
      "epoch": 0.23312373947087436,
      "grad_norm": 11.430913925170898,
      "learning_rate": 1.70419193250725e-05,
      "loss": 0.897,
      "step": 3930
    },
    {
      "epoch": 0.23318305848855142,
      "grad_norm": 7.703803062438965,
      "learning_rate": 1.7040601107302927e-05,
      "loss": 0.1307,
      "step": 3931
    },
    {
      "epoch": 0.2332423775062285,
      "grad_norm": 0.7154543995857239,
      "learning_rate": 1.7039282889533353e-05,
      "loss": 0.0075,
      "step": 3932
    },
    {
      "epoch": 0.23330169652390556,
      "grad_norm": 0.01630132459104061,
      "learning_rate": 1.7037964671763775e-05,
      "loss": 0.0006,
      "step": 3933
    },
    {
      "epoch": 0.23336101554158264,
      "grad_norm": 0.8224529027938843,
      "learning_rate": 1.70366464539942e-05,
      "loss": 0.0082,
      "step": 3934
    },
    {
      "epoch": 0.2334203345592597,
      "grad_norm": 13.323359489440918,
      "learning_rate": 1.7035328236224627e-05,
      "loss": 0.0649,
      "step": 3935
    },
    {
      "epoch": 0.23347965357693676,
      "grad_norm": 34.18792724609375,
      "learning_rate": 1.703401001845505e-05,
      "loss": 1.0475,
      "step": 3936
    },
    {
      "epoch": 0.23353897259461384,
      "grad_norm": 17.39840316772461,
      "learning_rate": 1.7032691800685475e-05,
      "loss": 0.4858,
      "step": 3937
    },
    {
      "epoch": 0.2335982916122909,
      "grad_norm": 1.4334594011306763,
      "learning_rate": 1.70313735829159e-05,
      "loss": 0.0219,
      "step": 3938
    },
    {
      "epoch": 0.23365761062996795,
      "grad_norm": 2.657191276550293,
      "learning_rate": 1.7030055365146324e-05,
      "loss": 0.032,
      "step": 3939
    },
    {
      "epoch": 0.23371692964764504,
      "grad_norm": 0.03238775208592415,
      "learning_rate": 1.702873714737675e-05,
      "loss": 0.0005,
      "step": 3940
    },
    {
      "epoch": 0.2337762486653221,
      "grad_norm": 11.858060836791992,
      "learning_rate": 1.7027418929607172e-05,
      "loss": 1.0472,
      "step": 3941
    },
    {
      "epoch": 0.23383556768299918,
      "grad_norm": 24.44088363647461,
      "learning_rate": 1.7026100711837598e-05,
      "loss": 0.9454,
      "step": 3942
    },
    {
      "epoch": 0.23389488670067624,
      "grad_norm": 5.2096452713012695,
      "learning_rate": 1.702478249406802e-05,
      "loss": 0.0729,
      "step": 3943
    },
    {
      "epoch": 0.2339542057183533,
      "grad_norm": 18.93594741821289,
      "learning_rate": 1.7023464276298446e-05,
      "loss": 0.5131,
      "step": 3944
    },
    {
      "epoch": 0.23401352473603038,
      "grad_norm": 0.07144682854413986,
      "learning_rate": 1.702214605852887e-05,
      "loss": 0.0016,
      "step": 3945
    },
    {
      "epoch": 0.23407284375370743,
      "grad_norm": 13.136003494262695,
      "learning_rate": 1.7020827840759295e-05,
      "loss": 0.4888,
      "step": 3946
    },
    {
      "epoch": 0.23413216277138452,
      "grad_norm": 1.4317044019699097,
      "learning_rate": 1.7019509622989717e-05,
      "loss": 0.0122,
      "step": 3947
    },
    {
      "epoch": 0.23419148178906157,
      "grad_norm": 3.4633185863494873,
      "learning_rate": 1.7018191405220143e-05,
      "loss": 0.0219,
      "step": 3948
    },
    {
      "epoch": 0.23425080080673863,
      "grad_norm": 6.4773054122924805,
      "learning_rate": 1.701687318745057e-05,
      "loss": 0.1743,
      "step": 3949
    },
    {
      "epoch": 0.2343101198244157,
      "grad_norm": 3.102179527282715,
      "learning_rate": 1.701555496968099e-05,
      "loss": 0.0292,
      "step": 3950
    },
    {
      "epoch": 0.23436943884209277,
      "grad_norm": 0.9427977204322815,
      "learning_rate": 1.7014236751911417e-05,
      "loss": 0.006,
      "step": 3951
    },
    {
      "epoch": 0.23442875785976985,
      "grad_norm": 6.986518859863281,
      "learning_rate": 1.7012918534141843e-05,
      "loss": 0.0982,
      "step": 3952
    },
    {
      "epoch": 0.2344880768774469,
      "grad_norm": 3.1009814739227295,
      "learning_rate": 1.7011600316372266e-05,
      "loss": 0.0294,
      "step": 3953
    },
    {
      "epoch": 0.23454739589512397,
      "grad_norm": 0.05572044476866722,
      "learning_rate": 1.701028209860269e-05,
      "loss": 0.001,
      "step": 3954
    },
    {
      "epoch": 0.23460671491280105,
      "grad_norm": 17.711566925048828,
      "learning_rate": 1.7008963880833117e-05,
      "loss": 0.5724,
      "step": 3955
    },
    {
      "epoch": 0.2346660339304781,
      "grad_norm": 0.3653305172920227,
      "learning_rate": 1.700764566306354e-05,
      "loss": 0.0034,
      "step": 3956
    },
    {
      "epoch": 0.2347253529481552,
      "grad_norm": 1.4588050842285156,
      "learning_rate": 1.7006327445293966e-05,
      "loss": 0.0151,
      "step": 3957
    },
    {
      "epoch": 0.23478467196583225,
      "grad_norm": 3.030885696411133,
      "learning_rate": 1.7005009227524388e-05,
      "loss": 0.0341,
      "step": 3958
    },
    {
      "epoch": 0.2348439909835093,
      "grad_norm": 10.063857078552246,
      "learning_rate": 1.700369100975481e-05,
      "loss": 0.1146,
      "step": 3959
    },
    {
      "epoch": 0.2349033100011864,
      "grad_norm": 16.868732452392578,
      "learning_rate": 1.7002372791985237e-05,
      "loss": 0.2585,
      "step": 3960
    },
    {
      "epoch": 0.23496262901886344,
      "grad_norm": 9.061382293701172,
      "learning_rate": 1.700105457421566e-05,
      "loss": 0.1699,
      "step": 3961
    },
    {
      "epoch": 0.2350219480365405,
      "grad_norm": 0.24098455905914307,
      "learning_rate": 1.6999736356446085e-05,
      "loss": 0.004,
      "step": 3962
    },
    {
      "epoch": 0.23508126705421759,
      "grad_norm": 14.101608276367188,
      "learning_rate": 1.699841813867651e-05,
      "loss": 0.2604,
      "step": 3963
    },
    {
      "epoch": 0.23514058607189464,
      "grad_norm": 12.419271469116211,
      "learning_rate": 1.6997099920906933e-05,
      "loss": 0.0831,
      "step": 3964
    },
    {
      "epoch": 0.23519990508957173,
      "grad_norm": 7.16019868850708,
      "learning_rate": 1.699578170313736e-05,
      "loss": 0.2503,
      "step": 3965
    },
    {
      "epoch": 0.23525922410724878,
      "grad_norm": 0.02425542101264,
      "learning_rate": 1.6994463485367785e-05,
      "loss": 0.0007,
      "step": 3966
    },
    {
      "epoch": 0.23531854312492584,
      "grad_norm": 5.164794921875,
      "learning_rate": 1.6993145267598208e-05,
      "loss": 0.0315,
      "step": 3967
    },
    {
      "epoch": 0.23537786214260292,
      "grad_norm": 1.6194621324539185,
      "learning_rate": 1.6991827049828634e-05,
      "loss": 0.0156,
      "step": 3968
    },
    {
      "epoch": 0.23543718116027998,
      "grad_norm": 4.951390266418457,
      "learning_rate": 1.699050883205906e-05,
      "loss": 0.1701,
      "step": 3969
    },
    {
      "epoch": 0.23549650017795706,
      "grad_norm": 5.157420635223389,
      "learning_rate": 1.6989190614289482e-05,
      "loss": 0.0732,
      "step": 3970
    },
    {
      "epoch": 0.23555581919563412,
      "grad_norm": 8.917431831359863,
      "learning_rate": 1.6987872396519908e-05,
      "loss": 0.3246,
      "step": 3971
    },
    {
      "epoch": 0.23561513821331118,
      "grad_norm": 8.285937309265137,
      "learning_rate": 1.698655417875033e-05,
      "loss": 0.2965,
      "step": 3972
    },
    {
      "epoch": 0.23567445723098826,
      "grad_norm": 3.415471076965332,
      "learning_rate": 1.6985235960980756e-05,
      "loss": 0.0416,
      "step": 3973
    },
    {
      "epoch": 0.23573377624866532,
      "grad_norm": 5.747356414794922,
      "learning_rate": 1.698391774321118e-05,
      "loss": 0.2044,
      "step": 3974
    },
    {
      "epoch": 0.2357930952663424,
      "grad_norm": 6.365458965301514,
      "learning_rate": 1.6982599525441605e-05,
      "loss": 0.1111,
      "step": 3975
    },
    {
      "epoch": 0.23585241428401946,
      "grad_norm": 22.83774757385254,
      "learning_rate": 1.6981281307672027e-05,
      "loss": 0.7157,
      "step": 3976
    },
    {
      "epoch": 0.2359117333016965,
      "grad_norm": 0.29901209473609924,
      "learning_rate": 1.6979963089902453e-05,
      "loss": 0.0025,
      "step": 3977
    },
    {
      "epoch": 0.2359710523193736,
      "grad_norm": 19.569398880004883,
      "learning_rate": 1.6978644872132875e-05,
      "loss": 0.5872,
      "step": 3978
    },
    {
      "epoch": 0.23603037133705065,
      "grad_norm": 4.532054901123047,
      "learning_rate": 1.69773266543633e-05,
      "loss": 0.0209,
      "step": 3979
    },
    {
      "epoch": 0.23608969035472774,
      "grad_norm": 0.6654362082481384,
      "learning_rate": 1.6976008436593727e-05,
      "loss": 0.0076,
      "step": 3980
    },
    {
      "epoch": 0.2361490093724048,
      "grad_norm": 0.08148957788944244,
      "learning_rate": 1.697469021882415e-05,
      "loss": 0.0022,
      "step": 3981
    },
    {
      "epoch": 0.23620832839008185,
      "grad_norm": 17.62580680847168,
      "learning_rate": 1.6973372001054576e-05,
      "loss": 0.7999,
      "step": 3982
    },
    {
      "epoch": 0.23626764740775894,
      "grad_norm": 2.8860435485839844,
      "learning_rate": 1.6972053783285e-05,
      "loss": 0.1883,
      "step": 3983
    },
    {
      "epoch": 0.236326966425436,
      "grad_norm": 1.9339032173156738,
      "learning_rate": 1.6970735565515424e-05,
      "loss": 0.0201,
      "step": 3984
    },
    {
      "epoch": 0.23638628544311308,
      "grad_norm": 20.688879013061523,
      "learning_rate": 1.696941734774585e-05,
      "loss": 0.2981,
      "step": 3985
    },
    {
      "epoch": 0.23644560446079013,
      "grad_norm": 1.5296194553375244,
      "learning_rate": 1.6968099129976276e-05,
      "loss": 0.0232,
      "step": 3986
    },
    {
      "epoch": 0.2365049234784672,
      "grad_norm": 29.698740005493164,
      "learning_rate": 1.6966780912206698e-05,
      "loss": 0.1479,
      "step": 3987
    },
    {
      "epoch": 0.23656424249614427,
      "grad_norm": 8.299274444580078,
      "learning_rate": 1.6965462694437124e-05,
      "loss": 0.2769,
      "step": 3988
    },
    {
      "epoch": 0.23662356151382133,
      "grad_norm": 1.2815661430358887,
      "learning_rate": 1.6964144476667547e-05,
      "loss": 0.0102,
      "step": 3989
    },
    {
      "epoch": 0.23668288053149839,
      "grad_norm": 0.12719163298606873,
      "learning_rate": 1.6962826258897972e-05,
      "loss": 0.0024,
      "step": 3990
    },
    {
      "epoch": 0.23674219954917547,
      "grad_norm": 12.436007499694824,
      "learning_rate": 1.6961508041128395e-05,
      "loss": 0.213,
      "step": 3991
    },
    {
      "epoch": 0.23680151856685253,
      "grad_norm": 3.6414430141448975,
      "learning_rate": 1.696018982335882e-05,
      "loss": 0.0321,
      "step": 3992
    },
    {
      "epoch": 0.2368608375845296,
      "grad_norm": 13.068988800048828,
      "learning_rate": 1.6958871605589243e-05,
      "loss": 0.532,
      "step": 3993
    },
    {
      "epoch": 0.23692015660220667,
      "grad_norm": 2.958889961242676,
      "learning_rate": 1.695755338781967e-05,
      "loss": 0.0618,
      "step": 3994
    },
    {
      "epoch": 0.23697947561988372,
      "grad_norm": 0.06567873060703278,
      "learning_rate": 1.695623517005009e-05,
      "loss": 0.0014,
      "step": 3995
    },
    {
      "epoch": 0.2370387946375608,
      "grad_norm": 0.023367952555418015,
      "learning_rate": 1.6954916952280518e-05,
      "loss": 0.0005,
      "step": 3996
    },
    {
      "epoch": 0.23709811365523786,
      "grad_norm": 11.147375106811523,
      "learning_rate": 1.6953598734510943e-05,
      "loss": 0.2275,
      "step": 3997
    },
    {
      "epoch": 0.23715743267291495,
      "grad_norm": 0.036024633795022964,
      "learning_rate": 1.6952280516741366e-05,
      "loss": 0.0007,
      "step": 3998
    },
    {
      "epoch": 0.237216751690592,
      "grad_norm": 4.869352340698242,
      "learning_rate": 1.6950962298971792e-05,
      "loss": 0.1883,
      "step": 3999
    },
    {
      "epoch": 0.23727607070826906,
      "grad_norm": 5.106389045715332,
      "learning_rate": 1.6949644081202218e-05,
      "loss": 0.2092,
      "step": 4000
    },
    {
      "epoch": 0.23733538972594614,
      "grad_norm": 10.155665397644043,
      "learning_rate": 1.694832586343264e-05,
      "loss": 1.1899,
      "step": 4001
    },
    {
      "epoch": 0.2373947087436232,
      "grad_norm": 7.168684005737305,
      "learning_rate": 1.6947007645663066e-05,
      "loss": 0.116,
      "step": 4002
    },
    {
      "epoch": 0.23745402776130028,
      "grad_norm": 0.08403729647397995,
      "learning_rate": 1.694568942789349e-05,
      "loss": 0.0014,
      "step": 4003
    },
    {
      "epoch": 0.23751334677897734,
      "grad_norm": 5.153623580932617,
      "learning_rate": 1.6944371210123914e-05,
      "loss": 0.0365,
      "step": 4004
    },
    {
      "epoch": 0.2375726657966544,
      "grad_norm": 0.6475091576576233,
      "learning_rate": 1.6943052992354337e-05,
      "loss": 0.0089,
      "step": 4005
    },
    {
      "epoch": 0.23763198481433148,
      "grad_norm": 0.1495928317308426,
      "learning_rate": 1.6941734774584763e-05,
      "loss": 0.003,
      "step": 4006
    },
    {
      "epoch": 0.23769130383200854,
      "grad_norm": 21.869714736938477,
      "learning_rate": 1.6940416556815185e-05,
      "loss": 0.1039,
      "step": 4007
    },
    {
      "epoch": 0.23775062284968562,
      "grad_norm": 2.4099338054656982,
      "learning_rate": 1.693909833904561e-05,
      "loss": 0.0106,
      "step": 4008
    },
    {
      "epoch": 0.23780994186736268,
      "grad_norm": 7.323741912841797,
      "learning_rate": 1.6937780121276034e-05,
      "loss": 0.0452,
      "step": 4009
    },
    {
      "epoch": 0.23786926088503973,
      "grad_norm": 14.591299057006836,
      "learning_rate": 1.693646190350646e-05,
      "loss": 0.7856,
      "step": 4010
    },
    {
      "epoch": 0.23792857990271682,
      "grad_norm": 6.535632133483887,
      "learning_rate": 1.6935143685736885e-05,
      "loss": 0.5755,
      "step": 4011
    },
    {
      "epoch": 0.23798789892039388,
      "grad_norm": 11.252049446105957,
      "learning_rate": 1.6933825467967308e-05,
      "loss": 0.687,
      "step": 4012
    },
    {
      "epoch": 0.23804721793807093,
      "grad_norm": 2.967628240585327,
      "learning_rate": 1.6932507250197734e-05,
      "loss": 0.0709,
      "step": 4013
    },
    {
      "epoch": 0.23810653695574802,
      "grad_norm": 2.5496151447296143,
      "learning_rate": 1.693118903242816e-05,
      "loss": 0.0317,
      "step": 4014
    },
    {
      "epoch": 0.23816585597342507,
      "grad_norm": 0.07147487998008728,
      "learning_rate": 1.6929870814658582e-05,
      "loss": 0.0017,
      "step": 4015
    },
    {
      "epoch": 0.23822517499110216,
      "grad_norm": 60.15842056274414,
      "learning_rate": 1.6928552596889008e-05,
      "loss": 0.1634,
      "step": 4016
    },
    {
      "epoch": 0.2382844940087792,
      "grad_norm": 0.5047816634178162,
      "learning_rate": 1.6927234379119434e-05,
      "loss": 0.0047,
      "step": 4017
    },
    {
      "epoch": 0.23834381302645627,
      "grad_norm": 0.045375656336545944,
      "learning_rate": 1.6925916161349856e-05,
      "loss": 0.0015,
      "step": 4018
    },
    {
      "epoch": 0.23840313204413335,
      "grad_norm": 4.262540340423584,
      "learning_rate": 1.6924597943580282e-05,
      "loss": 0.1695,
      "step": 4019
    },
    {
      "epoch": 0.2384624510618104,
      "grad_norm": 7.193764686584473,
      "learning_rate": 1.6923279725810705e-05,
      "loss": 0.2777,
      "step": 4020
    },
    {
      "epoch": 0.2385217700794875,
      "grad_norm": 3.655052900314331,
      "learning_rate": 1.692196150804113e-05,
      "loss": 0.0651,
      "step": 4021
    },
    {
      "epoch": 0.23858108909716455,
      "grad_norm": 7.716320514678955,
      "learning_rate": 1.6920643290271553e-05,
      "loss": 0.3513,
      "step": 4022
    },
    {
      "epoch": 0.2386404081148416,
      "grad_norm": 2.8140552043914795,
      "learning_rate": 1.691932507250198e-05,
      "loss": 0.019,
      "step": 4023
    },
    {
      "epoch": 0.2386997271325187,
      "grad_norm": 14.052403450012207,
      "learning_rate": 1.69180068547324e-05,
      "loss": 0.2024,
      "step": 4024
    },
    {
      "epoch": 0.23875904615019575,
      "grad_norm": 0.4335172176361084,
      "learning_rate": 1.6916688636962827e-05,
      "loss": 0.0056,
      "step": 4025
    },
    {
      "epoch": 0.23881836516787283,
      "grad_norm": 0.30964764952659607,
      "learning_rate": 1.691537041919325e-05,
      "loss": 0.0047,
      "step": 4026
    },
    {
      "epoch": 0.2388776841855499,
      "grad_norm": 1.4841059446334839,
      "learning_rate": 1.6914052201423676e-05,
      "loss": 0.018,
      "step": 4027
    },
    {
      "epoch": 0.23893700320322694,
      "grad_norm": 2.849010705947876,
      "learning_rate": 1.6912733983654102e-05,
      "loss": 0.0627,
      "step": 4028
    },
    {
      "epoch": 0.23899632222090403,
      "grad_norm": 0.1788046807050705,
      "learning_rate": 1.6911415765884524e-05,
      "loss": 0.0028,
      "step": 4029
    },
    {
      "epoch": 0.23905564123858108,
      "grad_norm": 1.8050403594970703,
      "learning_rate": 1.691009754811495e-05,
      "loss": 0.0195,
      "step": 4030
    },
    {
      "epoch": 0.23911496025625817,
      "grad_norm": 7.350335597991943,
      "learning_rate": 1.6908779330345376e-05,
      "loss": 0.1739,
      "step": 4031
    },
    {
      "epoch": 0.23917427927393523,
      "grad_norm": 2.170785665512085,
      "learning_rate": 1.69074611125758e-05,
      "loss": 0.0264,
      "step": 4032
    },
    {
      "epoch": 0.23923359829161228,
      "grad_norm": 0.27335160970687866,
      "learning_rate": 1.6906142894806224e-05,
      "loss": 0.0076,
      "step": 4033
    },
    {
      "epoch": 0.23929291730928937,
      "grad_norm": 0.19227302074432373,
      "learning_rate": 1.690482467703665e-05,
      "loss": 0.0018,
      "step": 4034
    },
    {
      "epoch": 0.23935223632696642,
      "grad_norm": 7.915323734283447,
      "learning_rate": 1.6903506459267073e-05,
      "loss": 0.1164,
      "step": 4035
    },
    {
      "epoch": 0.2394115553446435,
      "grad_norm": 42.19731140136719,
      "learning_rate": 1.69021882414975e-05,
      "loss": 2.021,
      "step": 4036
    },
    {
      "epoch": 0.23947087436232056,
      "grad_norm": 26.583974838256836,
      "learning_rate": 1.690087002372792e-05,
      "loss": 0.3771,
      "step": 4037
    },
    {
      "epoch": 0.23953019337999762,
      "grad_norm": 0.014595857821404934,
      "learning_rate": 1.6899551805958344e-05,
      "loss": 0.0004,
      "step": 4038
    },
    {
      "epoch": 0.2395895123976747,
      "grad_norm": 5.903522968292236,
      "learning_rate": 1.689823358818877e-05,
      "loss": 0.0566,
      "step": 4039
    },
    {
      "epoch": 0.23964883141535176,
      "grad_norm": 14.208864212036133,
      "learning_rate": 1.6896915370419195e-05,
      "loss": 0.4878,
      "step": 4040
    },
    {
      "epoch": 0.23970815043302882,
      "grad_norm": 0.30457621812820435,
      "learning_rate": 1.6895597152649618e-05,
      "loss": 0.0043,
      "step": 4041
    },
    {
      "epoch": 0.2397674694507059,
      "grad_norm": 24.23149299621582,
      "learning_rate": 1.6894278934880044e-05,
      "loss": 0.5109,
      "step": 4042
    },
    {
      "epoch": 0.23982678846838296,
      "grad_norm": 6.937339782714844,
      "learning_rate": 1.6892960717110466e-05,
      "loss": 0.0303,
      "step": 4043
    },
    {
      "epoch": 0.23988610748606004,
      "grad_norm": 0.09337817877531052,
      "learning_rate": 1.6891642499340892e-05,
      "loss": 0.0022,
      "step": 4044
    },
    {
      "epoch": 0.2399454265037371,
      "grad_norm": 0.6127050518989563,
      "learning_rate": 1.6890324281571318e-05,
      "loss": 0.0108,
      "step": 4045
    },
    {
      "epoch": 0.24000474552141415,
      "grad_norm": 10.094345092773438,
      "learning_rate": 1.688900606380174e-05,
      "loss": 0.1872,
      "step": 4046
    },
    {
      "epoch": 0.24006406453909124,
      "grad_norm": 13.341891288757324,
      "learning_rate": 1.6887687846032166e-05,
      "loss": 0.3508,
      "step": 4047
    },
    {
      "epoch": 0.2401233835567683,
      "grad_norm": 3.2978007793426514,
      "learning_rate": 1.6886369628262592e-05,
      "loss": 0.0537,
      "step": 4048
    },
    {
      "epoch": 0.24018270257444538,
      "grad_norm": 50.1765251159668,
      "learning_rate": 1.6885051410493015e-05,
      "loss": 0.6129,
      "step": 4049
    },
    {
      "epoch": 0.24024202159212243,
      "grad_norm": 7.360721588134766,
      "learning_rate": 1.688373319272344e-05,
      "loss": 0.087,
      "step": 4050
    },
    {
      "epoch": 0.2403013406097995,
      "grad_norm": 2.904188871383667,
      "learning_rate": 1.6882414974953863e-05,
      "loss": 0.0601,
      "step": 4051
    },
    {
      "epoch": 0.24036065962747657,
      "grad_norm": 12.421533584594727,
      "learning_rate": 1.688109675718429e-05,
      "loss": 0.2607,
      "step": 4052
    },
    {
      "epoch": 0.24041997864515363,
      "grad_norm": 4.325786590576172,
      "learning_rate": 1.687977853941471e-05,
      "loss": 0.0693,
      "step": 4053
    },
    {
      "epoch": 0.24047929766283072,
      "grad_norm": 4.273313999176025,
      "learning_rate": 1.6878460321645137e-05,
      "loss": 0.0513,
      "step": 4054
    },
    {
      "epoch": 0.24053861668050777,
      "grad_norm": 0.24780848622322083,
      "learning_rate": 1.687714210387556e-05,
      "loss": 0.0055,
      "step": 4055
    },
    {
      "epoch": 0.24059793569818483,
      "grad_norm": 3.446629524230957,
      "learning_rate": 1.6875823886105986e-05,
      "loss": 0.0528,
      "step": 4056
    },
    {
      "epoch": 0.2406572547158619,
      "grad_norm": 9.980836868286133,
      "learning_rate": 1.6874505668336408e-05,
      "loss": 0.4072,
      "step": 4057
    },
    {
      "epoch": 0.24071657373353897,
      "grad_norm": 4.196799278259277,
      "learning_rate": 1.6873187450566834e-05,
      "loss": 0.0464,
      "step": 4058
    },
    {
      "epoch": 0.24077589275121605,
      "grad_norm": 0.7586470246315002,
      "learning_rate": 1.687186923279726e-05,
      "loss": 0.0072,
      "step": 4059
    },
    {
      "epoch": 0.2408352117688931,
      "grad_norm": 4.7659010887146,
      "learning_rate": 1.6870551015027682e-05,
      "loss": 0.0736,
      "step": 4060
    },
    {
      "epoch": 0.24089453078657017,
      "grad_norm": 9.717406272888184,
      "learning_rate": 1.686923279725811e-05,
      "loss": 0.4543,
      "step": 4061
    },
    {
      "epoch": 0.24095384980424725,
      "grad_norm": 0.05815145745873451,
      "learning_rate": 1.6867914579488534e-05,
      "loss": 0.0006,
      "step": 4062
    },
    {
      "epoch": 0.2410131688219243,
      "grad_norm": 0.023380937054753304,
      "learning_rate": 1.6866596361718957e-05,
      "loss": 0.0005,
      "step": 4063
    },
    {
      "epoch": 0.24107248783960136,
      "grad_norm": 0.08297119289636612,
      "learning_rate": 1.6865278143949383e-05,
      "loss": 0.0018,
      "step": 4064
    },
    {
      "epoch": 0.24113180685727845,
      "grad_norm": 0.024712182581424713,
      "learning_rate": 1.686395992617981e-05,
      "loss": 0.0007,
      "step": 4065
    },
    {
      "epoch": 0.2411911258749555,
      "grad_norm": 10.25092887878418,
      "learning_rate": 1.686264170841023e-05,
      "loss": 0.2042,
      "step": 4066
    },
    {
      "epoch": 0.2412504448926326,
      "grad_norm": 2.029484987258911,
      "learning_rate": 1.6861323490640657e-05,
      "loss": 0.0337,
      "step": 4067
    },
    {
      "epoch": 0.24130976391030964,
      "grad_norm": 0.0404803603887558,
      "learning_rate": 1.686000527287108e-05,
      "loss": 0.0014,
      "step": 4068
    },
    {
      "epoch": 0.2413690829279867,
      "grad_norm": 33.45989990234375,
      "learning_rate": 1.6858687055101505e-05,
      "loss": 0.5482,
      "step": 4069
    },
    {
      "epoch": 0.24142840194566378,
      "grad_norm": 0.015262525528669357,
      "learning_rate": 1.6857368837331928e-05,
      "loss": 0.0004,
      "step": 4070
    },
    {
      "epoch": 0.24148772096334084,
      "grad_norm": 1.794765830039978,
      "learning_rate": 1.6856050619562354e-05,
      "loss": 0.0234,
      "step": 4071
    },
    {
      "epoch": 0.24154703998101792,
      "grad_norm": 8.341395378112793,
      "learning_rate": 1.6854732401792776e-05,
      "loss": 0.9017,
      "step": 4072
    },
    {
      "epoch": 0.24160635899869498,
      "grad_norm": 0.14338620007038116,
      "learning_rate": 1.6853414184023202e-05,
      "loss": 0.0023,
      "step": 4073
    },
    {
      "epoch": 0.24166567801637204,
      "grad_norm": 3.6265182495117188,
      "learning_rate": 1.6852095966253624e-05,
      "loss": 0.0473,
      "step": 4074
    },
    {
      "epoch": 0.24172499703404912,
      "grad_norm": 12.208039283752441,
      "learning_rate": 1.685077774848405e-05,
      "loss": 0.0481,
      "step": 4075
    },
    {
      "epoch": 0.24178431605172618,
      "grad_norm": 0.1391180008649826,
      "learning_rate": 1.6849459530714476e-05,
      "loss": 0.0024,
      "step": 4076
    },
    {
      "epoch": 0.24184363506940326,
      "grad_norm": 12.997568130493164,
      "learning_rate": 1.68481413129449e-05,
      "loss": 0.0275,
      "step": 4077
    },
    {
      "epoch": 0.24190295408708032,
      "grad_norm": 13.525384902954102,
      "learning_rate": 1.6846823095175325e-05,
      "loss": 0.3594,
      "step": 4078
    },
    {
      "epoch": 0.24196227310475737,
      "grad_norm": 10.027477264404297,
      "learning_rate": 1.684550487740575e-05,
      "loss": 0.2115,
      "step": 4079
    },
    {
      "epoch": 0.24202159212243446,
      "grad_norm": 0.030867232009768486,
      "learning_rate": 1.6844186659636173e-05,
      "loss": 0.0008,
      "step": 4080
    },
    {
      "epoch": 0.24208091114011152,
      "grad_norm": 17.624324798583984,
      "learning_rate": 1.68428684418666e-05,
      "loss": 1.4944,
      "step": 4081
    },
    {
      "epoch": 0.2421402301577886,
      "grad_norm": 0.4849452078342438,
      "learning_rate": 1.684155022409702e-05,
      "loss": 0.0036,
      "step": 4082
    },
    {
      "epoch": 0.24219954917546566,
      "grad_norm": 0.044073399156332016,
      "learning_rate": 1.6840232006327447e-05,
      "loss": 0.0012,
      "step": 4083
    },
    {
      "epoch": 0.2422588681931427,
      "grad_norm": 9.33703327178955,
      "learning_rate": 1.683891378855787e-05,
      "loss": 0.6144,
      "step": 4084
    },
    {
      "epoch": 0.2423181872108198,
      "grad_norm": 2.0731184482574463,
      "learning_rate": 1.6837595570788296e-05,
      "loss": 0.0207,
      "step": 4085
    },
    {
      "epoch": 0.24237750622849685,
      "grad_norm": 0.10026189684867859,
      "learning_rate": 1.6836277353018718e-05,
      "loss": 0.0025,
      "step": 4086
    },
    {
      "epoch": 0.24243682524617394,
      "grad_norm": 11.97087287902832,
      "learning_rate": 1.6834959135249144e-05,
      "loss": 0.0941,
      "step": 4087
    },
    {
      "epoch": 0.242496144263851,
      "grad_norm": 5.654275417327881,
      "learning_rate": 1.683364091747957e-05,
      "loss": 0.0265,
      "step": 4088
    },
    {
      "epoch": 0.24255546328152805,
      "grad_norm": 10.365778923034668,
      "learning_rate": 1.6832322699709992e-05,
      "loss": 0.1632,
      "step": 4089
    },
    {
      "epoch": 0.24261478229920513,
      "grad_norm": 2.019531011581421,
      "learning_rate": 1.6831004481940418e-05,
      "loss": 0.0301,
      "step": 4090
    },
    {
      "epoch": 0.2426741013168822,
      "grad_norm": 0.23904626071453094,
      "learning_rate": 1.682968626417084e-05,
      "loss": 0.0029,
      "step": 4091
    },
    {
      "epoch": 0.24273342033455925,
      "grad_norm": 0.03345412760972977,
      "learning_rate": 1.6828368046401267e-05,
      "loss": 0.0014,
      "step": 4092
    },
    {
      "epoch": 0.24279273935223633,
      "grad_norm": 0.03994118049740791,
      "learning_rate": 1.6827049828631693e-05,
      "loss": 0.0008,
      "step": 4093
    },
    {
      "epoch": 0.2428520583699134,
      "grad_norm": 0.11497973650693893,
      "learning_rate": 1.6825731610862115e-05,
      "loss": 0.0019,
      "step": 4094
    },
    {
      "epoch": 0.24291137738759047,
      "grad_norm": 1.5432186126708984,
      "learning_rate": 1.682441339309254e-05,
      "loss": 0.0166,
      "step": 4095
    },
    {
      "epoch": 0.24297069640526753,
      "grad_norm": 12.644611358642578,
      "learning_rate": 1.6823095175322967e-05,
      "loss": 0.1438,
      "step": 4096
    },
    {
      "epoch": 0.24303001542294458,
      "grad_norm": 1.7091542482376099,
      "learning_rate": 1.682177695755339e-05,
      "loss": 0.028,
      "step": 4097
    },
    {
      "epoch": 0.24308933444062167,
      "grad_norm": 5.634932041168213,
      "learning_rate": 1.6820458739783815e-05,
      "loss": 0.2618,
      "step": 4098
    },
    {
      "epoch": 0.24314865345829872,
      "grad_norm": 38.3167610168457,
      "learning_rate": 1.6819140522014238e-05,
      "loss": 0.3339,
      "step": 4099
    },
    {
      "epoch": 0.2432079724759758,
      "grad_norm": 44.118919372558594,
      "learning_rate": 1.6817822304244664e-05,
      "loss": 0.7581,
      "step": 4100
    },
    {
      "epoch": 0.24326729149365287,
      "grad_norm": 6.52690315246582,
      "learning_rate": 1.6816504086475086e-05,
      "loss": 0.3272,
      "step": 4101
    },
    {
      "epoch": 0.24332661051132992,
      "grad_norm": 6.841809272766113,
      "learning_rate": 1.6815185868705512e-05,
      "loss": 0.1212,
      "step": 4102
    },
    {
      "epoch": 0.243385929529007,
      "grad_norm": 0.026950297877192497,
      "learning_rate": 1.6813867650935934e-05,
      "loss": 0.0008,
      "step": 4103
    },
    {
      "epoch": 0.24344524854668406,
      "grad_norm": 0.12461807578802109,
      "learning_rate": 1.681254943316636e-05,
      "loss": 0.0022,
      "step": 4104
    },
    {
      "epoch": 0.24350456756436115,
      "grad_norm": 8.993120193481445,
      "learning_rate": 1.6811231215396783e-05,
      "loss": 0.4497,
      "step": 4105
    },
    {
      "epoch": 0.2435638865820382,
      "grad_norm": 0.055499766021966934,
      "learning_rate": 1.680991299762721e-05,
      "loss": 0.001,
      "step": 4106
    },
    {
      "epoch": 0.24362320559971526,
      "grad_norm": 0.09943786263465881,
      "learning_rate": 1.6808594779857635e-05,
      "loss": 0.0024,
      "step": 4107
    },
    {
      "epoch": 0.24368252461739234,
      "grad_norm": 3.5010249614715576,
      "learning_rate": 1.6807276562088057e-05,
      "loss": 0.0331,
      "step": 4108
    },
    {
      "epoch": 0.2437418436350694,
      "grad_norm": 3.8865175247192383,
      "learning_rate": 1.6805958344318483e-05,
      "loss": 0.027,
      "step": 4109
    },
    {
      "epoch": 0.24380116265274648,
      "grad_norm": 3.682513475418091,
      "learning_rate": 1.680464012654891e-05,
      "loss": 0.1895,
      "step": 4110
    },
    {
      "epoch": 0.24386048167042354,
      "grad_norm": 16.175188064575195,
      "learning_rate": 1.680332190877933e-05,
      "loss": 0.9795,
      "step": 4111
    },
    {
      "epoch": 0.2439198006881006,
      "grad_norm": 3.3540611267089844,
      "learning_rate": 1.6802003691009757e-05,
      "loss": 0.0568,
      "step": 4112
    },
    {
      "epoch": 0.24397911970577768,
      "grad_norm": 0.12162932753562927,
      "learning_rate": 1.6800685473240183e-05,
      "loss": 0.0019,
      "step": 4113
    },
    {
      "epoch": 0.24403843872345474,
      "grad_norm": 0.4882570803165436,
      "learning_rate": 1.6799367255470606e-05,
      "loss": 0.005,
      "step": 4114
    },
    {
      "epoch": 0.2440977577411318,
      "grad_norm": 16.578187942504883,
      "learning_rate": 1.6798049037701028e-05,
      "loss": 0.3473,
      "step": 4115
    },
    {
      "epoch": 0.24415707675880888,
      "grad_norm": 2.6796207427978516,
      "learning_rate": 1.6796730819931454e-05,
      "loss": 0.0207,
      "step": 4116
    },
    {
      "epoch": 0.24421639577648593,
      "grad_norm": 20.363866806030273,
      "learning_rate": 1.6795412602161876e-05,
      "loss": 0.3176,
      "step": 4117
    },
    {
      "epoch": 0.24427571479416302,
      "grad_norm": 9.537150382995605,
      "learning_rate": 1.6794094384392302e-05,
      "loss": 0.3478,
      "step": 4118
    },
    {
      "epoch": 0.24433503381184007,
      "grad_norm": 0.08402115851640701,
      "learning_rate": 1.6792776166622728e-05,
      "loss": 0.0011,
      "step": 4119
    },
    {
      "epoch": 0.24439435282951713,
      "grad_norm": 0.019619697704911232,
      "learning_rate": 1.679145794885315e-05,
      "loss": 0.0005,
      "step": 4120
    },
    {
      "epoch": 0.24445367184719421,
      "grad_norm": 6.320353031158447,
      "learning_rate": 1.6790139731083577e-05,
      "loss": 0.1032,
      "step": 4121
    },
    {
      "epoch": 0.24451299086487127,
      "grad_norm": 12.796154022216797,
      "learning_rate": 1.6788821513314e-05,
      "loss": 0.2062,
      "step": 4122
    },
    {
      "epoch": 0.24457230988254836,
      "grad_norm": 0.04822568595409393,
      "learning_rate": 1.6787503295544425e-05,
      "loss": 0.0008,
      "step": 4123
    },
    {
      "epoch": 0.2446316289002254,
      "grad_norm": 1.3086950778961182,
      "learning_rate": 1.678618507777485e-05,
      "loss": 0.0189,
      "step": 4124
    },
    {
      "epoch": 0.24469094791790247,
      "grad_norm": 0.9442541599273682,
      "learning_rate": 1.6784866860005273e-05,
      "loss": 0.0087,
      "step": 4125
    },
    {
      "epoch": 0.24475026693557955,
      "grad_norm": 0.03723163902759552,
      "learning_rate": 1.67835486422357e-05,
      "loss": 0.0006,
      "step": 4126
    },
    {
      "epoch": 0.2448095859532566,
      "grad_norm": 9.612001419067383,
      "learning_rate": 1.6782230424466125e-05,
      "loss": 0.2235,
      "step": 4127
    },
    {
      "epoch": 0.2448689049709337,
      "grad_norm": 9.071025848388672,
      "learning_rate": 1.6780912206696548e-05,
      "loss": 0.1338,
      "step": 4128
    },
    {
      "epoch": 0.24492822398861075,
      "grad_norm": 7.365016460418701,
      "learning_rate": 1.6779593988926973e-05,
      "loss": 0.3585,
      "step": 4129
    },
    {
      "epoch": 0.2449875430062878,
      "grad_norm": 0.23956340551376343,
      "learning_rate": 1.6778275771157396e-05,
      "loss": 0.0026,
      "step": 4130
    },
    {
      "epoch": 0.2450468620239649,
      "grad_norm": 1.4432412385940552,
      "learning_rate": 1.6776957553387822e-05,
      "loss": 0.0172,
      "step": 4131
    },
    {
      "epoch": 0.24510618104164195,
      "grad_norm": 7.24601936340332,
      "learning_rate": 1.6775639335618244e-05,
      "loss": 0.1079,
      "step": 4132
    },
    {
      "epoch": 0.24516550005931903,
      "grad_norm": 34.33693313598633,
      "learning_rate": 1.677432111784867e-05,
      "loss": 0.9007,
      "step": 4133
    },
    {
      "epoch": 0.2452248190769961,
      "grad_norm": 0.7581024169921875,
      "learning_rate": 1.6773002900079093e-05,
      "loss": 0.0062,
      "step": 4134
    },
    {
      "epoch": 0.24528413809467314,
      "grad_norm": 2.416574001312256,
      "learning_rate": 1.677168468230952e-05,
      "loss": 0.0141,
      "step": 4135
    },
    {
      "epoch": 0.24534345711235023,
      "grad_norm": 8.712681770324707,
      "learning_rate": 1.6770366464539944e-05,
      "loss": 0.256,
      "step": 4136
    },
    {
      "epoch": 0.24540277613002728,
      "grad_norm": 3.8123703002929688,
      "learning_rate": 1.6769048246770367e-05,
      "loss": 0.0546,
      "step": 4137
    },
    {
      "epoch": 0.24546209514770437,
      "grad_norm": 2.7801194190979004,
      "learning_rate": 1.6767730029000793e-05,
      "loss": 0.0148,
      "step": 4138
    },
    {
      "epoch": 0.24552141416538142,
      "grad_norm": 12.657750129699707,
      "learning_rate": 1.6766411811231215e-05,
      "loss": 0.2577,
      "step": 4139
    },
    {
      "epoch": 0.24558073318305848,
      "grad_norm": 22.381427764892578,
      "learning_rate": 1.676509359346164e-05,
      "loss": 0.3956,
      "step": 4140
    },
    {
      "epoch": 0.24564005220073556,
      "grad_norm": 4.395190715789795,
      "learning_rate": 1.6763775375692067e-05,
      "loss": 0.0597,
      "step": 4141
    },
    {
      "epoch": 0.24569937121841262,
      "grad_norm": 8.823283195495605,
      "learning_rate": 1.676245715792249e-05,
      "loss": 0.3066,
      "step": 4142
    },
    {
      "epoch": 0.24575869023608968,
      "grad_norm": 53.09052658081055,
      "learning_rate": 1.6761138940152915e-05,
      "loss": 2.6239,
      "step": 4143
    },
    {
      "epoch": 0.24581800925376676,
      "grad_norm": 0.7890408039093018,
      "learning_rate": 1.675982072238334e-05,
      "loss": 0.007,
      "step": 4144
    },
    {
      "epoch": 0.24587732827144382,
      "grad_norm": 0.25176700949668884,
      "learning_rate": 1.6758502504613764e-05,
      "loss": 0.0009,
      "step": 4145
    },
    {
      "epoch": 0.2459366472891209,
      "grad_norm": 0.5107918977737427,
      "learning_rate": 1.675718428684419e-05,
      "loss": 0.0029,
      "step": 4146
    },
    {
      "epoch": 0.24599596630679796,
      "grad_norm": 4.527586460113525,
      "learning_rate": 1.6755866069074612e-05,
      "loss": 0.2359,
      "step": 4147
    },
    {
      "epoch": 0.24605528532447501,
      "grad_norm": 1.9112114906311035,
      "learning_rate": 1.6754547851305038e-05,
      "loss": 0.0289,
      "step": 4148
    },
    {
      "epoch": 0.2461146043421521,
      "grad_norm": 0.5460745096206665,
      "learning_rate": 1.675322963353546e-05,
      "loss": 0.0056,
      "step": 4149
    },
    {
      "epoch": 0.24617392335982916,
      "grad_norm": 0.08810238540172577,
      "learning_rate": 1.6751911415765886e-05,
      "loss": 0.0013,
      "step": 4150
    },
    {
      "epoch": 0.24623324237750624,
      "grad_norm": 24.44417953491211,
      "learning_rate": 1.675059319799631e-05,
      "loss": 1.7091,
      "step": 4151
    },
    {
      "epoch": 0.2462925613951833,
      "grad_norm": 10.97189998626709,
      "learning_rate": 1.6749274980226735e-05,
      "loss": 0.2087,
      "step": 4152
    },
    {
      "epoch": 0.24635188041286035,
      "grad_norm": 2.394777536392212,
      "learning_rate": 1.674795676245716e-05,
      "loss": 0.0254,
      "step": 4153
    },
    {
      "epoch": 0.24641119943053744,
      "grad_norm": 8.498712539672852,
      "learning_rate": 1.6746638544687583e-05,
      "loss": 0.2832,
      "step": 4154
    },
    {
      "epoch": 0.2464705184482145,
      "grad_norm": 9.936985969543457,
      "learning_rate": 1.674532032691801e-05,
      "loss": 0.1314,
      "step": 4155
    },
    {
      "epoch": 0.24652983746589158,
      "grad_norm": 8.498617172241211,
      "learning_rate": 1.674400210914843e-05,
      "loss": 0.4411,
      "step": 4156
    },
    {
      "epoch": 0.24658915648356863,
      "grad_norm": 2.0712621212005615,
      "learning_rate": 1.6742683891378857e-05,
      "loss": 0.0232,
      "step": 4157
    },
    {
      "epoch": 0.2466484755012457,
      "grad_norm": 1.3243952989578247,
      "learning_rate": 1.6741365673609283e-05,
      "loss": 0.0118,
      "step": 4158
    },
    {
      "epoch": 0.24670779451892277,
      "grad_norm": 1.25478196144104,
      "learning_rate": 1.6740047455839706e-05,
      "loss": 0.0154,
      "step": 4159
    },
    {
      "epoch": 0.24676711353659983,
      "grad_norm": 17.867565155029297,
      "learning_rate": 1.673872923807013e-05,
      "loss": 0.6334,
      "step": 4160
    },
    {
      "epoch": 0.24682643255427691,
      "grad_norm": 0.04724130034446716,
      "learning_rate": 1.6737411020300554e-05,
      "loss": 0.0011,
      "step": 4161
    },
    {
      "epoch": 0.24688575157195397,
      "grad_norm": 15.132333755493164,
      "learning_rate": 1.673609280253098e-05,
      "loss": 0.5506,
      "step": 4162
    },
    {
      "epoch": 0.24694507058963103,
      "grad_norm": 4.325550556182861,
      "learning_rate": 1.6734774584761403e-05,
      "loss": 0.157,
      "step": 4163
    },
    {
      "epoch": 0.2470043896073081,
      "grad_norm": 5.074868679046631,
      "learning_rate": 1.673345636699183e-05,
      "loss": 0.0494,
      "step": 4164
    },
    {
      "epoch": 0.24706370862498517,
      "grad_norm": 0.029112253338098526,
      "learning_rate": 1.673213814922225e-05,
      "loss": 0.0007,
      "step": 4165
    },
    {
      "epoch": 0.24712302764266222,
      "grad_norm": 1.1274288892745972,
      "learning_rate": 1.6730819931452677e-05,
      "loss": 0.0124,
      "step": 4166
    },
    {
      "epoch": 0.2471823466603393,
      "grad_norm": 2.091003179550171,
      "learning_rate": 1.6729501713683103e-05,
      "loss": 0.0312,
      "step": 4167
    },
    {
      "epoch": 0.24724166567801636,
      "grad_norm": 0.6763787865638733,
      "learning_rate": 1.6728183495913525e-05,
      "loss": 0.0131,
      "step": 4168
    },
    {
      "epoch": 0.24730098469569345,
      "grad_norm": 7.446369171142578,
      "learning_rate": 1.672686527814395e-05,
      "loss": 0.0361,
      "step": 4169
    },
    {
      "epoch": 0.2473603037133705,
      "grad_norm": 5.182376861572266,
      "learning_rate": 1.6725547060374374e-05,
      "loss": 0.1003,
      "step": 4170
    },
    {
      "epoch": 0.24741962273104756,
      "grad_norm": 0.015511018224060535,
      "learning_rate": 1.67242288426048e-05,
      "loss": 0.0006,
      "step": 4171
    },
    {
      "epoch": 0.24747894174872465,
      "grad_norm": 8.160909652709961,
      "learning_rate": 1.6722910624835225e-05,
      "loss": 0.0921,
      "step": 4172
    },
    {
      "epoch": 0.2475382607664017,
      "grad_norm": 1.1600911617279053,
      "learning_rate": 1.6721592407065648e-05,
      "loss": 0.0091,
      "step": 4173
    },
    {
      "epoch": 0.2475975797840788,
      "grad_norm": 0.03659861534833908,
      "learning_rate": 1.6720274189296074e-05,
      "loss": 0.001,
      "step": 4174
    },
    {
      "epoch": 0.24765689880175584,
      "grad_norm": 10.159550666809082,
      "learning_rate": 1.67189559715265e-05,
      "loss": 0.3352,
      "step": 4175
    },
    {
      "epoch": 0.2477162178194329,
      "grad_norm": 14.691733360290527,
      "learning_rate": 1.6717637753756922e-05,
      "loss": 0.3633,
      "step": 4176
    },
    {
      "epoch": 0.24777553683710998,
      "grad_norm": 5.43265962600708,
      "learning_rate": 1.6716319535987348e-05,
      "loss": 0.0999,
      "step": 4177
    },
    {
      "epoch": 0.24783485585478704,
      "grad_norm": 13.087454795837402,
      "learning_rate": 1.671500131821777e-05,
      "loss": 0.1022,
      "step": 4178
    },
    {
      "epoch": 0.24789417487246412,
      "grad_norm": 9.757514953613281,
      "learning_rate": 1.6713683100448196e-05,
      "loss": 0.2637,
      "step": 4179
    },
    {
      "epoch": 0.24795349389014118,
      "grad_norm": 8.888648986816406,
      "learning_rate": 1.671236488267862e-05,
      "loss": 0.1922,
      "step": 4180
    },
    {
      "epoch": 0.24801281290781824,
      "grad_norm": 4.389613151550293,
      "learning_rate": 1.6711046664909045e-05,
      "loss": 0.0835,
      "step": 4181
    },
    {
      "epoch": 0.24807213192549532,
      "grad_norm": 0.01707356423139572,
      "learning_rate": 1.6709728447139467e-05,
      "loss": 0.0005,
      "step": 4182
    },
    {
      "epoch": 0.24813145094317238,
      "grad_norm": 1.101613998413086,
      "learning_rate": 1.6708410229369893e-05,
      "loss": 0.0072,
      "step": 4183
    },
    {
      "epoch": 0.24819076996084946,
      "grad_norm": 1.9481645822525024,
      "learning_rate": 1.670709201160032e-05,
      "loss": 0.0173,
      "step": 4184
    },
    {
      "epoch": 0.24825008897852652,
      "grad_norm": 2.9266927242279053,
      "learning_rate": 1.670577379383074e-05,
      "loss": 0.035,
      "step": 4185
    },
    {
      "epoch": 0.24830940799620357,
      "grad_norm": 9.791129112243652,
      "learning_rate": 1.6704455576061167e-05,
      "loss": 0.1287,
      "step": 4186
    },
    {
      "epoch": 0.24836872701388066,
      "grad_norm": 0.19093956053256989,
      "learning_rate": 1.670313735829159e-05,
      "loss": 0.002,
      "step": 4187
    },
    {
      "epoch": 0.24842804603155771,
      "grad_norm": 0.7659286856651306,
      "learning_rate": 1.6701819140522016e-05,
      "loss": 0.0059,
      "step": 4188
    },
    {
      "epoch": 0.2484873650492348,
      "grad_norm": 7.7396039962768555,
      "learning_rate": 1.670050092275244e-05,
      "loss": 0.4648,
      "step": 4189
    },
    {
      "epoch": 0.24854668406691185,
      "grad_norm": 2.054677963256836,
      "learning_rate": 1.6699182704982864e-05,
      "loss": 0.0059,
      "step": 4190
    },
    {
      "epoch": 0.2486060030845889,
      "grad_norm": 10.262627601623535,
      "learning_rate": 1.669786448721329e-05,
      "loss": 0.6395,
      "step": 4191
    },
    {
      "epoch": 0.248665322102266,
      "grad_norm": 1.2299540042877197,
      "learning_rate": 1.6696546269443716e-05,
      "loss": 0.0111,
      "step": 4192
    },
    {
      "epoch": 0.24872464111994305,
      "grad_norm": 3.922884941101074,
      "learning_rate": 1.669522805167414e-05,
      "loss": 0.0204,
      "step": 4193
    },
    {
      "epoch": 0.2487839601376201,
      "grad_norm": 0.12298022955656052,
      "learning_rate": 1.669390983390456e-05,
      "loss": 0.0006,
      "step": 4194
    },
    {
      "epoch": 0.2488432791552972,
      "grad_norm": 1.1282581090927124,
      "learning_rate": 1.6692591616134987e-05,
      "loss": 0.0116,
      "step": 4195
    },
    {
      "epoch": 0.24890259817297425,
      "grad_norm": 0.04445933550596237,
      "learning_rate": 1.669127339836541e-05,
      "loss": 0.0011,
      "step": 4196
    },
    {
      "epoch": 0.24896191719065133,
      "grad_norm": 0.15349464118480682,
      "learning_rate": 1.6689955180595835e-05,
      "loss": 0.0037,
      "step": 4197
    },
    {
      "epoch": 0.2490212362083284,
      "grad_norm": 0.2046564519405365,
      "learning_rate": 1.668863696282626e-05,
      "loss": 0.0038,
      "step": 4198
    },
    {
      "epoch": 0.24908055522600545,
      "grad_norm": 12.811121940612793,
      "learning_rate": 1.6687318745056683e-05,
      "loss": 0.2296,
      "step": 4199
    },
    {
      "epoch": 0.24913987424368253,
      "grad_norm": 3.5828123092651367,
      "learning_rate": 1.668600052728711e-05,
      "loss": 0.0835,
      "step": 4200
    },
    {
      "epoch": 0.2491991932613596,
      "grad_norm": 0.12293851375579834,
      "learning_rate": 1.6684682309517535e-05,
      "loss": 0.0022,
      "step": 4201
    },
    {
      "epoch": 0.24925851227903667,
      "grad_norm": 1.1414738893508911,
      "learning_rate": 1.6683364091747958e-05,
      "loss": 0.0092,
      "step": 4202
    },
    {
      "epoch": 0.24931783129671373,
      "grad_norm": 0.04922151193022728,
      "learning_rate": 1.6682045873978384e-05,
      "loss": 0.0008,
      "step": 4203
    },
    {
      "epoch": 0.24937715031439078,
      "grad_norm": 1.8919811248779297,
      "learning_rate": 1.6680727656208806e-05,
      "loss": 0.0216,
      "step": 4204
    },
    {
      "epoch": 0.24943646933206787,
      "grad_norm": 0.08178401738405228,
      "learning_rate": 1.6679409438439232e-05,
      "loss": 0.002,
      "step": 4205
    },
    {
      "epoch": 0.24949578834974492,
      "grad_norm": 0.8805055618286133,
      "learning_rate": 1.6678091220669658e-05,
      "loss": 0.0113,
      "step": 4206
    },
    {
      "epoch": 0.249555107367422,
      "grad_norm": 6.6201395988464355,
      "learning_rate": 1.667677300290008e-05,
      "loss": 0.0548,
      "step": 4207
    },
    {
      "epoch": 0.24961442638509906,
      "grad_norm": 16.573001861572266,
      "learning_rate": 1.6675454785130506e-05,
      "loss": 0.0841,
      "step": 4208
    },
    {
      "epoch": 0.24967374540277612,
      "grad_norm": 6.042990684509277,
      "learning_rate": 1.667413656736093e-05,
      "loss": 0.1663,
      "step": 4209
    },
    {
      "epoch": 0.2497330644204532,
      "grad_norm": 14.774015426635742,
      "learning_rate": 1.6672818349591355e-05,
      "loss": 0.2519,
      "step": 4210
    },
    {
      "epoch": 0.24979238343813026,
      "grad_norm": 0.09170757979154587,
      "learning_rate": 1.6671500131821777e-05,
      "loss": 0.0015,
      "step": 4211
    },
    {
      "epoch": 0.24985170245580735,
      "grad_norm": 13.628978729248047,
      "learning_rate": 1.6670181914052203e-05,
      "loss": 0.5278,
      "step": 4212
    },
    {
      "epoch": 0.2499110214734844,
      "grad_norm": 0.04520297795534134,
      "learning_rate": 1.6668863696282625e-05,
      "loss": 0.0006,
      "step": 4213
    },
    {
      "epoch": 0.24997034049116146,
      "grad_norm": 6.144725799560547,
      "learning_rate": 1.666754547851305e-05,
      "loss": 0.28,
      "step": 4214
    },
    {
      "epoch": 0.25002965950883854,
      "grad_norm": 4.292305946350098,
      "learning_rate": 1.6666227260743477e-05,
      "loss": 0.0599,
      "step": 4215
    },
    {
      "epoch": 0.2500889785265156,
      "grad_norm": 3.2552530765533447,
      "learning_rate": 1.66649090429739e-05,
      "loss": 0.0331,
      "step": 4216
    },
    {
      "epoch": 0.25014829754419265,
      "grad_norm": 0.01900612935423851,
      "learning_rate": 1.6663590825204326e-05,
      "loss": 0.0006,
      "step": 4217
    },
    {
      "epoch": 0.25020761656186974,
      "grad_norm": 10.589741706848145,
      "learning_rate": 1.6662272607434748e-05,
      "loss": 0.3916,
      "step": 4218
    },
    {
      "epoch": 0.2502669355795468,
      "grad_norm": 0.6470270752906799,
      "learning_rate": 1.6660954389665174e-05,
      "loss": 0.0043,
      "step": 4219
    },
    {
      "epoch": 0.25032625459722385,
      "grad_norm": 0.0643315464258194,
      "learning_rate": 1.66596361718956e-05,
      "loss": 0.0015,
      "step": 4220
    },
    {
      "epoch": 0.25038557361490094,
      "grad_norm": 0.0714547410607338,
      "learning_rate": 1.6658317954126022e-05,
      "loss": 0.0017,
      "step": 4221
    },
    {
      "epoch": 0.250444892632578,
      "grad_norm": 2.239403247833252,
      "learning_rate": 1.6656999736356448e-05,
      "loss": 0.0306,
      "step": 4222
    },
    {
      "epoch": 0.25050421165025505,
      "grad_norm": 29.695985794067383,
      "learning_rate": 1.6655681518586874e-05,
      "loss": 1.4211,
      "step": 4223
    },
    {
      "epoch": 0.25056353066793213,
      "grad_norm": 0.8070073127746582,
      "learning_rate": 1.6654363300817297e-05,
      "loss": 0.0077,
      "step": 4224
    },
    {
      "epoch": 0.2506228496856092,
      "grad_norm": 3.1091911792755127,
      "learning_rate": 1.6653045083047722e-05,
      "loss": 0.0292,
      "step": 4225
    },
    {
      "epoch": 0.2506821687032863,
      "grad_norm": 17.0052490234375,
      "learning_rate": 1.6651726865278145e-05,
      "loss": 0.3908,
      "step": 4226
    },
    {
      "epoch": 0.25074148772096333,
      "grad_norm": 6.109626770019531,
      "learning_rate": 1.6650408647508567e-05,
      "loss": 0.0658,
      "step": 4227
    },
    {
      "epoch": 0.2508008067386404,
      "grad_norm": 0.3124513626098633,
      "learning_rate": 1.6649090429738993e-05,
      "loss": 0.0031,
      "step": 4228
    },
    {
      "epoch": 0.2508601257563175,
      "grad_norm": 8.161359786987305,
      "learning_rate": 1.664777221196942e-05,
      "loss": 0.1056,
      "step": 4229
    },
    {
      "epoch": 0.2509194447739945,
      "grad_norm": 3.726262092590332,
      "learning_rate": 1.6646453994199842e-05,
      "loss": 0.0318,
      "step": 4230
    },
    {
      "epoch": 0.2509787637916716,
      "grad_norm": 0.21905457973480225,
      "learning_rate": 1.6645135776430268e-05,
      "loss": 0.0016,
      "step": 4231
    },
    {
      "epoch": 0.2510380828093487,
      "grad_norm": 0.02436450682580471,
      "learning_rate": 1.6643817558660693e-05,
      "loss": 0.0007,
      "step": 4232
    },
    {
      "epoch": 0.2510974018270257,
      "grad_norm": 5.4282708168029785,
      "learning_rate": 1.6642499340891116e-05,
      "loss": 0.0542,
      "step": 4233
    },
    {
      "epoch": 0.2511567208447028,
      "grad_norm": 0.9592070579528809,
      "learning_rate": 1.6641181123121542e-05,
      "loss": 0.0218,
      "step": 4234
    },
    {
      "epoch": 0.2512160398623799,
      "grad_norm": 0.035308778285980225,
      "learning_rate": 1.6639862905351964e-05,
      "loss": 0.0008,
      "step": 4235
    },
    {
      "epoch": 0.2512753588800569,
      "grad_norm": 3.945058822631836,
      "learning_rate": 1.663854468758239e-05,
      "loss": 0.0775,
      "step": 4236
    },
    {
      "epoch": 0.251334677897734,
      "grad_norm": 14.783682823181152,
      "learning_rate": 1.6637226469812816e-05,
      "loss": 0.9563,
      "step": 4237
    },
    {
      "epoch": 0.2513939969154111,
      "grad_norm": 15.435105323791504,
      "learning_rate": 1.663590825204324e-05,
      "loss": 0.2462,
      "step": 4238
    },
    {
      "epoch": 0.2514533159330882,
      "grad_norm": 9.730367660522461,
      "learning_rate": 1.6634590034273664e-05,
      "loss": 0.3001,
      "step": 4239
    },
    {
      "epoch": 0.2515126349507652,
      "grad_norm": 0.389242559671402,
      "learning_rate": 1.6633271816504087e-05,
      "loss": 0.004,
      "step": 4240
    },
    {
      "epoch": 0.2515719539684423,
      "grad_norm": 0.38846156001091003,
      "learning_rate": 1.6631953598734513e-05,
      "loss": 0.0056,
      "step": 4241
    },
    {
      "epoch": 0.25163127298611937,
      "grad_norm": 0.06011221930384636,
      "learning_rate": 1.6630635380964935e-05,
      "loss": 0.0019,
      "step": 4242
    },
    {
      "epoch": 0.2516905920037964,
      "grad_norm": 14.435778617858887,
      "learning_rate": 1.662931716319536e-05,
      "loss": 0.0749,
      "step": 4243
    },
    {
      "epoch": 0.2517499110214735,
      "grad_norm": 0.4733010232448578,
      "learning_rate": 1.6627998945425784e-05,
      "loss": 0.0029,
      "step": 4244
    },
    {
      "epoch": 0.25180923003915057,
      "grad_norm": 0.1135842502117157,
      "learning_rate": 1.662668072765621e-05,
      "loss": 0.0021,
      "step": 4245
    },
    {
      "epoch": 0.2518685490568276,
      "grad_norm": 0.3698074221611023,
      "learning_rate": 1.6625362509886635e-05,
      "loss": 0.005,
      "step": 4246
    },
    {
      "epoch": 0.2519278680745047,
      "grad_norm": 0.007731759920716286,
      "learning_rate": 1.6624044292117058e-05,
      "loss": 0.0002,
      "step": 4247
    },
    {
      "epoch": 0.25198718709218176,
      "grad_norm": 3.369687080383301,
      "learning_rate": 1.6622726074347484e-05,
      "loss": 0.0556,
      "step": 4248
    },
    {
      "epoch": 0.25204650610985885,
      "grad_norm": 0.011636540293693542,
      "learning_rate": 1.662140785657791e-05,
      "loss": 0.0002,
      "step": 4249
    },
    {
      "epoch": 0.2521058251275359,
      "grad_norm": 8.336437225341797,
      "learning_rate": 1.6620089638808332e-05,
      "loss": 0.4992,
      "step": 4250
    },
    {
      "epoch": 0.25216514414521296,
      "grad_norm": 0.8132568597793579,
      "learning_rate": 1.6618771421038758e-05,
      "loss": 0.0083,
      "step": 4251
    },
    {
      "epoch": 0.25222446316289004,
      "grad_norm": 13.443684577941895,
      "learning_rate": 1.661745320326918e-05,
      "loss": 0.3583,
      "step": 4252
    },
    {
      "epoch": 0.2522837821805671,
      "grad_norm": 0.02251606062054634,
      "learning_rate": 1.6616134985499606e-05,
      "loss": 0.0004,
      "step": 4253
    },
    {
      "epoch": 0.25234310119824416,
      "grad_norm": 0.32565590739250183,
      "learning_rate": 1.6614816767730032e-05,
      "loss": 0.0028,
      "step": 4254
    },
    {
      "epoch": 0.25240242021592124,
      "grad_norm": 13.425004959106445,
      "learning_rate": 1.6613498549960455e-05,
      "loss": 0.9972,
      "step": 4255
    },
    {
      "epoch": 0.25246173923359827,
      "grad_norm": 4.0901360511779785,
      "learning_rate": 1.661218033219088e-05,
      "loss": 0.0483,
      "step": 4256
    },
    {
      "epoch": 0.25252105825127535,
      "grad_norm": 0.29022151231765747,
      "learning_rate": 1.6610862114421303e-05,
      "loss": 0.0027,
      "step": 4257
    },
    {
      "epoch": 0.25258037726895244,
      "grad_norm": 14.112406730651855,
      "learning_rate": 1.660954389665173e-05,
      "loss": 0.7017,
      "step": 4258
    },
    {
      "epoch": 0.25263969628662947,
      "grad_norm": 12.97963809967041,
      "learning_rate": 1.660822567888215e-05,
      "loss": 0.534,
      "step": 4259
    },
    {
      "epoch": 0.25269901530430655,
      "grad_norm": 3.422400951385498,
      "learning_rate": 1.6606907461112577e-05,
      "loss": 0.0182,
      "step": 4260
    },
    {
      "epoch": 0.25275833432198364,
      "grad_norm": 13.891805648803711,
      "learning_rate": 1.6605589243343e-05,
      "loss": 1.0352,
      "step": 4261
    },
    {
      "epoch": 0.2528176533396607,
      "grad_norm": 0.04198209568858147,
      "learning_rate": 1.6604271025573426e-05,
      "loss": 0.0009,
      "step": 4262
    },
    {
      "epoch": 0.25287697235733775,
      "grad_norm": 6.625669479370117,
      "learning_rate": 1.6602952807803852e-05,
      "loss": 0.199,
      "step": 4263
    },
    {
      "epoch": 0.25293629137501483,
      "grad_norm": 5.6535491943359375,
      "learning_rate": 1.6601634590034274e-05,
      "loss": 0.0649,
      "step": 4264
    },
    {
      "epoch": 0.2529956103926919,
      "grad_norm": 0.024493766948580742,
      "learning_rate": 1.66003163722647e-05,
      "loss": 0.0004,
      "step": 4265
    },
    {
      "epoch": 0.25305492941036895,
      "grad_norm": 4.107476234436035,
      "learning_rate": 1.6598998154495123e-05,
      "loss": 0.0447,
      "step": 4266
    },
    {
      "epoch": 0.25311424842804603,
      "grad_norm": 12.81560230255127,
      "learning_rate": 1.659767993672555e-05,
      "loss": 0.2016,
      "step": 4267
    },
    {
      "epoch": 0.2531735674457231,
      "grad_norm": 7.019373416900635,
      "learning_rate": 1.6596361718955974e-05,
      "loss": 0.1718,
      "step": 4268
    },
    {
      "epoch": 0.25323288646340014,
      "grad_norm": 1.995302438735962,
      "learning_rate": 1.6595043501186397e-05,
      "loss": 0.0578,
      "step": 4269
    },
    {
      "epoch": 0.2532922054810772,
      "grad_norm": 0.04367951676249504,
      "learning_rate": 1.6593725283416823e-05,
      "loss": 0.0009,
      "step": 4270
    },
    {
      "epoch": 0.2533515244987543,
      "grad_norm": 2.9577999114990234,
      "learning_rate": 1.6592407065647245e-05,
      "loss": 0.0159,
      "step": 4271
    },
    {
      "epoch": 0.2534108435164314,
      "grad_norm": 10.955221176147461,
      "learning_rate": 1.659108884787767e-05,
      "loss": 0.2499,
      "step": 4272
    },
    {
      "epoch": 0.2534701625341084,
      "grad_norm": 0.05764847993850708,
      "learning_rate": 1.6589770630108094e-05,
      "loss": 0.0015,
      "step": 4273
    },
    {
      "epoch": 0.2535294815517855,
      "grad_norm": 25.272533416748047,
      "learning_rate": 1.658845241233852e-05,
      "loss": 0.5547,
      "step": 4274
    },
    {
      "epoch": 0.2535888005694626,
      "grad_norm": 3.8682520389556885,
      "learning_rate": 1.6587134194568942e-05,
      "loss": 0.0553,
      "step": 4275
    },
    {
      "epoch": 0.2536481195871396,
      "grad_norm": 8.811524391174316,
      "learning_rate": 1.6585815976799368e-05,
      "loss": 0.259,
      "step": 4276
    },
    {
      "epoch": 0.2537074386048167,
      "grad_norm": 1.343663215637207,
      "learning_rate": 1.6584497759029794e-05,
      "loss": 0.0091,
      "step": 4277
    },
    {
      "epoch": 0.2537667576224938,
      "grad_norm": 0.019329054281115532,
      "learning_rate": 1.6583179541260216e-05,
      "loss": 0.0005,
      "step": 4278
    },
    {
      "epoch": 0.2538260766401708,
      "grad_norm": 6.387125015258789,
      "learning_rate": 1.6581861323490642e-05,
      "loss": 0.0477,
      "step": 4279
    },
    {
      "epoch": 0.2538853956578479,
      "grad_norm": 11.937993049621582,
      "learning_rate": 1.6580543105721068e-05,
      "loss": 0.3451,
      "step": 4280
    },
    {
      "epoch": 0.253944714675525,
      "grad_norm": 1.671335220336914,
      "learning_rate": 1.657922488795149e-05,
      "loss": 0.0114,
      "step": 4281
    },
    {
      "epoch": 0.254004033693202,
      "grad_norm": 1.3361239433288574,
      "learning_rate": 1.6577906670181916e-05,
      "loss": 0.0084,
      "step": 4282
    },
    {
      "epoch": 0.2540633527108791,
      "grad_norm": 15.799659729003906,
      "learning_rate": 1.657658845241234e-05,
      "loss": 0.2654,
      "step": 4283
    },
    {
      "epoch": 0.2541226717285562,
      "grad_norm": 0.22379787266254425,
      "learning_rate": 1.6575270234642765e-05,
      "loss": 0.003,
      "step": 4284
    },
    {
      "epoch": 0.25418199074623327,
      "grad_norm": 8.603541374206543,
      "learning_rate": 1.657395201687319e-05,
      "loss": 0.0393,
      "step": 4285
    },
    {
      "epoch": 0.2542413097639103,
      "grad_norm": 18.382766723632812,
      "learning_rate": 1.6572633799103613e-05,
      "loss": 0.9896,
      "step": 4286
    },
    {
      "epoch": 0.2543006287815874,
      "grad_norm": 30.959257125854492,
      "learning_rate": 1.657131558133404e-05,
      "loss": 0.8387,
      "step": 4287
    },
    {
      "epoch": 0.25435994779926446,
      "grad_norm": 0.02673184871673584,
      "learning_rate": 1.656999736356446e-05,
      "loss": 0.0009,
      "step": 4288
    },
    {
      "epoch": 0.2544192668169415,
      "grad_norm": 7.969640731811523,
      "learning_rate": 1.6568679145794887e-05,
      "loss": 0.1044,
      "step": 4289
    },
    {
      "epoch": 0.2544785858346186,
      "grad_norm": 0.3316793143749237,
      "learning_rate": 1.656736092802531e-05,
      "loss": 0.0067,
      "step": 4290
    },
    {
      "epoch": 0.25453790485229566,
      "grad_norm": 2.3229687213897705,
      "learning_rate": 1.6566042710255736e-05,
      "loss": 0.0076,
      "step": 4291
    },
    {
      "epoch": 0.2545972238699727,
      "grad_norm": 10.739134788513184,
      "learning_rate": 1.6564724492486158e-05,
      "loss": 0.1835,
      "step": 4292
    },
    {
      "epoch": 0.2546565428876498,
      "grad_norm": 7.150609970092773,
      "learning_rate": 1.6563406274716584e-05,
      "loss": 0.1349,
      "step": 4293
    },
    {
      "epoch": 0.25471586190532686,
      "grad_norm": 1.3849608898162842,
      "learning_rate": 1.656208805694701e-05,
      "loss": 0.0163,
      "step": 4294
    },
    {
      "epoch": 0.25477518092300394,
      "grad_norm": 2.7351202964782715,
      "learning_rate": 1.6560769839177433e-05,
      "loss": 0.054,
      "step": 4295
    },
    {
      "epoch": 0.25483449994068097,
      "grad_norm": 4.066506862640381,
      "learning_rate": 1.655945162140786e-05,
      "loss": 0.0652,
      "step": 4296
    },
    {
      "epoch": 0.25489381895835805,
      "grad_norm": 0.03801065683364868,
      "learning_rate": 1.6558133403638284e-05,
      "loss": 0.0008,
      "step": 4297
    },
    {
      "epoch": 0.25495313797603514,
      "grad_norm": 20.80196762084961,
      "learning_rate": 1.6556815185868707e-05,
      "loss": 0.2258,
      "step": 4298
    },
    {
      "epoch": 0.25501245699371217,
      "grad_norm": 2.46584415435791,
      "learning_rate": 1.6555496968099133e-05,
      "loss": 0.0383,
      "step": 4299
    },
    {
      "epoch": 0.25507177601138925,
      "grad_norm": 15.921355247497559,
      "learning_rate": 1.6554178750329555e-05,
      "loss": 3.0281,
      "step": 4300
    },
    {
      "epoch": 0.25513109502906633,
      "grad_norm": 0.14198008179664612,
      "learning_rate": 1.655286053255998e-05,
      "loss": 0.0019,
      "step": 4301
    },
    {
      "epoch": 0.25519041404674336,
      "grad_norm": 17.588603973388672,
      "learning_rate": 1.6551542314790407e-05,
      "loss": 0.3545,
      "step": 4302
    },
    {
      "epoch": 0.25524973306442045,
      "grad_norm": 13.746026039123535,
      "learning_rate": 1.655022409702083e-05,
      "loss": 0.2992,
      "step": 4303
    },
    {
      "epoch": 0.25530905208209753,
      "grad_norm": 12.850289344787598,
      "learning_rate": 1.6548905879251252e-05,
      "loss": 0.0645,
      "step": 4304
    },
    {
      "epoch": 0.25536837109977456,
      "grad_norm": 11.340399742126465,
      "learning_rate": 1.6547587661481678e-05,
      "loss": 0.3274,
      "step": 4305
    },
    {
      "epoch": 0.25542769011745164,
      "grad_norm": 17.755355834960938,
      "learning_rate": 1.65462694437121e-05,
      "loss": 1.023,
      "step": 4306
    },
    {
      "epoch": 0.25548700913512873,
      "grad_norm": 4.904411792755127,
      "learning_rate": 1.6544951225942526e-05,
      "loss": 0.2784,
      "step": 4307
    },
    {
      "epoch": 0.2555463281528058,
      "grad_norm": 24.34653091430664,
      "learning_rate": 1.6543633008172952e-05,
      "loss": 0.9277,
      "step": 4308
    },
    {
      "epoch": 0.25560564717048284,
      "grad_norm": 0.23261931538581848,
      "learning_rate": 1.6542314790403375e-05,
      "loss": 0.003,
      "step": 4309
    },
    {
      "epoch": 0.2556649661881599,
      "grad_norm": 1.9646674394607544,
      "learning_rate": 1.65409965726338e-05,
      "loss": 0.0202,
      "step": 4310
    },
    {
      "epoch": 0.255724285205837,
      "grad_norm": 0.06470142304897308,
      "learning_rate": 1.6539678354864226e-05,
      "loss": 0.0016,
      "step": 4311
    },
    {
      "epoch": 0.25578360422351404,
      "grad_norm": 4.390420436859131,
      "learning_rate": 1.653836013709465e-05,
      "loss": 0.0221,
      "step": 4312
    },
    {
      "epoch": 0.2558429232411911,
      "grad_norm": 8.618720054626465,
      "learning_rate": 1.6537041919325075e-05,
      "loss": 0.0653,
      "step": 4313
    },
    {
      "epoch": 0.2559022422588682,
      "grad_norm": 13.028261184692383,
      "learning_rate": 1.6535723701555497e-05,
      "loss": 0.4165,
      "step": 4314
    },
    {
      "epoch": 0.25596156127654524,
      "grad_norm": 0.06315408647060394,
      "learning_rate": 1.6534405483785923e-05,
      "loss": 0.0017,
      "step": 4315
    },
    {
      "epoch": 0.2560208802942223,
      "grad_norm": 4.533543109893799,
      "learning_rate": 1.653308726601635e-05,
      "loss": 0.0476,
      "step": 4316
    },
    {
      "epoch": 0.2560801993118994,
      "grad_norm": 0.04628841578960419,
      "learning_rate": 1.653176904824677e-05,
      "loss": 0.0011,
      "step": 4317
    },
    {
      "epoch": 0.2561395183295765,
      "grad_norm": 3.2428781986236572,
      "learning_rate": 1.6530450830477197e-05,
      "loss": 0.0138,
      "step": 4318
    },
    {
      "epoch": 0.2561988373472535,
      "grad_norm": 0.07212310284376144,
      "learning_rate": 1.652913261270762e-05,
      "loss": 0.0011,
      "step": 4319
    },
    {
      "epoch": 0.2562581563649306,
      "grad_norm": 0.07778232544660568,
      "learning_rate": 1.6527814394938046e-05,
      "loss": 0.0018,
      "step": 4320
    },
    {
      "epoch": 0.2563174753826077,
      "grad_norm": 0.22680646181106567,
      "learning_rate": 1.6526496177168468e-05,
      "loss": 0.0031,
      "step": 4321
    },
    {
      "epoch": 0.2563767944002847,
      "grad_norm": 21.95113754272461,
      "learning_rate": 1.6525177959398894e-05,
      "loss": 1.6978,
      "step": 4322
    },
    {
      "epoch": 0.2564361134179618,
      "grad_norm": 0.23877555131912231,
      "learning_rate": 1.6523859741629317e-05,
      "loss": 0.0033,
      "step": 4323
    },
    {
      "epoch": 0.2564954324356389,
      "grad_norm": 17.73421287536621,
      "learning_rate": 1.6522541523859742e-05,
      "loss": 0.7568,
      "step": 4324
    },
    {
      "epoch": 0.2565547514533159,
      "grad_norm": 0.014365678653120995,
      "learning_rate": 1.6521223306090168e-05,
      "loss": 0.0006,
      "step": 4325
    },
    {
      "epoch": 0.256614070470993,
      "grad_norm": 0.06756114214658737,
      "learning_rate": 1.651990508832059e-05,
      "loss": 0.0016,
      "step": 4326
    },
    {
      "epoch": 0.2566733894886701,
      "grad_norm": 5.725818157196045,
      "learning_rate": 1.6518586870551017e-05,
      "loss": 0.2939,
      "step": 4327
    },
    {
      "epoch": 0.25673270850634716,
      "grad_norm": 11.082268714904785,
      "learning_rate": 1.6517268652781443e-05,
      "loss": 0.0735,
      "step": 4328
    },
    {
      "epoch": 0.2567920275240242,
      "grad_norm": 5.191308975219727,
      "learning_rate": 1.6515950435011865e-05,
      "loss": 0.0738,
      "step": 4329
    },
    {
      "epoch": 0.2568513465417013,
      "grad_norm": 5.693582057952881,
      "learning_rate": 1.651463221724229e-05,
      "loss": 0.0213,
      "step": 4330
    },
    {
      "epoch": 0.25691066555937836,
      "grad_norm": 0.24925430119037628,
      "learning_rate": 1.6513313999472713e-05,
      "loss": 0.0031,
      "step": 4331
    },
    {
      "epoch": 0.2569699845770554,
      "grad_norm": 0.08190015703439713,
      "learning_rate": 1.651199578170314e-05,
      "loss": 0.0021,
      "step": 4332
    },
    {
      "epoch": 0.25702930359473247,
      "grad_norm": 0.07689300179481506,
      "learning_rate": 1.6510677563933565e-05,
      "loss": 0.0007,
      "step": 4333
    },
    {
      "epoch": 0.25708862261240956,
      "grad_norm": 13.477313995361328,
      "learning_rate": 1.6509359346163988e-05,
      "loss": 0.6241,
      "step": 4334
    },
    {
      "epoch": 0.2571479416300866,
      "grad_norm": 8.595020294189453,
      "learning_rate": 1.6508041128394414e-05,
      "loss": 0.3661,
      "step": 4335
    },
    {
      "epoch": 0.25720726064776367,
      "grad_norm": 16.447914123535156,
      "learning_rate": 1.6506722910624836e-05,
      "loss": 0.4547,
      "step": 4336
    },
    {
      "epoch": 0.25726657966544075,
      "grad_norm": 0.18150769174098969,
      "learning_rate": 1.6505404692855262e-05,
      "loss": 0.002,
      "step": 4337
    },
    {
      "epoch": 0.2573258986831178,
      "grad_norm": 11.386960983276367,
      "learning_rate": 1.6504086475085684e-05,
      "loss": 0.3897,
      "step": 4338
    },
    {
      "epoch": 0.25738521770079487,
      "grad_norm": 1.3329293727874756,
      "learning_rate": 1.650276825731611e-05,
      "loss": 0.0157,
      "step": 4339
    },
    {
      "epoch": 0.25744453671847195,
      "grad_norm": 3.2517316341400146,
      "learning_rate": 1.6501450039546533e-05,
      "loss": 0.209,
      "step": 4340
    },
    {
      "epoch": 0.25750385573614903,
      "grad_norm": 15.291679382324219,
      "learning_rate": 1.650013182177696e-05,
      "loss": 0.4553,
      "step": 4341
    },
    {
      "epoch": 0.25756317475382606,
      "grad_norm": 1.1904479265213013,
      "learning_rate": 1.6498813604007385e-05,
      "loss": 0.0106,
      "step": 4342
    },
    {
      "epoch": 0.25762249377150315,
      "grad_norm": 2.3581504821777344,
      "learning_rate": 1.6497495386237807e-05,
      "loss": 0.0152,
      "step": 4343
    },
    {
      "epoch": 0.25768181278918023,
      "grad_norm": 6.435845851898193,
      "learning_rate": 1.6496177168468233e-05,
      "loss": 0.0781,
      "step": 4344
    },
    {
      "epoch": 0.25774113180685726,
      "grad_norm": 6.487961769104004,
      "learning_rate": 1.649485895069866e-05,
      "loss": 0.1742,
      "step": 4345
    },
    {
      "epoch": 0.25780045082453434,
      "grad_norm": 23.300369262695312,
      "learning_rate": 1.649354073292908e-05,
      "loss": 0.2485,
      "step": 4346
    },
    {
      "epoch": 0.25785976984221143,
      "grad_norm": 7.573122024536133,
      "learning_rate": 1.6492222515159507e-05,
      "loss": 0.176,
      "step": 4347
    },
    {
      "epoch": 0.25791908885988846,
      "grad_norm": 0.029995208606123924,
      "learning_rate": 1.649090429738993e-05,
      "loss": 0.001,
      "step": 4348
    },
    {
      "epoch": 0.25797840787756554,
      "grad_norm": 20.242137908935547,
      "learning_rate": 1.6489586079620356e-05,
      "loss": 0.8007,
      "step": 4349
    },
    {
      "epoch": 0.2580377268952426,
      "grad_norm": 0.10700388252735138,
      "learning_rate": 1.6488267861850778e-05,
      "loss": 0.0023,
      "step": 4350
    },
    {
      "epoch": 0.2580970459129197,
      "grad_norm": 21.385114669799805,
      "learning_rate": 1.6486949644081204e-05,
      "loss": 0.0445,
      "step": 4351
    },
    {
      "epoch": 0.25815636493059674,
      "grad_norm": 0.18687587976455688,
      "learning_rate": 1.6485631426311626e-05,
      "loss": 0.0031,
      "step": 4352
    },
    {
      "epoch": 0.2582156839482738,
      "grad_norm": 0.03604253754019737,
      "learning_rate": 1.6484313208542052e-05,
      "loss": 0.001,
      "step": 4353
    },
    {
      "epoch": 0.2582750029659509,
      "grad_norm": 2.598273277282715,
      "learning_rate": 1.6482994990772475e-05,
      "loss": 0.0202,
      "step": 4354
    },
    {
      "epoch": 0.25833432198362793,
      "grad_norm": 4.881113529205322,
      "learning_rate": 1.64816767730029e-05,
      "loss": 0.1603,
      "step": 4355
    },
    {
      "epoch": 0.258393641001305,
      "grad_norm": 17.02484893798828,
      "learning_rate": 1.6480358555233327e-05,
      "loss": 0.7857,
      "step": 4356
    },
    {
      "epoch": 0.2584529600189821,
      "grad_norm": 0.8378547430038452,
      "learning_rate": 1.647904033746375e-05,
      "loss": 0.0037,
      "step": 4357
    },
    {
      "epoch": 0.25851227903665913,
      "grad_norm": 10.178540229797363,
      "learning_rate": 1.6477722119694175e-05,
      "loss": 0.454,
      "step": 4358
    },
    {
      "epoch": 0.2585715980543362,
      "grad_norm": 0.1722252368927002,
      "learning_rate": 1.64764039019246e-05,
      "loss": 0.0024,
      "step": 4359
    },
    {
      "epoch": 0.2586309170720133,
      "grad_norm": 0.09894677996635437,
      "learning_rate": 1.6475085684155023e-05,
      "loss": 0.0017,
      "step": 4360
    },
    {
      "epoch": 0.25869023608969033,
      "grad_norm": 9.390303611755371,
      "learning_rate": 1.647376746638545e-05,
      "loss": 0.7993,
      "step": 4361
    },
    {
      "epoch": 0.2587495551073674,
      "grad_norm": 0.9225948452949524,
      "learning_rate": 1.647244924861587e-05,
      "loss": 0.0146,
      "step": 4362
    },
    {
      "epoch": 0.2588088741250445,
      "grad_norm": 0.8570178151130676,
      "learning_rate": 1.6471131030846298e-05,
      "loss": 0.0043,
      "step": 4363
    },
    {
      "epoch": 0.2588681931427216,
      "grad_norm": 19.625778198242188,
      "learning_rate": 1.6469812813076723e-05,
      "loss": 0.3151,
      "step": 4364
    },
    {
      "epoch": 0.2589275121603986,
      "grad_norm": 0.2309022843837738,
      "learning_rate": 1.6468494595307146e-05,
      "loss": 0.0056,
      "step": 4365
    },
    {
      "epoch": 0.2589868311780757,
      "grad_norm": 111.31129455566406,
      "learning_rate": 1.6467176377537572e-05,
      "loss": 0.3865,
      "step": 4366
    },
    {
      "epoch": 0.2590461501957528,
      "grad_norm": 3.8573179244995117,
      "learning_rate": 1.6465858159767994e-05,
      "loss": 0.0911,
      "step": 4367
    },
    {
      "epoch": 0.2591054692134298,
      "grad_norm": 17.757871627807617,
      "learning_rate": 1.646453994199842e-05,
      "loss": 0.2973,
      "step": 4368
    },
    {
      "epoch": 0.2591647882311069,
      "grad_norm": 6.217859745025635,
      "learning_rate": 1.6463221724228843e-05,
      "loss": 0.4144,
      "step": 4369
    },
    {
      "epoch": 0.259224107248784,
      "grad_norm": 11.89821720123291,
      "learning_rate": 1.646190350645927e-05,
      "loss": 0.1756,
      "step": 4370
    },
    {
      "epoch": 0.259283426266461,
      "grad_norm": 10.565231323242188,
      "learning_rate": 1.646058528868969e-05,
      "loss": 0.4253,
      "step": 4371
    },
    {
      "epoch": 0.2593427452841381,
      "grad_norm": 0.35086363554000854,
      "learning_rate": 1.6459267070920117e-05,
      "loss": 0.0048,
      "step": 4372
    },
    {
      "epoch": 0.25940206430181517,
      "grad_norm": 22.00098991394043,
      "learning_rate": 1.6457948853150543e-05,
      "loss": 0.3464,
      "step": 4373
    },
    {
      "epoch": 0.25946138331949226,
      "grad_norm": 17.646982192993164,
      "learning_rate": 1.6456630635380965e-05,
      "loss": 1.4375,
      "step": 4374
    },
    {
      "epoch": 0.2595207023371693,
      "grad_norm": 8.591986656188965,
      "learning_rate": 1.645531241761139e-05,
      "loss": 0.0858,
      "step": 4375
    },
    {
      "epoch": 0.25958002135484637,
      "grad_norm": 20.39699935913086,
      "learning_rate": 1.6453994199841817e-05,
      "loss": 0.9404,
      "step": 4376
    },
    {
      "epoch": 0.25963934037252345,
      "grad_norm": 24.9886474609375,
      "learning_rate": 1.645267598207224e-05,
      "loss": 0.6794,
      "step": 4377
    },
    {
      "epoch": 0.2596986593902005,
      "grad_norm": 10.030174255371094,
      "learning_rate": 1.6451357764302665e-05,
      "loss": 0.3459,
      "step": 4378
    },
    {
      "epoch": 0.25975797840787757,
      "grad_norm": 3.683361291885376,
      "learning_rate": 1.6450039546533088e-05,
      "loss": 0.0574,
      "step": 4379
    },
    {
      "epoch": 0.25981729742555465,
      "grad_norm": 15.797025680541992,
      "learning_rate": 1.6448721328763514e-05,
      "loss": 0.1817,
      "step": 4380
    },
    {
      "epoch": 0.2598766164432317,
      "grad_norm": 9.701172828674316,
      "learning_rate": 1.644740311099394e-05,
      "loss": 0.2104,
      "step": 4381
    },
    {
      "epoch": 0.25993593546090876,
      "grad_norm": 0.29748040437698364,
      "learning_rate": 1.6446084893224362e-05,
      "loss": 0.0034,
      "step": 4382
    },
    {
      "epoch": 0.25999525447858585,
      "grad_norm": 0.18868115544319153,
      "learning_rate": 1.6444766675454785e-05,
      "loss": 0.0042,
      "step": 4383
    },
    {
      "epoch": 0.2600545734962629,
      "grad_norm": 37.835418701171875,
      "learning_rate": 1.644344845768521e-05,
      "loss": 2.0113,
      "step": 4384
    },
    {
      "epoch": 0.26011389251393996,
      "grad_norm": 2.885549545288086,
      "learning_rate": 1.6442130239915633e-05,
      "loss": 0.0661,
      "step": 4385
    },
    {
      "epoch": 0.26017321153161704,
      "grad_norm": 0.12228433042764664,
      "learning_rate": 1.644081202214606e-05,
      "loss": 0.0015,
      "step": 4386
    },
    {
      "epoch": 0.2602325305492941,
      "grad_norm": 4.037082195281982,
      "learning_rate": 1.6439493804376485e-05,
      "loss": 0.0975,
      "step": 4387
    },
    {
      "epoch": 0.26029184956697116,
      "grad_norm": 0.4527135491371155,
      "learning_rate": 1.6438175586606907e-05,
      "loss": 0.0045,
      "step": 4388
    },
    {
      "epoch": 0.26035116858464824,
      "grad_norm": 12.598675727844238,
      "learning_rate": 1.6436857368837333e-05,
      "loss": 0.2278,
      "step": 4389
    },
    {
      "epoch": 0.2604104876023253,
      "grad_norm": 2.7869441509246826,
      "learning_rate": 1.643553915106776e-05,
      "loss": 0.0598,
      "step": 4390
    },
    {
      "epoch": 0.26046980662000235,
      "grad_norm": 0.3812887966632843,
      "learning_rate": 1.643422093329818e-05,
      "loss": 0.0056,
      "step": 4391
    },
    {
      "epoch": 0.26052912563767944,
      "grad_norm": 0.08242888003587723,
      "learning_rate": 1.6432902715528607e-05,
      "loss": 0.0011,
      "step": 4392
    },
    {
      "epoch": 0.2605884446553565,
      "grad_norm": 1.6488597393035889,
      "learning_rate": 1.6431584497759033e-05,
      "loss": 0.0232,
      "step": 4393
    },
    {
      "epoch": 0.26064776367303355,
      "grad_norm": 8.73378849029541,
      "learning_rate": 1.6430266279989456e-05,
      "loss": 0.1705,
      "step": 4394
    },
    {
      "epoch": 0.26070708269071063,
      "grad_norm": 9.453547477722168,
      "learning_rate": 1.6428948062219882e-05,
      "loss": 0.7397,
      "step": 4395
    },
    {
      "epoch": 0.2607664017083877,
      "grad_norm": 4.104933738708496,
      "learning_rate": 1.6427629844450304e-05,
      "loss": 0.0717,
      "step": 4396
    },
    {
      "epoch": 0.2608257207260648,
      "grad_norm": 7.55528450012207,
      "learning_rate": 1.642631162668073e-05,
      "loss": 0.2713,
      "step": 4397
    },
    {
      "epoch": 0.26088503974374183,
      "grad_norm": 7.78214168548584,
      "learning_rate": 1.6424993408911153e-05,
      "loss": 0.3973,
      "step": 4398
    },
    {
      "epoch": 0.2609443587614189,
      "grad_norm": 0.05966325104236603,
      "learning_rate": 1.642367519114158e-05,
      "loss": 0.0011,
      "step": 4399
    },
    {
      "epoch": 0.261003677779096,
      "grad_norm": 3.187905788421631,
      "learning_rate": 1.6422356973372e-05,
      "loss": 0.0128,
      "step": 4400
    },
    {
      "epoch": 0.26106299679677303,
      "grad_norm": 0.4203492999076843,
      "learning_rate": 1.6421038755602427e-05,
      "loss": 0.0086,
      "step": 4401
    },
    {
      "epoch": 0.2611223158144501,
      "grad_norm": 27.657833099365234,
      "learning_rate": 1.641972053783285e-05,
      "loss": 1.4392,
      "step": 4402
    },
    {
      "epoch": 0.2611816348321272,
      "grad_norm": 0.02098723314702511,
      "learning_rate": 1.6418402320063275e-05,
      "loss": 0.0008,
      "step": 4403
    },
    {
      "epoch": 0.2612409538498042,
      "grad_norm": 11.357442855834961,
      "learning_rate": 1.64170841022937e-05,
      "loss": 0.4218,
      "step": 4404
    },
    {
      "epoch": 0.2613002728674813,
      "grad_norm": 0.08592865616083145,
      "learning_rate": 1.6415765884524124e-05,
      "loss": 0.002,
      "step": 4405
    },
    {
      "epoch": 0.2613595918851584,
      "grad_norm": 1.3124423027038574,
      "learning_rate": 1.641444766675455e-05,
      "loss": 0.026,
      "step": 4406
    },
    {
      "epoch": 0.2614189109028354,
      "grad_norm": 0.3672885000705719,
      "learning_rate": 1.6413129448984975e-05,
      "loss": 0.006,
      "step": 4407
    },
    {
      "epoch": 0.2614782299205125,
      "grad_norm": 12.280111312866211,
      "learning_rate": 1.6411811231215398e-05,
      "loss": 0.4503,
      "step": 4408
    },
    {
      "epoch": 0.2615375489381896,
      "grad_norm": 3.344878911972046,
      "learning_rate": 1.6410493013445824e-05,
      "loss": 0.0712,
      "step": 4409
    },
    {
      "epoch": 0.2615968679558667,
      "grad_norm": 12.022895812988281,
      "learning_rate": 1.640917479567625e-05,
      "loss": 0.2907,
      "step": 4410
    },
    {
      "epoch": 0.2616561869735437,
      "grad_norm": 0.10085365921258926,
      "learning_rate": 1.6407856577906672e-05,
      "loss": 0.0013,
      "step": 4411
    },
    {
      "epoch": 0.2617155059912208,
      "grad_norm": 7.532283782958984,
      "learning_rate": 1.6406538360137098e-05,
      "loss": 0.0434,
      "step": 4412
    },
    {
      "epoch": 0.26177482500889787,
      "grad_norm": 0.532661497592926,
      "learning_rate": 1.640522014236752e-05,
      "loss": 0.0116,
      "step": 4413
    },
    {
      "epoch": 0.2618341440265749,
      "grad_norm": 9.873149871826172,
      "learning_rate": 1.6403901924597946e-05,
      "loss": 0.0731,
      "step": 4414
    },
    {
      "epoch": 0.261893463044252,
      "grad_norm": 0.4911859929561615,
      "learning_rate": 1.640258370682837e-05,
      "loss": 0.0087,
      "step": 4415
    },
    {
      "epoch": 0.26195278206192907,
      "grad_norm": 3.8956711292266846,
      "learning_rate": 1.640126548905879e-05,
      "loss": 0.1846,
      "step": 4416
    },
    {
      "epoch": 0.2620121010796061,
      "grad_norm": 13.398530960083008,
      "learning_rate": 1.6399947271289217e-05,
      "loss": 1.1364,
      "step": 4417
    },
    {
      "epoch": 0.2620714200972832,
      "grad_norm": 10.729790687561035,
      "learning_rate": 1.6398629053519643e-05,
      "loss": 0.4514,
      "step": 4418
    },
    {
      "epoch": 0.26213073911496027,
      "grad_norm": 5.828368663787842,
      "learning_rate": 1.6397310835750066e-05,
      "loss": 0.0316,
      "step": 4419
    },
    {
      "epoch": 0.26219005813263735,
      "grad_norm": 5.75669527053833,
      "learning_rate": 1.639599261798049e-05,
      "loss": 0.1987,
      "step": 4420
    },
    {
      "epoch": 0.2622493771503144,
      "grad_norm": 0.18699394166469574,
      "learning_rate": 1.6394674400210917e-05,
      "loss": 0.004,
      "step": 4421
    },
    {
      "epoch": 0.26230869616799146,
      "grad_norm": 5.862085342407227,
      "learning_rate": 1.639335618244134e-05,
      "loss": 0.0864,
      "step": 4422
    },
    {
      "epoch": 0.26236801518566855,
      "grad_norm": 0.17330396175384521,
      "learning_rate": 1.6392037964671766e-05,
      "loss": 0.0029,
      "step": 4423
    },
    {
      "epoch": 0.2624273342033456,
      "grad_norm": 6.127194404602051,
      "learning_rate": 1.639071974690219e-05,
      "loss": 0.1184,
      "step": 4424
    },
    {
      "epoch": 0.26248665322102266,
      "grad_norm": 8.69456958770752,
      "learning_rate": 1.6389401529132614e-05,
      "loss": 0.273,
      "step": 4425
    },
    {
      "epoch": 0.26254597223869974,
      "grad_norm": 7.526400566101074,
      "learning_rate": 1.638808331136304e-05,
      "loss": 0.1861,
      "step": 4426
    },
    {
      "epoch": 0.26260529125637677,
      "grad_norm": 9.638800621032715,
      "learning_rate": 1.6386765093593462e-05,
      "loss": 0.3431,
      "step": 4427
    },
    {
      "epoch": 0.26266461027405386,
      "grad_norm": 3.522831916809082,
      "learning_rate": 1.638544687582389e-05,
      "loss": 0.0344,
      "step": 4428
    },
    {
      "epoch": 0.26272392929173094,
      "grad_norm": 16.2702579498291,
      "learning_rate": 1.638412865805431e-05,
      "loss": 0.238,
      "step": 4429
    },
    {
      "epoch": 0.26278324830940797,
      "grad_norm": 4.949277877807617,
      "learning_rate": 1.6382810440284737e-05,
      "loss": 0.0511,
      "step": 4430
    },
    {
      "epoch": 0.26284256732708505,
      "grad_norm": 0.3191213011741638,
      "learning_rate": 1.638149222251516e-05,
      "loss": 0.0028,
      "step": 4431
    },
    {
      "epoch": 0.26290188634476214,
      "grad_norm": 9.916110038757324,
      "learning_rate": 1.6380174004745585e-05,
      "loss": 0.1498,
      "step": 4432
    },
    {
      "epoch": 0.2629612053624392,
      "grad_norm": 2.0501296520233154,
      "learning_rate": 1.6378855786976008e-05,
      "loss": 0.0321,
      "step": 4433
    },
    {
      "epoch": 0.26302052438011625,
      "grad_norm": 2.6153452396392822,
      "learning_rate": 1.6377537569206433e-05,
      "loss": 0.0228,
      "step": 4434
    },
    {
      "epoch": 0.26307984339779333,
      "grad_norm": 0.20767392218112946,
      "learning_rate": 1.637621935143686e-05,
      "loss": 0.0046,
      "step": 4435
    },
    {
      "epoch": 0.2631391624154704,
      "grad_norm": 2.833080768585205,
      "learning_rate": 1.6374901133667282e-05,
      "loss": 0.0454,
      "step": 4436
    },
    {
      "epoch": 0.26319848143314745,
      "grad_norm": 9.724451065063477,
      "learning_rate": 1.6373582915897708e-05,
      "loss": 0.0959,
      "step": 4437
    },
    {
      "epoch": 0.26325780045082453,
      "grad_norm": 6.708550930023193,
      "learning_rate": 1.6372264698128134e-05,
      "loss": 0.1347,
      "step": 4438
    },
    {
      "epoch": 0.2633171194685016,
      "grad_norm": 12.560420036315918,
      "learning_rate": 1.6370946480358556e-05,
      "loss": 0.5678,
      "step": 4439
    },
    {
      "epoch": 0.26337643848617864,
      "grad_norm": 0.19611337780952454,
      "learning_rate": 1.6369628262588982e-05,
      "loss": 0.004,
      "step": 4440
    },
    {
      "epoch": 0.2634357575038557,
      "grad_norm": 13.151718139648438,
      "learning_rate": 1.6368310044819408e-05,
      "loss": 0.221,
      "step": 4441
    },
    {
      "epoch": 0.2634950765215328,
      "grad_norm": 42.13862609863281,
      "learning_rate": 1.636699182704983e-05,
      "loss": 1.3469,
      "step": 4442
    },
    {
      "epoch": 0.2635543955392099,
      "grad_norm": 4.948955535888672,
      "learning_rate": 1.6365673609280256e-05,
      "loss": 0.07,
      "step": 4443
    },
    {
      "epoch": 0.2636137145568869,
      "grad_norm": 2.4498329162597656,
      "learning_rate": 1.636435539151068e-05,
      "loss": 0.03,
      "step": 4444
    },
    {
      "epoch": 0.263673033574564,
      "grad_norm": 0.29735520482063293,
      "learning_rate": 1.6363037173741105e-05,
      "loss": 0.0039,
      "step": 4445
    },
    {
      "epoch": 0.2637323525922411,
      "grad_norm": 12.75390911102295,
      "learning_rate": 1.6361718955971527e-05,
      "loss": 0.0711,
      "step": 4446
    },
    {
      "epoch": 0.2637916716099181,
      "grad_norm": 5.975674152374268,
      "learning_rate": 1.6360400738201953e-05,
      "loss": 0.1081,
      "step": 4447
    },
    {
      "epoch": 0.2638509906275952,
      "grad_norm": 4.057980060577393,
      "learning_rate": 1.6359082520432375e-05,
      "loss": 0.0393,
      "step": 4448
    },
    {
      "epoch": 0.2639103096452723,
      "grad_norm": 0.09275367110967636,
      "learning_rate": 1.63577643026628e-05,
      "loss": 0.0019,
      "step": 4449
    },
    {
      "epoch": 0.2639696286629493,
      "grad_norm": 0.01093593705445528,
      "learning_rate": 1.6356446084893224e-05,
      "loss": 0.0003,
      "step": 4450
    },
    {
      "epoch": 0.2640289476806264,
      "grad_norm": 3.8376593589782715,
      "learning_rate": 1.635512786712365e-05,
      "loss": 0.0308,
      "step": 4451
    },
    {
      "epoch": 0.2640882666983035,
      "grad_norm": 5.224438667297363,
      "learning_rate": 1.6353809649354076e-05,
      "loss": 0.0662,
      "step": 4452
    },
    {
      "epoch": 0.26414758571598057,
      "grad_norm": 2.3714709281921387,
      "learning_rate": 1.6352491431584498e-05,
      "loss": 0.0149,
      "step": 4453
    },
    {
      "epoch": 0.2642069047336576,
      "grad_norm": 7.544398784637451,
      "learning_rate": 1.6351173213814924e-05,
      "loss": 0.0499,
      "step": 4454
    },
    {
      "epoch": 0.2642662237513347,
      "grad_norm": 4.007561206817627,
      "learning_rate": 1.634985499604535e-05,
      "loss": 0.0587,
      "step": 4455
    },
    {
      "epoch": 0.26432554276901177,
      "grad_norm": 5.90894079208374,
      "learning_rate": 1.6348536778275772e-05,
      "loss": 0.0956,
      "step": 4456
    },
    {
      "epoch": 0.2643848617866888,
      "grad_norm": 3.266833782196045,
      "learning_rate": 1.6347218560506198e-05,
      "loss": 0.0497,
      "step": 4457
    },
    {
      "epoch": 0.2644441808043659,
      "grad_norm": 6.325953960418701,
      "learning_rate": 1.6345900342736624e-05,
      "loss": 0.0485,
      "step": 4458
    },
    {
      "epoch": 0.26450349982204296,
      "grad_norm": 1.8237831592559814,
      "learning_rate": 1.6344582124967047e-05,
      "loss": 0.0199,
      "step": 4459
    },
    {
      "epoch": 0.26456281883972,
      "grad_norm": 7.108018398284912,
      "learning_rate": 1.634326390719747e-05,
      "loss": 0.0931,
      "step": 4460
    },
    {
      "epoch": 0.2646221378573971,
      "grad_norm": 1.0565755367279053,
      "learning_rate": 1.6341945689427895e-05,
      "loss": 0.0092,
      "step": 4461
    },
    {
      "epoch": 0.26468145687507416,
      "grad_norm": 9.188051223754883,
      "learning_rate": 1.6340627471658318e-05,
      "loss": 0.0869,
      "step": 4462
    },
    {
      "epoch": 0.2647407758927512,
      "grad_norm": 3.5429983139038086,
      "learning_rate": 1.6339309253888743e-05,
      "loss": 0.0195,
      "step": 4463
    },
    {
      "epoch": 0.2648000949104283,
      "grad_norm": 1.1209516525268555,
      "learning_rate": 1.6337991036119166e-05,
      "loss": 0.023,
      "step": 4464
    },
    {
      "epoch": 0.26485941392810536,
      "grad_norm": 19.702787399291992,
      "learning_rate": 1.6336672818349592e-05,
      "loss": 0.3089,
      "step": 4465
    },
    {
      "epoch": 0.26491873294578244,
      "grad_norm": 1.373888373374939,
      "learning_rate": 1.6335354600580018e-05,
      "loss": 0.0227,
      "step": 4466
    },
    {
      "epoch": 0.26497805196345947,
      "grad_norm": 0.13709516823291779,
      "learning_rate": 1.633403638281044e-05,
      "loss": 0.0023,
      "step": 4467
    },
    {
      "epoch": 0.26503737098113656,
      "grad_norm": 11.277259826660156,
      "learning_rate": 1.6332718165040866e-05,
      "loss": 0.4848,
      "step": 4468
    },
    {
      "epoch": 0.26509668999881364,
      "grad_norm": 0.007407034281641245,
      "learning_rate": 1.6331399947271292e-05,
      "loss": 0.0003,
      "step": 4469
    },
    {
      "epoch": 0.26515600901649067,
      "grad_norm": 3.0592880249023438,
      "learning_rate": 1.6330081729501714e-05,
      "loss": 0.024,
      "step": 4470
    },
    {
      "epoch": 0.26521532803416775,
      "grad_norm": 0.37821319699287415,
      "learning_rate": 1.632876351173214e-05,
      "loss": 0.0037,
      "step": 4471
    },
    {
      "epoch": 0.26527464705184484,
      "grad_norm": 0.08132505416870117,
      "learning_rate": 1.6327445293962566e-05,
      "loss": 0.0008,
      "step": 4472
    },
    {
      "epoch": 0.26533396606952186,
      "grad_norm": 0.5162369608879089,
      "learning_rate": 1.632612707619299e-05,
      "loss": 0.0053,
      "step": 4473
    },
    {
      "epoch": 0.26539328508719895,
      "grad_norm": 9.836150169372559,
      "learning_rate": 1.6324808858423415e-05,
      "loss": 0.2398,
      "step": 4474
    },
    {
      "epoch": 0.26545260410487603,
      "grad_norm": 0.04958723112940788,
      "learning_rate": 1.6323490640653837e-05,
      "loss": 0.0012,
      "step": 4475
    },
    {
      "epoch": 0.2655119231225531,
      "grad_norm": 0.026113035157322884,
      "learning_rate": 1.6322172422884263e-05,
      "loss": 0.0009,
      "step": 4476
    },
    {
      "epoch": 0.26557124214023015,
      "grad_norm": 0.14290973544120789,
      "learning_rate": 1.6320854205114685e-05,
      "loss": 0.0016,
      "step": 4477
    },
    {
      "epoch": 0.26563056115790723,
      "grad_norm": 6.177119255065918,
      "learning_rate": 1.631953598734511e-05,
      "loss": 0.1356,
      "step": 4478
    },
    {
      "epoch": 0.2656898801755843,
      "grad_norm": 0.07652145624160767,
      "learning_rate": 1.6318217769575534e-05,
      "loss": 0.002,
      "step": 4479
    },
    {
      "epoch": 0.26574919919326134,
      "grad_norm": 0.05178508907556534,
      "learning_rate": 1.631689955180596e-05,
      "loss": 0.001,
      "step": 4480
    },
    {
      "epoch": 0.2658085182109384,
      "grad_norm": 0.44688794016838074,
      "learning_rate": 1.6315581334036382e-05,
      "loss": 0.005,
      "step": 4481
    },
    {
      "epoch": 0.2658678372286155,
      "grad_norm": 0.24927493929862976,
      "learning_rate": 1.6314263116266808e-05,
      "loss": 0.002,
      "step": 4482
    },
    {
      "epoch": 0.26592715624629254,
      "grad_norm": 0.4896313548088074,
      "learning_rate": 1.6312944898497234e-05,
      "loss": 0.0028,
      "step": 4483
    },
    {
      "epoch": 0.2659864752639696,
      "grad_norm": 19.732261657714844,
      "learning_rate": 1.6311626680727656e-05,
      "loss": 1.127,
      "step": 4484
    },
    {
      "epoch": 0.2660457942816467,
      "grad_norm": 0.12638887763023376,
      "learning_rate": 1.6310308462958082e-05,
      "loss": 0.0023,
      "step": 4485
    },
    {
      "epoch": 0.26610511329932374,
      "grad_norm": 0.022406958043575287,
      "learning_rate": 1.6308990245188508e-05,
      "loss": 0.0006,
      "step": 4486
    },
    {
      "epoch": 0.2661644323170008,
      "grad_norm": 9.123591423034668,
      "learning_rate": 1.630767202741893e-05,
      "loss": 0.1162,
      "step": 4487
    },
    {
      "epoch": 0.2662237513346779,
      "grad_norm": 55.94446563720703,
      "learning_rate": 1.6306353809649357e-05,
      "loss": 1.2356,
      "step": 4488
    },
    {
      "epoch": 0.266283070352355,
      "grad_norm": 1.5140122175216675,
      "learning_rate": 1.6305035591879782e-05,
      "loss": 0.0162,
      "step": 4489
    },
    {
      "epoch": 0.266342389370032,
      "grad_norm": 19.753564834594727,
      "learning_rate": 1.6303717374110205e-05,
      "loss": 0.3946,
      "step": 4490
    },
    {
      "epoch": 0.2664017083877091,
      "grad_norm": 2.035811424255371,
      "learning_rate": 1.630239915634063e-05,
      "loss": 0.0087,
      "step": 4491
    },
    {
      "epoch": 0.2664610274053862,
      "grad_norm": 37.838233947753906,
      "learning_rate": 1.6301080938571053e-05,
      "loss": 3.2115,
      "step": 4492
    },
    {
      "epoch": 0.2665203464230632,
      "grad_norm": 0.659912645816803,
      "learning_rate": 1.629976272080148e-05,
      "loss": 0.0026,
      "step": 4493
    },
    {
      "epoch": 0.2665796654407403,
      "grad_norm": 8.983372688293457,
      "learning_rate": 1.62984445030319e-05,
      "loss": 0.4796,
      "step": 4494
    },
    {
      "epoch": 0.2666389844584174,
      "grad_norm": 3.8721323013305664,
      "learning_rate": 1.6297126285262324e-05,
      "loss": 0.0292,
      "step": 4495
    },
    {
      "epoch": 0.2666983034760944,
      "grad_norm": 3.652167797088623,
      "learning_rate": 1.629580806749275e-05,
      "loss": 0.0148,
      "step": 4496
    },
    {
      "epoch": 0.2667576224937715,
      "grad_norm": 5.267159938812256,
      "learning_rate": 1.6294489849723176e-05,
      "loss": 0.0589,
      "step": 4497
    },
    {
      "epoch": 0.2668169415114486,
      "grad_norm": 1.40469229221344,
      "learning_rate": 1.62931716319536e-05,
      "loss": 0.0065,
      "step": 4498
    },
    {
      "epoch": 0.26687626052912566,
      "grad_norm": 0.2890406847000122,
      "learning_rate": 1.6291853414184024e-05,
      "loss": 0.0031,
      "step": 4499
    },
    {
      "epoch": 0.2669355795468027,
      "grad_norm": 0.020295608788728714,
      "learning_rate": 1.629053519641445e-05,
      "loss": 0.0006,
      "step": 4500
    },
    {
      "epoch": 0.2669948985644798,
      "grad_norm": 23.277814865112305,
      "learning_rate": 1.6289216978644873e-05,
      "loss": 0.3639,
      "step": 4501
    },
    {
      "epoch": 0.26705421758215686,
      "grad_norm": 0.029998779296875,
      "learning_rate": 1.62878987608753e-05,
      "loss": 0.0005,
      "step": 4502
    },
    {
      "epoch": 0.2671135365998339,
      "grad_norm": 24.384336471557617,
      "learning_rate": 1.6286580543105724e-05,
      "loss": 0.2837,
      "step": 4503
    },
    {
      "epoch": 0.267172855617511,
      "grad_norm": 7.29090690612793,
      "learning_rate": 1.6285262325336147e-05,
      "loss": 1.066,
      "step": 4504
    },
    {
      "epoch": 0.26723217463518806,
      "grad_norm": 0.043984416872262955,
      "learning_rate": 1.6283944107566573e-05,
      "loss": 0.001,
      "step": 4505
    },
    {
      "epoch": 0.2672914936528651,
      "grad_norm": 0.14721959829330444,
      "learning_rate": 1.6282625889796995e-05,
      "loss": 0.0028,
      "step": 4506
    },
    {
      "epoch": 0.26735081267054217,
      "grad_norm": 1.771750807762146,
      "learning_rate": 1.628130767202742e-05,
      "loss": 0.0206,
      "step": 4507
    },
    {
      "epoch": 0.26741013168821925,
      "grad_norm": 0.020082494243979454,
      "learning_rate": 1.6279989454257844e-05,
      "loss": 0.0004,
      "step": 4508
    },
    {
      "epoch": 0.2674694507058963,
      "grad_norm": 2.7161526679992676,
      "learning_rate": 1.627867123648827e-05,
      "loss": 0.0182,
      "step": 4509
    },
    {
      "epoch": 0.26752876972357337,
      "grad_norm": 5.907159805297852,
      "learning_rate": 1.6277353018718692e-05,
      "loss": 0.4549,
      "step": 4510
    },
    {
      "epoch": 0.26758808874125045,
      "grad_norm": 2.664560079574585,
      "learning_rate": 1.6276034800949118e-05,
      "loss": 0.0395,
      "step": 4511
    },
    {
      "epoch": 0.26764740775892754,
      "grad_norm": 0.024790454655885696,
      "learning_rate": 1.627471658317954e-05,
      "loss": 0.0007,
      "step": 4512
    },
    {
      "epoch": 0.26770672677660456,
      "grad_norm": 2.4665606021881104,
      "learning_rate": 1.6273398365409966e-05,
      "loss": 0.0365,
      "step": 4513
    },
    {
      "epoch": 0.26776604579428165,
      "grad_norm": 0.4567125141620636,
      "learning_rate": 1.6272080147640392e-05,
      "loss": 0.0049,
      "step": 4514
    },
    {
      "epoch": 0.26782536481195873,
      "grad_norm": 15.59391975402832,
      "learning_rate": 1.6270761929870815e-05,
      "loss": 1.344,
      "step": 4515
    },
    {
      "epoch": 0.26788468382963576,
      "grad_norm": 2.773253917694092,
      "learning_rate": 1.626944371210124e-05,
      "loss": 0.0213,
      "step": 4516
    },
    {
      "epoch": 0.26794400284731285,
      "grad_norm": 4.941647529602051,
      "learning_rate": 1.6268125494331666e-05,
      "loss": 0.2074,
      "step": 4517
    },
    {
      "epoch": 0.26800332186498993,
      "grad_norm": 0.7896852493286133,
      "learning_rate": 1.626680727656209e-05,
      "loss": 0.0074,
      "step": 4518
    },
    {
      "epoch": 0.26806264088266696,
      "grad_norm": 0.08448147773742676,
      "learning_rate": 1.6265489058792515e-05,
      "loss": 0.0014,
      "step": 4519
    },
    {
      "epoch": 0.26812195990034404,
      "grad_norm": 0.04397239163517952,
      "learning_rate": 1.626417084102294e-05,
      "loss": 0.0007,
      "step": 4520
    },
    {
      "epoch": 0.2681812789180211,
      "grad_norm": 9.493474006652832,
      "learning_rate": 1.6262852623253363e-05,
      "loss": 0.1305,
      "step": 4521
    },
    {
      "epoch": 0.2682405979356982,
      "grad_norm": 0.010518825612962246,
      "learning_rate": 1.626153440548379e-05,
      "loss": 0.0003,
      "step": 4522
    },
    {
      "epoch": 0.26829991695337524,
      "grad_norm": 0.6952179670333862,
      "learning_rate": 1.626021618771421e-05,
      "loss": 0.0031,
      "step": 4523
    },
    {
      "epoch": 0.2683592359710523,
      "grad_norm": 0.0851798951625824,
      "learning_rate": 1.6258897969944637e-05,
      "loss": 0.0019,
      "step": 4524
    },
    {
      "epoch": 0.2684185549887294,
      "grad_norm": 4.098028659820557,
      "learning_rate": 1.625757975217506e-05,
      "loss": 0.0486,
      "step": 4525
    },
    {
      "epoch": 0.26847787400640644,
      "grad_norm": 12.19819164276123,
      "learning_rate": 1.6256261534405486e-05,
      "loss": 0.1256,
      "step": 4526
    },
    {
      "epoch": 0.2685371930240835,
      "grad_norm": 4.679995059967041,
      "learning_rate": 1.6254943316635908e-05,
      "loss": 0.0463,
      "step": 4527
    },
    {
      "epoch": 0.2685965120417606,
      "grad_norm": 0.026606200262904167,
      "learning_rate": 1.6253625098866334e-05,
      "loss": 0.0011,
      "step": 4528
    },
    {
      "epoch": 0.26865583105943763,
      "grad_norm": 2.5784213542938232,
      "learning_rate": 1.6252306881096757e-05,
      "loss": 0.0287,
      "step": 4529
    },
    {
      "epoch": 0.2687151500771147,
      "grad_norm": 0.6688569784164429,
      "learning_rate": 1.6250988663327183e-05,
      "loss": 0.0039,
      "step": 4530
    },
    {
      "epoch": 0.2687744690947918,
      "grad_norm": 0.01179969310760498,
      "learning_rate": 1.624967044555761e-05,
      "loss": 0.0003,
      "step": 4531
    },
    {
      "epoch": 0.26883378811246883,
      "grad_norm": 0.23757123947143555,
      "learning_rate": 1.624835222778803e-05,
      "loss": 0.0018,
      "step": 4532
    },
    {
      "epoch": 0.2688931071301459,
      "grad_norm": 7.4234724044799805,
      "learning_rate": 1.6247034010018457e-05,
      "loss": 0.0776,
      "step": 4533
    },
    {
      "epoch": 0.268952426147823,
      "grad_norm": 0.12818892300128937,
      "learning_rate": 1.6245715792248883e-05,
      "loss": 0.0029,
      "step": 4534
    },
    {
      "epoch": 0.2690117451655001,
      "grad_norm": 7.502331256866455,
      "learning_rate": 1.6244397574479305e-05,
      "loss": 0.2811,
      "step": 4535
    },
    {
      "epoch": 0.2690710641831771,
      "grad_norm": 26.1414794921875,
      "learning_rate": 1.624307935670973e-05,
      "loss": 0.2074,
      "step": 4536
    },
    {
      "epoch": 0.2691303832008542,
      "grad_norm": 13.667784690856934,
      "learning_rate": 1.6241761138940157e-05,
      "loss": 0.3509,
      "step": 4537
    },
    {
      "epoch": 0.2691897022185313,
      "grad_norm": 6.683881759643555,
      "learning_rate": 1.624044292117058e-05,
      "loss": 0.1794,
      "step": 4538
    },
    {
      "epoch": 0.2692490212362083,
      "grad_norm": 20.651649475097656,
      "learning_rate": 1.6239124703401002e-05,
      "loss": 0.2644,
      "step": 4539
    },
    {
      "epoch": 0.2693083402538854,
      "grad_norm": 0.12124061584472656,
      "learning_rate": 1.6237806485631428e-05,
      "loss": 0.0014,
      "step": 4540
    },
    {
      "epoch": 0.2693676592715625,
      "grad_norm": 0.12529203295707703,
      "learning_rate": 1.623648826786185e-05,
      "loss": 0.0031,
      "step": 4541
    },
    {
      "epoch": 0.2694269782892395,
      "grad_norm": 0.2648180425167084,
      "learning_rate": 1.6235170050092276e-05,
      "loss": 0.0039,
      "step": 4542
    },
    {
      "epoch": 0.2694862973069166,
      "grad_norm": 0.09197880327701569,
      "learning_rate": 1.62338518323227e-05,
      "loss": 0.0015,
      "step": 4543
    },
    {
      "epoch": 0.2695456163245937,
      "grad_norm": 7.379016399383545,
      "learning_rate": 1.6232533614553125e-05,
      "loss": 0.7042,
      "step": 4544
    },
    {
      "epoch": 0.26960493534227076,
      "grad_norm": 7.786382675170898,
      "learning_rate": 1.623121539678355e-05,
      "loss": 0.0698,
      "step": 4545
    },
    {
      "epoch": 0.2696642543599478,
      "grad_norm": 10.02905559539795,
      "learning_rate": 1.6229897179013973e-05,
      "loss": 0.1769,
      "step": 4546
    },
    {
      "epoch": 0.26972357337762487,
      "grad_norm": 16.868032455444336,
      "learning_rate": 1.62285789612444e-05,
      "loss": 0.865,
      "step": 4547
    },
    {
      "epoch": 0.26978289239530195,
      "grad_norm": 8.284955978393555,
      "learning_rate": 1.6227260743474825e-05,
      "loss": 0.1202,
      "step": 4548
    },
    {
      "epoch": 0.269842211412979,
      "grad_norm": 6.751079559326172,
      "learning_rate": 1.6225942525705247e-05,
      "loss": 0.0349,
      "step": 4549
    },
    {
      "epoch": 0.26990153043065607,
      "grad_norm": 51.62068557739258,
      "learning_rate": 1.6224624307935673e-05,
      "loss": 0.367,
      "step": 4550
    },
    {
      "epoch": 0.26996084944833315,
      "grad_norm": 0.18443083763122559,
      "learning_rate": 1.62233060901661e-05,
      "loss": 0.0027,
      "step": 4551
    },
    {
      "epoch": 0.2700201684660102,
      "grad_norm": 1.1664952039718628,
      "learning_rate": 1.622198787239652e-05,
      "loss": 0.013,
      "step": 4552
    },
    {
      "epoch": 0.27007948748368726,
      "grad_norm": 0.06086941063404083,
      "learning_rate": 1.6220669654626947e-05,
      "loss": 0.0014,
      "step": 4553
    },
    {
      "epoch": 0.27013880650136435,
      "grad_norm": 0.061228372156620026,
      "learning_rate": 1.621935143685737e-05,
      "loss": 0.0012,
      "step": 4554
    },
    {
      "epoch": 0.27019812551904143,
      "grad_norm": 1.896687626838684,
      "learning_rate": 1.6218033219087796e-05,
      "loss": 0.0202,
      "step": 4555
    },
    {
      "epoch": 0.27025744453671846,
      "grad_norm": 0.01547944825142622,
      "learning_rate": 1.6216715001318218e-05,
      "loss": 0.0005,
      "step": 4556
    },
    {
      "epoch": 0.27031676355439554,
      "grad_norm": 0.16677746176719666,
      "learning_rate": 1.6215396783548644e-05,
      "loss": 0.0021,
      "step": 4557
    },
    {
      "epoch": 0.27037608257207263,
      "grad_norm": 11.027100563049316,
      "learning_rate": 1.6214078565779067e-05,
      "loss": 0.3409,
      "step": 4558
    },
    {
      "epoch": 0.27043540158974966,
      "grad_norm": 0.08019710332155228,
      "learning_rate": 1.6212760348009492e-05,
      "loss": 0.001,
      "step": 4559
    },
    {
      "epoch": 0.27049472060742674,
      "grad_norm": 0.05738566815853119,
      "learning_rate": 1.6211442130239915e-05,
      "loss": 0.0007,
      "step": 4560
    },
    {
      "epoch": 0.2705540396251038,
      "grad_norm": 8.005599021911621,
      "learning_rate": 1.621012391247034e-05,
      "loss": 0.5941,
      "step": 4561
    },
    {
      "epoch": 0.27061335864278085,
      "grad_norm": 8.414612770080566,
      "learning_rate": 1.6208805694700767e-05,
      "loss": 0.1814,
      "step": 4562
    },
    {
      "epoch": 0.27067267766045794,
      "grad_norm": 10.71745491027832,
      "learning_rate": 1.620748747693119e-05,
      "loss": 0.2065,
      "step": 4563
    },
    {
      "epoch": 0.270731996678135,
      "grad_norm": 17.89007568359375,
      "learning_rate": 1.6206169259161615e-05,
      "loss": 0.3277,
      "step": 4564
    },
    {
      "epoch": 0.27079131569581205,
      "grad_norm": 12.41970443725586,
      "learning_rate": 1.620485104139204e-05,
      "loss": 0.1044,
      "step": 4565
    },
    {
      "epoch": 0.27085063471348914,
      "grad_norm": 0.006091155577450991,
      "learning_rate": 1.6203532823622463e-05,
      "loss": 0.0002,
      "step": 4566
    },
    {
      "epoch": 0.2709099537311662,
      "grad_norm": 0.016330687329173088,
      "learning_rate": 1.620221460585289e-05,
      "loss": 0.0005,
      "step": 4567
    },
    {
      "epoch": 0.2709692727488433,
      "grad_norm": 1.7057989835739136,
      "learning_rate": 1.6200896388083315e-05,
      "loss": 0.0322,
      "step": 4568
    },
    {
      "epoch": 0.27102859176652033,
      "grad_norm": 0.0056301746517419815,
      "learning_rate": 1.6199578170313738e-05,
      "loss": 0.0002,
      "step": 4569
    },
    {
      "epoch": 0.2710879107841974,
      "grad_norm": 7.234524726867676,
      "learning_rate": 1.6198259952544164e-05,
      "loss": 0.2147,
      "step": 4570
    },
    {
      "epoch": 0.2711472298018745,
      "grad_norm": 12.115278244018555,
      "learning_rate": 1.6196941734774586e-05,
      "loss": 0.3494,
      "step": 4571
    },
    {
      "epoch": 0.27120654881955153,
      "grad_norm": 3.5830328464508057,
      "learning_rate": 1.619562351700501e-05,
      "loss": 0.1098,
      "step": 4572
    },
    {
      "epoch": 0.2712658678372286,
      "grad_norm": 3.18829345703125,
      "learning_rate": 1.6194305299235434e-05,
      "loss": 0.0666,
      "step": 4573
    },
    {
      "epoch": 0.2713251868549057,
      "grad_norm": 0.06830891966819763,
      "learning_rate": 1.6192987081465857e-05,
      "loss": 0.0017,
      "step": 4574
    },
    {
      "epoch": 0.2713845058725827,
      "grad_norm": 12.166559219360352,
      "learning_rate": 1.6191668863696283e-05,
      "loss": 0.4677,
      "step": 4575
    },
    {
      "epoch": 0.2714438248902598,
      "grad_norm": 1.042629599571228,
      "learning_rate": 1.619035064592671e-05,
      "loss": 0.013,
      "step": 4576
    },
    {
      "epoch": 0.2715031439079369,
      "grad_norm": 10.126925468444824,
      "learning_rate": 1.618903242815713e-05,
      "loss": 0.3686,
      "step": 4577
    },
    {
      "epoch": 0.271562462925614,
      "grad_norm": 11.523838996887207,
      "learning_rate": 1.6187714210387557e-05,
      "loss": 0.1752,
      "step": 4578
    },
    {
      "epoch": 0.271621781943291,
      "grad_norm": 0.38837769627571106,
      "learning_rate": 1.6186395992617983e-05,
      "loss": 0.0045,
      "step": 4579
    },
    {
      "epoch": 0.2716811009609681,
      "grad_norm": 0.05298885703086853,
      "learning_rate": 1.6185077774848405e-05,
      "loss": 0.0012,
      "step": 4580
    },
    {
      "epoch": 0.2717404199786452,
      "grad_norm": 0.03415639325976372,
      "learning_rate": 1.618375955707883e-05,
      "loss": 0.0008,
      "step": 4581
    },
    {
      "epoch": 0.2717997389963222,
      "grad_norm": 0.2587643265724182,
      "learning_rate": 1.6182441339309257e-05,
      "loss": 0.0032,
      "step": 4582
    },
    {
      "epoch": 0.2718590580139993,
      "grad_norm": 0.17758622765541077,
      "learning_rate": 1.618112312153968e-05,
      "loss": 0.002,
      "step": 4583
    },
    {
      "epoch": 0.2719183770316764,
      "grad_norm": 0.0740007758140564,
      "learning_rate": 1.6179804903770106e-05,
      "loss": 0.0017,
      "step": 4584
    },
    {
      "epoch": 0.2719776960493534,
      "grad_norm": 6.947943210601807,
      "learning_rate": 1.6178486686000528e-05,
      "loss": 0.1217,
      "step": 4585
    },
    {
      "epoch": 0.2720370150670305,
      "grad_norm": 14.603182792663574,
      "learning_rate": 1.6177168468230954e-05,
      "loss": 0.8995,
      "step": 4586
    },
    {
      "epoch": 0.27209633408470757,
      "grad_norm": 0.012534440495073795,
      "learning_rate": 1.6175850250461376e-05,
      "loss": 0.0003,
      "step": 4587
    },
    {
      "epoch": 0.2721556531023846,
      "grad_norm": 7.414565086364746,
      "learning_rate": 1.6174532032691802e-05,
      "loss": 0.0359,
      "step": 4588
    },
    {
      "epoch": 0.2722149721200617,
      "grad_norm": 0.11093592643737793,
      "learning_rate": 1.6173213814922225e-05,
      "loss": 0.0016,
      "step": 4589
    },
    {
      "epoch": 0.27227429113773877,
      "grad_norm": 0.21686868369579315,
      "learning_rate": 1.617189559715265e-05,
      "loss": 0.002,
      "step": 4590
    },
    {
      "epoch": 0.27233361015541585,
      "grad_norm": 0.3653506338596344,
      "learning_rate": 1.6170577379383073e-05,
      "loss": 0.0034,
      "step": 4591
    },
    {
      "epoch": 0.2723929291730929,
      "grad_norm": 3.436237096786499,
      "learning_rate": 1.61692591616135e-05,
      "loss": 0.1043,
      "step": 4592
    },
    {
      "epoch": 0.27245224819076996,
      "grad_norm": 18.227487564086914,
      "learning_rate": 1.6167940943843925e-05,
      "loss": 0.293,
      "step": 4593
    },
    {
      "epoch": 0.27251156720844705,
      "grad_norm": 10.568005561828613,
      "learning_rate": 1.6166622726074347e-05,
      "loss": 0.163,
      "step": 4594
    },
    {
      "epoch": 0.2725708862261241,
      "grad_norm": 2.2132105827331543,
      "learning_rate": 1.6165304508304773e-05,
      "loss": 0.0108,
      "step": 4595
    },
    {
      "epoch": 0.27263020524380116,
      "grad_norm": 0.07671336084604263,
      "learning_rate": 1.61639862905352e-05,
      "loss": 0.0027,
      "step": 4596
    },
    {
      "epoch": 0.27268952426147824,
      "grad_norm": 13.40902042388916,
      "learning_rate": 1.6162668072765622e-05,
      "loss": 0.3701,
      "step": 4597
    },
    {
      "epoch": 0.2727488432791553,
      "grad_norm": 20.274633407592773,
      "learning_rate": 1.6161349854996048e-05,
      "loss": 0.6252,
      "step": 4598
    },
    {
      "epoch": 0.27280816229683236,
      "grad_norm": 28.870824813842773,
      "learning_rate": 1.6160031637226473e-05,
      "loss": 1.8515,
      "step": 4599
    },
    {
      "epoch": 0.27286748131450944,
      "grad_norm": 25.003034591674805,
      "learning_rate": 1.6158713419456896e-05,
      "loss": 0.9286,
      "step": 4600
    },
    {
      "epoch": 0.2729268003321865,
      "grad_norm": 12.755033493041992,
      "learning_rate": 1.6157395201687322e-05,
      "loss": 0.0496,
      "step": 4601
    },
    {
      "epoch": 0.27298611934986355,
      "grad_norm": 9.765386581420898,
      "learning_rate": 1.6156076983917744e-05,
      "loss": 0.2668,
      "step": 4602
    },
    {
      "epoch": 0.27304543836754064,
      "grad_norm": 2.877260208129883,
      "learning_rate": 1.615475876614817e-05,
      "loss": 0.0347,
      "step": 4603
    },
    {
      "epoch": 0.2731047573852177,
      "grad_norm": 0.5296184420585632,
      "learning_rate": 1.6153440548378593e-05,
      "loss": 0.007,
      "step": 4604
    },
    {
      "epoch": 0.27316407640289475,
      "grad_norm": 13.955662727355957,
      "learning_rate": 1.6152122330609015e-05,
      "loss": 0.5222,
      "step": 4605
    },
    {
      "epoch": 0.27322339542057184,
      "grad_norm": 4.277707099914551,
      "learning_rate": 1.615080411283944e-05,
      "loss": 0.1424,
      "step": 4606
    },
    {
      "epoch": 0.2732827144382489,
      "grad_norm": 0.011369362473487854,
      "learning_rate": 1.6149485895069867e-05,
      "loss": 0.0003,
      "step": 4607
    },
    {
      "epoch": 0.27334203345592595,
      "grad_norm": 0.6411917805671692,
      "learning_rate": 1.614816767730029e-05,
      "loss": 0.0084,
      "step": 4608
    },
    {
      "epoch": 0.27340135247360303,
      "grad_norm": 1.742652416229248,
      "learning_rate": 1.6146849459530715e-05,
      "loss": 0.0145,
      "step": 4609
    },
    {
      "epoch": 0.2734606714912801,
      "grad_norm": 6.699395656585693,
      "learning_rate": 1.614553124176114e-05,
      "loss": 0.0823,
      "step": 4610
    },
    {
      "epoch": 0.27351999050895714,
      "grad_norm": 0.6659582257270813,
      "learning_rate": 1.6144213023991564e-05,
      "loss": 0.0052,
      "step": 4611
    },
    {
      "epoch": 0.27357930952663423,
      "grad_norm": 12.105513572692871,
      "learning_rate": 1.614289480622199e-05,
      "loss": 0.6876,
      "step": 4612
    },
    {
      "epoch": 0.2736386285443113,
      "grad_norm": 9.711569786071777,
      "learning_rate": 1.6141576588452415e-05,
      "loss": 0.1729,
      "step": 4613
    },
    {
      "epoch": 0.2736979475619884,
      "grad_norm": 0.6485319137573242,
      "learning_rate": 1.6140258370682838e-05,
      "loss": 0.0065,
      "step": 4614
    },
    {
      "epoch": 0.2737572665796654,
      "grad_norm": 0.3961893320083618,
      "learning_rate": 1.6138940152913264e-05,
      "loss": 0.0045,
      "step": 4615
    },
    {
      "epoch": 0.2738165855973425,
      "grad_norm": 1.844340443611145,
      "learning_rate": 1.6137621935143686e-05,
      "loss": 0.0259,
      "step": 4616
    },
    {
      "epoch": 0.2738759046150196,
      "grad_norm": 17.5140380859375,
      "learning_rate": 1.6136303717374112e-05,
      "loss": 0.3391,
      "step": 4617
    },
    {
      "epoch": 0.2739352236326966,
      "grad_norm": 6.34945821762085,
      "learning_rate": 1.6134985499604535e-05,
      "loss": 0.0689,
      "step": 4618
    },
    {
      "epoch": 0.2739945426503737,
      "grad_norm": 11.057775497436523,
      "learning_rate": 1.613366728183496e-05,
      "loss": 0.0346,
      "step": 4619
    },
    {
      "epoch": 0.2740538616680508,
      "grad_norm": 0.04801099747419357,
      "learning_rate": 1.6132349064065383e-05,
      "loss": 0.0008,
      "step": 4620
    },
    {
      "epoch": 0.2741131806857278,
      "grad_norm": 1.655400276184082,
      "learning_rate": 1.613103084629581e-05,
      "loss": 0.0105,
      "step": 4621
    },
    {
      "epoch": 0.2741724997034049,
      "grad_norm": 1.0740872621536255,
      "learning_rate": 1.612971262852623e-05,
      "loss": 0.0094,
      "step": 4622
    },
    {
      "epoch": 0.274231818721082,
      "grad_norm": 6.4897918701171875,
      "learning_rate": 1.6128394410756657e-05,
      "loss": 0.1264,
      "step": 4623
    },
    {
      "epoch": 0.27429113773875907,
      "grad_norm": 10.334083557128906,
      "learning_rate": 1.6127076192987083e-05,
      "loss": 0.3427,
      "step": 4624
    },
    {
      "epoch": 0.2743504567564361,
      "grad_norm": 0.05191342160105705,
      "learning_rate": 1.6125757975217506e-05,
      "loss": 0.0013,
      "step": 4625
    },
    {
      "epoch": 0.2744097757741132,
      "grad_norm": 0.18218588829040527,
      "learning_rate": 1.612443975744793e-05,
      "loss": 0.0017,
      "step": 4626
    },
    {
      "epoch": 0.27446909479179027,
      "grad_norm": 1.394329309463501,
      "learning_rate": 1.6123121539678358e-05,
      "loss": 0.0031,
      "step": 4627
    },
    {
      "epoch": 0.2745284138094673,
      "grad_norm": 33.86976623535156,
      "learning_rate": 1.612180332190878e-05,
      "loss": 0.4445,
      "step": 4628
    },
    {
      "epoch": 0.2745877328271444,
      "grad_norm": 1.5509116649627686,
      "learning_rate": 1.6120485104139206e-05,
      "loss": 0.0229,
      "step": 4629
    },
    {
      "epoch": 0.27464705184482147,
      "grad_norm": 0.025519687682390213,
      "learning_rate": 1.6119166886369632e-05,
      "loss": 0.0006,
      "step": 4630
    },
    {
      "epoch": 0.2747063708624985,
      "grad_norm": 4.941802024841309,
      "learning_rate": 1.6117848668600054e-05,
      "loss": 0.1927,
      "step": 4631
    },
    {
      "epoch": 0.2747656898801756,
      "grad_norm": 0.15892207622528076,
      "learning_rate": 1.611653045083048e-05,
      "loss": 0.0023,
      "step": 4632
    },
    {
      "epoch": 0.27482500889785266,
      "grad_norm": 29.54808807373047,
      "learning_rate": 1.6115212233060903e-05,
      "loss": 2.0683,
      "step": 4633
    },
    {
      "epoch": 0.2748843279155297,
      "grad_norm": 0.31764692068099976,
      "learning_rate": 1.611389401529133e-05,
      "loss": 0.0032,
      "step": 4634
    },
    {
      "epoch": 0.2749436469332068,
      "grad_norm": 17.789690017700195,
      "learning_rate": 1.611257579752175e-05,
      "loss": 0.4643,
      "step": 4635
    },
    {
      "epoch": 0.27500296595088386,
      "grad_norm": 16.252145767211914,
      "learning_rate": 1.6111257579752177e-05,
      "loss": 0.097,
      "step": 4636
    },
    {
      "epoch": 0.27506228496856094,
      "grad_norm": 34.234031677246094,
      "learning_rate": 1.61099393619826e-05,
      "loss": 0.4601,
      "step": 4637
    },
    {
      "epoch": 0.275121603986238,
      "grad_norm": 0.8272107839584351,
      "learning_rate": 1.6108621144213025e-05,
      "loss": 0.0038,
      "step": 4638
    },
    {
      "epoch": 0.27518092300391506,
      "grad_norm": 0.062459796667099,
      "learning_rate": 1.6107302926443448e-05,
      "loss": 0.0011,
      "step": 4639
    },
    {
      "epoch": 0.27524024202159214,
      "grad_norm": 23.24505043029785,
      "learning_rate": 1.6105984708673874e-05,
      "loss": 0.6857,
      "step": 4640
    },
    {
      "epoch": 0.27529956103926917,
      "grad_norm": 0.11213837563991547,
      "learning_rate": 1.61046664909043e-05,
      "loss": 0.0024,
      "step": 4641
    },
    {
      "epoch": 0.27535888005694625,
      "grad_norm": 0.1970905065536499,
      "learning_rate": 1.6103348273134722e-05,
      "loss": 0.0042,
      "step": 4642
    },
    {
      "epoch": 0.27541819907462334,
      "grad_norm": 1.9925479888916016,
      "learning_rate": 1.6102030055365148e-05,
      "loss": 0.0296,
      "step": 4643
    },
    {
      "epoch": 0.27547751809230037,
      "grad_norm": 0.7083112597465515,
      "learning_rate": 1.6100711837595574e-05,
      "loss": 0.0041,
      "step": 4644
    },
    {
      "epoch": 0.27553683710997745,
      "grad_norm": 23.363746643066406,
      "learning_rate": 1.6099393619825996e-05,
      "loss": 0.4689,
      "step": 4645
    },
    {
      "epoch": 0.27559615612765453,
      "grad_norm": 65.25585174560547,
      "learning_rate": 1.6098075402056422e-05,
      "loss": 0.5887,
      "step": 4646
    },
    {
      "epoch": 0.2756554751453316,
      "grad_norm": 0.5961382985115051,
      "learning_rate": 1.6096757184286848e-05,
      "loss": 0.0077,
      "step": 4647
    },
    {
      "epoch": 0.27571479416300865,
      "grad_norm": 0.32803070545196533,
      "learning_rate": 1.609543896651727e-05,
      "loss": 0.0063,
      "step": 4648
    },
    {
      "epoch": 0.27577411318068573,
      "grad_norm": 22.1651668548584,
      "learning_rate": 1.6094120748747696e-05,
      "loss": 0.7121,
      "step": 4649
    },
    {
      "epoch": 0.2758334321983628,
      "grad_norm": 0.027869071811437607,
      "learning_rate": 1.609280253097812e-05,
      "loss": 0.0007,
      "step": 4650
    },
    {
      "epoch": 0.27589275121603984,
      "grad_norm": 0.5866150259971619,
      "learning_rate": 1.609148431320854e-05,
      "loss": 0.0088,
      "step": 4651
    },
    {
      "epoch": 0.27595207023371693,
      "grad_norm": 20.917369842529297,
      "learning_rate": 1.6090166095438967e-05,
      "loss": 0.5005,
      "step": 4652
    },
    {
      "epoch": 0.276011389251394,
      "grad_norm": 0.10039590299129486,
      "learning_rate": 1.608884787766939e-05,
      "loss": 0.0011,
      "step": 4653
    },
    {
      "epoch": 0.27607070826907104,
      "grad_norm": 29.03032684326172,
      "learning_rate": 1.6087529659899816e-05,
      "loss": 0.2014,
      "step": 4654
    },
    {
      "epoch": 0.2761300272867481,
      "grad_norm": 0.019233612343668938,
      "learning_rate": 1.608621144213024e-05,
      "loss": 0.0006,
      "step": 4655
    },
    {
      "epoch": 0.2761893463044252,
      "grad_norm": 5.5127153396606445,
      "learning_rate": 1.6084893224360664e-05,
      "loss": 0.1072,
      "step": 4656
    },
    {
      "epoch": 0.2762486653221023,
      "grad_norm": 1.4925854206085205,
      "learning_rate": 1.608357500659109e-05,
      "loss": 0.0103,
      "step": 4657
    },
    {
      "epoch": 0.2763079843397793,
      "grad_norm": 0.30637693405151367,
      "learning_rate": 1.6082256788821516e-05,
      "loss": 0.0042,
      "step": 4658
    },
    {
      "epoch": 0.2763673033574564,
      "grad_norm": 15.320662498474121,
      "learning_rate": 1.6080938571051938e-05,
      "loss": 0.3991,
      "step": 4659
    },
    {
      "epoch": 0.2764266223751335,
      "grad_norm": 0.23235538601875305,
      "learning_rate": 1.6079620353282364e-05,
      "loss": 0.0032,
      "step": 4660
    },
    {
      "epoch": 0.2764859413928105,
      "grad_norm": 0.09616100788116455,
      "learning_rate": 1.607830213551279e-05,
      "loss": 0.0015,
      "step": 4661
    },
    {
      "epoch": 0.2765452604104876,
      "grad_norm": 0.5915737748146057,
      "learning_rate": 1.6076983917743213e-05,
      "loss": 0.0053,
      "step": 4662
    },
    {
      "epoch": 0.2766045794281647,
      "grad_norm": 0.035523634403944016,
      "learning_rate": 1.607566569997364e-05,
      "loss": 0.0008,
      "step": 4663
    },
    {
      "epoch": 0.2766638984458417,
      "grad_norm": 0.05616368353366852,
      "learning_rate": 1.607434748220406e-05,
      "loss": 0.0016,
      "step": 4664
    },
    {
      "epoch": 0.2767232174635188,
      "grad_norm": 4.016870975494385,
      "learning_rate": 1.6073029264434487e-05,
      "loss": 0.3662,
      "step": 4665
    },
    {
      "epoch": 0.2767825364811959,
      "grad_norm": 0.1503533273935318,
      "learning_rate": 1.607171104666491e-05,
      "loss": 0.002,
      "step": 4666
    },
    {
      "epoch": 0.2768418554988729,
      "grad_norm": 0.26978015899658203,
      "learning_rate": 1.6070392828895335e-05,
      "loss": 0.0035,
      "step": 4667
    },
    {
      "epoch": 0.27690117451655,
      "grad_norm": 0.056612830609083176,
      "learning_rate": 1.6069074611125758e-05,
      "loss": 0.0011,
      "step": 4668
    },
    {
      "epoch": 0.2769604935342271,
      "grad_norm": 6.178035259246826,
      "learning_rate": 1.6067756393356184e-05,
      "loss": 0.2037,
      "step": 4669
    },
    {
      "epoch": 0.27701981255190417,
      "grad_norm": 0.1486068069934845,
      "learning_rate": 1.6066438175586606e-05,
      "loss": 0.0026,
      "step": 4670
    },
    {
      "epoch": 0.2770791315695812,
      "grad_norm": 21.557998657226562,
      "learning_rate": 1.6065119957817032e-05,
      "loss": 0.2032,
      "step": 4671
    },
    {
      "epoch": 0.2771384505872583,
      "grad_norm": 0.02998514473438263,
      "learning_rate": 1.6063801740047458e-05,
      "loss": 0.0007,
      "step": 4672
    },
    {
      "epoch": 0.27719776960493536,
      "grad_norm": 0.5753428339958191,
      "learning_rate": 1.606248352227788e-05,
      "loss": 0.0096,
      "step": 4673
    },
    {
      "epoch": 0.2772570886226124,
      "grad_norm": 0.39483797550201416,
      "learning_rate": 1.6061165304508306e-05,
      "loss": 0.0034,
      "step": 4674
    },
    {
      "epoch": 0.2773164076402895,
      "grad_norm": 0.05922042950987816,
      "learning_rate": 1.6059847086738732e-05,
      "loss": 0.0014,
      "step": 4675
    },
    {
      "epoch": 0.27737572665796656,
      "grad_norm": 6.808981895446777,
      "learning_rate": 1.6058528868969155e-05,
      "loss": 0.2201,
      "step": 4676
    },
    {
      "epoch": 0.2774350456756436,
      "grad_norm": 0.01036598440259695,
      "learning_rate": 1.605721065119958e-05,
      "loss": 0.0005,
      "step": 4677
    },
    {
      "epoch": 0.27749436469332067,
      "grad_norm": 0.02105100266635418,
      "learning_rate": 1.6055892433430006e-05,
      "loss": 0.0006,
      "step": 4678
    },
    {
      "epoch": 0.27755368371099776,
      "grad_norm": 0.05196905881166458,
      "learning_rate": 1.605457421566043e-05,
      "loss": 0.001,
      "step": 4679
    },
    {
      "epoch": 0.27761300272867484,
      "grad_norm": 7.769132137298584,
      "learning_rate": 1.6053255997890855e-05,
      "loss": 0.2666,
      "step": 4680
    },
    {
      "epoch": 0.27767232174635187,
      "grad_norm": 4.285905838012695,
      "learning_rate": 1.6051937780121277e-05,
      "loss": 0.0771,
      "step": 4681
    },
    {
      "epoch": 0.27773164076402895,
      "grad_norm": 0.018818354234099388,
      "learning_rate": 1.6050619562351703e-05,
      "loss": 0.0005,
      "step": 4682
    },
    {
      "epoch": 0.27779095978170604,
      "grad_norm": 15.313163757324219,
      "learning_rate": 1.6049301344582126e-05,
      "loss": 0.1686,
      "step": 4683
    },
    {
      "epoch": 0.27785027879938307,
      "grad_norm": 0.6947954297065735,
      "learning_rate": 1.6047983126812548e-05,
      "loss": 0.0065,
      "step": 4684
    },
    {
      "epoch": 0.27790959781706015,
      "grad_norm": 21.61440086364746,
      "learning_rate": 1.6046664909042974e-05,
      "loss": 1.7929,
      "step": 4685
    },
    {
      "epoch": 0.27796891683473723,
      "grad_norm": 0.02902231551706791,
      "learning_rate": 1.60453466912734e-05,
      "loss": 0.0009,
      "step": 4686
    },
    {
      "epoch": 0.27802823585241426,
      "grad_norm": 54.688873291015625,
      "learning_rate": 1.6044028473503822e-05,
      "loss": 0.6667,
      "step": 4687
    },
    {
      "epoch": 0.27808755487009135,
      "grad_norm": 0.01755286380648613,
      "learning_rate": 1.6042710255734248e-05,
      "loss": 0.0004,
      "step": 4688
    },
    {
      "epoch": 0.27814687388776843,
      "grad_norm": 25.22675323486328,
      "learning_rate": 1.6041392037964674e-05,
      "loss": 0.3083,
      "step": 4689
    },
    {
      "epoch": 0.27820619290544546,
      "grad_norm": 0.284830778837204,
      "learning_rate": 1.6040073820195097e-05,
      "loss": 0.0024,
      "step": 4690
    },
    {
      "epoch": 0.27826551192312254,
      "grad_norm": 0.012193646281957626,
      "learning_rate": 1.6038755602425522e-05,
      "loss": 0.0004,
      "step": 4691
    },
    {
      "epoch": 0.27832483094079963,
      "grad_norm": 13.972128868103027,
      "learning_rate": 1.6037437384655948e-05,
      "loss": 0.5061,
      "step": 4692
    },
    {
      "epoch": 0.2783841499584767,
      "grad_norm": 5.424173355102539,
      "learning_rate": 1.603611916688637e-05,
      "loss": 0.0707,
      "step": 4693
    },
    {
      "epoch": 0.27844346897615374,
      "grad_norm": 39.049617767333984,
      "learning_rate": 1.6034800949116797e-05,
      "loss": 0.1736,
      "step": 4694
    },
    {
      "epoch": 0.2785027879938308,
      "grad_norm": 0.013805810362100601,
      "learning_rate": 1.603348273134722e-05,
      "loss": 0.0003,
      "step": 4695
    },
    {
      "epoch": 0.2785621070115079,
      "grad_norm": 27.629793167114258,
      "learning_rate": 1.6032164513577645e-05,
      "loss": 0.6368,
      "step": 4696
    },
    {
      "epoch": 0.27862142602918494,
      "grad_norm": 46.38093948364258,
      "learning_rate": 1.6030846295808068e-05,
      "loss": 0.2315,
      "step": 4697
    },
    {
      "epoch": 0.278680745046862,
      "grad_norm": 0.009471438825130463,
      "learning_rate": 1.6029528078038493e-05,
      "loss": 0.0005,
      "step": 4698
    },
    {
      "epoch": 0.2787400640645391,
      "grad_norm": 0.4457472860813141,
      "learning_rate": 1.6028209860268916e-05,
      "loss": 0.0041,
      "step": 4699
    },
    {
      "epoch": 0.27879938308221613,
      "grad_norm": 0.19293078780174255,
      "learning_rate": 1.6026891642499342e-05,
      "loss": 0.004,
      "step": 4700
    },
    {
      "epoch": 0.2788587020998932,
      "grad_norm": 6.588262557983398,
      "learning_rate": 1.6025573424729764e-05,
      "loss": 0.0171,
      "step": 4701
    },
    {
      "epoch": 0.2789180211175703,
      "grad_norm": 0.7959980368614197,
      "learning_rate": 1.602425520696019e-05,
      "loss": 0.0087,
      "step": 4702
    },
    {
      "epoch": 0.2789773401352474,
      "grad_norm": 0.03678147494792938,
      "learning_rate": 1.6022936989190616e-05,
      "loss": 0.001,
      "step": 4703
    },
    {
      "epoch": 0.2790366591529244,
      "grad_norm": 0.06865780800580978,
      "learning_rate": 1.602161877142104e-05,
      "loss": 0.0013,
      "step": 4704
    },
    {
      "epoch": 0.2790959781706015,
      "grad_norm": 6.9539947509765625,
      "learning_rate": 1.6020300553651464e-05,
      "loss": 0.0593,
      "step": 4705
    },
    {
      "epoch": 0.2791552971882786,
      "grad_norm": 0.10463140904903412,
      "learning_rate": 1.601898233588189e-05,
      "loss": 0.0012,
      "step": 4706
    },
    {
      "epoch": 0.2792146162059556,
      "grad_norm": 69.2931137084961,
      "learning_rate": 1.6017664118112313e-05,
      "loss": 1.767,
      "step": 4707
    },
    {
      "epoch": 0.2792739352236327,
      "grad_norm": 31.785213470458984,
      "learning_rate": 1.601634590034274e-05,
      "loss": 0.4614,
      "step": 4708
    },
    {
      "epoch": 0.2793332542413098,
      "grad_norm": 0.22144073247909546,
      "learning_rate": 1.6015027682573165e-05,
      "loss": 0.0019,
      "step": 4709
    },
    {
      "epoch": 0.2793925732589868,
      "grad_norm": 0.022408315911889076,
      "learning_rate": 1.6013709464803587e-05,
      "loss": 0.0004,
      "step": 4710
    },
    {
      "epoch": 0.2794518922766639,
      "grad_norm": 6.997566223144531,
      "learning_rate": 1.6012391247034013e-05,
      "loss": 0.041,
      "step": 4711
    },
    {
      "epoch": 0.279511211294341,
      "grad_norm": 2.5744359493255615,
      "learning_rate": 1.6011073029264435e-05,
      "loss": 0.0285,
      "step": 4712
    },
    {
      "epoch": 0.279570530312018,
      "grad_norm": 0.10406626760959625,
      "learning_rate": 1.600975481149486e-05,
      "loss": 0.0007,
      "step": 4713
    },
    {
      "epoch": 0.2796298493296951,
      "grad_norm": 13.571626663208008,
      "learning_rate": 1.6008436593725284e-05,
      "loss": 0.0624,
      "step": 4714
    },
    {
      "epoch": 0.2796891683473722,
      "grad_norm": 0.06256718933582306,
      "learning_rate": 1.600711837595571e-05,
      "loss": 0.0012,
      "step": 4715
    },
    {
      "epoch": 0.27974848736504926,
      "grad_norm": 3.066051483154297,
      "learning_rate": 1.6005800158186132e-05,
      "loss": 0.032,
      "step": 4716
    },
    {
      "epoch": 0.2798078063827263,
      "grad_norm": 9.208083152770996,
      "learning_rate": 1.6004481940416558e-05,
      "loss": 0.4416,
      "step": 4717
    },
    {
      "epoch": 0.27986712540040337,
      "grad_norm": 0.06956300139427185,
      "learning_rate": 1.600316372264698e-05,
      "loss": 0.0012,
      "step": 4718
    },
    {
      "epoch": 0.27992644441808046,
      "grad_norm": 13.024153709411621,
      "learning_rate": 1.6001845504877406e-05,
      "loss": 0.1273,
      "step": 4719
    },
    {
      "epoch": 0.2799857634357575,
      "grad_norm": 8.830499649047852,
      "learning_rate": 1.6000527287107832e-05,
      "loss": 0.6763,
      "step": 4720
    },
    {
      "epoch": 0.28004508245343457,
      "grad_norm": 19.42691421508789,
      "learning_rate": 1.5999209069338255e-05,
      "loss": 0.3115,
      "step": 4721
    },
    {
      "epoch": 0.28010440147111165,
      "grad_norm": 13.566535949707031,
      "learning_rate": 1.599789085156868e-05,
      "loss": 1.8486,
      "step": 4722
    },
    {
      "epoch": 0.2801637204887887,
      "grad_norm": 3.3297717571258545,
      "learning_rate": 1.5996572633799107e-05,
      "loss": 0.0465,
      "step": 4723
    },
    {
      "epoch": 0.28022303950646577,
      "grad_norm": 0.14249205589294434,
      "learning_rate": 1.599525441602953e-05,
      "loss": 0.0018,
      "step": 4724
    },
    {
      "epoch": 0.28028235852414285,
      "grad_norm": 8.957128524780273,
      "learning_rate": 1.5993936198259955e-05,
      "loss": 0.2312,
      "step": 4725
    },
    {
      "epoch": 0.28034167754181993,
      "grad_norm": 0.20644961297512054,
      "learning_rate": 1.599261798049038e-05,
      "loss": 0.0017,
      "step": 4726
    },
    {
      "epoch": 0.28040099655949696,
      "grad_norm": 0.016688374802470207,
      "learning_rate": 1.5991299762720803e-05,
      "loss": 0.0004,
      "step": 4727
    },
    {
      "epoch": 0.28046031557717405,
      "grad_norm": 41.02644348144531,
      "learning_rate": 1.5989981544951226e-05,
      "loss": 0.4742,
      "step": 4728
    },
    {
      "epoch": 0.28051963459485113,
      "grad_norm": 0.08838342130184174,
      "learning_rate": 1.598866332718165e-05,
      "loss": 0.0017,
      "step": 4729
    },
    {
      "epoch": 0.28057895361252816,
      "grad_norm": 1.8274503946304321,
      "learning_rate": 1.5987345109412074e-05,
      "loss": 0.0947,
      "step": 4730
    },
    {
      "epoch": 0.28063827263020524,
      "grad_norm": 0.02766892872750759,
      "learning_rate": 1.59860268916425e-05,
      "loss": 0.0006,
      "step": 4731
    },
    {
      "epoch": 0.2806975916478823,
      "grad_norm": 12.945086479187012,
      "learning_rate": 1.5984708673872923e-05,
      "loss": 0.4404,
      "step": 4732
    },
    {
      "epoch": 0.28075691066555936,
      "grad_norm": 4.84807825088501,
      "learning_rate": 1.598339045610335e-05,
      "loss": 0.0214,
      "step": 4733
    },
    {
      "epoch": 0.28081622968323644,
      "grad_norm": 64.73670959472656,
      "learning_rate": 1.5982072238333774e-05,
      "loss": 1.6169,
      "step": 4734
    },
    {
      "epoch": 0.2808755487009135,
      "grad_norm": 0.02921854518353939,
      "learning_rate": 1.5980754020564197e-05,
      "loss": 0.0007,
      "step": 4735
    },
    {
      "epoch": 0.28093486771859055,
      "grad_norm": 0.17000390589237213,
      "learning_rate": 1.5979435802794623e-05,
      "loss": 0.0033,
      "step": 4736
    },
    {
      "epoch": 0.28099418673626764,
      "grad_norm": 8.807199478149414,
      "learning_rate": 1.597811758502505e-05,
      "loss": 0.5072,
      "step": 4737
    },
    {
      "epoch": 0.2810535057539447,
      "grad_norm": 0.09574250131845474,
      "learning_rate": 1.597679936725547e-05,
      "loss": 0.0016,
      "step": 4738
    },
    {
      "epoch": 0.2811128247716218,
      "grad_norm": 11.060359954833984,
      "learning_rate": 1.5975481149485897e-05,
      "loss": 0.0497,
      "step": 4739
    },
    {
      "epoch": 0.28117214378929883,
      "grad_norm": 21.336166381835938,
      "learning_rate": 1.5974162931716323e-05,
      "loss": 0.856,
      "step": 4740
    },
    {
      "epoch": 0.2812314628069759,
      "grad_norm": 4.103138446807861,
      "learning_rate": 1.5972844713946745e-05,
      "loss": 0.1259,
      "step": 4741
    },
    {
      "epoch": 0.281290781824653,
      "grad_norm": 8.258484840393066,
      "learning_rate": 1.597152649617717e-05,
      "loss": 0.1501,
      "step": 4742
    },
    {
      "epoch": 0.28135010084233003,
      "grad_norm": 0.033995505422353745,
      "learning_rate": 1.5970208278407594e-05,
      "loss": 0.0007,
      "step": 4743
    },
    {
      "epoch": 0.2814094198600071,
      "grad_norm": 8.989269256591797,
      "learning_rate": 1.596889006063802e-05,
      "loss": 0.2675,
      "step": 4744
    },
    {
      "epoch": 0.2814687388776842,
      "grad_norm": 21.45716094970703,
      "learning_rate": 1.5967571842868442e-05,
      "loss": 0.2127,
      "step": 4745
    },
    {
      "epoch": 0.28152805789536123,
      "grad_norm": 0.0934394896030426,
      "learning_rate": 1.5966253625098868e-05,
      "loss": 0.0017,
      "step": 4746
    },
    {
      "epoch": 0.2815873769130383,
      "grad_norm": 3.5987095832824707,
      "learning_rate": 1.596493540732929e-05,
      "loss": 0.1632,
      "step": 4747
    },
    {
      "epoch": 0.2816466959307154,
      "grad_norm": 11.613269805908203,
      "learning_rate": 1.5963617189559716e-05,
      "loss": 0.2268,
      "step": 4748
    },
    {
      "epoch": 0.2817060149483925,
      "grad_norm": 5.806702613830566,
      "learning_rate": 1.596229897179014e-05,
      "loss": 0.4037,
      "step": 4749
    },
    {
      "epoch": 0.2817653339660695,
      "grad_norm": 11.462475776672363,
      "learning_rate": 1.5960980754020565e-05,
      "loss": 0.3565,
      "step": 4750
    },
    {
      "epoch": 0.2818246529837466,
      "grad_norm": 0.7319256067276001,
      "learning_rate": 1.595966253625099e-05,
      "loss": 0.0058,
      "step": 4751
    },
    {
      "epoch": 0.2818839720014237,
      "grad_norm": 3.1840434074401855,
      "learning_rate": 1.5958344318481413e-05,
      "loss": 0.0416,
      "step": 4752
    },
    {
      "epoch": 0.2819432910191007,
      "grad_norm": 0.4106092154979706,
      "learning_rate": 1.595702610071184e-05,
      "loss": 0.0045,
      "step": 4753
    },
    {
      "epoch": 0.2820026100367778,
      "grad_norm": 1.9515653848648071,
      "learning_rate": 1.5955707882942265e-05,
      "loss": 0.0162,
      "step": 4754
    },
    {
      "epoch": 0.2820619290544549,
      "grad_norm": 9.45553207397461,
      "learning_rate": 1.5954389665172687e-05,
      "loss": 0.3676,
      "step": 4755
    },
    {
      "epoch": 0.2821212480721319,
      "grad_norm": 0.06262143701314926,
      "learning_rate": 1.5953071447403113e-05,
      "loss": 0.0014,
      "step": 4756
    },
    {
      "epoch": 0.282180567089809,
      "grad_norm": 1.179558515548706,
      "learning_rate": 1.595175322963354e-05,
      "loss": 0.0109,
      "step": 4757
    },
    {
      "epoch": 0.28223988610748607,
      "grad_norm": 2.964972972869873,
      "learning_rate": 1.595043501186396e-05,
      "loss": 0.1305,
      "step": 4758
    },
    {
      "epoch": 0.2822992051251631,
      "grad_norm": 6.463174819946289,
      "learning_rate": 1.5949116794094387e-05,
      "loss": 0.1117,
      "step": 4759
    },
    {
      "epoch": 0.2823585241428402,
      "grad_norm": 1.6385096311569214,
      "learning_rate": 1.594779857632481e-05,
      "loss": 0.0206,
      "step": 4760
    },
    {
      "epoch": 0.28241784316051727,
      "grad_norm": 7.486926078796387,
      "learning_rate": 1.5946480358555232e-05,
      "loss": 0.3663,
      "step": 4761
    },
    {
      "epoch": 0.28247716217819435,
      "grad_norm": 0.1784421056509018,
      "learning_rate": 1.594516214078566e-05,
      "loss": 0.0023,
      "step": 4762
    },
    {
      "epoch": 0.2825364811958714,
      "grad_norm": 0.06366907805204391,
      "learning_rate": 1.5943843923016084e-05,
      "loss": 0.0016,
      "step": 4763
    },
    {
      "epoch": 0.28259580021354846,
      "grad_norm": 16.39168357849121,
      "learning_rate": 1.5942525705246507e-05,
      "loss": 0.2888,
      "step": 4764
    },
    {
      "epoch": 0.28265511923122555,
      "grad_norm": 1.6990658044815063,
      "learning_rate": 1.5941207487476933e-05,
      "loss": 0.0121,
      "step": 4765
    },
    {
      "epoch": 0.2827144382489026,
      "grad_norm": 0.3029789626598358,
      "learning_rate": 1.5939889269707355e-05,
      "loss": 0.0045,
      "step": 4766
    },
    {
      "epoch": 0.28277375726657966,
      "grad_norm": 0.024488050490617752,
      "learning_rate": 1.593857105193778e-05,
      "loss": 0.0004,
      "step": 4767
    },
    {
      "epoch": 0.28283307628425675,
      "grad_norm": 0.2643160820007324,
      "learning_rate": 1.5937252834168207e-05,
      "loss": 0.0053,
      "step": 4768
    },
    {
      "epoch": 0.2828923953019338,
      "grad_norm": 1.3492944240570068,
      "learning_rate": 1.593593461639863e-05,
      "loss": 0.0146,
      "step": 4769
    },
    {
      "epoch": 0.28295171431961086,
      "grad_norm": 0.23051975667476654,
      "learning_rate": 1.5934616398629055e-05,
      "loss": 0.002,
      "step": 4770
    },
    {
      "epoch": 0.28301103333728794,
      "grad_norm": 21.603897094726562,
      "learning_rate": 1.593329818085948e-05,
      "loss": 0.8599,
      "step": 4771
    },
    {
      "epoch": 0.283070352354965,
      "grad_norm": 0.04141613468527794,
      "learning_rate": 1.5931979963089904e-05,
      "loss": 0.0011,
      "step": 4772
    },
    {
      "epoch": 0.28312967137264206,
      "grad_norm": 4.526472568511963,
      "learning_rate": 1.593066174532033e-05,
      "loss": 0.0296,
      "step": 4773
    },
    {
      "epoch": 0.28318899039031914,
      "grad_norm": 23.303266525268555,
      "learning_rate": 1.5929343527550752e-05,
      "loss": 0.3596,
      "step": 4774
    },
    {
      "epoch": 0.2832483094079962,
      "grad_norm": 0.01893799565732479,
      "learning_rate": 1.5928025309781178e-05,
      "loss": 0.0006,
      "step": 4775
    },
    {
      "epoch": 0.28330762842567325,
      "grad_norm": 7.235708713531494,
      "learning_rate": 1.59267070920116e-05,
      "loss": 0.1438,
      "step": 4776
    },
    {
      "epoch": 0.28336694744335034,
      "grad_norm": 0.37373730540275574,
      "learning_rate": 1.5925388874242026e-05,
      "loss": 0.0072,
      "step": 4777
    },
    {
      "epoch": 0.2834262664610274,
      "grad_norm": 5.653981685638428,
      "learning_rate": 1.592407065647245e-05,
      "loss": 0.2417,
      "step": 4778
    },
    {
      "epoch": 0.28348558547870445,
      "grad_norm": 0.05123353376984596,
      "learning_rate": 1.5922752438702875e-05,
      "loss": 0.0011,
      "step": 4779
    },
    {
      "epoch": 0.28354490449638153,
      "grad_norm": 0.05706402659416199,
      "learning_rate": 1.5921434220933297e-05,
      "loss": 0.0016,
      "step": 4780
    },
    {
      "epoch": 0.2836042235140586,
      "grad_norm": 13.343317031860352,
      "learning_rate": 1.5920116003163723e-05,
      "loss": 0.1511,
      "step": 4781
    },
    {
      "epoch": 0.2836635425317357,
      "grad_norm": 0.10690560191869736,
      "learning_rate": 1.591879778539415e-05,
      "loss": 0.0013,
      "step": 4782
    },
    {
      "epoch": 0.28372286154941273,
      "grad_norm": 6.964364051818848,
      "learning_rate": 1.591747956762457e-05,
      "loss": 0.1019,
      "step": 4783
    },
    {
      "epoch": 0.2837821805670898,
      "grad_norm": 7.778669834136963,
      "learning_rate": 1.5916161349854997e-05,
      "loss": 0.1376,
      "step": 4784
    },
    {
      "epoch": 0.2838414995847669,
      "grad_norm": 12.844545364379883,
      "learning_rate": 1.5914843132085423e-05,
      "loss": 0.1026,
      "step": 4785
    },
    {
      "epoch": 0.2839008186024439,
      "grad_norm": 1.152153491973877,
      "learning_rate": 1.5913524914315846e-05,
      "loss": 0.0052,
      "step": 4786
    },
    {
      "epoch": 0.283960137620121,
      "grad_norm": 0.32917195558547974,
      "learning_rate": 1.591220669654627e-05,
      "loss": 0.0046,
      "step": 4787
    },
    {
      "epoch": 0.2840194566377981,
      "grad_norm": 4.244654178619385,
      "learning_rate": 1.5910888478776697e-05,
      "loss": 0.0867,
      "step": 4788
    },
    {
      "epoch": 0.2840787756554751,
      "grad_norm": 7.918093204498291,
      "learning_rate": 1.590957026100712e-05,
      "loss": 0.6068,
      "step": 4789
    },
    {
      "epoch": 0.2841380946731522,
      "grad_norm": 0.1807892918586731,
      "learning_rate": 1.5908252043237546e-05,
      "loss": 0.0026,
      "step": 4790
    },
    {
      "epoch": 0.2841974136908293,
      "grad_norm": 0.3054443597793579,
      "learning_rate": 1.5906933825467968e-05,
      "loss": 0.0055,
      "step": 4791
    },
    {
      "epoch": 0.2842567327085063,
      "grad_norm": 12.680244445800781,
      "learning_rate": 1.5905615607698394e-05,
      "loss": 0.1618,
      "step": 4792
    },
    {
      "epoch": 0.2843160517261834,
      "grad_norm": 2.1369986534118652,
      "learning_rate": 1.5904297389928817e-05,
      "loss": 0.0285,
      "step": 4793
    },
    {
      "epoch": 0.2843753707438605,
      "grad_norm": 9.606226921081543,
      "learning_rate": 1.5902979172159242e-05,
      "loss": 0.0628,
      "step": 4794
    },
    {
      "epoch": 0.2844346897615376,
      "grad_norm": 7.516176700592041,
      "learning_rate": 1.5901660954389665e-05,
      "loss": 0.3139,
      "step": 4795
    },
    {
      "epoch": 0.2844940087792146,
      "grad_norm": 0.19658106565475464,
      "learning_rate": 1.590034273662009e-05,
      "loss": 0.0028,
      "step": 4796
    },
    {
      "epoch": 0.2845533277968917,
      "grad_norm": 5.012189865112305,
      "learning_rate": 1.5899024518850513e-05,
      "loss": 0.0772,
      "step": 4797
    },
    {
      "epoch": 0.28461264681456877,
      "grad_norm": 1.761647343635559,
      "learning_rate": 1.589770630108094e-05,
      "loss": 0.0259,
      "step": 4798
    },
    {
      "epoch": 0.2846719658322458,
      "grad_norm": 2.8205924034118652,
      "learning_rate": 1.5896388083311365e-05,
      "loss": 0.0409,
      "step": 4799
    },
    {
      "epoch": 0.2847312848499229,
      "grad_norm": 0.10497352480888367,
      "learning_rate": 1.5895069865541788e-05,
      "loss": 0.0019,
      "step": 4800
    },
    {
      "epoch": 0.28479060386759997,
      "grad_norm": 10.825839042663574,
      "learning_rate": 1.5893751647772213e-05,
      "loss": 0.1304,
      "step": 4801
    },
    {
      "epoch": 0.284849922885277,
      "grad_norm": 17.76970863342285,
      "learning_rate": 1.589243343000264e-05,
      "loss": 0.2958,
      "step": 4802
    },
    {
      "epoch": 0.2849092419029541,
      "grad_norm": 0.086489737033844,
      "learning_rate": 1.5891115212233062e-05,
      "loss": 0.0021,
      "step": 4803
    },
    {
      "epoch": 0.28496856092063116,
      "grad_norm": 0.6891216039657593,
      "learning_rate": 1.5889796994463488e-05,
      "loss": 0.0069,
      "step": 4804
    },
    {
      "epoch": 0.28502787993830825,
      "grad_norm": 0.0847228541970253,
      "learning_rate": 1.588847877669391e-05,
      "loss": 0.0015,
      "step": 4805
    },
    {
      "epoch": 0.2850871989559853,
      "grad_norm": 7.472345352172852,
      "learning_rate": 1.5887160558924336e-05,
      "loss": 0.0793,
      "step": 4806
    },
    {
      "epoch": 0.28514651797366236,
      "grad_norm": 16.168359756469727,
      "learning_rate": 1.588584234115476e-05,
      "loss": 2.2215,
      "step": 4807
    },
    {
      "epoch": 0.28520583699133945,
      "grad_norm": 0.18686901032924652,
      "learning_rate": 1.5884524123385184e-05,
      "loss": 0.0017,
      "step": 4808
    },
    {
      "epoch": 0.2852651560090165,
      "grad_norm": 0.10194942355155945,
      "learning_rate": 1.5883205905615607e-05,
      "loss": 0.0019,
      "step": 4809
    },
    {
      "epoch": 0.28532447502669356,
      "grad_norm": 9.720858573913574,
      "learning_rate": 1.5881887687846033e-05,
      "loss": 0.4136,
      "step": 4810
    },
    {
      "epoch": 0.28538379404437064,
      "grad_norm": 3.264784812927246,
      "learning_rate": 1.588056947007646e-05,
      "loss": 0.0474,
      "step": 4811
    },
    {
      "epoch": 0.28544311306204767,
      "grad_norm": 5.294352054595947,
      "learning_rate": 1.587925125230688e-05,
      "loss": 0.189,
      "step": 4812
    },
    {
      "epoch": 0.28550243207972476,
      "grad_norm": 7.892303466796875,
      "learning_rate": 1.5877933034537307e-05,
      "loss": 0.0409,
      "step": 4813
    },
    {
      "epoch": 0.28556175109740184,
      "grad_norm": 1.8177119493484497,
      "learning_rate": 1.587661481676773e-05,
      "loss": 0.0203,
      "step": 4814
    },
    {
      "epoch": 0.28562107011507887,
      "grad_norm": 1.706726312637329,
      "learning_rate": 1.5875296598998155e-05,
      "loss": 0.0214,
      "step": 4815
    },
    {
      "epoch": 0.28568038913275595,
      "grad_norm": 0.01892491802573204,
      "learning_rate": 1.587397838122858e-05,
      "loss": 0.0003,
      "step": 4816
    },
    {
      "epoch": 0.28573970815043304,
      "grad_norm": 10.746665954589844,
      "learning_rate": 1.5872660163459004e-05,
      "loss": 0.1801,
      "step": 4817
    },
    {
      "epoch": 0.2857990271681101,
      "grad_norm": 20.485849380493164,
      "learning_rate": 1.587134194568943e-05,
      "loss": 0.0427,
      "step": 4818
    },
    {
      "epoch": 0.28585834618578715,
      "grad_norm": 7.166670799255371,
      "learning_rate": 1.5870023727919856e-05,
      "loss": 0.1533,
      "step": 4819
    },
    {
      "epoch": 0.28591766520346423,
      "grad_norm": 0.8158703446388245,
      "learning_rate": 1.5868705510150278e-05,
      "loss": 0.0164,
      "step": 4820
    },
    {
      "epoch": 0.2859769842211413,
      "grad_norm": 0.15265001356601715,
      "learning_rate": 1.5867387292380704e-05,
      "loss": 0.0035,
      "step": 4821
    },
    {
      "epoch": 0.28603630323881835,
      "grad_norm": 89.32218170166016,
      "learning_rate": 1.5866069074611127e-05,
      "loss": 0.756,
      "step": 4822
    },
    {
      "epoch": 0.28609562225649543,
      "grad_norm": 9.57850456237793,
      "learning_rate": 1.5864750856841552e-05,
      "loss": 0.4886,
      "step": 4823
    },
    {
      "epoch": 0.2861549412741725,
      "grad_norm": 17.096872329711914,
      "learning_rate": 1.5863432639071975e-05,
      "loss": 0.9644,
      "step": 4824
    },
    {
      "epoch": 0.28621426029184954,
      "grad_norm": 5.878016471862793,
      "learning_rate": 1.58621144213024e-05,
      "loss": 0.0891,
      "step": 4825
    },
    {
      "epoch": 0.2862735793095266,
      "grad_norm": 5.007025241851807,
      "learning_rate": 1.5860796203532823e-05,
      "loss": 0.098,
      "step": 4826
    },
    {
      "epoch": 0.2863328983272037,
      "grad_norm": 1.6678931713104248,
      "learning_rate": 1.585947798576325e-05,
      "loss": 0.0169,
      "step": 4827
    },
    {
      "epoch": 0.2863922173448808,
      "grad_norm": 1.6337001323699951,
      "learning_rate": 1.5858159767993675e-05,
      "loss": 0.0081,
      "step": 4828
    },
    {
      "epoch": 0.2864515363625578,
      "grad_norm": 1.1518114805221558,
      "learning_rate": 1.5856841550224098e-05,
      "loss": 0.007,
      "step": 4829
    },
    {
      "epoch": 0.2865108553802349,
      "grad_norm": 0.005572413560003042,
      "learning_rate": 1.5855523332454523e-05,
      "loss": 0.0002,
      "step": 4830
    },
    {
      "epoch": 0.286570174397912,
      "grad_norm": 0.6312809586524963,
      "learning_rate": 1.5854205114684946e-05,
      "loss": 0.0088,
      "step": 4831
    },
    {
      "epoch": 0.286629493415589,
      "grad_norm": 0.025847675278782845,
      "learning_rate": 1.5852886896915372e-05,
      "loss": 0.0007,
      "step": 4832
    },
    {
      "epoch": 0.2866888124332661,
      "grad_norm": 0.01590890809893608,
      "learning_rate": 1.5851568679145798e-05,
      "loss": 0.0006,
      "step": 4833
    },
    {
      "epoch": 0.2867481314509432,
      "grad_norm": 0.04641716927289963,
      "learning_rate": 1.585025046137622e-05,
      "loss": 0.0013,
      "step": 4834
    },
    {
      "epoch": 0.2868074504686202,
      "grad_norm": 28.009925842285156,
      "learning_rate": 1.5848932243606646e-05,
      "loss": 0.6795,
      "step": 4835
    },
    {
      "epoch": 0.2868667694862973,
      "grad_norm": 36.00238800048828,
      "learning_rate": 1.5847614025837072e-05,
      "loss": 0.3253,
      "step": 4836
    },
    {
      "epoch": 0.2869260885039744,
      "grad_norm": 0.4982356131076813,
      "learning_rate": 1.5846295808067494e-05,
      "loss": 0.0052,
      "step": 4837
    },
    {
      "epoch": 0.2869854075216514,
      "grad_norm": 0.05158437415957451,
      "learning_rate": 1.584497759029792e-05,
      "loss": 0.0014,
      "step": 4838
    },
    {
      "epoch": 0.2870447265393285,
      "grad_norm": 6.459299564361572,
      "learning_rate": 1.5843659372528343e-05,
      "loss": 0.3433,
      "step": 4839
    },
    {
      "epoch": 0.2871040455570056,
      "grad_norm": 10.943960189819336,
      "learning_rate": 1.5842341154758765e-05,
      "loss": 0.0699,
      "step": 4840
    },
    {
      "epoch": 0.28716336457468267,
      "grad_norm": 8.804398536682129,
      "learning_rate": 1.584102293698919e-05,
      "loss": 0.1108,
      "step": 4841
    },
    {
      "epoch": 0.2872226835923597,
      "grad_norm": 0.14277063310146332,
      "learning_rate": 1.5839704719219617e-05,
      "loss": 0.0021,
      "step": 4842
    },
    {
      "epoch": 0.2872820026100368,
      "grad_norm": 2.2392070293426514,
      "learning_rate": 1.583838650145004e-05,
      "loss": 0.0199,
      "step": 4843
    },
    {
      "epoch": 0.28734132162771386,
      "grad_norm": 16.591922760009766,
      "learning_rate": 1.5837068283680465e-05,
      "loss": 1.5414,
      "step": 4844
    },
    {
      "epoch": 0.2874006406453909,
      "grad_norm": 0.11014319211244583,
      "learning_rate": 1.5835750065910888e-05,
      "loss": 0.0028,
      "step": 4845
    },
    {
      "epoch": 0.287459959663068,
      "grad_norm": 35.27214431762695,
      "learning_rate": 1.5834431848141314e-05,
      "loss": 1.827,
      "step": 4846
    },
    {
      "epoch": 0.28751927868074506,
      "grad_norm": 0.6160626411437988,
      "learning_rate": 1.583311363037174e-05,
      "loss": 0.0097,
      "step": 4847
    },
    {
      "epoch": 0.2875785976984221,
      "grad_norm": 16.91867446899414,
      "learning_rate": 1.5831795412602162e-05,
      "loss": 0.0857,
      "step": 4848
    },
    {
      "epoch": 0.2876379167160992,
      "grad_norm": 19.788869857788086,
      "learning_rate": 1.5830477194832588e-05,
      "loss": 0.4639,
      "step": 4849
    },
    {
      "epoch": 0.28769723573377626,
      "grad_norm": 0.5637612342834473,
      "learning_rate": 1.5829158977063014e-05,
      "loss": 0.0049,
      "step": 4850
    },
    {
      "epoch": 0.28775655475145334,
      "grad_norm": 6.691619396209717,
      "learning_rate": 1.5827840759293436e-05,
      "loss": 0.015,
      "step": 4851
    },
    {
      "epoch": 0.28781587376913037,
      "grad_norm": 0.04441297426819801,
      "learning_rate": 1.5826522541523862e-05,
      "loss": 0.0015,
      "step": 4852
    },
    {
      "epoch": 0.28787519278680745,
      "grad_norm": 2.351364850997925,
      "learning_rate": 1.5825204323754285e-05,
      "loss": 0.0207,
      "step": 4853
    },
    {
      "epoch": 0.28793451180448454,
      "grad_norm": 9.79886531829834,
      "learning_rate": 1.582388610598471e-05,
      "loss": 0.2517,
      "step": 4854
    },
    {
      "epoch": 0.28799383082216157,
      "grad_norm": 0.06331948190927505,
      "learning_rate": 1.5822567888215133e-05,
      "loss": 0.0013,
      "step": 4855
    },
    {
      "epoch": 0.28805314983983865,
      "grad_norm": 0.5295647382736206,
      "learning_rate": 1.582124967044556e-05,
      "loss": 0.0046,
      "step": 4856
    },
    {
      "epoch": 0.28811246885751574,
      "grad_norm": 0.10544878989458084,
      "learning_rate": 1.581993145267598e-05,
      "loss": 0.0018,
      "step": 4857
    },
    {
      "epoch": 0.28817178787519276,
      "grad_norm": 0.04411252215504646,
      "learning_rate": 1.5818613234906407e-05,
      "loss": 0.0012,
      "step": 4858
    },
    {
      "epoch": 0.28823110689286985,
      "grad_norm": 0.7904211282730103,
      "learning_rate": 1.5817295017136833e-05,
      "loss": 0.0099,
      "step": 4859
    },
    {
      "epoch": 0.28829042591054693,
      "grad_norm": 18.707012176513672,
      "learning_rate": 1.5815976799367256e-05,
      "loss": 0.5866,
      "step": 4860
    },
    {
      "epoch": 0.28834974492822396,
      "grad_norm": 5.528905391693115,
      "learning_rate": 1.581465858159768e-05,
      "loss": 0.0634,
      "step": 4861
    },
    {
      "epoch": 0.28840906394590105,
      "grad_norm": 0.01797221601009369,
      "learning_rate": 1.5813340363828104e-05,
      "loss": 0.0004,
      "step": 4862
    },
    {
      "epoch": 0.28846838296357813,
      "grad_norm": 19.719772338867188,
      "learning_rate": 1.581202214605853e-05,
      "loss": 0.4027,
      "step": 4863
    },
    {
      "epoch": 0.2885277019812552,
      "grad_norm": 0.794969916343689,
      "learning_rate": 1.5810703928288956e-05,
      "loss": 0.008,
      "step": 4864
    },
    {
      "epoch": 0.28858702099893224,
      "grad_norm": 3.769437313079834,
      "learning_rate": 1.580938571051938e-05,
      "loss": 0.0859,
      "step": 4865
    },
    {
      "epoch": 0.2886463400166093,
      "grad_norm": 5.552491188049316,
      "learning_rate": 1.5808067492749804e-05,
      "loss": 0.0666,
      "step": 4866
    },
    {
      "epoch": 0.2887056590342864,
      "grad_norm": 1.766614317893982,
      "learning_rate": 1.580674927498023e-05,
      "loss": 0.0342,
      "step": 4867
    },
    {
      "epoch": 0.28876497805196344,
      "grad_norm": 0.1075458750128746,
      "learning_rate": 1.5805431057210653e-05,
      "loss": 0.0025,
      "step": 4868
    },
    {
      "epoch": 0.2888242970696405,
      "grad_norm": 2.77120041847229,
      "learning_rate": 1.580411283944108e-05,
      "loss": 0.0285,
      "step": 4869
    },
    {
      "epoch": 0.2888836160873176,
      "grad_norm": 14.220904350280762,
      "learning_rate": 1.58027946216715e-05,
      "loss": 0.0547,
      "step": 4870
    },
    {
      "epoch": 0.28894293510499464,
      "grad_norm": 0.011786586605012417,
      "learning_rate": 1.5801476403901927e-05,
      "loss": 0.0004,
      "step": 4871
    },
    {
      "epoch": 0.2890022541226717,
      "grad_norm": 0.604883074760437,
      "learning_rate": 1.580015818613235e-05,
      "loss": 0.0052,
      "step": 4872
    },
    {
      "epoch": 0.2890615731403488,
      "grad_norm": 13.730013847351074,
      "learning_rate": 1.5798839968362775e-05,
      "loss": 0.2018,
      "step": 4873
    },
    {
      "epoch": 0.2891208921580259,
      "grad_norm": 0.06870592385530472,
      "learning_rate": 1.5797521750593198e-05,
      "loss": 0.0019,
      "step": 4874
    },
    {
      "epoch": 0.2891802111757029,
      "grad_norm": 11.04275131225586,
      "learning_rate": 1.5796203532823624e-05,
      "loss": 0.2224,
      "step": 4875
    },
    {
      "epoch": 0.28923953019338,
      "grad_norm": 0.0943232849240303,
      "learning_rate": 1.579488531505405e-05,
      "loss": 0.001,
      "step": 4876
    },
    {
      "epoch": 0.2892988492110571,
      "grad_norm": 4.547469615936279,
      "learning_rate": 1.5793567097284472e-05,
      "loss": 0.0511,
      "step": 4877
    },
    {
      "epoch": 0.2893581682287341,
      "grad_norm": 23.518945693969727,
      "learning_rate": 1.5792248879514898e-05,
      "loss": 0.2033,
      "step": 4878
    },
    {
      "epoch": 0.2894174872464112,
      "grad_norm": 0.04240482673048973,
      "learning_rate": 1.579093066174532e-05,
      "loss": 0.0006,
      "step": 4879
    },
    {
      "epoch": 0.2894768062640883,
      "grad_norm": 0.2894969582557678,
      "learning_rate": 1.5789612443975746e-05,
      "loss": 0.0038,
      "step": 4880
    },
    {
      "epoch": 0.2895361252817653,
      "grad_norm": 0.4487518072128296,
      "learning_rate": 1.5788294226206172e-05,
      "loss": 0.0052,
      "step": 4881
    },
    {
      "epoch": 0.2895954442994424,
      "grad_norm": 17.695491790771484,
      "learning_rate": 1.5786976008436595e-05,
      "loss": 0.093,
      "step": 4882
    },
    {
      "epoch": 0.2896547633171195,
      "grad_norm": 31.846769332885742,
      "learning_rate": 1.578565779066702e-05,
      "loss": 1.2691,
      "step": 4883
    },
    {
      "epoch": 0.28971408233479656,
      "grad_norm": 7.08672571182251,
      "learning_rate": 1.5784339572897443e-05,
      "loss": 0.1527,
      "step": 4884
    },
    {
      "epoch": 0.2897734013524736,
      "grad_norm": 0.7189409136772156,
      "learning_rate": 1.578302135512787e-05,
      "loss": 0.0142,
      "step": 4885
    },
    {
      "epoch": 0.2898327203701507,
      "grad_norm": 27.610788345336914,
      "learning_rate": 1.578170313735829e-05,
      "loss": 0.5317,
      "step": 4886
    },
    {
      "epoch": 0.28989203938782776,
      "grad_norm": 2.1247732639312744,
      "learning_rate": 1.5780384919588717e-05,
      "loss": 0.021,
      "step": 4887
    },
    {
      "epoch": 0.2899513584055048,
      "grad_norm": 0.007767799776047468,
      "learning_rate": 1.577906670181914e-05,
      "loss": 0.0003,
      "step": 4888
    },
    {
      "epoch": 0.2900106774231819,
      "grad_norm": 14.666783332824707,
      "learning_rate": 1.5777748484049566e-05,
      "loss": 0.1657,
      "step": 4889
    },
    {
      "epoch": 0.29006999644085896,
      "grad_norm": 0.5811651349067688,
      "learning_rate": 1.577643026627999e-05,
      "loss": 0.0074,
      "step": 4890
    },
    {
      "epoch": 0.290129315458536,
      "grad_norm": 34.125267028808594,
      "learning_rate": 1.5775112048510414e-05,
      "loss": 0.2256,
      "step": 4891
    },
    {
      "epoch": 0.29018863447621307,
      "grad_norm": 0.19531656801700592,
      "learning_rate": 1.577379383074084e-05,
      "loss": 0.0019,
      "step": 4892
    },
    {
      "epoch": 0.29024795349389015,
      "grad_norm": 1.7496592998504639,
      "learning_rate": 1.5772475612971262e-05,
      "loss": 0.0171,
      "step": 4893
    },
    {
      "epoch": 0.2903072725115672,
      "grad_norm": 9.21706485748291,
      "learning_rate": 1.5771157395201688e-05,
      "loss": 0.1804,
      "step": 4894
    },
    {
      "epoch": 0.29036659152924427,
      "grad_norm": 2.46771240234375,
      "learning_rate": 1.5769839177432114e-05,
      "loss": 0.0818,
      "step": 4895
    },
    {
      "epoch": 0.29042591054692135,
      "grad_norm": 6.270474433898926,
      "learning_rate": 1.5768520959662537e-05,
      "loss": 0.2281,
      "step": 4896
    },
    {
      "epoch": 0.29048522956459844,
      "grad_norm": 14.839192390441895,
      "learning_rate": 1.5767202741892963e-05,
      "loss": 0.3542,
      "step": 4897
    },
    {
      "epoch": 0.29054454858227546,
      "grad_norm": 0.037498608231544495,
      "learning_rate": 1.576588452412339e-05,
      "loss": 0.0006,
      "step": 4898
    },
    {
      "epoch": 0.29060386759995255,
      "grad_norm": 5.741519927978516,
      "learning_rate": 1.576456630635381e-05,
      "loss": 0.0451,
      "step": 4899
    },
    {
      "epoch": 0.29066318661762963,
      "grad_norm": 0.0052187759429216385,
      "learning_rate": 1.5763248088584237e-05,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 0.29072250563530666,
      "grad_norm": 0.016749167814850807,
      "learning_rate": 1.576192987081466e-05,
      "loss": 0.0005,
      "step": 4901
    },
    {
      "epoch": 0.29078182465298374,
      "grad_norm": 8.05815601348877,
      "learning_rate": 1.5760611653045085e-05,
      "loss": 0.3282,
      "step": 4902
    },
    {
      "epoch": 0.29084114367066083,
      "grad_norm": 7.104221343994141,
      "learning_rate": 1.5759293435275508e-05,
      "loss": 0.0461,
      "step": 4903
    },
    {
      "epoch": 0.29090046268833786,
      "grad_norm": 3.7071516513824463,
      "learning_rate": 1.5757975217505934e-05,
      "loss": 0.1128,
      "step": 4904
    },
    {
      "epoch": 0.29095978170601494,
      "grad_norm": 0.059310343116521835,
      "learning_rate": 1.5756656999736356e-05,
      "loss": 0.001,
      "step": 4905
    },
    {
      "epoch": 0.291019100723692,
      "grad_norm": 0.7820702791213989,
      "learning_rate": 1.5755338781966782e-05,
      "loss": 0.0041,
      "step": 4906
    },
    {
      "epoch": 0.2910784197413691,
      "grad_norm": 1.2976131439208984,
      "learning_rate": 1.5754020564197208e-05,
      "loss": 0.016,
      "step": 4907
    },
    {
      "epoch": 0.29113773875904614,
      "grad_norm": 0.011151242069900036,
      "learning_rate": 1.575270234642763e-05,
      "loss": 0.0003,
      "step": 4908
    },
    {
      "epoch": 0.2911970577767232,
      "grad_norm": 0.6005200743675232,
      "learning_rate": 1.5751384128658056e-05,
      "loss": 0.0061,
      "step": 4909
    },
    {
      "epoch": 0.2912563767944003,
      "grad_norm": 0.05273125320672989,
      "learning_rate": 1.575006591088848e-05,
      "loss": 0.0012,
      "step": 4910
    },
    {
      "epoch": 0.29131569581207734,
      "grad_norm": 0.4416629672050476,
      "learning_rate": 1.5748747693118905e-05,
      "loss": 0.0051,
      "step": 4911
    },
    {
      "epoch": 0.2913750148297544,
      "grad_norm": 0.01132366992533207,
      "learning_rate": 1.574742947534933e-05,
      "loss": 0.0004,
      "step": 4912
    },
    {
      "epoch": 0.2914343338474315,
      "grad_norm": 22.19622039794922,
      "learning_rate": 1.5746111257579753e-05,
      "loss": 0.7655,
      "step": 4913
    },
    {
      "epoch": 0.29149365286510853,
      "grad_norm": 0.3377777636051178,
      "learning_rate": 1.574479303981018e-05,
      "loss": 0.0052,
      "step": 4914
    },
    {
      "epoch": 0.2915529718827856,
      "grad_norm": 15.876447677612305,
      "learning_rate": 1.5743474822040605e-05,
      "loss": 0.8855,
      "step": 4915
    },
    {
      "epoch": 0.2916122909004627,
      "grad_norm": 0.5208010077476501,
      "learning_rate": 1.5742156604271027e-05,
      "loss": 0.0066,
      "step": 4916
    },
    {
      "epoch": 0.29167160991813973,
      "grad_norm": 18.21941375732422,
      "learning_rate": 1.574083838650145e-05,
      "loss": 1.1993,
      "step": 4917
    },
    {
      "epoch": 0.2917309289358168,
      "grad_norm": 17.6268310546875,
      "learning_rate": 1.5739520168731876e-05,
      "loss": 0.479,
      "step": 4918
    },
    {
      "epoch": 0.2917902479534939,
      "grad_norm": 1.253250002861023,
      "learning_rate": 1.5738201950962298e-05,
      "loss": 0.0188,
      "step": 4919
    },
    {
      "epoch": 0.291849566971171,
      "grad_norm": 0.3706118166446686,
      "learning_rate": 1.5736883733192724e-05,
      "loss": 0.0033,
      "step": 4920
    },
    {
      "epoch": 0.291908885988848,
      "grad_norm": 8.112032890319824,
      "learning_rate": 1.573556551542315e-05,
      "loss": 0.0692,
      "step": 4921
    },
    {
      "epoch": 0.2919682050065251,
      "grad_norm": 33.62228012084961,
      "learning_rate": 1.5734247297653572e-05,
      "loss": 0.6543,
      "step": 4922
    },
    {
      "epoch": 0.2920275240242022,
      "grad_norm": 7.80000114440918,
      "learning_rate": 1.5732929079883998e-05,
      "loss": 0.4115,
      "step": 4923
    },
    {
      "epoch": 0.2920868430418792,
      "grad_norm": 1.8483226299285889,
      "learning_rate": 1.5731610862114424e-05,
      "loss": 0.0134,
      "step": 4924
    },
    {
      "epoch": 0.2921461620595563,
      "grad_norm": 1.418487310409546,
      "learning_rate": 1.5730292644344847e-05,
      "loss": 0.009,
      "step": 4925
    },
    {
      "epoch": 0.2922054810772334,
      "grad_norm": 8.128501892089844,
      "learning_rate": 1.5728974426575272e-05,
      "loss": 0.4007,
      "step": 4926
    },
    {
      "epoch": 0.2922648000949104,
      "grad_norm": 0.11894887685775757,
      "learning_rate": 1.5727656208805695e-05,
      "loss": 0.0016,
      "step": 4927
    },
    {
      "epoch": 0.2923241191125875,
      "grad_norm": 17.29413604736328,
      "learning_rate": 1.572633799103612e-05,
      "loss": 0.5833,
      "step": 4928
    },
    {
      "epoch": 0.2923834381302646,
      "grad_norm": 0.6533821821212769,
      "learning_rate": 1.5725019773266547e-05,
      "loss": 0.0071,
      "step": 4929
    },
    {
      "epoch": 0.29244275714794166,
      "grad_norm": 10.718883514404297,
      "learning_rate": 1.572370155549697e-05,
      "loss": 0.0998,
      "step": 4930
    },
    {
      "epoch": 0.2925020761656187,
      "grad_norm": 0.10373692214488983,
      "learning_rate": 1.5722383337727395e-05,
      "loss": 0.0029,
      "step": 4931
    },
    {
      "epoch": 0.29256139518329577,
      "grad_norm": 0.17352822422981262,
      "learning_rate": 1.5721065119957818e-05,
      "loss": 0.0017,
      "step": 4932
    },
    {
      "epoch": 0.29262071420097285,
      "grad_norm": 10.921184539794922,
      "learning_rate": 1.5719746902188243e-05,
      "loss": 0.2896,
      "step": 4933
    },
    {
      "epoch": 0.2926800332186499,
      "grad_norm": 0.08693120628595352,
      "learning_rate": 1.5718428684418666e-05,
      "loss": 0.0017,
      "step": 4934
    },
    {
      "epoch": 0.29273935223632697,
      "grad_norm": 10.613571166992188,
      "learning_rate": 1.5717110466649092e-05,
      "loss": 0.4295,
      "step": 4935
    },
    {
      "epoch": 0.29279867125400405,
      "grad_norm": 0.04729895666241646,
      "learning_rate": 1.5715792248879514e-05,
      "loss": 0.0009,
      "step": 4936
    },
    {
      "epoch": 0.2928579902716811,
      "grad_norm": 1.81400465965271,
      "learning_rate": 1.571447403110994e-05,
      "loss": 0.0141,
      "step": 4937
    },
    {
      "epoch": 0.29291730928935816,
      "grad_norm": 16.12934112548828,
      "learning_rate": 1.5713155813340366e-05,
      "loss": 1.2525,
      "step": 4938
    },
    {
      "epoch": 0.29297662830703525,
      "grad_norm": 8.510432243347168,
      "learning_rate": 1.571183759557079e-05,
      "loss": 0.2445,
      "step": 4939
    },
    {
      "epoch": 0.2930359473247123,
      "grad_norm": 0.012567082419991493,
      "learning_rate": 1.5710519377801214e-05,
      "loss": 0.0003,
      "step": 4940
    },
    {
      "epoch": 0.29309526634238936,
      "grad_norm": 0.013692142441868782,
      "learning_rate": 1.5709201160031637e-05,
      "loss": 0.0004,
      "step": 4941
    },
    {
      "epoch": 0.29315458536006644,
      "grad_norm": 0.014141997322440147,
      "learning_rate": 1.5707882942262063e-05,
      "loss": 0.0005,
      "step": 4942
    },
    {
      "epoch": 0.29321390437774353,
      "grad_norm": 8.543299674987793,
      "learning_rate": 1.570656472449249e-05,
      "loss": 0.6168,
      "step": 4943
    },
    {
      "epoch": 0.29327322339542056,
      "grad_norm": 0.1668260544538498,
      "learning_rate": 1.570524650672291e-05,
      "loss": 0.0012,
      "step": 4944
    },
    {
      "epoch": 0.29333254241309764,
      "grad_norm": 68.51173400878906,
      "learning_rate": 1.5703928288953337e-05,
      "loss": 1.1169,
      "step": 4945
    },
    {
      "epoch": 0.2933918614307747,
      "grad_norm": 4.410935401916504,
      "learning_rate": 1.5702610071183763e-05,
      "loss": 0.0841,
      "step": 4946
    },
    {
      "epoch": 0.29345118044845175,
      "grad_norm": 0.007504282984882593,
      "learning_rate": 1.5701291853414185e-05,
      "loss": 0.0002,
      "step": 4947
    },
    {
      "epoch": 0.29351049946612884,
      "grad_norm": 1.5165975093841553,
      "learning_rate": 1.569997363564461e-05,
      "loss": 0.0117,
      "step": 4948
    },
    {
      "epoch": 0.2935698184838059,
      "grad_norm": 11.659690856933594,
      "learning_rate": 1.5698655417875034e-05,
      "loss": 0.1343,
      "step": 4949
    },
    {
      "epoch": 0.29362913750148295,
      "grad_norm": 0.008279741741716862,
      "learning_rate": 1.569733720010546e-05,
      "loss": 0.0002,
      "step": 4950
    },
    {
      "epoch": 0.29368845651916003,
      "grad_norm": 8.427337646484375,
      "learning_rate": 1.5696018982335882e-05,
      "loss": 0.0373,
      "step": 4951
    },
    {
      "epoch": 0.2937477755368371,
      "grad_norm": 0.33633744716644287,
      "learning_rate": 1.5694700764566308e-05,
      "loss": 0.004,
      "step": 4952
    },
    {
      "epoch": 0.2938070945545142,
      "grad_norm": 11.128159523010254,
      "learning_rate": 1.569338254679673e-05,
      "loss": 0.25,
      "step": 4953
    },
    {
      "epoch": 0.29386641357219123,
      "grad_norm": 1.6349780559539795,
      "learning_rate": 1.5692064329027156e-05,
      "loss": 0.0156,
      "step": 4954
    },
    {
      "epoch": 0.2939257325898683,
      "grad_norm": 10.451346397399902,
      "learning_rate": 1.5690746111257582e-05,
      "loss": 0.1154,
      "step": 4955
    },
    {
      "epoch": 0.2939850516075454,
      "grad_norm": 0.833875298500061,
      "learning_rate": 1.5689427893488005e-05,
      "loss": 0.0127,
      "step": 4956
    },
    {
      "epoch": 0.29404437062522243,
      "grad_norm": 0.5912002921104431,
      "learning_rate": 1.568810967571843e-05,
      "loss": 0.0028,
      "step": 4957
    },
    {
      "epoch": 0.2941036896428995,
      "grad_norm": 2.0036044120788574,
      "learning_rate": 1.5686791457948853e-05,
      "loss": 0.014,
      "step": 4958
    },
    {
      "epoch": 0.2941630086605766,
      "grad_norm": 6.974843502044678,
      "learning_rate": 1.568547324017928e-05,
      "loss": 0.0794,
      "step": 4959
    },
    {
      "epoch": 0.2942223276782536,
      "grad_norm": 0.01335096638649702,
      "learning_rate": 1.5684155022409705e-05,
      "loss": 0.0006,
      "step": 4960
    },
    {
      "epoch": 0.2942816466959307,
      "grad_norm": 0.004621319938451052,
      "learning_rate": 1.5682836804640127e-05,
      "loss": 0.0002,
      "step": 4961
    },
    {
      "epoch": 0.2943409657136078,
      "grad_norm": 12.575557708740234,
      "learning_rate": 1.5681518586870553e-05,
      "loss": 0.1902,
      "step": 4962
    },
    {
      "epoch": 0.2944002847312848,
      "grad_norm": 23.501306533813477,
      "learning_rate": 1.5680200369100976e-05,
      "loss": 0.8124,
      "step": 4963
    },
    {
      "epoch": 0.2944596037489619,
      "grad_norm": 5.583080768585205,
      "learning_rate": 1.5678882151331402e-05,
      "loss": 0.0857,
      "step": 4964
    },
    {
      "epoch": 0.294518922766639,
      "grad_norm": 4.194756031036377,
      "learning_rate": 1.5677563933561824e-05,
      "loss": 0.028,
      "step": 4965
    },
    {
      "epoch": 0.2945782417843161,
      "grad_norm": 14.916963577270508,
      "learning_rate": 1.567624571579225e-05,
      "loss": 0.5373,
      "step": 4966
    },
    {
      "epoch": 0.2946375608019931,
      "grad_norm": 50.30683517456055,
      "learning_rate": 1.5674927498022673e-05,
      "loss": 1.1201,
      "step": 4967
    },
    {
      "epoch": 0.2946968798196702,
      "grad_norm": 0.013901839964091778,
      "learning_rate": 1.56736092802531e-05,
      "loss": 0.0004,
      "step": 4968
    },
    {
      "epoch": 0.29475619883734727,
      "grad_norm": 1.1166744232177734,
      "learning_rate": 1.5672291062483524e-05,
      "loss": 0.0049,
      "step": 4969
    },
    {
      "epoch": 0.2948155178550243,
      "grad_norm": 6.514810562133789,
      "learning_rate": 1.5670972844713947e-05,
      "loss": 0.4554,
      "step": 4970
    },
    {
      "epoch": 0.2948748368727014,
      "grad_norm": 0.03800661116838455,
      "learning_rate": 1.5669654626944373e-05,
      "loss": 0.0007,
      "step": 4971
    },
    {
      "epoch": 0.29493415589037847,
      "grad_norm": 9.56355094909668,
      "learning_rate": 1.56683364091748e-05,
      "loss": 0.1306,
      "step": 4972
    },
    {
      "epoch": 0.2949934749080555,
      "grad_norm": 1.5881167650222778,
      "learning_rate": 1.566701819140522e-05,
      "loss": 0.0182,
      "step": 4973
    },
    {
      "epoch": 0.2950527939257326,
      "grad_norm": 2.1663978099823,
      "learning_rate": 1.5665699973635647e-05,
      "loss": 0.0461,
      "step": 4974
    },
    {
      "epoch": 0.29511211294340967,
      "grad_norm": 0.01313847303390503,
      "learning_rate": 1.566438175586607e-05,
      "loss": 0.0004,
      "step": 4975
    },
    {
      "epoch": 0.29517143196108675,
      "grad_norm": 8.381510734558105,
      "learning_rate": 1.5663063538096495e-05,
      "loss": 0.0609,
      "step": 4976
    },
    {
      "epoch": 0.2952307509787638,
      "grad_norm": 0.00828653946518898,
      "learning_rate": 1.566174532032692e-05,
      "loss": 0.0003,
      "step": 4977
    },
    {
      "epoch": 0.29529006999644086,
      "grad_norm": 11.709206581115723,
      "learning_rate": 1.5660427102557344e-05,
      "loss": 0.3107,
      "step": 4978
    },
    {
      "epoch": 0.29534938901411795,
      "grad_norm": 2.684208393096924,
      "learning_rate": 1.565910888478777e-05,
      "loss": 0.0266,
      "step": 4979
    },
    {
      "epoch": 0.295408708031795,
      "grad_norm": 0.012259063310921192,
      "learning_rate": 1.5657790667018192e-05,
      "loss": 0.0002,
      "step": 4980
    },
    {
      "epoch": 0.29546802704947206,
      "grad_norm": 10.37540340423584,
      "learning_rate": 1.5656472449248618e-05,
      "loss": 0.1771,
      "step": 4981
    },
    {
      "epoch": 0.29552734606714914,
      "grad_norm": 29.102764129638672,
      "learning_rate": 1.565515423147904e-05,
      "loss": 0.355,
      "step": 4982
    },
    {
      "epoch": 0.2955866650848262,
      "grad_norm": 10.244378089904785,
      "learning_rate": 1.5653836013709466e-05,
      "loss": 0.921,
      "step": 4983
    },
    {
      "epoch": 0.29564598410250326,
      "grad_norm": 0.013231282122433186,
      "learning_rate": 1.565251779593989e-05,
      "loss": 0.0004,
      "step": 4984
    },
    {
      "epoch": 0.29570530312018034,
      "grad_norm": 0.8502051830291748,
      "learning_rate": 1.5651199578170315e-05,
      "loss": 0.0172,
      "step": 4985
    },
    {
      "epoch": 0.2957646221378574,
      "grad_norm": 0.005071363411843777,
      "learning_rate": 1.564988136040074e-05,
      "loss": 0.0002,
      "step": 4986
    },
    {
      "epoch": 0.29582394115553445,
      "grad_norm": 8.017648696899414,
      "learning_rate": 1.5648563142631163e-05,
      "loss": 0.2517,
      "step": 4987
    },
    {
      "epoch": 0.29588326017321154,
      "grad_norm": 7.554989337921143,
      "learning_rate": 1.564724492486159e-05,
      "loss": 0.0952,
      "step": 4988
    },
    {
      "epoch": 0.2959425791908886,
      "grad_norm": 0.10914067924022675,
      "learning_rate": 1.564592670709201e-05,
      "loss": 0.0014,
      "step": 4989
    },
    {
      "epoch": 0.29600189820856565,
      "grad_norm": 0.03939572721719742,
      "learning_rate": 1.5644608489322437e-05,
      "loss": 0.0009,
      "step": 4990
    },
    {
      "epoch": 0.29606121722624273,
      "grad_norm": 7.46597146987915,
      "learning_rate": 1.5643290271552863e-05,
      "loss": 0.0613,
      "step": 4991
    },
    {
      "epoch": 0.2961205362439198,
      "grad_norm": 1.3987343311309814,
      "learning_rate": 1.5641972053783286e-05,
      "loss": 0.0166,
      "step": 4992
    },
    {
      "epoch": 0.29617985526159685,
      "grad_norm": 0.011096159927546978,
      "learning_rate": 1.564065383601371e-05,
      "loss": 0.0005,
      "step": 4993
    },
    {
      "epoch": 0.29623917427927393,
      "grad_norm": 3.2770535945892334,
      "learning_rate": 1.5639335618244138e-05,
      "loss": 0.0211,
      "step": 4994
    },
    {
      "epoch": 0.296298493296951,
      "grad_norm": 0.8504665493965149,
      "learning_rate": 1.563801740047456e-05,
      "loss": 0.0082,
      "step": 4995
    },
    {
      "epoch": 0.29635781231462804,
      "grad_norm": 0.0150825884193182,
      "learning_rate": 1.5636699182704982e-05,
      "loss": 0.0006,
      "step": 4996
    },
    {
      "epoch": 0.29641713133230513,
      "grad_norm": 0.7262645363807678,
      "learning_rate": 1.563538096493541e-05,
      "loss": 0.0058,
      "step": 4997
    },
    {
      "epoch": 0.2964764503499822,
      "grad_norm": 10.897930145263672,
      "learning_rate": 1.563406274716583e-05,
      "loss": 0.1207,
      "step": 4998
    },
    {
      "epoch": 0.2965357693676593,
      "grad_norm": 3.4464309215545654,
      "learning_rate": 1.5632744529396257e-05,
      "loss": 0.1294,
      "step": 4999
    },
    {
      "epoch": 0.2965950883853363,
      "grad_norm": 0.018199695274233818,
      "learning_rate": 1.5631426311626683e-05,
      "loss": 0.0004,
      "step": 5000
    },
    {
      "epoch": 0.2966544074030134,
      "grad_norm": 0.060507893562316895,
      "learning_rate": 1.5630108093857105e-05,
      "loss": 0.0009,
      "step": 5001
    },
    {
      "epoch": 0.2967137264206905,
      "grad_norm": 0.02701917663216591,
      "learning_rate": 1.562878987608753e-05,
      "loss": 0.0007,
      "step": 5002
    },
    {
      "epoch": 0.2967730454383675,
      "grad_norm": 0.08205629140138626,
      "learning_rate": 1.5627471658317957e-05,
      "loss": 0.0012,
      "step": 5003
    },
    {
      "epoch": 0.2968323644560446,
      "grad_norm": 5.434902191162109,
      "learning_rate": 1.562615344054838e-05,
      "loss": 0.2241,
      "step": 5004
    },
    {
      "epoch": 0.2968916834737217,
      "grad_norm": 19.54429054260254,
      "learning_rate": 1.5624835222778805e-05,
      "loss": 1.4102,
      "step": 5005
    },
    {
      "epoch": 0.2969510024913987,
      "grad_norm": 8.001581192016602,
      "learning_rate": 1.5623517005009228e-05,
      "loss": 0.0559,
      "step": 5006
    },
    {
      "epoch": 0.2970103215090758,
      "grad_norm": 22.146141052246094,
      "learning_rate": 1.5622198787239654e-05,
      "loss": 0.7093,
      "step": 5007
    },
    {
      "epoch": 0.2970696405267529,
      "grad_norm": 9.530308723449707,
      "learning_rate": 1.562088056947008e-05,
      "loss": 0.1298,
      "step": 5008
    },
    {
      "epoch": 0.29712895954442997,
      "grad_norm": 0.28500622510910034,
      "learning_rate": 1.5619562351700502e-05,
      "loss": 0.0072,
      "step": 5009
    },
    {
      "epoch": 0.297188278562107,
      "grad_norm": 0.21289163827896118,
      "learning_rate": 1.5618244133930928e-05,
      "loss": 0.0028,
      "step": 5010
    },
    {
      "epoch": 0.2972475975797841,
      "grad_norm": 0.07244372367858887,
      "learning_rate": 1.561692591616135e-05,
      "loss": 0.0014,
      "step": 5011
    },
    {
      "epoch": 0.29730691659746117,
      "grad_norm": 0.08824808150529861,
      "learning_rate": 1.5615607698391776e-05,
      "loss": 0.002,
      "step": 5012
    },
    {
      "epoch": 0.2973662356151382,
      "grad_norm": 6.92667818069458,
      "learning_rate": 1.56142894806222e-05,
      "loss": 0.2289,
      "step": 5013
    },
    {
      "epoch": 0.2974255546328153,
      "grad_norm": 1.4683781862258911,
      "learning_rate": 1.5612971262852625e-05,
      "loss": 0.0155,
      "step": 5014
    },
    {
      "epoch": 0.29748487365049237,
      "grad_norm": 9.250787734985352,
      "learning_rate": 1.5611653045083047e-05,
      "loss": 0.1002,
      "step": 5015
    },
    {
      "epoch": 0.2975441926681694,
      "grad_norm": 4.5433173179626465,
      "learning_rate": 1.5610334827313473e-05,
      "loss": 0.0439,
      "step": 5016
    },
    {
      "epoch": 0.2976035116858465,
      "grad_norm": 10.574006080627441,
      "learning_rate": 1.56090166095439e-05,
      "loss": 0.4803,
      "step": 5017
    },
    {
      "epoch": 0.29766283070352356,
      "grad_norm": 0.24348480999469757,
      "learning_rate": 1.560769839177432e-05,
      "loss": 0.0036,
      "step": 5018
    },
    {
      "epoch": 0.2977221497212006,
      "grad_norm": 5.4161057472229,
      "learning_rate": 1.5606380174004747e-05,
      "loss": 0.1374,
      "step": 5019
    },
    {
      "epoch": 0.2977814687388777,
      "grad_norm": 10.784029960632324,
      "learning_rate": 1.5605061956235173e-05,
      "loss": 1.9323,
      "step": 5020
    },
    {
      "epoch": 0.29784078775655476,
      "grad_norm": 2.631444215774536,
      "learning_rate": 1.5603743738465596e-05,
      "loss": 0.0314,
      "step": 5021
    },
    {
      "epoch": 0.29790010677423184,
      "grad_norm": 21.884401321411133,
      "learning_rate": 1.560242552069602e-05,
      "loss": 0.5986,
      "step": 5022
    },
    {
      "epoch": 0.29795942579190887,
      "grad_norm": 8.865447044372559,
      "learning_rate": 1.5601107302926444e-05,
      "loss": 0.1734,
      "step": 5023
    },
    {
      "epoch": 0.29801874480958596,
      "grad_norm": 16.525524139404297,
      "learning_rate": 1.559978908515687e-05,
      "loss": 0.1214,
      "step": 5024
    },
    {
      "epoch": 0.29807806382726304,
      "grad_norm": 8.140007019042969,
      "learning_rate": 1.5598470867387296e-05,
      "loss": 0.4633,
      "step": 5025
    },
    {
      "epoch": 0.29813738284494007,
      "grad_norm": 2.5056142807006836,
      "learning_rate": 1.5597152649617718e-05,
      "loss": 0.0229,
      "step": 5026
    },
    {
      "epoch": 0.29819670186261715,
      "grad_norm": 0.057465244084596634,
      "learning_rate": 1.5595834431848144e-05,
      "loss": 0.0009,
      "step": 5027
    },
    {
      "epoch": 0.29825602088029424,
      "grad_norm": 33.371177673339844,
      "learning_rate": 1.5594516214078567e-05,
      "loss": 0.1903,
      "step": 5028
    },
    {
      "epoch": 0.29831533989797127,
      "grad_norm": 3.418642997741699,
      "learning_rate": 1.559319799630899e-05,
      "loss": 0.0428,
      "step": 5029
    },
    {
      "epoch": 0.29837465891564835,
      "grad_norm": 0.9124374389648438,
      "learning_rate": 1.5591879778539415e-05,
      "loss": 0.0052,
      "step": 5030
    },
    {
      "epoch": 0.29843397793332543,
      "grad_norm": 0.782762348651886,
      "learning_rate": 1.559056156076984e-05,
      "loss": 0.0076,
      "step": 5031
    },
    {
      "epoch": 0.2984932969510025,
      "grad_norm": 11.296476364135742,
      "learning_rate": 1.5589243343000263e-05,
      "loss": 0.4988,
      "step": 5032
    },
    {
      "epoch": 0.29855261596867955,
      "grad_norm": 0.05083303153514862,
      "learning_rate": 1.558792512523069e-05,
      "loss": 0.001,
      "step": 5033
    },
    {
      "epoch": 0.29861193498635663,
      "grad_norm": 6.12900972366333,
      "learning_rate": 1.5586606907461115e-05,
      "loss": 0.0768,
      "step": 5034
    },
    {
      "epoch": 0.2986712540040337,
      "grad_norm": 0.17921854555606842,
      "learning_rate": 1.5585288689691538e-05,
      "loss": 0.0022,
      "step": 5035
    },
    {
      "epoch": 0.29873057302171074,
      "grad_norm": 8.348118782043457,
      "learning_rate": 1.5583970471921964e-05,
      "loss": 1.0141,
      "step": 5036
    },
    {
      "epoch": 0.2987898920393878,
      "grad_norm": 8.569145202636719,
      "learning_rate": 1.558265225415239e-05,
      "loss": 0.128,
      "step": 5037
    },
    {
      "epoch": 0.2988492110570649,
      "grad_norm": 0.3130240738391876,
      "learning_rate": 1.5581334036382812e-05,
      "loss": 0.0038,
      "step": 5038
    },
    {
      "epoch": 0.29890853007474194,
      "grad_norm": 0.09338583797216415,
      "learning_rate": 1.5580015818613238e-05,
      "loss": 0.0012,
      "step": 5039
    },
    {
      "epoch": 0.298967849092419,
      "grad_norm": 0.022140460088849068,
      "learning_rate": 1.557869760084366e-05,
      "loss": 0.0005,
      "step": 5040
    },
    {
      "epoch": 0.2990271681100961,
      "grad_norm": 5.748372554779053,
      "learning_rate": 1.5577379383074086e-05,
      "loss": 0.4263,
      "step": 5041
    },
    {
      "epoch": 0.29908648712777314,
      "grad_norm": 11.17000675201416,
      "learning_rate": 1.557606116530451e-05,
      "loss": 0.5411,
      "step": 5042
    },
    {
      "epoch": 0.2991458061454502,
      "grad_norm": 3.9519829750061035,
      "learning_rate": 1.5574742947534935e-05,
      "loss": 0.0224,
      "step": 5043
    },
    {
      "epoch": 0.2992051251631273,
      "grad_norm": 0.11292898654937744,
      "learning_rate": 1.5573424729765357e-05,
      "loss": 0.0012,
      "step": 5044
    },
    {
      "epoch": 0.2992644441808044,
      "grad_norm": 18.607675552368164,
      "learning_rate": 1.5572106511995783e-05,
      "loss": 1.2982,
      "step": 5045
    },
    {
      "epoch": 0.2993237631984814,
      "grad_norm": 5.740334510803223,
      "learning_rate": 1.5570788294226205e-05,
      "loss": 0.3963,
      "step": 5046
    },
    {
      "epoch": 0.2993830822161585,
      "grad_norm": 0.5206903219223022,
      "learning_rate": 1.556947007645663e-05,
      "loss": 0.0061,
      "step": 5047
    },
    {
      "epoch": 0.2994424012338356,
      "grad_norm": 0.043312717229127884,
      "learning_rate": 1.5568151858687057e-05,
      "loss": 0.0012,
      "step": 5048
    },
    {
      "epoch": 0.2995017202515126,
      "grad_norm": 4.368993282318115,
      "learning_rate": 1.556683364091748e-05,
      "loss": 0.0166,
      "step": 5049
    },
    {
      "epoch": 0.2995610392691897,
      "grad_norm": 3.738006353378296,
      "learning_rate": 1.5565515423147906e-05,
      "loss": 0.0381,
      "step": 5050
    },
    {
      "epoch": 0.2996203582868668,
      "grad_norm": 0.024921568110585213,
      "learning_rate": 1.556419720537833e-05,
      "loss": 0.0006,
      "step": 5051
    },
    {
      "epoch": 0.2996796773045438,
      "grad_norm": 0.8838091492652893,
      "learning_rate": 1.5562878987608754e-05,
      "loss": 0.0133,
      "step": 5052
    },
    {
      "epoch": 0.2997389963222209,
      "grad_norm": 1.6973997354507446,
      "learning_rate": 1.556156076983918e-05,
      "loss": 0.0202,
      "step": 5053
    },
    {
      "epoch": 0.299798315339898,
      "grad_norm": 0.037026990205049515,
      "learning_rate": 1.5560242552069602e-05,
      "loss": 0.001,
      "step": 5054
    },
    {
      "epoch": 0.29985763435757506,
      "grad_norm": 1.0594375133514404,
      "learning_rate": 1.5558924334300028e-05,
      "loss": 0.0152,
      "step": 5055
    },
    {
      "epoch": 0.2999169533752521,
      "grad_norm": 7.2710652351379395,
      "learning_rate": 1.5557606116530454e-05,
      "loss": 0.0282,
      "step": 5056
    },
    {
      "epoch": 0.2999762723929292,
      "grad_norm": 9.740195274353027,
      "learning_rate": 1.5556287898760877e-05,
      "loss": 0.3694,
      "step": 5057
    },
    {
      "epoch": 0.30003559141060626,
      "grad_norm": 0.8613906502723694,
      "learning_rate": 1.5554969680991302e-05,
      "loss": 0.0091,
      "step": 5058
    },
    {
      "epoch": 0.3000949104282833,
      "grad_norm": 0.08286219835281372,
      "learning_rate": 1.5553651463221725e-05,
      "loss": 0.0015,
      "step": 5059
    },
    {
      "epoch": 0.3001542294459604,
      "grad_norm": 0.03927573189139366,
      "learning_rate": 1.555233324545215e-05,
      "loss": 0.0009,
      "step": 5060
    },
    {
      "epoch": 0.30021354846363746,
      "grad_norm": 12.979174613952637,
      "learning_rate": 1.5551015027682573e-05,
      "loss": 0.129,
      "step": 5061
    },
    {
      "epoch": 0.3002728674813145,
      "grad_norm": 0.5246259570121765,
      "learning_rate": 1.5549696809913e-05,
      "loss": 0.0042,
      "step": 5062
    },
    {
      "epoch": 0.30033218649899157,
      "grad_norm": 0.333732008934021,
      "learning_rate": 1.554837859214342e-05,
      "loss": 0.0071,
      "step": 5063
    },
    {
      "epoch": 0.30039150551666866,
      "grad_norm": 0.02741074189543724,
      "learning_rate": 1.5547060374373848e-05,
      "loss": 0.001,
      "step": 5064
    },
    {
      "epoch": 0.3004508245343457,
      "grad_norm": 1.4107493162155151,
      "learning_rate": 1.5545742156604273e-05,
      "loss": 0.025,
      "step": 5065
    },
    {
      "epoch": 0.30051014355202277,
      "grad_norm": 0.2759539484977722,
      "learning_rate": 1.5544423938834696e-05,
      "loss": 0.0034,
      "step": 5066
    },
    {
      "epoch": 0.30056946256969985,
      "grad_norm": 1.8219057321548462,
      "learning_rate": 1.5543105721065122e-05,
      "loss": 0.0058,
      "step": 5067
    },
    {
      "epoch": 0.30062878158737694,
      "grad_norm": 0.14875070750713348,
      "learning_rate": 1.5541787503295548e-05,
      "loss": 0.0037,
      "step": 5068
    },
    {
      "epoch": 0.30068810060505397,
      "grad_norm": 3.35976243019104,
      "learning_rate": 1.554046928552597e-05,
      "loss": 0.0587,
      "step": 5069
    },
    {
      "epoch": 0.30074741962273105,
      "grad_norm": 0.06679779291152954,
      "learning_rate": 1.5539151067756396e-05,
      "loss": 0.0016,
      "step": 5070
    },
    {
      "epoch": 0.30080673864040813,
      "grad_norm": 0.13839638233184814,
      "learning_rate": 1.553783284998682e-05,
      "loss": 0.0024,
      "step": 5071
    },
    {
      "epoch": 0.30086605765808516,
      "grad_norm": 4.792566299438477,
      "learning_rate": 1.5536514632217244e-05,
      "loss": 0.0264,
      "step": 5072
    },
    {
      "epoch": 0.30092537667576225,
      "grad_norm": 0.28121909499168396,
      "learning_rate": 1.5535196414447667e-05,
      "loss": 0.0037,
      "step": 5073
    },
    {
      "epoch": 0.30098469569343933,
      "grad_norm": 35.043914794921875,
      "learning_rate": 1.5533878196678093e-05,
      "loss": 0.4587,
      "step": 5074
    },
    {
      "epoch": 0.30104401471111636,
      "grad_norm": 3.7451632022857666,
      "learning_rate": 1.5532559978908515e-05,
      "loss": 0.0539,
      "step": 5075
    },
    {
      "epoch": 0.30110333372879344,
      "grad_norm": 1.828342080116272,
      "learning_rate": 1.553124176113894e-05,
      "loss": 0.021,
      "step": 5076
    },
    {
      "epoch": 0.3011626527464705,
      "grad_norm": 3.663148880004883,
      "learning_rate": 1.5529923543369364e-05,
      "loss": 0.0562,
      "step": 5077
    },
    {
      "epoch": 0.3012219717641476,
      "grad_norm": 0.3647172152996063,
      "learning_rate": 1.552860532559979e-05,
      "loss": 0.004,
      "step": 5078
    },
    {
      "epoch": 0.30128129078182464,
      "grad_norm": 2.5248377323150635,
      "learning_rate": 1.5527287107830215e-05,
      "loss": 0.0208,
      "step": 5079
    },
    {
      "epoch": 0.3013406097995017,
      "grad_norm": 0.02508419007062912,
      "learning_rate": 1.5525968890060638e-05,
      "loss": 0.0008,
      "step": 5080
    },
    {
      "epoch": 0.3013999288171788,
      "grad_norm": 3.2633512020111084,
      "learning_rate": 1.5524650672291064e-05,
      "loss": 0.0444,
      "step": 5081
    },
    {
      "epoch": 0.30145924783485584,
      "grad_norm": 0.4332200586795807,
      "learning_rate": 1.552333245452149e-05,
      "loss": 0.0052,
      "step": 5082
    },
    {
      "epoch": 0.3015185668525329,
      "grad_norm": 0.17551298439502716,
      "learning_rate": 1.5522014236751912e-05,
      "loss": 0.0032,
      "step": 5083
    },
    {
      "epoch": 0.30157788587021,
      "grad_norm": 1.8065874576568604,
      "learning_rate": 1.5520696018982338e-05,
      "loss": 0.0182,
      "step": 5084
    },
    {
      "epoch": 0.30163720488788703,
      "grad_norm": 3.454090118408203,
      "learning_rate": 1.5519377801212764e-05,
      "loss": 0.0716,
      "step": 5085
    },
    {
      "epoch": 0.3016965239055641,
      "grad_norm": 1.2764437198638916,
      "learning_rate": 1.5518059583443186e-05,
      "loss": 0.0166,
      "step": 5086
    },
    {
      "epoch": 0.3017558429232412,
      "grad_norm": 15.098254203796387,
      "learning_rate": 1.5516741365673612e-05,
      "loss": 0.7666,
      "step": 5087
    },
    {
      "epoch": 0.30181516194091823,
      "grad_norm": 3.9708335399627686,
      "learning_rate": 1.5515423147904035e-05,
      "loss": 0.0358,
      "step": 5088
    },
    {
      "epoch": 0.3018744809585953,
      "grad_norm": 0.14203055202960968,
      "learning_rate": 1.551410493013446e-05,
      "loss": 0.0022,
      "step": 5089
    },
    {
      "epoch": 0.3019337999762724,
      "grad_norm": 0.20196454226970673,
      "learning_rate": 1.5512786712364883e-05,
      "loss": 0.0024,
      "step": 5090
    },
    {
      "epoch": 0.3019931189939495,
      "grad_norm": 0.5956060290336609,
      "learning_rate": 1.551146849459531e-05,
      "loss": 0.0045,
      "step": 5091
    },
    {
      "epoch": 0.3020524380116265,
      "grad_norm": 0.5042324066162109,
      "learning_rate": 1.551015027682573e-05,
      "loss": 0.004,
      "step": 5092
    },
    {
      "epoch": 0.3021117570293036,
      "grad_norm": 2.4297895431518555,
      "learning_rate": 1.5508832059056157e-05,
      "loss": 0.0597,
      "step": 5093
    },
    {
      "epoch": 0.3021710760469807,
      "grad_norm": 0.2272440642118454,
      "learning_rate": 1.550751384128658e-05,
      "loss": 0.0029,
      "step": 5094
    },
    {
      "epoch": 0.3022303950646577,
      "grad_norm": 1.9767168760299683,
      "learning_rate": 1.5506195623517006e-05,
      "loss": 0.0226,
      "step": 5095
    },
    {
      "epoch": 0.3022897140823348,
      "grad_norm": 0.07863752543926239,
      "learning_rate": 1.550487740574743e-05,
      "loss": 0.0012,
      "step": 5096
    },
    {
      "epoch": 0.3023490331000119,
      "grad_norm": 0.3181582987308502,
      "learning_rate": 1.5503559187977854e-05,
      "loss": 0.0033,
      "step": 5097
    },
    {
      "epoch": 0.3024083521176889,
      "grad_norm": 0.5280295610427856,
      "learning_rate": 1.550224097020828e-05,
      "loss": 0.0059,
      "step": 5098
    },
    {
      "epoch": 0.302467671135366,
      "grad_norm": 0.04653806611895561,
      "learning_rate": 1.5500922752438706e-05,
      "loss": 0.0008,
      "step": 5099
    },
    {
      "epoch": 0.3025269901530431,
      "grad_norm": 52.04468536376953,
      "learning_rate": 1.549960453466913e-05,
      "loss": 0.6421,
      "step": 5100
    },
    {
      "epoch": 0.30258630917072016,
      "grad_norm": 3.6394286155700684,
      "learning_rate": 1.5498286316899554e-05,
      "loss": 0.0711,
      "step": 5101
    },
    {
      "epoch": 0.3026456281883972,
      "grad_norm": 1.1294268369674683,
      "learning_rate": 1.5496968099129977e-05,
      "loss": 0.0109,
      "step": 5102
    },
    {
      "epoch": 0.30270494720607427,
      "grad_norm": 12.255218505859375,
      "learning_rate": 1.5495649881360403e-05,
      "loss": 0.2846,
      "step": 5103
    },
    {
      "epoch": 0.30276426622375135,
      "grad_norm": 0.3797721266746521,
      "learning_rate": 1.549433166359083e-05,
      "loss": 0.0048,
      "step": 5104
    },
    {
      "epoch": 0.3028235852414284,
      "grad_norm": 2.978757858276367,
      "learning_rate": 1.549301344582125e-05,
      "loss": 0.0681,
      "step": 5105
    },
    {
      "epoch": 0.30288290425910547,
      "grad_norm": 3.0211379528045654,
      "learning_rate": 1.5491695228051674e-05,
      "loss": 0.0261,
      "step": 5106
    },
    {
      "epoch": 0.30294222327678255,
      "grad_norm": 6.4582438468933105,
      "learning_rate": 1.54903770102821e-05,
      "loss": 0.0346,
      "step": 5107
    },
    {
      "epoch": 0.3030015422944596,
      "grad_norm": 0.2410644292831421,
      "learning_rate": 1.5489058792512522e-05,
      "loss": 0.0025,
      "step": 5108
    },
    {
      "epoch": 0.30306086131213666,
      "grad_norm": 1.661285400390625,
      "learning_rate": 1.5487740574742948e-05,
      "loss": 0.0074,
      "step": 5109
    },
    {
      "epoch": 0.30312018032981375,
      "grad_norm": 0.18094293773174286,
      "learning_rate": 1.5486422356973374e-05,
      "loss": 0.001,
      "step": 5110
    },
    {
      "epoch": 0.30317949934749083,
      "grad_norm": 5.79213285446167,
      "learning_rate": 1.5485104139203796e-05,
      "loss": 0.1329,
      "step": 5111
    },
    {
      "epoch": 0.30323881836516786,
      "grad_norm": 1.954042673110962,
      "learning_rate": 1.5483785921434222e-05,
      "loss": 0.0272,
      "step": 5112
    },
    {
      "epoch": 0.30329813738284495,
      "grad_norm": 0.014551139436662197,
      "learning_rate": 1.5482467703664648e-05,
      "loss": 0.0004,
      "step": 5113
    },
    {
      "epoch": 0.30335745640052203,
      "grad_norm": 3.784050226211548,
      "learning_rate": 1.548114948589507e-05,
      "loss": 0.0534,
      "step": 5114
    },
    {
      "epoch": 0.30341677541819906,
      "grad_norm": 0.6544271111488342,
      "learning_rate": 1.5479831268125496e-05,
      "loss": 0.0088,
      "step": 5115
    },
    {
      "epoch": 0.30347609443587614,
      "grad_norm": 0.10273732244968414,
      "learning_rate": 1.5478513050355922e-05,
      "loss": 0.0015,
      "step": 5116
    },
    {
      "epoch": 0.3035354134535532,
      "grad_norm": 6.110193252563477,
      "learning_rate": 1.5477194832586345e-05,
      "loss": 0.1241,
      "step": 5117
    },
    {
      "epoch": 0.30359473247123026,
      "grad_norm": 4.6592254638671875,
      "learning_rate": 1.547587661481677e-05,
      "loss": 0.0114,
      "step": 5118
    },
    {
      "epoch": 0.30365405148890734,
      "grad_norm": 0.02189287357032299,
      "learning_rate": 1.5474558397047193e-05,
      "loss": 0.0007,
      "step": 5119
    },
    {
      "epoch": 0.3037133705065844,
      "grad_norm": 2.026337146759033,
      "learning_rate": 1.547324017927762e-05,
      "loss": 0.0212,
      "step": 5120
    },
    {
      "epoch": 0.30377268952426145,
      "grad_norm": 0.005446252413094044,
      "learning_rate": 1.547192196150804e-05,
      "loss": 0.0003,
      "step": 5121
    },
    {
      "epoch": 0.30383200854193854,
      "grad_norm": 22.660551071166992,
      "learning_rate": 1.5470603743738467e-05,
      "loss": 0.4963,
      "step": 5122
    },
    {
      "epoch": 0.3038913275596156,
      "grad_norm": 0.03049321286380291,
      "learning_rate": 1.546928552596889e-05,
      "loss": 0.0006,
      "step": 5123
    },
    {
      "epoch": 0.3039506465772927,
      "grad_norm": 10.08256721496582,
      "learning_rate": 1.5467967308199316e-05,
      "loss": 0.4542,
      "step": 5124
    },
    {
      "epoch": 0.30400996559496973,
      "grad_norm": 0.013037814758718014,
      "learning_rate": 1.5466649090429738e-05,
      "loss": 0.0004,
      "step": 5125
    },
    {
      "epoch": 0.3040692846126468,
      "grad_norm": 0.07759882509708405,
      "learning_rate": 1.5465330872660164e-05,
      "loss": 0.0009,
      "step": 5126
    },
    {
      "epoch": 0.3041286036303239,
      "grad_norm": 32.075965881347656,
      "learning_rate": 1.546401265489059e-05,
      "loss": 0.2757,
      "step": 5127
    },
    {
      "epoch": 0.30418792264800093,
      "grad_norm": 13.495994567871094,
      "learning_rate": 1.5462694437121012e-05,
      "loss": 0.3143,
      "step": 5128
    },
    {
      "epoch": 0.304247241665678,
      "grad_norm": 14.28884506225586,
      "learning_rate": 1.546137621935144e-05,
      "loss": 0.5697,
      "step": 5129
    },
    {
      "epoch": 0.3043065606833551,
      "grad_norm": 5.851222038269043,
      "learning_rate": 1.5460058001581864e-05,
      "loss": 0.2336,
      "step": 5130
    },
    {
      "epoch": 0.3043658797010321,
      "grad_norm": 22.4630126953125,
      "learning_rate": 1.5458739783812287e-05,
      "loss": 0.2211,
      "step": 5131
    },
    {
      "epoch": 0.3044251987187092,
      "grad_norm": 17.283950805664062,
      "learning_rate": 1.5457421566042713e-05,
      "loss": 0.2431,
      "step": 5132
    },
    {
      "epoch": 0.3044845177363863,
      "grad_norm": 10.577632904052734,
      "learning_rate": 1.545610334827314e-05,
      "loss": 0.296,
      "step": 5133
    },
    {
      "epoch": 0.3045438367540634,
      "grad_norm": 2.899730682373047,
      "learning_rate": 1.545478513050356e-05,
      "loss": 0.0225,
      "step": 5134
    },
    {
      "epoch": 0.3046031557717404,
      "grad_norm": 0.06773281842470169,
      "learning_rate": 1.5453466912733987e-05,
      "loss": 0.0025,
      "step": 5135
    },
    {
      "epoch": 0.3046624747894175,
      "grad_norm": 0.01082391943782568,
      "learning_rate": 1.545214869496441e-05,
      "loss": 0.0003,
      "step": 5136
    },
    {
      "epoch": 0.3047217938070946,
      "grad_norm": 0.15862631797790527,
      "learning_rate": 1.5450830477194835e-05,
      "loss": 0.0025,
      "step": 5137
    },
    {
      "epoch": 0.3047811128247716,
      "grad_norm": 3.8918659687042236,
      "learning_rate": 1.5449512259425258e-05,
      "loss": 0.0556,
      "step": 5138
    },
    {
      "epoch": 0.3048404318424487,
      "grad_norm": 5.793599605560303,
      "learning_rate": 1.5448194041655684e-05,
      "loss": 0.0543,
      "step": 5139
    },
    {
      "epoch": 0.3048997508601258,
      "grad_norm": 0.850732684135437,
      "learning_rate": 1.5446875823886106e-05,
      "loss": 0.0072,
      "step": 5140
    },
    {
      "epoch": 0.3049590698778028,
      "grad_norm": 0.2413691133260727,
      "learning_rate": 1.5445557606116532e-05,
      "loss": 0.002,
      "step": 5141
    },
    {
      "epoch": 0.3050183888954799,
      "grad_norm": 8.721833229064941,
      "learning_rate": 1.5444239388346954e-05,
      "loss": 0.1678,
      "step": 5142
    },
    {
      "epoch": 0.30507770791315697,
      "grad_norm": 12.9591646194458,
      "learning_rate": 1.544292117057738e-05,
      "loss": 0.1288,
      "step": 5143
    },
    {
      "epoch": 0.305137026930834,
      "grad_norm": 0.027646850794553757,
      "learning_rate": 1.5441602952807806e-05,
      "loss": 0.0006,
      "step": 5144
    },
    {
      "epoch": 0.3051963459485111,
      "grad_norm": 13.49374008178711,
      "learning_rate": 1.544028473503823e-05,
      "loss": 0.6607,
      "step": 5145
    },
    {
      "epoch": 0.30525566496618817,
      "grad_norm": 0.030239244922995567,
      "learning_rate": 1.5438966517268655e-05,
      "loss": 0.0008,
      "step": 5146
    },
    {
      "epoch": 0.30531498398386525,
      "grad_norm": 22.30635643005371,
      "learning_rate": 1.543764829949908e-05,
      "loss": 1.2521,
      "step": 5147
    },
    {
      "epoch": 0.3053743030015423,
      "grad_norm": 7.828218936920166,
      "learning_rate": 1.5436330081729503e-05,
      "loss": 0.1702,
      "step": 5148
    },
    {
      "epoch": 0.30543362201921936,
      "grad_norm": 0.08168186992406845,
      "learning_rate": 1.543501186395993e-05,
      "loss": 0.001,
      "step": 5149
    },
    {
      "epoch": 0.30549294103689645,
      "grad_norm": 3.8627965450286865,
      "learning_rate": 1.543369364619035e-05,
      "loss": 0.0584,
      "step": 5150
    },
    {
      "epoch": 0.3055522600545735,
      "grad_norm": 1.2040940523147583,
      "learning_rate": 1.5432375428420777e-05,
      "loss": 0.0103,
      "step": 5151
    },
    {
      "epoch": 0.30561157907225056,
      "grad_norm": 0.06761083751916885,
      "learning_rate": 1.54310572106512e-05,
      "loss": 0.0004,
      "step": 5152
    },
    {
      "epoch": 0.30567089808992765,
      "grad_norm": 0.09637123346328735,
      "learning_rate": 1.5429738992881626e-05,
      "loss": 0.0017,
      "step": 5153
    },
    {
      "epoch": 0.3057302171076047,
      "grad_norm": 4.3591766357421875,
      "learning_rate": 1.5428420775112048e-05,
      "loss": 0.1694,
      "step": 5154
    },
    {
      "epoch": 0.30578953612528176,
      "grad_norm": 0.06151719391345978,
      "learning_rate": 1.5427102557342474e-05,
      "loss": 0.0014,
      "step": 5155
    },
    {
      "epoch": 0.30584885514295884,
      "grad_norm": 0.013321153819561005,
      "learning_rate": 1.5425784339572896e-05,
      "loss": 0.0003,
      "step": 5156
    },
    {
      "epoch": 0.3059081741606359,
      "grad_norm": 5.649471759796143,
      "learning_rate": 1.5424466121803322e-05,
      "loss": 0.1896,
      "step": 5157
    },
    {
      "epoch": 0.30596749317831295,
      "grad_norm": 0.045348990708589554,
      "learning_rate": 1.5423147904033748e-05,
      "loss": 0.0007,
      "step": 5158
    },
    {
      "epoch": 0.30602681219599004,
      "grad_norm": 0.01824209839105606,
      "learning_rate": 1.542182968626417e-05,
      "loss": 0.0006,
      "step": 5159
    },
    {
      "epoch": 0.3060861312136671,
      "grad_norm": 31.418607711791992,
      "learning_rate": 1.5420511468494597e-05,
      "loss": 0.1643,
      "step": 5160
    },
    {
      "epoch": 0.30614545023134415,
      "grad_norm": 26.943527221679688,
      "learning_rate": 1.5419193250725022e-05,
      "loss": 0.3931,
      "step": 5161
    },
    {
      "epoch": 0.30620476924902124,
      "grad_norm": 0.585583508014679,
      "learning_rate": 1.5417875032955445e-05,
      "loss": 0.0055,
      "step": 5162
    },
    {
      "epoch": 0.3062640882666983,
      "grad_norm": 28.378890991210938,
      "learning_rate": 1.541655681518587e-05,
      "loss": 0.2788,
      "step": 5163
    },
    {
      "epoch": 0.30632340728437535,
      "grad_norm": 2.358090400695801,
      "learning_rate": 1.5415238597416297e-05,
      "loss": 0.0268,
      "step": 5164
    },
    {
      "epoch": 0.30638272630205243,
      "grad_norm": 0.0703963041305542,
      "learning_rate": 1.541392037964672e-05,
      "loss": 0.0012,
      "step": 5165
    },
    {
      "epoch": 0.3064420453197295,
      "grad_norm": 14.101966857910156,
      "learning_rate": 1.5412602161877145e-05,
      "loss": 0.6444,
      "step": 5166
    },
    {
      "epoch": 0.30650136433740655,
      "grad_norm": 0.00780390715226531,
      "learning_rate": 1.5411283944107568e-05,
      "loss": 0.0002,
      "step": 5167
    },
    {
      "epoch": 0.30656068335508363,
      "grad_norm": 0.1495792418718338,
      "learning_rate": 1.5409965726337993e-05,
      "loss": 0.0007,
      "step": 5168
    },
    {
      "epoch": 0.3066200023727607,
      "grad_norm": 1.4680359363555908,
      "learning_rate": 1.5408647508568416e-05,
      "loss": 0.0225,
      "step": 5169
    },
    {
      "epoch": 0.3066793213904378,
      "grad_norm": 1.316716194152832,
      "learning_rate": 1.5407329290798842e-05,
      "loss": 0.0224,
      "step": 5170
    },
    {
      "epoch": 0.3067386404081148,
      "grad_norm": 0.6941515803337097,
      "learning_rate": 1.5406011073029264e-05,
      "loss": 0.0051,
      "step": 5171
    },
    {
      "epoch": 0.3067979594257919,
      "grad_norm": 4.827106475830078,
      "learning_rate": 1.540469285525969e-05,
      "loss": 0.0198,
      "step": 5172
    },
    {
      "epoch": 0.306857278443469,
      "grad_norm": 16.955520629882812,
      "learning_rate": 1.5403374637490113e-05,
      "loss": 0.7092,
      "step": 5173
    },
    {
      "epoch": 0.306916597461146,
      "grad_norm": 0.7370877861976624,
      "learning_rate": 1.540205641972054e-05,
      "loss": 0.0058,
      "step": 5174
    },
    {
      "epoch": 0.3069759164788231,
      "grad_norm": 19.65455436706543,
      "learning_rate": 1.5400738201950964e-05,
      "loss": 1.4726,
      "step": 5175
    },
    {
      "epoch": 0.3070352354965002,
      "grad_norm": 0.3529494106769562,
      "learning_rate": 1.5399419984181387e-05,
      "loss": 0.0043,
      "step": 5176
    },
    {
      "epoch": 0.3070945545141772,
      "grad_norm": 5.655972480773926,
      "learning_rate": 1.5398101766411813e-05,
      "loss": 0.1101,
      "step": 5177
    },
    {
      "epoch": 0.3071538735318543,
      "grad_norm": 0.09994164109230042,
      "learning_rate": 1.539678354864224e-05,
      "loss": 0.0026,
      "step": 5178
    },
    {
      "epoch": 0.3072131925495314,
      "grad_norm": 1.3983196020126343,
      "learning_rate": 1.539546533087266e-05,
      "loss": 0.0142,
      "step": 5179
    },
    {
      "epoch": 0.3072725115672085,
      "grad_norm": 34.288299560546875,
      "learning_rate": 1.5394147113103087e-05,
      "loss": 1.0337,
      "step": 5180
    },
    {
      "epoch": 0.3073318305848855,
      "grad_norm": 5.7385759353637695,
      "learning_rate": 1.5392828895333513e-05,
      "loss": 1.028,
      "step": 5181
    },
    {
      "epoch": 0.3073911496025626,
      "grad_norm": 0.034139879047870636,
      "learning_rate": 1.5391510677563935e-05,
      "loss": 0.0004,
      "step": 5182
    },
    {
      "epoch": 0.30745046862023967,
      "grad_norm": 7.402897357940674,
      "learning_rate": 1.539019245979436e-05,
      "loss": 0.0442,
      "step": 5183
    },
    {
      "epoch": 0.3075097876379167,
      "grad_norm": 5.012925624847412,
      "learning_rate": 1.5388874242024784e-05,
      "loss": 0.1146,
      "step": 5184
    },
    {
      "epoch": 0.3075691066555938,
      "grad_norm": 0.8732568025588989,
      "learning_rate": 1.5387556024255206e-05,
      "loss": 0.0063,
      "step": 5185
    },
    {
      "epoch": 0.30762842567327087,
      "grad_norm": 4.509578227996826,
      "learning_rate": 1.5386237806485632e-05,
      "loss": 0.0431,
      "step": 5186
    },
    {
      "epoch": 0.3076877446909479,
      "grad_norm": 26.010610580444336,
      "learning_rate": 1.5384919588716055e-05,
      "loss": 1.0665,
      "step": 5187
    },
    {
      "epoch": 0.307747063708625,
      "grad_norm": 21.246826171875,
      "learning_rate": 1.538360137094648e-05,
      "loss": 0.4403,
      "step": 5188
    },
    {
      "epoch": 0.30780638272630206,
      "grad_norm": 10.60641098022461,
      "learning_rate": 1.5382283153176907e-05,
      "loss": 0.2201,
      "step": 5189
    },
    {
      "epoch": 0.3078657017439791,
      "grad_norm": 0.37056317925453186,
      "learning_rate": 1.538096493540733e-05,
      "loss": 0.0039,
      "step": 5190
    },
    {
      "epoch": 0.3079250207616562,
      "grad_norm": 0.8243504762649536,
      "learning_rate": 1.5379646717637755e-05,
      "loss": 0.0057,
      "step": 5191
    },
    {
      "epoch": 0.30798433977933326,
      "grad_norm": 8.66611385345459,
      "learning_rate": 1.537832849986818e-05,
      "loss": 0.0636,
      "step": 5192
    },
    {
      "epoch": 0.30804365879701034,
      "grad_norm": 0.4497702121734619,
      "learning_rate": 1.5377010282098603e-05,
      "loss": 0.0044,
      "step": 5193
    },
    {
      "epoch": 0.3081029778146874,
      "grad_norm": 7.254580020904541,
      "learning_rate": 1.537569206432903e-05,
      "loss": 0.3177,
      "step": 5194
    },
    {
      "epoch": 0.30816229683236446,
      "grad_norm": 0.22777172923088074,
      "learning_rate": 1.5374373846559455e-05,
      "loss": 0.0029,
      "step": 5195
    },
    {
      "epoch": 0.30822161585004154,
      "grad_norm": 0.03113139234483242,
      "learning_rate": 1.5373055628789878e-05,
      "loss": 0.0005,
      "step": 5196
    },
    {
      "epoch": 0.30828093486771857,
      "grad_norm": 16.094131469726562,
      "learning_rate": 1.5371737411020303e-05,
      "loss": 0.5058,
      "step": 5197
    },
    {
      "epoch": 0.30834025388539565,
      "grad_norm": 0.11324260383844376,
      "learning_rate": 1.5370419193250726e-05,
      "loss": 0.001,
      "step": 5198
    },
    {
      "epoch": 0.30839957290307274,
      "grad_norm": 17.916412353515625,
      "learning_rate": 1.5369100975481152e-05,
      "loss": 1.7644,
      "step": 5199
    },
    {
      "epoch": 0.30845889192074977,
      "grad_norm": 9.995442390441895,
      "learning_rate": 1.5367782757711574e-05,
      "loss": 0.3237,
      "step": 5200
    },
    {
      "epoch": 0.30851821093842685,
      "grad_norm": 5.8727569580078125,
      "learning_rate": 1.5366464539942e-05,
      "loss": 0.045,
      "step": 5201
    },
    {
      "epoch": 0.30857752995610394,
      "grad_norm": 0.5453356504440308,
      "learning_rate": 1.5365146322172423e-05,
      "loss": 0.0054,
      "step": 5202
    },
    {
      "epoch": 0.308636848973781,
      "grad_norm": 3.127908229827881,
      "learning_rate": 1.536382810440285e-05,
      "loss": 0.0142,
      "step": 5203
    },
    {
      "epoch": 0.30869616799145805,
      "grad_norm": 8.736238479614258,
      "learning_rate": 1.536250988663327e-05,
      "loss": 0.1055,
      "step": 5204
    },
    {
      "epoch": 0.30875548700913513,
      "grad_norm": 8.522591590881348,
      "learning_rate": 1.5361191668863697e-05,
      "loss": 0.8159,
      "step": 5205
    },
    {
      "epoch": 0.3088148060268122,
      "grad_norm": 3.304957151412964,
      "learning_rate": 1.5359873451094123e-05,
      "loss": 0.0693,
      "step": 5206
    },
    {
      "epoch": 0.30887412504448924,
      "grad_norm": 0.1158524602651596,
      "learning_rate": 1.5358555233324545e-05,
      "loss": 0.0021,
      "step": 5207
    },
    {
      "epoch": 0.30893344406216633,
      "grad_norm": 16.021728515625,
      "learning_rate": 1.535723701555497e-05,
      "loss": 0.5216,
      "step": 5208
    },
    {
      "epoch": 0.3089927630798434,
      "grad_norm": 4.9313130378723145,
      "learning_rate": 1.5355918797785397e-05,
      "loss": 0.0279,
      "step": 5209
    },
    {
      "epoch": 0.30905208209752044,
      "grad_norm": 2.8812358379364014,
      "learning_rate": 1.535460058001582e-05,
      "loss": 0.0544,
      "step": 5210
    },
    {
      "epoch": 0.3091114011151975,
      "grad_norm": 1.3451354503631592,
      "learning_rate": 1.5353282362246245e-05,
      "loss": 0.0112,
      "step": 5211
    },
    {
      "epoch": 0.3091707201328746,
      "grad_norm": 2.1874330043792725,
      "learning_rate": 1.535196414447667e-05,
      "loss": 0.0275,
      "step": 5212
    },
    {
      "epoch": 0.3092300391505517,
      "grad_norm": 7.157107830047607,
      "learning_rate": 1.5350645926707094e-05,
      "loss": 0.0404,
      "step": 5213
    },
    {
      "epoch": 0.3092893581682287,
      "grad_norm": 30.690425872802734,
      "learning_rate": 1.534932770893752e-05,
      "loss": 2.8456,
      "step": 5214
    },
    {
      "epoch": 0.3093486771859058,
      "grad_norm": 4.136112689971924,
      "learning_rate": 1.5348009491167942e-05,
      "loss": 0.1725,
      "step": 5215
    },
    {
      "epoch": 0.3094079962035829,
      "grad_norm": 0.043194398283958435,
      "learning_rate": 1.5346691273398368e-05,
      "loss": 0.0012,
      "step": 5216
    },
    {
      "epoch": 0.3094673152212599,
      "grad_norm": 6.608060836791992,
      "learning_rate": 1.534537305562879e-05,
      "loss": 0.4501,
      "step": 5217
    },
    {
      "epoch": 0.309526634238937,
      "grad_norm": 4.3862786293029785,
      "learning_rate": 1.5344054837859213e-05,
      "loss": 0.0342,
      "step": 5218
    },
    {
      "epoch": 0.3095859532566141,
      "grad_norm": 4.981308937072754,
      "learning_rate": 1.534273662008964e-05,
      "loss": 0.1072,
      "step": 5219
    },
    {
      "epoch": 0.3096452722742911,
      "grad_norm": 0.18783919513225555,
      "learning_rate": 1.5341418402320065e-05,
      "loss": 0.0024,
      "step": 5220
    },
    {
      "epoch": 0.3097045912919682,
      "grad_norm": 2.195175886154175,
      "learning_rate": 1.5340100184550487e-05,
      "loss": 0.2019,
      "step": 5221
    },
    {
      "epoch": 0.3097639103096453,
      "grad_norm": 0.007999330759048462,
      "learning_rate": 1.5338781966780913e-05,
      "loss": 0.0003,
      "step": 5222
    },
    {
      "epoch": 0.3098232293273223,
      "grad_norm": 0.19715456664562225,
      "learning_rate": 1.533746374901134e-05,
      "loss": 0.0024,
      "step": 5223
    },
    {
      "epoch": 0.3098825483449994,
      "grad_norm": 1.5079104900360107,
      "learning_rate": 1.533614553124176e-05,
      "loss": 0.0105,
      "step": 5224
    },
    {
      "epoch": 0.3099418673626765,
      "grad_norm": 0.06946516036987305,
      "learning_rate": 1.5334827313472187e-05,
      "loss": 0.0013,
      "step": 5225
    },
    {
      "epoch": 0.31000118638035357,
      "grad_norm": 8.984173774719238,
      "learning_rate": 1.5333509095702613e-05,
      "loss": 0.1034,
      "step": 5226
    },
    {
      "epoch": 0.3100605053980306,
      "grad_norm": 17.650653839111328,
      "learning_rate": 1.5332190877933036e-05,
      "loss": 0.1183,
      "step": 5227
    },
    {
      "epoch": 0.3101198244157077,
      "grad_norm": 0.29668572545051575,
      "learning_rate": 1.533087266016346e-05,
      "loss": 0.0031,
      "step": 5228
    },
    {
      "epoch": 0.31017914343338476,
      "grad_norm": 0.0509747639298439,
      "learning_rate": 1.5329554442393884e-05,
      "loss": 0.001,
      "step": 5229
    },
    {
      "epoch": 0.3102384624510618,
      "grad_norm": 0.10458706319332123,
      "learning_rate": 1.532823622462431e-05,
      "loss": 0.0014,
      "step": 5230
    },
    {
      "epoch": 0.3102977814687389,
      "grad_norm": 0.05363302677869797,
      "learning_rate": 1.5326918006854733e-05,
      "loss": 0.0011,
      "step": 5231
    },
    {
      "epoch": 0.31035710048641596,
      "grad_norm": 0.05793830379843712,
      "learning_rate": 1.532559978908516e-05,
      "loss": 0.001,
      "step": 5232
    },
    {
      "epoch": 0.310416419504093,
      "grad_norm": 0.14417921006679535,
      "learning_rate": 1.532428157131558e-05,
      "loss": 0.0028,
      "step": 5233
    },
    {
      "epoch": 0.3104757385217701,
      "grad_norm": 0.01584288477897644,
      "learning_rate": 1.5322963353546007e-05,
      "loss": 0.0004,
      "step": 5234
    },
    {
      "epoch": 0.31053505753944716,
      "grad_norm": 0.07960416376590729,
      "learning_rate": 1.532164513577643e-05,
      "loss": 0.0009,
      "step": 5235
    },
    {
      "epoch": 0.31059437655712424,
      "grad_norm": 21.430448532104492,
      "learning_rate": 1.5320326918006855e-05,
      "loss": 0.8401,
      "step": 5236
    },
    {
      "epoch": 0.31065369557480127,
      "grad_norm": 8.437764167785645,
      "learning_rate": 1.531900870023728e-05,
      "loss": 0.1254,
      "step": 5237
    },
    {
      "epoch": 0.31071301459247835,
      "grad_norm": 0.9221854209899902,
      "learning_rate": 1.5317690482467704e-05,
      "loss": 0.0114,
      "step": 5238
    },
    {
      "epoch": 0.31077233361015544,
      "grad_norm": 8.428306579589844,
      "learning_rate": 1.531637226469813e-05,
      "loss": 0.2169,
      "step": 5239
    },
    {
      "epoch": 0.31083165262783247,
      "grad_norm": 1.8706896305084229,
      "learning_rate": 1.5315054046928555e-05,
      "loss": 0.0221,
      "step": 5240
    },
    {
      "epoch": 0.31089097164550955,
      "grad_norm": 1.4917556047439575,
      "learning_rate": 1.5313735829158978e-05,
      "loss": 0.033,
      "step": 5241
    },
    {
      "epoch": 0.31095029066318663,
      "grad_norm": 7.7584004402160645,
      "learning_rate": 1.5312417611389404e-05,
      "loss": 0.3137,
      "step": 5242
    },
    {
      "epoch": 0.31100960968086366,
      "grad_norm": 10.038056373596191,
      "learning_rate": 1.531109939361983e-05,
      "loss": 0.6597,
      "step": 5243
    },
    {
      "epoch": 0.31106892869854075,
      "grad_norm": 17.91121482849121,
      "learning_rate": 1.5309781175850252e-05,
      "loss": 0.3121,
      "step": 5244
    },
    {
      "epoch": 0.31112824771621783,
      "grad_norm": 12.21464729309082,
      "learning_rate": 1.5308462958080678e-05,
      "loss": 0.3987,
      "step": 5245
    },
    {
      "epoch": 0.31118756673389486,
      "grad_norm": 11.78524398803711,
      "learning_rate": 1.53071447403111e-05,
      "loss": 0.3552,
      "step": 5246
    },
    {
      "epoch": 0.31124688575157194,
      "grad_norm": 0.009683565236628056,
      "learning_rate": 1.5305826522541526e-05,
      "loss": 0.0003,
      "step": 5247
    },
    {
      "epoch": 0.31130620476924903,
      "grad_norm": 7.200201511383057,
      "learning_rate": 1.530450830477195e-05,
      "loss": 0.2274,
      "step": 5248
    },
    {
      "epoch": 0.3113655237869261,
      "grad_norm": 0.27640679478645325,
      "learning_rate": 1.5303190087002375e-05,
      "loss": 0.0035,
      "step": 5249
    },
    {
      "epoch": 0.31142484280460314,
      "grad_norm": 6.432808876037598,
      "learning_rate": 1.5301871869232797e-05,
      "loss": 0.2935,
      "step": 5250
    },
    {
      "epoch": 0.3114841618222802,
      "grad_norm": 0.029056599363684654,
      "learning_rate": 1.5300553651463223e-05,
      "loss": 0.0005,
      "step": 5251
    },
    {
      "epoch": 0.3115434808399573,
      "grad_norm": 29.025615692138672,
      "learning_rate": 1.5299235433693646e-05,
      "loss": 0.1929,
      "step": 5252
    },
    {
      "epoch": 0.31160279985763434,
      "grad_norm": 13.356759071350098,
      "learning_rate": 1.529791721592407e-05,
      "loss": 0.1611,
      "step": 5253
    },
    {
      "epoch": 0.3116621188753114,
      "grad_norm": 4.101633071899414,
      "learning_rate": 1.5296598998154497e-05,
      "loss": 0.2187,
      "step": 5254
    },
    {
      "epoch": 0.3117214378929885,
      "grad_norm": 18.922508239746094,
      "learning_rate": 1.529528078038492e-05,
      "loss": 0.7998,
      "step": 5255
    },
    {
      "epoch": 0.31178075691066554,
      "grad_norm": 0.12148314714431763,
      "learning_rate": 1.5293962562615346e-05,
      "loss": 0.0018,
      "step": 5256
    },
    {
      "epoch": 0.3118400759283426,
      "grad_norm": 4.172266483306885,
      "learning_rate": 1.529264434484577e-05,
      "loss": 0.0283,
      "step": 5257
    },
    {
      "epoch": 0.3118993949460197,
      "grad_norm": 0.059787288308143616,
      "learning_rate": 1.5291326127076194e-05,
      "loss": 0.0018,
      "step": 5258
    },
    {
      "epoch": 0.3119587139636968,
      "grad_norm": 7.559799671173096,
      "learning_rate": 1.529000790930662e-05,
      "loss": 0.6147,
      "step": 5259
    },
    {
      "epoch": 0.3120180329813738,
      "grad_norm": 2.374885082244873,
      "learning_rate": 1.5288689691537046e-05,
      "loss": 0.0262,
      "step": 5260
    },
    {
      "epoch": 0.3120773519990509,
      "grad_norm": 7.935129165649414,
      "learning_rate": 1.5287371473767468e-05,
      "loss": 0.3203,
      "step": 5261
    },
    {
      "epoch": 0.312136671016728,
      "grad_norm": 2.654175281524658,
      "learning_rate": 1.528605325599789e-05,
      "loss": 0.3302,
      "step": 5262
    },
    {
      "epoch": 0.312195990034405,
      "grad_norm": 30.346376419067383,
      "learning_rate": 1.5284735038228317e-05,
      "loss": 2.3842,
      "step": 5263
    },
    {
      "epoch": 0.3122553090520821,
      "grad_norm": 6.8357930183410645,
      "learning_rate": 1.528341682045874e-05,
      "loss": 0.5307,
      "step": 5264
    },
    {
      "epoch": 0.3123146280697592,
      "grad_norm": 14.473040580749512,
      "learning_rate": 1.5282098602689165e-05,
      "loss": 0.8152,
      "step": 5265
    },
    {
      "epoch": 0.3123739470874362,
      "grad_norm": 15.376692771911621,
      "learning_rate": 1.5280780384919588e-05,
      "loss": 0.3459,
      "step": 5266
    },
    {
      "epoch": 0.3124332661051133,
      "grad_norm": 0.8036598563194275,
      "learning_rate": 1.5279462167150013e-05,
      "loss": 0.0104,
      "step": 5267
    },
    {
      "epoch": 0.3124925851227904,
      "grad_norm": 1.5196201801300049,
      "learning_rate": 1.527814394938044e-05,
      "loss": 0.0225,
      "step": 5268
    },
    {
      "epoch": 0.3125519041404674,
      "grad_norm": 70.31987762451172,
      "learning_rate": 1.5276825731610862e-05,
      "loss": 0.545,
      "step": 5269
    },
    {
      "epoch": 0.3126112231581445,
      "grad_norm": 0.11049876362085342,
      "learning_rate": 1.5275507513841288e-05,
      "loss": 0.002,
      "step": 5270
    },
    {
      "epoch": 0.3126705421758216,
      "grad_norm": 0.019617831334471703,
      "learning_rate": 1.5274189296071714e-05,
      "loss": 0.0006,
      "step": 5271
    },
    {
      "epoch": 0.31272986119349866,
      "grad_norm": 29.007946014404297,
      "learning_rate": 1.5272871078302136e-05,
      "loss": 1.2566,
      "step": 5272
    },
    {
      "epoch": 0.3127891802111757,
      "grad_norm": 0.1532442718744278,
      "learning_rate": 1.5271552860532562e-05,
      "loss": 0.0028,
      "step": 5273
    },
    {
      "epoch": 0.31284849922885277,
      "grad_norm": 31.66792869567871,
      "learning_rate": 1.5270234642762988e-05,
      "loss": 1.0326,
      "step": 5274
    },
    {
      "epoch": 0.31290781824652986,
      "grad_norm": 22.17671775817871,
      "learning_rate": 1.526891642499341e-05,
      "loss": 0.6582,
      "step": 5275
    },
    {
      "epoch": 0.3129671372642069,
      "grad_norm": 0.03845783695578575,
      "learning_rate": 1.5267598207223836e-05,
      "loss": 0.0013,
      "step": 5276
    },
    {
      "epoch": 0.31302645628188397,
      "grad_norm": 7.40620231628418,
      "learning_rate": 1.526627998945426e-05,
      "loss": 0.1529,
      "step": 5277
    },
    {
      "epoch": 0.31308577529956105,
      "grad_norm": 5.28870964050293,
      "learning_rate": 1.5264961771684685e-05,
      "loss": 0.1661,
      "step": 5278
    },
    {
      "epoch": 0.3131450943172381,
      "grad_norm": 10.771769523620605,
      "learning_rate": 1.5263643553915107e-05,
      "loss": 0.3425,
      "step": 5279
    },
    {
      "epoch": 0.31320441333491517,
      "grad_norm": 2.386547088623047,
      "learning_rate": 1.5262325336145533e-05,
      "loss": 0.0582,
      "step": 5280
    },
    {
      "epoch": 0.31326373235259225,
      "grad_norm": 0.12765520811080933,
      "learning_rate": 1.5261007118375955e-05,
      "loss": 0.0011,
      "step": 5281
    },
    {
      "epoch": 0.31332305137026933,
      "grad_norm": 0.578295886516571,
      "learning_rate": 1.525968890060638e-05,
      "loss": 0.0068,
      "step": 5282
    },
    {
      "epoch": 0.31338237038794636,
      "grad_norm": 0.07364095747470856,
      "learning_rate": 1.5258370682836805e-05,
      "loss": 0.0015,
      "step": 5283
    },
    {
      "epoch": 0.31344168940562345,
      "grad_norm": 7.171382904052734,
      "learning_rate": 1.525705246506723e-05,
      "loss": 0.1536,
      "step": 5284
    },
    {
      "epoch": 0.31350100842330053,
      "grad_norm": 12.363016128540039,
      "learning_rate": 1.5255734247297656e-05,
      "loss": 0.1562,
      "step": 5285
    },
    {
      "epoch": 0.31356032744097756,
      "grad_norm": 1.0346983671188354,
      "learning_rate": 1.5254416029528078e-05,
      "loss": 0.0173,
      "step": 5286
    },
    {
      "epoch": 0.31361964645865464,
      "grad_norm": 12.648796081542969,
      "learning_rate": 1.5253097811758504e-05,
      "loss": 0.2066,
      "step": 5287
    },
    {
      "epoch": 0.31367896547633173,
      "grad_norm": 11.112588882446289,
      "learning_rate": 1.525177959398893e-05,
      "loss": 0.0771,
      "step": 5288
    },
    {
      "epoch": 0.31373828449400876,
      "grad_norm": 1.7464781999588013,
      "learning_rate": 1.5250461376219352e-05,
      "loss": 0.0061,
      "step": 5289
    },
    {
      "epoch": 0.31379760351168584,
      "grad_norm": 13.128232955932617,
      "learning_rate": 1.5249143158449777e-05,
      "loss": 0.1715,
      "step": 5290
    },
    {
      "epoch": 0.3138569225293629,
      "grad_norm": 2.2005980014801025,
      "learning_rate": 1.5247824940680202e-05,
      "loss": 0.0412,
      "step": 5291
    },
    {
      "epoch": 0.31391624154703995,
      "grad_norm": 9.737650871276855,
      "learning_rate": 1.5246506722910625e-05,
      "loss": 0.156,
      "step": 5292
    },
    {
      "epoch": 0.31397556056471704,
      "grad_norm": 9.479503631591797,
      "learning_rate": 1.524518850514105e-05,
      "loss": 0.2505,
      "step": 5293
    },
    {
      "epoch": 0.3140348795823941,
      "grad_norm": 0.17122937738895416,
      "learning_rate": 1.5243870287371477e-05,
      "loss": 0.0024,
      "step": 5294
    },
    {
      "epoch": 0.3140941986000712,
      "grad_norm": 0.16471843421459198,
      "learning_rate": 1.5242552069601899e-05,
      "loss": 0.0013,
      "step": 5295
    },
    {
      "epoch": 0.31415351761774823,
      "grad_norm": 7.863375663757324,
      "learning_rate": 1.5241233851832325e-05,
      "loss": 0.1452,
      "step": 5296
    },
    {
      "epoch": 0.3142128366354253,
      "grad_norm": 3.8632426261901855,
      "learning_rate": 1.5239915634062748e-05,
      "loss": 0.0121,
      "step": 5297
    },
    {
      "epoch": 0.3142721556531024,
      "grad_norm": 8.165109634399414,
      "learning_rate": 1.5238597416293173e-05,
      "loss": 0.3327,
      "step": 5298
    },
    {
      "epoch": 0.31433147467077943,
      "grad_norm": 7.811634540557861,
      "learning_rate": 1.5237279198523598e-05,
      "loss": 0.0896,
      "step": 5299
    },
    {
      "epoch": 0.3143907936884565,
      "grad_norm": 0.27127641439437866,
      "learning_rate": 1.5235960980754022e-05,
      "loss": 0.005,
      "step": 5300
    },
    {
      "epoch": 0.3144501127061336,
      "grad_norm": 0.2631402611732483,
      "learning_rate": 1.5234642762984446e-05,
      "loss": 0.0041,
      "step": 5301
    },
    {
      "epoch": 0.31450943172381063,
      "grad_norm": 3.068629503250122,
      "learning_rate": 1.5233324545214872e-05,
      "loss": 0.0638,
      "step": 5302
    },
    {
      "epoch": 0.3145687507414877,
      "grad_norm": 0.11785644292831421,
      "learning_rate": 1.5232006327445294e-05,
      "loss": 0.0019,
      "step": 5303
    },
    {
      "epoch": 0.3146280697591648,
      "grad_norm": 11.053035736083984,
      "learning_rate": 1.523068810967572e-05,
      "loss": 0.1538,
      "step": 5304
    },
    {
      "epoch": 0.3146873887768419,
      "grad_norm": 12.343901634216309,
      "learning_rate": 1.5229369891906144e-05,
      "loss": 0.8998,
      "step": 5305
    },
    {
      "epoch": 0.3147467077945189,
      "grad_norm": 21.79526138305664,
      "learning_rate": 1.5228051674136569e-05,
      "loss": 0.8106,
      "step": 5306
    },
    {
      "epoch": 0.314806026812196,
      "grad_norm": 9.421847343444824,
      "learning_rate": 1.5226733456366993e-05,
      "loss": 0.0821,
      "step": 5307
    },
    {
      "epoch": 0.3148653458298731,
      "grad_norm": 0.914169192314148,
      "learning_rate": 1.5225415238597419e-05,
      "loss": 0.0071,
      "step": 5308
    },
    {
      "epoch": 0.3149246648475501,
      "grad_norm": 14.304421424865723,
      "learning_rate": 1.5224097020827841e-05,
      "loss": 0.5905,
      "step": 5309
    },
    {
      "epoch": 0.3149839838652272,
      "grad_norm": 8.570727348327637,
      "learning_rate": 1.5222778803058267e-05,
      "loss": 0.1033,
      "step": 5310
    },
    {
      "epoch": 0.3150433028829043,
      "grad_norm": 1.1386152505874634,
      "learning_rate": 1.522146058528869e-05,
      "loss": 0.0192,
      "step": 5311
    },
    {
      "epoch": 0.3151026219005813,
      "grad_norm": 0.07652458548545837,
      "learning_rate": 1.5220142367519115e-05,
      "loss": 0.0015,
      "step": 5312
    },
    {
      "epoch": 0.3151619409182584,
      "grad_norm": 1.9547345638275146,
      "learning_rate": 1.521882414974954e-05,
      "loss": 0.0174,
      "step": 5313
    },
    {
      "epoch": 0.31522125993593547,
      "grad_norm": 0.14950792491436005,
      "learning_rate": 1.5217505931979964e-05,
      "loss": 0.0025,
      "step": 5314
    },
    {
      "epoch": 0.31528057895361256,
      "grad_norm": 2.7949881553649902,
      "learning_rate": 1.5216187714210388e-05,
      "loss": 0.0264,
      "step": 5315
    },
    {
      "epoch": 0.3153398979712896,
      "grad_norm": 3.3992927074432373,
      "learning_rate": 1.5214869496440814e-05,
      "loss": 0.0652,
      "step": 5316
    },
    {
      "epoch": 0.31539921698896667,
      "grad_norm": 17.983135223388672,
      "learning_rate": 1.5213551278671236e-05,
      "loss": 0.3538,
      "step": 5317
    },
    {
      "epoch": 0.31545853600664375,
      "grad_norm": 0.2759075462818146,
      "learning_rate": 1.5212233060901662e-05,
      "loss": 0.004,
      "step": 5318
    },
    {
      "epoch": 0.3155178550243208,
      "grad_norm": 2.013718605041504,
      "learning_rate": 1.5210914843132088e-05,
      "loss": 0.0195,
      "step": 5319
    },
    {
      "epoch": 0.31557717404199787,
      "grad_norm": 0.10893924534320831,
      "learning_rate": 1.520959662536251e-05,
      "loss": 0.0016,
      "step": 5320
    },
    {
      "epoch": 0.31563649305967495,
      "grad_norm": 11.394209861755371,
      "learning_rate": 1.5208278407592936e-05,
      "loss": 0.1433,
      "step": 5321
    },
    {
      "epoch": 0.315695812077352,
      "grad_norm": 5.690013408660889,
      "learning_rate": 1.520696018982336e-05,
      "loss": 0.275,
      "step": 5322
    },
    {
      "epoch": 0.31575513109502906,
      "grad_norm": 0.762836217880249,
      "learning_rate": 1.5205641972053785e-05,
      "loss": 0.0088,
      "step": 5323
    },
    {
      "epoch": 0.31581445011270615,
      "grad_norm": 37.493568420410156,
      "learning_rate": 1.5204323754284209e-05,
      "loss": 0.5826,
      "step": 5324
    },
    {
      "epoch": 0.3158737691303832,
      "grad_norm": 4.666975498199463,
      "learning_rate": 1.5203005536514635e-05,
      "loss": 0.1233,
      "step": 5325
    },
    {
      "epoch": 0.31593308814806026,
      "grad_norm": 13.82991886138916,
      "learning_rate": 1.5201687318745057e-05,
      "loss": 0.1759,
      "step": 5326
    },
    {
      "epoch": 0.31599240716573734,
      "grad_norm": 0.09623369574546814,
      "learning_rate": 1.5200369100975483e-05,
      "loss": 0.0023,
      "step": 5327
    },
    {
      "epoch": 0.3160517261834144,
      "grad_norm": 20.072784423828125,
      "learning_rate": 1.5199050883205906e-05,
      "loss": 0.5987,
      "step": 5328
    },
    {
      "epoch": 0.31611104520109146,
      "grad_norm": 0.0694253072142601,
      "learning_rate": 1.5197732665436332e-05,
      "loss": 0.0008,
      "step": 5329
    },
    {
      "epoch": 0.31617036421876854,
      "grad_norm": 0.06960160285234451,
      "learning_rate": 1.5196414447666756e-05,
      "loss": 0.0012,
      "step": 5330
    },
    {
      "epoch": 0.3162296832364456,
      "grad_norm": 1.9471396207809448,
      "learning_rate": 1.519509622989718e-05,
      "loss": 0.0112,
      "step": 5331
    },
    {
      "epoch": 0.31628900225412265,
      "grad_norm": 0.5226147174835205,
      "learning_rate": 1.5193778012127604e-05,
      "loss": 0.0063,
      "step": 5332
    },
    {
      "epoch": 0.31634832127179974,
      "grad_norm": 7.259321689605713,
      "learning_rate": 1.519245979435803e-05,
      "loss": 0.1097,
      "step": 5333
    },
    {
      "epoch": 0.3164076402894768,
      "grad_norm": 0.09562145173549652,
      "learning_rate": 1.5191141576588453e-05,
      "loss": 0.0023,
      "step": 5334
    },
    {
      "epoch": 0.31646695930715385,
      "grad_norm": 4.468203544616699,
      "learning_rate": 1.5189823358818878e-05,
      "loss": 0.0839,
      "step": 5335
    },
    {
      "epoch": 0.31652627832483093,
      "grad_norm": 9.144560813903809,
      "learning_rate": 1.5188505141049303e-05,
      "loss": 0.1896,
      "step": 5336
    },
    {
      "epoch": 0.316585597342508,
      "grad_norm": 3.5798285007476807,
      "learning_rate": 1.5187186923279727e-05,
      "loss": 0.0317,
      "step": 5337
    },
    {
      "epoch": 0.3166449163601851,
      "grad_norm": 3.6290504932403564,
      "learning_rate": 1.5185868705510151e-05,
      "loss": 0.1805,
      "step": 5338
    },
    {
      "epoch": 0.31670423537786213,
      "grad_norm": 11.50810432434082,
      "learning_rate": 1.5184550487740577e-05,
      "loss": 0.4969,
      "step": 5339
    },
    {
      "epoch": 0.3167635543955392,
      "grad_norm": 5.905455112457275,
      "learning_rate": 1.5183232269971e-05,
      "loss": 0.1047,
      "step": 5340
    },
    {
      "epoch": 0.3168228734132163,
      "grad_norm": 21.564388275146484,
      "learning_rate": 1.5181914052201425e-05,
      "loss": 0.3869,
      "step": 5341
    },
    {
      "epoch": 0.31688219243089333,
      "grad_norm": 0.036855001002550125,
      "learning_rate": 1.5180595834431851e-05,
      "loss": 0.0008,
      "step": 5342
    },
    {
      "epoch": 0.3169415114485704,
      "grad_norm": 6.695606708526611,
      "learning_rate": 1.5179277616662274e-05,
      "loss": 0.1362,
      "step": 5343
    },
    {
      "epoch": 0.3170008304662475,
      "grad_norm": 3.251992702484131,
      "learning_rate": 1.51779593988927e-05,
      "loss": 0.0185,
      "step": 5344
    },
    {
      "epoch": 0.3170601494839245,
      "grad_norm": 0.2629096806049347,
      "learning_rate": 1.5176641181123122e-05,
      "loss": 0.0025,
      "step": 5345
    },
    {
      "epoch": 0.3171194685016016,
      "grad_norm": 0.22360606491565704,
      "learning_rate": 1.5175322963353546e-05,
      "loss": 0.003,
      "step": 5346
    },
    {
      "epoch": 0.3171787875192787,
      "grad_norm": 1.0686111450195312,
      "learning_rate": 1.5174004745583972e-05,
      "loss": 0.0106,
      "step": 5347
    },
    {
      "epoch": 0.3172381065369557,
      "grad_norm": 32.58787155151367,
      "learning_rate": 1.5172686527814395e-05,
      "loss": 0.4428,
      "step": 5348
    },
    {
      "epoch": 0.3172974255546328,
      "grad_norm": 18.168886184692383,
      "learning_rate": 1.517136831004482e-05,
      "loss": 1.2495,
      "step": 5349
    },
    {
      "epoch": 0.3173567445723099,
      "grad_norm": 2.642739772796631,
      "learning_rate": 1.5170050092275246e-05,
      "loss": 0.111,
      "step": 5350
    },
    {
      "epoch": 0.317416063589987,
      "grad_norm": 0.972683846950531,
      "learning_rate": 1.5168731874505669e-05,
      "loss": 0.0117,
      "step": 5351
    },
    {
      "epoch": 0.317475382607664,
      "grad_norm": 2.987304449081421,
      "learning_rate": 1.5167413656736095e-05,
      "loss": 0.0173,
      "step": 5352
    },
    {
      "epoch": 0.3175347016253411,
      "grad_norm": 1.4780197143554688,
      "learning_rate": 1.5166095438966519e-05,
      "loss": 0.0183,
      "step": 5353
    },
    {
      "epoch": 0.31759402064301817,
      "grad_norm": 21.859434127807617,
      "learning_rate": 1.5164777221196943e-05,
      "loss": 0.1103,
      "step": 5354
    },
    {
      "epoch": 0.3176533396606952,
      "grad_norm": 3.085881471633911,
      "learning_rate": 1.5163459003427367e-05,
      "loss": 0.1871,
      "step": 5355
    },
    {
      "epoch": 0.3177126586783723,
      "grad_norm": 9.76910400390625,
      "learning_rate": 1.5162140785657793e-05,
      "loss": 0.1137,
      "step": 5356
    },
    {
      "epoch": 0.31777197769604937,
      "grad_norm": 12.240263938903809,
      "learning_rate": 1.5160822567888216e-05,
      "loss": 0.2389,
      "step": 5357
    },
    {
      "epoch": 0.3178312967137264,
      "grad_norm": 5.917331218719482,
      "learning_rate": 1.5159504350118642e-05,
      "loss": 0.2486,
      "step": 5358
    },
    {
      "epoch": 0.3178906157314035,
      "grad_norm": 1.4655146598815918,
      "learning_rate": 1.5158186132349064e-05,
      "loss": 0.0118,
      "step": 5359
    },
    {
      "epoch": 0.31794993474908056,
      "grad_norm": 0.16793429851531982,
      "learning_rate": 1.515686791457949e-05,
      "loss": 0.0027,
      "step": 5360
    },
    {
      "epoch": 0.31800925376675765,
      "grad_norm": 16.73647117614746,
      "learning_rate": 1.5155549696809914e-05,
      "loss": 0.1663,
      "step": 5361
    },
    {
      "epoch": 0.3180685727844347,
      "grad_norm": 11.455559730529785,
      "learning_rate": 1.5154231479040338e-05,
      "loss": 1.0703,
      "step": 5362
    },
    {
      "epoch": 0.31812789180211176,
      "grad_norm": 14.167455673217773,
      "learning_rate": 1.5152913261270762e-05,
      "loss": 0.2041,
      "step": 5363
    },
    {
      "epoch": 0.31818721081978885,
      "grad_norm": 0.7518884539604187,
      "learning_rate": 1.5151595043501188e-05,
      "loss": 0.0121,
      "step": 5364
    },
    {
      "epoch": 0.3182465298374659,
      "grad_norm": 2.5727710723876953,
      "learning_rate": 1.5150276825731611e-05,
      "loss": 0.0229,
      "step": 5365
    },
    {
      "epoch": 0.31830584885514296,
      "grad_norm": 0.2144087255001068,
      "learning_rate": 1.5148958607962037e-05,
      "loss": 0.004,
      "step": 5366
    },
    {
      "epoch": 0.31836516787282004,
      "grad_norm": 0.4605317711830139,
      "learning_rate": 1.5147640390192463e-05,
      "loss": 0.0079,
      "step": 5367
    },
    {
      "epoch": 0.31842448689049707,
      "grad_norm": 2.37538743019104,
      "learning_rate": 1.5146322172422885e-05,
      "loss": 0.0395,
      "step": 5368
    },
    {
      "epoch": 0.31848380590817416,
      "grad_norm": 0.24508175253868103,
      "learning_rate": 1.514500395465331e-05,
      "loss": 0.0035,
      "step": 5369
    },
    {
      "epoch": 0.31854312492585124,
      "grad_norm": 12.545343399047852,
      "learning_rate": 1.5143685736883735e-05,
      "loss": 0.1363,
      "step": 5370
    },
    {
      "epoch": 0.31860244394352827,
      "grad_norm": 0.07619805634021759,
      "learning_rate": 1.5142367519114158e-05,
      "loss": 0.0011,
      "step": 5371
    },
    {
      "epoch": 0.31866176296120535,
      "grad_norm": 0.0147359948605299,
      "learning_rate": 1.5141049301344584e-05,
      "loss": 0.0004,
      "step": 5372
    },
    {
      "epoch": 0.31872108197888244,
      "grad_norm": 54.13505172729492,
      "learning_rate": 1.513973108357501e-05,
      "loss": 0.3608,
      "step": 5373
    },
    {
      "epoch": 0.3187804009965595,
      "grad_norm": 10.76458740234375,
      "learning_rate": 1.5138412865805432e-05,
      "loss": 0.127,
      "step": 5374
    },
    {
      "epoch": 0.31883972001423655,
      "grad_norm": 0.021556032821536064,
      "learning_rate": 1.5137094648035858e-05,
      "loss": 0.0009,
      "step": 5375
    },
    {
      "epoch": 0.31889903903191363,
      "grad_norm": 2.6222639083862305,
      "learning_rate": 1.513577643026628e-05,
      "loss": 0.0088,
      "step": 5376
    },
    {
      "epoch": 0.3189583580495907,
      "grad_norm": 1.2526330947875977,
      "learning_rate": 1.5134458212496706e-05,
      "loss": 0.0114,
      "step": 5377
    },
    {
      "epoch": 0.31901767706726775,
      "grad_norm": 11.609041213989258,
      "learning_rate": 1.513313999472713e-05,
      "loss": 0.7227,
      "step": 5378
    },
    {
      "epoch": 0.31907699608494483,
      "grad_norm": 0.009392785839736462,
      "learning_rate": 1.5131821776957555e-05,
      "loss": 0.0003,
      "step": 5379
    },
    {
      "epoch": 0.3191363151026219,
      "grad_norm": 4.796258449554443,
      "learning_rate": 1.5130503559187979e-05,
      "loss": 0.1215,
      "step": 5380
    },
    {
      "epoch": 0.31919563412029894,
      "grad_norm": 3.890845775604248,
      "learning_rate": 1.5129185341418405e-05,
      "loss": 0.0556,
      "step": 5381
    },
    {
      "epoch": 0.319254953137976,
      "grad_norm": 4.319370269775391,
      "learning_rate": 1.5127867123648827e-05,
      "loss": 0.0446,
      "step": 5382
    },
    {
      "epoch": 0.3193142721556531,
      "grad_norm": 0.036113277077674866,
      "learning_rate": 1.5126548905879253e-05,
      "loss": 0.0007,
      "step": 5383
    },
    {
      "epoch": 0.3193735911733302,
      "grad_norm": 0.029183004051446915,
      "learning_rate": 1.5125230688109677e-05,
      "loss": 0.0006,
      "step": 5384
    },
    {
      "epoch": 0.3194329101910072,
      "grad_norm": 18.119569778442383,
      "learning_rate": 1.5123912470340101e-05,
      "loss": 0.2654,
      "step": 5385
    },
    {
      "epoch": 0.3194922292086843,
      "grad_norm": 0.1403466910123825,
      "learning_rate": 1.5122594252570526e-05,
      "loss": 0.0017,
      "step": 5386
    },
    {
      "epoch": 0.3195515482263614,
      "grad_norm": 0.25189462304115295,
      "learning_rate": 1.5121276034800951e-05,
      "loss": 0.0062,
      "step": 5387
    },
    {
      "epoch": 0.3196108672440384,
      "grad_norm": 5.54478120803833,
      "learning_rate": 1.5119957817031374e-05,
      "loss": 0.0212,
      "step": 5388
    },
    {
      "epoch": 0.3196701862617155,
      "grad_norm": 0.1445685625076294,
      "learning_rate": 1.51186395992618e-05,
      "loss": 0.003,
      "step": 5389
    },
    {
      "epoch": 0.3197295052793926,
      "grad_norm": 0.03562045842409134,
      "learning_rate": 1.5117321381492224e-05,
      "loss": 0.0008,
      "step": 5390
    },
    {
      "epoch": 0.3197888242970696,
      "grad_norm": 0.3450753092765808,
      "learning_rate": 1.5116003163722648e-05,
      "loss": 0.004,
      "step": 5391
    },
    {
      "epoch": 0.3198481433147467,
      "grad_norm": 0.10988704860210419,
      "learning_rate": 1.5114684945953072e-05,
      "loss": 0.0022,
      "step": 5392
    },
    {
      "epoch": 0.3199074623324238,
      "grad_norm": 15.79709529876709,
      "learning_rate": 1.5113366728183497e-05,
      "loss": 0.6648,
      "step": 5393
    },
    {
      "epoch": 0.3199667813501008,
      "grad_norm": 0.032919105142354965,
      "learning_rate": 1.511204851041392e-05,
      "loss": 0.0011,
      "step": 5394
    },
    {
      "epoch": 0.3200261003677779,
      "grad_norm": 13.20529842376709,
      "learning_rate": 1.5110730292644347e-05,
      "loss": 0.2152,
      "step": 5395
    },
    {
      "epoch": 0.320085419385455,
      "grad_norm": 0.36029675602912903,
      "learning_rate": 1.5109412074874769e-05,
      "loss": 0.0074,
      "step": 5396
    },
    {
      "epoch": 0.32014473840313207,
      "grad_norm": 3.040224552154541,
      "learning_rate": 1.5108093857105195e-05,
      "loss": 0.0354,
      "step": 5397
    },
    {
      "epoch": 0.3202040574208091,
      "grad_norm": 14.437992095947266,
      "learning_rate": 1.5106775639335621e-05,
      "loss": 0.3704,
      "step": 5398
    },
    {
      "epoch": 0.3202633764384862,
      "grad_norm": 0.6785816550254822,
      "learning_rate": 1.5105457421566043e-05,
      "loss": 0.008,
      "step": 5399
    },
    {
      "epoch": 0.32032269545616326,
      "grad_norm": 6.432302474975586,
      "learning_rate": 1.510413920379647e-05,
      "loss": 0.0236,
      "step": 5400
    },
    {
      "epoch": 0.3203820144738403,
      "grad_norm": 0.049904435873031616,
      "learning_rate": 1.5102820986026893e-05,
      "loss": 0.0008,
      "step": 5401
    },
    {
      "epoch": 0.3204413334915174,
      "grad_norm": 3.653193712234497,
      "learning_rate": 1.5101502768257316e-05,
      "loss": 0.0807,
      "step": 5402
    },
    {
      "epoch": 0.32050065250919446,
      "grad_norm": 3.257380723953247,
      "learning_rate": 1.5100184550487742e-05,
      "loss": 0.0537,
      "step": 5403
    },
    {
      "epoch": 0.3205599715268715,
      "grad_norm": 0.04118727520108223,
      "learning_rate": 1.5098866332718168e-05,
      "loss": 0.0007,
      "step": 5404
    },
    {
      "epoch": 0.3206192905445486,
      "grad_norm": 5.291638374328613,
      "learning_rate": 1.509754811494859e-05,
      "loss": 0.0856,
      "step": 5405
    },
    {
      "epoch": 0.32067860956222566,
      "grad_norm": 0.515346348285675,
      "learning_rate": 1.5096229897179016e-05,
      "loss": 0.0046,
      "step": 5406
    },
    {
      "epoch": 0.32073792857990274,
      "grad_norm": 9.876919746398926,
      "learning_rate": 1.5094911679409439e-05,
      "loss": 0.4836,
      "step": 5407
    },
    {
      "epoch": 0.32079724759757977,
      "grad_norm": 2.1918935775756836,
      "learning_rate": 1.5093593461639864e-05,
      "loss": 0.0237,
      "step": 5408
    },
    {
      "epoch": 0.32085656661525686,
      "grad_norm": 0.9691508412361145,
      "learning_rate": 1.5092275243870289e-05,
      "loss": 0.0069,
      "step": 5409
    },
    {
      "epoch": 0.32091588563293394,
      "grad_norm": 2.401536464691162,
      "learning_rate": 1.5090957026100713e-05,
      "loss": 0.0802,
      "step": 5410
    },
    {
      "epoch": 0.32097520465061097,
      "grad_norm": 23.059412002563477,
      "learning_rate": 1.5089638808331137e-05,
      "loss": 0.3418,
      "step": 5411
    },
    {
      "epoch": 0.32103452366828805,
      "grad_norm": 1.174766182899475,
      "learning_rate": 1.5088320590561563e-05,
      "loss": 0.0089,
      "step": 5412
    },
    {
      "epoch": 0.32109384268596514,
      "grad_norm": 0.5666558742523193,
      "learning_rate": 1.5087002372791985e-05,
      "loss": 0.0046,
      "step": 5413
    },
    {
      "epoch": 0.32115316170364216,
      "grad_norm": 0.2842507064342499,
      "learning_rate": 1.5085684155022411e-05,
      "loss": 0.0078,
      "step": 5414
    },
    {
      "epoch": 0.32121248072131925,
      "grad_norm": 10.253700256347656,
      "learning_rate": 1.5084365937252835e-05,
      "loss": 0.4271,
      "step": 5415
    },
    {
      "epoch": 0.32127179973899633,
      "grad_norm": 0.35503923892974854,
      "learning_rate": 1.508304771948326e-05,
      "loss": 0.0028,
      "step": 5416
    },
    {
      "epoch": 0.32133111875667336,
      "grad_norm": 0.29302018880844116,
      "learning_rate": 1.5081729501713684e-05,
      "loss": 0.0041,
      "step": 5417
    },
    {
      "epoch": 0.32139043777435045,
      "grad_norm": 2.6957714557647705,
      "learning_rate": 1.508041128394411e-05,
      "loss": 0.0147,
      "step": 5418
    },
    {
      "epoch": 0.32144975679202753,
      "grad_norm": 32.75531768798828,
      "learning_rate": 1.5079093066174532e-05,
      "loss": 0.6922,
      "step": 5419
    },
    {
      "epoch": 0.3215090758097046,
      "grad_norm": 9.687742233276367,
      "learning_rate": 1.5077774848404958e-05,
      "loss": 0.6838,
      "step": 5420
    },
    {
      "epoch": 0.32156839482738164,
      "grad_norm": 0.2596798837184906,
      "learning_rate": 1.5076456630635384e-05,
      "loss": 0.003,
      "step": 5421
    },
    {
      "epoch": 0.3216277138450587,
      "grad_norm": 0.7827545404434204,
      "learning_rate": 1.5075138412865806e-05,
      "loss": 0.0119,
      "step": 5422
    },
    {
      "epoch": 0.3216870328627358,
      "grad_norm": 5.33810567855835,
      "learning_rate": 1.5073820195096232e-05,
      "loss": 0.2583,
      "step": 5423
    },
    {
      "epoch": 0.32174635188041284,
      "grad_norm": 2.151221752166748,
      "learning_rate": 1.5072501977326655e-05,
      "loss": 0.0588,
      "step": 5424
    },
    {
      "epoch": 0.3218056708980899,
      "grad_norm": 116.13915252685547,
      "learning_rate": 1.5071183759557079e-05,
      "loss": 0.7164,
      "step": 5425
    },
    {
      "epoch": 0.321864989915767,
      "grad_norm": 0.055808257311582565,
      "learning_rate": 1.5069865541787505e-05,
      "loss": 0.0018,
      "step": 5426
    },
    {
      "epoch": 0.32192430893344404,
      "grad_norm": 0.11393050849437714,
      "learning_rate": 1.5068547324017927e-05,
      "loss": 0.0015,
      "step": 5427
    },
    {
      "epoch": 0.3219836279511211,
      "grad_norm": 0.46429532766342163,
      "learning_rate": 1.5067229106248353e-05,
      "loss": 0.0048,
      "step": 5428
    },
    {
      "epoch": 0.3220429469687982,
      "grad_norm": 4.055222511291504,
      "learning_rate": 1.506591088847878e-05,
      "loss": 0.047,
      "step": 5429
    },
    {
      "epoch": 0.3221022659864753,
      "grad_norm": 7.379126071929932,
      "learning_rate": 1.5064592670709202e-05,
      "loss": 0.1015,
      "step": 5430
    },
    {
      "epoch": 0.3221615850041523,
      "grad_norm": 2.9536213874816895,
      "learning_rate": 1.5063274452939628e-05,
      "loss": 0.0334,
      "step": 5431
    },
    {
      "epoch": 0.3222209040218294,
      "grad_norm": 2.16090726852417,
      "learning_rate": 1.5061956235170052e-05,
      "loss": 0.0234,
      "step": 5432
    },
    {
      "epoch": 0.3222802230395065,
      "grad_norm": 0.03670882061123848,
      "learning_rate": 1.5060638017400476e-05,
      "loss": 0.0011,
      "step": 5433
    },
    {
      "epoch": 0.3223395420571835,
      "grad_norm": 0.09851217269897461,
      "learning_rate": 1.50593197996309e-05,
      "loss": 0.0014,
      "step": 5434
    },
    {
      "epoch": 0.3223988610748606,
      "grad_norm": 3.163357973098755,
      "learning_rate": 1.5058001581861326e-05,
      "loss": 0.033,
      "step": 5435
    },
    {
      "epoch": 0.3224581800925377,
      "grad_norm": 0.7543057799339294,
      "learning_rate": 1.5056683364091748e-05,
      "loss": 0.0064,
      "step": 5436
    },
    {
      "epoch": 0.3225174991102147,
      "grad_norm": 0.06844639778137207,
      "learning_rate": 1.5055365146322174e-05,
      "loss": 0.0014,
      "step": 5437
    },
    {
      "epoch": 0.3225768181278918,
      "grad_norm": 1.3506419658660889,
      "learning_rate": 1.5054046928552599e-05,
      "loss": 0.0137,
      "step": 5438
    },
    {
      "epoch": 0.3226361371455689,
      "grad_norm": 10.017760276794434,
      "learning_rate": 1.5052728710783023e-05,
      "loss": 0.3251,
      "step": 5439
    },
    {
      "epoch": 0.32269545616324596,
      "grad_norm": 0.18146011233329773,
      "learning_rate": 1.5051410493013447e-05,
      "loss": 0.0023,
      "step": 5440
    },
    {
      "epoch": 0.322754775180923,
      "grad_norm": 18.172956466674805,
      "learning_rate": 1.5050092275243871e-05,
      "loss": 0.4545,
      "step": 5441
    },
    {
      "epoch": 0.3228140941986001,
      "grad_norm": 9.783011436462402,
      "learning_rate": 1.5048774057474295e-05,
      "loss": 0.5169,
      "step": 5442
    },
    {
      "epoch": 0.32287341321627716,
      "grad_norm": 26.974306106567383,
      "learning_rate": 1.5047455839704721e-05,
      "loss": 0.4046,
      "step": 5443
    },
    {
      "epoch": 0.3229327322339542,
      "grad_norm": 0.3440156579017639,
      "learning_rate": 1.5046137621935144e-05,
      "loss": 0.0027,
      "step": 5444
    },
    {
      "epoch": 0.3229920512516313,
      "grad_norm": 30.484785079956055,
      "learning_rate": 1.504481940416557e-05,
      "loss": 0.8873,
      "step": 5445
    },
    {
      "epoch": 0.32305137026930836,
      "grad_norm": 0.3845008611679077,
      "learning_rate": 1.5043501186395994e-05,
      "loss": 0.0051,
      "step": 5446
    },
    {
      "epoch": 0.3231106892869854,
      "grad_norm": 4.858712196350098,
      "learning_rate": 1.5042182968626418e-05,
      "loss": 0.1227,
      "step": 5447
    },
    {
      "epoch": 0.32317000830466247,
      "grad_norm": 0.26937857270240784,
      "learning_rate": 1.5040864750856842e-05,
      "loss": 0.0031,
      "step": 5448
    },
    {
      "epoch": 0.32322932732233955,
      "grad_norm": 0.34955525398254395,
      "learning_rate": 1.5039546533087268e-05,
      "loss": 0.0034,
      "step": 5449
    },
    {
      "epoch": 0.3232886463400166,
      "grad_norm": 12.188194274902344,
      "learning_rate": 1.503822831531769e-05,
      "loss": 0.1513,
      "step": 5450
    },
    {
      "epoch": 0.32334796535769367,
      "grad_norm": 0.4497261941432953,
      "learning_rate": 1.5036910097548116e-05,
      "loss": 0.0051,
      "step": 5451
    },
    {
      "epoch": 0.32340728437537075,
      "grad_norm": 0.05609254911541939,
      "learning_rate": 1.5035591879778542e-05,
      "loss": 0.0008,
      "step": 5452
    },
    {
      "epoch": 0.32346660339304784,
      "grad_norm": 4.839599132537842,
      "learning_rate": 1.5034273662008965e-05,
      "loss": 0.0781,
      "step": 5453
    },
    {
      "epoch": 0.32352592241072486,
      "grad_norm": 0.012594623491168022,
      "learning_rate": 1.503295544423939e-05,
      "loss": 0.0004,
      "step": 5454
    },
    {
      "epoch": 0.32358524142840195,
      "grad_norm": 0.006242315750569105,
      "learning_rate": 1.5031637226469813e-05,
      "loss": 0.0002,
      "step": 5455
    },
    {
      "epoch": 0.32364456044607903,
      "grad_norm": 0.019617320969700813,
      "learning_rate": 1.5030319008700239e-05,
      "loss": 0.0005,
      "step": 5456
    },
    {
      "epoch": 0.32370387946375606,
      "grad_norm": 3.1279053688049316,
      "learning_rate": 1.5029000790930663e-05,
      "loss": 0.0591,
      "step": 5457
    },
    {
      "epoch": 0.32376319848143315,
      "grad_norm": 0.5592477321624756,
      "learning_rate": 1.5027682573161086e-05,
      "loss": 0.0063,
      "step": 5458
    },
    {
      "epoch": 0.32382251749911023,
      "grad_norm": 5.699953079223633,
      "learning_rate": 1.5026364355391512e-05,
      "loss": 0.3986,
      "step": 5459
    },
    {
      "epoch": 0.32388183651678726,
      "grad_norm": 0.058007605373859406,
      "learning_rate": 1.5025046137621937e-05,
      "loss": 0.0012,
      "step": 5460
    },
    {
      "epoch": 0.32394115553446434,
      "grad_norm": 4.824307918548584,
      "learning_rate": 1.502372791985236e-05,
      "loss": 0.0434,
      "step": 5461
    },
    {
      "epoch": 0.3240004745521414,
      "grad_norm": 0.13876911997795105,
      "learning_rate": 1.5022409702082786e-05,
      "loss": 0.0028,
      "step": 5462
    },
    {
      "epoch": 0.3240597935698185,
      "grad_norm": 0.2013310045003891,
      "learning_rate": 1.502109148431321e-05,
      "loss": 0.0025,
      "step": 5463
    },
    {
      "epoch": 0.32411911258749554,
      "grad_norm": 0.6709865927696228,
      "learning_rate": 1.5019773266543634e-05,
      "loss": 0.0049,
      "step": 5464
    },
    {
      "epoch": 0.3241784316051726,
      "grad_norm": 10.599106788635254,
      "learning_rate": 1.5018455048774058e-05,
      "loss": 0.4842,
      "step": 5465
    },
    {
      "epoch": 0.3242377506228497,
      "grad_norm": 0.3865152597427368,
      "learning_rate": 1.5017136831004484e-05,
      "loss": 0.0029,
      "step": 5466
    },
    {
      "epoch": 0.32429706964052674,
      "grad_norm": 19.514375686645508,
      "learning_rate": 1.5015818613234907e-05,
      "loss": 1.0385,
      "step": 5467
    },
    {
      "epoch": 0.3243563886582038,
      "grad_norm": 4.86908483505249,
      "learning_rate": 1.5014500395465333e-05,
      "loss": 0.1135,
      "step": 5468
    },
    {
      "epoch": 0.3244157076758809,
      "grad_norm": 3.1827754974365234,
      "learning_rate": 1.5013182177695757e-05,
      "loss": 0.0237,
      "step": 5469
    },
    {
      "epoch": 0.32447502669355793,
      "grad_norm": 0.013826061971485615,
      "learning_rate": 1.5011863959926181e-05,
      "loss": 0.0003,
      "step": 5470
    },
    {
      "epoch": 0.324534345711235,
      "grad_norm": 2.771897792816162,
      "learning_rate": 1.5010545742156605e-05,
      "loss": 0.2738,
      "step": 5471
    },
    {
      "epoch": 0.3245936647289121,
      "grad_norm": 2.6931424140930176,
      "learning_rate": 1.500922752438703e-05,
      "loss": 0.0433,
      "step": 5472
    },
    {
      "epoch": 0.32465298374658913,
      "grad_norm": 81.35832977294922,
      "learning_rate": 1.5007909306617454e-05,
      "loss": 0.753,
      "step": 5473
    },
    {
      "epoch": 0.3247123027642662,
      "grad_norm": 13.602645874023438,
      "learning_rate": 1.500659108884788e-05,
      "loss": 0.4023,
      "step": 5474
    },
    {
      "epoch": 0.3247716217819433,
      "grad_norm": 1.7470974922180176,
      "learning_rate": 1.5005272871078302e-05,
      "loss": 0.0253,
      "step": 5475
    },
    {
      "epoch": 0.3248309407996204,
      "grad_norm": 0.013469723984599113,
      "learning_rate": 1.5003954653308728e-05,
      "loss": 0.0003,
      "step": 5476
    },
    {
      "epoch": 0.3248902598172974,
      "grad_norm": 1.2116484642028809,
      "learning_rate": 1.5002636435539154e-05,
      "loss": 0.0177,
      "step": 5477
    },
    {
      "epoch": 0.3249495788349745,
      "grad_norm": 9.244950294494629,
      "learning_rate": 1.5001318217769576e-05,
      "loss": 0.4451,
      "step": 5478
    },
    {
      "epoch": 0.3250088978526516,
      "grad_norm": 6.312064170837402,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.2329,
      "step": 5479
    },
    {
      "epoch": 0.3250682168703286,
      "grad_norm": 0.22736388444900513,
      "learning_rate": 1.4998681782230426e-05,
      "loss": 0.0041,
      "step": 5480
    },
    {
      "epoch": 0.3251275358880057,
      "grad_norm": 1.639865756034851,
      "learning_rate": 1.4997363564460849e-05,
      "loss": 0.0126,
      "step": 5481
    },
    {
      "epoch": 0.3251868549056828,
      "grad_norm": 3.5822627544403076,
      "learning_rate": 1.4996045346691275e-05,
      "loss": 0.024,
      "step": 5482
    },
    {
      "epoch": 0.3252461739233598,
      "grad_norm": 19.980731964111328,
      "learning_rate": 1.49947271289217e-05,
      "loss": 0.2312,
      "step": 5483
    },
    {
      "epoch": 0.3253054929410369,
      "grad_norm": 0.056972719728946686,
      "learning_rate": 1.4993408911152123e-05,
      "loss": 0.0017,
      "step": 5484
    },
    {
      "epoch": 0.325364811958714,
      "grad_norm": 12.172553062438965,
      "learning_rate": 1.4992090693382549e-05,
      "loss": 0.5191,
      "step": 5485
    },
    {
      "epoch": 0.32542413097639106,
      "grad_norm": 2.879946231842041,
      "learning_rate": 1.4990772475612973e-05,
      "loss": 0.0234,
      "step": 5486
    },
    {
      "epoch": 0.3254834499940681,
      "grad_norm": 0.04221788048744202,
      "learning_rate": 1.4989454257843397e-05,
      "loss": 0.0007,
      "step": 5487
    },
    {
      "epoch": 0.32554276901174517,
      "grad_norm": 12.56955337524414,
      "learning_rate": 1.4988136040073821e-05,
      "loss": 0.7236,
      "step": 5488
    },
    {
      "epoch": 0.32560208802942225,
      "grad_norm": 0.017940254881978035,
      "learning_rate": 1.4986817822304246e-05,
      "loss": 0.0006,
      "step": 5489
    },
    {
      "epoch": 0.3256614070470993,
      "grad_norm": 0.7029110193252563,
      "learning_rate": 1.498549960453467e-05,
      "loss": 0.007,
      "step": 5490
    },
    {
      "epoch": 0.32572072606477637,
      "grad_norm": 5.404758930206299,
      "learning_rate": 1.4984181386765096e-05,
      "loss": 0.1211,
      "step": 5491
    },
    {
      "epoch": 0.32578004508245345,
      "grad_norm": 0.039585456252098083,
      "learning_rate": 1.4982863168995518e-05,
      "loss": 0.0013,
      "step": 5492
    },
    {
      "epoch": 0.3258393641001305,
      "grad_norm": 0.11472615599632263,
      "learning_rate": 1.4981544951225944e-05,
      "loss": 0.0016,
      "step": 5493
    },
    {
      "epoch": 0.32589868311780756,
      "grad_norm": 0.15740810334682465,
      "learning_rate": 1.4980226733456368e-05,
      "loss": 0.0014,
      "step": 5494
    },
    {
      "epoch": 0.32595800213548465,
      "grad_norm": 26.841228485107422,
      "learning_rate": 1.4978908515686792e-05,
      "loss": 0.2224,
      "step": 5495
    },
    {
      "epoch": 0.3260173211531617,
      "grad_norm": 1.1524691581726074,
      "learning_rate": 1.4977590297917217e-05,
      "loss": 0.0109,
      "step": 5496
    },
    {
      "epoch": 0.32607664017083876,
      "grad_norm": 0.009530739858746529,
      "learning_rate": 1.4976272080147643e-05,
      "loss": 0.0003,
      "step": 5497
    },
    {
      "epoch": 0.32613595918851584,
      "grad_norm": 51.10015106201172,
      "learning_rate": 1.4974953862378065e-05,
      "loss": 0.4054,
      "step": 5498
    },
    {
      "epoch": 0.32619527820619293,
      "grad_norm": 4.63920259475708,
      "learning_rate": 1.4973635644608491e-05,
      "loss": 0.0606,
      "step": 5499
    },
    {
      "epoch": 0.32625459722386996,
      "grad_norm": 0.06560806930065155,
      "learning_rate": 1.4972317426838917e-05,
      "loss": 0.0008,
      "step": 5500
    },
    {
      "epoch": 0.32631391624154704,
      "grad_norm": 2.351506471633911,
      "learning_rate": 1.497099920906934e-05,
      "loss": 0.0079,
      "step": 5501
    },
    {
      "epoch": 0.3263732352592241,
      "grad_norm": 18.694650650024414,
      "learning_rate": 1.4969680991299763e-05,
      "loss": 0.493,
      "step": 5502
    },
    {
      "epoch": 0.32643255427690115,
      "grad_norm": 1.4568284749984741,
      "learning_rate": 1.496836277353019e-05,
      "loss": 0.0283,
      "step": 5503
    },
    {
      "epoch": 0.32649187329457824,
      "grad_norm": 2.12151837348938,
      "learning_rate": 1.4967044555760612e-05,
      "loss": 0.0405,
      "step": 5504
    },
    {
      "epoch": 0.3265511923122553,
      "grad_norm": 0.009205319918692112,
      "learning_rate": 1.4965726337991038e-05,
      "loss": 0.0002,
      "step": 5505
    },
    {
      "epoch": 0.32661051132993235,
      "grad_norm": 0.012130596674978733,
      "learning_rate": 1.496440812022146e-05,
      "loss": 0.0004,
      "step": 5506
    },
    {
      "epoch": 0.32666983034760944,
      "grad_norm": 0.24026642739772797,
      "learning_rate": 1.4963089902451886e-05,
      "loss": 0.0045,
      "step": 5507
    },
    {
      "epoch": 0.3267291493652865,
      "grad_norm": 0.07331736385822296,
      "learning_rate": 1.4961771684682312e-05,
      "loss": 0.0012,
      "step": 5508
    },
    {
      "epoch": 0.3267884683829636,
      "grad_norm": 34.16257095336914,
      "learning_rate": 1.4960453466912734e-05,
      "loss": 1.508,
      "step": 5509
    },
    {
      "epoch": 0.32684778740064063,
      "grad_norm": 0.6396766304969788,
      "learning_rate": 1.495913524914316e-05,
      "loss": 0.0043,
      "step": 5510
    },
    {
      "epoch": 0.3269071064183177,
      "grad_norm": 3.96685528755188,
      "learning_rate": 1.4957817031373585e-05,
      "loss": 0.1022,
      "step": 5511
    },
    {
      "epoch": 0.3269664254359948,
      "grad_norm": 0.1248873770236969,
      "learning_rate": 1.4956498813604009e-05,
      "loss": 0.0021,
      "step": 5512
    },
    {
      "epoch": 0.32702574445367183,
      "grad_norm": 0.01433270052075386,
      "learning_rate": 1.4955180595834433e-05,
      "loss": 0.0004,
      "step": 5513
    },
    {
      "epoch": 0.3270850634713489,
      "grad_norm": 0.024338047951459885,
      "learning_rate": 1.4953862378064859e-05,
      "loss": 0.0006,
      "step": 5514
    },
    {
      "epoch": 0.327144382489026,
      "grad_norm": 0.006627113092690706,
      "learning_rate": 1.4952544160295281e-05,
      "loss": 0.0002,
      "step": 5515
    },
    {
      "epoch": 0.327203701506703,
      "grad_norm": 0.1599501222372055,
      "learning_rate": 1.4951225942525707e-05,
      "loss": 0.0017,
      "step": 5516
    },
    {
      "epoch": 0.3272630205243801,
      "grad_norm": 0.0320591926574707,
      "learning_rate": 1.4949907724756131e-05,
      "loss": 0.0007,
      "step": 5517
    },
    {
      "epoch": 0.3273223395420572,
      "grad_norm": 0.008370998315513134,
      "learning_rate": 1.4948589506986556e-05,
      "loss": 0.0003,
      "step": 5518
    },
    {
      "epoch": 0.3273816585597342,
      "grad_norm": 10.904728889465332,
      "learning_rate": 1.494727128921698e-05,
      "loss": 0.5569,
      "step": 5519
    },
    {
      "epoch": 0.3274409775774113,
      "grad_norm": 11.654718399047852,
      "learning_rate": 1.4945953071447404e-05,
      "loss": 0.1203,
      "step": 5520
    },
    {
      "epoch": 0.3275002965950884,
      "grad_norm": 6.721482753753662,
      "learning_rate": 1.4944634853677828e-05,
      "loss": 0.0992,
      "step": 5521
    },
    {
      "epoch": 0.3275596156127655,
      "grad_norm": 0.7106631994247437,
      "learning_rate": 1.4943316635908254e-05,
      "loss": 0.0084,
      "step": 5522
    },
    {
      "epoch": 0.3276189346304425,
      "grad_norm": 0.18374225497245789,
      "learning_rate": 1.4941998418138676e-05,
      "loss": 0.003,
      "step": 5523
    },
    {
      "epoch": 0.3276782536481196,
      "grad_norm": 0.12562766671180725,
      "learning_rate": 1.4940680200369102e-05,
      "loss": 0.0033,
      "step": 5524
    },
    {
      "epoch": 0.3277375726657967,
      "grad_norm": 0.012794459238648415,
      "learning_rate": 1.4939361982599527e-05,
      "loss": 0.0003,
      "step": 5525
    },
    {
      "epoch": 0.3277968916834737,
      "grad_norm": 2.556305408477783,
      "learning_rate": 1.493804376482995e-05,
      "loss": 0.0183,
      "step": 5526
    },
    {
      "epoch": 0.3278562107011508,
      "grad_norm": 8.579815864562988,
      "learning_rate": 1.4936725547060375e-05,
      "loss": 0.5451,
      "step": 5527
    },
    {
      "epoch": 0.32791552971882787,
      "grad_norm": 1.7102136611938477,
      "learning_rate": 1.49354073292908e-05,
      "loss": 0.0105,
      "step": 5528
    },
    {
      "epoch": 0.3279748487365049,
      "grad_norm": 0.09073217958211899,
      "learning_rate": 1.4934089111521223e-05,
      "loss": 0.0021,
      "step": 5529
    },
    {
      "epoch": 0.328034167754182,
      "grad_norm": 55.45115661621094,
      "learning_rate": 1.493277089375165e-05,
      "loss": 0.829,
      "step": 5530
    },
    {
      "epoch": 0.32809348677185907,
      "grad_norm": 0.011133559048175812,
      "learning_rate": 1.4931452675982075e-05,
      "loss": 0.0004,
      "step": 5531
    },
    {
      "epoch": 0.32815280578953615,
      "grad_norm": 0.02264111489057541,
      "learning_rate": 1.4930134458212498e-05,
      "loss": 0.0005,
      "step": 5532
    },
    {
      "epoch": 0.3282121248072132,
      "grad_norm": 17.937026977539062,
      "learning_rate": 1.4928816240442923e-05,
      "loss": 0.2586,
      "step": 5533
    },
    {
      "epoch": 0.32827144382489026,
      "grad_norm": 8.04010009765625,
      "learning_rate": 1.4927498022673348e-05,
      "loss": 0.1686,
      "step": 5534
    },
    {
      "epoch": 0.32833076284256735,
      "grad_norm": 1.0060886144638062,
      "learning_rate": 1.492617980490377e-05,
      "loss": 0.0115,
      "step": 5535
    },
    {
      "epoch": 0.3283900818602444,
      "grad_norm": 0.014862681739032269,
      "learning_rate": 1.4924861587134196e-05,
      "loss": 0.0005,
      "step": 5536
    },
    {
      "epoch": 0.32844940087792146,
      "grad_norm": 7.1803812980651855,
      "learning_rate": 1.4923543369364618e-05,
      "loss": 0.0463,
      "step": 5537
    },
    {
      "epoch": 0.32850871989559854,
      "grad_norm": 0.6061575412750244,
      "learning_rate": 1.4922225151595044e-05,
      "loss": 0.0141,
      "step": 5538
    },
    {
      "epoch": 0.3285680389132756,
      "grad_norm": 0.19607782363891602,
      "learning_rate": 1.492090693382547e-05,
      "loss": 0.004,
      "step": 5539
    },
    {
      "epoch": 0.32862735793095266,
      "grad_norm": 6.426136016845703,
      "learning_rate": 1.4919588716055893e-05,
      "loss": 0.033,
      "step": 5540
    },
    {
      "epoch": 0.32868667694862974,
      "grad_norm": 3.2216696739196777,
      "learning_rate": 1.4918270498286319e-05,
      "loss": 0.0241,
      "step": 5541
    },
    {
      "epoch": 0.3287459959663068,
      "grad_norm": 14.338995933532715,
      "learning_rate": 1.4916952280516743e-05,
      "loss": 0.3644,
      "step": 5542
    },
    {
      "epoch": 0.32880531498398385,
      "grad_norm": 1.3336817026138306,
      "learning_rate": 1.4915634062747167e-05,
      "loss": 0.0079,
      "step": 5543
    },
    {
      "epoch": 0.32886463400166094,
      "grad_norm": 10.400218963623047,
      "learning_rate": 1.4914315844977591e-05,
      "loss": 0.4261,
      "step": 5544
    },
    {
      "epoch": 0.328923953019338,
      "grad_norm": 0.8921005129814148,
      "learning_rate": 1.4912997627208017e-05,
      "loss": 0.0108,
      "step": 5545
    },
    {
      "epoch": 0.32898327203701505,
      "grad_norm": 21.24614715576172,
      "learning_rate": 1.491167940943844e-05,
      "loss": 0.3059,
      "step": 5546
    },
    {
      "epoch": 0.32904259105469214,
      "grad_norm": 0.0666269063949585,
      "learning_rate": 1.4910361191668865e-05,
      "loss": 0.0007,
      "step": 5547
    },
    {
      "epoch": 0.3291019100723692,
      "grad_norm": 0.19568568468093872,
      "learning_rate": 1.490904297389929e-05,
      "loss": 0.003,
      "step": 5548
    },
    {
      "epoch": 0.32916122909004625,
      "grad_norm": 0.0215260311961174,
      "learning_rate": 1.4907724756129714e-05,
      "loss": 0.0006,
      "step": 5549
    },
    {
      "epoch": 0.32922054810772333,
      "grad_norm": 14.569323539733887,
      "learning_rate": 1.4906406538360138e-05,
      "loss": 0.7274,
      "step": 5550
    },
    {
      "epoch": 0.3292798671254004,
      "grad_norm": 9.878499984741211,
      "learning_rate": 1.4905088320590564e-05,
      "loss": 0.057,
      "step": 5551
    },
    {
      "epoch": 0.32933918614307744,
      "grad_norm": 0.7692064046859741,
      "learning_rate": 1.4903770102820986e-05,
      "loss": 0.0061,
      "step": 5552
    },
    {
      "epoch": 0.32939850516075453,
      "grad_norm": 0.6460027098655701,
      "learning_rate": 1.4902451885051412e-05,
      "loss": 0.0068,
      "step": 5553
    },
    {
      "epoch": 0.3294578241784316,
      "grad_norm": 6.35192346572876,
      "learning_rate": 1.4901133667281835e-05,
      "loss": 0.2049,
      "step": 5554
    },
    {
      "epoch": 0.3295171431961087,
      "grad_norm": 0.014980195090174675,
      "learning_rate": 1.489981544951226e-05,
      "loss": 0.0003,
      "step": 5555
    },
    {
      "epoch": 0.3295764622137857,
      "grad_norm": 6.675956726074219,
      "learning_rate": 1.4898497231742687e-05,
      "loss": 0.1818,
      "step": 5556
    },
    {
      "epoch": 0.3296357812314628,
      "grad_norm": 2.978248357772827,
      "learning_rate": 1.4897179013973109e-05,
      "loss": 0.017,
      "step": 5557
    },
    {
      "epoch": 0.3296951002491399,
      "grad_norm": 0.009145032614469528,
      "learning_rate": 1.4895860796203533e-05,
      "loss": 0.0003,
      "step": 5558
    },
    {
      "epoch": 0.3297544192668169,
      "grad_norm": 0.131571426987648,
      "learning_rate": 1.4894542578433959e-05,
      "loss": 0.0015,
      "step": 5559
    },
    {
      "epoch": 0.329813738284494,
      "grad_norm": 0.0076260133646428585,
      "learning_rate": 1.4893224360664382e-05,
      "loss": 0.0003,
      "step": 5560
    },
    {
      "epoch": 0.3298730573021711,
      "grad_norm": 4.867372512817383,
      "learning_rate": 1.4891906142894807e-05,
      "loss": 0.0509,
      "step": 5561
    },
    {
      "epoch": 0.3299323763198481,
      "grad_norm": 9.08536434173584,
      "learning_rate": 1.4890587925125233e-05,
      "loss": 0.6968,
      "step": 5562
    },
    {
      "epoch": 0.3299916953375252,
      "grad_norm": 29.344295501708984,
      "learning_rate": 1.4889269707355656e-05,
      "loss": 0.6439,
      "step": 5563
    },
    {
      "epoch": 0.3300510143552023,
      "grad_norm": 0.11779386550188065,
      "learning_rate": 1.4887951489586082e-05,
      "loss": 0.0018,
      "step": 5564
    },
    {
      "epoch": 0.33011033337287937,
      "grad_norm": 21.374467849731445,
      "learning_rate": 1.4886633271816506e-05,
      "loss": 1.0457,
      "step": 5565
    },
    {
      "epoch": 0.3301696523905564,
      "grad_norm": 4.943877696990967,
      "learning_rate": 1.488531505404693e-05,
      "loss": 0.4338,
      "step": 5566
    },
    {
      "epoch": 0.3302289714082335,
      "grad_norm": 1.3845500946044922,
      "learning_rate": 1.4883996836277354e-05,
      "loss": 0.0109,
      "step": 5567
    },
    {
      "epoch": 0.33028829042591057,
      "grad_norm": 3.6650924682617188,
      "learning_rate": 1.4882678618507778e-05,
      "loss": 0.0362,
      "step": 5568
    },
    {
      "epoch": 0.3303476094435876,
      "grad_norm": 0.01932588964700699,
      "learning_rate": 1.4881360400738203e-05,
      "loss": 0.0005,
      "step": 5569
    },
    {
      "epoch": 0.3304069284612647,
      "grad_norm": 20.89640235900879,
      "learning_rate": 1.4880042182968629e-05,
      "loss": 0.0616,
      "step": 5570
    },
    {
      "epoch": 0.33046624747894177,
      "grad_norm": 14.514612197875977,
      "learning_rate": 1.4878723965199051e-05,
      "loss": 0.4893,
      "step": 5571
    },
    {
      "epoch": 0.3305255664966188,
      "grad_norm": 9.05501651763916,
      "learning_rate": 1.4877405747429477e-05,
      "loss": 0.4421,
      "step": 5572
    },
    {
      "epoch": 0.3305848855142959,
      "grad_norm": 0.43620243668556213,
      "learning_rate": 1.4876087529659901e-05,
      "loss": 0.0041,
      "step": 5573
    },
    {
      "epoch": 0.33064420453197296,
      "grad_norm": 0.2509210407733917,
      "learning_rate": 1.4874769311890325e-05,
      "loss": 0.0041,
      "step": 5574
    },
    {
      "epoch": 0.33070352354965,
      "grad_norm": 15.090001106262207,
      "learning_rate": 1.487345109412075e-05,
      "loss": 0.4154,
      "step": 5575
    },
    {
      "epoch": 0.3307628425673271,
      "grad_norm": 13.352953910827637,
      "learning_rate": 1.4872132876351175e-05,
      "loss": 0.0781,
      "step": 5576
    },
    {
      "epoch": 0.33082216158500416,
      "grad_norm": 12.33962631225586,
      "learning_rate": 1.4870814658581598e-05,
      "loss": 0.441,
      "step": 5577
    },
    {
      "epoch": 0.33088148060268124,
      "grad_norm": 0.04327305778861046,
      "learning_rate": 1.4869496440812024e-05,
      "loss": 0.0008,
      "step": 5578
    },
    {
      "epoch": 0.3309407996203583,
      "grad_norm": 9.852258682250977,
      "learning_rate": 1.4868178223042448e-05,
      "loss": 0.9492,
      "step": 5579
    },
    {
      "epoch": 0.33100011863803536,
      "grad_norm": 8.833964347839355,
      "learning_rate": 1.4866860005272872e-05,
      "loss": 0.1092,
      "step": 5580
    },
    {
      "epoch": 0.33105943765571244,
      "grad_norm": 3.13517689704895,
      "learning_rate": 1.4865541787503296e-05,
      "loss": 0.0334,
      "step": 5581
    },
    {
      "epoch": 0.33111875667338947,
      "grad_norm": 0.12961731851100922,
      "learning_rate": 1.4864223569733722e-05,
      "loss": 0.0017,
      "step": 5582
    },
    {
      "epoch": 0.33117807569106655,
      "grad_norm": 0.009316719137132168,
      "learning_rate": 1.4862905351964145e-05,
      "loss": 0.0003,
      "step": 5583
    },
    {
      "epoch": 0.33123739470874364,
      "grad_norm": 14.60049057006836,
      "learning_rate": 1.486158713419457e-05,
      "loss": 0.5071,
      "step": 5584
    },
    {
      "epoch": 0.33129671372642067,
      "grad_norm": 0.07077528536319733,
      "learning_rate": 1.4860268916424993e-05,
      "loss": 0.0015,
      "step": 5585
    },
    {
      "epoch": 0.33135603274409775,
      "grad_norm": 0.667305588722229,
      "learning_rate": 1.4858950698655419e-05,
      "loss": 0.0079,
      "step": 5586
    },
    {
      "epoch": 0.33141535176177483,
      "grad_norm": 0.285799503326416,
      "learning_rate": 1.4857632480885845e-05,
      "loss": 0.0056,
      "step": 5587
    },
    {
      "epoch": 0.3314746707794519,
      "grad_norm": 6.9315595626831055,
      "learning_rate": 1.4856314263116267e-05,
      "loss": 0.0495,
      "step": 5588
    },
    {
      "epoch": 0.33153398979712895,
      "grad_norm": 0.26261672377586365,
      "learning_rate": 1.4854996045346693e-05,
      "loss": 0.0017,
      "step": 5589
    },
    {
      "epoch": 0.33159330881480603,
      "grad_norm": 1.984702229499817,
      "learning_rate": 1.4853677827577117e-05,
      "loss": 0.0207,
      "step": 5590
    },
    {
      "epoch": 0.3316526278324831,
      "grad_norm": 0.06928884238004684,
      "learning_rate": 1.485235960980754e-05,
      "loss": 0.0008,
      "step": 5591
    },
    {
      "epoch": 0.33171194685016014,
      "grad_norm": 0.6571189761161804,
      "learning_rate": 1.4851041392037966e-05,
      "loss": 0.0081,
      "step": 5592
    },
    {
      "epoch": 0.33177126586783723,
      "grad_norm": 0.19462721049785614,
      "learning_rate": 1.4849723174268392e-05,
      "loss": 0.0019,
      "step": 5593
    },
    {
      "epoch": 0.3318305848855143,
      "grad_norm": 6.102080821990967,
      "learning_rate": 1.4848404956498814e-05,
      "loss": 0.6263,
      "step": 5594
    },
    {
      "epoch": 0.33188990390319134,
      "grad_norm": 5.414578437805176,
      "learning_rate": 1.484708673872924e-05,
      "loss": 0.1607,
      "step": 5595
    },
    {
      "epoch": 0.3319492229208684,
      "grad_norm": 0.5527231693267822,
      "learning_rate": 1.4845768520959664e-05,
      "loss": 0.0034,
      "step": 5596
    },
    {
      "epoch": 0.3320085419385455,
      "grad_norm": 21.44161605834961,
      "learning_rate": 1.4844450303190088e-05,
      "loss": 0.6019,
      "step": 5597
    },
    {
      "epoch": 0.33206786095622254,
      "grad_norm": 2.452301502227783,
      "learning_rate": 1.4843132085420513e-05,
      "loss": 0.0246,
      "step": 5598
    },
    {
      "epoch": 0.3321271799738996,
      "grad_norm": 15.547582626342773,
      "learning_rate": 1.4841813867650938e-05,
      "loss": 0.3036,
      "step": 5599
    },
    {
      "epoch": 0.3321864989915767,
      "grad_norm": 29.10845375061035,
      "learning_rate": 1.4840495649881361e-05,
      "loss": 0.1674,
      "step": 5600
    },
    {
      "epoch": 0.3322458180092538,
      "grad_norm": 15.712754249572754,
      "learning_rate": 1.4839177432111787e-05,
      "loss": 1.0496,
      "step": 5601
    },
    {
      "epoch": 0.3323051370269308,
      "grad_norm": 0.24984227120876312,
      "learning_rate": 1.483785921434221e-05,
      "loss": 0.005,
      "step": 5602
    },
    {
      "epoch": 0.3323644560446079,
      "grad_norm": 9.568869590759277,
      "learning_rate": 1.4836540996572635e-05,
      "loss": 0.1569,
      "step": 5603
    },
    {
      "epoch": 0.332423775062285,
      "grad_norm": 16.593326568603516,
      "learning_rate": 1.483522277880306e-05,
      "loss": 0.5268,
      "step": 5604
    },
    {
      "epoch": 0.332483094079962,
      "grad_norm": 4.0115742683410645,
      "learning_rate": 1.4833904561033484e-05,
      "loss": 0.0447,
      "step": 5605
    },
    {
      "epoch": 0.3325424130976391,
      "grad_norm": 0.0688546672463417,
      "learning_rate": 1.4832586343263908e-05,
      "loss": 0.0012,
      "step": 5606
    },
    {
      "epoch": 0.3326017321153162,
      "grad_norm": 15.291110038757324,
      "learning_rate": 1.4831268125494334e-05,
      "loss": 1.9386,
      "step": 5607
    },
    {
      "epoch": 0.3326610511329932,
      "grad_norm": 2.2165186405181885,
      "learning_rate": 1.4829949907724756e-05,
      "loss": 0.0108,
      "step": 5608
    },
    {
      "epoch": 0.3327203701506703,
      "grad_norm": 0.23129808902740479,
      "learning_rate": 1.4828631689955182e-05,
      "loss": 0.0016,
      "step": 5609
    },
    {
      "epoch": 0.3327796891683474,
      "grad_norm": 2.89359712600708,
      "learning_rate": 1.4827313472185608e-05,
      "loss": 0.0351,
      "step": 5610
    },
    {
      "epoch": 0.33283900818602447,
      "grad_norm": 8.25378131866455,
      "learning_rate": 1.482599525441603e-05,
      "loss": 0.1674,
      "step": 5611
    },
    {
      "epoch": 0.3328983272037015,
      "grad_norm": 8.078105926513672,
      "learning_rate": 1.4824677036646456e-05,
      "loss": 0.107,
      "step": 5612
    },
    {
      "epoch": 0.3329576462213786,
      "grad_norm": 0.09229093044996262,
      "learning_rate": 1.482335881887688e-05,
      "loss": 0.0019,
      "step": 5613
    },
    {
      "epoch": 0.33301696523905566,
      "grad_norm": 8.496621131896973,
      "learning_rate": 1.4822040601107303e-05,
      "loss": 0.3918,
      "step": 5614
    },
    {
      "epoch": 0.3330762842567327,
      "grad_norm": 6.454343318939209,
      "learning_rate": 1.4820722383337729e-05,
      "loss": 0.1501,
      "step": 5615
    },
    {
      "epoch": 0.3331356032744098,
      "grad_norm": 0.019358033314347267,
      "learning_rate": 1.4819404165568151e-05,
      "loss": 0.0004,
      "step": 5616
    },
    {
      "epoch": 0.33319492229208686,
      "grad_norm": 0.03533666208386421,
      "learning_rate": 1.4818085947798577e-05,
      "loss": 0.0009,
      "step": 5617
    },
    {
      "epoch": 0.3332542413097639,
      "grad_norm": 8.130547523498535,
      "learning_rate": 1.4816767730029003e-05,
      "loss": 0.1423,
      "step": 5618
    },
    {
      "epoch": 0.33331356032744097,
      "grad_norm": 75.75037384033203,
      "learning_rate": 1.4815449512259426e-05,
      "loss": 1.2418,
      "step": 5619
    },
    {
      "epoch": 0.33337287934511806,
      "grad_norm": 0.1377134919166565,
      "learning_rate": 1.4814131294489851e-05,
      "loss": 0.003,
      "step": 5620
    },
    {
      "epoch": 0.3334321983627951,
      "grad_norm": 10.62508487701416,
      "learning_rate": 1.4812813076720276e-05,
      "loss": 0.1838,
      "step": 5621
    },
    {
      "epoch": 0.33349151738047217,
      "grad_norm": 0.4368034601211548,
      "learning_rate": 1.48114948589507e-05,
      "loss": 0.0082,
      "step": 5622
    },
    {
      "epoch": 0.33355083639814925,
      "grad_norm": 13.445338249206543,
      "learning_rate": 1.4810176641181124e-05,
      "loss": 0.3564,
      "step": 5623
    },
    {
      "epoch": 0.33361015541582634,
      "grad_norm": 7.839378356933594,
      "learning_rate": 1.480885842341155e-05,
      "loss": 0.2317,
      "step": 5624
    },
    {
      "epoch": 0.33366947443350337,
      "grad_norm": 7.809516429901123,
      "learning_rate": 1.4807540205641972e-05,
      "loss": 0.1444,
      "step": 5625
    },
    {
      "epoch": 0.33372879345118045,
      "grad_norm": 0.21524305641651154,
      "learning_rate": 1.4806221987872398e-05,
      "loss": 0.0024,
      "step": 5626
    },
    {
      "epoch": 0.33378811246885753,
      "grad_norm": 0.28571417927742004,
      "learning_rate": 1.4804903770102822e-05,
      "loss": 0.0018,
      "step": 5627
    },
    {
      "epoch": 0.33384743148653456,
      "grad_norm": 0.04105304926633835,
      "learning_rate": 1.4803585552333247e-05,
      "loss": 0.0007,
      "step": 5628
    },
    {
      "epoch": 0.33390675050421165,
      "grad_norm": 14.64341926574707,
      "learning_rate": 1.480226733456367e-05,
      "loss": 0.2355,
      "step": 5629
    },
    {
      "epoch": 0.33396606952188873,
      "grad_norm": 0.1784830391407013,
      "learning_rate": 1.4800949116794097e-05,
      "loss": 0.0017,
      "step": 5630
    },
    {
      "epoch": 0.33402538853956576,
      "grad_norm": 4.079051494598389,
      "learning_rate": 1.479963089902452e-05,
      "loss": 0.0129,
      "step": 5631
    },
    {
      "epoch": 0.33408470755724284,
      "grad_norm": 0.39976152777671814,
      "learning_rate": 1.4798312681254945e-05,
      "loss": 0.0123,
      "step": 5632
    },
    {
      "epoch": 0.33414402657491993,
      "grad_norm": 21.21687889099121,
      "learning_rate": 1.4796994463485368e-05,
      "loss": 1.4879,
      "step": 5633
    },
    {
      "epoch": 0.334203345592597,
      "grad_norm": 0.8010168671607971,
      "learning_rate": 1.4795676245715793e-05,
      "loss": 0.0108,
      "step": 5634
    },
    {
      "epoch": 0.33426266461027404,
      "grad_norm": 0.14984078705310822,
      "learning_rate": 1.4794358027946218e-05,
      "loss": 0.002,
      "step": 5635
    },
    {
      "epoch": 0.3343219836279511,
      "grad_norm": 6.018479824066162,
      "learning_rate": 1.4793039810176642e-05,
      "loss": 0.1359,
      "step": 5636
    },
    {
      "epoch": 0.3343813026456282,
      "grad_norm": 0.587850034236908,
      "learning_rate": 1.4791721592407066e-05,
      "loss": 0.0034,
      "step": 5637
    },
    {
      "epoch": 0.33444062166330524,
      "grad_norm": 10.760732650756836,
      "learning_rate": 1.4790403374637492e-05,
      "loss": 0.2135,
      "step": 5638
    },
    {
      "epoch": 0.3344999406809823,
      "grad_norm": 8.432146072387695,
      "learning_rate": 1.4789085156867914e-05,
      "loss": 0.2727,
      "step": 5639
    },
    {
      "epoch": 0.3345592596986594,
      "grad_norm": 0.055342938750982285,
      "learning_rate": 1.478776693909834e-05,
      "loss": 0.0007,
      "step": 5640
    },
    {
      "epoch": 0.33461857871633643,
      "grad_norm": 8.757211685180664,
      "learning_rate": 1.4786448721328766e-05,
      "loss": 0.5419,
      "step": 5641
    },
    {
      "epoch": 0.3346778977340135,
      "grad_norm": 7.439413070678711,
      "learning_rate": 1.4785130503559189e-05,
      "loss": 0.0969,
      "step": 5642
    },
    {
      "epoch": 0.3347372167516906,
      "grad_norm": 6.580842018127441,
      "learning_rate": 1.4783812285789614e-05,
      "loss": 0.2097,
      "step": 5643
    },
    {
      "epoch": 0.3347965357693677,
      "grad_norm": 0.10475339740514755,
      "learning_rate": 1.4782494068020039e-05,
      "loss": 0.0009,
      "step": 5644
    },
    {
      "epoch": 0.3348558547870447,
      "grad_norm": 7.119059085845947,
      "learning_rate": 1.4781175850250463e-05,
      "loss": 0.0968,
      "step": 5645
    },
    {
      "epoch": 0.3349151738047218,
      "grad_norm": 9.93811321258545,
      "learning_rate": 1.4779857632480887e-05,
      "loss": 0.4113,
      "step": 5646
    },
    {
      "epoch": 0.3349744928223989,
      "grad_norm": 16.69786834716797,
      "learning_rate": 1.4778539414711313e-05,
      "loss": 0.57,
      "step": 5647
    },
    {
      "epoch": 0.3350338118400759,
      "grad_norm": 0.039884768426418304,
      "learning_rate": 1.4777221196941735e-05,
      "loss": 0.0014,
      "step": 5648
    },
    {
      "epoch": 0.335093130857753,
      "grad_norm": 2.8336615562438965,
      "learning_rate": 1.4775902979172161e-05,
      "loss": 0.0606,
      "step": 5649
    },
    {
      "epoch": 0.3351524498754301,
      "grad_norm": 0.2656121253967285,
      "learning_rate": 1.4774584761402584e-05,
      "loss": 0.0034,
      "step": 5650
    },
    {
      "epoch": 0.3352117688931071,
      "grad_norm": 25.5152645111084,
      "learning_rate": 1.477326654363301e-05,
      "loss": 0.4046,
      "step": 5651
    },
    {
      "epoch": 0.3352710879107842,
      "grad_norm": 0.03390442207455635,
      "learning_rate": 1.4771948325863434e-05,
      "loss": 0.0007,
      "step": 5652
    },
    {
      "epoch": 0.3353304069284613,
      "grad_norm": 2.491236686706543,
      "learning_rate": 1.4770630108093858e-05,
      "loss": 0.1555,
      "step": 5653
    },
    {
      "epoch": 0.3353897259461383,
      "grad_norm": 0.6328257322311401,
      "learning_rate": 1.4769311890324282e-05,
      "loss": 0.0154,
      "step": 5654
    },
    {
      "epoch": 0.3354490449638154,
      "grad_norm": 0.09705734997987747,
      "learning_rate": 1.4767993672554708e-05,
      "loss": 0.0027,
      "step": 5655
    },
    {
      "epoch": 0.3355083639814925,
      "grad_norm": 0.23755910992622375,
      "learning_rate": 1.476667545478513e-05,
      "loss": 0.0038,
      "step": 5656
    },
    {
      "epoch": 0.33556768299916956,
      "grad_norm": 12.961894989013672,
      "learning_rate": 1.4765357237015557e-05,
      "loss": 0.0319,
      "step": 5657
    },
    {
      "epoch": 0.3356270020168466,
      "grad_norm": 0.0751177966594696,
      "learning_rate": 1.476403901924598e-05,
      "loss": 0.0022,
      "step": 5658
    },
    {
      "epoch": 0.33568632103452367,
      "grad_norm": 5.786700248718262,
      "learning_rate": 1.4762720801476405e-05,
      "loss": 0.2891,
      "step": 5659
    },
    {
      "epoch": 0.33574564005220076,
      "grad_norm": 15.920793533325195,
      "learning_rate": 1.4761402583706829e-05,
      "loss": 0.4105,
      "step": 5660
    },
    {
      "epoch": 0.3358049590698778,
      "grad_norm": 0.1731874793767929,
      "learning_rate": 1.4760084365937255e-05,
      "loss": 0.0032,
      "step": 5661
    },
    {
      "epoch": 0.33586427808755487,
      "grad_norm": 4.5471014976501465,
      "learning_rate": 1.4758766148167677e-05,
      "loss": 0.0997,
      "step": 5662
    },
    {
      "epoch": 0.33592359710523195,
      "grad_norm": 12.105998039245605,
      "learning_rate": 1.4757447930398103e-05,
      "loss": 0.5481,
      "step": 5663
    },
    {
      "epoch": 0.335982916122909,
      "grad_norm": 0.24308544397354126,
      "learning_rate": 1.4756129712628526e-05,
      "loss": 0.0026,
      "step": 5664
    },
    {
      "epoch": 0.33604223514058607,
      "grad_norm": 7.355139255523682,
      "learning_rate": 1.4754811494858952e-05,
      "loss": 0.0484,
      "step": 5665
    },
    {
      "epoch": 0.33610155415826315,
      "grad_norm": 0.010573385283350945,
      "learning_rate": 1.4753493277089378e-05,
      "loss": 0.0003,
      "step": 5666
    },
    {
      "epoch": 0.33616087317594023,
      "grad_norm": 0.755722165107727,
      "learning_rate": 1.47521750593198e-05,
      "loss": 0.0058,
      "step": 5667
    },
    {
      "epoch": 0.33622019219361726,
      "grad_norm": 17.42269515991211,
      "learning_rate": 1.4750856841550226e-05,
      "loss": 0.7748,
      "step": 5668
    },
    {
      "epoch": 0.33627951121129435,
      "grad_norm": 0.8065311908721924,
      "learning_rate": 1.474953862378065e-05,
      "loss": 0.0075,
      "step": 5669
    },
    {
      "epoch": 0.33633883022897143,
      "grad_norm": 9.787687301635742,
      "learning_rate": 1.4748220406011073e-05,
      "loss": 1.0382,
      "step": 5670
    },
    {
      "epoch": 0.33639814924664846,
      "grad_norm": 20.178651809692383,
      "learning_rate": 1.4746902188241499e-05,
      "loss": 0.8845,
      "step": 5671
    },
    {
      "epoch": 0.33645746826432554,
      "grad_norm": 29.983552932739258,
      "learning_rate": 1.4745583970471924e-05,
      "loss": 0.3223,
      "step": 5672
    },
    {
      "epoch": 0.3365167872820026,
      "grad_norm": 6.175131797790527,
      "learning_rate": 1.4744265752702347e-05,
      "loss": 0.4162,
      "step": 5673
    },
    {
      "epoch": 0.33657610629967966,
      "grad_norm": 0.023330075666308403,
      "learning_rate": 1.4742947534932773e-05,
      "loss": 0.0007,
      "step": 5674
    },
    {
      "epoch": 0.33663542531735674,
      "grad_norm": 67.19087982177734,
      "learning_rate": 1.4741629317163197e-05,
      "loss": 1.9298,
      "step": 5675
    },
    {
      "epoch": 0.3366947443350338,
      "grad_norm": 0.07055151462554932,
      "learning_rate": 1.4740311099393621e-05,
      "loss": 0.0015,
      "step": 5676
    },
    {
      "epoch": 0.33675406335271085,
      "grad_norm": 0.15075020492076874,
      "learning_rate": 1.4738992881624045e-05,
      "loss": 0.0017,
      "step": 5677
    },
    {
      "epoch": 0.33681338237038794,
      "grad_norm": 10.027236938476562,
      "learning_rate": 1.4737674663854471e-05,
      "loss": 0.298,
      "step": 5678
    },
    {
      "epoch": 0.336872701388065,
      "grad_norm": 6.122823238372803,
      "learning_rate": 1.4736356446084894e-05,
      "loss": 0.0275,
      "step": 5679
    },
    {
      "epoch": 0.3369320204057421,
      "grad_norm": 0.37529170513153076,
      "learning_rate": 1.473503822831532e-05,
      "loss": 0.0067,
      "step": 5680
    },
    {
      "epoch": 0.33699133942341913,
      "grad_norm": 49.715232849121094,
      "learning_rate": 1.4733720010545742e-05,
      "loss": 0.3064,
      "step": 5681
    },
    {
      "epoch": 0.3370506584410962,
      "grad_norm": 9.720638275146484,
      "learning_rate": 1.4732401792776168e-05,
      "loss": 0.6795,
      "step": 5682
    },
    {
      "epoch": 0.3371099774587733,
      "grad_norm": 0.011217115446925163,
      "learning_rate": 1.4731083575006592e-05,
      "loss": 0.0004,
      "step": 5683
    },
    {
      "epoch": 0.33716929647645033,
      "grad_norm": 0.4796227514743805,
      "learning_rate": 1.4729765357237016e-05,
      "loss": 0.004,
      "step": 5684
    },
    {
      "epoch": 0.3372286154941274,
      "grad_norm": 6.588440895080566,
      "learning_rate": 1.472844713946744e-05,
      "loss": 0.1024,
      "step": 5685
    },
    {
      "epoch": 0.3372879345118045,
      "grad_norm": 11.224428176879883,
      "learning_rate": 1.4727128921697866e-05,
      "loss": 0.2725,
      "step": 5686
    },
    {
      "epoch": 0.33734725352948153,
      "grad_norm": 1.576223611831665,
      "learning_rate": 1.4725810703928289e-05,
      "loss": 0.019,
      "step": 5687
    },
    {
      "epoch": 0.3374065725471586,
      "grad_norm": 0.09324145317077637,
      "learning_rate": 1.4724492486158715e-05,
      "loss": 0.0029,
      "step": 5688
    },
    {
      "epoch": 0.3374658915648357,
      "grad_norm": 20.60521697998047,
      "learning_rate": 1.472317426838914e-05,
      "loss": 0.1348,
      "step": 5689
    },
    {
      "epoch": 0.3375252105825128,
      "grad_norm": 7.246563911437988,
      "learning_rate": 1.4721856050619563e-05,
      "loss": 0.0465,
      "step": 5690
    },
    {
      "epoch": 0.3375845296001898,
      "grad_norm": 1.5913286209106445,
      "learning_rate": 1.4720537832849987e-05,
      "loss": 0.0477,
      "step": 5691
    },
    {
      "epoch": 0.3376438486178669,
      "grad_norm": 3.7479045391082764,
      "learning_rate": 1.4719219615080413e-05,
      "loss": 0.4558,
      "step": 5692
    },
    {
      "epoch": 0.337703167635544,
      "grad_norm": 0.5746440887451172,
      "learning_rate": 1.4717901397310836e-05,
      "loss": 0.0086,
      "step": 5693
    },
    {
      "epoch": 0.337762486653221,
      "grad_norm": 1.3976625204086304,
      "learning_rate": 1.4716583179541262e-05,
      "loss": 0.0081,
      "step": 5694
    },
    {
      "epoch": 0.3378218056708981,
      "grad_norm": 5.8183207511901855,
      "learning_rate": 1.4715264961771687e-05,
      "loss": 0.0789,
      "step": 5695
    },
    {
      "epoch": 0.3378811246885752,
      "grad_norm": 0.7652807235717773,
      "learning_rate": 1.471394674400211e-05,
      "loss": 0.0102,
      "step": 5696
    },
    {
      "epoch": 0.3379404437062522,
      "grad_norm": 2.198469400405884,
      "learning_rate": 1.4712628526232536e-05,
      "loss": 0.0184,
      "step": 5697
    },
    {
      "epoch": 0.3379997627239293,
      "grad_norm": 13.226839065551758,
      "learning_rate": 1.4711310308462958e-05,
      "loss": 0.163,
      "step": 5698
    },
    {
      "epoch": 0.33805908174160637,
      "grad_norm": 0.0729774609208107,
      "learning_rate": 1.4709992090693384e-05,
      "loss": 0.0011,
      "step": 5699
    },
    {
      "epoch": 0.3381184007592834,
      "grad_norm": 0.09887942671775818,
      "learning_rate": 1.4708673872923808e-05,
      "loss": 0.0017,
      "step": 5700
    },
    {
      "epoch": 0.3381777197769605,
      "grad_norm": 1.809967279434204,
      "learning_rate": 1.4707355655154233e-05,
      "loss": 0.0088,
      "step": 5701
    },
    {
      "epoch": 0.33823703879463757,
      "grad_norm": 7.654978275299072,
      "learning_rate": 1.4706037437384657e-05,
      "loss": 0.0302,
      "step": 5702
    },
    {
      "epoch": 0.33829635781231465,
      "grad_norm": 0.39056313037872314,
      "learning_rate": 1.4704719219615083e-05,
      "loss": 0.0046,
      "step": 5703
    },
    {
      "epoch": 0.3383556768299917,
      "grad_norm": 0.4721981883049011,
      "learning_rate": 1.4703401001845505e-05,
      "loss": 0.0069,
      "step": 5704
    },
    {
      "epoch": 0.33841499584766876,
      "grad_norm": 5.77716064453125,
      "learning_rate": 1.4702082784075931e-05,
      "loss": 0.1679,
      "step": 5705
    },
    {
      "epoch": 0.33847431486534585,
      "grad_norm": 0.03565330058336258,
      "learning_rate": 1.4700764566306355e-05,
      "loss": 0.001,
      "step": 5706
    },
    {
      "epoch": 0.3385336338830229,
      "grad_norm": 3.087661027908325,
      "learning_rate": 1.469944634853678e-05,
      "loss": 0.1118,
      "step": 5707
    },
    {
      "epoch": 0.33859295290069996,
      "grad_norm": 0.42690348625183105,
      "learning_rate": 1.4698128130767204e-05,
      "loss": 0.0074,
      "step": 5708
    },
    {
      "epoch": 0.33865227191837705,
      "grad_norm": 1.6730303764343262,
      "learning_rate": 1.469680991299763e-05,
      "loss": 0.0185,
      "step": 5709
    },
    {
      "epoch": 0.3387115909360541,
      "grad_norm": 0.8037707209587097,
      "learning_rate": 1.4695491695228052e-05,
      "loss": 0.0163,
      "step": 5710
    },
    {
      "epoch": 0.33877090995373116,
      "grad_norm": 13.569343566894531,
      "learning_rate": 1.4694173477458478e-05,
      "loss": 0.8889,
      "step": 5711
    },
    {
      "epoch": 0.33883022897140824,
      "grad_norm": 10.097837448120117,
      "learning_rate": 1.4692855259688904e-05,
      "loss": 0.2139,
      "step": 5712
    },
    {
      "epoch": 0.3388895479890853,
      "grad_norm": 1.069488763809204,
      "learning_rate": 1.4691537041919326e-05,
      "loss": 0.0186,
      "step": 5713
    },
    {
      "epoch": 0.33894886700676236,
      "grad_norm": 3.1348226070404053,
      "learning_rate": 1.469021882414975e-05,
      "loss": 0.0489,
      "step": 5714
    },
    {
      "epoch": 0.33900818602443944,
      "grad_norm": 0.07901953160762787,
      "learning_rate": 1.4688900606380175e-05,
      "loss": 0.0013,
      "step": 5715
    },
    {
      "epoch": 0.3390675050421165,
      "grad_norm": 20.148542404174805,
      "learning_rate": 1.4687582388610599e-05,
      "loss": 0.2537,
      "step": 5716
    },
    {
      "epoch": 0.33912682405979355,
      "grad_norm": 2.378265380859375,
      "learning_rate": 1.4686264170841025e-05,
      "loss": 0.0131,
      "step": 5717
    },
    {
      "epoch": 0.33918614307747064,
      "grad_norm": 17.520660400390625,
      "learning_rate": 1.4684945953071447e-05,
      "loss": 0.6682,
      "step": 5718
    },
    {
      "epoch": 0.3392454620951477,
      "grad_norm": 14.46899127960205,
      "learning_rate": 1.4683627735301873e-05,
      "loss": 0.4479,
      "step": 5719
    },
    {
      "epoch": 0.33930478111282475,
      "grad_norm": 0.20252373814582825,
      "learning_rate": 1.4682309517532299e-05,
      "loss": 0.0032,
      "step": 5720
    },
    {
      "epoch": 0.33936410013050183,
      "grad_norm": 18.403850555419922,
      "learning_rate": 1.4680991299762721e-05,
      "loss": 0.1517,
      "step": 5721
    },
    {
      "epoch": 0.3394234191481789,
      "grad_norm": 1.1042416095733643,
      "learning_rate": 1.4679673081993147e-05,
      "loss": 0.0077,
      "step": 5722
    },
    {
      "epoch": 0.33948273816585595,
      "grad_norm": 5.251873016357422,
      "learning_rate": 1.4678354864223571e-05,
      "loss": 0.1459,
      "step": 5723
    },
    {
      "epoch": 0.33954205718353303,
      "grad_norm": 1.8488144874572754,
      "learning_rate": 1.4677036646453996e-05,
      "loss": 0.0109,
      "step": 5724
    },
    {
      "epoch": 0.3396013762012101,
      "grad_norm": 0.2284121811389923,
      "learning_rate": 1.467571842868442e-05,
      "loss": 0.0044,
      "step": 5725
    },
    {
      "epoch": 0.3396606952188872,
      "grad_norm": 0.10558724403381348,
      "learning_rate": 1.4674400210914846e-05,
      "loss": 0.0017,
      "step": 5726
    },
    {
      "epoch": 0.3397200142365642,
      "grad_norm": 0.8130900263786316,
      "learning_rate": 1.4673081993145268e-05,
      "loss": 0.0081,
      "step": 5727
    },
    {
      "epoch": 0.3397793332542413,
      "grad_norm": 9.629157066345215,
      "learning_rate": 1.4671763775375694e-05,
      "loss": 0.2707,
      "step": 5728
    },
    {
      "epoch": 0.3398386522719184,
      "grad_norm": 0.3573014736175537,
      "learning_rate": 1.4670445557606117e-05,
      "loss": 0.0027,
      "step": 5729
    },
    {
      "epoch": 0.3398979712895954,
      "grad_norm": 0.21466690301895142,
      "learning_rate": 1.4669127339836542e-05,
      "loss": 0.0038,
      "step": 5730
    },
    {
      "epoch": 0.3399572903072725,
      "grad_norm": 9.309968948364258,
      "learning_rate": 1.4667809122066967e-05,
      "loss": 0.7045,
      "step": 5731
    },
    {
      "epoch": 0.3400166093249496,
      "grad_norm": 9.566117286682129,
      "learning_rate": 1.4666490904297391e-05,
      "loss": 0.2116,
      "step": 5732
    },
    {
      "epoch": 0.3400759283426266,
      "grad_norm": 0.010447226464748383,
      "learning_rate": 1.4665172686527815e-05,
      "loss": 0.0003,
      "step": 5733
    },
    {
      "epoch": 0.3401352473603037,
      "grad_norm": 3.8436269760131836,
      "learning_rate": 1.4663854468758241e-05,
      "loss": 0.0521,
      "step": 5734
    },
    {
      "epoch": 0.3401945663779808,
      "grad_norm": 4.9546895027160645,
      "learning_rate": 1.4662536250988663e-05,
      "loss": 0.0842,
      "step": 5735
    },
    {
      "epoch": 0.3402538853956579,
      "grad_norm": 0.5830106735229492,
      "learning_rate": 1.466121803321909e-05,
      "loss": 0.0047,
      "step": 5736
    },
    {
      "epoch": 0.3403132044133349,
      "grad_norm": 15.224742889404297,
      "learning_rate": 1.4659899815449513e-05,
      "loss": 0.7161,
      "step": 5737
    },
    {
      "epoch": 0.340372523431012,
      "grad_norm": 2.256357192993164,
      "learning_rate": 1.4658581597679938e-05,
      "loss": 0.0354,
      "step": 5738
    },
    {
      "epoch": 0.34043184244868907,
      "grad_norm": 0.07453392446041107,
      "learning_rate": 1.4657263379910362e-05,
      "loss": 0.0012,
      "step": 5739
    },
    {
      "epoch": 0.3404911614663661,
      "grad_norm": 1.5024975538253784,
      "learning_rate": 1.4655945162140788e-05,
      "loss": 0.0623,
      "step": 5740
    },
    {
      "epoch": 0.3405504804840432,
      "grad_norm": 5.3548784255981445,
      "learning_rate": 1.465462694437121e-05,
      "loss": 0.1234,
      "step": 5741
    },
    {
      "epoch": 0.34060979950172027,
      "grad_norm": 0.07746774703264236,
      "learning_rate": 1.4653308726601636e-05,
      "loss": 0.0014,
      "step": 5742
    },
    {
      "epoch": 0.3406691185193973,
      "grad_norm": 10.11115837097168,
      "learning_rate": 1.4651990508832062e-05,
      "loss": 0.1323,
      "step": 5743
    },
    {
      "epoch": 0.3407284375370744,
      "grad_norm": 4.075381755828857,
      "learning_rate": 1.4650672291062484e-05,
      "loss": 0.0763,
      "step": 5744
    },
    {
      "epoch": 0.34078775655475146,
      "grad_norm": 22.589704513549805,
      "learning_rate": 1.464935407329291e-05,
      "loss": 0.2203,
      "step": 5745
    },
    {
      "epoch": 0.3408470755724285,
      "grad_norm": 24.38426971435547,
      "learning_rate": 1.4648035855523333e-05,
      "loss": 0.5016,
      "step": 5746
    },
    {
      "epoch": 0.3409063945901056,
      "grad_norm": 3.2572450637817383,
      "learning_rate": 1.4646717637753757e-05,
      "loss": 0.0221,
      "step": 5747
    },
    {
      "epoch": 0.34096571360778266,
      "grad_norm": 10.18366527557373,
      "learning_rate": 1.4645399419984183e-05,
      "loss": 0.3818,
      "step": 5748
    },
    {
      "epoch": 0.34102503262545975,
      "grad_norm": 8.381271362304688,
      "learning_rate": 1.4644081202214605e-05,
      "loss": 0.0194,
      "step": 5749
    },
    {
      "epoch": 0.3410843516431368,
      "grad_norm": 0.3124030530452728,
      "learning_rate": 1.4642762984445031e-05,
      "loss": 0.0013,
      "step": 5750
    },
    {
      "epoch": 0.34114367066081386,
      "grad_norm": 0.18308083713054657,
      "learning_rate": 1.4641444766675457e-05,
      "loss": 0.0028,
      "step": 5751
    },
    {
      "epoch": 0.34120298967849094,
      "grad_norm": 0.9664117693901062,
      "learning_rate": 1.464012654890588e-05,
      "loss": 0.0054,
      "step": 5752
    },
    {
      "epoch": 0.34126230869616797,
      "grad_norm": 1.668818473815918,
      "learning_rate": 1.4638808331136306e-05,
      "loss": 0.0291,
      "step": 5753
    },
    {
      "epoch": 0.34132162771384505,
      "grad_norm": 0.16082803905010223,
      "learning_rate": 1.463749011336673e-05,
      "loss": 0.0022,
      "step": 5754
    },
    {
      "epoch": 0.34138094673152214,
      "grad_norm": 8.39241886138916,
      "learning_rate": 1.4636171895597154e-05,
      "loss": 1.034,
      "step": 5755
    },
    {
      "epoch": 0.34144026574919917,
      "grad_norm": 0.13097834587097168,
      "learning_rate": 1.4634853677827578e-05,
      "loss": 0.0009,
      "step": 5756
    },
    {
      "epoch": 0.34149958476687625,
      "grad_norm": 0.0791439563035965,
      "learning_rate": 1.4633535460058004e-05,
      "loss": 0.0011,
      "step": 5757
    },
    {
      "epoch": 0.34155890378455334,
      "grad_norm": 3.4687182903289795,
      "learning_rate": 1.4632217242288427e-05,
      "loss": 0.0591,
      "step": 5758
    },
    {
      "epoch": 0.3416182228022304,
      "grad_norm": 7.745105743408203,
      "learning_rate": 1.4630899024518852e-05,
      "loss": 0.5707,
      "step": 5759
    },
    {
      "epoch": 0.34167754181990745,
      "grad_norm": 15.303570747375488,
      "learning_rate": 1.4629580806749277e-05,
      "loss": 0.825,
      "step": 5760
    },
    {
      "epoch": 0.34173686083758453,
      "grad_norm": 0.9087395668029785,
      "learning_rate": 1.46282625889797e-05,
      "loss": 0.0189,
      "step": 5761
    },
    {
      "epoch": 0.3417961798552616,
      "grad_norm": 5.621950149536133,
      "learning_rate": 1.4626944371210125e-05,
      "loss": 0.3875,
      "step": 5762
    },
    {
      "epoch": 0.34185549887293865,
      "grad_norm": 0.019623832777142525,
      "learning_rate": 1.4625626153440549e-05,
      "loss": 0.0005,
      "step": 5763
    },
    {
      "epoch": 0.34191481789061573,
      "grad_norm": 4.848268508911133,
      "learning_rate": 1.4624307935670973e-05,
      "loss": 0.169,
      "step": 5764
    },
    {
      "epoch": 0.3419741369082928,
      "grad_norm": 0.03940875083208084,
      "learning_rate": 1.46229897179014e-05,
      "loss": 0.0007,
      "step": 5765
    },
    {
      "epoch": 0.34203345592596984,
      "grad_norm": 0.12740986049175262,
      "learning_rate": 1.4621671500131822e-05,
      "loss": 0.0039,
      "step": 5766
    },
    {
      "epoch": 0.3420927749436469,
      "grad_norm": 12.33265209197998,
      "learning_rate": 1.4620353282362248e-05,
      "loss": 0.1794,
      "step": 5767
    },
    {
      "epoch": 0.342152093961324,
      "grad_norm": 15.525840759277344,
      "learning_rate": 1.4619035064592673e-05,
      "loss": 0.6031,
      "step": 5768
    },
    {
      "epoch": 0.3422114129790011,
      "grad_norm": 17.004655838012695,
      "learning_rate": 1.4617716846823096e-05,
      "loss": 0.3525,
      "step": 5769
    },
    {
      "epoch": 0.3422707319966781,
      "grad_norm": 0.7646604180335999,
      "learning_rate": 1.461639862905352e-05,
      "loss": 0.0103,
      "step": 5770
    },
    {
      "epoch": 0.3423300510143552,
      "grad_norm": 15.301191329956055,
      "learning_rate": 1.4615080411283946e-05,
      "loss": 0.1839,
      "step": 5771
    },
    {
      "epoch": 0.3423893700320323,
      "grad_norm": 7.60427188873291,
      "learning_rate": 1.4613762193514369e-05,
      "loss": 0.0932,
      "step": 5772
    },
    {
      "epoch": 0.3424486890497093,
      "grad_norm": 0.027811650186777115,
      "learning_rate": 1.4612443975744794e-05,
      "loss": 0.0007,
      "step": 5773
    },
    {
      "epoch": 0.3425080080673864,
      "grad_norm": 1.9475418329238892,
      "learning_rate": 1.461112575797522e-05,
      "loss": 0.0165,
      "step": 5774
    },
    {
      "epoch": 0.3425673270850635,
      "grad_norm": 13.29499340057373,
      "learning_rate": 1.4609807540205643e-05,
      "loss": 0.3808,
      "step": 5775
    },
    {
      "epoch": 0.3426266461027405,
      "grad_norm": 0.2867099344730377,
      "learning_rate": 1.4608489322436069e-05,
      "loss": 0.0064,
      "step": 5776
    },
    {
      "epoch": 0.3426859651204176,
      "grad_norm": 0.2409810870885849,
      "learning_rate": 1.4607171104666491e-05,
      "loss": 0.004,
      "step": 5777
    },
    {
      "epoch": 0.3427452841380947,
      "grad_norm": 0.024867955595254898,
      "learning_rate": 1.4605852886896917e-05,
      "loss": 0.0008,
      "step": 5778
    },
    {
      "epoch": 0.3428046031557717,
      "grad_norm": 0.20758773386478424,
      "learning_rate": 1.4604534669127341e-05,
      "loss": 0.0033,
      "step": 5779
    },
    {
      "epoch": 0.3428639221734488,
      "grad_norm": 0.07957550138235092,
      "learning_rate": 1.4603216451357765e-05,
      "loss": 0.0014,
      "step": 5780
    },
    {
      "epoch": 0.3429232411911259,
      "grad_norm": 3.8154430389404297,
      "learning_rate": 1.460189823358819e-05,
      "loss": 0.0377,
      "step": 5781
    },
    {
      "epoch": 0.34298256020880297,
      "grad_norm": 3.084197998046875,
      "learning_rate": 1.4600580015818615e-05,
      "loss": 0.0673,
      "step": 5782
    },
    {
      "epoch": 0.34304187922648,
      "grad_norm": 0.30249983072280884,
      "learning_rate": 1.4599261798049038e-05,
      "loss": 0.0053,
      "step": 5783
    },
    {
      "epoch": 0.3431011982441571,
      "grad_norm": 5.254010200500488,
      "learning_rate": 1.4597943580279464e-05,
      "loss": 0.023,
      "step": 5784
    },
    {
      "epoch": 0.34316051726183416,
      "grad_norm": 2.575061798095703,
      "learning_rate": 1.4596625362509888e-05,
      "loss": 0.2853,
      "step": 5785
    },
    {
      "epoch": 0.3432198362795112,
      "grad_norm": 1.2001819610595703,
      "learning_rate": 1.4595307144740312e-05,
      "loss": 0.0195,
      "step": 5786
    },
    {
      "epoch": 0.3432791552971883,
      "grad_norm": 0.03909962251782417,
      "learning_rate": 1.4593988926970736e-05,
      "loss": 0.0008,
      "step": 5787
    },
    {
      "epoch": 0.34333847431486536,
      "grad_norm": 0.3756909668445587,
      "learning_rate": 1.4592670709201162e-05,
      "loss": 0.0068,
      "step": 5788
    },
    {
      "epoch": 0.3433977933325424,
      "grad_norm": 9.702836036682129,
      "learning_rate": 1.4591352491431585e-05,
      "loss": 0.4457,
      "step": 5789
    },
    {
      "epoch": 0.3434571123502195,
      "grad_norm": 0.26627954840660095,
      "learning_rate": 1.459003427366201e-05,
      "loss": 0.0061,
      "step": 5790
    },
    {
      "epoch": 0.34351643136789656,
      "grad_norm": 5.394385814666748,
      "learning_rate": 1.4588716055892435e-05,
      "loss": 0.0668,
      "step": 5791
    },
    {
      "epoch": 0.34357575038557364,
      "grad_norm": 0.22664576768875122,
      "learning_rate": 1.4587397838122859e-05,
      "loss": 0.0021,
      "step": 5792
    },
    {
      "epoch": 0.34363506940325067,
      "grad_norm": 13.105684280395508,
      "learning_rate": 1.4586079620353283e-05,
      "loss": 0.2621,
      "step": 5793
    },
    {
      "epoch": 0.34369438842092775,
      "grad_norm": 2.7191154956817627,
      "learning_rate": 1.4584761402583707e-05,
      "loss": 0.0326,
      "step": 5794
    },
    {
      "epoch": 0.34375370743860484,
      "grad_norm": 1.5996198654174805,
      "learning_rate": 1.4583443184814132e-05,
      "loss": 0.0184,
      "step": 5795
    },
    {
      "epoch": 0.34381302645628187,
      "grad_norm": 0.04363605007529259,
      "learning_rate": 1.4582124967044557e-05,
      "loss": 0.0009,
      "step": 5796
    },
    {
      "epoch": 0.34387234547395895,
      "grad_norm": 8.835001945495605,
      "learning_rate": 1.458080674927498e-05,
      "loss": 0.5394,
      "step": 5797
    },
    {
      "epoch": 0.34393166449163604,
      "grad_norm": 0.522350549697876,
      "learning_rate": 1.4579488531505406e-05,
      "loss": 0.0069,
      "step": 5798
    },
    {
      "epoch": 0.34399098350931306,
      "grad_norm": 5.644120216369629,
      "learning_rate": 1.4578170313735832e-05,
      "loss": 0.3924,
      "step": 5799
    },
    {
      "epoch": 0.34405030252699015,
      "grad_norm": 0.11697706580162048,
      "learning_rate": 1.4576852095966254e-05,
      "loss": 0.0016,
      "step": 5800
    },
    {
      "epoch": 0.34410962154466723,
      "grad_norm": 0.8608781099319458,
      "learning_rate": 1.457553387819668e-05,
      "loss": 0.008,
      "step": 5801
    },
    {
      "epoch": 0.34416894056234426,
      "grad_norm": 24.77727508544922,
      "learning_rate": 1.4574215660427104e-05,
      "loss": 0.7515,
      "step": 5802
    },
    {
      "epoch": 0.34422825958002135,
      "grad_norm": 40.25728988647461,
      "learning_rate": 1.4572897442657527e-05,
      "loss": 0.8373,
      "step": 5803
    },
    {
      "epoch": 0.34428757859769843,
      "grad_norm": 0.7134180068969727,
      "learning_rate": 1.4571579224887953e-05,
      "loss": 0.0119,
      "step": 5804
    },
    {
      "epoch": 0.3443468976153755,
      "grad_norm": 0.09043850004673004,
      "learning_rate": 1.4570261007118379e-05,
      "loss": 0.0018,
      "step": 5805
    },
    {
      "epoch": 0.34440621663305254,
      "grad_norm": 6.561233997344971,
      "learning_rate": 1.4568942789348801e-05,
      "loss": 0.0727,
      "step": 5806
    },
    {
      "epoch": 0.3444655356507296,
      "grad_norm": 5.756687164306641,
      "learning_rate": 1.4567624571579227e-05,
      "loss": 0.2015,
      "step": 5807
    },
    {
      "epoch": 0.3445248546684067,
      "grad_norm": 0.07837065309286118,
      "learning_rate": 1.4566306353809651e-05,
      "loss": 0.0011,
      "step": 5808
    },
    {
      "epoch": 0.34458417368608374,
      "grad_norm": 0.45227497816085815,
      "learning_rate": 1.4564988136040075e-05,
      "loss": 0.0063,
      "step": 5809
    },
    {
      "epoch": 0.3446434927037608,
      "grad_norm": 6.569143772125244,
      "learning_rate": 1.45636699182705e-05,
      "loss": 0.1773,
      "step": 5810
    },
    {
      "epoch": 0.3447028117214379,
      "grad_norm": 0.05641082301735878,
      "learning_rate": 1.4562351700500924e-05,
      "loss": 0.0013,
      "step": 5811
    },
    {
      "epoch": 0.34476213073911494,
      "grad_norm": 0.029478389769792557,
      "learning_rate": 1.4561033482731348e-05,
      "loss": 0.0006,
      "step": 5812
    },
    {
      "epoch": 0.344821449756792,
      "grad_norm": 7.307693958282471,
      "learning_rate": 1.4559715264961774e-05,
      "loss": 0.083,
      "step": 5813
    },
    {
      "epoch": 0.3448807687744691,
      "grad_norm": 0.1391567587852478,
      "learning_rate": 1.4558397047192196e-05,
      "loss": 0.0027,
      "step": 5814
    },
    {
      "epoch": 0.3449400877921462,
      "grad_norm": 4.5369157791137695,
      "learning_rate": 1.4557078829422622e-05,
      "loss": 0.0765,
      "step": 5815
    },
    {
      "epoch": 0.3449994068098232,
      "grad_norm": 0.06849799305200577,
      "learning_rate": 1.4555760611653046e-05,
      "loss": 0.0016,
      "step": 5816
    },
    {
      "epoch": 0.3450587258275003,
      "grad_norm": 2.6950571537017822,
      "learning_rate": 1.455444239388347e-05,
      "loss": 0.0159,
      "step": 5817
    },
    {
      "epoch": 0.3451180448451774,
      "grad_norm": 7.4512739181518555,
      "learning_rate": 1.4553124176113895e-05,
      "loss": 0.1749,
      "step": 5818
    },
    {
      "epoch": 0.3451773638628544,
      "grad_norm": 4.872638702392578,
      "learning_rate": 1.455180595834432e-05,
      "loss": 0.0957,
      "step": 5819
    },
    {
      "epoch": 0.3452366828805315,
      "grad_norm": 4.2282209396362305,
      "learning_rate": 1.4550487740574743e-05,
      "loss": 0.052,
      "step": 5820
    },
    {
      "epoch": 0.3452960018982086,
      "grad_norm": 8.505729675292969,
      "learning_rate": 1.4549169522805169e-05,
      "loss": 0.2582,
      "step": 5821
    },
    {
      "epoch": 0.3453553209158856,
      "grad_norm": 4.421701431274414,
      "learning_rate": 1.4547851305035595e-05,
      "loss": 0.1174,
      "step": 5822
    },
    {
      "epoch": 0.3454146399335627,
      "grad_norm": 0.0164949931204319,
      "learning_rate": 1.4546533087266017e-05,
      "loss": 0.0005,
      "step": 5823
    },
    {
      "epoch": 0.3454739589512398,
      "grad_norm": 1.8891857862472534,
      "learning_rate": 1.4545214869496443e-05,
      "loss": 0.0137,
      "step": 5824
    },
    {
      "epoch": 0.3455332779689168,
      "grad_norm": 2.8420488834381104,
      "learning_rate": 1.4543896651726866e-05,
      "loss": 0.0205,
      "step": 5825
    },
    {
      "epoch": 0.3455925969865939,
      "grad_norm": 0.6908156871795654,
      "learning_rate": 1.454257843395729e-05,
      "loss": 0.0162,
      "step": 5826
    },
    {
      "epoch": 0.345651916004271,
      "grad_norm": 0.4124421775341034,
      "learning_rate": 1.4541260216187716e-05,
      "loss": 0.0041,
      "step": 5827
    },
    {
      "epoch": 0.34571123502194806,
      "grad_norm": 25.458301544189453,
      "learning_rate": 1.4539941998418138e-05,
      "loss": 0.3083,
      "step": 5828
    },
    {
      "epoch": 0.3457705540396251,
      "grad_norm": 6.400030136108398,
      "learning_rate": 1.4538623780648564e-05,
      "loss": 0.2328,
      "step": 5829
    },
    {
      "epoch": 0.3458298730573022,
      "grad_norm": 0.015093617141246796,
      "learning_rate": 1.453730556287899e-05,
      "loss": 0.0004,
      "step": 5830
    },
    {
      "epoch": 0.34588919207497926,
      "grad_norm": 16.224895477294922,
      "learning_rate": 1.4535987345109412e-05,
      "loss": 0.3766,
      "step": 5831
    },
    {
      "epoch": 0.3459485110926563,
      "grad_norm": 0.4702633321285248,
      "learning_rate": 1.4534669127339838e-05,
      "loss": 0.0055,
      "step": 5832
    },
    {
      "epoch": 0.34600783011033337,
      "grad_norm": 0.0073700351640582085,
      "learning_rate": 1.4533350909570263e-05,
      "loss": 0.0003,
      "step": 5833
    },
    {
      "epoch": 0.34606714912801045,
      "grad_norm": 2.909510612487793,
      "learning_rate": 1.4532032691800687e-05,
      "loss": 0.1918,
      "step": 5834
    },
    {
      "epoch": 0.3461264681456875,
      "grad_norm": 0.5016974806785583,
      "learning_rate": 1.4530714474031111e-05,
      "loss": 0.0094,
      "step": 5835
    },
    {
      "epoch": 0.34618578716336457,
      "grad_norm": 1.9486181735992432,
      "learning_rate": 1.4529396256261537e-05,
      "loss": 0.0274,
      "step": 5836
    },
    {
      "epoch": 0.34624510618104165,
      "grad_norm": 3.5060346126556396,
      "learning_rate": 1.452807803849196e-05,
      "loss": 0.281,
      "step": 5837
    },
    {
      "epoch": 0.34630442519871873,
      "grad_norm": 0.23106619715690613,
      "learning_rate": 1.4526759820722385e-05,
      "loss": 0.0034,
      "step": 5838
    },
    {
      "epoch": 0.34636374421639576,
      "grad_norm": 1.5767687559127808,
      "learning_rate": 1.452544160295281e-05,
      "loss": 0.0206,
      "step": 5839
    },
    {
      "epoch": 0.34642306323407285,
      "grad_norm": 1.8513532876968384,
      "learning_rate": 1.4524123385183234e-05,
      "loss": 0.0273,
      "step": 5840
    },
    {
      "epoch": 0.34648238225174993,
      "grad_norm": 0.5100567936897278,
      "learning_rate": 1.4522805167413658e-05,
      "loss": 0.0057,
      "step": 5841
    },
    {
      "epoch": 0.34654170126942696,
      "grad_norm": 2.760784864425659,
      "learning_rate": 1.4521486949644082e-05,
      "loss": 0.0272,
      "step": 5842
    },
    {
      "epoch": 0.34660102028710404,
      "grad_norm": 11.470295906066895,
      "learning_rate": 1.4520168731874506e-05,
      "loss": 0.2043,
      "step": 5843
    },
    {
      "epoch": 0.34666033930478113,
      "grad_norm": 4.343212604522705,
      "learning_rate": 1.4518850514104932e-05,
      "loss": 0.0445,
      "step": 5844
    },
    {
      "epoch": 0.34671965832245816,
      "grad_norm": 2.1578428745269775,
      "learning_rate": 1.4517532296335355e-05,
      "loss": 0.0382,
      "step": 5845
    },
    {
      "epoch": 0.34677897734013524,
      "grad_norm": 1.2341102361679077,
      "learning_rate": 1.451621407856578e-05,
      "loss": 0.0169,
      "step": 5846
    },
    {
      "epoch": 0.3468382963578123,
      "grad_norm": 7.778809070587158,
      "learning_rate": 1.4514895860796205e-05,
      "loss": 0.0381,
      "step": 5847
    },
    {
      "epoch": 0.34689761537548935,
      "grad_norm": 1.4086235761642456,
      "learning_rate": 1.4513577643026629e-05,
      "loss": 0.0125,
      "step": 5848
    },
    {
      "epoch": 0.34695693439316644,
      "grad_norm": 0.09270632266998291,
      "learning_rate": 1.4512259425257053e-05,
      "loss": 0.0019,
      "step": 5849
    },
    {
      "epoch": 0.3470162534108435,
      "grad_norm": 7.043906211853027,
      "learning_rate": 1.4510941207487479e-05,
      "loss": 0.5132,
      "step": 5850
    },
    {
      "epoch": 0.3470755724285206,
      "grad_norm": 19.948652267456055,
      "learning_rate": 1.4509622989717901e-05,
      "loss": 0.3447,
      "step": 5851
    },
    {
      "epoch": 0.34713489144619764,
      "grad_norm": 1.9144648313522339,
      "learning_rate": 1.4508304771948327e-05,
      "loss": 0.0254,
      "step": 5852
    },
    {
      "epoch": 0.3471942104638747,
      "grad_norm": 0.07596991211175919,
      "learning_rate": 1.4506986554178753e-05,
      "loss": 0.0017,
      "step": 5853
    },
    {
      "epoch": 0.3472535294815518,
      "grad_norm": 2.3971598148345947,
      "learning_rate": 1.4505668336409176e-05,
      "loss": 0.0417,
      "step": 5854
    },
    {
      "epoch": 0.34731284849922883,
      "grad_norm": 61.653079986572266,
      "learning_rate": 1.4504350118639601e-05,
      "loss": 0.6379,
      "step": 5855
    },
    {
      "epoch": 0.3473721675169059,
      "grad_norm": 0.9883148670196533,
      "learning_rate": 1.4503031900870026e-05,
      "loss": 0.0057,
      "step": 5856
    },
    {
      "epoch": 0.347431486534583,
      "grad_norm": 5.642002105712891,
      "learning_rate": 1.450171368310045e-05,
      "loss": 0.1002,
      "step": 5857
    },
    {
      "epoch": 0.34749080555226003,
      "grad_norm": 6.844995975494385,
      "learning_rate": 1.4500395465330874e-05,
      "loss": 0.1096,
      "step": 5858
    },
    {
      "epoch": 0.3475501245699371,
      "grad_norm": 0.013116450980305672,
      "learning_rate": 1.4499077247561297e-05,
      "loss": 0.0005,
      "step": 5859
    },
    {
      "epoch": 0.3476094435876142,
      "grad_norm": 2.3584682941436768,
      "learning_rate": 1.4497759029791722e-05,
      "loss": 0.0458,
      "step": 5860
    },
    {
      "epoch": 0.3476687626052913,
      "grad_norm": 22.493587493896484,
      "learning_rate": 1.4496440812022148e-05,
      "loss": 0.4672,
      "step": 5861
    },
    {
      "epoch": 0.3477280816229683,
      "grad_norm": 0.04223070293664932,
      "learning_rate": 1.449512259425257e-05,
      "loss": 0.0009,
      "step": 5862
    },
    {
      "epoch": 0.3477874006406454,
      "grad_norm": 4.25413703918457,
      "learning_rate": 1.4493804376482997e-05,
      "loss": 0.1266,
      "step": 5863
    },
    {
      "epoch": 0.3478467196583225,
      "grad_norm": 0.11084084212779999,
      "learning_rate": 1.449248615871342e-05,
      "loss": 0.0015,
      "step": 5864
    },
    {
      "epoch": 0.3479060386759995,
      "grad_norm": 0.014888700097799301,
      "learning_rate": 1.4491167940943845e-05,
      "loss": 0.0004,
      "step": 5865
    },
    {
      "epoch": 0.3479653576936766,
      "grad_norm": 0.054444801062345505,
      "learning_rate": 1.448984972317427e-05,
      "loss": 0.0012,
      "step": 5866
    },
    {
      "epoch": 0.3480246767113537,
      "grad_norm": 0.08590445667505264,
      "learning_rate": 1.4488531505404695e-05,
      "loss": 0.0022,
      "step": 5867
    },
    {
      "epoch": 0.3480839957290307,
      "grad_norm": 8.677145957946777,
      "learning_rate": 1.4487213287635118e-05,
      "loss": 0.1675,
      "step": 5868
    },
    {
      "epoch": 0.3481433147467078,
      "grad_norm": 11.225685119628906,
      "learning_rate": 1.4485895069865543e-05,
      "loss": 0.3406,
      "step": 5869
    },
    {
      "epoch": 0.3482026337643849,
      "grad_norm": 0.013448026031255722,
      "learning_rate": 1.4484576852095968e-05,
      "loss": 0.0004,
      "step": 5870
    },
    {
      "epoch": 0.34826195278206196,
      "grad_norm": 0.22194097936153412,
      "learning_rate": 1.4483258634326392e-05,
      "loss": 0.002,
      "step": 5871
    },
    {
      "epoch": 0.348321271799739,
      "grad_norm": 10.382987022399902,
      "learning_rate": 1.4481940416556816e-05,
      "loss": 0.2344,
      "step": 5872
    },
    {
      "epoch": 0.34838059081741607,
      "grad_norm": 0.1860702484846115,
      "learning_rate": 1.448062219878724e-05,
      "loss": 0.0025,
      "step": 5873
    },
    {
      "epoch": 0.34843990983509315,
      "grad_norm": 16.11174964904785,
      "learning_rate": 1.4479303981017664e-05,
      "loss": 0.2739,
      "step": 5874
    },
    {
      "epoch": 0.3484992288527702,
      "grad_norm": 13.37156867980957,
      "learning_rate": 1.447798576324809e-05,
      "loss": 0.3098,
      "step": 5875
    },
    {
      "epoch": 0.34855854787044727,
      "grad_norm": 0.09587317705154419,
      "learning_rate": 1.4476667545478513e-05,
      "loss": 0.0017,
      "step": 5876
    },
    {
      "epoch": 0.34861786688812435,
      "grad_norm": 0.3275981843471527,
      "learning_rate": 1.4475349327708939e-05,
      "loss": 0.0049,
      "step": 5877
    },
    {
      "epoch": 0.3486771859058014,
      "grad_norm": 0.2187338024377823,
      "learning_rate": 1.4474031109939365e-05,
      "loss": 0.0031,
      "step": 5878
    },
    {
      "epoch": 0.34873650492347846,
      "grad_norm": 9.346200942993164,
      "learning_rate": 1.4472712892169787e-05,
      "loss": 0.4749,
      "step": 5879
    },
    {
      "epoch": 0.34879582394115555,
      "grad_norm": 17.105493545532227,
      "learning_rate": 1.4471394674400213e-05,
      "loss": 0.2133,
      "step": 5880
    },
    {
      "epoch": 0.3488551429588326,
      "grad_norm": 7.52554178237915,
      "learning_rate": 1.4470076456630637e-05,
      "loss": 0.2353,
      "step": 5881
    },
    {
      "epoch": 0.34891446197650966,
      "grad_norm": 4.877655506134033,
      "learning_rate": 1.446875823886106e-05,
      "loss": 0.0943,
      "step": 5882
    },
    {
      "epoch": 0.34897378099418674,
      "grad_norm": 5.087045192718506,
      "learning_rate": 1.4467440021091485e-05,
      "loss": 0.2669,
      "step": 5883
    },
    {
      "epoch": 0.34903310001186383,
      "grad_norm": 0.014103129506111145,
      "learning_rate": 1.4466121803321911e-05,
      "loss": 0.0004,
      "step": 5884
    },
    {
      "epoch": 0.34909241902954086,
      "grad_norm": 3.1357603073120117,
      "learning_rate": 1.4464803585552334e-05,
      "loss": 0.0626,
      "step": 5885
    },
    {
      "epoch": 0.34915173804721794,
      "grad_norm": 10.586702346801758,
      "learning_rate": 1.446348536778276e-05,
      "loss": 0.6326,
      "step": 5886
    },
    {
      "epoch": 0.349211057064895,
      "grad_norm": 2.9862208366394043,
      "learning_rate": 1.4462167150013184e-05,
      "loss": 0.0889,
      "step": 5887
    },
    {
      "epoch": 0.34927037608257205,
      "grad_norm": 1.7537288665771484,
      "learning_rate": 1.4460848932243608e-05,
      "loss": 0.015,
      "step": 5888
    },
    {
      "epoch": 0.34932969510024914,
      "grad_norm": 1.769141674041748,
      "learning_rate": 1.4459530714474032e-05,
      "loss": 0.0201,
      "step": 5889
    },
    {
      "epoch": 0.3493890141179262,
      "grad_norm": 0.013388363644480705,
      "learning_rate": 1.4458212496704456e-05,
      "loss": 0.0004,
      "step": 5890
    },
    {
      "epoch": 0.34944833313560325,
      "grad_norm": 0.03559510037302971,
      "learning_rate": 1.445689427893488e-05,
      "loss": 0.0007,
      "step": 5891
    },
    {
      "epoch": 0.34950765215328033,
      "grad_norm": 3.5308282375335693,
      "learning_rate": 1.4455576061165307e-05,
      "loss": 0.0444,
      "step": 5892
    },
    {
      "epoch": 0.3495669711709574,
      "grad_norm": 8.07848072052002,
      "learning_rate": 1.4454257843395729e-05,
      "loss": 0.0634,
      "step": 5893
    },
    {
      "epoch": 0.3496262901886345,
      "grad_norm": 22.276193618774414,
      "learning_rate": 1.4452939625626155e-05,
      "loss": 0.913,
      "step": 5894
    },
    {
      "epoch": 0.34968560920631153,
      "grad_norm": 5.7544264793396,
      "learning_rate": 1.4451621407856579e-05,
      "loss": 0.154,
      "step": 5895
    },
    {
      "epoch": 0.3497449282239886,
      "grad_norm": 0.009912383742630482,
      "learning_rate": 1.4450303190087003e-05,
      "loss": 0.0003,
      "step": 5896
    },
    {
      "epoch": 0.3498042472416657,
      "grad_norm": 5.001615524291992,
      "learning_rate": 1.4448984972317427e-05,
      "loss": 0.2398,
      "step": 5897
    },
    {
      "epoch": 0.34986356625934273,
      "grad_norm": 26.147541046142578,
      "learning_rate": 1.4447666754547853e-05,
      "loss": 0.5679,
      "step": 5898
    },
    {
      "epoch": 0.3499228852770198,
      "grad_norm": 11.239909172058105,
      "learning_rate": 1.4446348536778276e-05,
      "loss": 0.6579,
      "step": 5899
    },
    {
      "epoch": 0.3499822042946969,
      "grad_norm": 24.511995315551758,
      "learning_rate": 1.4445030319008702e-05,
      "loss": 0.4498,
      "step": 5900
    },
    {
      "epoch": 0.3500415233123739,
      "grad_norm": 0.19408917427062988,
      "learning_rate": 1.4443712101239128e-05,
      "loss": 0.0028,
      "step": 5901
    },
    {
      "epoch": 0.350100842330051,
      "grad_norm": 0.14690375328063965,
      "learning_rate": 1.444239388346955e-05,
      "loss": 0.0032,
      "step": 5902
    },
    {
      "epoch": 0.3501601613477281,
      "grad_norm": 0.08904270827770233,
      "learning_rate": 1.4441075665699974e-05,
      "loss": 0.0018,
      "step": 5903
    },
    {
      "epoch": 0.3502194803654051,
      "grad_norm": 11.320941925048828,
      "learning_rate": 1.44397574479304e-05,
      "loss": 0.1817,
      "step": 5904
    },
    {
      "epoch": 0.3502787993830822,
      "grad_norm": 3.3183233737945557,
      "learning_rate": 1.4438439230160823e-05,
      "loss": 0.0542,
      "step": 5905
    },
    {
      "epoch": 0.3503381184007593,
      "grad_norm": 18.08686065673828,
      "learning_rate": 1.4437121012391249e-05,
      "loss": 0.5049,
      "step": 5906
    },
    {
      "epoch": 0.3503974374184364,
      "grad_norm": 0.024770643562078476,
      "learning_rate": 1.4435802794621671e-05,
      "loss": 0.0005,
      "step": 5907
    },
    {
      "epoch": 0.3504567564361134,
      "grad_norm": 4.613832950592041,
      "learning_rate": 1.4434484576852097e-05,
      "loss": 0.0659,
      "step": 5908
    },
    {
      "epoch": 0.3505160754537905,
      "grad_norm": 9.073829650878906,
      "learning_rate": 1.4433166359082523e-05,
      "loss": 0.0301,
      "step": 5909
    },
    {
      "epoch": 0.35057539447146757,
      "grad_norm": 13.73071002960205,
      "learning_rate": 1.4431848141312945e-05,
      "loss": 0.136,
      "step": 5910
    },
    {
      "epoch": 0.3506347134891446,
      "grad_norm": 19.493297576904297,
      "learning_rate": 1.4430529923543371e-05,
      "loss": 0.1962,
      "step": 5911
    },
    {
      "epoch": 0.3506940325068217,
      "grad_norm": 1.9586492776870728,
      "learning_rate": 1.4429211705773795e-05,
      "loss": 0.0403,
      "step": 5912
    },
    {
      "epoch": 0.35075335152449877,
      "grad_norm": 1.5378419160842896,
      "learning_rate": 1.442789348800422e-05,
      "loss": 0.0256,
      "step": 5913
    },
    {
      "epoch": 0.3508126705421758,
      "grad_norm": 0.03102259524166584,
      "learning_rate": 1.4426575270234644e-05,
      "loss": 0.0009,
      "step": 5914
    },
    {
      "epoch": 0.3508719895598529,
      "grad_norm": 0.13496774435043335,
      "learning_rate": 1.442525705246507e-05,
      "loss": 0.003,
      "step": 5915
    },
    {
      "epoch": 0.35093130857752997,
      "grad_norm": 0.17939864099025726,
      "learning_rate": 1.4423938834695492e-05,
      "loss": 0.0014,
      "step": 5916
    },
    {
      "epoch": 0.35099062759520705,
      "grad_norm": 0.05200546607375145,
      "learning_rate": 1.4422620616925918e-05,
      "loss": 0.0013,
      "step": 5917
    },
    {
      "epoch": 0.3510499466128841,
      "grad_norm": 8.431488037109375,
      "learning_rate": 1.4421302399156342e-05,
      "loss": 0.3787,
      "step": 5918
    },
    {
      "epoch": 0.35110926563056116,
      "grad_norm": 3.1095476150512695,
      "learning_rate": 1.4419984181386766e-05,
      "loss": 0.042,
      "step": 5919
    },
    {
      "epoch": 0.35116858464823825,
      "grad_norm": 0.07353708148002625,
      "learning_rate": 1.441866596361719e-05,
      "loss": 0.0009,
      "step": 5920
    },
    {
      "epoch": 0.3512279036659153,
      "grad_norm": 0.1095733568072319,
      "learning_rate": 1.4417347745847615e-05,
      "loss": 0.0027,
      "step": 5921
    },
    {
      "epoch": 0.35128722268359236,
      "grad_norm": 5.390735149383545,
      "learning_rate": 1.4416029528078039e-05,
      "loss": 0.2443,
      "step": 5922
    },
    {
      "epoch": 0.35134654170126944,
      "grad_norm": 0.029076462611556053,
      "learning_rate": 1.4414711310308465e-05,
      "loss": 0.0006,
      "step": 5923
    },
    {
      "epoch": 0.35140586071894647,
      "grad_norm": 1.9783730506896973,
      "learning_rate": 1.4413393092538887e-05,
      "loss": 0.0577,
      "step": 5924
    },
    {
      "epoch": 0.35146517973662356,
      "grad_norm": 19.477294921875,
      "learning_rate": 1.4412074874769313e-05,
      "loss": 0.4962,
      "step": 5925
    },
    {
      "epoch": 0.35152449875430064,
      "grad_norm": 2.4980127811431885,
      "learning_rate": 1.4410756656999737e-05,
      "loss": 0.0279,
      "step": 5926
    },
    {
      "epoch": 0.35158381777197767,
      "grad_norm": 5.108601093292236,
      "learning_rate": 1.4409438439230162e-05,
      "loss": 0.6365,
      "step": 5927
    },
    {
      "epoch": 0.35164313678965475,
      "grad_norm": 8.103567123413086,
      "learning_rate": 1.4408120221460586e-05,
      "loss": 0.4392,
      "step": 5928
    },
    {
      "epoch": 0.35170245580733184,
      "grad_norm": 5.596650123596191,
      "learning_rate": 1.4406802003691012e-05,
      "loss": 0.2788,
      "step": 5929
    },
    {
      "epoch": 0.3517617748250089,
      "grad_norm": 0.6651386022567749,
      "learning_rate": 1.4405483785921434e-05,
      "loss": 0.0057,
      "step": 5930
    },
    {
      "epoch": 0.35182109384268595,
      "grad_norm": 6.808170318603516,
      "learning_rate": 1.440416556815186e-05,
      "loss": 0.092,
      "step": 5931
    },
    {
      "epoch": 0.35188041286036303,
      "grad_norm": 4.832155227661133,
      "learning_rate": 1.4402847350382286e-05,
      "loss": 0.0707,
      "step": 5932
    },
    {
      "epoch": 0.3519397318780401,
      "grad_norm": 2.16717529296875,
      "learning_rate": 1.4401529132612708e-05,
      "loss": 0.0338,
      "step": 5933
    },
    {
      "epoch": 0.35199905089571715,
      "grad_norm": 0.0260660108178854,
      "learning_rate": 1.4400210914843134e-05,
      "loss": 0.0004,
      "step": 5934
    },
    {
      "epoch": 0.35205836991339423,
      "grad_norm": 0.21118666231632233,
      "learning_rate": 1.4398892697073558e-05,
      "loss": 0.0023,
      "step": 5935
    },
    {
      "epoch": 0.3521176889310713,
      "grad_norm": 3.6845932006835938,
      "learning_rate": 1.4397574479303981e-05,
      "loss": 0.0691,
      "step": 5936
    },
    {
      "epoch": 0.35217700794874834,
      "grad_norm": 4.976821422576904,
      "learning_rate": 1.4396256261534407e-05,
      "loss": 0.5138,
      "step": 5937
    },
    {
      "epoch": 0.35223632696642543,
      "grad_norm": 0.11373620480298996,
      "learning_rate": 1.439493804376483e-05,
      "loss": 0.0022,
      "step": 5938
    },
    {
      "epoch": 0.3522956459841025,
      "grad_norm": 12.617709159851074,
      "learning_rate": 1.4393619825995255e-05,
      "loss": 0.1544,
      "step": 5939
    },
    {
      "epoch": 0.3523549650017796,
      "grad_norm": 0.328838586807251,
      "learning_rate": 1.4392301608225681e-05,
      "loss": 0.0058,
      "step": 5940
    },
    {
      "epoch": 0.3524142840194566,
      "grad_norm": 0.005107313860207796,
      "learning_rate": 1.4390983390456104e-05,
      "loss": 0.0002,
      "step": 5941
    },
    {
      "epoch": 0.3524736030371337,
      "grad_norm": 3.895942449569702,
      "learning_rate": 1.438966517268653e-05,
      "loss": 0.039,
      "step": 5942
    },
    {
      "epoch": 0.3525329220548108,
      "grad_norm": 0.1768440157175064,
      "learning_rate": 1.4388346954916954e-05,
      "loss": 0.0016,
      "step": 5943
    },
    {
      "epoch": 0.3525922410724878,
      "grad_norm": 9.568892478942871,
      "learning_rate": 1.4387028737147378e-05,
      "loss": 1.3852,
      "step": 5944
    },
    {
      "epoch": 0.3526515600901649,
      "grad_norm": 0.09696856886148453,
      "learning_rate": 1.4385710519377802e-05,
      "loss": 0.0018,
      "step": 5945
    },
    {
      "epoch": 0.352710879107842,
      "grad_norm": 15.614326477050781,
      "learning_rate": 1.4384392301608228e-05,
      "loss": 0.1671,
      "step": 5946
    },
    {
      "epoch": 0.352770198125519,
      "grad_norm": 4.458376884460449,
      "learning_rate": 1.438307408383865e-05,
      "loss": 0.0608,
      "step": 5947
    },
    {
      "epoch": 0.3528295171431961,
      "grad_norm": 0.13687384128570557,
      "learning_rate": 1.4381755866069076e-05,
      "loss": 0.0025,
      "step": 5948
    },
    {
      "epoch": 0.3528888361608732,
      "grad_norm": 0.26357710361480713,
      "learning_rate": 1.43804376482995e-05,
      "loss": 0.0039,
      "step": 5949
    },
    {
      "epoch": 0.3529481551785502,
      "grad_norm": 14.87870979309082,
      "learning_rate": 1.4379119430529925e-05,
      "loss": 0.248,
      "step": 5950
    },
    {
      "epoch": 0.3530074741962273,
      "grad_norm": 1.790289282798767,
      "learning_rate": 1.4377801212760349e-05,
      "loss": 0.0186,
      "step": 5951
    },
    {
      "epoch": 0.3530667932139044,
      "grad_norm": 0.10307368636131287,
      "learning_rate": 1.4376482994990775e-05,
      "loss": 0.0021,
      "step": 5952
    },
    {
      "epoch": 0.35312611223158147,
      "grad_norm": 9.564746856689453,
      "learning_rate": 1.4375164777221197e-05,
      "loss": 0.4641,
      "step": 5953
    },
    {
      "epoch": 0.3531854312492585,
      "grad_norm": 0.04404792562127113,
      "learning_rate": 1.4373846559451623e-05,
      "loss": 0.0008,
      "step": 5954
    },
    {
      "epoch": 0.3532447502669356,
      "grad_norm": 6.115714073181152,
      "learning_rate": 1.4372528341682046e-05,
      "loss": 0.0792,
      "step": 5955
    },
    {
      "epoch": 0.35330406928461267,
      "grad_norm": 0.2504764795303345,
      "learning_rate": 1.4371210123912471e-05,
      "loss": 0.0024,
      "step": 5956
    },
    {
      "epoch": 0.3533633883022897,
      "grad_norm": 0.4742834270000458,
      "learning_rate": 1.4369891906142897e-05,
      "loss": 0.0042,
      "step": 5957
    },
    {
      "epoch": 0.3534227073199668,
      "grad_norm": 0.2896135449409485,
      "learning_rate": 1.436857368837332e-05,
      "loss": 0.0028,
      "step": 5958
    },
    {
      "epoch": 0.35348202633764386,
      "grad_norm": 6.671419143676758,
      "learning_rate": 1.4367255470603744e-05,
      "loss": 0.0404,
      "step": 5959
    },
    {
      "epoch": 0.3535413453553209,
      "grad_norm": 0.15638969838619232,
      "learning_rate": 1.436593725283417e-05,
      "loss": 0.002,
      "step": 5960
    },
    {
      "epoch": 0.353600664372998,
      "grad_norm": 0.08579977601766586,
      "learning_rate": 1.4364619035064592e-05,
      "loss": 0.0013,
      "step": 5961
    },
    {
      "epoch": 0.35365998339067506,
      "grad_norm": 4.725333213806152,
      "learning_rate": 1.4363300817295018e-05,
      "loss": 0.1465,
      "step": 5962
    },
    {
      "epoch": 0.35371930240835214,
      "grad_norm": 0.01661152020096779,
      "learning_rate": 1.4361982599525444e-05,
      "loss": 0.0004,
      "step": 5963
    },
    {
      "epoch": 0.35377862142602917,
      "grad_norm": 0.8316054940223694,
      "learning_rate": 1.4360664381755867e-05,
      "loss": 0.0164,
      "step": 5964
    },
    {
      "epoch": 0.35383794044370626,
      "grad_norm": 0.03270448371767998,
      "learning_rate": 1.4359346163986293e-05,
      "loss": 0.0009,
      "step": 5965
    },
    {
      "epoch": 0.35389725946138334,
      "grad_norm": 2.192072629928589,
      "learning_rate": 1.4358027946216717e-05,
      "loss": 0.0098,
      "step": 5966
    },
    {
      "epoch": 0.35395657847906037,
      "grad_norm": 7.678971767425537,
      "learning_rate": 1.4356709728447141e-05,
      "loss": 0.1347,
      "step": 5967
    },
    {
      "epoch": 0.35401589749673745,
      "grad_norm": 0.20442505180835724,
      "learning_rate": 1.4355391510677565e-05,
      "loss": 0.0044,
      "step": 5968
    },
    {
      "epoch": 0.35407521651441454,
      "grad_norm": 6.298272609710693,
      "learning_rate": 1.4354073292907991e-05,
      "loss": 0.0583,
      "step": 5969
    },
    {
      "epoch": 0.35413453553209157,
      "grad_norm": 0.07235817611217499,
      "learning_rate": 1.4352755075138413e-05,
      "loss": 0.0011,
      "step": 5970
    },
    {
      "epoch": 0.35419385454976865,
      "grad_norm": 6.670869827270508,
      "learning_rate": 1.435143685736884e-05,
      "loss": 0.3795,
      "step": 5971
    },
    {
      "epoch": 0.35425317356744573,
      "grad_norm": 2.7141265869140625,
      "learning_rate": 1.4350118639599262e-05,
      "loss": 0.0595,
      "step": 5972
    },
    {
      "epoch": 0.3543124925851228,
      "grad_norm": 0.23645715415477753,
      "learning_rate": 1.4348800421829688e-05,
      "loss": 0.0018,
      "step": 5973
    },
    {
      "epoch": 0.35437181160279985,
      "grad_norm": 2.8825912475585938,
      "learning_rate": 1.4347482204060112e-05,
      "loss": 0.0508,
      "step": 5974
    },
    {
      "epoch": 0.35443113062047693,
      "grad_norm": 4.320090293884277,
      "learning_rate": 1.4346163986290536e-05,
      "loss": 0.2123,
      "step": 5975
    },
    {
      "epoch": 0.354490449638154,
      "grad_norm": 2.663902997970581,
      "learning_rate": 1.434484576852096e-05,
      "loss": 0.0577,
      "step": 5976
    },
    {
      "epoch": 0.35454976865583104,
      "grad_norm": 15.73885726928711,
      "learning_rate": 1.4343527550751386e-05,
      "loss": 0.0686,
      "step": 5977
    },
    {
      "epoch": 0.3546090876735081,
      "grad_norm": 0.2462572604417801,
      "learning_rate": 1.4342209332981809e-05,
      "loss": 0.0025,
      "step": 5978
    },
    {
      "epoch": 0.3546684066911852,
      "grad_norm": 5.003432273864746,
      "learning_rate": 1.4340891115212235e-05,
      "loss": 0.0768,
      "step": 5979
    },
    {
      "epoch": 0.35472772570886224,
      "grad_norm": 0.034336864948272705,
      "learning_rate": 1.4339572897442659e-05,
      "loss": 0.0003,
      "step": 5980
    },
    {
      "epoch": 0.3547870447265393,
      "grad_norm": 0.021363912150263786,
      "learning_rate": 1.4338254679673083e-05,
      "loss": 0.0006,
      "step": 5981
    },
    {
      "epoch": 0.3548463637442164,
      "grad_norm": 15.679361343383789,
      "learning_rate": 1.4336936461903507e-05,
      "loss": 0.7895,
      "step": 5982
    },
    {
      "epoch": 0.35490568276189344,
      "grad_norm": 14.517105102539062,
      "learning_rate": 1.4335618244133933e-05,
      "loss": 1.3342,
      "step": 5983
    },
    {
      "epoch": 0.3549650017795705,
      "grad_norm": 31.411945343017578,
      "learning_rate": 1.4334300026364355e-05,
      "loss": 0.1998,
      "step": 5984
    },
    {
      "epoch": 0.3550243207972476,
      "grad_norm": 0.09779183566570282,
      "learning_rate": 1.4332981808594781e-05,
      "loss": 0.0016,
      "step": 5985
    },
    {
      "epoch": 0.3550836398149247,
      "grad_norm": 5.9196648597717285,
      "learning_rate": 1.4331663590825204e-05,
      "loss": 0.186,
      "step": 5986
    },
    {
      "epoch": 0.3551429588326017,
      "grad_norm": 1.7924745082855225,
      "learning_rate": 1.433034537305563e-05,
      "loss": 0.01,
      "step": 5987
    },
    {
      "epoch": 0.3552022778502788,
      "grad_norm": 6.856205940246582,
      "learning_rate": 1.4329027155286056e-05,
      "loss": 0.0722,
      "step": 5988
    },
    {
      "epoch": 0.3552615968679559,
      "grad_norm": 13.833684921264648,
      "learning_rate": 1.4327708937516478e-05,
      "loss": 0.3042,
      "step": 5989
    },
    {
      "epoch": 0.3553209158856329,
      "grad_norm": 0.015925893560051918,
      "learning_rate": 1.4326390719746904e-05,
      "loss": 0.0005,
      "step": 5990
    },
    {
      "epoch": 0.35538023490331,
      "grad_norm": 6.551090240478516,
      "learning_rate": 1.4325072501977328e-05,
      "loss": 0.2946,
      "step": 5991
    },
    {
      "epoch": 0.3554395539209871,
      "grad_norm": 0.23937903344631195,
      "learning_rate": 1.432375428420775e-05,
      "loss": 0.0025,
      "step": 5992
    },
    {
      "epoch": 0.3554988729386641,
      "grad_norm": 13.961612701416016,
      "learning_rate": 1.4322436066438177e-05,
      "loss": 0.1405,
      "step": 5993
    },
    {
      "epoch": 0.3555581919563412,
      "grad_norm": 0.019667796790599823,
      "learning_rate": 1.4321117848668602e-05,
      "loss": 0.0006,
      "step": 5994
    },
    {
      "epoch": 0.3556175109740183,
      "grad_norm": 0.18870848417282104,
      "learning_rate": 1.4319799630899025e-05,
      "loss": 0.0015,
      "step": 5995
    },
    {
      "epoch": 0.35567682999169536,
      "grad_norm": 0.21625877916812897,
      "learning_rate": 1.431848141312945e-05,
      "loss": 0.0036,
      "step": 5996
    },
    {
      "epoch": 0.3557361490093724,
      "grad_norm": 0.08814270049333572,
      "learning_rate": 1.4317163195359875e-05,
      "loss": 0.0015,
      "step": 5997
    },
    {
      "epoch": 0.3557954680270495,
      "grad_norm": 0.03459307923913002,
      "learning_rate": 1.43158449775903e-05,
      "loss": 0.001,
      "step": 5998
    },
    {
      "epoch": 0.35585478704472656,
      "grad_norm": 0.08900429308414459,
      "learning_rate": 1.4314526759820723e-05,
      "loss": 0.001,
      "step": 5999
    },
    {
      "epoch": 0.3559141060624036,
      "grad_norm": 0.014960476197302341,
      "learning_rate": 1.431320854205115e-05,
      "loss": 0.0006,
      "step": 6000
    },
    {
      "epoch": 0.3559734250800807,
      "grad_norm": 9.010406494140625,
      "learning_rate": 1.4311890324281572e-05,
      "loss": 0.875,
      "step": 6001
    },
    {
      "epoch": 0.35603274409775776,
      "grad_norm": 0.12775754928588867,
      "learning_rate": 1.4310572106511998e-05,
      "loss": 0.0028,
      "step": 6002
    },
    {
      "epoch": 0.3560920631154348,
      "grad_norm": 3.8000130653381348,
      "learning_rate": 1.430925388874242e-05,
      "loss": 0.0464,
      "step": 6003
    },
    {
      "epoch": 0.35615138213311187,
      "grad_norm": 0.5877233743667603,
      "learning_rate": 1.4307935670972846e-05,
      "loss": 0.0074,
      "step": 6004
    },
    {
      "epoch": 0.35621070115078896,
      "grad_norm": 0.8295550346374512,
      "learning_rate": 1.430661745320327e-05,
      "loss": 0.0075,
      "step": 6005
    },
    {
      "epoch": 0.356270020168466,
      "grad_norm": 0.1159091591835022,
      "learning_rate": 1.4305299235433694e-05,
      "loss": 0.0023,
      "step": 6006
    },
    {
      "epoch": 0.35632933918614307,
      "grad_norm": 0.07634813338518143,
      "learning_rate": 1.4303981017664119e-05,
      "loss": 0.0008,
      "step": 6007
    },
    {
      "epoch": 0.35638865820382015,
      "grad_norm": 3.372593641281128,
      "learning_rate": 1.4302662799894544e-05,
      "loss": 0.0468,
      "step": 6008
    },
    {
      "epoch": 0.35644797722149724,
      "grad_norm": 16.75792121887207,
      "learning_rate": 1.4301344582124967e-05,
      "loss": 0.0925,
      "step": 6009
    },
    {
      "epoch": 0.35650729623917427,
      "grad_norm": 3.4870707988739014,
      "learning_rate": 1.4300026364355393e-05,
      "loss": 0.0779,
      "step": 6010
    },
    {
      "epoch": 0.35656661525685135,
      "grad_norm": 33.925262451171875,
      "learning_rate": 1.4298708146585819e-05,
      "loss": 1.0103,
      "step": 6011
    },
    {
      "epoch": 0.35662593427452843,
      "grad_norm": 0.30560827255249023,
      "learning_rate": 1.4297389928816241e-05,
      "loss": 0.0068,
      "step": 6012
    },
    {
      "epoch": 0.35668525329220546,
      "grad_norm": 0.024570375680923462,
      "learning_rate": 1.4296071711046667e-05,
      "loss": 0.0005,
      "step": 6013
    },
    {
      "epoch": 0.35674457230988255,
      "grad_norm": 0.11816070228815079,
      "learning_rate": 1.4294753493277091e-05,
      "loss": 0.0015,
      "step": 6014
    },
    {
      "epoch": 0.35680389132755963,
      "grad_norm": 0.2593587636947632,
      "learning_rate": 1.4293435275507514e-05,
      "loss": 0.0033,
      "step": 6015
    },
    {
      "epoch": 0.35686321034523666,
      "grad_norm": 1.5991780757904053,
      "learning_rate": 1.429211705773794e-05,
      "loss": 0.0254,
      "step": 6016
    },
    {
      "epoch": 0.35692252936291374,
      "grad_norm": 0.0545540414750576,
      "learning_rate": 1.4290798839968366e-05,
      "loss": 0.0012,
      "step": 6017
    },
    {
      "epoch": 0.3569818483805908,
      "grad_norm": 4.886170864105225,
      "learning_rate": 1.4289480622198788e-05,
      "loss": 0.2692,
      "step": 6018
    },
    {
      "epoch": 0.3570411673982679,
      "grad_norm": 3.851308822631836,
      "learning_rate": 1.4288162404429214e-05,
      "loss": 0.0292,
      "step": 6019
    },
    {
      "epoch": 0.35710048641594494,
      "grad_norm": 0.10187190026044846,
      "learning_rate": 1.4286844186659636e-05,
      "loss": 0.002,
      "step": 6020
    },
    {
      "epoch": 0.357159805433622,
      "grad_norm": 0.13597571849822998,
      "learning_rate": 1.4285525968890062e-05,
      "loss": 0.0036,
      "step": 6021
    },
    {
      "epoch": 0.3572191244512991,
      "grad_norm": 1.120606541633606,
      "learning_rate": 1.4284207751120486e-05,
      "loss": 0.0034,
      "step": 6022
    },
    {
      "epoch": 0.35727844346897614,
      "grad_norm": 0.6437700390815735,
      "learning_rate": 1.428288953335091e-05,
      "loss": 0.0071,
      "step": 6023
    },
    {
      "epoch": 0.3573377624866532,
      "grad_norm": 0.8319544792175293,
      "learning_rate": 1.4281571315581335e-05,
      "loss": 0.0102,
      "step": 6024
    },
    {
      "epoch": 0.3573970815043303,
      "grad_norm": 27.916181564331055,
      "learning_rate": 1.428025309781176e-05,
      "loss": 0.5747,
      "step": 6025
    },
    {
      "epoch": 0.35745640052200733,
      "grad_norm": 26.032373428344727,
      "learning_rate": 1.4278934880042183e-05,
      "loss": 0.6721,
      "step": 6026
    },
    {
      "epoch": 0.3575157195396844,
      "grad_norm": 0.039095837622880936,
      "learning_rate": 1.4277616662272609e-05,
      "loss": 0.0009,
      "step": 6027
    },
    {
      "epoch": 0.3575750385573615,
      "grad_norm": 33.20003890991211,
      "learning_rate": 1.4276298444503033e-05,
      "loss": 0.1976,
      "step": 6028
    },
    {
      "epoch": 0.35763435757503853,
      "grad_norm": 6.16611909866333,
      "learning_rate": 1.4274980226733457e-05,
      "loss": 0.0515,
      "step": 6029
    },
    {
      "epoch": 0.3576936765927156,
      "grad_norm": 0.043981634080410004,
      "learning_rate": 1.4273662008963882e-05,
      "loss": 0.0016,
      "step": 6030
    },
    {
      "epoch": 0.3577529956103927,
      "grad_norm": 7.022783279418945,
      "learning_rate": 1.4272343791194308e-05,
      "loss": 0.1803,
      "step": 6031
    },
    {
      "epoch": 0.3578123146280698,
      "grad_norm": 0.0931176170706749,
      "learning_rate": 1.427102557342473e-05,
      "loss": 0.0022,
      "step": 6032
    },
    {
      "epoch": 0.3578716336457468,
      "grad_norm": 1.2021821737289429,
      "learning_rate": 1.4269707355655156e-05,
      "loss": 0.0206,
      "step": 6033
    },
    {
      "epoch": 0.3579309526634239,
      "grad_norm": 51.22200393676758,
      "learning_rate": 1.4268389137885578e-05,
      "loss": 1.1119,
      "step": 6034
    },
    {
      "epoch": 0.357990271681101,
      "grad_norm": 0.192686066031456,
      "learning_rate": 1.4267070920116004e-05,
      "loss": 0.0022,
      "step": 6035
    },
    {
      "epoch": 0.358049590698778,
      "grad_norm": 13.297598838806152,
      "learning_rate": 1.4265752702346428e-05,
      "loss": 0.4653,
      "step": 6036
    },
    {
      "epoch": 0.3581089097164551,
      "grad_norm": 18.655324935913086,
      "learning_rate": 1.4264434484576853e-05,
      "loss": 1.2186,
      "step": 6037
    },
    {
      "epoch": 0.3581682287341322,
      "grad_norm": 16.172014236450195,
      "learning_rate": 1.4263116266807277e-05,
      "loss": 0.7183,
      "step": 6038
    },
    {
      "epoch": 0.3582275477518092,
      "grad_norm": 13.102993965148926,
      "learning_rate": 1.4261798049037703e-05,
      "loss": 0.1226,
      "step": 6039
    },
    {
      "epoch": 0.3582868667694863,
      "grad_norm": 0.03218863159418106,
      "learning_rate": 1.4260479831268125e-05,
      "loss": 0.0009,
      "step": 6040
    },
    {
      "epoch": 0.3583461857871634,
      "grad_norm": 15.594526290893555,
      "learning_rate": 1.4259161613498551e-05,
      "loss": 0.4973,
      "step": 6041
    },
    {
      "epoch": 0.35840550480484046,
      "grad_norm": 4.419561862945557,
      "learning_rate": 1.4257843395728977e-05,
      "loss": 0.0639,
      "step": 6042
    },
    {
      "epoch": 0.3584648238225175,
      "grad_norm": 0.05527010187506676,
      "learning_rate": 1.42565251779594e-05,
      "loss": 0.0011,
      "step": 6043
    },
    {
      "epoch": 0.35852414284019457,
      "grad_norm": 0.03924345225095749,
      "learning_rate": 1.4255206960189825e-05,
      "loss": 0.0009,
      "step": 6044
    },
    {
      "epoch": 0.35858346185787165,
      "grad_norm": 14.54130744934082,
      "learning_rate": 1.425388874242025e-05,
      "loss": 0.0555,
      "step": 6045
    },
    {
      "epoch": 0.3586427808755487,
      "grad_norm": 16.05558204650879,
      "learning_rate": 1.4252570524650674e-05,
      "loss": 0.4846,
      "step": 6046
    },
    {
      "epoch": 0.35870209989322577,
      "grad_norm": 0.043560437858104706,
      "learning_rate": 1.4251252306881098e-05,
      "loss": 0.0008,
      "step": 6047
    },
    {
      "epoch": 0.35876141891090285,
      "grad_norm": 9.228683471679688,
      "learning_rate": 1.4249934089111524e-05,
      "loss": 0.1923,
      "step": 6048
    },
    {
      "epoch": 0.3588207379285799,
      "grad_norm": 1.9092073440551758,
      "learning_rate": 1.4248615871341946e-05,
      "loss": 0.0229,
      "step": 6049
    },
    {
      "epoch": 0.35888005694625696,
      "grad_norm": 11.482283592224121,
      "learning_rate": 1.4247297653572372e-05,
      "loss": 0.4814,
      "step": 6050
    },
    {
      "epoch": 0.35893937596393405,
      "grad_norm": 15.052407264709473,
      "learning_rate": 1.4245979435802795e-05,
      "loss": 0.6335,
      "step": 6051
    },
    {
      "epoch": 0.3589986949816111,
      "grad_norm": 0.6983609795570374,
      "learning_rate": 1.424466121803322e-05,
      "loss": 0.0133,
      "step": 6052
    },
    {
      "epoch": 0.35905801399928816,
      "grad_norm": 8.1605863571167,
      "learning_rate": 1.4243343000263645e-05,
      "loss": 0.3268,
      "step": 6053
    },
    {
      "epoch": 0.35911733301696525,
      "grad_norm": 8.01700210571289,
      "learning_rate": 1.4242024782494069e-05,
      "loss": 0.3378,
      "step": 6054
    },
    {
      "epoch": 0.35917665203464233,
      "grad_norm": 5.216760158538818,
      "learning_rate": 1.4240706564724493e-05,
      "loss": 0.0675,
      "step": 6055
    },
    {
      "epoch": 0.35923597105231936,
      "grad_norm": 13.122550010681152,
      "learning_rate": 1.4239388346954919e-05,
      "loss": 0.1483,
      "step": 6056
    },
    {
      "epoch": 0.35929529006999644,
      "grad_norm": 4.970274925231934,
      "learning_rate": 1.4238070129185341e-05,
      "loss": 0.0973,
      "step": 6057
    },
    {
      "epoch": 0.3593546090876735,
      "grad_norm": 0.1034967452287674,
      "learning_rate": 1.4236751911415767e-05,
      "loss": 0.0023,
      "step": 6058
    },
    {
      "epoch": 0.35941392810535056,
      "grad_norm": 0.019701221957802773,
      "learning_rate": 1.4235433693646192e-05,
      "loss": 0.0005,
      "step": 6059
    },
    {
      "epoch": 0.35947324712302764,
      "grad_norm": 0.28633764386177063,
      "learning_rate": 1.4234115475876616e-05,
      "loss": 0.0042,
      "step": 6060
    },
    {
      "epoch": 0.3595325661407047,
      "grad_norm": 2.8588180541992188,
      "learning_rate": 1.423279725810704e-05,
      "loss": 0.0407,
      "step": 6061
    },
    {
      "epoch": 0.35959188515838175,
      "grad_norm": 1.4837496280670166,
      "learning_rate": 1.4231479040337466e-05,
      "loss": 0.0365,
      "step": 6062
    },
    {
      "epoch": 0.35965120417605884,
      "grad_norm": 0.6383337378501892,
      "learning_rate": 1.4230160822567888e-05,
      "loss": 0.004,
      "step": 6063
    },
    {
      "epoch": 0.3597105231937359,
      "grad_norm": 0.06827747821807861,
      "learning_rate": 1.4228842604798314e-05,
      "loss": 0.0008,
      "step": 6064
    },
    {
      "epoch": 0.359769842211413,
      "grad_norm": 0.09646041691303253,
      "learning_rate": 1.422752438702874e-05,
      "loss": 0.0016,
      "step": 6065
    },
    {
      "epoch": 0.35982916122909003,
      "grad_norm": 18.021581649780273,
      "learning_rate": 1.4226206169259163e-05,
      "loss": 0.6515,
      "step": 6066
    },
    {
      "epoch": 0.3598884802467671,
      "grad_norm": 14.275704383850098,
      "learning_rate": 1.4224887951489588e-05,
      "loss": 0.1873,
      "step": 6067
    },
    {
      "epoch": 0.3599477992644442,
      "grad_norm": 0.031022217124700546,
      "learning_rate": 1.4223569733720011e-05,
      "loss": 0.0004,
      "step": 6068
    },
    {
      "epoch": 0.36000711828212123,
      "grad_norm": 0.008643250912427902,
      "learning_rate": 1.4222251515950437e-05,
      "loss": 0.0002,
      "step": 6069
    },
    {
      "epoch": 0.3600664372997983,
      "grad_norm": 38.879966735839844,
      "learning_rate": 1.4220933298180861e-05,
      "loss": 0.347,
      "step": 6070
    },
    {
      "epoch": 0.3601257563174754,
      "grad_norm": 2.0349714756011963,
      "learning_rate": 1.4219615080411283e-05,
      "loss": 0.0216,
      "step": 6071
    },
    {
      "epoch": 0.3601850753351524,
      "grad_norm": 10.42111873626709,
      "learning_rate": 1.421829686264171e-05,
      "loss": 0.1597,
      "step": 6072
    },
    {
      "epoch": 0.3602443943528295,
      "grad_norm": 16.357481002807617,
      "learning_rate": 1.4216978644872135e-05,
      "loss": 0.3293,
      "step": 6073
    },
    {
      "epoch": 0.3603037133705066,
      "grad_norm": 6.660175800323486,
      "learning_rate": 1.4215660427102558e-05,
      "loss": 0.0323,
      "step": 6074
    },
    {
      "epoch": 0.3603630323881836,
      "grad_norm": 18.144336700439453,
      "learning_rate": 1.4214342209332984e-05,
      "loss": 0.8218,
      "step": 6075
    },
    {
      "epoch": 0.3604223514058607,
      "grad_norm": 0.012765295803546906,
      "learning_rate": 1.4213023991563408e-05,
      "loss": 0.0003,
      "step": 6076
    },
    {
      "epoch": 0.3604816704235378,
      "grad_norm": 4.319693565368652,
      "learning_rate": 1.4211705773793832e-05,
      "loss": 0.0424,
      "step": 6077
    },
    {
      "epoch": 0.3605409894412149,
      "grad_norm": 8.40670108795166,
      "learning_rate": 1.4210387556024256e-05,
      "loss": 0.348,
      "step": 6078
    },
    {
      "epoch": 0.3606003084588919,
      "grad_norm": 28.732046127319336,
      "learning_rate": 1.4209069338254682e-05,
      "loss": 0.9765,
      "step": 6079
    },
    {
      "epoch": 0.360659627476569,
      "grad_norm": 10.598665237426758,
      "learning_rate": 1.4207751120485105e-05,
      "loss": 0.2127,
      "step": 6080
    },
    {
      "epoch": 0.3607189464942461,
      "grad_norm": 0.43243882060050964,
      "learning_rate": 1.420643290271553e-05,
      "loss": 0.0075,
      "step": 6081
    },
    {
      "epoch": 0.3607782655119231,
      "grad_norm": 5.517517566680908,
      "learning_rate": 1.4205114684945953e-05,
      "loss": 0.0436,
      "step": 6082
    },
    {
      "epoch": 0.3608375845296002,
      "grad_norm": 8.063591957092285,
      "learning_rate": 1.4203796467176379e-05,
      "loss": 0.6147,
      "step": 6083
    },
    {
      "epoch": 0.36089690354727727,
      "grad_norm": 0.06143892928957939,
      "learning_rate": 1.4202478249406803e-05,
      "loss": 0.0012,
      "step": 6084
    },
    {
      "epoch": 0.3609562225649543,
      "grad_norm": 12.351242065429688,
      "learning_rate": 1.4201160031637227e-05,
      "loss": 0.3067,
      "step": 6085
    },
    {
      "epoch": 0.3610155415826314,
      "grad_norm": 2.6254401206970215,
      "learning_rate": 1.4199841813867651e-05,
      "loss": 0.2465,
      "step": 6086
    },
    {
      "epoch": 0.36107486060030847,
      "grad_norm": 1.5006729364395142,
      "learning_rate": 1.4198523596098077e-05,
      "loss": 0.0162,
      "step": 6087
    },
    {
      "epoch": 0.36113417961798555,
      "grad_norm": 0.23151126503944397,
      "learning_rate": 1.41972053783285e-05,
      "loss": 0.002,
      "step": 6088
    },
    {
      "epoch": 0.3611934986356626,
      "grad_norm": 7.626280784606934,
      "learning_rate": 1.4195887160558926e-05,
      "loss": 0.1473,
      "step": 6089
    },
    {
      "epoch": 0.36125281765333966,
      "grad_norm": 0.864355206489563,
      "learning_rate": 1.4194568942789351e-05,
      "loss": 0.0127,
      "step": 6090
    },
    {
      "epoch": 0.36131213667101675,
      "grad_norm": 0.8855874538421631,
      "learning_rate": 1.4193250725019774e-05,
      "loss": 0.0139,
      "step": 6091
    },
    {
      "epoch": 0.3613714556886938,
      "grad_norm": 0.22886976599693298,
      "learning_rate": 1.4191932507250198e-05,
      "loss": 0.0025,
      "step": 6092
    },
    {
      "epoch": 0.36143077470637086,
      "grad_norm": 0.04836588352918625,
      "learning_rate": 1.4190614289480624e-05,
      "loss": 0.0007,
      "step": 6093
    },
    {
      "epoch": 0.36149009372404795,
      "grad_norm": 8.109543800354004,
      "learning_rate": 1.4189296071711047e-05,
      "loss": 0.0487,
      "step": 6094
    },
    {
      "epoch": 0.361549412741725,
      "grad_norm": 2.132979393005371,
      "learning_rate": 1.4187977853941472e-05,
      "loss": 0.0246,
      "step": 6095
    },
    {
      "epoch": 0.36160873175940206,
      "grad_norm": 8.063897132873535,
      "learning_rate": 1.4186659636171898e-05,
      "loss": 0.054,
      "step": 6096
    },
    {
      "epoch": 0.36166805077707914,
      "grad_norm": 6.016246795654297,
      "learning_rate": 1.418534141840232e-05,
      "loss": 0.1416,
      "step": 6097
    },
    {
      "epoch": 0.3617273697947562,
      "grad_norm": 15.591672897338867,
      "learning_rate": 1.4184023200632747e-05,
      "loss": 0.3254,
      "step": 6098
    },
    {
      "epoch": 0.36178668881243325,
      "grad_norm": 8.531198501586914,
      "learning_rate": 1.418270498286317e-05,
      "loss": 0.3306,
      "step": 6099
    },
    {
      "epoch": 0.36184600783011034,
      "grad_norm": 1.058517336845398,
      "learning_rate": 1.4181386765093595e-05,
      "loss": 0.0048,
      "step": 6100
    },
    {
      "epoch": 0.3619053268477874,
      "grad_norm": 28.262554168701172,
      "learning_rate": 1.418006854732402e-05,
      "loss": 1.1032,
      "step": 6101
    },
    {
      "epoch": 0.36196464586546445,
      "grad_norm": 0.3985346257686615,
      "learning_rate": 1.4178750329554443e-05,
      "loss": 0.005,
      "step": 6102
    },
    {
      "epoch": 0.36202396488314154,
      "grad_norm": 0.885957658290863,
      "learning_rate": 1.4177432111784868e-05,
      "loss": 0.0071,
      "step": 6103
    },
    {
      "epoch": 0.3620832839008186,
      "grad_norm": 5.189332008361816,
      "learning_rate": 1.4176113894015293e-05,
      "loss": 0.0538,
      "step": 6104
    },
    {
      "epoch": 0.36214260291849565,
      "grad_norm": 1.0182368755340576,
      "learning_rate": 1.4174795676245716e-05,
      "loss": 0.011,
      "step": 6105
    },
    {
      "epoch": 0.36220192193617273,
      "grad_norm": 12.102846145629883,
      "learning_rate": 1.4173477458476142e-05,
      "loss": 0.5526,
      "step": 6106
    },
    {
      "epoch": 0.3622612409538498,
      "grad_norm": 6.099486351013184,
      "learning_rate": 1.4172159240706566e-05,
      "loss": 0.3927,
      "step": 6107
    },
    {
      "epoch": 0.36232055997152685,
      "grad_norm": 1.9810866117477417,
      "learning_rate": 1.417084102293699e-05,
      "loss": 0.0271,
      "step": 6108
    },
    {
      "epoch": 0.36237987898920393,
      "grad_norm": 0.11222423613071442,
      "learning_rate": 1.4169522805167414e-05,
      "loss": 0.0018,
      "step": 6109
    },
    {
      "epoch": 0.362439198006881,
      "grad_norm": 13.54323959350586,
      "learning_rate": 1.416820458739784e-05,
      "loss": 0.4524,
      "step": 6110
    },
    {
      "epoch": 0.3624985170245581,
      "grad_norm": 15.797375679016113,
      "learning_rate": 1.4166886369628263e-05,
      "loss": 0.8886,
      "step": 6111
    },
    {
      "epoch": 0.3625578360422351,
      "grad_norm": 0.05038074031472206,
      "learning_rate": 1.4165568151858689e-05,
      "loss": 0.001,
      "step": 6112
    },
    {
      "epoch": 0.3626171550599122,
      "grad_norm": 0.02684059925377369,
      "learning_rate": 1.4164249934089115e-05,
      "loss": 0.0008,
      "step": 6113
    },
    {
      "epoch": 0.3626764740775893,
      "grad_norm": 39.73579788208008,
      "learning_rate": 1.4162931716319537e-05,
      "loss": 0.5917,
      "step": 6114
    },
    {
      "epoch": 0.3627357930952663,
      "grad_norm": 2.1156883239746094,
      "learning_rate": 1.4161613498549961e-05,
      "loss": 0.0163,
      "step": 6115
    },
    {
      "epoch": 0.3627951121129434,
      "grad_norm": 14.448251724243164,
      "learning_rate": 1.4160295280780385e-05,
      "loss": 0.135,
      "step": 6116
    },
    {
      "epoch": 0.3628544311306205,
      "grad_norm": 3.3962771892547607,
      "learning_rate": 1.415897706301081e-05,
      "loss": 0.0375,
      "step": 6117
    },
    {
      "epoch": 0.3629137501482975,
      "grad_norm": 1.3591924905776978,
      "learning_rate": 1.4157658845241236e-05,
      "loss": 0.0108,
      "step": 6118
    },
    {
      "epoch": 0.3629730691659746,
      "grad_norm": 22.882596969604492,
      "learning_rate": 1.4156340627471658e-05,
      "loss": 0.839,
      "step": 6119
    },
    {
      "epoch": 0.3630323881836517,
      "grad_norm": 20.62042236328125,
      "learning_rate": 1.4155022409702084e-05,
      "loss": 0.8384,
      "step": 6120
    },
    {
      "epoch": 0.3630917072013288,
      "grad_norm": 3.041444778442383,
      "learning_rate": 1.415370419193251e-05,
      "loss": 0.043,
      "step": 6121
    },
    {
      "epoch": 0.3631510262190058,
      "grad_norm": 0.01767919957637787,
      "learning_rate": 1.4152385974162932e-05,
      "loss": 0.0006,
      "step": 6122
    },
    {
      "epoch": 0.3632103452366829,
      "grad_norm": 9.890631675720215,
      "learning_rate": 1.4151067756393358e-05,
      "loss": 1.06,
      "step": 6123
    },
    {
      "epoch": 0.36326966425435997,
      "grad_norm": 2.287153482437134,
      "learning_rate": 1.4149749538623782e-05,
      "loss": 0.0387,
      "step": 6124
    },
    {
      "epoch": 0.363328983272037,
      "grad_norm": 0.22796480357646942,
      "learning_rate": 1.4148431320854207e-05,
      "loss": 0.0043,
      "step": 6125
    },
    {
      "epoch": 0.3633883022897141,
      "grad_norm": 13.900233268737793,
      "learning_rate": 1.414711310308463e-05,
      "loss": 0.5196,
      "step": 6126
    },
    {
      "epoch": 0.36344762130739117,
      "grad_norm": 7.23302698135376,
      "learning_rate": 1.4145794885315057e-05,
      "loss": 0.0721,
      "step": 6127
    },
    {
      "epoch": 0.3635069403250682,
      "grad_norm": 0.5893177390098572,
      "learning_rate": 1.4144476667545479e-05,
      "loss": 0.0067,
      "step": 6128
    },
    {
      "epoch": 0.3635662593427453,
      "grad_norm": 10.444713592529297,
      "learning_rate": 1.4143158449775905e-05,
      "loss": 0.2726,
      "step": 6129
    },
    {
      "epoch": 0.36362557836042236,
      "grad_norm": 0.03103676438331604,
      "learning_rate": 1.4141840232006327e-05,
      "loss": 0.0008,
      "step": 6130
    },
    {
      "epoch": 0.3636848973780994,
      "grad_norm": 5.032322406768799,
      "learning_rate": 1.4140522014236753e-05,
      "loss": 0.2664,
      "step": 6131
    },
    {
      "epoch": 0.3637442163957765,
      "grad_norm": 0.01981024444103241,
      "learning_rate": 1.4139203796467178e-05,
      "loss": 0.0005,
      "step": 6132
    },
    {
      "epoch": 0.36380353541345356,
      "grad_norm": 4.0982208251953125,
      "learning_rate": 1.4137885578697602e-05,
      "loss": 0.1951,
      "step": 6133
    },
    {
      "epoch": 0.36386285443113064,
      "grad_norm": 18.247671127319336,
      "learning_rate": 1.4136567360928026e-05,
      "loss": 0.1594,
      "step": 6134
    },
    {
      "epoch": 0.3639221734488077,
      "grad_norm": 0.07713832706212997,
      "learning_rate": 1.4135249143158452e-05,
      "loss": 0.0011,
      "step": 6135
    },
    {
      "epoch": 0.36398149246648476,
      "grad_norm": 0.018394339829683304,
      "learning_rate": 1.4133930925388874e-05,
      "loss": 0.0007,
      "step": 6136
    },
    {
      "epoch": 0.36404081148416184,
      "grad_norm": 16.268169403076172,
      "learning_rate": 1.41326127076193e-05,
      "loss": 0.498,
      "step": 6137
    },
    {
      "epoch": 0.36410013050183887,
      "grad_norm": 12.914922714233398,
      "learning_rate": 1.4131294489849724e-05,
      "loss": 0.3779,
      "step": 6138
    },
    {
      "epoch": 0.36415944951951595,
      "grad_norm": 7.033880710601807,
      "learning_rate": 1.4129976272080149e-05,
      "loss": 0.1248,
      "step": 6139
    },
    {
      "epoch": 0.36421876853719304,
      "grad_norm": 11.561813354492188,
      "learning_rate": 1.4128658054310573e-05,
      "loss": 0.2622,
      "step": 6140
    },
    {
      "epoch": 0.36427808755487007,
      "grad_norm": 0.7694549560546875,
      "learning_rate": 1.4127339836540999e-05,
      "loss": 0.0138,
      "step": 6141
    },
    {
      "epoch": 0.36433740657254715,
      "grad_norm": 2.091170310974121,
      "learning_rate": 1.4126021618771421e-05,
      "loss": 0.0211,
      "step": 6142
    },
    {
      "epoch": 0.36439672559022424,
      "grad_norm": 0.05132105201482773,
      "learning_rate": 1.4124703401001847e-05,
      "loss": 0.0016,
      "step": 6143
    },
    {
      "epoch": 0.3644560446079013,
      "grad_norm": 10.162303924560547,
      "learning_rate": 1.4123385183232273e-05,
      "loss": 0.3065,
      "step": 6144
    },
    {
      "epoch": 0.36451536362557835,
      "grad_norm": 9.53333854675293,
      "learning_rate": 1.4122066965462695e-05,
      "loss": 0.0449,
      "step": 6145
    },
    {
      "epoch": 0.36457468264325543,
      "grad_norm": 11.67988109588623,
      "learning_rate": 1.4120748747693121e-05,
      "loss": 0.1094,
      "step": 6146
    },
    {
      "epoch": 0.3646340016609325,
      "grad_norm": 20.83402442932129,
      "learning_rate": 1.4119430529923544e-05,
      "loss": 0.0697,
      "step": 6147
    },
    {
      "epoch": 0.36469332067860954,
      "grad_norm": 55.9651985168457,
      "learning_rate": 1.4118112312153968e-05,
      "loss": 0.1411,
      "step": 6148
    },
    {
      "epoch": 0.36475263969628663,
      "grad_norm": 10.560835838317871,
      "learning_rate": 1.4116794094384394e-05,
      "loss": 0.5252,
      "step": 6149
    },
    {
      "epoch": 0.3648119587139637,
      "grad_norm": 5.652530670166016,
      "learning_rate": 1.4115475876614816e-05,
      "loss": 0.0624,
      "step": 6150
    },
    {
      "epoch": 0.36487127773164074,
      "grad_norm": 5.317917346954346,
      "learning_rate": 1.4114157658845242e-05,
      "loss": 0.2022,
      "step": 6151
    },
    {
      "epoch": 0.3649305967493178,
      "grad_norm": 22.77689552307129,
      "learning_rate": 1.4112839441075668e-05,
      "loss": 0.2302,
      "step": 6152
    },
    {
      "epoch": 0.3649899157669949,
      "grad_norm": 0.00906011089682579,
      "learning_rate": 1.411152122330609e-05,
      "loss": 0.0004,
      "step": 6153
    },
    {
      "epoch": 0.36504923478467194,
      "grad_norm": 8.115862846374512,
      "learning_rate": 1.4110203005536516e-05,
      "loss": 0.4937,
      "step": 6154
    },
    {
      "epoch": 0.365108553802349,
      "grad_norm": 8.05072021484375,
      "learning_rate": 1.410888478776694e-05,
      "loss": 0.2308,
      "step": 6155
    },
    {
      "epoch": 0.3651678728200261,
      "grad_norm": 1.0678555965423584,
      "learning_rate": 1.4107566569997365e-05,
      "loss": 0.0113,
      "step": 6156
    },
    {
      "epoch": 0.3652271918377032,
      "grad_norm": 0.023815931752324104,
      "learning_rate": 1.4106248352227789e-05,
      "loss": 0.0005,
      "step": 6157
    },
    {
      "epoch": 0.3652865108553802,
      "grad_norm": 2.670161247253418,
      "learning_rate": 1.4104930134458215e-05,
      "loss": 0.053,
      "step": 6158
    },
    {
      "epoch": 0.3653458298730573,
      "grad_norm": 0.3106454610824585,
      "learning_rate": 1.4103611916688637e-05,
      "loss": 0.0057,
      "step": 6159
    },
    {
      "epoch": 0.3654051488907344,
      "grad_norm": 0.2883167862892151,
      "learning_rate": 1.4102293698919063e-05,
      "loss": 0.0047,
      "step": 6160
    },
    {
      "epoch": 0.3654644679084114,
      "grad_norm": 14.978729248046875,
      "learning_rate": 1.4100975481149487e-05,
      "loss": 0.2777,
      "step": 6161
    },
    {
      "epoch": 0.3655237869260885,
      "grad_norm": 0.04584822058677673,
      "learning_rate": 1.4099657263379912e-05,
      "loss": 0.0015,
      "step": 6162
    },
    {
      "epoch": 0.3655831059437656,
      "grad_norm": 4.539613723754883,
      "learning_rate": 1.4098339045610336e-05,
      "loss": 0.0781,
      "step": 6163
    },
    {
      "epoch": 0.3656424249614426,
      "grad_norm": 1.688930630683899,
      "learning_rate": 1.409702082784076e-05,
      "loss": 0.019,
      "step": 6164
    },
    {
      "epoch": 0.3657017439791197,
      "grad_norm": 27.0759220123291,
      "learning_rate": 1.4095702610071184e-05,
      "loss": 0.5228,
      "step": 6165
    },
    {
      "epoch": 0.3657610629967968,
      "grad_norm": 0.014859943650662899,
      "learning_rate": 1.409438439230161e-05,
      "loss": 0.0004,
      "step": 6166
    },
    {
      "epoch": 0.36582038201447387,
      "grad_norm": 5.920302867889404,
      "learning_rate": 1.4093066174532033e-05,
      "loss": 0.0521,
      "step": 6167
    },
    {
      "epoch": 0.3658797010321509,
      "grad_norm": 7.818828105926514,
      "learning_rate": 1.4091747956762458e-05,
      "loss": 0.1138,
      "step": 6168
    },
    {
      "epoch": 0.365939020049828,
      "grad_norm": 0.03990788385272026,
      "learning_rate": 1.4090429738992884e-05,
      "loss": 0.0012,
      "step": 6169
    },
    {
      "epoch": 0.36599833906750506,
      "grad_norm": 0.04195030778646469,
      "learning_rate": 1.4089111521223307e-05,
      "loss": 0.0008,
      "step": 6170
    },
    {
      "epoch": 0.3660576580851821,
      "grad_norm": 0.7159849405288696,
      "learning_rate": 1.4087793303453731e-05,
      "loss": 0.0105,
      "step": 6171
    },
    {
      "epoch": 0.3661169771028592,
      "grad_norm": 21.781932830810547,
      "learning_rate": 1.4086475085684157e-05,
      "loss": 0.7447,
      "step": 6172
    },
    {
      "epoch": 0.36617629612053626,
      "grad_norm": 17.767356872558594,
      "learning_rate": 1.408515686791458e-05,
      "loss": 0.893,
      "step": 6173
    },
    {
      "epoch": 0.3662356151382133,
      "grad_norm": 8.105413436889648,
      "learning_rate": 1.4083838650145005e-05,
      "loss": 0.272,
      "step": 6174
    },
    {
      "epoch": 0.3662949341558904,
      "grad_norm": 8.329474449157715,
      "learning_rate": 1.4082520432375431e-05,
      "loss": 0.8868,
      "step": 6175
    },
    {
      "epoch": 0.36635425317356746,
      "grad_norm": 5.945667743682861,
      "learning_rate": 1.4081202214605854e-05,
      "loss": 0.0352,
      "step": 6176
    },
    {
      "epoch": 0.3664135721912445,
      "grad_norm": 11.035651206970215,
      "learning_rate": 1.407988399683628e-05,
      "loss": 0.8339,
      "step": 6177
    },
    {
      "epoch": 0.36647289120892157,
      "grad_norm": 10.296767234802246,
      "learning_rate": 1.4078565779066704e-05,
      "loss": 0.565,
      "step": 6178
    },
    {
      "epoch": 0.36653221022659865,
      "grad_norm": 0.8062202334403992,
      "learning_rate": 1.4077247561297128e-05,
      "loss": 0.0065,
      "step": 6179
    },
    {
      "epoch": 0.36659152924427574,
      "grad_norm": 23.748111724853516,
      "learning_rate": 1.4075929343527552e-05,
      "loss": 0.4244,
      "step": 6180
    },
    {
      "epoch": 0.36665084826195277,
      "grad_norm": 14.018293380737305,
      "learning_rate": 1.4074611125757976e-05,
      "loss": 0.4854,
      "step": 6181
    },
    {
      "epoch": 0.36671016727962985,
      "grad_norm": 2.539519786834717,
      "learning_rate": 1.40732929079884e-05,
      "loss": 0.0394,
      "step": 6182
    },
    {
      "epoch": 0.36676948629730693,
      "grad_norm": 0.8942210078239441,
      "learning_rate": 1.4071974690218826e-05,
      "loss": 0.0111,
      "step": 6183
    },
    {
      "epoch": 0.36682880531498396,
      "grad_norm": 3.1261589527130127,
      "learning_rate": 1.4070656472449249e-05,
      "loss": 0.0604,
      "step": 6184
    },
    {
      "epoch": 0.36688812433266105,
      "grad_norm": 10.0478515625,
      "learning_rate": 1.4069338254679675e-05,
      "loss": 0.2014,
      "step": 6185
    },
    {
      "epoch": 0.36694744335033813,
      "grad_norm": 5.60019063949585,
      "learning_rate": 1.4068020036910099e-05,
      "loss": 0.4248,
      "step": 6186
    },
    {
      "epoch": 0.36700676236801516,
      "grad_norm": 0.7663553953170776,
      "learning_rate": 1.4066701819140523e-05,
      "loss": 0.0097,
      "step": 6187
    },
    {
      "epoch": 0.36706608138569224,
      "grad_norm": 12.027070999145508,
      "learning_rate": 1.4065383601370947e-05,
      "loss": 0.3239,
      "step": 6188
    },
    {
      "epoch": 0.36712540040336933,
      "grad_norm": 5.806207180023193,
      "learning_rate": 1.4064065383601373e-05,
      "loss": 0.0798,
      "step": 6189
    },
    {
      "epoch": 0.3671847194210464,
      "grad_norm": 0.13659131526947021,
      "learning_rate": 1.4062747165831796e-05,
      "loss": 0.0015,
      "step": 6190
    },
    {
      "epoch": 0.36724403843872344,
      "grad_norm": 0.06035766005516052,
      "learning_rate": 1.4061428948062221e-05,
      "loss": 0.0019,
      "step": 6191
    },
    {
      "epoch": 0.3673033574564005,
      "grad_norm": 4.522428512573242,
      "learning_rate": 1.4060110730292646e-05,
      "loss": 0.0458,
      "step": 6192
    },
    {
      "epoch": 0.3673626764740776,
      "grad_norm": 11.508015632629395,
      "learning_rate": 1.405879251252307e-05,
      "loss": 0.2345,
      "step": 6193
    },
    {
      "epoch": 0.36742199549175464,
      "grad_norm": 13.009713172912598,
      "learning_rate": 1.4057474294753494e-05,
      "loss": 0.1675,
      "step": 6194
    },
    {
      "epoch": 0.3674813145094317,
      "grad_norm": 4.607023239135742,
      "learning_rate": 1.4056156076983918e-05,
      "loss": 0.0852,
      "step": 6195
    },
    {
      "epoch": 0.3675406335271088,
      "grad_norm": 9.120434761047363,
      "learning_rate": 1.4054837859214342e-05,
      "loss": 0.1666,
      "step": 6196
    },
    {
      "epoch": 0.36759995254478584,
      "grad_norm": 0.27678924798965454,
      "learning_rate": 1.4053519641444768e-05,
      "loss": 0.0045,
      "step": 6197
    },
    {
      "epoch": 0.3676592715624629,
      "grad_norm": 5.967755317687988,
      "learning_rate": 1.405220142367519e-05,
      "loss": 0.4308,
      "step": 6198
    },
    {
      "epoch": 0.36771859058014,
      "grad_norm": 3.0582826137542725,
      "learning_rate": 1.4050883205905617e-05,
      "loss": 0.0795,
      "step": 6199
    },
    {
      "epoch": 0.3677779095978171,
      "grad_norm": 13.13331413269043,
      "learning_rate": 1.4049564988136043e-05,
      "loss": 0.0542,
      "step": 6200
    },
    {
      "epoch": 0.3678372286154941,
      "grad_norm": 3.677645444869995,
      "learning_rate": 1.4048246770366465e-05,
      "loss": 0.0261,
      "step": 6201
    },
    {
      "epoch": 0.3678965476331712,
      "grad_norm": 0.06256123632192612,
      "learning_rate": 1.4046928552596891e-05,
      "loss": 0.0008,
      "step": 6202
    },
    {
      "epoch": 0.3679558666508483,
      "grad_norm": 0.07100293785333633,
      "learning_rate": 1.4045610334827315e-05,
      "loss": 0.0012,
      "step": 6203
    },
    {
      "epoch": 0.3680151856685253,
      "grad_norm": 0.11888907104730606,
      "learning_rate": 1.4044292117057738e-05,
      "loss": 0.0028,
      "step": 6204
    },
    {
      "epoch": 0.3680745046862024,
      "grad_norm": 2.962738275527954,
      "learning_rate": 1.4042973899288163e-05,
      "loss": 0.0178,
      "step": 6205
    },
    {
      "epoch": 0.3681338237038795,
      "grad_norm": 2.300626754760742,
      "learning_rate": 1.404165568151859e-05,
      "loss": 0.012,
      "step": 6206
    },
    {
      "epoch": 0.3681931427215565,
      "grad_norm": 3.5113978385925293,
      "learning_rate": 1.4040337463749012e-05,
      "loss": 0.2454,
      "step": 6207
    },
    {
      "epoch": 0.3682524617392336,
      "grad_norm": 3.3246419429779053,
      "learning_rate": 1.4039019245979438e-05,
      "loss": 0.4591,
      "step": 6208
    },
    {
      "epoch": 0.3683117807569107,
      "grad_norm": 10.738000869750977,
      "learning_rate": 1.4037701028209862e-05,
      "loss": 0.6533,
      "step": 6209
    },
    {
      "epoch": 0.3683710997745877,
      "grad_norm": 0.2953295111656189,
      "learning_rate": 1.4036382810440286e-05,
      "loss": 0.0042,
      "step": 6210
    },
    {
      "epoch": 0.3684304187922648,
      "grad_norm": 64.40846252441406,
      "learning_rate": 1.403506459267071e-05,
      "loss": 1.9595,
      "step": 6211
    },
    {
      "epoch": 0.3684897378099419,
      "grad_norm": 7.092153072357178,
      "learning_rate": 1.4033746374901135e-05,
      "loss": 0.0962,
      "step": 6212
    },
    {
      "epoch": 0.36854905682761896,
      "grad_norm": 0.3579344153404236,
      "learning_rate": 1.4032428157131559e-05,
      "loss": 0.0029,
      "step": 6213
    },
    {
      "epoch": 0.368608375845296,
      "grad_norm": 9.790264129638672,
      "learning_rate": 1.4031109939361985e-05,
      "loss": 0.1909,
      "step": 6214
    },
    {
      "epoch": 0.36866769486297307,
      "grad_norm": 0.3087697923183441,
      "learning_rate": 1.4029791721592407e-05,
      "loss": 0.0031,
      "step": 6215
    },
    {
      "epoch": 0.36872701388065016,
      "grad_norm": 17.01412582397461,
      "learning_rate": 1.4028473503822833e-05,
      "loss": 0.0541,
      "step": 6216
    },
    {
      "epoch": 0.3687863328983272,
      "grad_norm": 0.7743797898292542,
      "learning_rate": 1.4027155286053257e-05,
      "loss": 0.0132,
      "step": 6217
    },
    {
      "epoch": 0.36884565191600427,
      "grad_norm": 3.889880657196045,
      "learning_rate": 1.4025837068283681e-05,
      "loss": 0.1967,
      "step": 6218
    },
    {
      "epoch": 0.36890497093368135,
      "grad_norm": 0.18048758804798126,
      "learning_rate": 1.4024518850514106e-05,
      "loss": 0.0036,
      "step": 6219
    },
    {
      "epoch": 0.3689642899513584,
      "grad_norm": 8.377460479736328,
      "learning_rate": 1.4023200632744531e-05,
      "loss": 0.1165,
      "step": 6220
    },
    {
      "epoch": 0.36902360896903547,
      "grad_norm": 2.9346671104431152,
      "learning_rate": 1.4021882414974954e-05,
      "loss": 0.0487,
      "step": 6221
    },
    {
      "epoch": 0.36908292798671255,
      "grad_norm": 0.18568381667137146,
      "learning_rate": 1.402056419720538e-05,
      "loss": 0.0033,
      "step": 6222
    },
    {
      "epoch": 0.36914224700438963,
      "grad_norm": 9.410614967346191,
      "learning_rate": 1.4019245979435806e-05,
      "loss": 0.1485,
      "step": 6223
    },
    {
      "epoch": 0.36920156602206666,
      "grad_norm": 0.39203590154647827,
      "learning_rate": 1.4017927761666228e-05,
      "loss": 0.0052,
      "step": 6224
    },
    {
      "epoch": 0.36926088503974375,
      "grad_norm": 0.060037434101104736,
      "learning_rate": 1.4016609543896654e-05,
      "loss": 0.0019,
      "step": 6225
    },
    {
      "epoch": 0.36932020405742083,
      "grad_norm": 2.2777509689331055,
      "learning_rate": 1.4015291326127078e-05,
      "loss": 0.0164,
      "step": 6226
    },
    {
      "epoch": 0.36937952307509786,
      "grad_norm": 1.6359443664550781,
      "learning_rate": 1.40139731083575e-05,
      "loss": 0.015,
      "step": 6227
    },
    {
      "epoch": 0.36943884209277494,
      "grad_norm": 22.72946548461914,
      "learning_rate": 1.4012654890587927e-05,
      "loss": 0.3009,
      "step": 6228
    },
    {
      "epoch": 0.36949816111045203,
      "grad_norm": 11.08419132232666,
      "learning_rate": 1.4011336672818349e-05,
      "loss": 1.2306,
      "step": 6229
    },
    {
      "epoch": 0.36955748012812906,
      "grad_norm": 7.093306541442871,
      "learning_rate": 1.4010018455048775e-05,
      "loss": 0.2321,
      "step": 6230
    },
    {
      "epoch": 0.36961679914580614,
      "grad_norm": 0.22880828380584717,
      "learning_rate": 1.40087002372792e-05,
      "loss": 0.0035,
      "step": 6231
    },
    {
      "epoch": 0.3696761181634832,
      "grad_norm": 13.530521392822266,
      "learning_rate": 1.4007382019509623e-05,
      "loss": 0.1352,
      "step": 6232
    },
    {
      "epoch": 0.36973543718116025,
      "grad_norm": 7.632521629333496,
      "learning_rate": 1.400606380174005e-05,
      "loss": 0.3193,
      "step": 6233
    },
    {
      "epoch": 0.36979475619883734,
      "grad_norm": 11.400543212890625,
      "learning_rate": 1.4004745583970473e-05,
      "loss": 0.1044,
      "step": 6234
    },
    {
      "epoch": 0.3698540752165144,
      "grad_norm": 0.17191797494888306,
      "learning_rate": 1.4003427366200898e-05,
      "loss": 0.0037,
      "step": 6235
    },
    {
      "epoch": 0.3699133942341915,
      "grad_norm": 10.403839111328125,
      "learning_rate": 1.4002109148431322e-05,
      "loss": 0.1352,
      "step": 6236
    },
    {
      "epoch": 0.36997271325186853,
      "grad_norm": 6.945317268371582,
      "learning_rate": 1.4000790930661748e-05,
      "loss": 0.146,
      "step": 6237
    },
    {
      "epoch": 0.3700320322695456,
      "grad_norm": 0.2829468548297882,
      "learning_rate": 1.399947271289217e-05,
      "loss": 0.0035,
      "step": 6238
    },
    {
      "epoch": 0.3700913512872227,
      "grad_norm": 4.555628776550293,
      "learning_rate": 1.3998154495122596e-05,
      "loss": 0.0587,
      "step": 6239
    },
    {
      "epoch": 0.37015067030489973,
      "grad_norm": 17.235633850097656,
      "learning_rate": 1.399683627735302e-05,
      "loss": 0.5521,
      "step": 6240
    },
    {
      "epoch": 0.3702099893225768,
      "grad_norm": 4.199375629425049,
      "learning_rate": 1.3995518059583444e-05,
      "loss": 0.1856,
      "step": 6241
    },
    {
      "epoch": 0.3702693083402539,
      "grad_norm": 3.250765800476074,
      "learning_rate": 1.3994199841813869e-05,
      "loss": 0.1501,
      "step": 6242
    },
    {
      "epoch": 0.37032862735793093,
      "grad_norm": 0.23963207006454468,
      "learning_rate": 1.3992881624044293e-05,
      "loss": 0.0026,
      "step": 6243
    },
    {
      "epoch": 0.370387946375608,
      "grad_norm": 14.10142993927002,
      "learning_rate": 1.3991563406274717e-05,
      "loss": 0.7389,
      "step": 6244
    },
    {
      "epoch": 0.3704472653932851,
      "grad_norm": 6.57108736038208,
      "learning_rate": 1.3990245188505143e-05,
      "loss": 0.2524,
      "step": 6245
    },
    {
      "epoch": 0.3705065844109622,
      "grad_norm": 0.017315182834863663,
      "learning_rate": 1.3988926970735565e-05,
      "loss": 0.0005,
      "step": 6246
    },
    {
      "epoch": 0.3705659034286392,
      "grad_norm": 0.16209419071674347,
      "learning_rate": 1.3987608752965991e-05,
      "loss": 0.0037,
      "step": 6247
    },
    {
      "epoch": 0.3706252224463163,
      "grad_norm": 1.968892216682434,
      "learning_rate": 1.3986290535196415e-05,
      "loss": 0.0215,
      "step": 6248
    },
    {
      "epoch": 0.3706845414639934,
      "grad_norm": 0.28612399101257324,
      "learning_rate": 1.398497231742684e-05,
      "loss": 0.0023,
      "step": 6249
    },
    {
      "epoch": 0.3707438604816704,
      "grad_norm": 0.1611621081829071,
      "learning_rate": 1.3983654099657264e-05,
      "loss": 0.003,
      "step": 6250
    },
    {
      "epoch": 0.3708031794993475,
      "grad_norm": 9.989788055419922,
      "learning_rate": 1.398233588188769e-05,
      "loss": 0.0924,
      "step": 6251
    },
    {
      "epoch": 0.3708624985170246,
      "grad_norm": 0.24906277656555176,
      "learning_rate": 1.3981017664118112e-05,
      "loss": 0.0029,
      "step": 6252
    },
    {
      "epoch": 0.3709218175347016,
      "grad_norm": 7.077434539794922,
      "learning_rate": 1.3979699446348538e-05,
      "loss": 0.2464,
      "step": 6253
    },
    {
      "epoch": 0.3709811365523787,
      "grad_norm": 6.713737964630127,
      "learning_rate": 1.3978381228578964e-05,
      "loss": 0.0365,
      "step": 6254
    },
    {
      "epoch": 0.37104045557005577,
      "grad_norm": 0.6645397543907166,
      "learning_rate": 1.3977063010809386e-05,
      "loss": 0.0103,
      "step": 6255
    },
    {
      "epoch": 0.3710997745877328,
      "grad_norm": 14.974096298217773,
      "learning_rate": 1.3975744793039812e-05,
      "loss": 0.4983,
      "step": 6256
    },
    {
      "epoch": 0.3711590936054099,
      "grad_norm": 2.8306500911712646,
      "learning_rate": 1.3974426575270236e-05,
      "loss": 0.0458,
      "step": 6257
    },
    {
      "epoch": 0.37121841262308697,
      "grad_norm": 0.03525349125266075,
      "learning_rate": 1.397310835750066e-05,
      "loss": 0.0008,
      "step": 6258
    },
    {
      "epoch": 0.37127773164076405,
      "grad_norm": 0.7458527088165283,
      "learning_rate": 1.3971790139731085e-05,
      "loss": 0.009,
      "step": 6259
    },
    {
      "epoch": 0.3713370506584411,
      "grad_norm": 0.02252073772251606,
      "learning_rate": 1.3970471921961507e-05,
      "loss": 0.0005,
      "step": 6260
    },
    {
      "epoch": 0.37139636967611817,
      "grad_norm": 4.827846050262451,
      "learning_rate": 1.3969153704191933e-05,
      "loss": 0.0807,
      "step": 6261
    },
    {
      "epoch": 0.37145568869379525,
      "grad_norm": 9.56661319732666,
      "learning_rate": 1.3967835486422359e-05,
      "loss": 0.1497,
      "step": 6262
    },
    {
      "epoch": 0.3715150077114723,
      "grad_norm": 0.15306536853313446,
      "learning_rate": 1.3966517268652782e-05,
      "loss": 0.0022,
      "step": 6263
    },
    {
      "epoch": 0.37157432672914936,
      "grad_norm": 10.845539093017578,
      "learning_rate": 1.3965199050883207e-05,
      "loss": 0.2428,
      "step": 6264
    },
    {
      "epoch": 0.37163364574682645,
      "grad_norm": 7.718648910522461,
      "learning_rate": 1.3963880833113632e-05,
      "loss": 0.1055,
      "step": 6265
    },
    {
      "epoch": 0.3716929647645035,
      "grad_norm": 0.21704405546188354,
      "learning_rate": 1.3962562615344056e-05,
      "loss": 0.004,
      "step": 6266
    },
    {
      "epoch": 0.37175228378218056,
      "grad_norm": 2.9521899223327637,
      "learning_rate": 1.396124439757448e-05,
      "loss": 0.0167,
      "step": 6267
    },
    {
      "epoch": 0.37181160279985764,
      "grad_norm": 2.343299627304077,
      "learning_rate": 1.3959926179804906e-05,
      "loss": 0.0281,
      "step": 6268
    },
    {
      "epoch": 0.3718709218175347,
      "grad_norm": 9.240561485290527,
      "learning_rate": 1.3958607962035328e-05,
      "loss": 0.2287,
      "step": 6269
    },
    {
      "epoch": 0.37193024083521176,
      "grad_norm": 20.11457061767578,
      "learning_rate": 1.3957289744265754e-05,
      "loss": 0.6036,
      "step": 6270
    },
    {
      "epoch": 0.37198955985288884,
      "grad_norm": 0.23079094290733337,
      "learning_rate": 1.3955971526496178e-05,
      "loss": 0.0028,
      "step": 6271
    },
    {
      "epoch": 0.3720488788705659,
      "grad_norm": 1.3860327005386353,
      "learning_rate": 1.3954653308726603e-05,
      "loss": 0.0245,
      "step": 6272
    },
    {
      "epoch": 0.37210819788824295,
      "grad_norm": 0.02861117571592331,
      "learning_rate": 1.3953335090957027e-05,
      "loss": 0.0008,
      "step": 6273
    },
    {
      "epoch": 0.37216751690592004,
      "grad_norm": 0.012578753754496574,
      "learning_rate": 1.3952016873187453e-05,
      "loss": 0.0004,
      "step": 6274
    },
    {
      "epoch": 0.3722268359235971,
      "grad_norm": 3.0310487747192383,
      "learning_rate": 1.3950698655417875e-05,
      "loss": 0.0233,
      "step": 6275
    },
    {
      "epoch": 0.37228615494127415,
      "grad_norm": 0.10037913173437119,
      "learning_rate": 1.3949380437648301e-05,
      "loss": 0.0012,
      "step": 6276
    },
    {
      "epoch": 0.37234547395895123,
      "grad_norm": 2.964043617248535,
      "learning_rate": 1.3948062219878724e-05,
      "loss": 0.0166,
      "step": 6277
    },
    {
      "epoch": 0.3724047929766283,
      "grad_norm": 0.63788902759552,
      "learning_rate": 1.394674400210915e-05,
      "loss": 0.0072,
      "step": 6278
    },
    {
      "epoch": 0.37246411199430535,
      "grad_norm": 30.011070251464844,
      "learning_rate": 1.3945425784339575e-05,
      "loss": 0.7741,
      "step": 6279
    },
    {
      "epoch": 0.37252343101198243,
      "grad_norm": 0.22989289462566376,
      "learning_rate": 1.3944107566569998e-05,
      "loss": 0.0033,
      "step": 6280
    },
    {
      "epoch": 0.3725827500296595,
      "grad_norm": 3.5430290699005127,
      "learning_rate": 1.3942789348800424e-05,
      "loss": 0.0593,
      "step": 6281
    },
    {
      "epoch": 0.3726420690473366,
      "grad_norm": 19.148664474487305,
      "learning_rate": 1.3941471131030848e-05,
      "loss": 0.408,
      "step": 6282
    },
    {
      "epoch": 0.37270138806501363,
      "grad_norm": 11.564997673034668,
      "learning_rate": 1.394015291326127e-05,
      "loss": 0.0693,
      "step": 6283
    },
    {
      "epoch": 0.3727607070826907,
      "grad_norm": 0.03717178851366043,
      "learning_rate": 1.3938834695491696e-05,
      "loss": 0.0007,
      "step": 6284
    },
    {
      "epoch": 0.3728200261003678,
      "grad_norm": 19.9725399017334,
      "learning_rate": 1.3937516477722122e-05,
      "loss": 0.7681,
      "step": 6285
    },
    {
      "epoch": 0.3728793451180448,
      "grad_norm": 0.0685582235455513,
      "learning_rate": 1.3936198259952545e-05,
      "loss": 0.0015,
      "step": 6286
    },
    {
      "epoch": 0.3729386641357219,
      "grad_norm": 1.191972255706787,
      "learning_rate": 1.393488004218297e-05,
      "loss": 0.0159,
      "step": 6287
    },
    {
      "epoch": 0.372997983153399,
      "grad_norm": 0.0632457584142685,
      "learning_rate": 1.3933561824413395e-05,
      "loss": 0.0009,
      "step": 6288
    },
    {
      "epoch": 0.373057302171076,
      "grad_norm": 20.07666015625,
      "learning_rate": 1.3932243606643819e-05,
      "loss": 0.2173,
      "step": 6289
    },
    {
      "epoch": 0.3731166211887531,
      "grad_norm": 2.0243096351623535,
      "learning_rate": 1.3930925388874243e-05,
      "loss": 0.0188,
      "step": 6290
    },
    {
      "epoch": 0.3731759402064302,
      "grad_norm": 0.01687082275748253,
      "learning_rate": 1.3929607171104667e-05,
      "loss": 0.0007,
      "step": 6291
    },
    {
      "epoch": 0.3732352592241073,
      "grad_norm": 0.5021461248397827,
      "learning_rate": 1.3928288953335091e-05,
      "loss": 0.0097,
      "step": 6292
    },
    {
      "epoch": 0.3732945782417843,
      "grad_norm": 4.65571928024292,
      "learning_rate": 1.3926970735565517e-05,
      "loss": 0.0335,
      "step": 6293
    },
    {
      "epoch": 0.3733538972594614,
      "grad_norm": 0.44086018204689026,
      "learning_rate": 1.392565251779594e-05,
      "loss": 0.0051,
      "step": 6294
    },
    {
      "epoch": 0.37341321627713847,
      "grad_norm": 7.2163310050964355,
      "learning_rate": 1.3924334300026366e-05,
      "loss": 0.1388,
      "step": 6295
    },
    {
      "epoch": 0.3734725352948155,
      "grad_norm": 0.03864545375108719,
      "learning_rate": 1.392301608225679e-05,
      "loss": 0.0009,
      "step": 6296
    },
    {
      "epoch": 0.3735318543124926,
      "grad_norm": 3.5869598388671875,
      "learning_rate": 1.3921697864487214e-05,
      "loss": 0.1676,
      "step": 6297
    },
    {
      "epoch": 0.37359117333016967,
      "grad_norm": 6.086640357971191,
      "learning_rate": 1.3920379646717638e-05,
      "loss": 0.1415,
      "step": 6298
    },
    {
      "epoch": 0.3736504923478467,
      "grad_norm": 21.412033081054688,
      "learning_rate": 1.3919061428948064e-05,
      "loss": 0.4815,
      "step": 6299
    },
    {
      "epoch": 0.3737098113655238,
      "grad_norm": 17.282825469970703,
      "learning_rate": 1.3917743211178487e-05,
      "loss": 0.5491,
      "step": 6300
    },
    {
      "epoch": 0.37376913038320086,
      "grad_norm": 27.88047981262207,
      "learning_rate": 1.3916424993408913e-05,
      "loss": 0.0832,
      "step": 6301
    },
    {
      "epoch": 0.37382844940087795,
      "grad_norm": 0.35422784090042114,
      "learning_rate": 1.3915106775639338e-05,
      "loss": 0.0037,
      "step": 6302
    },
    {
      "epoch": 0.373887768418555,
      "grad_norm": 3.2014172077178955,
      "learning_rate": 1.3913788557869761e-05,
      "loss": 0.0351,
      "step": 6303
    },
    {
      "epoch": 0.37394708743623206,
      "grad_norm": 3.744173526763916,
      "learning_rate": 1.3912470340100185e-05,
      "loss": 0.0922,
      "step": 6304
    },
    {
      "epoch": 0.37400640645390915,
      "grad_norm": 0.2515498995780945,
      "learning_rate": 1.3911152122330611e-05,
      "loss": 0.0053,
      "step": 6305
    },
    {
      "epoch": 0.3740657254715862,
      "grad_norm": 0.05090295895934105,
      "learning_rate": 1.3909833904561033e-05,
      "loss": 0.0009,
      "step": 6306
    },
    {
      "epoch": 0.37412504448926326,
      "grad_norm": 11.60030460357666,
      "learning_rate": 1.390851568679146e-05,
      "loss": 0.1415,
      "step": 6307
    },
    {
      "epoch": 0.37418436350694034,
      "grad_norm": 10.092052459716797,
      "learning_rate": 1.3907197469021882e-05,
      "loss": 0.0771,
      "step": 6308
    },
    {
      "epoch": 0.37424368252461737,
      "grad_norm": 43.36116027832031,
      "learning_rate": 1.3905879251252308e-05,
      "loss": 0.8834,
      "step": 6309
    },
    {
      "epoch": 0.37430300154229446,
      "grad_norm": 8.107904434204102,
      "learning_rate": 1.3904561033482734e-05,
      "loss": 0.1579,
      "step": 6310
    },
    {
      "epoch": 0.37436232055997154,
      "grad_norm": 0.024920757859945297,
      "learning_rate": 1.3903242815713156e-05,
      "loss": 0.0004,
      "step": 6311
    },
    {
      "epoch": 0.37442163957764857,
      "grad_norm": 4.32274866104126,
      "learning_rate": 1.3901924597943582e-05,
      "loss": 0.116,
      "step": 6312
    },
    {
      "epoch": 0.37448095859532565,
      "grad_norm": 0.2440793216228485,
      "learning_rate": 1.3900606380174006e-05,
      "loss": 0.0051,
      "step": 6313
    },
    {
      "epoch": 0.37454027761300274,
      "grad_norm": 0.010332496836781502,
      "learning_rate": 1.389928816240443e-05,
      "loss": 0.0004,
      "step": 6314
    },
    {
      "epoch": 0.3745995966306798,
      "grad_norm": 15.016647338867188,
      "learning_rate": 1.3897969944634855e-05,
      "loss": 0.1402,
      "step": 6315
    },
    {
      "epoch": 0.37465891564835685,
      "grad_norm": 14.027681350708008,
      "learning_rate": 1.389665172686528e-05,
      "loss": 0.3409,
      "step": 6316
    },
    {
      "epoch": 0.37471823466603393,
      "grad_norm": 10.512633323669434,
      "learning_rate": 1.3895333509095703e-05,
      "loss": 0.6327,
      "step": 6317
    },
    {
      "epoch": 0.374777553683711,
      "grad_norm": 9.601046562194824,
      "learning_rate": 1.3894015291326129e-05,
      "loss": 0.2439,
      "step": 6318
    },
    {
      "epoch": 0.37483687270138805,
      "grad_norm": 0.48264843225479126,
      "learning_rate": 1.3892697073556553e-05,
      "loss": 0.012,
      "step": 6319
    },
    {
      "epoch": 0.37489619171906513,
      "grad_norm": 12.966381072998047,
      "learning_rate": 1.3891378855786977e-05,
      "loss": 0.2792,
      "step": 6320
    },
    {
      "epoch": 0.3749555107367422,
      "grad_norm": 0.083527572453022,
      "learning_rate": 1.3890060638017401e-05,
      "loss": 0.0012,
      "step": 6321
    },
    {
      "epoch": 0.37501482975441924,
      "grad_norm": 8.111679077148438,
      "learning_rate": 1.3888742420247827e-05,
      "loss": 0.091,
      "step": 6322
    },
    {
      "epoch": 0.3750741487720963,
      "grad_norm": 5.82553243637085,
      "learning_rate": 1.388742420247825e-05,
      "loss": 0.0831,
      "step": 6323
    },
    {
      "epoch": 0.3751334677897734,
      "grad_norm": 0.5667573809623718,
      "learning_rate": 1.3886105984708676e-05,
      "loss": 0.0034,
      "step": 6324
    },
    {
      "epoch": 0.3751927868074505,
      "grad_norm": 4.677309989929199,
      "learning_rate": 1.3884787766939098e-05,
      "loss": 0.0237,
      "step": 6325
    },
    {
      "epoch": 0.3752521058251275,
      "grad_norm": 13.75461483001709,
      "learning_rate": 1.3883469549169524e-05,
      "loss": 0.1601,
      "step": 6326
    },
    {
      "epoch": 0.3753114248428046,
      "grad_norm": 3.6754143238067627,
      "learning_rate": 1.3882151331399948e-05,
      "loss": 0.0443,
      "step": 6327
    },
    {
      "epoch": 0.3753707438604817,
      "grad_norm": 0.016917292028665543,
      "learning_rate": 1.3880833113630372e-05,
      "loss": 0.0005,
      "step": 6328
    },
    {
      "epoch": 0.3754300628781587,
      "grad_norm": 0.189839169383049,
      "learning_rate": 1.3879514895860797e-05,
      "loss": 0.0028,
      "step": 6329
    },
    {
      "epoch": 0.3754893818958358,
      "grad_norm": 35.71076583862305,
      "learning_rate": 1.3878196678091222e-05,
      "loss": 0.1288,
      "step": 6330
    },
    {
      "epoch": 0.3755487009135129,
      "grad_norm": 34.051204681396484,
      "learning_rate": 1.3876878460321645e-05,
      "loss": 0.4664,
      "step": 6331
    },
    {
      "epoch": 0.3756080199311899,
      "grad_norm": 0.11073659360408783,
      "learning_rate": 1.387556024255207e-05,
      "loss": 0.0014,
      "step": 6332
    },
    {
      "epoch": 0.375667338948867,
      "grad_norm": 0.2567630708217621,
      "learning_rate": 1.3874242024782497e-05,
      "loss": 0.0027,
      "step": 6333
    },
    {
      "epoch": 0.3757266579665441,
      "grad_norm": 0.011895385570824146,
      "learning_rate": 1.387292380701292e-05,
      "loss": 0.0003,
      "step": 6334
    },
    {
      "epoch": 0.3757859769842211,
      "grad_norm": 1.014836072921753,
      "learning_rate": 1.3871605589243345e-05,
      "loss": 0.0093,
      "step": 6335
    },
    {
      "epoch": 0.3758452960018982,
      "grad_norm": 0.032912787050008774,
      "learning_rate": 1.387028737147377e-05,
      "loss": 0.0007,
      "step": 6336
    },
    {
      "epoch": 0.3759046150195753,
      "grad_norm": 0.06097722798585892,
      "learning_rate": 1.3868969153704192e-05,
      "loss": 0.0016,
      "step": 6337
    },
    {
      "epoch": 0.37596393403725237,
      "grad_norm": 1.659513235092163,
      "learning_rate": 1.3867650935934618e-05,
      "loss": 0.01,
      "step": 6338
    },
    {
      "epoch": 0.3760232530549294,
      "grad_norm": 6.218993663787842,
      "learning_rate": 1.386633271816504e-05,
      "loss": 0.0728,
      "step": 6339
    },
    {
      "epoch": 0.3760825720726065,
      "grad_norm": 0.03349107876420021,
      "learning_rate": 1.3865014500395466e-05,
      "loss": 0.0006,
      "step": 6340
    },
    {
      "epoch": 0.37614189109028356,
      "grad_norm": 0.02149316668510437,
      "learning_rate": 1.3863696282625892e-05,
      "loss": 0.0006,
      "step": 6341
    },
    {
      "epoch": 0.3762012101079606,
      "grad_norm": 0.027454886585474014,
      "learning_rate": 1.3862378064856314e-05,
      "loss": 0.0006,
      "step": 6342
    },
    {
      "epoch": 0.3762605291256377,
      "grad_norm": 5.726175785064697,
      "learning_rate": 1.386105984708674e-05,
      "loss": 0.194,
      "step": 6343
    },
    {
      "epoch": 0.37631984814331476,
      "grad_norm": 0.23919083178043365,
      "learning_rate": 1.3859741629317164e-05,
      "loss": 0.0031,
      "step": 6344
    },
    {
      "epoch": 0.3763791671609918,
      "grad_norm": 0.29582443833351135,
      "learning_rate": 1.3858423411547589e-05,
      "loss": 0.0031,
      "step": 6345
    },
    {
      "epoch": 0.3764384861786689,
      "grad_norm": 0.15911036729812622,
      "learning_rate": 1.3857105193778013e-05,
      "loss": 0.004,
      "step": 6346
    },
    {
      "epoch": 0.37649780519634596,
      "grad_norm": 26.239534378051758,
      "learning_rate": 1.3855786976008439e-05,
      "loss": 0.452,
      "step": 6347
    },
    {
      "epoch": 0.37655712421402304,
      "grad_norm": 30.802356719970703,
      "learning_rate": 1.3854468758238861e-05,
      "loss": 0.4783,
      "step": 6348
    },
    {
      "epoch": 0.37661644323170007,
      "grad_norm": 11.527860641479492,
      "learning_rate": 1.3853150540469287e-05,
      "loss": 0.4507,
      "step": 6349
    },
    {
      "epoch": 0.37667576224937716,
      "grad_norm": 10.849410057067871,
      "learning_rate": 1.3851832322699711e-05,
      "loss": 0.3389,
      "step": 6350
    },
    {
      "epoch": 0.37673508126705424,
      "grad_norm": 3.0296237468719482,
      "learning_rate": 1.3850514104930135e-05,
      "loss": 0.1667,
      "step": 6351
    },
    {
      "epoch": 0.37679440028473127,
      "grad_norm": 34.514461517333984,
      "learning_rate": 1.384919588716056e-05,
      "loss": 0.5674,
      "step": 6352
    },
    {
      "epoch": 0.37685371930240835,
      "grad_norm": 7.623770236968994,
      "learning_rate": 1.3847877669390986e-05,
      "loss": 0.4909,
      "step": 6353
    },
    {
      "epoch": 0.37691303832008544,
      "grad_norm": 14.331042289733887,
      "learning_rate": 1.3846559451621408e-05,
      "loss": 0.2167,
      "step": 6354
    },
    {
      "epoch": 0.37697235733776246,
      "grad_norm": 0.21979199349880219,
      "learning_rate": 1.3845241233851834e-05,
      "loss": 0.0029,
      "step": 6355
    },
    {
      "epoch": 0.37703167635543955,
      "grad_norm": 3.307948350906372,
      "learning_rate": 1.3843923016082256e-05,
      "loss": 0.0255,
      "step": 6356
    },
    {
      "epoch": 0.37709099537311663,
      "grad_norm": 15.24543285369873,
      "learning_rate": 1.3842604798312682e-05,
      "loss": 1.2459,
      "step": 6357
    },
    {
      "epoch": 0.37715031439079366,
      "grad_norm": 19.092130661010742,
      "learning_rate": 1.3841286580543108e-05,
      "loss": 0.8228,
      "step": 6358
    },
    {
      "epoch": 0.37720963340847075,
      "grad_norm": 0.6842519044876099,
      "learning_rate": 1.383996836277353e-05,
      "loss": 0.0105,
      "step": 6359
    },
    {
      "epoch": 0.37726895242614783,
      "grad_norm": 0.1470995396375656,
      "learning_rate": 1.3838650145003955e-05,
      "loss": 0.0021,
      "step": 6360
    },
    {
      "epoch": 0.3773282714438249,
      "grad_norm": 0.03436535224318504,
      "learning_rate": 1.383733192723438e-05,
      "loss": 0.001,
      "step": 6361
    },
    {
      "epoch": 0.37738759046150194,
      "grad_norm": 0.4306645691394806,
      "learning_rate": 1.3836013709464803e-05,
      "loss": 0.0059,
      "step": 6362
    },
    {
      "epoch": 0.377446909479179,
      "grad_norm": 1.5529717206954956,
      "learning_rate": 1.3834695491695229e-05,
      "loss": 0.0192,
      "step": 6363
    },
    {
      "epoch": 0.3775062284968561,
      "grad_norm": 4.190718173980713,
      "learning_rate": 1.3833377273925655e-05,
      "loss": 0.0171,
      "step": 6364
    },
    {
      "epoch": 0.37756554751453314,
      "grad_norm": 1.7741904258728027,
      "learning_rate": 1.3832059056156077e-05,
      "loss": 0.0165,
      "step": 6365
    },
    {
      "epoch": 0.3776248665322102,
      "grad_norm": 0.0067311786115169525,
      "learning_rate": 1.3830740838386503e-05,
      "loss": 0.0003,
      "step": 6366
    },
    {
      "epoch": 0.3776841855498873,
      "grad_norm": 0.11789057403802872,
      "learning_rate": 1.3829422620616928e-05,
      "loss": 0.0015,
      "step": 6367
    },
    {
      "epoch": 0.37774350456756434,
      "grad_norm": 10.299057006835938,
      "learning_rate": 1.3828104402847352e-05,
      "loss": 0.0781,
      "step": 6368
    },
    {
      "epoch": 0.3778028235852414,
      "grad_norm": 0.03336176648736,
      "learning_rate": 1.3826786185077776e-05,
      "loss": 0.0006,
      "step": 6369
    },
    {
      "epoch": 0.3778621426029185,
      "grad_norm": 0.026882177218794823,
      "learning_rate": 1.3825467967308202e-05,
      "loss": 0.0007,
      "step": 6370
    },
    {
      "epoch": 0.3779214616205956,
      "grad_norm": 9.046591758728027,
      "learning_rate": 1.3824149749538624e-05,
      "loss": 0.0292,
      "step": 6371
    },
    {
      "epoch": 0.3779807806382726,
      "grad_norm": 19.654760360717773,
      "learning_rate": 1.382283153176905e-05,
      "loss": 0.1752,
      "step": 6372
    },
    {
      "epoch": 0.3780400996559497,
      "grad_norm": 0.11197328567504883,
      "learning_rate": 1.3821513313999473e-05,
      "loss": 0.0017,
      "step": 6373
    },
    {
      "epoch": 0.3780994186736268,
      "grad_norm": 0.2090122401714325,
      "learning_rate": 1.3820195096229899e-05,
      "loss": 0.0043,
      "step": 6374
    },
    {
      "epoch": 0.3781587376913038,
      "grad_norm": 0.5188727974891663,
      "learning_rate": 1.3818876878460323e-05,
      "loss": 0.0062,
      "step": 6375
    },
    {
      "epoch": 0.3782180567089809,
      "grad_norm": 1.2400972843170166,
      "learning_rate": 1.3817558660690747e-05,
      "loss": 0.0179,
      "step": 6376
    },
    {
      "epoch": 0.378277375726658,
      "grad_norm": 9.003615379333496,
      "learning_rate": 1.3816240442921171e-05,
      "loss": 0.3538,
      "step": 6377
    },
    {
      "epoch": 0.378336694744335,
      "grad_norm": 0.1173800528049469,
      "learning_rate": 1.3814922225151597e-05,
      "loss": 0.0017,
      "step": 6378
    },
    {
      "epoch": 0.3783960137620121,
      "grad_norm": 0.010153479874134064,
      "learning_rate": 1.381360400738202e-05,
      "loss": 0.0003,
      "step": 6379
    },
    {
      "epoch": 0.3784553327796892,
      "grad_norm": 0.7416516542434692,
      "learning_rate": 1.3812285789612445e-05,
      "loss": 0.0072,
      "step": 6380
    },
    {
      "epoch": 0.3785146517973662,
      "grad_norm": 10.764119148254395,
      "learning_rate": 1.3810967571842871e-05,
      "loss": 0.1993,
      "step": 6381
    },
    {
      "epoch": 0.3785739708150433,
      "grad_norm": 9.64089584350586,
      "learning_rate": 1.3809649354073294e-05,
      "loss": 0.0578,
      "step": 6382
    },
    {
      "epoch": 0.3786332898327204,
      "grad_norm": 23.10899543762207,
      "learning_rate": 1.3808331136303718e-05,
      "loss": 1.1018,
      "step": 6383
    },
    {
      "epoch": 0.37869260885039746,
      "grad_norm": 1.3551822900772095,
      "learning_rate": 1.3807012918534144e-05,
      "loss": 0.0156,
      "step": 6384
    },
    {
      "epoch": 0.3787519278680745,
      "grad_norm": 0.38889527320861816,
      "learning_rate": 1.3805694700764566e-05,
      "loss": 0.0038,
      "step": 6385
    },
    {
      "epoch": 0.3788112468857516,
      "grad_norm": 6.989540100097656,
      "learning_rate": 1.3804376482994992e-05,
      "loss": 0.128,
      "step": 6386
    },
    {
      "epoch": 0.37887056590342866,
      "grad_norm": 14.764602661132812,
      "learning_rate": 1.3803058265225418e-05,
      "loss": 1.1178,
      "step": 6387
    },
    {
      "epoch": 0.3789298849211057,
      "grad_norm": 29.606067657470703,
      "learning_rate": 1.380174004745584e-05,
      "loss": 1.252,
      "step": 6388
    },
    {
      "epoch": 0.37898920393878277,
      "grad_norm": 3.9321460723876953,
      "learning_rate": 1.3800421829686266e-05,
      "loss": 0.0229,
      "step": 6389
    },
    {
      "epoch": 0.37904852295645985,
      "grad_norm": 0.13380345702171326,
      "learning_rate": 1.3799103611916689e-05,
      "loss": 0.0029,
      "step": 6390
    },
    {
      "epoch": 0.3791078419741369,
      "grad_norm": 0.16207967698574066,
      "learning_rate": 1.3797785394147115e-05,
      "loss": 0.0027,
      "step": 6391
    },
    {
      "epoch": 0.37916716099181397,
      "grad_norm": 0.9421104192733765,
      "learning_rate": 1.3796467176377539e-05,
      "loss": 0.0078,
      "step": 6392
    },
    {
      "epoch": 0.37922648000949105,
      "grad_norm": 8.28975772857666,
      "learning_rate": 1.3795148958607961e-05,
      "loss": 0.1497,
      "step": 6393
    },
    {
      "epoch": 0.37928579902716814,
      "grad_norm": 13.039620399475098,
      "learning_rate": 1.3793830740838387e-05,
      "loss": 0.2901,
      "step": 6394
    },
    {
      "epoch": 0.37934511804484516,
      "grad_norm": 0.4386436343193054,
      "learning_rate": 1.3792512523068813e-05,
      "loss": 0.0088,
      "step": 6395
    },
    {
      "epoch": 0.37940443706252225,
      "grad_norm": 2.3063132762908936,
      "learning_rate": 1.3791194305299236e-05,
      "loss": 0.0143,
      "step": 6396
    },
    {
      "epoch": 0.37946375608019933,
      "grad_norm": 32.46891403198242,
      "learning_rate": 1.3789876087529662e-05,
      "loss": 0.1079,
      "step": 6397
    },
    {
      "epoch": 0.37952307509787636,
      "grad_norm": 0.32265615463256836,
      "learning_rate": 1.3788557869760086e-05,
      "loss": 0.0061,
      "step": 6398
    },
    {
      "epoch": 0.37958239411555345,
      "grad_norm": 0.3477821946144104,
      "learning_rate": 1.378723965199051e-05,
      "loss": 0.0021,
      "step": 6399
    },
    {
      "epoch": 0.37964171313323053,
      "grad_norm": 4.028804779052734,
      "learning_rate": 1.3785921434220934e-05,
      "loss": 0.1404,
      "step": 6400
    },
    {
      "epoch": 0.37970103215090756,
      "grad_norm": 0.036041442304849625,
      "learning_rate": 1.378460321645136e-05,
      "loss": 0.0009,
      "step": 6401
    },
    {
      "epoch": 0.37976035116858464,
      "grad_norm": 7.729593276977539,
      "learning_rate": 1.3783284998681783e-05,
      "loss": 0.2234,
      "step": 6402
    },
    {
      "epoch": 0.3798196701862617,
      "grad_norm": 0.05413397401571274,
      "learning_rate": 1.3781966780912208e-05,
      "loss": 0.0009,
      "step": 6403
    },
    {
      "epoch": 0.3798789892039388,
      "grad_norm": 0.5950656533241272,
      "learning_rate": 1.3780648563142631e-05,
      "loss": 0.0038,
      "step": 6404
    },
    {
      "epoch": 0.37993830822161584,
      "grad_norm": 0.4213157892227173,
      "learning_rate": 1.3779330345373057e-05,
      "loss": 0.0041,
      "step": 6405
    },
    {
      "epoch": 0.3799976272392929,
      "grad_norm": 10.513693809509277,
      "learning_rate": 1.3778012127603481e-05,
      "loss": 0.3291,
      "step": 6406
    },
    {
      "epoch": 0.38005694625697,
      "grad_norm": 0.33489635586738586,
      "learning_rate": 1.3776693909833905e-05,
      "loss": 0.0026,
      "step": 6407
    },
    {
      "epoch": 0.38011626527464704,
      "grad_norm": 0.7344319820404053,
      "learning_rate": 1.377537569206433e-05,
      "loss": 0.0131,
      "step": 6408
    },
    {
      "epoch": 0.3801755842923241,
      "grad_norm": 7.390782833099365,
      "learning_rate": 1.3774057474294755e-05,
      "loss": 0.0771,
      "step": 6409
    },
    {
      "epoch": 0.3802349033100012,
      "grad_norm": 0.9047533273696899,
      "learning_rate": 1.3772739256525178e-05,
      "loss": 0.0104,
      "step": 6410
    },
    {
      "epoch": 0.38029422232767823,
      "grad_norm": 2.300006628036499,
      "learning_rate": 1.3771421038755604e-05,
      "loss": 0.0363,
      "step": 6411
    },
    {
      "epoch": 0.3803535413453553,
      "grad_norm": 0.5604397058486938,
      "learning_rate": 1.377010282098603e-05,
      "loss": 0.0065,
      "step": 6412
    },
    {
      "epoch": 0.3804128603630324,
      "grad_norm": 4.770140647888184,
      "learning_rate": 1.3768784603216452e-05,
      "loss": 0.0508,
      "step": 6413
    },
    {
      "epoch": 0.38047217938070943,
      "grad_norm": 14.102834701538086,
      "learning_rate": 1.3767466385446878e-05,
      "loss": 0.3043,
      "step": 6414
    },
    {
      "epoch": 0.3805314983983865,
      "grad_norm": 10.2202787399292,
      "learning_rate": 1.3766148167677302e-05,
      "loss": 0.2503,
      "step": 6415
    },
    {
      "epoch": 0.3805908174160636,
      "grad_norm": 0.8124027848243713,
      "learning_rate": 1.3764829949907725e-05,
      "loss": 0.0107,
      "step": 6416
    },
    {
      "epoch": 0.3806501364337407,
      "grad_norm": 16.031803131103516,
      "learning_rate": 1.376351173213815e-05,
      "loss": 1.2193,
      "step": 6417
    },
    {
      "epoch": 0.3807094554514177,
      "grad_norm": 17.854902267456055,
      "learning_rate": 1.3762193514368576e-05,
      "loss": 0.6724,
      "step": 6418
    },
    {
      "epoch": 0.3807687744690948,
      "grad_norm": 10.713265419006348,
      "learning_rate": 1.3760875296598999e-05,
      "loss": 0.6896,
      "step": 6419
    },
    {
      "epoch": 0.3808280934867719,
      "grad_norm": 30.949201583862305,
      "learning_rate": 1.3759557078829425e-05,
      "loss": 0.1923,
      "step": 6420
    },
    {
      "epoch": 0.3808874125044489,
      "grad_norm": 6.986085891723633,
      "learning_rate": 1.3758238861059847e-05,
      "loss": 0.0951,
      "step": 6421
    },
    {
      "epoch": 0.380946731522126,
      "grad_norm": 9.219035148620605,
      "learning_rate": 1.3756920643290273e-05,
      "loss": 0.0253,
      "step": 6422
    },
    {
      "epoch": 0.3810060505398031,
      "grad_norm": 22.083383560180664,
      "learning_rate": 1.3755602425520697e-05,
      "loss": 0.5173,
      "step": 6423
    },
    {
      "epoch": 0.3810653695574801,
      "grad_norm": 2.7400448322296143,
      "learning_rate": 1.3754284207751121e-05,
      "loss": 0.1004,
      "step": 6424
    },
    {
      "epoch": 0.3811246885751572,
      "grad_norm": 12.351630210876465,
      "learning_rate": 1.3752965989981546e-05,
      "loss": 0.4635,
      "step": 6425
    },
    {
      "epoch": 0.3811840075928343,
      "grad_norm": 0.7967493534088135,
      "learning_rate": 1.3751647772211972e-05,
      "loss": 0.0073,
      "step": 6426
    },
    {
      "epoch": 0.38124332661051136,
      "grad_norm": 0.17622476816177368,
      "learning_rate": 1.3750329554442394e-05,
      "loss": 0.0033,
      "step": 6427
    },
    {
      "epoch": 0.3813026456281884,
      "grad_norm": 19.65880012512207,
      "learning_rate": 1.374901133667282e-05,
      "loss": 0.8954,
      "step": 6428
    },
    {
      "epoch": 0.38136196464586547,
      "grad_norm": 6.90733528137207,
      "learning_rate": 1.3747693118903244e-05,
      "loss": 0.123,
      "step": 6429
    },
    {
      "epoch": 0.38142128366354255,
      "grad_norm": 0.4208241403102875,
      "learning_rate": 1.3746374901133668e-05,
      "loss": 0.0045,
      "step": 6430
    },
    {
      "epoch": 0.3814806026812196,
      "grad_norm": 16.791284561157227,
      "learning_rate": 1.3745056683364092e-05,
      "loss": 0.3535,
      "step": 6431
    },
    {
      "epoch": 0.38153992169889667,
      "grad_norm": 0.48007774353027344,
      "learning_rate": 1.3743738465594518e-05,
      "loss": 0.0046,
      "step": 6432
    },
    {
      "epoch": 0.38159924071657375,
      "grad_norm": 1.416202187538147,
      "learning_rate": 1.374242024782494e-05,
      "loss": 0.0214,
      "step": 6433
    },
    {
      "epoch": 0.3816585597342508,
      "grad_norm": 0.6257219910621643,
      "learning_rate": 1.3741102030055367e-05,
      "loss": 0.0064,
      "step": 6434
    },
    {
      "epoch": 0.38171787875192786,
      "grad_norm": 6.251006126403809,
      "learning_rate": 1.3739783812285793e-05,
      "loss": 0.3942,
      "step": 6435
    },
    {
      "epoch": 0.38177719776960495,
      "grad_norm": 5.838866233825684,
      "learning_rate": 1.3738465594516215e-05,
      "loss": 0.0549,
      "step": 6436
    },
    {
      "epoch": 0.381836516787282,
      "grad_norm": 0.2126758098602295,
      "learning_rate": 1.373714737674664e-05,
      "loss": 0.0052,
      "step": 6437
    },
    {
      "epoch": 0.38189583580495906,
      "grad_norm": 5.568331718444824,
      "learning_rate": 1.3735829158977063e-05,
      "loss": 0.2951,
      "step": 6438
    },
    {
      "epoch": 0.38195515482263614,
      "grad_norm": 4.157374382019043,
      "learning_rate": 1.3734510941207488e-05,
      "loss": 0.0815,
      "step": 6439
    },
    {
      "epoch": 0.38201447384031323,
      "grad_norm": 4.734460353851318,
      "learning_rate": 1.3733192723437914e-05,
      "loss": 0.1665,
      "step": 6440
    },
    {
      "epoch": 0.38207379285799026,
      "grad_norm": 9.8123779296875,
      "learning_rate": 1.3731874505668336e-05,
      "loss": 0.1403,
      "step": 6441
    },
    {
      "epoch": 0.38213311187566734,
      "grad_norm": 3.044233798980713,
      "learning_rate": 1.3730556287898762e-05,
      "loss": 0.0299,
      "step": 6442
    },
    {
      "epoch": 0.3821924308933444,
      "grad_norm": 33.35026168823242,
      "learning_rate": 1.3729238070129188e-05,
      "loss": 0.978,
      "step": 6443
    },
    {
      "epoch": 0.38225174991102145,
      "grad_norm": 0.1669616848230362,
      "learning_rate": 1.372791985235961e-05,
      "loss": 0.0027,
      "step": 6444
    },
    {
      "epoch": 0.38231106892869854,
      "grad_norm": 0.015954090282320976,
      "learning_rate": 1.3726601634590036e-05,
      "loss": 0.0005,
      "step": 6445
    },
    {
      "epoch": 0.3823703879463756,
      "grad_norm": 1.9093103408813477,
      "learning_rate": 1.372528341682046e-05,
      "loss": 0.0336,
      "step": 6446
    },
    {
      "epoch": 0.38242970696405265,
      "grad_norm": 0.0339619517326355,
      "learning_rate": 1.3723965199050885e-05,
      "loss": 0.0008,
      "step": 6447
    },
    {
      "epoch": 0.38248902598172974,
      "grad_norm": 1.876249074935913,
      "learning_rate": 1.3722646981281309e-05,
      "loss": 0.0171,
      "step": 6448
    },
    {
      "epoch": 0.3825483449994068,
      "grad_norm": 0.23291750252246857,
      "learning_rate": 1.3721328763511735e-05,
      "loss": 0.0016,
      "step": 6449
    },
    {
      "epoch": 0.3826076640170839,
      "grad_norm": 1.4861745834350586,
      "learning_rate": 1.3720010545742157e-05,
      "loss": 0.0237,
      "step": 6450
    },
    {
      "epoch": 0.38266698303476093,
      "grad_norm": 0.45297759771347046,
      "learning_rate": 1.3718692327972583e-05,
      "loss": 0.0069,
      "step": 6451
    },
    {
      "epoch": 0.382726302052438,
      "grad_norm": 0.0927625522017479,
      "learning_rate": 1.3717374110203005e-05,
      "loss": 0.0016,
      "step": 6452
    },
    {
      "epoch": 0.3827856210701151,
      "grad_norm": 0.31621041893959045,
      "learning_rate": 1.3716055892433431e-05,
      "loss": 0.003,
      "step": 6453
    },
    {
      "epoch": 0.38284494008779213,
      "grad_norm": 4.681623935699463,
      "learning_rate": 1.3714737674663856e-05,
      "loss": 0.062,
      "step": 6454
    },
    {
      "epoch": 0.3829042591054692,
      "grad_norm": 5.024198055267334,
      "learning_rate": 1.371341945689428e-05,
      "loss": 0.076,
      "step": 6455
    },
    {
      "epoch": 0.3829635781231463,
      "grad_norm": 0.04219982400536537,
      "learning_rate": 1.3712101239124704e-05,
      "loss": 0.0009,
      "step": 6456
    },
    {
      "epoch": 0.3830228971408233,
      "grad_norm": 0.04585004970431328,
      "learning_rate": 1.371078302135513e-05,
      "loss": 0.0009,
      "step": 6457
    },
    {
      "epoch": 0.3830822161585004,
      "grad_norm": 0.10825282335281372,
      "learning_rate": 1.3709464803585552e-05,
      "loss": 0.0017,
      "step": 6458
    },
    {
      "epoch": 0.3831415351761775,
      "grad_norm": 0.059633929282426834,
      "learning_rate": 1.3708146585815978e-05,
      "loss": 0.0007,
      "step": 6459
    },
    {
      "epoch": 0.3832008541938545,
      "grad_norm": 13.016768455505371,
      "learning_rate": 1.3706828368046402e-05,
      "loss": 0.1098,
      "step": 6460
    },
    {
      "epoch": 0.3832601732115316,
      "grad_norm": 0.19766542315483093,
      "learning_rate": 1.3705510150276827e-05,
      "loss": 0.0041,
      "step": 6461
    },
    {
      "epoch": 0.3833194922292087,
      "grad_norm": 0.6067960262298584,
      "learning_rate": 1.370419193250725e-05,
      "loss": 0.0068,
      "step": 6462
    },
    {
      "epoch": 0.3833788112468858,
      "grad_norm": 9.453341484069824,
      "learning_rate": 1.3702873714737677e-05,
      "loss": 0.4616,
      "step": 6463
    },
    {
      "epoch": 0.3834381302645628,
      "grad_norm": 5.408447265625,
      "learning_rate": 1.3701555496968099e-05,
      "loss": 0.1857,
      "step": 6464
    },
    {
      "epoch": 0.3834974492822399,
      "grad_norm": 10.002816200256348,
      "learning_rate": 1.3700237279198525e-05,
      "loss": 0.397,
      "step": 6465
    },
    {
      "epoch": 0.383556768299917,
      "grad_norm": 0.2837146818637848,
      "learning_rate": 1.3698919061428951e-05,
      "loss": 0.0034,
      "step": 6466
    },
    {
      "epoch": 0.383616087317594,
      "grad_norm": 0.5202128887176514,
      "learning_rate": 1.3697600843659373e-05,
      "loss": 0.0121,
      "step": 6467
    },
    {
      "epoch": 0.3836754063352711,
      "grad_norm": 16.134380340576172,
      "learning_rate": 1.36962826258898e-05,
      "loss": 0.7074,
      "step": 6468
    },
    {
      "epoch": 0.38373472535294817,
      "grad_norm": 23.789291381835938,
      "learning_rate": 1.3694964408120222e-05,
      "loss": 0.7207,
      "step": 6469
    },
    {
      "epoch": 0.3837940443706252,
      "grad_norm": 38.662986755371094,
      "learning_rate": 1.3693646190350648e-05,
      "loss": 1.3671,
      "step": 6470
    },
    {
      "epoch": 0.3838533633883023,
      "grad_norm": 1.8349076509475708,
      "learning_rate": 1.3692327972581072e-05,
      "loss": 0.019,
      "step": 6471
    },
    {
      "epoch": 0.38391268240597937,
      "grad_norm": 9.754581451416016,
      "learning_rate": 1.3691009754811494e-05,
      "loss": 0.0582,
      "step": 6472
    },
    {
      "epoch": 0.38397200142365645,
      "grad_norm": 0.08743941783905029,
      "learning_rate": 1.368969153704192e-05,
      "loss": 0.0017,
      "step": 6473
    },
    {
      "epoch": 0.3840313204413335,
      "grad_norm": 8.557586669921875,
      "learning_rate": 1.3688373319272346e-05,
      "loss": 0.4854,
      "step": 6474
    },
    {
      "epoch": 0.38409063945901056,
      "grad_norm": 0.10740894079208374,
      "learning_rate": 1.3687055101502769e-05,
      "loss": 0.0015,
      "step": 6475
    },
    {
      "epoch": 0.38414995847668765,
      "grad_norm": 0.00929306261241436,
      "learning_rate": 1.3685736883733194e-05,
      "loss": 0.0003,
      "step": 6476
    },
    {
      "epoch": 0.3842092774943647,
      "grad_norm": 5.533428192138672,
      "learning_rate": 1.3684418665963619e-05,
      "loss": 0.2712,
      "step": 6477
    },
    {
      "epoch": 0.38426859651204176,
      "grad_norm": 0.037600304931402206,
      "learning_rate": 1.3683100448194043e-05,
      "loss": 0.001,
      "step": 6478
    },
    {
      "epoch": 0.38432791552971884,
      "grad_norm": 7.908144474029541,
      "learning_rate": 1.3681782230424467e-05,
      "loss": 0.2366,
      "step": 6479
    },
    {
      "epoch": 0.3843872345473959,
      "grad_norm": 24.049955368041992,
      "learning_rate": 1.3680464012654893e-05,
      "loss": 0.1396,
      "step": 6480
    },
    {
      "epoch": 0.38444655356507296,
      "grad_norm": 57.768829345703125,
      "learning_rate": 1.3679145794885315e-05,
      "loss": 1.1176,
      "step": 6481
    },
    {
      "epoch": 0.38450587258275004,
      "grad_norm": 18.13840103149414,
      "learning_rate": 1.3677827577115741e-05,
      "loss": 0.5163,
      "step": 6482
    },
    {
      "epoch": 0.38456519160042707,
      "grad_norm": 0.0794997587800026,
      "learning_rate": 1.3676509359346165e-05,
      "loss": 0.0014,
      "step": 6483
    },
    {
      "epoch": 0.38462451061810415,
      "grad_norm": 0.07845357805490494,
      "learning_rate": 1.367519114157659e-05,
      "loss": 0.001,
      "step": 6484
    },
    {
      "epoch": 0.38468382963578124,
      "grad_norm": 4.427989959716797,
      "learning_rate": 1.3673872923807014e-05,
      "loss": 0.0727,
      "step": 6485
    },
    {
      "epoch": 0.3847431486534583,
      "grad_norm": 3.130319833755493,
      "learning_rate": 1.3672554706037438e-05,
      "loss": 0.0576,
      "step": 6486
    },
    {
      "epoch": 0.38480246767113535,
      "grad_norm": 12.774991035461426,
      "learning_rate": 1.3671236488267862e-05,
      "loss": 0.7037,
      "step": 6487
    },
    {
      "epoch": 0.38486178668881244,
      "grad_norm": 0.12297576665878296,
      "learning_rate": 1.3669918270498288e-05,
      "loss": 0.0027,
      "step": 6488
    },
    {
      "epoch": 0.3849211057064895,
      "grad_norm": 0.0411604568362236,
      "learning_rate": 1.366860005272871e-05,
      "loss": 0.0007,
      "step": 6489
    },
    {
      "epoch": 0.38498042472416655,
      "grad_norm": 4.595162868499756,
      "learning_rate": 1.3667281834959136e-05,
      "loss": 0.0897,
      "step": 6490
    },
    {
      "epoch": 0.38503974374184363,
      "grad_norm": 20.780685424804688,
      "learning_rate": 1.3665963617189562e-05,
      "loss": 0.6158,
      "step": 6491
    },
    {
      "epoch": 0.3850990627595207,
      "grad_norm": 0.015558866783976555,
      "learning_rate": 1.3664645399419985e-05,
      "loss": 0.0005,
      "step": 6492
    },
    {
      "epoch": 0.38515838177719774,
      "grad_norm": 2.9142658710479736,
      "learning_rate": 1.3663327181650409e-05,
      "loss": 0.1696,
      "step": 6493
    },
    {
      "epoch": 0.38521770079487483,
      "grad_norm": 25.75357437133789,
      "learning_rate": 1.3662008963880835e-05,
      "loss": 0.2495,
      "step": 6494
    },
    {
      "epoch": 0.3852770198125519,
      "grad_norm": 0.022955821827054024,
      "learning_rate": 1.3660690746111257e-05,
      "loss": 0.0005,
      "step": 6495
    },
    {
      "epoch": 0.385336338830229,
      "grad_norm": 0.03110189363360405,
      "learning_rate": 1.3659372528341683e-05,
      "loss": 0.0009,
      "step": 6496
    },
    {
      "epoch": 0.385395657847906,
      "grad_norm": 3.6352622509002686,
      "learning_rate": 1.3658054310572109e-05,
      "loss": 0.1503,
      "step": 6497
    },
    {
      "epoch": 0.3854549768655831,
      "grad_norm": 2.353628158569336,
      "learning_rate": 1.3656736092802532e-05,
      "loss": 0.0343,
      "step": 6498
    },
    {
      "epoch": 0.3855142958832602,
      "grad_norm": 11.286554336547852,
      "learning_rate": 1.3655417875032958e-05,
      "loss": 0.6172,
      "step": 6499
    },
    {
      "epoch": 0.3855736149009372,
      "grad_norm": 1.1483887434005737,
      "learning_rate": 1.365409965726338e-05,
      "loss": 0.0088,
      "step": 6500
    },
    {
      "epoch": 0.3856329339186143,
      "grad_norm": 0.03844452276825905,
      "learning_rate": 1.3652781439493806e-05,
      "loss": 0.0009,
      "step": 6501
    },
    {
      "epoch": 0.3856922529362914,
      "grad_norm": 1.9909156560897827,
      "learning_rate": 1.365146322172423e-05,
      "loss": 0.0317,
      "step": 6502
    },
    {
      "epoch": 0.3857515719539684,
      "grad_norm": 5.438320636749268,
      "learning_rate": 1.3650145003954654e-05,
      "loss": 0.1255,
      "step": 6503
    },
    {
      "epoch": 0.3858108909716455,
      "grad_norm": 10.729691505432129,
      "learning_rate": 1.3648826786185078e-05,
      "loss": 0.5264,
      "step": 6504
    },
    {
      "epoch": 0.3858702099893226,
      "grad_norm": 0.9604144096374512,
      "learning_rate": 1.3647508568415504e-05,
      "loss": 0.0116,
      "step": 6505
    },
    {
      "epoch": 0.3859295290069996,
      "grad_norm": 6.231253623962402,
      "learning_rate": 1.3646190350645927e-05,
      "loss": 0.0345,
      "step": 6506
    },
    {
      "epoch": 0.3859888480246767,
      "grad_norm": 0.037705693393945694,
      "learning_rate": 1.3644872132876353e-05,
      "loss": 0.0013,
      "step": 6507
    },
    {
      "epoch": 0.3860481670423538,
      "grad_norm": 0.7366481423377991,
      "learning_rate": 1.3643553915106777e-05,
      "loss": 0.0037,
      "step": 6508
    },
    {
      "epoch": 0.38610748606003087,
      "grad_norm": 7.041335105895996,
      "learning_rate": 1.3642235697337201e-05,
      "loss": 0.279,
      "step": 6509
    },
    {
      "epoch": 0.3861668050777079,
      "grad_norm": 0.043435562402009964,
      "learning_rate": 1.3640917479567625e-05,
      "loss": 0.0006,
      "step": 6510
    },
    {
      "epoch": 0.386226124095385,
      "grad_norm": 0.006629343144595623,
      "learning_rate": 1.3639599261798051e-05,
      "loss": 0.0002,
      "step": 6511
    },
    {
      "epoch": 0.38628544311306207,
      "grad_norm": 0.019239025190472603,
      "learning_rate": 1.3638281044028474e-05,
      "loss": 0.0005,
      "step": 6512
    },
    {
      "epoch": 0.3863447621307391,
      "grad_norm": 12.343478202819824,
      "learning_rate": 1.36369628262589e-05,
      "loss": 0.099,
      "step": 6513
    },
    {
      "epoch": 0.3864040811484162,
      "grad_norm": 0.07293789088726044,
      "learning_rate": 1.3635644608489325e-05,
      "loss": 0.001,
      "step": 6514
    },
    {
      "epoch": 0.38646340016609326,
      "grad_norm": 3.0043628215789795,
      "learning_rate": 1.3634326390719748e-05,
      "loss": 0.0204,
      "step": 6515
    },
    {
      "epoch": 0.3865227191837703,
      "grad_norm": 0.40692824125289917,
      "learning_rate": 1.3633008172950172e-05,
      "loss": 0.0043,
      "step": 6516
    },
    {
      "epoch": 0.3865820382014474,
      "grad_norm": 8.747159957885742,
      "learning_rate": 1.3631689955180596e-05,
      "loss": 0.3994,
      "step": 6517
    },
    {
      "epoch": 0.38664135721912446,
      "grad_norm": 11.33739185333252,
      "learning_rate": 1.363037173741102e-05,
      "loss": 0.3106,
      "step": 6518
    },
    {
      "epoch": 0.38670067623680154,
      "grad_norm": 0.9321014285087585,
      "learning_rate": 1.3629053519641446e-05,
      "loss": 0.0132,
      "step": 6519
    },
    {
      "epoch": 0.3867599952544786,
      "grad_norm": 9.774870872497559,
      "learning_rate": 1.3627735301871869e-05,
      "loss": 0.6257,
      "step": 6520
    },
    {
      "epoch": 0.38681931427215566,
      "grad_norm": 9.551323890686035,
      "learning_rate": 1.3626417084102295e-05,
      "loss": 0.1578,
      "step": 6521
    },
    {
      "epoch": 0.38687863328983274,
      "grad_norm": 0.04709390178322792,
      "learning_rate": 1.362509886633272e-05,
      "loss": 0.0008,
      "step": 6522
    },
    {
      "epoch": 0.38693795230750977,
      "grad_norm": 5.168545246124268,
      "learning_rate": 1.3623780648563143e-05,
      "loss": 0.054,
      "step": 6523
    },
    {
      "epoch": 0.38699727132518685,
      "grad_norm": 20.88770866394043,
      "learning_rate": 1.3622462430793569e-05,
      "loss": 0.5733,
      "step": 6524
    },
    {
      "epoch": 0.38705659034286394,
      "grad_norm": 7.81536865234375,
      "learning_rate": 1.3621144213023993e-05,
      "loss": 0.1291,
      "step": 6525
    },
    {
      "epoch": 0.38711590936054097,
      "grad_norm": 5.168537139892578,
      "learning_rate": 1.3619825995254417e-05,
      "loss": 0.0318,
      "step": 6526
    },
    {
      "epoch": 0.38717522837821805,
      "grad_norm": 0.3582524359226227,
      "learning_rate": 1.3618507777484842e-05,
      "loss": 0.0041,
      "step": 6527
    },
    {
      "epoch": 0.38723454739589513,
      "grad_norm": 11.431658744812012,
      "learning_rate": 1.3617189559715267e-05,
      "loss": 0.0079,
      "step": 6528
    },
    {
      "epoch": 0.3872938664135722,
      "grad_norm": 3.6654253005981445,
      "learning_rate": 1.361587134194569e-05,
      "loss": 0.0417,
      "step": 6529
    },
    {
      "epoch": 0.38735318543124925,
      "grad_norm": 4.270747661590576,
      "learning_rate": 1.3614553124176116e-05,
      "loss": 0.1984,
      "step": 6530
    },
    {
      "epoch": 0.38741250444892633,
      "grad_norm": 0.17168474197387695,
      "learning_rate": 1.361323490640654e-05,
      "loss": 0.0029,
      "step": 6531
    },
    {
      "epoch": 0.3874718234666034,
      "grad_norm": 3.865633010864258,
      "learning_rate": 1.3611916688636964e-05,
      "loss": 0.1247,
      "step": 6532
    },
    {
      "epoch": 0.38753114248428044,
      "grad_norm": 17.815038681030273,
      "learning_rate": 1.3610598470867388e-05,
      "loss": 0.4962,
      "step": 6533
    },
    {
      "epoch": 0.38759046150195753,
      "grad_norm": 11.686270713806152,
      "learning_rate": 1.3609280253097813e-05,
      "loss": 0.1437,
      "step": 6534
    },
    {
      "epoch": 0.3876497805196346,
      "grad_norm": 0.04208078980445862,
      "learning_rate": 1.3607962035328237e-05,
      "loss": 0.001,
      "step": 6535
    },
    {
      "epoch": 0.38770909953731164,
      "grad_norm": 36.37833786010742,
      "learning_rate": 1.3606643817558663e-05,
      "loss": 1.151,
      "step": 6536
    },
    {
      "epoch": 0.3877684185549887,
      "grad_norm": 0.07121682912111282,
      "learning_rate": 1.3605325599789085e-05,
      "loss": 0.0017,
      "step": 6537
    },
    {
      "epoch": 0.3878277375726658,
      "grad_norm": 0.04829895496368408,
      "learning_rate": 1.3604007382019511e-05,
      "loss": 0.0012,
      "step": 6538
    },
    {
      "epoch": 0.38788705659034284,
      "grad_norm": 26.98530387878418,
      "learning_rate": 1.3602689164249935e-05,
      "loss": 1.4489,
      "step": 6539
    },
    {
      "epoch": 0.3879463756080199,
      "grad_norm": 0.15445837378501892,
      "learning_rate": 1.360137094648036e-05,
      "loss": 0.0017,
      "step": 6540
    },
    {
      "epoch": 0.388005694625697,
      "grad_norm": 1.1692379713058472,
      "learning_rate": 1.3600052728710784e-05,
      "loss": 0.0073,
      "step": 6541
    },
    {
      "epoch": 0.3880650136433741,
      "grad_norm": 4.838637351989746,
      "learning_rate": 1.359873451094121e-05,
      "loss": 0.5586,
      "step": 6542
    },
    {
      "epoch": 0.3881243326610511,
      "grad_norm": 0.01152559369802475,
      "learning_rate": 1.3597416293171632e-05,
      "loss": 0.0003,
      "step": 6543
    },
    {
      "epoch": 0.3881836516787282,
      "grad_norm": 0.0520334467291832,
      "learning_rate": 1.3596098075402058e-05,
      "loss": 0.0006,
      "step": 6544
    },
    {
      "epoch": 0.3882429706964053,
      "grad_norm": 3.9741811752319336,
      "learning_rate": 1.3594779857632484e-05,
      "loss": 0.0776,
      "step": 6545
    },
    {
      "epoch": 0.3883022897140823,
      "grad_norm": 13.916512489318848,
      "learning_rate": 1.3593461639862906e-05,
      "loss": 0.0516,
      "step": 6546
    },
    {
      "epoch": 0.3883616087317594,
      "grad_norm": 14.10610580444336,
      "learning_rate": 1.3592143422093332e-05,
      "loss": 0.4604,
      "step": 6547
    },
    {
      "epoch": 0.3884209277494365,
      "grad_norm": 8.060667037963867,
      "learning_rate": 1.3590825204323755e-05,
      "loss": 0.1647,
      "step": 6548
    },
    {
      "epoch": 0.3884802467671135,
      "grad_norm": 0.4597054719924927,
      "learning_rate": 1.3589506986554179e-05,
      "loss": 0.0036,
      "step": 6549
    },
    {
      "epoch": 0.3885395657847906,
      "grad_norm": 9.441838264465332,
      "learning_rate": 1.3588188768784605e-05,
      "loss": 0.3886,
      "step": 6550
    },
    {
      "epoch": 0.3885988848024677,
      "grad_norm": 1.8727251291275024,
      "learning_rate": 1.3586870551015027e-05,
      "loss": 0.0312,
      "step": 6551
    },
    {
      "epoch": 0.38865820382014477,
      "grad_norm": 11.132610321044922,
      "learning_rate": 1.3585552333245453e-05,
      "loss": 0.0943,
      "step": 6552
    },
    {
      "epoch": 0.3887175228378218,
      "grad_norm": 12.43382740020752,
      "learning_rate": 1.3584234115475879e-05,
      "loss": 0.0819,
      "step": 6553
    },
    {
      "epoch": 0.3887768418554989,
      "grad_norm": 0.12438278645277023,
      "learning_rate": 1.3582915897706301e-05,
      "loss": 0.0021,
      "step": 6554
    },
    {
      "epoch": 0.38883616087317596,
      "grad_norm": 0.7049412727355957,
      "learning_rate": 1.3581597679936727e-05,
      "loss": 0.0038,
      "step": 6555
    },
    {
      "epoch": 0.388895479890853,
      "grad_norm": 0.017218489199876785,
      "learning_rate": 1.3580279462167151e-05,
      "loss": 0.0005,
      "step": 6556
    },
    {
      "epoch": 0.3889547989085301,
      "grad_norm": 3.855301856994629,
      "learning_rate": 1.3578961244397576e-05,
      "loss": 0.2074,
      "step": 6557
    },
    {
      "epoch": 0.38901411792620716,
      "grad_norm": 0.7384977340698242,
      "learning_rate": 1.3577643026628e-05,
      "loss": 0.0065,
      "step": 6558
    },
    {
      "epoch": 0.3890734369438842,
      "grad_norm": 14.173237800598145,
      "learning_rate": 1.3576324808858426e-05,
      "loss": 0.2549,
      "step": 6559
    },
    {
      "epoch": 0.38913275596156127,
      "grad_norm": 26.27881622314453,
      "learning_rate": 1.3575006591088848e-05,
      "loss": 0.1364,
      "step": 6560
    },
    {
      "epoch": 0.38919207497923836,
      "grad_norm": 4.9887919425964355,
      "learning_rate": 1.3573688373319274e-05,
      "loss": 0.2441,
      "step": 6561
    },
    {
      "epoch": 0.3892513939969154,
      "grad_norm": 4.2247090339660645,
      "learning_rate": 1.3572370155549698e-05,
      "loss": 0.0851,
      "step": 6562
    },
    {
      "epoch": 0.38931071301459247,
      "grad_norm": 4.412658214569092,
      "learning_rate": 1.3571051937780122e-05,
      "loss": 0.08,
      "step": 6563
    },
    {
      "epoch": 0.38937003203226955,
      "grad_norm": 0.5817493796348572,
      "learning_rate": 1.3569733720010547e-05,
      "loss": 0.0059,
      "step": 6564
    },
    {
      "epoch": 0.38942935104994664,
      "grad_norm": 3.9025237560272217,
      "learning_rate": 1.356841550224097e-05,
      "loss": 0.0277,
      "step": 6565
    },
    {
      "epoch": 0.38948867006762367,
      "grad_norm": 11.327154159545898,
      "learning_rate": 1.3567097284471395e-05,
      "loss": 0.495,
      "step": 6566
    },
    {
      "epoch": 0.38954798908530075,
      "grad_norm": 5.515975475311279,
      "learning_rate": 1.3565779066701821e-05,
      "loss": 0.104,
      "step": 6567
    },
    {
      "epoch": 0.38960730810297783,
      "grad_norm": 13.701407432556152,
      "learning_rate": 1.3564460848932243e-05,
      "loss": 0.0987,
      "step": 6568
    },
    {
      "epoch": 0.38966662712065486,
      "grad_norm": 0.11988810449838638,
      "learning_rate": 1.356314263116267e-05,
      "loss": 0.0019,
      "step": 6569
    },
    {
      "epoch": 0.38972594613833195,
      "grad_norm": 3.8091962337493896,
      "learning_rate": 1.3561824413393095e-05,
      "loss": 0.0509,
      "step": 6570
    },
    {
      "epoch": 0.38978526515600903,
      "grad_norm": 0.2840474545955658,
      "learning_rate": 1.3560506195623518e-05,
      "loss": 0.0037,
      "step": 6571
    },
    {
      "epoch": 0.38984458417368606,
      "grad_norm": 0.02757963165640831,
      "learning_rate": 1.3559187977853942e-05,
      "loss": 0.0007,
      "step": 6572
    },
    {
      "epoch": 0.38990390319136314,
      "grad_norm": 2.493438959121704,
      "learning_rate": 1.3557869760084368e-05,
      "loss": 0.4468,
      "step": 6573
    },
    {
      "epoch": 0.38996322220904023,
      "grad_norm": 0.14724203944206238,
      "learning_rate": 1.355655154231479e-05,
      "loss": 0.0023,
      "step": 6574
    },
    {
      "epoch": 0.3900225412267173,
      "grad_norm": 0.5197601914405823,
      "learning_rate": 1.3555233324545216e-05,
      "loss": 0.0073,
      "step": 6575
    },
    {
      "epoch": 0.39008186024439434,
      "grad_norm": 0.23066669702529907,
      "learning_rate": 1.3553915106775642e-05,
      "loss": 0.0018,
      "step": 6576
    },
    {
      "epoch": 0.3901411792620714,
      "grad_norm": 1.1383508443832397,
      "learning_rate": 1.3552596889006064e-05,
      "loss": 0.0089,
      "step": 6577
    },
    {
      "epoch": 0.3902004982797485,
      "grad_norm": 13.528746604919434,
      "learning_rate": 1.355127867123649e-05,
      "loss": 0.3963,
      "step": 6578
    },
    {
      "epoch": 0.39025981729742554,
      "grad_norm": 3.413515567779541,
      "learning_rate": 1.3549960453466915e-05,
      "loss": 0.0402,
      "step": 6579
    },
    {
      "epoch": 0.3903191363151026,
      "grad_norm": 4.685174942016602,
      "learning_rate": 1.3548642235697339e-05,
      "loss": 0.1357,
      "step": 6580
    },
    {
      "epoch": 0.3903784553327797,
      "grad_norm": 0.33652934432029724,
      "learning_rate": 1.3547324017927763e-05,
      "loss": 0.0047,
      "step": 6581
    },
    {
      "epoch": 0.39043777435045673,
      "grad_norm": 2.5642335414886475,
      "learning_rate": 1.3546005800158187e-05,
      "loss": 0.009,
      "step": 6582
    },
    {
      "epoch": 0.3904970933681338,
      "grad_norm": 6.590513706207275,
      "learning_rate": 1.3544687582388611e-05,
      "loss": 0.0707,
      "step": 6583
    },
    {
      "epoch": 0.3905564123858109,
      "grad_norm": 0.5710933208465576,
      "learning_rate": 1.3543369364619037e-05,
      "loss": 0.0106,
      "step": 6584
    },
    {
      "epoch": 0.39061573140348793,
      "grad_norm": 0.13587899506092072,
      "learning_rate": 1.354205114684946e-05,
      "loss": 0.0026,
      "step": 6585
    },
    {
      "epoch": 0.390675050421165,
      "grad_norm": 0.034639421850442886,
      "learning_rate": 1.3540732929079886e-05,
      "loss": 0.0007,
      "step": 6586
    },
    {
      "epoch": 0.3907343694388421,
      "grad_norm": 3.3692502975463867,
      "learning_rate": 1.353941471131031e-05,
      "loss": 0.1121,
      "step": 6587
    },
    {
      "epoch": 0.3907936884565192,
      "grad_norm": 2.3347671031951904,
      "learning_rate": 1.3538096493540734e-05,
      "loss": 0.1493,
      "step": 6588
    },
    {
      "epoch": 0.3908530074741962,
      "grad_norm": 0.39319512248039246,
      "learning_rate": 1.3536778275771158e-05,
      "loss": 0.0037,
      "step": 6589
    },
    {
      "epoch": 0.3909123264918733,
      "grad_norm": 24.46937370300293,
      "learning_rate": 1.3535460058001584e-05,
      "loss": 0.2278,
      "step": 6590
    },
    {
      "epoch": 0.3909716455095504,
      "grad_norm": 0.026623589918017387,
      "learning_rate": 1.3534141840232006e-05,
      "loss": 0.0009,
      "step": 6591
    },
    {
      "epoch": 0.3910309645272274,
      "grad_norm": 0.015104608610272408,
      "learning_rate": 1.3532823622462432e-05,
      "loss": 0.0005,
      "step": 6592
    },
    {
      "epoch": 0.3910902835449045,
      "grad_norm": 15.749541282653809,
      "learning_rate": 1.3531505404692857e-05,
      "loss": 0.8088,
      "step": 6593
    },
    {
      "epoch": 0.3911496025625816,
      "grad_norm": 2.5225579738616943,
      "learning_rate": 1.353018718692328e-05,
      "loss": 0.1662,
      "step": 6594
    },
    {
      "epoch": 0.3912089215802586,
      "grad_norm": 1.3851937055587769,
      "learning_rate": 1.3528868969153705e-05,
      "loss": 0.0069,
      "step": 6595
    },
    {
      "epoch": 0.3912682405979357,
      "grad_norm": 0.1594775766134262,
      "learning_rate": 1.352755075138413e-05,
      "loss": 0.0034,
      "step": 6596
    },
    {
      "epoch": 0.3913275596156128,
      "grad_norm": 8.304732322692871,
      "learning_rate": 1.3526232533614553e-05,
      "loss": 0.2171,
      "step": 6597
    },
    {
      "epoch": 0.39138687863328986,
      "grad_norm": 0.006054410710930824,
      "learning_rate": 1.3524914315844979e-05,
      "loss": 0.0002,
      "step": 6598
    },
    {
      "epoch": 0.3914461976509669,
      "grad_norm": 0.22662195563316345,
      "learning_rate": 1.3523596098075402e-05,
      "loss": 0.004,
      "step": 6599
    },
    {
      "epoch": 0.39150551666864397,
      "grad_norm": 0.036707885563373566,
      "learning_rate": 1.3522277880305828e-05,
      "loss": 0.0008,
      "step": 6600
    },
    {
      "epoch": 0.39156483568632106,
      "grad_norm": 9.117776870727539,
      "learning_rate": 1.3520959662536253e-05,
      "loss": 0.0658,
      "step": 6601
    },
    {
      "epoch": 0.3916241547039981,
      "grad_norm": 8.55715274810791,
      "learning_rate": 1.3519641444766676e-05,
      "loss": 0.105,
      "step": 6602
    },
    {
      "epoch": 0.39168347372167517,
      "grad_norm": 0.057085949927568436,
      "learning_rate": 1.3518323226997102e-05,
      "loss": 0.001,
      "step": 6603
    },
    {
      "epoch": 0.39174279273935225,
      "grad_norm": 6.468422889709473,
      "learning_rate": 1.3517005009227526e-05,
      "loss": 0.7365,
      "step": 6604
    },
    {
      "epoch": 0.3918021117570293,
      "grad_norm": 9.104756355285645,
      "learning_rate": 1.3515686791457948e-05,
      "loss": 0.0921,
      "step": 6605
    },
    {
      "epoch": 0.39186143077470637,
      "grad_norm": 0.5503283739089966,
      "learning_rate": 1.3514368573688374e-05,
      "loss": 0.0067,
      "step": 6606
    },
    {
      "epoch": 0.39192074979238345,
      "grad_norm": 6.63438606262207,
      "learning_rate": 1.35130503559188e-05,
      "loss": 0.0936,
      "step": 6607
    },
    {
      "epoch": 0.3919800688100605,
      "grad_norm": 14.746467590332031,
      "learning_rate": 1.3511732138149223e-05,
      "loss": 0.5225,
      "step": 6608
    },
    {
      "epoch": 0.39203938782773756,
      "grad_norm": 10.845711708068848,
      "learning_rate": 1.3510413920379649e-05,
      "loss": 0.9424,
      "step": 6609
    },
    {
      "epoch": 0.39209870684541465,
      "grad_norm": 3.6748595237731934,
      "learning_rate": 1.3509095702610073e-05,
      "loss": 0.0169,
      "step": 6610
    },
    {
      "epoch": 0.39215802586309173,
      "grad_norm": 0.0386459119617939,
      "learning_rate": 1.3507777484840497e-05,
      "loss": 0.001,
      "step": 6611
    },
    {
      "epoch": 0.39221734488076876,
      "grad_norm": 5.074493408203125,
      "learning_rate": 1.3506459267070921e-05,
      "loss": 0.1552,
      "step": 6612
    },
    {
      "epoch": 0.39227666389844584,
      "grad_norm": 1.9315094947814941,
      "learning_rate": 1.3505141049301345e-05,
      "loss": 0.0277,
      "step": 6613
    },
    {
      "epoch": 0.3923359829161229,
      "grad_norm": 28.280630111694336,
      "learning_rate": 1.350382283153177e-05,
      "loss": 0.2165,
      "step": 6614
    },
    {
      "epoch": 0.39239530193379996,
      "grad_norm": 0.6625889539718628,
      "learning_rate": 1.3502504613762195e-05,
      "loss": 0.0075,
      "step": 6615
    },
    {
      "epoch": 0.39245462095147704,
      "grad_norm": 3.546006202697754,
      "learning_rate": 1.3501186395992618e-05,
      "loss": 0.0575,
      "step": 6616
    },
    {
      "epoch": 0.3925139399691541,
      "grad_norm": 0.12490715831518173,
      "learning_rate": 1.3499868178223044e-05,
      "loss": 0.0021,
      "step": 6617
    },
    {
      "epoch": 0.39257325898683115,
      "grad_norm": 0.05872563645243645,
      "learning_rate": 1.3498549960453468e-05,
      "loss": 0.0008,
      "step": 6618
    },
    {
      "epoch": 0.39263257800450824,
      "grad_norm": 12.740936279296875,
      "learning_rate": 1.3497231742683892e-05,
      "loss": 0.5613,
      "step": 6619
    },
    {
      "epoch": 0.3926918970221853,
      "grad_norm": 4.156679153442383,
      "learning_rate": 1.3495913524914316e-05,
      "loss": 0.0243,
      "step": 6620
    },
    {
      "epoch": 0.3927512160398624,
      "grad_norm": 0.01679692231118679,
      "learning_rate": 1.3494595307144742e-05,
      "loss": 0.0005,
      "step": 6621
    },
    {
      "epoch": 0.39281053505753943,
      "grad_norm": 0.025429319590330124,
      "learning_rate": 1.3493277089375165e-05,
      "loss": 0.0007,
      "step": 6622
    },
    {
      "epoch": 0.3928698540752165,
      "grad_norm": 3.8402628898620605,
      "learning_rate": 1.349195887160559e-05,
      "loss": 0.0316,
      "step": 6623
    },
    {
      "epoch": 0.3929291730928936,
      "grad_norm": 0.008449413813650608,
      "learning_rate": 1.3490640653836016e-05,
      "loss": 0.0002,
      "step": 6624
    },
    {
      "epoch": 0.39298849211057063,
      "grad_norm": 6.138121604919434,
      "learning_rate": 1.3489322436066439e-05,
      "loss": 0.194,
      "step": 6625
    },
    {
      "epoch": 0.3930478111282477,
      "grad_norm": 37.374568939208984,
      "learning_rate": 1.3488004218296865e-05,
      "loss": 0.6215,
      "step": 6626
    },
    {
      "epoch": 0.3931071301459248,
      "grad_norm": 7.766852855682373,
      "learning_rate": 1.3486686000527289e-05,
      "loss": 0.2338,
      "step": 6627
    },
    {
      "epoch": 0.3931664491636018,
      "grad_norm": 27.891700744628906,
      "learning_rate": 1.3485367782757712e-05,
      "loss": 1.2024,
      "step": 6628
    },
    {
      "epoch": 0.3932257681812789,
      "grad_norm": 0.0066010719165205956,
      "learning_rate": 1.3484049564988137e-05,
      "loss": 0.0003,
      "step": 6629
    },
    {
      "epoch": 0.393285087198956,
      "grad_norm": 2.057981252670288,
      "learning_rate": 1.348273134721856e-05,
      "loss": 0.0259,
      "step": 6630
    },
    {
      "epoch": 0.3933444062166331,
      "grad_norm": 15.327377319335938,
      "learning_rate": 1.3481413129448986e-05,
      "loss": 0.2246,
      "step": 6631
    },
    {
      "epoch": 0.3934037252343101,
      "grad_norm": 10.795839309692383,
      "learning_rate": 1.3480094911679412e-05,
      "loss": 0.2404,
      "step": 6632
    },
    {
      "epoch": 0.3934630442519872,
      "grad_norm": 5.548337459564209,
      "learning_rate": 1.3478776693909834e-05,
      "loss": 0.1272,
      "step": 6633
    },
    {
      "epoch": 0.3935223632696643,
      "grad_norm": 1.1357526779174805,
      "learning_rate": 1.347745847614026e-05,
      "loss": 0.015,
      "step": 6634
    },
    {
      "epoch": 0.3935816822873413,
      "grad_norm": 5.600718975067139,
      "learning_rate": 1.3476140258370684e-05,
      "loss": 0.1486,
      "step": 6635
    },
    {
      "epoch": 0.3936410013050184,
      "grad_norm": 0.01889074593782425,
      "learning_rate": 1.3474822040601108e-05,
      "loss": 0.0005,
      "step": 6636
    },
    {
      "epoch": 0.3937003203226955,
      "grad_norm": 0.4506550431251526,
      "learning_rate": 1.3473503822831533e-05,
      "loss": 0.0055,
      "step": 6637
    },
    {
      "epoch": 0.3937596393403725,
      "grad_norm": 0.41180551052093506,
      "learning_rate": 1.3472185605061958e-05,
      "loss": 0.0066,
      "step": 6638
    },
    {
      "epoch": 0.3938189583580496,
      "grad_norm": 0.13290593028068542,
      "learning_rate": 1.3470867387292381e-05,
      "loss": 0.0008,
      "step": 6639
    },
    {
      "epoch": 0.39387827737572667,
      "grad_norm": 2.340958833694458,
      "learning_rate": 1.3469549169522807e-05,
      "loss": 0.0457,
      "step": 6640
    },
    {
      "epoch": 0.3939375963934037,
      "grad_norm": 0.032022617757320404,
      "learning_rate": 1.3468230951753231e-05,
      "loss": 0.0008,
      "step": 6641
    },
    {
      "epoch": 0.3939969154110808,
      "grad_norm": 0.08423871546983719,
      "learning_rate": 1.3466912733983655e-05,
      "loss": 0.0009,
      "step": 6642
    },
    {
      "epoch": 0.39405623442875787,
      "grad_norm": 1.2750420570373535,
      "learning_rate": 1.346559451621408e-05,
      "loss": 0.0143,
      "step": 6643
    },
    {
      "epoch": 0.39411555344643495,
      "grad_norm": 0.05842120200395584,
      "learning_rate": 1.3464276298444505e-05,
      "loss": 0.0015,
      "step": 6644
    },
    {
      "epoch": 0.394174872464112,
      "grad_norm": 10.224328994750977,
      "learning_rate": 1.3462958080674928e-05,
      "loss": 0.3203,
      "step": 6645
    },
    {
      "epoch": 0.39423419148178906,
      "grad_norm": 0.3307908773422241,
      "learning_rate": 1.3461639862905354e-05,
      "loss": 0.0043,
      "step": 6646
    },
    {
      "epoch": 0.39429351049946615,
      "grad_norm": 3.3991520404815674,
      "learning_rate": 1.3460321645135776e-05,
      "loss": 0.4927,
      "step": 6647
    },
    {
      "epoch": 0.3943528295171432,
      "grad_norm": 0.044061947613954544,
      "learning_rate": 1.3459003427366202e-05,
      "loss": 0.0007,
      "step": 6648
    },
    {
      "epoch": 0.39441214853482026,
      "grad_norm": 4.429165363311768,
      "learning_rate": 1.3457685209596626e-05,
      "loss": 0.0307,
      "step": 6649
    },
    {
      "epoch": 0.39447146755249735,
      "grad_norm": 0.06933866441249847,
      "learning_rate": 1.345636699182705e-05,
      "loss": 0.0019,
      "step": 6650
    },
    {
      "epoch": 0.3945307865701744,
      "grad_norm": 8.357436180114746,
      "learning_rate": 1.3455048774057475e-05,
      "loss": 0.0587,
      "step": 6651
    },
    {
      "epoch": 0.39459010558785146,
      "grad_norm": 0.240412175655365,
      "learning_rate": 1.34537305562879e-05,
      "loss": 0.0054,
      "step": 6652
    },
    {
      "epoch": 0.39464942460552854,
      "grad_norm": 0.14854460954666138,
      "learning_rate": 1.3452412338518323e-05,
      "loss": 0.0012,
      "step": 6653
    },
    {
      "epoch": 0.3947087436232056,
      "grad_norm": 43.53593063354492,
      "learning_rate": 1.3451094120748749e-05,
      "loss": 0.9961,
      "step": 6654
    },
    {
      "epoch": 0.39476806264088266,
      "grad_norm": 0.33172401785850525,
      "learning_rate": 1.3449775902979175e-05,
      "loss": 0.0044,
      "step": 6655
    },
    {
      "epoch": 0.39482738165855974,
      "grad_norm": 10.514007568359375,
      "learning_rate": 1.3448457685209597e-05,
      "loss": 0.2189,
      "step": 6656
    },
    {
      "epoch": 0.3948867006762368,
      "grad_norm": 3.3514513969421387,
      "learning_rate": 1.3447139467440023e-05,
      "loss": 0.0799,
      "step": 6657
    },
    {
      "epoch": 0.39494601969391385,
      "grad_norm": 0.23128297924995422,
      "learning_rate": 1.3445821249670447e-05,
      "loss": 0.0027,
      "step": 6658
    },
    {
      "epoch": 0.39500533871159094,
      "grad_norm": 8.6895170211792,
      "learning_rate": 1.3444503031900871e-05,
      "loss": 0.0446,
      "step": 6659
    },
    {
      "epoch": 0.395064657729268,
      "grad_norm": 2.484614610671997,
      "learning_rate": 1.3443184814131296e-05,
      "loss": 0.0458,
      "step": 6660
    },
    {
      "epoch": 0.39512397674694505,
      "grad_norm": 0.032127343118190765,
      "learning_rate": 1.3441866596361718e-05,
      "loss": 0.0004,
      "step": 6661
    },
    {
      "epoch": 0.39518329576462213,
      "grad_norm": 2.4584593772888184,
      "learning_rate": 1.3440548378592144e-05,
      "loss": 0.033,
      "step": 6662
    },
    {
      "epoch": 0.3952426147822992,
      "grad_norm": 5.138596057891846,
      "learning_rate": 1.343923016082257e-05,
      "loss": 0.029,
      "step": 6663
    },
    {
      "epoch": 0.39530193379997625,
      "grad_norm": 1.0268491506576538,
      "learning_rate": 1.3437911943052992e-05,
      "loss": 0.0138,
      "step": 6664
    },
    {
      "epoch": 0.39536125281765333,
      "grad_norm": 6.023639678955078,
      "learning_rate": 1.3436593725283418e-05,
      "loss": 0.151,
      "step": 6665
    },
    {
      "epoch": 0.3954205718353304,
      "grad_norm": 0.7436871528625488,
      "learning_rate": 1.3435275507513842e-05,
      "loss": 0.0086,
      "step": 6666
    },
    {
      "epoch": 0.3954798908530075,
      "grad_norm": 4.389946937561035,
      "learning_rate": 1.3433957289744267e-05,
      "loss": 0.0399,
      "step": 6667
    },
    {
      "epoch": 0.3955392098706845,
      "grad_norm": 23.042919158935547,
      "learning_rate": 1.3432639071974691e-05,
      "loss": 0.5526,
      "step": 6668
    },
    {
      "epoch": 0.3955985288883616,
      "grad_norm": 0.11372045427560806,
      "learning_rate": 1.3431320854205117e-05,
      "loss": 0.0029,
      "step": 6669
    },
    {
      "epoch": 0.3956578479060387,
      "grad_norm": 29.988510131835938,
      "learning_rate": 1.343000263643554e-05,
      "loss": 1.4189,
      "step": 6670
    },
    {
      "epoch": 0.3957171669237157,
      "grad_norm": 0.267722487449646,
      "learning_rate": 1.3428684418665965e-05,
      "loss": 0.0036,
      "step": 6671
    },
    {
      "epoch": 0.3957764859413928,
      "grad_norm": 8.167245864868164,
      "learning_rate": 1.342736620089639e-05,
      "loss": 0.1064,
      "step": 6672
    },
    {
      "epoch": 0.3958358049590699,
      "grad_norm": 12.063826560974121,
      "learning_rate": 1.3426047983126814e-05,
      "loss": 0.2845,
      "step": 6673
    },
    {
      "epoch": 0.3958951239767469,
      "grad_norm": 0.20253656804561615,
      "learning_rate": 1.3424729765357238e-05,
      "loss": 0.0021,
      "step": 6674
    },
    {
      "epoch": 0.395954442994424,
      "grad_norm": 0.18011201918125153,
      "learning_rate": 1.3423411547587664e-05,
      "loss": 0.0025,
      "step": 6675
    },
    {
      "epoch": 0.3960137620121011,
      "grad_norm": 0.45126980543136597,
      "learning_rate": 1.3422093329818086e-05,
      "loss": 0.0066,
      "step": 6676
    },
    {
      "epoch": 0.3960730810297782,
      "grad_norm": 3.096021890640259,
      "learning_rate": 1.3420775112048512e-05,
      "loss": 0.0592,
      "step": 6677
    },
    {
      "epoch": 0.3961324000474552,
      "grad_norm": 18.329917907714844,
      "learning_rate": 1.3419456894278934e-05,
      "loss": 0.3375,
      "step": 6678
    },
    {
      "epoch": 0.3961917190651323,
      "grad_norm": 14.468660354614258,
      "learning_rate": 1.341813867650936e-05,
      "loss": 0.7872,
      "step": 6679
    },
    {
      "epoch": 0.39625103808280937,
      "grad_norm": 2.4508938789367676,
      "learning_rate": 1.3416820458739786e-05,
      "loss": 0.0109,
      "step": 6680
    },
    {
      "epoch": 0.3963103571004864,
      "grad_norm": 1.1989448070526123,
      "learning_rate": 1.3415502240970209e-05,
      "loss": 0.0141,
      "step": 6681
    },
    {
      "epoch": 0.3963696761181635,
      "grad_norm": 17.872928619384766,
      "learning_rate": 1.3414184023200635e-05,
      "loss": 0.398,
      "step": 6682
    },
    {
      "epoch": 0.39642899513584057,
      "grad_norm": 1.0024361610412598,
      "learning_rate": 1.3412865805431059e-05,
      "loss": 0.0138,
      "step": 6683
    },
    {
      "epoch": 0.3964883141535176,
      "grad_norm": 8.772690773010254,
      "learning_rate": 1.3411547587661481e-05,
      "loss": 0.1316,
      "step": 6684
    },
    {
      "epoch": 0.3965476331711947,
      "grad_norm": 3.576186180114746,
      "learning_rate": 1.3410229369891907e-05,
      "loss": 0.1221,
      "step": 6685
    },
    {
      "epoch": 0.39660695218887176,
      "grad_norm": 0.02688448131084442,
      "learning_rate": 1.3408911152122333e-05,
      "loss": 0.0004,
      "step": 6686
    },
    {
      "epoch": 0.3966662712065488,
      "grad_norm": 4.120349884033203,
      "learning_rate": 1.3407592934352756e-05,
      "loss": 0.312,
      "step": 6687
    },
    {
      "epoch": 0.3967255902242259,
      "grad_norm": 9.582377433776855,
      "learning_rate": 1.3406274716583181e-05,
      "loss": 0.626,
      "step": 6688
    },
    {
      "epoch": 0.39678490924190296,
      "grad_norm": 0.6913209557533264,
      "learning_rate": 1.3404956498813606e-05,
      "loss": 0.0059,
      "step": 6689
    },
    {
      "epoch": 0.39684422825958005,
      "grad_norm": 2.774116277694702,
      "learning_rate": 1.340363828104403e-05,
      "loss": 0.0284,
      "step": 6690
    },
    {
      "epoch": 0.3969035472772571,
      "grad_norm": 0.38898447155952454,
      "learning_rate": 1.3402320063274454e-05,
      "loss": 0.007,
      "step": 6691
    },
    {
      "epoch": 0.39696286629493416,
      "grad_norm": 7.641861438751221,
      "learning_rate": 1.340100184550488e-05,
      "loss": 0.0539,
      "step": 6692
    },
    {
      "epoch": 0.39702218531261124,
      "grad_norm": 0.6057050228118896,
      "learning_rate": 1.3399683627735302e-05,
      "loss": 0.0091,
      "step": 6693
    },
    {
      "epoch": 0.39708150433028827,
      "grad_norm": 3.935924530029297,
      "learning_rate": 1.3398365409965728e-05,
      "loss": 0.0077,
      "step": 6694
    },
    {
      "epoch": 0.39714082334796535,
      "grad_norm": 5.437393665313721,
      "learning_rate": 1.339704719219615e-05,
      "loss": 0.034,
      "step": 6695
    },
    {
      "epoch": 0.39720014236564244,
      "grad_norm": 0.33212947845458984,
      "learning_rate": 1.3395728974426577e-05,
      "loss": 0.0041,
      "step": 6696
    },
    {
      "epoch": 0.39725946138331947,
      "grad_norm": 14.100146293640137,
      "learning_rate": 1.3394410756657e-05,
      "loss": 0.4164,
      "step": 6697
    },
    {
      "epoch": 0.39731878040099655,
      "grad_norm": 19.910245895385742,
      "learning_rate": 1.3393092538887425e-05,
      "loss": 0.8259,
      "step": 6698
    },
    {
      "epoch": 0.39737809941867364,
      "grad_norm": 9.935644149780273,
      "learning_rate": 1.3391774321117849e-05,
      "loss": 0.2898,
      "step": 6699
    },
    {
      "epoch": 0.3974374184363507,
      "grad_norm": 1.4635396003723145,
      "learning_rate": 1.3390456103348275e-05,
      "loss": 0.0065,
      "step": 6700
    },
    {
      "epoch": 0.39749673745402775,
      "grad_norm": 10.55758285522461,
      "learning_rate": 1.3389137885578698e-05,
      "loss": 0.0522,
      "step": 6701
    },
    {
      "epoch": 0.39755605647170483,
      "grad_norm": 0.17019332945346832,
      "learning_rate": 1.3387819667809123e-05,
      "loss": 0.0024,
      "step": 6702
    },
    {
      "epoch": 0.3976153754893819,
      "grad_norm": 0.19159293174743652,
      "learning_rate": 1.338650145003955e-05,
      "loss": 0.0026,
      "step": 6703
    },
    {
      "epoch": 0.39767469450705895,
      "grad_norm": 0.8469893336296082,
      "learning_rate": 1.3385183232269972e-05,
      "loss": 0.0156,
      "step": 6704
    },
    {
      "epoch": 0.39773401352473603,
      "grad_norm": 3.8482816219329834,
      "learning_rate": 1.3383865014500396e-05,
      "loss": 0.0547,
      "step": 6705
    },
    {
      "epoch": 0.3977933325424131,
      "grad_norm": 0.06543362885713577,
      "learning_rate": 1.3382546796730822e-05,
      "loss": 0.0016,
      "step": 6706
    },
    {
      "epoch": 0.39785265156009014,
      "grad_norm": 12.607175827026367,
      "learning_rate": 1.3381228578961244e-05,
      "loss": 0.0682,
      "step": 6707
    },
    {
      "epoch": 0.3979119705777672,
      "grad_norm": 4.37645149230957,
      "learning_rate": 1.337991036119167e-05,
      "loss": 0.0653,
      "step": 6708
    },
    {
      "epoch": 0.3979712895954443,
      "grad_norm": 7.440517425537109,
      "learning_rate": 1.3378592143422093e-05,
      "loss": 0.0848,
      "step": 6709
    },
    {
      "epoch": 0.39803060861312134,
      "grad_norm": 0.03518638387322426,
      "learning_rate": 1.3377273925652519e-05,
      "loss": 0.0009,
      "step": 6710
    },
    {
      "epoch": 0.3980899276307984,
      "grad_norm": 0.43896380066871643,
      "learning_rate": 1.3375955707882944e-05,
      "loss": 0.0061,
      "step": 6711
    },
    {
      "epoch": 0.3981492466484755,
      "grad_norm": 0.025518452748656273,
      "learning_rate": 1.3374637490113367e-05,
      "loss": 0.0006,
      "step": 6712
    },
    {
      "epoch": 0.3982085656661526,
      "grad_norm": 0.019934481009840965,
      "learning_rate": 1.3373319272343793e-05,
      "loss": 0.0005,
      "step": 6713
    },
    {
      "epoch": 0.3982678846838296,
      "grad_norm": 6.401686191558838,
      "learning_rate": 1.3372001054574217e-05,
      "loss": 0.0743,
      "step": 6714
    },
    {
      "epoch": 0.3983272037015067,
      "grad_norm": 45.086727142333984,
      "learning_rate": 1.3370682836804641e-05,
      "loss": 0.6181,
      "step": 6715
    },
    {
      "epoch": 0.3983865227191838,
      "grad_norm": 0.9657905697822571,
      "learning_rate": 1.3369364619035065e-05,
      "loss": 0.021,
      "step": 6716
    },
    {
      "epoch": 0.3984458417368608,
      "grad_norm": 0.13081002235412598,
      "learning_rate": 1.3368046401265491e-05,
      "loss": 0.0014,
      "step": 6717
    },
    {
      "epoch": 0.3985051607545379,
      "grad_norm": 2.7765145301818848,
      "learning_rate": 1.3366728183495914e-05,
      "loss": 0.096,
      "step": 6718
    },
    {
      "epoch": 0.398564479772215,
      "grad_norm": 14.365401268005371,
      "learning_rate": 1.336540996572634e-05,
      "loss": 0.5446,
      "step": 6719
    },
    {
      "epoch": 0.398623798789892,
      "grad_norm": 0.01820405386388302,
      "learning_rate": 1.3364091747956764e-05,
      "loss": 0.0003,
      "step": 6720
    },
    {
      "epoch": 0.3986831178075691,
      "grad_norm": 9.98715591430664,
      "learning_rate": 1.3362773530187188e-05,
      "loss": 0.1792,
      "step": 6721
    },
    {
      "epoch": 0.3987424368252462,
      "grad_norm": 0.032046619802713394,
      "learning_rate": 1.3361455312417612e-05,
      "loss": 0.001,
      "step": 6722
    },
    {
      "epoch": 0.39880175584292327,
      "grad_norm": 23.796693801879883,
      "learning_rate": 1.3360137094648038e-05,
      "loss": 0.2034,
      "step": 6723
    },
    {
      "epoch": 0.3988610748606003,
      "grad_norm": 0.16165141761302948,
      "learning_rate": 1.335881887687846e-05,
      "loss": 0.0016,
      "step": 6724
    },
    {
      "epoch": 0.3989203938782774,
      "grad_norm": 0.01440660934895277,
      "learning_rate": 1.3357500659108886e-05,
      "loss": 0.0004,
      "step": 6725
    },
    {
      "epoch": 0.39897971289595446,
      "grad_norm": 12.060214042663574,
      "learning_rate": 1.3356182441339309e-05,
      "loss": 0.2139,
      "step": 6726
    },
    {
      "epoch": 0.3990390319136315,
      "grad_norm": 10.025785446166992,
      "learning_rate": 1.3354864223569735e-05,
      "loss": 0.0207,
      "step": 6727
    },
    {
      "epoch": 0.3990983509313086,
      "grad_norm": 2.304837942123413,
      "learning_rate": 1.3353546005800159e-05,
      "loss": 0.024,
      "step": 6728
    },
    {
      "epoch": 0.39915766994898566,
      "grad_norm": 1.6221445798873901,
      "learning_rate": 1.3352227788030583e-05,
      "loss": 0.0175,
      "step": 6729
    },
    {
      "epoch": 0.3992169889666627,
      "grad_norm": 0.020837677642703056,
      "learning_rate": 1.3350909570261007e-05,
      "loss": 0.0005,
      "step": 6730
    },
    {
      "epoch": 0.3992763079843398,
      "grad_norm": 0.4683457911014557,
      "learning_rate": 1.3349591352491433e-05,
      "loss": 0.0071,
      "step": 6731
    },
    {
      "epoch": 0.39933562700201686,
      "grad_norm": 0.01230345107614994,
      "learning_rate": 1.3348273134721856e-05,
      "loss": 0.0004,
      "step": 6732
    },
    {
      "epoch": 0.39939494601969394,
      "grad_norm": 0.1595691293478012,
      "learning_rate": 1.3346954916952282e-05,
      "loss": 0.002,
      "step": 6733
    },
    {
      "epoch": 0.39945426503737097,
      "grad_norm": 0.03180588036775589,
      "learning_rate": 1.3345636699182708e-05,
      "loss": 0.0006,
      "step": 6734
    },
    {
      "epoch": 0.39951358405504805,
      "grad_norm": 0.02639128267765045,
      "learning_rate": 1.334431848141313e-05,
      "loss": 0.0006,
      "step": 6735
    },
    {
      "epoch": 0.39957290307272514,
      "grad_norm": 2.615215301513672,
      "learning_rate": 1.3343000263643556e-05,
      "loss": 0.0524,
      "step": 6736
    },
    {
      "epoch": 0.39963222209040217,
      "grad_norm": 17.573551177978516,
      "learning_rate": 1.334168204587398e-05,
      "loss": 0.3431,
      "step": 6737
    },
    {
      "epoch": 0.39969154110807925,
      "grad_norm": 8.116415977478027,
      "learning_rate": 1.3340363828104403e-05,
      "loss": 0.0992,
      "step": 6738
    },
    {
      "epoch": 0.39975086012575634,
      "grad_norm": 1.6362805366516113,
      "learning_rate": 1.3339045610334828e-05,
      "loss": 0.0159,
      "step": 6739
    },
    {
      "epoch": 0.39981017914343336,
      "grad_norm": 0.03066188283264637,
      "learning_rate": 1.3337727392565254e-05,
      "loss": 0.0005,
      "step": 6740
    },
    {
      "epoch": 0.39986949816111045,
      "grad_norm": 5.823052406311035,
      "learning_rate": 1.3336409174795677e-05,
      "loss": 0.0347,
      "step": 6741
    },
    {
      "epoch": 0.39992881717878753,
      "grad_norm": 4.03162956237793,
      "learning_rate": 1.3335090957026103e-05,
      "loss": 0.3512,
      "step": 6742
    },
    {
      "epoch": 0.39998813619646456,
      "grad_norm": 15.756135940551758,
      "learning_rate": 1.3333772739256525e-05,
      "loss": 0.6882,
      "step": 6743
    },
    {
      "epoch": 0.40004745521414165,
      "grad_norm": 0.4706425368785858,
      "learning_rate": 1.3332454521486951e-05,
      "loss": 0.0083,
      "step": 6744
    },
    {
      "epoch": 0.40010677423181873,
      "grad_norm": 13.47420597076416,
      "learning_rate": 1.3331136303717375e-05,
      "loss": 0.0908,
      "step": 6745
    },
    {
      "epoch": 0.4001660932494958,
      "grad_norm": 1.9690327644348145,
      "learning_rate": 1.33298180859478e-05,
      "loss": 0.0194,
      "step": 6746
    },
    {
      "epoch": 0.40022541226717284,
      "grad_norm": 0.02511417493224144,
      "learning_rate": 1.3328499868178224e-05,
      "loss": 0.0006,
      "step": 6747
    },
    {
      "epoch": 0.4002847312848499,
      "grad_norm": 6.806341171264648,
      "learning_rate": 1.332718165040865e-05,
      "loss": 0.1212,
      "step": 6748
    },
    {
      "epoch": 0.400344050302527,
      "grad_norm": 1.173431634902954,
      "learning_rate": 1.3325863432639072e-05,
      "loss": 0.0056,
      "step": 6749
    },
    {
      "epoch": 0.40040336932020404,
      "grad_norm": 1.347038984298706,
      "learning_rate": 1.3324545214869498e-05,
      "loss": 0.0099,
      "step": 6750
    },
    {
      "epoch": 0.4004626883378811,
      "grad_norm": 0.03502218425273895,
      "learning_rate": 1.3323226997099922e-05,
      "loss": 0.0007,
      "step": 6751
    },
    {
      "epoch": 0.4005220073555582,
      "grad_norm": 45.33293533325195,
      "learning_rate": 1.3321908779330346e-05,
      "loss": 0.1481,
      "step": 6752
    },
    {
      "epoch": 0.40058132637323524,
      "grad_norm": 17.15469741821289,
      "learning_rate": 1.332059056156077e-05,
      "loss": 0.2281,
      "step": 6753
    },
    {
      "epoch": 0.4006406453909123,
      "grad_norm": 13.793771743774414,
      "learning_rate": 1.3319272343791196e-05,
      "loss": 0.4254,
      "step": 6754
    },
    {
      "epoch": 0.4006999644085894,
      "grad_norm": 6.3026862144470215,
      "learning_rate": 1.3317954126021619e-05,
      "loss": 0.2146,
      "step": 6755
    },
    {
      "epoch": 0.4007592834262665,
      "grad_norm": 17.002832412719727,
      "learning_rate": 1.3316635908252045e-05,
      "loss": 0.1747,
      "step": 6756
    },
    {
      "epoch": 0.4008186024439435,
      "grad_norm": 0.48599839210510254,
      "learning_rate": 1.3315317690482467e-05,
      "loss": 0.0079,
      "step": 6757
    },
    {
      "epoch": 0.4008779214616206,
      "grad_norm": 0.0179689209908247,
      "learning_rate": 1.3313999472712893e-05,
      "loss": 0.0004,
      "step": 6758
    },
    {
      "epoch": 0.4009372404792977,
      "grad_norm": 2.0534281730651855,
      "learning_rate": 1.3312681254943319e-05,
      "loss": 0.0277,
      "step": 6759
    },
    {
      "epoch": 0.4009965594969747,
      "grad_norm": 7.785284042358398,
      "learning_rate": 1.3311363037173741e-05,
      "loss": 0.433,
      "step": 6760
    },
    {
      "epoch": 0.4010558785146518,
      "grad_norm": 0.0181460939347744,
      "learning_rate": 1.3310044819404166e-05,
      "loss": 0.0004,
      "step": 6761
    },
    {
      "epoch": 0.4011151975323289,
      "grad_norm": 14.136336326599121,
      "learning_rate": 1.3308726601634592e-05,
      "loss": 0.3549,
      "step": 6762
    },
    {
      "epoch": 0.4011745165500059,
      "grad_norm": 0.055069245398044586,
      "learning_rate": 1.3307408383865014e-05,
      "loss": 0.0009,
      "step": 6763
    },
    {
      "epoch": 0.401233835567683,
      "grad_norm": 0.016287004575133324,
      "learning_rate": 1.330609016609544e-05,
      "loss": 0.0005,
      "step": 6764
    },
    {
      "epoch": 0.4012931545853601,
      "grad_norm": 0.003625149605795741,
      "learning_rate": 1.3304771948325866e-05,
      "loss": 0.0001,
      "step": 6765
    },
    {
      "epoch": 0.4013524736030371,
      "grad_norm": 0.1196100264787674,
      "learning_rate": 1.3303453730556288e-05,
      "loss": 0.002,
      "step": 6766
    },
    {
      "epoch": 0.4014117926207142,
      "grad_norm": 36.277103424072266,
      "learning_rate": 1.3302135512786714e-05,
      "loss": 0.6988,
      "step": 6767
    },
    {
      "epoch": 0.4014711116383913,
      "grad_norm": 12.497309684753418,
      "learning_rate": 1.3300817295017138e-05,
      "loss": 0.0745,
      "step": 6768
    },
    {
      "epoch": 0.40153043065606836,
      "grad_norm": 2.7666537761688232,
      "learning_rate": 1.3299499077247563e-05,
      "loss": 0.0127,
      "step": 6769
    },
    {
      "epoch": 0.4015897496737454,
      "grad_norm": 3.4191830158233643,
      "learning_rate": 1.3298180859477987e-05,
      "loss": 0.0143,
      "step": 6770
    },
    {
      "epoch": 0.4016490686914225,
      "grad_norm": 6.491742134094238,
      "learning_rate": 1.3296862641708413e-05,
      "loss": 0.3392,
      "step": 6771
    },
    {
      "epoch": 0.40170838770909956,
      "grad_norm": 8.075804710388184,
      "learning_rate": 1.3295544423938835e-05,
      "loss": 0.2311,
      "step": 6772
    },
    {
      "epoch": 0.4017677067267766,
      "grad_norm": 8.57651424407959,
      "learning_rate": 1.3294226206169261e-05,
      "loss": 0.0394,
      "step": 6773
    },
    {
      "epoch": 0.40182702574445367,
      "grad_norm": 8.057540893554688,
      "learning_rate": 1.3292907988399684e-05,
      "loss": 0.2332,
      "step": 6774
    },
    {
      "epoch": 0.40188634476213075,
      "grad_norm": 4.606586456298828,
      "learning_rate": 1.329158977063011e-05,
      "loss": 0.0232,
      "step": 6775
    },
    {
      "epoch": 0.4019456637798078,
      "grad_norm": 0.3840099275112152,
      "learning_rate": 1.3290271552860534e-05,
      "loss": 0.0028,
      "step": 6776
    },
    {
      "epoch": 0.40200498279748487,
      "grad_norm": 7.219244956970215,
      "learning_rate": 1.3288953335090958e-05,
      "loss": 0.1929,
      "step": 6777
    },
    {
      "epoch": 0.40206430181516195,
      "grad_norm": 38.42461395263672,
      "learning_rate": 1.3287635117321382e-05,
      "loss": 0.548,
      "step": 6778
    },
    {
      "epoch": 0.40212362083283903,
      "grad_norm": 7.199373245239258,
      "learning_rate": 1.3286316899551808e-05,
      "loss": 0.0497,
      "step": 6779
    },
    {
      "epoch": 0.40218293985051606,
      "grad_norm": 0.04573517665266991,
      "learning_rate": 1.328499868178223e-05,
      "loss": 0.001,
      "step": 6780
    },
    {
      "epoch": 0.40224225886819315,
      "grad_norm": 0.4962538182735443,
      "learning_rate": 1.3283680464012656e-05,
      "loss": 0.0055,
      "step": 6781
    },
    {
      "epoch": 0.40230157788587023,
      "grad_norm": 14.038935661315918,
      "learning_rate": 1.3282362246243082e-05,
      "loss": 0.1381,
      "step": 6782
    },
    {
      "epoch": 0.40236089690354726,
      "grad_norm": 0.6412093043327332,
      "learning_rate": 1.3281044028473505e-05,
      "loss": 0.0061,
      "step": 6783
    },
    {
      "epoch": 0.40242021592122434,
      "grad_norm": 6.338815212249756,
      "learning_rate": 1.3279725810703929e-05,
      "loss": 0.07,
      "step": 6784
    },
    {
      "epoch": 0.40247953493890143,
      "grad_norm": 2.5983784198760986,
      "learning_rate": 1.3278407592934355e-05,
      "loss": 0.0135,
      "step": 6785
    },
    {
      "epoch": 0.40253885395657846,
      "grad_norm": 5.379086017608643,
      "learning_rate": 1.3277089375164777e-05,
      "loss": 0.0305,
      "step": 6786
    },
    {
      "epoch": 0.40259817297425554,
      "grad_norm": 17.547239303588867,
      "learning_rate": 1.3275771157395203e-05,
      "loss": 0.9102,
      "step": 6787
    },
    {
      "epoch": 0.4026574919919326,
      "grad_norm": 2.9039855003356934,
      "learning_rate": 1.3274452939625629e-05,
      "loss": 0.0402,
      "step": 6788
    },
    {
      "epoch": 0.40271681100960965,
      "grad_norm": 0.6751369833946228,
      "learning_rate": 1.3273134721856051e-05,
      "loss": 0.0042,
      "step": 6789
    },
    {
      "epoch": 0.40277613002728674,
      "grad_norm": 0.2879025340080261,
      "learning_rate": 1.3271816504086477e-05,
      "loss": 0.0036,
      "step": 6790
    },
    {
      "epoch": 0.4028354490449638,
      "grad_norm": 2.135101079940796,
      "learning_rate": 1.32704982863169e-05,
      "loss": 0.0383,
      "step": 6791
    },
    {
      "epoch": 0.4028947680626409,
      "grad_norm": 0.03752196580171585,
      "learning_rate": 1.3269180068547326e-05,
      "loss": 0.0008,
      "step": 6792
    },
    {
      "epoch": 0.40295408708031794,
      "grad_norm": 0.6176542043685913,
      "learning_rate": 1.326786185077775e-05,
      "loss": 0.0071,
      "step": 6793
    },
    {
      "epoch": 0.403013406097995,
      "grad_norm": 1.4719079732894897,
      "learning_rate": 1.3266543633008172e-05,
      "loss": 0.0148,
      "step": 6794
    },
    {
      "epoch": 0.4030727251156721,
      "grad_norm": 0.22893096506595612,
      "learning_rate": 1.3265225415238598e-05,
      "loss": 0.0021,
      "step": 6795
    },
    {
      "epoch": 0.40313204413334913,
      "grad_norm": 10.015721321105957,
      "learning_rate": 1.3263907197469024e-05,
      "loss": 0.2904,
      "step": 6796
    },
    {
      "epoch": 0.4031913631510262,
      "grad_norm": 21.075855255126953,
      "learning_rate": 1.3262588979699447e-05,
      "loss": 0.1443,
      "step": 6797
    },
    {
      "epoch": 0.4032506821687033,
      "grad_norm": 0.07763631641864777,
      "learning_rate": 1.3261270761929872e-05,
      "loss": 0.001,
      "step": 6798
    },
    {
      "epoch": 0.40331000118638033,
      "grad_norm": 2.461744546890259,
      "learning_rate": 1.3259952544160297e-05,
      "loss": 0.0534,
      "step": 6799
    },
    {
      "epoch": 0.4033693202040574,
      "grad_norm": 6.099026679992676,
      "learning_rate": 1.325863432639072e-05,
      "loss": 0.0681,
      "step": 6800
    },
    {
      "epoch": 0.4034286392217345,
      "grad_norm": 2.310838222503662,
      "learning_rate": 1.3257316108621145e-05,
      "loss": 0.0115,
      "step": 6801
    },
    {
      "epoch": 0.4034879582394116,
      "grad_norm": 7.681604862213135,
      "learning_rate": 1.3255997890851571e-05,
      "loss": 0.2025,
      "step": 6802
    },
    {
      "epoch": 0.4035472772570886,
      "grad_norm": 9.044389724731445,
      "learning_rate": 1.3254679673081993e-05,
      "loss": 0.5688,
      "step": 6803
    },
    {
      "epoch": 0.4036065962747657,
      "grad_norm": 5.588831424713135,
      "learning_rate": 1.325336145531242e-05,
      "loss": 0.0478,
      "step": 6804
    },
    {
      "epoch": 0.4036659152924428,
      "grad_norm": 0.394290030002594,
      "learning_rate": 1.3252043237542842e-05,
      "loss": 0.011,
      "step": 6805
    },
    {
      "epoch": 0.4037252343101198,
      "grad_norm": 28.57290267944336,
      "learning_rate": 1.3250725019773268e-05,
      "loss": 0.3077,
      "step": 6806
    },
    {
      "epoch": 0.4037845533277969,
      "grad_norm": 1.278493046760559,
      "learning_rate": 1.3249406802003692e-05,
      "loss": 0.0263,
      "step": 6807
    },
    {
      "epoch": 0.403843872345474,
      "grad_norm": 63.56023406982422,
      "learning_rate": 1.3248088584234116e-05,
      "loss": 0.707,
      "step": 6808
    },
    {
      "epoch": 0.403903191363151,
      "grad_norm": 3.231275796890259,
      "learning_rate": 1.324677036646454e-05,
      "loss": 0.326,
      "step": 6809
    },
    {
      "epoch": 0.4039625103808281,
      "grad_norm": 0.9663982391357422,
      "learning_rate": 1.3245452148694966e-05,
      "loss": 0.01,
      "step": 6810
    },
    {
      "epoch": 0.4040218293985052,
      "grad_norm": 18.330440521240234,
      "learning_rate": 1.3244133930925389e-05,
      "loss": 0.1692,
      "step": 6811
    },
    {
      "epoch": 0.4040811484161822,
      "grad_norm": 3.826218366622925,
      "learning_rate": 1.3242815713155814e-05,
      "loss": 0.2576,
      "step": 6812
    },
    {
      "epoch": 0.4041404674338593,
      "grad_norm": 13.293180465698242,
      "learning_rate": 1.324149749538624e-05,
      "loss": 0.1246,
      "step": 6813
    },
    {
      "epoch": 0.40419978645153637,
      "grad_norm": 0.04749324917793274,
      "learning_rate": 1.3240179277616663e-05,
      "loss": 0.0008,
      "step": 6814
    },
    {
      "epoch": 0.40425910546921345,
      "grad_norm": 4.877146244049072,
      "learning_rate": 1.3238861059847089e-05,
      "loss": 0.0516,
      "step": 6815
    },
    {
      "epoch": 0.4043184244868905,
      "grad_norm": 20.446537017822266,
      "learning_rate": 1.3237542842077513e-05,
      "loss": 0.2207,
      "step": 6816
    },
    {
      "epoch": 0.40437774350456757,
      "grad_norm": 0.4424341320991516,
      "learning_rate": 1.3236224624307935e-05,
      "loss": 0.0044,
      "step": 6817
    },
    {
      "epoch": 0.40443706252224465,
      "grad_norm": 32.73021697998047,
      "learning_rate": 1.3234906406538361e-05,
      "loss": 0.3044,
      "step": 6818
    },
    {
      "epoch": 0.4044963815399217,
      "grad_norm": 12.768119812011719,
      "learning_rate": 1.3233588188768787e-05,
      "loss": 0.1816,
      "step": 6819
    },
    {
      "epoch": 0.40455570055759876,
      "grad_norm": 0.03696463257074356,
      "learning_rate": 1.323226997099921e-05,
      "loss": 0.0008,
      "step": 6820
    },
    {
      "epoch": 0.40461501957527585,
      "grad_norm": 0.019496595486998558,
      "learning_rate": 1.3230951753229636e-05,
      "loss": 0.0005,
      "step": 6821
    },
    {
      "epoch": 0.4046743385929529,
      "grad_norm": 15.2188720703125,
      "learning_rate": 1.3229633535460058e-05,
      "loss": 0.6855,
      "step": 6822
    },
    {
      "epoch": 0.40473365761062996,
      "grad_norm": 2.5621635913848877,
      "learning_rate": 1.3228315317690484e-05,
      "loss": 0.0351,
      "step": 6823
    },
    {
      "epoch": 0.40479297662830704,
      "grad_norm": 6.962411880493164,
      "learning_rate": 1.3226997099920908e-05,
      "loss": 0.1029,
      "step": 6824
    },
    {
      "epoch": 0.40485229564598413,
      "grad_norm": 8.099003791809082,
      "learning_rate": 1.3225678882151332e-05,
      "loss": 0.4163,
      "step": 6825
    },
    {
      "epoch": 0.40491161466366116,
      "grad_norm": 19.23114776611328,
      "learning_rate": 1.3224360664381756e-05,
      "loss": 0.7399,
      "step": 6826
    },
    {
      "epoch": 0.40497093368133824,
      "grad_norm": 0.021922525018453598,
      "learning_rate": 1.3223042446612182e-05,
      "loss": 0.0005,
      "step": 6827
    },
    {
      "epoch": 0.4050302526990153,
      "grad_norm": 17.712242126464844,
      "learning_rate": 1.3221724228842605e-05,
      "loss": 0.673,
      "step": 6828
    },
    {
      "epoch": 0.40508957171669235,
      "grad_norm": 2.0814716815948486,
      "learning_rate": 1.322040601107303e-05,
      "loss": 0.0138,
      "step": 6829
    },
    {
      "epoch": 0.40514889073436944,
      "grad_norm": 22.97789192199707,
      "learning_rate": 1.3219087793303455e-05,
      "loss": 0.0718,
      "step": 6830
    },
    {
      "epoch": 0.4052082097520465,
      "grad_norm": 3.1750457286834717,
      "learning_rate": 1.3217769575533879e-05,
      "loss": 0.0401,
      "step": 6831
    },
    {
      "epoch": 0.40526752876972355,
      "grad_norm": 0.03288671746850014,
      "learning_rate": 1.3216451357764303e-05,
      "loss": 0.0008,
      "step": 6832
    },
    {
      "epoch": 0.40532684778740063,
      "grad_norm": 12.121481895446777,
      "learning_rate": 1.321513313999473e-05,
      "loss": 0.2825,
      "step": 6833
    },
    {
      "epoch": 0.4053861668050777,
      "grad_norm": 15.765412330627441,
      "learning_rate": 1.3213814922225152e-05,
      "loss": 0.1381,
      "step": 6834
    },
    {
      "epoch": 0.40544548582275475,
      "grad_norm": 5.639240264892578,
      "learning_rate": 1.3212496704455578e-05,
      "loss": 0.0666,
      "step": 6835
    },
    {
      "epoch": 0.40550480484043183,
      "grad_norm": 24.042173385620117,
      "learning_rate": 1.3211178486686003e-05,
      "loss": 0.342,
      "step": 6836
    },
    {
      "epoch": 0.4055641238581089,
      "grad_norm": 5.49786901473999,
      "learning_rate": 1.3209860268916426e-05,
      "loss": 0.1102,
      "step": 6837
    },
    {
      "epoch": 0.405623442875786,
      "grad_norm": 3.407670259475708,
      "learning_rate": 1.320854205114685e-05,
      "loss": 0.0224,
      "step": 6838
    },
    {
      "epoch": 0.40568276189346303,
      "grad_norm": 3.284447193145752,
      "learning_rate": 1.3207223833377274e-05,
      "loss": 0.046,
      "step": 6839
    },
    {
      "epoch": 0.4057420809111401,
      "grad_norm": 0.07778086513280869,
      "learning_rate": 1.3205905615607698e-05,
      "loss": 0.0017,
      "step": 6840
    },
    {
      "epoch": 0.4058013999288172,
      "grad_norm": 0.017729220911860466,
      "learning_rate": 1.3204587397838124e-05,
      "loss": 0.0006,
      "step": 6841
    },
    {
      "epoch": 0.4058607189464942,
      "grad_norm": 11.504932403564453,
      "learning_rate": 1.3203269180068547e-05,
      "loss": 0.5796,
      "step": 6842
    },
    {
      "epoch": 0.4059200379641713,
      "grad_norm": 2.619673728942871,
      "learning_rate": 1.3201950962298973e-05,
      "loss": 0.0443,
      "step": 6843
    },
    {
      "epoch": 0.4059793569818484,
      "grad_norm": 37.649330139160156,
      "learning_rate": 1.3200632744529399e-05,
      "loss": 0.908,
      "step": 6844
    },
    {
      "epoch": 0.4060386759995254,
      "grad_norm": 13.154759407043457,
      "learning_rate": 1.3199314526759821e-05,
      "loss": 0.4506,
      "step": 6845
    },
    {
      "epoch": 0.4060979950172025,
      "grad_norm": 0.33913925290107727,
      "learning_rate": 1.3197996308990247e-05,
      "loss": 0.0084,
      "step": 6846
    },
    {
      "epoch": 0.4061573140348796,
      "grad_norm": 11.306422233581543,
      "learning_rate": 1.3196678091220671e-05,
      "loss": 0.1565,
      "step": 6847
    },
    {
      "epoch": 0.4062166330525567,
      "grad_norm": 6.914426803588867,
      "learning_rate": 1.3195359873451095e-05,
      "loss": 0.0415,
      "step": 6848
    },
    {
      "epoch": 0.4062759520702337,
      "grad_norm": 7.720919132232666,
      "learning_rate": 1.319404165568152e-05,
      "loss": 0.1721,
      "step": 6849
    },
    {
      "epoch": 0.4063352710879108,
      "grad_norm": 0.026919236406683922,
      "learning_rate": 1.3192723437911945e-05,
      "loss": 0.0008,
      "step": 6850
    },
    {
      "epoch": 0.40639459010558787,
      "grad_norm": 0.10443852841854095,
      "learning_rate": 1.3191405220142368e-05,
      "loss": 0.0018,
      "step": 6851
    },
    {
      "epoch": 0.4064539091232649,
      "grad_norm": 0.22178226709365845,
      "learning_rate": 1.3190087002372794e-05,
      "loss": 0.0038,
      "step": 6852
    },
    {
      "epoch": 0.406513228140942,
      "grad_norm": 16.955923080444336,
      "learning_rate": 1.3188768784603218e-05,
      "loss": 0.1111,
      "step": 6853
    },
    {
      "epoch": 0.40657254715861907,
      "grad_norm": 0.13003666698932648,
      "learning_rate": 1.3187450566833642e-05,
      "loss": 0.0012,
      "step": 6854
    },
    {
      "epoch": 0.4066318661762961,
      "grad_norm": 12.82082748413086,
      "learning_rate": 1.3186132349064066e-05,
      "loss": 0.2681,
      "step": 6855
    },
    {
      "epoch": 0.4066911851939732,
      "grad_norm": 0.03160499036312103,
      "learning_rate": 1.318481413129449e-05,
      "loss": 0.0006,
      "step": 6856
    },
    {
      "epoch": 0.40675050421165027,
      "grad_norm": 29.585960388183594,
      "learning_rate": 1.3183495913524915e-05,
      "loss": 0.2451,
      "step": 6857
    },
    {
      "epoch": 0.40680982322932735,
      "grad_norm": 6.491981029510498,
      "learning_rate": 1.318217769575534e-05,
      "loss": 0.1442,
      "step": 6858
    },
    {
      "epoch": 0.4068691422470044,
      "grad_norm": 33.24970626831055,
      "learning_rate": 1.3180859477985763e-05,
      "loss": 0.7313,
      "step": 6859
    },
    {
      "epoch": 0.40692846126468146,
      "grad_norm": 6.470446586608887,
      "learning_rate": 1.3179541260216189e-05,
      "loss": 0.1269,
      "step": 6860
    },
    {
      "epoch": 0.40698778028235855,
      "grad_norm": 0.035256125032901764,
      "learning_rate": 1.3178223042446613e-05,
      "loss": 0.0005,
      "step": 6861
    },
    {
      "epoch": 0.4070470993000356,
      "grad_norm": 12.267521858215332,
      "learning_rate": 1.3176904824677037e-05,
      "loss": 0.248,
      "step": 6862
    },
    {
      "epoch": 0.40710641831771266,
      "grad_norm": 8.471789360046387,
      "learning_rate": 1.3175586606907462e-05,
      "loss": 0.5211,
      "step": 6863
    },
    {
      "epoch": 0.40716573733538974,
      "grad_norm": 3.1053407192230225,
      "learning_rate": 1.3174268389137887e-05,
      "loss": 0.0275,
      "step": 6864
    },
    {
      "epoch": 0.40722505635306677,
      "grad_norm": 30.914966583251953,
      "learning_rate": 1.317295017136831e-05,
      "loss": 0.131,
      "step": 6865
    },
    {
      "epoch": 0.40728437537074386,
      "grad_norm": 7.84405517578125,
      "learning_rate": 1.3171631953598736e-05,
      "loss": 0.2234,
      "step": 6866
    },
    {
      "epoch": 0.40734369438842094,
      "grad_norm": 0.08557607978582382,
      "learning_rate": 1.3170313735829162e-05,
      "loss": 0.0014,
      "step": 6867
    },
    {
      "epoch": 0.40740301340609797,
      "grad_norm": 0.21516145765781403,
      "learning_rate": 1.3168995518059584e-05,
      "loss": 0.0043,
      "step": 6868
    },
    {
      "epoch": 0.40746233242377505,
      "grad_norm": 91.9043960571289,
      "learning_rate": 1.316767730029001e-05,
      "loss": 0.5039,
      "step": 6869
    },
    {
      "epoch": 0.40752165144145214,
      "grad_norm": 0.9836260080337524,
      "learning_rate": 1.3166359082520433e-05,
      "loss": 0.0102,
      "step": 6870
    },
    {
      "epoch": 0.4075809704591292,
      "grad_norm": 4.096743106842041,
      "learning_rate": 1.3165040864750858e-05,
      "loss": 0.0271,
      "step": 6871
    },
    {
      "epoch": 0.40764028947680625,
      "grad_norm": 0.018846331164240837,
      "learning_rate": 1.3163722646981283e-05,
      "loss": 0.0004,
      "step": 6872
    },
    {
      "epoch": 0.40769960849448333,
      "grad_norm": 1.195967197418213,
      "learning_rate": 1.3162404429211705e-05,
      "loss": 0.0075,
      "step": 6873
    },
    {
      "epoch": 0.4077589275121604,
      "grad_norm": 0.6824999451637268,
      "learning_rate": 1.3161086211442131e-05,
      "loss": 0.007,
      "step": 6874
    },
    {
      "epoch": 0.40781824652983745,
      "grad_norm": 0.174940824508667,
      "learning_rate": 1.3159767993672557e-05,
      "loss": 0.003,
      "step": 6875
    },
    {
      "epoch": 0.40787756554751453,
      "grad_norm": 8.865514755249023,
      "learning_rate": 1.315844977590298e-05,
      "loss": 0.4997,
      "step": 6876
    },
    {
      "epoch": 0.4079368845651916,
      "grad_norm": 8.765785217285156,
      "learning_rate": 1.3157131558133405e-05,
      "loss": 0.0599,
      "step": 6877
    },
    {
      "epoch": 0.40799620358286864,
      "grad_norm": 2.3452415466308594,
      "learning_rate": 1.315581334036383e-05,
      "loss": 0.0334,
      "step": 6878
    },
    {
      "epoch": 0.40805552260054573,
      "grad_norm": 11.891383171081543,
      "learning_rate": 1.3154495122594254e-05,
      "loss": 0.2436,
      "step": 6879
    },
    {
      "epoch": 0.4081148416182228,
      "grad_norm": 6.638443946838379,
      "learning_rate": 1.3153176904824678e-05,
      "loss": 0.1954,
      "step": 6880
    },
    {
      "epoch": 0.4081741606358999,
      "grad_norm": 6.8270087242126465,
      "learning_rate": 1.3151858687055104e-05,
      "loss": 0.082,
      "step": 6881
    },
    {
      "epoch": 0.4082334796535769,
      "grad_norm": 7.577353477478027,
      "learning_rate": 1.3150540469285526e-05,
      "loss": 0.0986,
      "step": 6882
    },
    {
      "epoch": 0.408292798671254,
      "grad_norm": 8.138972282409668,
      "learning_rate": 1.3149222251515952e-05,
      "loss": 0.0532,
      "step": 6883
    },
    {
      "epoch": 0.4083521176889311,
      "grad_norm": 6.78536319732666,
      "learning_rate": 1.3147904033746376e-05,
      "loss": 0.1519,
      "step": 6884
    },
    {
      "epoch": 0.4084114367066081,
      "grad_norm": 0.006962744519114494,
      "learning_rate": 1.31465858159768e-05,
      "loss": 0.0002,
      "step": 6885
    },
    {
      "epoch": 0.4084707557242852,
      "grad_norm": 12.979310989379883,
      "learning_rate": 1.3145267598207225e-05,
      "loss": 0.3066,
      "step": 6886
    },
    {
      "epoch": 0.4085300747419623,
      "grad_norm": 11.660505294799805,
      "learning_rate": 1.3143949380437649e-05,
      "loss": 0.1323,
      "step": 6887
    },
    {
      "epoch": 0.4085893937596393,
      "grad_norm": 19.231538772583008,
      "learning_rate": 1.3142631162668073e-05,
      "loss": 0.148,
      "step": 6888
    },
    {
      "epoch": 0.4086487127773164,
      "grad_norm": 0.060245759785175323,
      "learning_rate": 1.3141312944898499e-05,
      "loss": 0.0013,
      "step": 6889
    },
    {
      "epoch": 0.4087080317949935,
      "grad_norm": 9.187315940856934,
      "learning_rate": 1.3139994727128921e-05,
      "loss": 0.4711,
      "step": 6890
    },
    {
      "epoch": 0.4087673508126705,
      "grad_norm": 1.3627742528915405,
      "learning_rate": 1.3138676509359347e-05,
      "loss": 0.0078,
      "step": 6891
    },
    {
      "epoch": 0.4088266698303476,
      "grad_norm": 1.6247128248214722,
      "learning_rate": 1.3137358291589773e-05,
      "loss": 0.0336,
      "step": 6892
    },
    {
      "epoch": 0.4088859888480247,
      "grad_norm": 8.690866470336914,
      "learning_rate": 1.3136040073820196e-05,
      "loss": 0.753,
      "step": 6893
    },
    {
      "epoch": 0.40894530786570177,
      "grad_norm": 0.08657486736774445,
      "learning_rate": 1.313472185605062e-05,
      "loss": 0.001,
      "step": 6894
    },
    {
      "epoch": 0.4090046268833788,
      "grad_norm": 0.08113005757331848,
      "learning_rate": 1.3133403638281046e-05,
      "loss": 0.001,
      "step": 6895
    },
    {
      "epoch": 0.4090639459010559,
      "grad_norm": 0.23916089534759521,
      "learning_rate": 1.3132085420511468e-05,
      "loss": 0.0038,
      "step": 6896
    },
    {
      "epoch": 0.40912326491873297,
      "grad_norm": 6.026294231414795,
      "learning_rate": 1.3130767202741894e-05,
      "loss": 0.1324,
      "step": 6897
    },
    {
      "epoch": 0.40918258393641,
      "grad_norm": 0.12097648531198502,
      "learning_rate": 1.312944898497232e-05,
      "loss": 0.0016,
      "step": 6898
    },
    {
      "epoch": 0.4092419029540871,
      "grad_norm": 1.8648594617843628,
      "learning_rate": 1.3128130767202742e-05,
      "loss": 0.0345,
      "step": 6899
    },
    {
      "epoch": 0.40930122197176416,
      "grad_norm": 10.195874214172363,
      "learning_rate": 1.3126812549433168e-05,
      "loss": 0.1099,
      "step": 6900
    },
    {
      "epoch": 0.4093605409894412,
      "grad_norm": 27.212968826293945,
      "learning_rate": 1.3125494331663593e-05,
      "loss": 0.2179,
      "step": 6901
    },
    {
      "epoch": 0.4094198600071183,
      "grad_norm": 9.156540870666504,
      "learning_rate": 1.3124176113894017e-05,
      "loss": 0.3966,
      "step": 6902
    },
    {
      "epoch": 0.40947917902479536,
      "grad_norm": 0.027944188565015793,
      "learning_rate": 1.3122857896124441e-05,
      "loss": 0.0009,
      "step": 6903
    },
    {
      "epoch": 0.40953849804247244,
      "grad_norm": 0.40342530608177185,
      "learning_rate": 1.3121539678354865e-05,
      "loss": 0.0048,
      "step": 6904
    },
    {
      "epoch": 0.40959781706014947,
      "grad_norm": 0.19074681401252747,
      "learning_rate": 1.312022146058529e-05,
      "loss": 0.0029,
      "step": 6905
    },
    {
      "epoch": 0.40965713607782656,
      "grad_norm": 1.426771879196167,
      "learning_rate": 1.3118903242815715e-05,
      "loss": 0.0225,
      "step": 6906
    },
    {
      "epoch": 0.40971645509550364,
      "grad_norm": 15.352071762084961,
      "learning_rate": 1.3117585025046138e-05,
      "loss": 0.6026,
      "step": 6907
    },
    {
      "epoch": 0.40977577411318067,
      "grad_norm": 0.009156821295619011,
      "learning_rate": 1.3116266807276564e-05,
      "loss": 0.0003,
      "step": 6908
    },
    {
      "epoch": 0.40983509313085775,
      "grad_norm": 10.13642692565918,
      "learning_rate": 1.3114948589506988e-05,
      "loss": 0.0842,
      "step": 6909
    },
    {
      "epoch": 0.40989441214853484,
      "grad_norm": 0.08607188612222672,
      "learning_rate": 1.3113630371737412e-05,
      "loss": 0.0013,
      "step": 6910
    },
    {
      "epoch": 0.40995373116621187,
      "grad_norm": 0.24176521599292755,
      "learning_rate": 1.3112312153967836e-05,
      "loss": 0.0039,
      "step": 6911
    },
    {
      "epoch": 0.41001305018388895,
      "grad_norm": 20.83586311340332,
      "learning_rate": 1.3110993936198262e-05,
      "loss": 0.2145,
      "step": 6912
    },
    {
      "epoch": 0.41007236920156603,
      "grad_norm": 0.017096849158406258,
      "learning_rate": 1.3109675718428684e-05,
      "loss": 0.0004,
      "step": 6913
    },
    {
      "epoch": 0.41013168821924306,
      "grad_norm": 0.08333511650562286,
      "learning_rate": 1.310835750065911e-05,
      "loss": 0.0017,
      "step": 6914
    },
    {
      "epoch": 0.41019100723692015,
      "grad_norm": 8.54934310913086,
      "learning_rate": 1.3107039282889536e-05,
      "loss": 0.1406,
      "step": 6915
    },
    {
      "epoch": 0.41025032625459723,
      "grad_norm": 0.4735013246536255,
      "learning_rate": 1.3105721065119959e-05,
      "loss": 0.0042,
      "step": 6916
    },
    {
      "epoch": 0.4103096452722743,
      "grad_norm": 8.556828498840332,
      "learning_rate": 1.3104402847350383e-05,
      "loss": 0.141,
      "step": 6917
    },
    {
      "epoch": 0.41036896428995134,
      "grad_norm": 0.0389392264187336,
      "learning_rate": 1.3103084629580807e-05,
      "loss": 0.0007,
      "step": 6918
    },
    {
      "epoch": 0.4104282833076284,
      "grad_norm": 0.027137156575918198,
      "learning_rate": 1.3101766411811231e-05,
      "loss": 0.0006,
      "step": 6919
    },
    {
      "epoch": 0.4104876023253055,
      "grad_norm": 14.51349925994873,
      "learning_rate": 1.3100448194041657e-05,
      "loss": 0.6569,
      "step": 6920
    },
    {
      "epoch": 0.41054692134298254,
      "grad_norm": 0.28231924772262573,
      "learning_rate": 1.309912997627208e-05,
      "loss": 0.0052,
      "step": 6921
    },
    {
      "epoch": 0.4106062403606596,
      "grad_norm": 6.120980739593506,
      "learning_rate": 1.3097811758502506e-05,
      "loss": 0.0856,
      "step": 6922
    },
    {
      "epoch": 0.4106655593783367,
      "grad_norm": 0.13430741429328918,
      "learning_rate": 1.3096493540732931e-05,
      "loss": 0.0027,
      "step": 6923
    },
    {
      "epoch": 0.41072487839601374,
      "grad_norm": 0.41042661666870117,
      "learning_rate": 1.3095175322963354e-05,
      "loss": 0.0042,
      "step": 6924
    },
    {
      "epoch": 0.4107841974136908,
      "grad_norm": 10.437836647033691,
      "learning_rate": 1.309385710519378e-05,
      "loss": 0.0389,
      "step": 6925
    },
    {
      "epoch": 0.4108435164313679,
      "grad_norm": 3.8755500316619873,
      "learning_rate": 1.3092538887424204e-05,
      "loss": 0.0356,
      "step": 6926
    },
    {
      "epoch": 0.410902835449045,
      "grad_norm": 0.0625755712389946,
      "learning_rate": 1.3091220669654628e-05,
      "loss": 0.0004,
      "step": 6927
    },
    {
      "epoch": 0.410962154466722,
      "grad_norm": 1.6168595552444458,
      "learning_rate": 1.3089902451885052e-05,
      "loss": 0.0122,
      "step": 6928
    },
    {
      "epoch": 0.4110214734843991,
      "grad_norm": 5.21088981628418,
      "learning_rate": 1.3088584234115478e-05,
      "loss": 0.1757,
      "step": 6929
    },
    {
      "epoch": 0.4110807925020762,
      "grad_norm": 4.529349327087402,
      "learning_rate": 1.30872660163459e-05,
      "loss": 0.0653,
      "step": 6930
    },
    {
      "epoch": 0.4111401115197532,
      "grad_norm": 25.85943031311035,
      "learning_rate": 1.3085947798576327e-05,
      "loss": 0.7492,
      "step": 6931
    },
    {
      "epoch": 0.4111994305374303,
      "grad_norm": 3.286937713623047,
      "learning_rate": 1.308462958080675e-05,
      "loss": 0.1276,
      "step": 6932
    },
    {
      "epoch": 0.4112587495551074,
      "grad_norm": 8.316864967346191,
      "learning_rate": 1.3083311363037175e-05,
      "loss": 0.1742,
      "step": 6933
    },
    {
      "epoch": 0.4113180685727844,
      "grad_norm": 15.859745025634766,
      "learning_rate": 1.30819931452676e-05,
      "loss": 0.2787,
      "step": 6934
    },
    {
      "epoch": 0.4113773875904615,
      "grad_norm": 3.99377179145813,
      "learning_rate": 1.3080674927498023e-05,
      "loss": 0.6128,
      "step": 6935
    },
    {
      "epoch": 0.4114367066081386,
      "grad_norm": 7.317808151245117,
      "learning_rate": 1.3079356709728448e-05,
      "loss": 0.2096,
      "step": 6936
    },
    {
      "epoch": 0.4114960256258156,
      "grad_norm": 0.04418376833200455,
      "learning_rate": 1.3078038491958873e-05,
      "loss": 0.0005,
      "step": 6937
    },
    {
      "epoch": 0.4115553446434927,
      "grad_norm": 12.337223052978516,
      "learning_rate": 1.3076720274189296e-05,
      "loss": 0.2372,
      "step": 6938
    },
    {
      "epoch": 0.4116146636611698,
      "grad_norm": 2.6679866313934326,
      "learning_rate": 1.3075402056419722e-05,
      "loss": 0.0486,
      "step": 6939
    },
    {
      "epoch": 0.41167398267884686,
      "grad_norm": 1.7997134923934937,
      "learning_rate": 1.3074083838650146e-05,
      "loss": 0.0169,
      "step": 6940
    },
    {
      "epoch": 0.4117333016965239,
      "grad_norm": 0.10718659311532974,
      "learning_rate": 1.307276562088057e-05,
      "loss": 0.0022,
      "step": 6941
    },
    {
      "epoch": 0.411792620714201,
      "grad_norm": 4.0220255851745605,
      "learning_rate": 1.3071447403110994e-05,
      "loss": 0.0453,
      "step": 6942
    },
    {
      "epoch": 0.41185193973187806,
      "grad_norm": 3.0953590869903564,
      "learning_rate": 1.307012918534142e-05,
      "loss": 0.1004,
      "step": 6943
    },
    {
      "epoch": 0.4119112587495551,
      "grad_norm": 0.8061952590942383,
      "learning_rate": 1.3068810967571843e-05,
      "loss": 0.0118,
      "step": 6944
    },
    {
      "epoch": 0.41197057776723217,
      "grad_norm": 0.009947600774466991,
      "learning_rate": 1.3067492749802269e-05,
      "loss": 0.0004,
      "step": 6945
    },
    {
      "epoch": 0.41202989678490926,
      "grad_norm": 11.10933780670166,
      "learning_rate": 1.3066174532032695e-05,
      "loss": 0.2609,
      "step": 6946
    },
    {
      "epoch": 0.4120892158025863,
      "grad_norm": 23.96159553527832,
      "learning_rate": 1.3064856314263117e-05,
      "loss": 0.3272,
      "step": 6947
    },
    {
      "epoch": 0.41214853482026337,
      "grad_norm": 4.768117904663086,
      "learning_rate": 1.3063538096493543e-05,
      "loss": 0.0797,
      "step": 6948
    },
    {
      "epoch": 0.41220785383794045,
      "grad_norm": 0.5386658310890198,
      "learning_rate": 1.3062219878723967e-05,
      "loss": 0.0062,
      "step": 6949
    },
    {
      "epoch": 0.41226717285561754,
      "grad_norm": 0.024018600583076477,
      "learning_rate": 1.306090166095439e-05,
      "loss": 0.0005,
      "step": 6950
    },
    {
      "epoch": 0.41232649187329456,
      "grad_norm": 0.02393648773431778,
      "learning_rate": 1.3059583443184815e-05,
      "loss": 0.0007,
      "step": 6951
    },
    {
      "epoch": 0.41238581089097165,
      "grad_norm": 0.6036139130592346,
      "learning_rate": 1.3058265225415238e-05,
      "loss": 0.0062,
      "step": 6952
    },
    {
      "epoch": 0.41244512990864873,
      "grad_norm": 10.426884651184082,
      "learning_rate": 1.3056947007645664e-05,
      "loss": 0.6563,
      "step": 6953
    },
    {
      "epoch": 0.41250444892632576,
      "grad_norm": 6.408549785614014,
      "learning_rate": 1.305562878987609e-05,
      "loss": 0.7828,
      "step": 6954
    },
    {
      "epoch": 0.41256376794400285,
      "grad_norm": 35.61209487915039,
      "learning_rate": 1.3054310572106512e-05,
      "loss": 0.5685,
      "step": 6955
    },
    {
      "epoch": 0.41262308696167993,
      "grad_norm": 0.0826726034283638,
      "learning_rate": 1.3052992354336938e-05,
      "loss": 0.0013,
      "step": 6956
    },
    {
      "epoch": 0.41268240597935696,
      "grad_norm": 22.71392250061035,
      "learning_rate": 1.3051674136567362e-05,
      "loss": 0.1914,
      "step": 6957
    },
    {
      "epoch": 0.41274172499703404,
      "grad_norm": 0.4393376111984253,
      "learning_rate": 1.3050355918797786e-05,
      "loss": 0.004,
      "step": 6958
    },
    {
      "epoch": 0.4128010440147111,
      "grad_norm": 0.1033954992890358,
      "learning_rate": 1.304903770102821e-05,
      "loss": 0.0018,
      "step": 6959
    },
    {
      "epoch": 0.4128603630323882,
      "grad_norm": 0.0064523364417254925,
      "learning_rate": 1.3047719483258637e-05,
      "loss": 0.0002,
      "step": 6960
    },
    {
      "epoch": 0.41291968205006524,
      "grad_norm": 7.42592716217041,
      "learning_rate": 1.3046401265489059e-05,
      "loss": 0.1132,
      "step": 6961
    },
    {
      "epoch": 0.4129790010677423,
      "grad_norm": 0.2115236520767212,
      "learning_rate": 1.3045083047719485e-05,
      "loss": 0.0021,
      "step": 6962
    },
    {
      "epoch": 0.4130383200854194,
      "grad_norm": 3.907122850418091,
      "learning_rate": 1.3043764829949909e-05,
      "loss": 0.1018,
      "step": 6963
    },
    {
      "epoch": 0.41309763910309644,
      "grad_norm": 13.94058609008789,
      "learning_rate": 1.3042446612180333e-05,
      "loss": 0.3766,
      "step": 6964
    },
    {
      "epoch": 0.4131569581207735,
      "grad_norm": 10.40772819519043,
      "learning_rate": 1.3041128394410757e-05,
      "loss": 0.5222,
      "step": 6965
    },
    {
      "epoch": 0.4132162771384506,
      "grad_norm": 10.032062530517578,
      "learning_rate": 1.3039810176641182e-05,
      "loss": 0.3414,
      "step": 6966
    },
    {
      "epoch": 0.41327559615612763,
      "grad_norm": 22.109960556030273,
      "learning_rate": 1.3038491958871606e-05,
      "loss": 0.7683,
      "step": 6967
    },
    {
      "epoch": 0.4133349151738047,
      "grad_norm": 13.968757629394531,
      "learning_rate": 1.3037173741102032e-05,
      "loss": 0.3364,
      "step": 6968
    },
    {
      "epoch": 0.4133942341914818,
      "grad_norm": 0.24655357003211975,
      "learning_rate": 1.3035855523332454e-05,
      "loss": 0.0032,
      "step": 6969
    },
    {
      "epoch": 0.41345355320915883,
      "grad_norm": 3.847979784011841,
      "learning_rate": 1.303453730556288e-05,
      "loss": 0.1062,
      "step": 6970
    },
    {
      "epoch": 0.4135128722268359,
      "grad_norm": 0.009166412986814976,
      "learning_rate": 1.3033219087793306e-05,
      "loss": 0.0003,
      "step": 6971
    },
    {
      "epoch": 0.413572191244513,
      "grad_norm": 0.06457270681858063,
      "learning_rate": 1.3031900870023728e-05,
      "loss": 0.0013,
      "step": 6972
    },
    {
      "epoch": 0.4136315102621901,
      "grad_norm": 0.04447464644908905,
      "learning_rate": 1.3030582652254153e-05,
      "loss": 0.0012,
      "step": 6973
    },
    {
      "epoch": 0.4136908292798671,
      "grad_norm": 6.436850070953369,
      "learning_rate": 1.3029264434484579e-05,
      "loss": 0.0451,
      "step": 6974
    },
    {
      "epoch": 0.4137501482975442,
      "grad_norm": 4.2825493812561035,
      "learning_rate": 1.3027946216715001e-05,
      "loss": 0.0452,
      "step": 6975
    },
    {
      "epoch": 0.4138094673152213,
      "grad_norm": 6.8076701164245605,
      "learning_rate": 1.3026627998945427e-05,
      "loss": 0.2879,
      "step": 6976
    },
    {
      "epoch": 0.4138687863328983,
      "grad_norm": 14.833138465881348,
      "learning_rate": 1.3025309781175853e-05,
      "loss": 0.3572,
      "step": 6977
    },
    {
      "epoch": 0.4139281053505754,
      "grad_norm": 14.75479507446289,
      "learning_rate": 1.3023991563406275e-05,
      "loss": 0.9566,
      "step": 6978
    },
    {
      "epoch": 0.4139874243682525,
      "grad_norm": 5.470386505126953,
      "learning_rate": 1.3022673345636701e-05,
      "loss": 0.2634,
      "step": 6979
    },
    {
      "epoch": 0.4140467433859295,
      "grad_norm": 11.956636428833008,
      "learning_rate": 1.3021355127867125e-05,
      "loss": 0.3612,
      "step": 6980
    },
    {
      "epoch": 0.4141060624036066,
      "grad_norm": 0.9109588861465454,
      "learning_rate": 1.302003691009755e-05,
      "loss": 0.0143,
      "step": 6981
    },
    {
      "epoch": 0.4141653814212837,
      "grad_norm": 0.25066685676574707,
      "learning_rate": 1.3018718692327974e-05,
      "loss": 0.0034,
      "step": 6982
    },
    {
      "epoch": 0.41422470043896076,
      "grad_norm": 0.016298916190862656,
      "learning_rate": 1.3017400474558398e-05,
      "loss": 0.0005,
      "step": 6983
    },
    {
      "epoch": 0.4142840194566378,
      "grad_norm": 0.029651399701833725,
      "learning_rate": 1.3016082256788822e-05,
      "loss": 0.0007,
      "step": 6984
    },
    {
      "epoch": 0.41434333847431487,
      "grad_norm": 5.012238025665283,
      "learning_rate": 1.3014764039019248e-05,
      "loss": 0.0592,
      "step": 6985
    },
    {
      "epoch": 0.41440265749199195,
      "grad_norm": 0.5661229491233826,
      "learning_rate": 1.301344582124967e-05,
      "loss": 0.0073,
      "step": 6986
    },
    {
      "epoch": 0.414461976509669,
      "grad_norm": 0.03231534734368324,
      "learning_rate": 1.3012127603480096e-05,
      "loss": 0.0008,
      "step": 6987
    },
    {
      "epoch": 0.41452129552734607,
      "grad_norm": 16.66648292541504,
      "learning_rate": 1.301080938571052e-05,
      "loss": 0.5136,
      "step": 6988
    },
    {
      "epoch": 0.41458061454502315,
      "grad_norm": 0.262048602104187,
      "learning_rate": 1.3009491167940945e-05,
      "loss": 0.0043,
      "step": 6989
    },
    {
      "epoch": 0.4146399335627002,
      "grad_norm": 12.213711738586426,
      "learning_rate": 1.3008172950171369e-05,
      "loss": 0.4567,
      "step": 6990
    },
    {
      "epoch": 0.41469925258037726,
      "grad_norm": 1.7753852605819702,
      "learning_rate": 1.3006854732401795e-05,
      "loss": 0.0158,
      "step": 6991
    },
    {
      "epoch": 0.41475857159805435,
      "grad_norm": 1.0278270244598389,
      "learning_rate": 1.3005536514632217e-05,
      "loss": 0.0137,
      "step": 6992
    },
    {
      "epoch": 0.4148178906157314,
      "grad_norm": 9.66521167755127,
      "learning_rate": 1.3004218296862643e-05,
      "loss": 0.3423,
      "step": 6993
    },
    {
      "epoch": 0.41487720963340846,
      "grad_norm": 3.154909372329712,
      "learning_rate": 1.3002900079093067e-05,
      "loss": 0.0547,
      "step": 6994
    },
    {
      "epoch": 0.41493652865108555,
      "grad_norm": 5.806154251098633,
      "learning_rate": 1.3001581861323492e-05,
      "loss": 0.0917,
      "step": 6995
    },
    {
      "epoch": 0.41499584766876263,
      "grad_norm": 4.577342987060547,
      "learning_rate": 1.3000263643553916e-05,
      "loss": 0.085,
      "step": 6996
    },
    {
      "epoch": 0.41505516668643966,
      "grad_norm": 5.141234874725342,
      "learning_rate": 1.2998945425784342e-05,
      "loss": 0.1223,
      "step": 6997
    },
    {
      "epoch": 0.41511448570411674,
      "grad_norm": 1.0633456707000732,
      "learning_rate": 1.2997627208014764e-05,
      "loss": 0.0183,
      "step": 6998
    },
    {
      "epoch": 0.4151738047217938,
      "grad_norm": 0.038728341460227966,
      "learning_rate": 1.299630899024519e-05,
      "loss": 0.0008,
      "step": 6999
    },
    {
      "epoch": 0.41523312373947086,
      "grad_norm": 0.030482487753033638,
      "learning_rate": 1.2994990772475612e-05,
      "loss": 0.0008,
      "step": 7000
    },
    {
      "epoch": 0.41529244275714794,
      "grad_norm": 0.028804151341319084,
      "learning_rate": 1.2993672554706038e-05,
      "loss": 0.0008,
      "step": 7001
    },
    {
      "epoch": 0.415351761774825,
      "grad_norm": 6.2814202308654785,
      "learning_rate": 1.2992354336936464e-05,
      "loss": 0.2159,
      "step": 7002
    },
    {
      "epoch": 0.41541108079250205,
      "grad_norm": 30.579509735107422,
      "learning_rate": 1.2991036119166887e-05,
      "loss": 0.317,
      "step": 7003
    },
    {
      "epoch": 0.41547039981017914,
      "grad_norm": 15.312661170959473,
      "learning_rate": 1.2989717901397313e-05,
      "loss": 1.0981,
      "step": 7004
    },
    {
      "epoch": 0.4155297188278562,
      "grad_norm": 13.25863265991211,
      "learning_rate": 1.2988399683627737e-05,
      "loss": 0.1222,
      "step": 7005
    },
    {
      "epoch": 0.4155890378455333,
      "grad_norm": 3.9529709815979004,
      "learning_rate": 1.298708146585816e-05,
      "loss": 0.0504,
      "step": 7006
    },
    {
      "epoch": 0.41564835686321033,
      "grad_norm": 4.289238929748535,
      "learning_rate": 1.2985763248088585e-05,
      "loss": 0.0899,
      "step": 7007
    },
    {
      "epoch": 0.4157076758808874,
      "grad_norm": 3.310328960418701,
      "learning_rate": 1.2984445030319011e-05,
      "loss": 0.033,
      "step": 7008
    },
    {
      "epoch": 0.4157669948985645,
      "grad_norm": 88.416015625,
      "learning_rate": 1.2983126812549434e-05,
      "loss": 0.2497,
      "step": 7009
    },
    {
      "epoch": 0.41582631391624153,
      "grad_norm": 2.416783332824707,
      "learning_rate": 1.298180859477986e-05,
      "loss": 0.0884,
      "step": 7010
    },
    {
      "epoch": 0.4158856329339186,
      "grad_norm": 6.732017993927002,
      "learning_rate": 1.2980490377010284e-05,
      "loss": 0.1335,
      "step": 7011
    },
    {
      "epoch": 0.4159449519515957,
      "grad_norm": 13.04374885559082,
      "learning_rate": 1.2979172159240708e-05,
      "loss": 0.4893,
      "step": 7012
    },
    {
      "epoch": 0.4160042709692727,
      "grad_norm": 0.9115605354309082,
      "learning_rate": 1.2977853941471132e-05,
      "loss": 0.0057,
      "step": 7013
    },
    {
      "epoch": 0.4160635899869498,
      "grad_norm": 0.03580283746123314,
      "learning_rate": 1.2976535723701556e-05,
      "loss": 0.0009,
      "step": 7014
    },
    {
      "epoch": 0.4161229090046269,
      "grad_norm": 0.24716602265834808,
      "learning_rate": 1.297521750593198e-05,
      "loss": 0.0056,
      "step": 7015
    },
    {
      "epoch": 0.4161822280223039,
      "grad_norm": 8.628365516662598,
      "learning_rate": 1.2973899288162406e-05,
      "loss": 0.5393,
      "step": 7016
    },
    {
      "epoch": 0.416241547039981,
      "grad_norm": 0.09413588792085648,
      "learning_rate": 1.2972581070392829e-05,
      "loss": 0.0019,
      "step": 7017
    },
    {
      "epoch": 0.4163008660576581,
      "grad_norm": 13.084493637084961,
      "learning_rate": 1.2971262852623255e-05,
      "loss": 0.0868,
      "step": 7018
    },
    {
      "epoch": 0.4163601850753352,
      "grad_norm": 0.9098148941993713,
      "learning_rate": 1.2969944634853679e-05,
      "loss": 0.01,
      "step": 7019
    },
    {
      "epoch": 0.4164195040930122,
      "grad_norm": 0.5924280881881714,
      "learning_rate": 1.2968626417084103e-05,
      "loss": 0.0088,
      "step": 7020
    },
    {
      "epoch": 0.4164788231106893,
      "grad_norm": 0.052334826439619064,
      "learning_rate": 1.2967308199314527e-05,
      "loss": 0.0012,
      "step": 7021
    },
    {
      "epoch": 0.4165381421283664,
      "grad_norm": 12.350850105285645,
      "learning_rate": 1.2965989981544953e-05,
      "loss": 0.199,
      "step": 7022
    },
    {
      "epoch": 0.4165974611460434,
      "grad_norm": 0.1535966694355011,
      "learning_rate": 1.2964671763775376e-05,
      "loss": 0.0029,
      "step": 7023
    },
    {
      "epoch": 0.4166567801637205,
      "grad_norm": 4.569777011871338,
      "learning_rate": 1.2963353546005801e-05,
      "loss": 0.3866,
      "step": 7024
    },
    {
      "epoch": 0.41671609918139757,
      "grad_norm": 0.045325879007577896,
      "learning_rate": 1.2962035328236227e-05,
      "loss": 0.0011,
      "step": 7025
    },
    {
      "epoch": 0.4167754181990746,
      "grad_norm": 7.8199543952941895,
      "learning_rate": 1.296071711046665e-05,
      "loss": 0.0584,
      "step": 7026
    },
    {
      "epoch": 0.4168347372167517,
      "grad_norm": 4.817275524139404,
      "learning_rate": 1.2959398892697076e-05,
      "loss": 0.0858,
      "step": 7027
    },
    {
      "epoch": 0.41689405623442877,
      "grad_norm": 3.876638412475586,
      "learning_rate": 1.29580806749275e-05,
      "loss": 0.1462,
      "step": 7028
    },
    {
      "epoch": 0.41695337525210585,
      "grad_norm": 1.305296778678894,
      "learning_rate": 1.2956762457157922e-05,
      "loss": 0.016,
      "step": 7029
    },
    {
      "epoch": 0.4170126942697829,
      "grad_norm": 1.310470700263977,
      "learning_rate": 1.2955444239388348e-05,
      "loss": 0.015,
      "step": 7030
    },
    {
      "epoch": 0.41707201328745996,
      "grad_norm": 15.290532112121582,
      "learning_rate": 1.295412602161877e-05,
      "loss": 0.2167,
      "step": 7031
    },
    {
      "epoch": 0.41713133230513705,
      "grad_norm": 0.34365731477737427,
      "learning_rate": 1.2952807803849197e-05,
      "loss": 0.0049,
      "step": 7032
    },
    {
      "epoch": 0.4171906513228141,
      "grad_norm": 4.202185153961182,
      "learning_rate": 1.2951489586079622e-05,
      "loss": 0.0139,
      "step": 7033
    },
    {
      "epoch": 0.41724997034049116,
      "grad_norm": 1.2431612014770508,
      "learning_rate": 1.2950171368310045e-05,
      "loss": 0.0116,
      "step": 7034
    },
    {
      "epoch": 0.41730928935816824,
      "grad_norm": 4.8744282722473145,
      "learning_rate": 1.2948853150540471e-05,
      "loss": 0.072,
      "step": 7035
    },
    {
      "epoch": 0.4173686083758453,
      "grad_norm": 10.474181175231934,
      "learning_rate": 1.2947534932770895e-05,
      "loss": 0.1027,
      "step": 7036
    },
    {
      "epoch": 0.41742792739352236,
      "grad_norm": 0.1714581996202469,
      "learning_rate": 1.294621671500132e-05,
      "loss": 0.0028,
      "step": 7037
    },
    {
      "epoch": 0.41748724641119944,
      "grad_norm": 4.6226677894592285,
      "learning_rate": 1.2944898497231743e-05,
      "loss": 0.2735,
      "step": 7038
    },
    {
      "epoch": 0.41754656542887647,
      "grad_norm": 9.424240112304688,
      "learning_rate": 1.294358027946217e-05,
      "loss": 0.053,
      "step": 7039
    },
    {
      "epoch": 0.41760588444655355,
      "grad_norm": 10.872245788574219,
      "learning_rate": 1.2942262061692592e-05,
      "loss": 0.1876,
      "step": 7040
    },
    {
      "epoch": 0.41766520346423064,
      "grad_norm": 14.548785209655762,
      "learning_rate": 1.2940943843923018e-05,
      "loss": 0.0194,
      "step": 7041
    },
    {
      "epoch": 0.4177245224819077,
      "grad_norm": 0.9423878788948059,
      "learning_rate": 1.2939625626153442e-05,
      "loss": 0.0173,
      "step": 7042
    },
    {
      "epoch": 0.41778384149958475,
      "grad_norm": 0.10172392427921295,
      "learning_rate": 1.2938307408383866e-05,
      "loss": 0.0017,
      "step": 7043
    },
    {
      "epoch": 0.41784316051726184,
      "grad_norm": 0.5442575216293335,
      "learning_rate": 1.293698919061429e-05,
      "loss": 0.0049,
      "step": 7044
    },
    {
      "epoch": 0.4179024795349389,
      "grad_norm": 0.3740116357803345,
      "learning_rate": 1.2935670972844716e-05,
      "loss": 0.005,
      "step": 7045
    },
    {
      "epoch": 0.41796179855261595,
      "grad_norm": 0.023228250443935394,
      "learning_rate": 1.2934352755075139e-05,
      "loss": 0.0005,
      "step": 7046
    },
    {
      "epoch": 0.41802111757029303,
      "grad_norm": 25.982885360717773,
      "learning_rate": 1.2933034537305565e-05,
      "loss": 2.5971,
      "step": 7047
    },
    {
      "epoch": 0.4180804365879701,
      "grad_norm": 0.635370135307312,
      "learning_rate": 1.2931716319535987e-05,
      "loss": 0.0095,
      "step": 7048
    },
    {
      "epoch": 0.41813975560564715,
      "grad_norm": 4.112022876739502,
      "learning_rate": 1.2930398101766413e-05,
      "loss": 0.0573,
      "step": 7049
    },
    {
      "epoch": 0.41819907462332423,
      "grad_norm": 10.467191696166992,
      "learning_rate": 1.2929079883996837e-05,
      "loss": 0.5627,
      "step": 7050
    },
    {
      "epoch": 0.4182583936410013,
      "grad_norm": 0.10658085346221924,
      "learning_rate": 1.2927761666227261e-05,
      "loss": 0.0011,
      "step": 7051
    },
    {
      "epoch": 0.4183177126586784,
      "grad_norm": 0.19515834748744965,
      "learning_rate": 1.2926443448457685e-05,
      "loss": 0.0033,
      "step": 7052
    },
    {
      "epoch": 0.4183770316763554,
      "grad_norm": 2.1039555072784424,
      "learning_rate": 1.2925125230688111e-05,
      "loss": 0.0299,
      "step": 7053
    },
    {
      "epoch": 0.4184363506940325,
      "grad_norm": 0.017256956547498703,
      "learning_rate": 1.2923807012918534e-05,
      "loss": 0.0006,
      "step": 7054
    },
    {
      "epoch": 0.4184956697117096,
      "grad_norm": 27.739299774169922,
      "learning_rate": 1.292248879514896e-05,
      "loss": 0.6111,
      "step": 7055
    },
    {
      "epoch": 0.4185549887293866,
      "grad_norm": 9.240989685058594,
      "learning_rate": 1.2921170577379386e-05,
      "loss": 0.8475,
      "step": 7056
    },
    {
      "epoch": 0.4186143077470637,
      "grad_norm": 0.08368942886590958,
      "learning_rate": 1.2919852359609808e-05,
      "loss": 0.0014,
      "step": 7057
    },
    {
      "epoch": 0.4186736267647408,
      "grad_norm": 0.08580823242664337,
      "learning_rate": 1.2918534141840234e-05,
      "loss": 0.0017,
      "step": 7058
    },
    {
      "epoch": 0.4187329457824178,
      "grad_norm": 0.039209287613630295,
      "learning_rate": 1.2917215924070658e-05,
      "loss": 0.0007,
      "step": 7059
    },
    {
      "epoch": 0.4187922648000949,
      "grad_norm": 20.989185333251953,
      "learning_rate": 1.2915897706301082e-05,
      "loss": 1.4997,
      "step": 7060
    },
    {
      "epoch": 0.418851583817772,
      "grad_norm": 14.396130561828613,
      "learning_rate": 1.2914579488531507e-05,
      "loss": 1.0868,
      "step": 7061
    },
    {
      "epoch": 0.4189109028354491,
      "grad_norm": 0.0717029720544815,
      "learning_rate": 1.2913261270761932e-05,
      "loss": 0.0019,
      "step": 7062
    },
    {
      "epoch": 0.4189702218531261,
      "grad_norm": 19.716419219970703,
      "learning_rate": 1.2911943052992355e-05,
      "loss": 0.1456,
      "step": 7063
    },
    {
      "epoch": 0.4190295408708032,
      "grad_norm": 5.36123514175415,
      "learning_rate": 1.291062483522278e-05,
      "loss": 0.2566,
      "step": 7064
    },
    {
      "epoch": 0.41908885988848027,
      "grad_norm": 11.723382949829102,
      "learning_rate": 1.2909306617453203e-05,
      "loss": 0.5645,
      "step": 7065
    },
    {
      "epoch": 0.4191481789061573,
      "grad_norm": 0.294781357049942,
      "learning_rate": 1.2907988399683629e-05,
      "loss": 0.0039,
      "step": 7066
    },
    {
      "epoch": 0.4192074979238344,
      "grad_norm": 5.115306377410889,
      "learning_rate": 1.2906670181914053e-05,
      "loss": 0.0261,
      "step": 7067
    },
    {
      "epoch": 0.41926681694151147,
      "grad_norm": 0.08785228431224823,
      "learning_rate": 1.2905351964144478e-05,
      "loss": 0.0016,
      "step": 7068
    },
    {
      "epoch": 0.4193261359591885,
      "grad_norm": 0.05924440920352936,
      "learning_rate": 1.2904033746374902e-05,
      "loss": 0.001,
      "step": 7069
    },
    {
      "epoch": 0.4193854549768656,
      "grad_norm": 0.13682377338409424,
      "learning_rate": 1.2902715528605328e-05,
      "loss": 0.0009,
      "step": 7070
    },
    {
      "epoch": 0.41944477399454266,
      "grad_norm": 2.465698480606079,
      "learning_rate": 1.290139731083575e-05,
      "loss": 0.0784,
      "step": 7071
    },
    {
      "epoch": 0.4195040930122197,
      "grad_norm": 17.87217140197754,
      "learning_rate": 1.2900079093066176e-05,
      "loss": 0.9848,
      "step": 7072
    },
    {
      "epoch": 0.4195634120298968,
      "grad_norm": 7.5907087326049805,
      "learning_rate": 1.28987608752966e-05,
      "loss": 0.0702,
      "step": 7073
    },
    {
      "epoch": 0.41962273104757386,
      "grad_norm": 4.196374416351318,
      "learning_rate": 1.2897442657527024e-05,
      "loss": 0.1636,
      "step": 7074
    },
    {
      "epoch": 0.41968205006525094,
      "grad_norm": 2.313281536102295,
      "learning_rate": 1.2896124439757449e-05,
      "loss": 0.03,
      "step": 7075
    },
    {
      "epoch": 0.419741369082928,
      "grad_norm": 1.0421775579452515,
      "learning_rate": 1.2894806221987874e-05,
      "loss": 0.0148,
      "step": 7076
    },
    {
      "epoch": 0.41980068810060506,
      "grad_norm": 1.0426567792892456,
      "learning_rate": 1.2893488004218297e-05,
      "loss": 0.015,
      "step": 7077
    },
    {
      "epoch": 0.41986000711828214,
      "grad_norm": 25.09276580810547,
      "learning_rate": 1.2892169786448723e-05,
      "loss": 2.0563,
      "step": 7078
    },
    {
      "epoch": 0.41991932613595917,
      "grad_norm": 7.930866718292236,
      "learning_rate": 1.2890851568679145e-05,
      "loss": 0.5469,
      "step": 7079
    },
    {
      "epoch": 0.41997864515363625,
      "grad_norm": 8.478837013244629,
      "learning_rate": 1.2889533350909571e-05,
      "loss": 0.1134,
      "step": 7080
    },
    {
      "epoch": 0.42003796417131334,
      "grad_norm": 0.13099202513694763,
      "learning_rate": 1.2888215133139997e-05,
      "loss": 0.0027,
      "step": 7081
    },
    {
      "epoch": 0.42009728318899037,
      "grad_norm": 0.0378778800368309,
      "learning_rate": 1.288689691537042e-05,
      "loss": 0.001,
      "step": 7082
    },
    {
      "epoch": 0.42015660220666745,
      "grad_norm": 3.011733293533325,
      "learning_rate": 1.2885578697600845e-05,
      "loss": 0.1747,
      "step": 7083
    },
    {
      "epoch": 0.42021592122434454,
      "grad_norm": 0.22473390400409698,
      "learning_rate": 1.288426047983127e-05,
      "loss": 0.0037,
      "step": 7084
    },
    {
      "epoch": 0.4202752402420216,
      "grad_norm": 0.03878143057227135,
      "learning_rate": 1.2882942262061692e-05,
      "loss": 0.0008,
      "step": 7085
    },
    {
      "epoch": 0.42033455925969865,
      "grad_norm": 0.19625982642173767,
      "learning_rate": 1.2881624044292118e-05,
      "loss": 0.0032,
      "step": 7086
    },
    {
      "epoch": 0.42039387827737573,
      "grad_norm": 2.517993927001953,
      "learning_rate": 1.2880305826522544e-05,
      "loss": 0.0323,
      "step": 7087
    },
    {
      "epoch": 0.4204531972950528,
      "grad_norm": 54.012451171875,
      "learning_rate": 1.2878987608752966e-05,
      "loss": 0.5404,
      "step": 7088
    },
    {
      "epoch": 0.42051251631272984,
      "grad_norm": 1.0740512609481812,
      "learning_rate": 1.2877669390983392e-05,
      "loss": 0.0095,
      "step": 7089
    },
    {
      "epoch": 0.42057183533040693,
      "grad_norm": 9.373897552490234,
      "learning_rate": 1.2876351173213816e-05,
      "loss": 0.25,
      "step": 7090
    },
    {
      "epoch": 0.420631154348084,
      "grad_norm": 2.226755380630493,
      "learning_rate": 1.287503295544424e-05,
      "loss": 0.0587,
      "step": 7091
    },
    {
      "epoch": 0.42069047336576104,
      "grad_norm": 32.618995666503906,
      "learning_rate": 1.2873714737674665e-05,
      "loss": 1.5569,
      "step": 7092
    },
    {
      "epoch": 0.4207497923834381,
      "grad_norm": 1.0248949527740479,
      "learning_rate": 1.287239651990509e-05,
      "loss": 0.0128,
      "step": 7093
    },
    {
      "epoch": 0.4208091114011152,
      "grad_norm": 4.771353721618652,
      "learning_rate": 1.2871078302135513e-05,
      "loss": 0.0362,
      "step": 7094
    },
    {
      "epoch": 0.42086843041879224,
      "grad_norm": 43.42305374145508,
      "learning_rate": 1.2869760084365939e-05,
      "loss": 0.2311,
      "step": 7095
    },
    {
      "epoch": 0.4209277494364693,
      "grad_norm": 0.2193610519170761,
      "learning_rate": 1.2868441866596362e-05,
      "loss": 0.0026,
      "step": 7096
    },
    {
      "epoch": 0.4209870684541464,
      "grad_norm": 0.05853673070669174,
      "learning_rate": 1.2867123648826787e-05,
      "loss": 0.0014,
      "step": 7097
    },
    {
      "epoch": 0.4210463874718235,
      "grad_norm": 13.091702461242676,
      "learning_rate": 1.2865805431057212e-05,
      "loss": 1.1507,
      "step": 7098
    },
    {
      "epoch": 0.4211057064895005,
      "grad_norm": 0.07564888894557953,
      "learning_rate": 1.2864487213287636e-05,
      "loss": 0.0015,
      "step": 7099
    },
    {
      "epoch": 0.4211650255071776,
      "grad_norm": 16.895442962646484,
      "learning_rate": 1.286316899551806e-05,
      "loss": 0.3498,
      "step": 7100
    },
    {
      "epoch": 0.4212243445248547,
      "grad_norm": 0.08482097834348679,
      "learning_rate": 1.2861850777748486e-05,
      "loss": 0.0012,
      "step": 7101
    },
    {
      "epoch": 0.4212836635425317,
      "grad_norm": 16.325963973999023,
      "learning_rate": 1.2860532559978908e-05,
      "loss": 0.1497,
      "step": 7102
    },
    {
      "epoch": 0.4213429825602088,
      "grad_norm": 9.021493911743164,
      "learning_rate": 1.2859214342209334e-05,
      "loss": 0.6525,
      "step": 7103
    },
    {
      "epoch": 0.4214023015778859,
      "grad_norm": 10.14946460723877,
      "learning_rate": 1.285789612443976e-05,
      "loss": 0.2562,
      "step": 7104
    },
    {
      "epoch": 0.4214616205955629,
      "grad_norm": 10.97758674621582,
      "learning_rate": 1.2856577906670183e-05,
      "loss": 0.5845,
      "step": 7105
    },
    {
      "epoch": 0.42152093961324,
      "grad_norm": 0.6592854261398315,
      "learning_rate": 1.2855259688900607e-05,
      "loss": 0.0108,
      "step": 7106
    },
    {
      "epoch": 0.4215802586309171,
      "grad_norm": 0.09239409118890762,
      "learning_rate": 1.2853941471131033e-05,
      "loss": 0.0015,
      "step": 7107
    },
    {
      "epoch": 0.42163957764859417,
      "grad_norm": 1.2505871057510376,
      "learning_rate": 1.2852623253361455e-05,
      "loss": 0.0166,
      "step": 7108
    },
    {
      "epoch": 0.4216988966662712,
      "grad_norm": 0.052281323820352554,
      "learning_rate": 1.2851305035591881e-05,
      "loss": 0.001,
      "step": 7109
    },
    {
      "epoch": 0.4217582156839483,
      "grad_norm": 6.943104267120361,
      "learning_rate": 1.2849986817822307e-05,
      "loss": 0.1591,
      "step": 7110
    },
    {
      "epoch": 0.42181753470162536,
      "grad_norm": 3.9895682334899902,
      "learning_rate": 1.284866860005273e-05,
      "loss": 0.0204,
      "step": 7111
    },
    {
      "epoch": 0.4218768537193024,
      "grad_norm": 7.955635070800781,
      "learning_rate": 1.2847350382283155e-05,
      "loss": 0.3136,
      "step": 7112
    },
    {
      "epoch": 0.4219361727369795,
      "grad_norm": 4.964093208312988,
      "learning_rate": 1.2846032164513578e-05,
      "loss": 0.0506,
      "step": 7113
    },
    {
      "epoch": 0.42199549175465656,
      "grad_norm": 3.2979767322540283,
      "learning_rate": 1.2844713946744004e-05,
      "loss": 0.1976,
      "step": 7114
    },
    {
      "epoch": 0.4220548107723336,
      "grad_norm": 26.9434814453125,
      "learning_rate": 1.2843395728974428e-05,
      "loss": 0.5686,
      "step": 7115
    },
    {
      "epoch": 0.4221141297900107,
      "grad_norm": 15.039905548095703,
      "learning_rate": 1.2842077511204852e-05,
      "loss": 0.3236,
      "step": 7116
    },
    {
      "epoch": 0.42217344880768776,
      "grad_norm": 33.264122009277344,
      "learning_rate": 1.2840759293435276e-05,
      "loss": 0.4124,
      "step": 7117
    },
    {
      "epoch": 0.4222327678253648,
      "grad_norm": 0.12390586733818054,
      "learning_rate": 1.2839441075665702e-05,
      "loss": 0.0026,
      "step": 7118
    },
    {
      "epoch": 0.42229208684304187,
      "grad_norm": 0.026590799912810326,
      "learning_rate": 1.2838122857896125e-05,
      "loss": 0.0007,
      "step": 7119
    },
    {
      "epoch": 0.42235140586071895,
      "grad_norm": 6.442625999450684,
      "learning_rate": 1.283680464012655e-05,
      "loss": 0.0675,
      "step": 7120
    },
    {
      "epoch": 0.42241072487839604,
      "grad_norm": 4.661133289337158,
      "learning_rate": 1.2835486422356975e-05,
      "loss": 0.1789,
      "step": 7121
    },
    {
      "epoch": 0.42247004389607307,
      "grad_norm": 19.11085319519043,
      "learning_rate": 1.2834168204587399e-05,
      "loss": 0.495,
      "step": 7122
    },
    {
      "epoch": 0.42252936291375015,
      "grad_norm": 0.29466480016708374,
      "learning_rate": 1.2832849986817823e-05,
      "loss": 0.0042,
      "step": 7123
    },
    {
      "epoch": 0.42258868193142723,
      "grad_norm": 0.2584262788295746,
      "learning_rate": 1.2831531769048249e-05,
      "loss": 0.004,
      "step": 7124
    },
    {
      "epoch": 0.42264800094910426,
      "grad_norm": 15.414454460144043,
      "learning_rate": 1.2830213551278671e-05,
      "loss": 0.3291,
      "step": 7125
    },
    {
      "epoch": 0.42270731996678135,
      "grad_norm": 2.5491182804107666,
      "learning_rate": 1.2828895333509097e-05,
      "loss": 0.0511,
      "step": 7126
    },
    {
      "epoch": 0.42276663898445843,
      "grad_norm": 6.6374664306640625,
      "learning_rate": 1.282757711573952e-05,
      "loss": 0.1343,
      "step": 7127
    },
    {
      "epoch": 0.42282595800213546,
      "grad_norm": 8.048317909240723,
      "learning_rate": 1.2826258897969946e-05,
      "loss": 0.1523,
      "step": 7128
    },
    {
      "epoch": 0.42288527701981254,
      "grad_norm": 3.4176340103149414,
      "learning_rate": 1.282494068020037e-05,
      "loss": 0.0704,
      "step": 7129
    },
    {
      "epoch": 0.42294459603748963,
      "grad_norm": 0.3292020261287689,
      "learning_rate": 1.2823622462430794e-05,
      "loss": 0.006,
      "step": 7130
    },
    {
      "epoch": 0.4230039150551667,
      "grad_norm": 0.4597044587135315,
      "learning_rate": 1.2822304244661218e-05,
      "loss": 0.0057,
      "step": 7131
    },
    {
      "epoch": 0.42306323407284374,
      "grad_norm": 6.237027168273926,
      "learning_rate": 1.2820986026891644e-05,
      "loss": 0.2561,
      "step": 7132
    },
    {
      "epoch": 0.4231225530905208,
      "grad_norm": 0.09187266230583191,
      "learning_rate": 1.2819667809122067e-05,
      "loss": 0.0015,
      "step": 7133
    },
    {
      "epoch": 0.4231818721081979,
      "grad_norm": 16.776607513427734,
      "learning_rate": 1.2818349591352493e-05,
      "loss": 0.2744,
      "step": 7134
    },
    {
      "epoch": 0.42324119112587494,
      "grad_norm": 6.607336521148682,
      "learning_rate": 1.2817031373582918e-05,
      "loss": 0.4903,
      "step": 7135
    },
    {
      "epoch": 0.423300510143552,
      "grad_norm": 0.023557066917419434,
      "learning_rate": 1.2815713155813341e-05,
      "loss": 0.0006,
      "step": 7136
    },
    {
      "epoch": 0.4233598291612291,
      "grad_norm": 0.03658053278923035,
      "learning_rate": 1.2814394938043767e-05,
      "loss": 0.0012,
      "step": 7137
    },
    {
      "epoch": 0.42341914817890614,
      "grad_norm": 0.4093868136405945,
      "learning_rate": 1.2813076720274191e-05,
      "loss": 0.0029,
      "step": 7138
    },
    {
      "epoch": 0.4234784671965832,
      "grad_norm": 0.07948984205722809,
      "learning_rate": 1.2811758502504613e-05,
      "loss": 0.0011,
      "step": 7139
    },
    {
      "epoch": 0.4235377862142603,
      "grad_norm": 8.334338188171387,
      "learning_rate": 1.281044028473504e-05,
      "loss": 0.1471,
      "step": 7140
    },
    {
      "epoch": 0.42359710523193733,
      "grad_norm": 8.273262977600098,
      "learning_rate": 1.2809122066965465e-05,
      "loss": 0.1182,
      "step": 7141
    },
    {
      "epoch": 0.4236564242496144,
      "grad_norm": 0.10503783822059631,
      "learning_rate": 1.2807803849195888e-05,
      "loss": 0.0018,
      "step": 7142
    },
    {
      "epoch": 0.4237157432672915,
      "grad_norm": 7.048295497894287,
      "learning_rate": 1.2806485631426314e-05,
      "loss": 0.1148,
      "step": 7143
    },
    {
      "epoch": 0.4237750622849686,
      "grad_norm": 0.05062943696975708,
      "learning_rate": 1.2805167413656736e-05,
      "loss": 0.001,
      "step": 7144
    },
    {
      "epoch": 0.4238343813026456,
      "grad_norm": 0.03619427606463432,
      "learning_rate": 1.2803849195887162e-05,
      "loss": 0.0008,
      "step": 7145
    },
    {
      "epoch": 0.4238937003203227,
      "grad_norm": 6.699947357177734,
      "learning_rate": 1.2802530978117586e-05,
      "loss": 0.1347,
      "step": 7146
    },
    {
      "epoch": 0.4239530193379998,
      "grad_norm": 1.066219449043274,
      "learning_rate": 1.280121276034801e-05,
      "loss": 0.0106,
      "step": 7147
    },
    {
      "epoch": 0.4240123383556768,
      "grad_norm": 0.02101188711822033,
      "learning_rate": 1.2799894542578435e-05,
      "loss": 0.0007,
      "step": 7148
    },
    {
      "epoch": 0.4240716573733539,
      "grad_norm": 2.735004186630249,
      "learning_rate": 1.279857632480886e-05,
      "loss": 0.0735,
      "step": 7149
    },
    {
      "epoch": 0.424130976391031,
      "grad_norm": 1.6097307205200195,
      "learning_rate": 1.2797258107039283e-05,
      "loss": 0.0415,
      "step": 7150
    },
    {
      "epoch": 0.424190295408708,
      "grad_norm": 21.93779754638672,
      "learning_rate": 1.2795939889269709e-05,
      "loss": 0.1827,
      "step": 7151
    },
    {
      "epoch": 0.4242496144263851,
      "grad_norm": 2.1157608032226562,
      "learning_rate": 1.2794621671500133e-05,
      "loss": 0.03,
      "step": 7152
    },
    {
      "epoch": 0.4243089334440622,
      "grad_norm": 25.727725982666016,
      "learning_rate": 1.2793303453730557e-05,
      "loss": 0.7209,
      "step": 7153
    },
    {
      "epoch": 0.42436825246173926,
      "grad_norm": 3.3160560131073,
      "learning_rate": 1.2791985235960981e-05,
      "loss": 0.046,
      "step": 7154
    },
    {
      "epoch": 0.4244275714794163,
      "grad_norm": 16.304899215698242,
      "learning_rate": 1.2790667018191407e-05,
      "loss": 0.6104,
      "step": 7155
    },
    {
      "epoch": 0.42448689049709337,
      "grad_norm": 0.13264591991901398,
      "learning_rate": 1.278934880042183e-05,
      "loss": 0.0022,
      "step": 7156
    },
    {
      "epoch": 0.42454620951477046,
      "grad_norm": 0.023374244570732117,
      "learning_rate": 1.2788030582652256e-05,
      "loss": 0.0009,
      "step": 7157
    },
    {
      "epoch": 0.4246055285324475,
      "grad_norm": 1.1028858423233032,
      "learning_rate": 1.2786712364882681e-05,
      "loss": 0.0166,
      "step": 7158
    },
    {
      "epoch": 0.42466484755012457,
      "grad_norm": 13.30310344696045,
      "learning_rate": 1.2785394147113104e-05,
      "loss": 0.5772,
      "step": 7159
    },
    {
      "epoch": 0.42472416656780165,
      "grad_norm": 6.920755863189697,
      "learning_rate": 1.278407592934353e-05,
      "loss": 0.1313,
      "step": 7160
    },
    {
      "epoch": 0.4247834855854787,
      "grad_norm": 0.03630650416016579,
      "learning_rate": 1.2782757711573952e-05,
      "loss": 0.0012,
      "step": 7161
    },
    {
      "epoch": 0.42484280460315577,
      "grad_norm": 1.8964416980743408,
      "learning_rate": 1.2781439493804377e-05,
      "loss": 0.0664,
      "step": 7162
    },
    {
      "epoch": 0.42490212362083285,
      "grad_norm": 0.056260112673044205,
      "learning_rate": 1.2780121276034802e-05,
      "loss": 0.0014,
      "step": 7163
    },
    {
      "epoch": 0.4249614426385099,
      "grad_norm": 19.00655174255371,
      "learning_rate": 1.2778803058265225e-05,
      "loss": 0.652,
      "step": 7164
    },
    {
      "epoch": 0.42502076165618696,
      "grad_norm": 0.10274172574281693,
      "learning_rate": 1.277748484049565e-05,
      "loss": 0.0028,
      "step": 7165
    },
    {
      "epoch": 0.42508008067386405,
      "grad_norm": 0.11991355568170547,
      "learning_rate": 1.2776166622726077e-05,
      "loss": 0.0014,
      "step": 7166
    },
    {
      "epoch": 0.42513939969154113,
      "grad_norm": 0.22137071192264557,
      "learning_rate": 1.2774848404956499e-05,
      "loss": 0.0028,
      "step": 7167
    },
    {
      "epoch": 0.42519871870921816,
      "grad_norm": 9.2271146774292,
      "learning_rate": 1.2773530187186925e-05,
      "loss": 0.4393,
      "step": 7168
    },
    {
      "epoch": 0.42525803772689524,
      "grad_norm": 0.3395271599292755,
      "learning_rate": 1.277221196941735e-05,
      "loss": 0.0035,
      "step": 7169
    },
    {
      "epoch": 0.42531735674457233,
      "grad_norm": 0.030192852020263672,
      "learning_rate": 1.2770893751647773e-05,
      "loss": 0.0006,
      "step": 7170
    },
    {
      "epoch": 0.42537667576224936,
      "grad_norm": 4.357998371124268,
      "learning_rate": 1.2769575533878198e-05,
      "loss": 0.1858,
      "step": 7171
    },
    {
      "epoch": 0.42543599477992644,
      "grad_norm": 0.09872838854789734,
      "learning_rate": 1.2768257316108623e-05,
      "loss": 0.0005,
      "step": 7172
    },
    {
      "epoch": 0.4254953137976035,
      "grad_norm": 3.327207326889038,
      "learning_rate": 1.2766939098339046e-05,
      "loss": 0.0535,
      "step": 7173
    },
    {
      "epoch": 0.42555463281528055,
      "grad_norm": 5.511017799377441,
      "learning_rate": 1.2765620880569472e-05,
      "loss": 0.0954,
      "step": 7174
    },
    {
      "epoch": 0.42561395183295764,
      "grad_norm": 8.322662353515625,
      "learning_rate": 1.2764302662799894e-05,
      "loss": 0.2285,
      "step": 7175
    },
    {
      "epoch": 0.4256732708506347,
      "grad_norm": 0.007585357408970594,
      "learning_rate": 1.276298444503032e-05,
      "loss": 0.0003,
      "step": 7176
    },
    {
      "epoch": 0.4257325898683118,
      "grad_norm": 0.7773216366767883,
      "learning_rate": 1.2761666227260744e-05,
      "loss": 0.0172,
      "step": 7177
    },
    {
      "epoch": 0.42579190888598883,
      "grad_norm": 0.07258325070142746,
      "learning_rate": 1.2760348009491169e-05,
      "loss": 0.0018,
      "step": 7178
    },
    {
      "epoch": 0.4258512279036659,
      "grad_norm": 15.14533805847168,
      "learning_rate": 1.2759029791721593e-05,
      "loss": 0.2877,
      "step": 7179
    },
    {
      "epoch": 0.425910546921343,
      "grad_norm": 0.04464205726981163,
      "learning_rate": 1.2757711573952019e-05,
      "loss": 0.0006,
      "step": 7180
    },
    {
      "epoch": 0.42596986593902003,
      "grad_norm": 4.8597259521484375,
      "learning_rate": 1.2756393356182441e-05,
      "loss": 0.037,
      "step": 7181
    },
    {
      "epoch": 0.4260291849566971,
      "grad_norm": 0.02215041033923626,
      "learning_rate": 1.2755075138412867e-05,
      "loss": 0.0006,
      "step": 7182
    },
    {
      "epoch": 0.4260885039743742,
      "grad_norm": 0.17568542063236237,
      "learning_rate": 1.2753756920643293e-05,
      "loss": 0.0029,
      "step": 7183
    },
    {
      "epoch": 0.42614782299205123,
      "grad_norm": 47.486141204833984,
      "learning_rate": 1.2752438702873715e-05,
      "loss": 0.0927,
      "step": 7184
    },
    {
      "epoch": 0.4262071420097283,
      "grad_norm": 0.4705125093460083,
      "learning_rate": 1.275112048510414e-05,
      "loss": 0.0062,
      "step": 7185
    },
    {
      "epoch": 0.4262664610274054,
      "grad_norm": 13.272769927978516,
      "learning_rate": 1.2749802267334565e-05,
      "loss": 0.488,
      "step": 7186
    },
    {
      "epoch": 0.4263257800450825,
      "grad_norm": 0.11036795377731323,
      "learning_rate": 1.2748484049564988e-05,
      "loss": 0.0014,
      "step": 7187
    },
    {
      "epoch": 0.4263850990627595,
      "grad_norm": 7.7520952224731445,
      "learning_rate": 1.2747165831795414e-05,
      "loss": 0.1517,
      "step": 7188
    },
    {
      "epoch": 0.4264444180804366,
      "grad_norm": 0.12154588103294373,
      "learning_rate": 1.274584761402584e-05,
      "loss": 0.0021,
      "step": 7189
    },
    {
      "epoch": 0.4265037370981137,
      "grad_norm": 7.592050075531006,
      "learning_rate": 1.2744529396256262e-05,
      "loss": 0.0303,
      "step": 7190
    },
    {
      "epoch": 0.4265630561157907,
      "grad_norm": 0.3248476982116699,
      "learning_rate": 1.2743211178486688e-05,
      "loss": 0.005,
      "step": 7191
    },
    {
      "epoch": 0.4266223751334678,
      "grad_norm": 13.466736793518066,
      "learning_rate": 1.274189296071711e-05,
      "loss": 0.3661,
      "step": 7192
    },
    {
      "epoch": 0.4266816941511449,
      "grad_norm": 10.467790603637695,
      "learning_rate": 1.2740574742947536e-05,
      "loss": 0.1666,
      "step": 7193
    },
    {
      "epoch": 0.4267410131688219,
      "grad_norm": 1.9657829999923706,
      "learning_rate": 1.273925652517796e-05,
      "loss": 0.0329,
      "step": 7194
    },
    {
      "epoch": 0.426800332186499,
      "grad_norm": 12.491140365600586,
      "learning_rate": 1.2737938307408383e-05,
      "loss": 0.0961,
      "step": 7195
    },
    {
      "epoch": 0.42685965120417607,
      "grad_norm": 4.985966682434082,
      "learning_rate": 1.2736620089638809e-05,
      "loss": 0.1338,
      "step": 7196
    },
    {
      "epoch": 0.4269189702218531,
      "grad_norm": 0.20452745258808136,
      "learning_rate": 1.2735301871869235e-05,
      "loss": 0.0024,
      "step": 7197
    },
    {
      "epoch": 0.4269782892395302,
      "grad_norm": 0.024390222504734993,
      "learning_rate": 1.2733983654099657e-05,
      "loss": 0.0007,
      "step": 7198
    },
    {
      "epoch": 0.42703760825720727,
      "grad_norm": 12.059127807617188,
      "learning_rate": 1.2732665436330083e-05,
      "loss": 0.0789,
      "step": 7199
    },
    {
      "epoch": 0.42709692727488435,
      "grad_norm": 1.5242836475372314,
      "learning_rate": 1.2731347218560507e-05,
      "loss": 0.0236,
      "step": 7200
    },
    {
      "epoch": 0.4271562462925614,
      "grad_norm": 24.01624298095703,
      "learning_rate": 1.2730029000790932e-05,
      "loss": 0.1653,
      "step": 7201
    },
    {
      "epoch": 0.42721556531023847,
      "grad_norm": 0.27492600679397583,
      "learning_rate": 1.2728710783021356e-05,
      "loss": 0.0027,
      "step": 7202
    },
    {
      "epoch": 0.42727488432791555,
      "grad_norm": 0.0855272188782692,
      "learning_rate": 1.2727392565251782e-05,
      "loss": 0.0014,
      "step": 7203
    },
    {
      "epoch": 0.4273342033455926,
      "grad_norm": 6.059290885925293,
      "learning_rate": 1.2726074347482204e-05,
      "loss": 0.3259,
      "step": 7204
    },
    {
      "epoch": 0.42739352236326966,
      "grad_norm": 5.1358842849731445,
      "learning_rate": 1.272475612971263e-05,
      "loss": 0.1003,
      "step": 7205
    },
    {
      "epoch": 0.42745284138094675,
      "grad_norm": 1.0155131816864014,
      "learning_rate": 1.2723437911943054e-05,
      "loss": 0.0143,
      "step": 7206
    },
    {
      "epoch": 0.4275121603986238,
      "grad_norm": 10.718687057495117,
      "learning_rate": 1.2722119694173478e-05,
      "loss": 0.3143,
      "step": 7207
    },
    {
      "epoch": 0.42757147941630086,
      "grad_norm": 7.979756832122803,
      "learning_rate": 1.2720801476403903e-05,
      "loss": 0.2103,
      "step": 7208
    },
    {
      "epoch": 0.42763079843397794,
      "grad_norm": 3.133090019226074,
      "learning_rate": 1.2719483258634327e-05,
      "loss": 0.0406,
      "step": 7209
    },
    {
      "epoch": 0.427690117451655,
      "grad_norm": 2.085573196411133,
      "learning_rate": 1.2718165040864751e-05,
      "loss": 0.0115,
      "step": 7210
    },
    {
      "epoch": 0.42774943646933206,
      "grad_norm": 0.34357893466949463,
      "learning_rate": 1.2716846823095177e-05,
      "loss": 0.0074,
      "step": 7211
    },
    {
      "epoch": 0.42780875548700914,
      "grad_norm": 27.608118057250977,
      "learning_rate": 1.27155286053256e-05,
      "loss": 0.2801,
      "step": 7212
    },
    {
      "epoch": 0.4278680745046862,
      "grad_norm": 13.205490112304688,
      "learning_rate": 1.2714210387556025e-05,
      "loss": 0.1283,
      "step": 7213
    },
    {
      "epoch": 0.42792739352236325,
      "grad_norm": 1.2988449335098267,
      "learning_rate": 1.2712892169786451e-05,
      "loss": 0.013,
      "step": 7214
    },
    {
      "epoch": 0.42798671254004034,
      "grad_norm": 3.586742401123047,
      "learning_rate": 1.2711573952016874e-05,
      "loss": 0.2772,
      "step": 7215
    },
    {
      "epoch": 0.4280460315577174,
      "grad_norm": 11.805771827697754,
      "learning_rate": 1.27102557342473e-05,
      "loss": 0.1574,
      "step": 7216
    },
    {
      "epoch": 0.42810535057539445,
      "grad_norm": 9.387850761413574,
      "learning_rate": 1.2708937516477724e-05,
      "loss": 0.4068,
      "step": 7217
    },
    {
      "epoch": 0.42816466959307153,
      "grad_norm": 0.019304750487208366,
      "learning_rate": 1.2707619298708146e-05,
      "loss": 0.0005,
      "step": 7218
    },
    {
      "epoch": 0.4282239886107486,
      "grad_norm": 4.708355903625488,
      "learning_rate": 1.2706301080938572e-05,
      "loss": 0.1433,
      "step": 7219
    },
    {
      "epoch": 0.42828330762842565,
      "grad_norm": 11.330889701843262,
      "learning_rate": 1.2704982863168998e-05,
      "loss": 0.3394,
      "step": 7220
    },
    {
      "epoch": 0.42834262664610273,
      "grad_norm": 3.033289670944214,
      "learning_rate": 1.270366464539942e-05,
      "loss": 0.0281,
      "step": 7221
    },
    {
      "epoch": 0.4284019456637798,
      "grad_norm": 2.6193697452545166,
      "learning_rate": 1.2702346427629846e-05,
      "loss": 0.0414,
      "step": 7222
    },
    {
      "epoch": 0.4284612646814569,
      "grad_norm": 0.015799591317772865,
      "learning_rate": 1.2701028209860269e-05,
      "loss": 0.0006,
      "step": 7223
    },
    {
      "epoch": 0.42852058369913393,
      "grad_norm": 1.2299443483352661,
      "learning_rate": 1.2699709992090695e-05,
      "loss": 0.0146,
      "step": 7224
    },
    {
      "epoch": 0.428579902716811,
      "grad_norm": 2.091160774230957,
      "learning_rate": 1.2698391774321119e-05,
      "loss": 0.0677,
      "step": 7225
    },
    {
      "epoch": 0.4286392217344881,
      "grad_norm": 8.585249900817871,
      "learning_rate": 1.2697073556551543e-05,
      "loss": 0.0587,
      "step": 7226
    },
    {
      "epoch": 0.4286985407521651,
      "grad_norm": 7.776392936706543,
      "learning_rate": 1.2695755338781967e-05,
      "loss": 0.0699,
      "step": 7227
    },
    {
      "epoch": 0.4287578597698422,
      "grad_norm": 0.31948888301849365,
      "learning_rate": 1.2694437121012393e-05,
      "loss": 0.0048,
      "step": 7228
    },
    {
      "epoch": 0.4288171787875193,
      "grad_norm": 8.185103416442871,
      "learning_rate": 1.2693118903242816e-05,
      "loss": 0.6884,
      "step": 7229
    },
    {
      "epoch": 0.4288764978051963,
      "grad_norm": 6.66724967956543,
      "learning_rate": 1.2691800685473242e-05,
      "loss": 0.3345,
      "step": 7230
    },
    {
      "epoch": 0.4289358168228734,
      "grad_norm": 1.4419711828231812,
      "learning_rate": 1.2690482467703666e-05,
      "loss": 0.0137,
      "step": 7231
    },
    {
      "epoch": 0.4289951358405505,
      "grad_norm": 0.006711720488965511,
      "learning_rate": 1.268916424993409e-05,
      "loss": 0.0002,
      "step": 7232
    },
    {
      "epoch": 0.4290544548582276,
      "grad_norm": 2.2136685848236084,
      "learning_rate": 1.2687846032164514e-05,
      "loss": 0.029,
      "step": 7233
    },
    {
      "epoch": 0.4291137738759046,
      "grad_norm": 0.06317708641290665,
      "learning_rate": 1.268652781439494e-05,
      "loss": 0.0016,
      "step": 7234
    },
    {
      "epoch": 0.4291730928935817,
      "grad_norm": 0.013262782245874405,
      "learning_rate": 1.2685209596625363e-05,
      "loss": 0.0003,
      "step": 7235
    },
    {
      "epoch": 0.42923241191125877,
      "grad_norm": 14.995903968811035,
      "learning_rate": 1.2683891378855788e-05,
      "loss": 0.5223,
      "step": 7236
    },
    {
      "epoch": 0.4292917309289358,
      "grad_norm": 2.156634569168091,
      "learning_rate": 1.2682573161086214e-05,
      "loss": 0.03,
      "step": 7237
    },
    {
      "epoch": 0.4293510499466129,
      "grad_norm": 12.282867431640625,
      "learning_rate": 1.2681254943316637e-05,
      "loss": 0.9547,
      "step": 7238
    },
    {
      "epoch": 0.42941036896428997,
      "grad_norm": 4.829378604888916,
      "learning_rate": 1.2679936725547061e-05,
      "loss": 0.0848,
      "step": 7239
    },
    {
      "epoch": 0.429469687981967,
      "grad_norm": 14.871376037597656,
      "learning_rate": 1.2678618507777485e-05,
      "loss": 1.4067,
      "step": 7240
    },
    {
      "epoch": 0.4295290069996441,
      "grad_norm": 0.04961828887462616,
      "learning_rate": 1.267730029000791e-05,
      "loss": 0.0018,
      "step": 7241
    },
    {
      "epoch": 0.42958832601732116,
      "grad_norm": 0.05618263781070709,
      "learning_rate": 1.2675982072238335e-05,
      "loss": 0.0009,
      "step": 7242
    },
    {
      "epoch": 0.4296476450349982,
      "grad_norm": 14.261157035827637,
      "learning_rate": 1.2674663854468758e-05,
      "loss": 0.2664,
      "step": 7243
    },
    {
      "epoch": 0.4297069640526753,
      "grad_norm": 14.940929412841797,
      "learning_rate": 1.2673345636699184e-05,
      "loss": 0.1626,
      "step": 7244
    },
    {
      "epoch": 0.42976628307035236,
      "grad_norm": 0.0904872715473175,
      "learning_rate": 1.267202741892961e-05,
      "loss": 0.0013,
      "step": 7245
    },
    {
      "epoch": 0.42982560208802945,
      "grad_norm": 2.0841281414031982,
      "learning_rate": 1.2670709201160032e-05,
      "loss": 0.0395,
      "step": 7246
    },
    {
      "epoch": 0.4298849211057065,
      "grad_norm": 0.028323329985141754,
      "learning_rate": 1.2669390983390458e-05,
      "loss": 0.001,
      "step": 7247
    },
    {
      "epoch": 0.42994424012338356,
      "grad_norm": 13.461371421813965,
      "learning_rate": 1.2668072765620882e-05,
      "loss": 0.2131,
      "step": 7248
    },
    {
      "epoch": 0.43000355914106064,
      "grad_norm": 6.533684253692627,
      "learning_rate": 1.2666754547851306e-05,
      "loss": 0.1739,
      "step": 7249
    },
    {
      "epoch": 0.43006287815873767,
      "grad_norm": 20.518274307250977,
      "learning_rate": 1.266543633008173e-05,
      "loss": 0.2796,
      "step": 7250
    },
    {
      "epoch": 0.43012219717641476,
      "grad_norm": 6.75977897644043,
      "learning_rate": 1.2664118112312156e-05,
      "loss": 0.342,
      "step": 7251
    },
    {
      "epoch": 0.43018151619409184,
      "grad_norm": 6.613142490386963,
      "learning_rate": 1.2662799894542579e-05,
      "loss": 0.1411,
      "step": 7252
    },
    {
      "epoch": 0.43024083521176887,
      "grad_norm": 0.8773506879806519,
      "learning_rate": 1.2661481676773005e-05,
      "loss": 0.0067,
      "step": 7253
    },
    {
      "epoch": 0.43030015422944595,
      "grad_norm": 0.12871523201465607,
      "learning_rate": 1.2660163459003429e-05,
      "loss": 0.0034,
      "step": 7254
    },
    {
      "epoch": 0.43035947324712304,
      "grad_norm": 70.01197052001953,
      "learning_rate": 1.2658845241233853e-05,
      "loss": 0.9505,
      "step": 7255
    },
    {
      "epoch": 0.4304187922648001,
      "grad_norm": 13.739667892456055,
      "learning_rate": 1.2657527023464277e-05,
      "loss": 0.6154,
      "step": 7256
    },
    {
      "epoch": 0.43047811128247715,
      "grad_norm": 1.5505725145339966,
      "learning_rate": 1.2656208805694701e-05,
      "loss": 0.0378,
      "step": 7257
    },
    {
      "epoch": 0.43053743030015423,
      "grad_norm": 1.2961360216140747,
      "learning_rate": 1.2654890587925126e-05,
      "loss": 0.0159,
      "step": 7258
    },
    {
      "epoch": 0.4305967493178313,
      "grad_norm": 0.14543938636779785,
      "learning_rate": 1.2653572370155551e-05,
      "loss": 0.0022,
      "step": 7259
    },
    {
      "epoch": 0.43065606833550835,
      "grad_norm": 0.1394212692975998,
      "learning_rate": 1.2652254152385974e-05,
      "loss": 0.0021,
      "step": 7260
    },
    {
      "epoch": 0.43071538735318543,
      "grad_norm": 0.2050998955965042,
      "learning_rate": 1.26509359346164e-05,
      "loss": 0.0028,
      "step": 7261
    },
    {
      "epoch": 0.4307747063708625,
      "grad_norm": 0.3676040768623352,
      "learning_rate": 1.2649617716846824e-05,
      "loss": 0.0045,
      "step": 7262
    },
    {
      "epoch": 0.43083402538853954,
      "grad_norm": 15.504542350769043,
      "learning_rate": 1.2648299499077248e-05,
      "loss": 0.6284,
      "step": 7263
    },
    {
      "epoch": 0.4308933444062166,
      "grad_norm": 8.562325477600098,
      "learning_rate": 1.2646981281307672e-05,
      "loss": 0.428,
      "step": 7264
    },
    {
      "epoch": 0.4309526634238937,
      "grad_norm": 11.259757995605469,
      "learning_rate": 1.2645663063538098e-05,
      "loss": 0.227,
      "step": 7265
    },
    {
      "epoch": 0.43101198244157074,
      "grad_norm": 4.356784820556641,
      "learning_rate": 1.264434484576852e-05,
      "loss": 0.3489,
      "step": 7266
    },
    {
      "epoch": 0.4310713014592478,
      "grad_norm": 8.93144702911377,
      "learning_rate": 1.2643026627998947e-05,
      "loss": 0.4418,
      "step": 7267
    },
    {
      "epoch": 0.4311306204769249,
      "grad_norm": 0.12516522407531738,
      "learning_rate": 1.2641708410229373e-05,
      "loss": 0.0022,
      "step": 7268
    },
    {
      "epoch": 0.431189939494602,
      "grad_norm": 0.994667112827301,
      "learning_rate": 1.2640390192459795e-05,
      "loss": 0.0152,
      "step": 7269
    },
    {
      "epoch": 0.431249258512279,
      "grad_norm": 9.58193588256836,
      "learning_rate": 1.2639071974690221e-05,
      "loss": 0.3328,
      "step": 7270
    },
    {
      "epoch": 0.4313085775299561,
      "grad_norm": 0.14233331382274628,
      "learning_rate": 1.2637753756920645e-05,
      "loss": 0.0018,
      "step": 7271
    },
    {
      "epoch": 0.4313678965476332,
      "grad_norm": 0.16886655986309052,
      "learning_rate": 1.263643553915107e-05,
      "loss": 0.0022,
      "step": 7272
    },
    {
      "epoch": 0.4314272155653102,
      "grad_norm": 17.921335220336914,
      "learning_rate": 1.2635117321381493e-05,
      "loss": 0.1741,
      "step": 7273
    },
    {
      "epoch": 0.4314865345829873,
      "grad_norm": 0.15692660212516785,
      "learning_rate": 1.2633799103611916e-05,
      "loss": 0.002,
      "step": 7274
    },
    {
      "epoch": 0.4315458536006644,
      "grad_norm": 0.036818213760852814,
      "learning_rate": 1.2632480885842342e-05,
      "loss": 0.0014,
      "step": 7275
    },
    {
      "epoch": 0.4316051726183414,
      "grad_norm": 1.0014326572418213,
      "learning_rate": 1.2631162668072768e-05,
      "loss": 0.0107,
      "step": 7276
    },
    {
      "epoch": 0.4316644916360185,
      "grad_norm": 0.0351937934756279,
      "learning_rate": 1.262984445030319e-05,
      "loss": 0.0012,
      "step": 7277
    },
    {
      "epoch": 0.4317238106536956,
      "grad_norm": 12.619989395141602,
      "learning_rate": 1.2628526232533616e-05,
      "loss": 0.1534,
      "step": 7278
    },
    {
      "epoch": 0.43178312967137267,
      "grad_norm": 0.036399029195308685,
      "learning_rate": 1.262720801476404e-05,
      "loss": 0.0011,
      "step": 7279
    },
    {
      "epoch": 0.4318424486890497,
      "grad_norm": 29.600704193115234,
      "learning_rate": 1.2625889796994464e-05,
      "loss": 0.5222,
      "step": 7280
    },
    {
      "epoch": 0.4319017677067268,
      "grad_norm": 4.839616775512695,
      "learning_rate": 1.2624571579224889e-05,
      "loss": 0.0883,
      "step": 7281
    },
    {
      "epoch": 0.43196108672440386,
      "grad_norm": 0.4628922939300537,
      "learning_rate": 1.2623253361455315e-05,
      "loss": 0.0036,
      "step": 7282
    },
    {
      "epoch": 0.4320204057420809,
      "grad_norm": 3.4241247177124023,
      "learning_rate": 1.2621935143685737e-05,
      "loss": 0.0424,
      "step": 7283
    },
    {
      "epoch": 0.432079724759758,
      "grad_norm": 2.3577842712402344,
      "learning_rate": 1.2620616925916163e-05,
      "loss": 0.0436,
      "step": 7284
    },
    {
      "epoch": 0.43213904377743506,
      "grad_norm": 1.0926156044006348,
      "learning_rate": 1.2619298708146587e-05,
      "loss": 0.0191,
      "step": 7285
    },
    {
      "epoch": 0.4321983627951121,
      "grad_norm": 16.955421447753906,
      "learning_rate": 1.2617980490377011e-05,
      "loss": 0.1281,
      "step": 7286
    },
    {
      "epoch": 0.4322576818127892,
      "grad_norm": 0.7375155091285706,
      "learning_rate": 1.2616662272607435e-05,
      "loss": 0.0097,
      "step": 7287
    },
    {
      "epoch": 0.43231700083046626,
      "grad_norm": 6.011630535125732,
      "learning_rate": 1.261534405483786e-05,
      "loss": 0.1355,
      "step": 7288
    },
    {
      "epoch": 0.43237631984814334,
      "grad_norm": 4.432865619659424,
      "learning_rate": 1.2614025837068284e-05,
      "loss": 0.628,
      "step": 7289
    },
    {
      "epoch": 0.43243563886582037,
      "grad_norm": 1.4882335662841797,
      "learning_rate": 1.261270761929871e-05,
      "loss": 0.0732,
      "step": 7290
    },
    {
      "epoch": 0.43249495788349746,
      "grad_norm": 5.821542263031006,
      "learning_rate": 1.2611389401529132e-05,
      "loss": 0.1231,
      "step": 7291
    },
    {
      "epoch": 0.43255427690117454,
      "grad_norm": 0.0054628727957606316,
      "learning_rate": 1.2610071183759558e-05,
      "loss": 0.0001,
      "step": 7292
    },
    {
      "epoch": 0.43261359591885157,
      "grad_norm": 0.050103623420000076,
      "learning_rate": 1.2608752965989984e-05,
      "loss": 0.0007,
      "step": 7293
    },
    {
      "epoch": 0.43267291493652865,
      "grad_norm": 2.3196871280670166,
      "learning_rate": 1.2607434748220406e-05,
      "loss": 0.0431,
      "step": 7294
    },
    {
      "epoch": 0.43273223395420574,
      "grad_norm": 5.100180625915527,
      "learning_rate": 1.260611653045083e-05,
      "loss": 0.0503,
      "step": 7295
    },
    {
      "epoch": 0.43279155297188276,
      "grad_norm": 0.30180293321609497,
      "learning_rate": 1.2604798312681257e-05,
      "loss": 0.0023,
      "step": 7296
    },
    {
      "epoch": 0.43285087198955985,
      "grad_norm": 1.0943151712417603,
      "learning_rate": 1.2603480094911679e-05,
      "loss": 0.0062,
      "step": 7297
    },
    {
      "epoch": 0.43291019100723693,
      "grad_norm": 2.1856689453125,
      "learning_rate": 1.2602161877142105e-05,
      "loss": 0.0335,
      "step": 7298
    },
    {
      "epoch": 0.43296951002491396,
      "grad_norm": 22.094919204711914,
      "learning_rate": 1.260084365937253e-05,
      "loss": 0.429,
      "step": 7299
    },
    {
      "epoch": 0.43302882904259105,
      "grad_norm": 64.88555145263672,
      "learning_rate": 1.2599525441602953e-05,
      "loss": 0.7866,
      "step": 7300
    },
    {
      "epoch": 0.43308814806026813,
      "grad_norm": 0.3155647814273834,
      "learning_rate": 1.259820722383338e-05,
      "loss": 0.0049,
      "step": 7301
    },
    {
      "epoch": 0.4331474670779452,
      "grad_norm": 10.459112167358398,
      "learning_rate": 1.2596889006063803e-05,
      "loss": 0.3006,
      "step": 7302
    },
    {
      "epoch": 0.43320678609562224,
      "grad_norm": 14.146334648132324,
      "learning_rate": 1.2595570788294228e-05,
      "loss": 0.2656,
      "step": 7303
    },
    {
      "epoch": 0.4332661051132993,
      "grad_norm": 8.979146957397461,
      "learning_rate": 1.2594252570524652e-05,
      "loss": 0.1113,
      "step": 7304
    },
    {
      "epoch": 0.4333254241309764,
      "grad_norm": 0.38789063692092896,
      "learning_rate": 1.2592934352755076e-05,
      "loss": 0.0068,
      "step": 7305
    },
    {
      "epoch": 0.43338474314865344,
      "grad_norm": 12.089627265930176,
      "learning_rate": 1.25916161349855e-05,
      "loss": 0.5319,
      "step": 7306
    },
    {
      "epoch": 0.4334440621663305,
      "grad_norm": 0.028402188792824745,
      "learning_rate": 1.2590297917215926e-05,
      "loss": 0.001,
      "step": 7307
    },
    {
      "epoch": 0.4335033811840076,
      "grad_norm": 0.0950942188501358,
      "learning_rate": 1.2588979699446348e-05,
      "loss": 0.0014,
      "step": 7308
    },
    {
      "epoch": 0.43356270020168464,
      "grad_norm": 0.0069990819320082664,
      "learning_rate": 1.2587661481676774e-05,
      "loss": 0.0002,
      "step": 7309
    },
    {
      "epoch": 0.4336220192193617,
      "grad_norm": 14.482083320617676,
      "learning_rate": 1.2586343263907199e-05,
      "loss": 0.3324,
      "step": 7310
    },
    {
      "epoch": 0.4336813382370388,
      "grad_norm": 0.14385712146759033,
      "learning_rate": 1.2585025046137623e-05,
      "loss": 0.0028,
      "step": 7311
    },
    {
      "epoch": 0.4337406572547159,
      "grad_norm": 6.020851135253906,
      "learning_rate": 1.2583706828368047e-05,
      "loss": 0.0726,
      "step": 7312
    },
    {
      "epoch": 0.4337999762723929,
      "grad_norm": 0.30981209874153137,
      "learning_rate": 1.2582388610598473e-05,
      "loss": 0.0045,
      "step": 7313
    },
    {
      "epoch": 0.43385929529007,
      "grad_norm": 0.03208562731742859,
      "learning_rate": 1.2581070392828895e-05,
      "loss": 0.0011,
      "step": 7314
    },
    {
      "epoch": 0.4339186143077471,
      "grad_norm": 0.7070516347885132,
      "learning_rate": 1.2579752175059321e-05,
      "loss": 0.0095,
      "step": 7315
    },
    {
      "epoch": 0.4339779333254241,
      "grad_norm": 17.23998260498047,
      "learning_rate": 1.2578433957289747e-05,
      "loss": 0.4988,
      "step": 7316
    },
    {
      "epoch": 0.4340372523431012,
      "grad_norm": 31.886425018310547,
      "learning_rate": 1.257711573952017e-05,
      "loss": 0.1765,
      "step": 7317
    },
    {
      "epoch": 0.4340965713607783,
      "grad_norm": 0.09134034067392349,
      "learning_rate": 1.2575797521750594e-05,
      "loss": 0.0018,
      "step": 7318
    },
    {
      "epoch": 0.4341558903784553,
      "grad_norm": 11.155119895935059,
      "learning_rate": 1.257447930398102e-05,
      "loss": 0.0954,
      "step": 7319
    },
    {
      "epoch": 0.4342152093961324,
      "grad_norm": 1.1468743085861206,
      "learning_rate": 1.2573161086211442e-05,
      "loss": 0.0087,
      "step": 7320
    },
    {
      "epoch": 0.4342745284138095,
      "grad_norm": 0.045488595962524414,
      "learning_rate": 1.2571842868441868e-05,
      "loss": 0.0008,
      "step": 7321
    },
    {
      "epoch": 0.4343338474314865,
      "grad_norm": 8.916999816894531,
      "learning_rate": 1.257052465067229e-05,
      "loss": 0.3846,
      "step": 7322
    },
    {
      "epoch": 0.4343931664491636,
      "grad_norm": 28.963685989379883,
      "learning_rate": 1.2569206432902716e-05,
      "loss": 1.0142,
      "step": 7323
    },
    {
      "epoch": 0.4344524854668407,
      "grad_norm": 16.872676849365234,
      "learning_rate": 1.2567888215133142e-05,
      "loss": 1.0683,
      "step": 7324
    },
    {
      "epoch": 0.43451180448451776,
      "grad_norm": 0.015022269450128078,
      "learning_rate": 1.2566569997363565e-05,
      "loss": 0.0006,
      "step": 7325
    },
    {
      "epoch": 0.4345711235021948,
      "grad_norm": 0.04218564182519913,
      "learning_rate": 1.256525177959399e-05,
      "loss": 0.0013,
      "step": 7326
    },
    {
      "epoch": 0.4346304425198719,
      "grad_norm": 15.798215866088867,
      "learning_rate": 1.2563933561824415e-05,
      "loss": 1.1041,
      "step": 7327
    },
    {
      "epoch": 0.43468976153754896,
      "grad_norm": 13.071224212646484,
      "learning_rate": 1.2562615344054839e-05,
      "loss": 0.307,
      "step": 7328
    },
    {
      "epoch": 0.434749080555226,
      "grad_norm": 11.18808650970459,
      "learning_rate": 1.2561297126285263e-05,
      "loss": 0.6454,
      "step": 7329
    },
    {
      "epoch": 0.43480839957290307,
      "grad_norm": 6.70203971862793,
      "learning_rate": 1.2559978908515689e-05,
      "loss": 0.0893,
      "step": 7330
    },
    {
      "epoch": 0.43486771859058015,
      "grad_norm": 0.3652748763561249,
      "learning_rate": 1.2558660690746112e-05,
      "loss": 0.0046,
      "step": 7331
    },
    {
      "epoch": 0.4349270376082572,
      "grad_norm": 9.142867088317871,
      "learning_rate": 1.2557342472976537e-05,
      "loss": 0.4552,
      "step": 7332
    },
    {
      "epoch": 0.43498635662593427,
      "grad_norm": 16.193523406982422,
      "learning_rate": 1.2556024255206962e-05,
      "loss": 0.6299,
      "step": 7333
    },
    {
      "epoch": 0.43504567564361135,
      "grad_norm": 0.013263997621834278,
      "learning_rate": 1.2554706037437386e-05,
      "loss": 0.0005,
      "step": 7334
    },
    {
      "epoch": 0.43510499466128844,
      "grad_norm": 0.0394023098051548,
      "learning_rate": 1.255338781966781e-05,
      "loss": 0.0008,
      "step": 7335
    },
    {
      "epoch": 0.43516431367896546,
      "grad_norm": 4.854032039642334,
      "learning_rate": 1.2552069601898234e-05,
      "loss": 0.117,
      "step": 7336
    },
    {
      "epoch": 0.43522363269664255,
      "grad_norm": 4.113559246063232,
      "learning_rate": 1.2550751384128658e-05,
      "loss": 0.0298,
      "step": 7337
    },
    {
      "epoch": 0.43528295171431963,
      "grad_norm": 0.6642777323722839,
      "learning_rate": 1.2549433166359084e-05,
      "loss": 0.0054,
      "step": 7338
    },
    {
      "epoch": 0.43534227073199666,
      "grad_norm": 5.535788059234619,
      "learning_rate": 1.2548114948589507e-05,
      "loss": 0.218,
      "step": 7339
    },
    {
      "epoch": 0.43540158974967375,
      "grad_norm": 0.3426387906074524,
      "learning_rate": 1.2546796730819933e-05,
      "loss": 0.0062,
      "step": 7340
    },
    {
      "epoch": 0.43546090876735083,
      "grad_norm": 0.1313527375459671,
      "learning_rate": 1.2545478513050357e-05,
      "loss": 0.0033,
      "step": 7341
    },
    {
      "epoch": 0.43552022778502786,
      "grad_norm": 13.272954940795898,
      "learning_rate": 1.2544160295280781e-05,
      "loss": 0.4237,
      "step": 7342
    },
    {
      "epoch": 0.43557954680270494,
      "grad_norm": 0.5409478545188904,
      "learning_rate": 1.2542842077511205e-05,
      "loss": 0.0078,
      "step": 7343
    },
    {
      "epoch": 0.435638865820382,
      "grad_norm": 42.64136505126953,
      "learning_rate": 1.2541523859741631e-05,
      "loss": 0.9352,
      "step": 7344
    },
    {
      "epoch": 0.43569818483805905,
      "grad_norm": 3.030766248703003,
      "learning_rate": 1.2540205641972054e-05,
      "loss": 0.0196,
      "step": 7345
    },
    {
      "epoch": 0.43575750385573614,
      "grad_norm": 8.43709659576416,
      "learning_rate": 1.253888742420248e-05,
      "loss": 0.0544,
      "step": 7346
    },
    {
      "epoch": 0.4358168228734132,
      "grad_norm": 1.2481540441513062,
      "learning_rate": 1.2537569206432905e-05,
      "loss": 0.0135,
      "step": 7347
    },
    {
      "epoch": 0.4358761418910903,
      "grad_norm": 0.34891238808631897,
      "learning_rate": 1.2536250988663328e-05,
      "loss": 0.006,
      "step": 7348
    },
    {
      "epoch": 0.43593546090876734,
      "grad_norm": 10.680989265441895,
      "learning_rate": 1.2534932770893754e-05,
      "loss": 0.7181,
      "step": 7349
    },
    {
      "epoch": 0.4359947799264444,
      "grad_norm": 0.053616706281900406,
      "learning_rate": 1.2533614553124178e-05,
      "loss": 0.0013,
      "step": 7350
    },
    {
      "epoch": 0.4360540989441215,
      "grad_norm": 6.649363994598389,
      "learning_rate": 1.25322963353546e-05,
      "loss": 0.0739,
      "step": 7351
    },
    {
      "epoch": 0.43611341796179853,
      "grad_norm": 0.010368790477514267,
      "learning_rate": 1.2530978117585026e-05,
      "loss": 0.0003,
      "step": 7352
    },
    {
      "epoch": 0.4361727369794756,
      "grad_norm": 0.688613772392273,
      "learning_rate": 1.2529659899815449e-05,
      "loss": 0.0098,
      "step": 7353
    },
    {
      "epoch": 0.4362320559971527,
      "grad_norm": 0.7580487728118896,
      "learning_rate": 1.2528341682045875e-05,
      "loss": 0.0103,
      "step": 7354
    },
    {
      "epoch": 0.43629137501482973,
      "grad_norm": 6.335393905639648,
      "learning_rate": 1.25270234642763e-05,
      "loss": 0.2428,
      "step": 7355
    },
    {
      "epoch": 0.4363506940325068,
      "grad_norm": 11.41384506225586,
      "learning_rate": 1.2525705246506723e-05,
      "loss": 0.4461,
      "step": 7356
    },
    {
      "epoch": 0.4364100130501839,
      "grad_norm": 6.0478434562683105,
      "learning_rate": 1.2524387028737149e-05,
      "loss": 0.2057,
      "step": 7357
    },
    {
      "epoch": 0.436469332067861,
      "grad_norm": 4.832099437713623,
      "learning_rate": 1.2523068810967573e-05,
      "loss": 0.088,
      "step": 7358
    },
    {
      "epoch": 0.436528651085538,
      "grad_norm": 0.04417785629630089,
      "learning_rate": 1.2521750593197997e-05,
      "loss": 0.0008,
      "step": 7359
    },
    {
      "epoch": 0.4365879701032151,
      "grad_norm": 1.43020761013031,
      "learning_rate": 1.2520432375428421e-05,
      "loss": 0.0092,
      "step": 7360
    },
    {
      "epoch": 0.4366472891208922,
      "grad_norm": 0.029946675524115562,
      "learning_rate": 1.2519114157658847e-05,
      "loss": 0.0005,
      "step": 7361
    },
    {
      "epoch": 0.4367066081385692,
      "grad_norm": 2.1549441814422607,
      "learning_rate": 1.251779593988927e-05,
      "loss": 0.0245,
      "step": 7362
    },
    {
      "epoch": 0.4367659271562463,
      "grad_norm": 0.034140605479478836,
      "learning_rate": 1.2516477722119696e-05,
      "loss": 0.0009,
      "step": 7363
    },
    {
      "epoch": 0.4368252461739234,
      "grad_norm": 0.03626787289977074,
      "learning_rate": 1.251515950435012e-05,
      "loss": 0.0005,
      "step": 7364
    },
    {
      "epoch": 0.4368845651916004,
      "grad_norm": 0.061270926147699356,
      "learning_rate": 1.2513841286580544e-05,
      "loss": 0.0014,
      "step": 7365
    },
    {
      "epoch": 0.4369438842092775,
      "grad_norm": 2.5850441455841064,
      "learning_rate": 1.2512523068810968e-05,
      "loss": 0.0303,
      "step": 7366
    },
    {
      "epoch": 0.4370032032269546,
      "grad_norm": 2.826402187347412,
      "learning_rate": 1.2511204851041394e-05,
      "loss": 0.2198,
      "step": 7367
    },
    {
      "epoch": 0.4370625222446316,
      "grad_norm": 0.007066535763442516,
      "learning_rate": 1.2509886633271817e-05,
      "loss": 0.0002,
      "step": 7368
    },
    {
      "epoch": 0.4371218412623087,
      "grad_norm": 0.20917007327079773,
      "learning_rate": 1.2508568415502243e-05,
      "loss": 0.0041,
      "step": 7369
    },
    {
      "epoch": 0.43718116027998577,
      "grad_norm": 1.0840473175048828,
      "learning_rate": 1.2507250197732665e-05,
      "loss": 0.0116,
      "step": 7370
    },
    {
      "epoch": 0.43724047929766285,
      "grad_norm": 0.4829402565956116,
      "learning_rate": 1.2505931979963091e-05,
      "loss": 0.0039,
      "step": 7371
    },
    {
      "epoch": 0.4372997983153399,
      "grad_norm": 11.737624168395996,
      "learning_rate": 1.2504613762193517e-05,
      "loss": 0.0991,
      "step": 7372
    },
    {
      "epoch": 0.43735911733301697,
      "grad_norm": 0.17529840767383575,
      "learning_rate": 1.250329554442394e-05,
      "loss": 0.0035,
      "step": 7373
    },
    {
      "epoch": 0.43741843635069405,
      "grad_norm": 0.5442265868186951,
      "learning_rate": 1.2501977326654363e-05,
      "loss": 0.0111,
      "step": 7374
    },
    {
      "epoch": 0.4374777553683711,
      "grad_norm": 5.55181360244751,
      "learning_rate": 1.250065910888479e-05,
      "loss": 0.1231,
      "step": 7375
    },
    {
      "epoch": 0.43753707438604816,
      "grad_norm": 3.9143478870391846,
      "learning_rate": 1.2499340891115212e-05,
      "loss": 0.0398,
      "step": 7376
    },
    {
      "epoch": 0.43759639340372525,
      "grad_norm": 14.282927513122559,
      "learning_rate": 1.2498022673345638e-05,
      "loss": 0.0996,
      "step": 7377
    },
    {
      "epoch": 0.4376557124214023,
      "grad_norm": 1.4918268918991089,
      "learning_rate": 1.2496704455576064e-05,
      "loss": 0.0136,
      "step": 7378
    },
    {
      "epoch": 0.43771503143907936,
      "grad_norm": 2.27815580368042,
      "learning_rate": 1.2495386237806486e-05,
      "loss": 0.0312,
      "step": 7379
    },
    {
      "epoch": 0.43777435045675644,
      "grad_norm": 0.0824694111943245,
      "learning_rate": 1.2494068020036912e-05,
      "loss": 0.0017,
      "step": 7380
    },
    {
      "epoch": 0.43783366947443353,
      "grad_norm": 26.831605911254883,
      "learning_rate": 1.2492749802267336e-05,
      "loss": 0.6439,
      "step": 7381
    },
    {
      "epoch": 0.43789298849211056,
      "grad_norm": 0.049779199063777924,
      "learning_rate": 1.249143158449776e-05,
      "loss": 0.0015,
      "step": 7382
    },
    {
      "epoch": 0.43795230750978764,
      "grad_norm": 1.6106135845184326,
      "learning_rate": 1.2490113366728185e-05,
      "loss": 0.0072,
      "step": 7383
    },
    {
      "epoch": 0.4380116265274647,
      "grad_norm": 9.987462043762207,
      "learning_rate": 1.2488795148958609e-05,
      "loss": 0.3793,
      "step": 7384
    },
    {
      "epoch": 0.43807094554514175,
      "grad_norm": 0.3435819149017334,
      "learning_rate": 1.2487476931189033e-05,
      "loss": 0.0044,
      "step": 7385
    },
    {
      "epoch": 0.43813026456281884,
      "grad_norm": 7.915467262268066,
      "learning_rate": 1.2486158713419459e-05,
      "loss": 0.112,
      "step": 7386
    },
    {
      "epoch": 0.4381895835804959,
      "grad_norm": 0.05956712365150452,
      "learning_rate": 1.2484840495649881e-05,
      "loss": 0.0014,
      "step": 7387
    },
    {
      "epoch": 0.43824890259817295,
      "grad_norm": 4.633886814117432,
      "learning_rate": 1.2483522277880307e-05,
      "loss": 0.3007,
      "step": 7388
    },
    {
      "epoch": 0.43830822161585004,
      "grad_norm": 8.795881271362305,
      "learning_rate": 1.2482204060110731e-05,
      "loss": 0.7489,
      "step": 7389
    },
    {
      "epoch": 0.4383675406335271,
      "grad_norm": 2.671661853790283,
      "learning_rate": 1.2480885842341156e-05,
      "loss": 0.0449,
      "step": 7390
    },
    {
      "epoch": 0.4384268596512042,
      "grad_norm": 4.877722263336182,
      "learning_rate": 1.247956762457158e-05,
      "loss": 0.0328,
      "step": 7391
    },
    {
      "epoch": 0.43848617866888123,
      "grad_norm": 12.734357833862305,
      "learning_rate": 1.2478249406802006e-05,
      "loss": 0.1723,
      "step": 7392
    },
    {
      "epoch": 0.4385454976865583,
      "grad_norm": 3.9249279499053955,
      "learning_rate": 1.2476931189032428e-05,
      "loss": 0.0317,
      "step": 7393
    },
    {
      "epoch": 0.4386048167042354,
      "grad_norm": 0.03309287503361702,
      "learning_rate": 1.2475612971262854e-05,
      "loss": 0.0007,
      "step": 7394
    },
    {
      "epoch": 0.43866413572191243,
      "grad_norm": 0.00861209537833929,
      "learning_rate": 1.2474294753493278e-05,
      "loss": 0.0002,
      "step": 7395
    },
    {
      "epoch": 0.4387234547395895,
      "grad_norm": 0.21045881509780884,
      "learning_rate": 1.2472976535723702e-05,
      "loss": 0.0019,
      "step": 7396
    },
    {
      "epoch": 0.4387827737572666,
      "grad_norm": 6.253778457641602,
      "learning_rate": 1.2471658317954127e-05,
      "loss": 0.0436,
      "step": 7397
    },
    {
      "epoch": 0.4388420927749436,
      "grad_norm": 0.5734153389930725,
      "learning_rate": 1.2470340100184552e-05,
      "loss": 0.0152,
      "step": 7398
    },
    {
      "epoch": 0.4389014117926207,
      "grad_norm": 20.814207077026367,
      "learning_rate": 1.2469021882414975e-05,
      "loss": 1.2948,
      "step": 7399
    },
    {
      "epoch": 0.4389607308102978,
      "grad_norm": 0.09164154529571533,
      "learning_rate": 1.24677036646454e-05,
      "loss": 0.0019,
      "step": 7400
    },
    {
      "epoch": 0.4390200498279748,
      "grad_norm": 0.009980672970414162,
      "learning_rate": 1.2466385446875823e-05,
      "loss": 0.0003,
      "step": 7401
    },
    {
      "epoch": 0.4390793688456519,
      "grad_norm": 0.7502416372299194,
      "learning_rate": 1.246506722910625e-05,
      "loss": 0.011,
      "step": 7402
    },
    {
      "epoch": 0.439138687863329,
      "grad_norm": 1.8003945350646973,
      "learning_rate": 1.2463749011336675e-05,
      "loss": 0.0031,
      "step": 7403
    },
    {
      "epoch": 0.4391980068810061,
      "grad_norm": 2.4771649837493896,
      "learning_rate": 1.2462430793567098e-05,
      "loss": 0.0362,
      "step": 7404
    },
    {
      "epoch": 0.4392573258986831,
      "grad_norm": 1.4855326414108276,
      "learning_rate": 1.2461112575797523e-05,
      "loss": 0.01,
      "step": 7405
    },
    {
      "epoch": 0.4393166449163602,
      "grad_norm": 0.2962048649787903,
      "learning_rate": 1.2459794358027948e-05,
      "loss": 0.0043,
      "step": 7406
    },
    {
      "epoch": 0.4393759639340373,
      "grad_norm": 8.14381217956543,
      "learning_rate": 1.245847614025837e-05,
      "loss": 0.1095,
      "step": 7407
    },
    {
      "epoch": 0.4394352829517143,
      "grad_norm": 22.5451717376709,
      "learning_rate": 1.2457157922488796e-05,
      "loss": 1.5094,
      "step": 7408
    },
    {
      "epoch": 0.4394946019693914,
      "grad_norm": 3.8291313648223877,
      "learning_rate": 1.2455839704719222e-05,
      "loss": 0.0763,
      "step": 7409
    },
    {
      "epoch": 0.43955392098706847,
      "grad_norm": 10.421272277832031,
      "learning_rate": 1.2454521486949644e-05,
      "loss": 0.2441,
      "step": 7410
    },
    {
      "epoch": 0.4396132400047455,
      "grad_norm": 27.221004486083984,
      "learning_rate": 1.245320326918007e-05,
      "loss": 0.7463,
      "step": 7411
    },
    {
      "epoch": 0.4396725590224226,
      "grad_norm": 0.4322124123573303,
      "learning_rate": 1.2451885051410494e-05,
      "loss": 0.0073,
      "step": 7412
    },
    {
      "epoch": 0.43973187804009967,
      "grad_norm": 17.214271545410156,
      "learning_rate": 1.2450566833640919e-05,
      "loss": 0.827,
      "step": 7413
    },
    {
      "epoch": 0.43979119705777675,
      "grad_norm": 6.904513359069824,
      "learning_rate": 1.2449248615871343e-05,
      "loss": 0.17,
      "step": 7414
    },
    {
      "epoch": 0.4398505160754538,
      "grad_norm": 8.130860328674316,
      "learning_rate": 1.2447930398101769e-05,
      "loss": 0.2526,
      "step": 7415
    },
    {
      "epoch": 0.43990983509313086,
      "grad_norm": 14.683372497558594,
      "learning_rate": 1.2446612180332191e-05,
      "loss": 0.4001,
      "step": 7416
    },
    {
      "epoch": 0.43996915411080795,
      "grad_norm": 22.627342224121094,
      "learning_rate": 1.2445293962562617e-05,
      "loss": 0.1605,
      "step": 7417
    },
    {
      "epoch": 0.440028473128485,
      "grad_norm": 2.3083279132843018,
      "learning_rate": 1.244397574479304e-05,
      "loss": 0.0193,
      "step": 7418
    },
    {
      "epoch": 0.44008779214616206,
      "grad_norm": 16.356903076171875,
      "learning_rate": 1.2442657527023465e-05,
      "loss": 0.4582,
      "step": 7419
    },
    {
      "epoch": 0.44014711116383914,
      "grad_norm": 0.14777417480945587,
      "learning_rate": 1.244133930925389e-05,
      "loss": 0.0029,
      "step": 7420
    },
    {
      "epoch": 0.4402064301815162,
      "grad_norm": 5.266023635864258,
      "learning_rate": 1.2440021091484314e-05,
      "loss": 0.0425,
      "step": 7421
    },
    {
      "epoch": 0.44026574919919326,
      "grad_norm": 22.409936904907227,
      "learning_rate": 1.2438702873714738e-05,
      "loss": 0.3278,
      "step": 7422
    },
    {
      "epoch": 0.44032506821687034,
      "grad_norm": 0.14881783723831177,
      "learning_rate": 1.2437384655945164e-05,
      "loss": 0.0017,
      "step": 7423
    },
    {
      "epoch": 0.44038438723454737,
      "grad_norm": 0.8637702465057373,
      "learning_rate": 1.2436066438175586e-05,
      "loss": 0.0058,
      "step": 7424
    },
    {
      "epoch": 0.44044370625222445,
      "grad_norm": 11.464213371276855,
      "learning_rate": 1.2434748220406012e-05,
      "loss": 0.2134,
      "step": 7425
    },
    {
      "epoch": 0.44050302526990154,
      "grad_norm": 10.191703796386719,
      "learning_rate": 1.2433430002636438e-05,
      "loss": 0.3323,
      "step": 7426
    },
    {
      "epoch": 0.4405623442875786,
      "grad_norm": 14.239789009094238,
      "learning_rate": 1.243211178486686e-05,
      "loss": 0.5986,
      "step": 7427
    },
    {
      "epoch": 0.44062166330525565,
      "grad_norm": 11.435586929321289,
      "learning_rate": 1.2430793567097287e-05,
      "loss": 0.5216,
      "step": 7428
    },
    {
      "epoch": 0.44068098232293273,
      "grad_norm": 0.05057261139154434,
      "learning_rate": 1.242947534932771e-05,
      "loss": 0.0011,
      "step": 7429
    },
    {
      "epoch": 0.4407403013406098,
      "grad_norm": 0.022399289533495903,
      "learning_rate": 1.2428157131558133e-05,
      "loss": 0.0006,
      "step": 7430
    },
    {
      "epoch": 0.44079962035828685,
      "grad_norm": 7.131928443908691,
      "learning_rate": 1.2426838913788559e-05,
      "loss": 0.3626,
      "step": 7431
    },
    {
      "epoch": 0.44085893937596393,
      "grad_norm": 1.0400396585464478,
      "learning_rate": 1.2425520696018982e-05,
      "loss": 0.0158,
      "step": 7432
    },
    {
      "epoch": 0.440918258393641,
      "grad_norm": 2.65124773979187,
      "learning_rate": 1.2424202478249407e-05,
      "loss": 0.0259,
      "step": 7433
    },
    {
      "epoch": 0.44097757741131804,
      "grad_norm": 14.9061918258667,
      "learning_rate": 1.2422884260479833e-05,
      "loss": 0.744,
      "step": 7434
    },
    {
      "epoch": 0.44103689642899513,
      "grad_norm": 7.89468240737915,
      "learning_rate": 1.2421566042710256e-05,
      "loss": 0.8109,
      "step": 7435
    },
    {
      "epoch": 0.4410962154466722,
      "grad_norm": 0.042641159147024155,
      "learning_rate": 1.2420247824940682e-05,
      "loss": 0.0005,
      "step": 7436
    },
    {
      "epoch": 0.4411555344643493,
      "grad_norm": 11.959212303161621,
      "learning_rate": 1.2418929607171106e-05,
      "loss": 0.4142,
      "step": 7437
    },
    {
      "epoch": 0.4412148534820263,
      "grad_norm": 4.240440845489502,
      "learning_rate": 1.241761138940153e-05,
      "loss": 0.0445,
      "step": 7438
    },
    {
      "epoch": 0.4412741724997034,
      "grad_norm": 10.445919036865234,
      "learning_rate": 1.2416293171631954e-05,
      "loss": 0.1397,
      "step": 7439
    },
    {
      "epoch": 0.4413334915173805,
      "grad_norm": 0.30477213859558105,
      "learning_rate": 1.241497495386238e-05,
      "loss": 0.0043,
      "step": 7440
    },
    {
      "epoch": 0.4413928105350575,
      "grad_norm": 0.20463210344314575,
      "learning_rate": 1.2413656736092803e-05,
      "loss": 0.0038,
      "step": 7441
    },
    {
      "epoch": 0.4414521295527346,
      "grad_norm": 0.027794137597084045,
      "learning_rate": 1.2412338518323229e-05,
      "loss": 0.0008,
      "step": 7442
    },
    {
      "epoch": 0.4415114485704117,
      "grad_norm": 4.1032328605651855,
      "learning_rate": 1.2411020300553653e-05,
      "loss": 0.0806,
      "step": 7443
    },
    {
      "epoch": 0.4415707675880887,
      "grad_norm": 15.281691551208496,
      "learning_rate": 1.2409702082784077e-05,
      "loss": 0.51,
      "step": 7444
    },
    {
      "epoch": 0.4416300866057658,
      "grad_norm": 2.323554515838623,
      "learning_rate": 1.2408383865014501e-05,
      "loss": 0.0203,
      "step": 7445
    },
    {
      "epoch": 0.4416894056234429,
      "grad_norm": 0.03281951695680618,
      "learning_rate": 1.2407065647244927e-05,
      "loss": 0.0007,
      "step": 7446
    },
    {
      "epoch": 0.4417487246411199,
      "grad_norm": 0.2935326099395752,
      "learning_rate": 1.240574742947535e-05,
      "loss": 0.0062,
      "step": 7447
    },
    {
      "epoch": 0.441808043658797,
      "grad_norm": 0.1362694948911667,
      "learning_rate": 1.2404429211705775e-05,
      "loss": 0.0024,
      "step": 7448
    },
    {
      "epoch": 0.4418673626764741,
      "grad_norm": 1.1677559614181519,
      "learning_rate": 1.2403110993936198e-05,
      "loss": 0.0065,
      "step": 7449
    },
    {
      "epoch": 0.44192668169415117,
      "grad_norm": 12.67115592956543,
      "learning_rate": 1.2401792776166624e-05,
      "loss": 0.2869,
      "step": 7450
    },
    {
      "epoch": 0.4419860007118282,
      "grad_norm": 13.2296142578125,
      "learning_rate": 1.2400474558397048e-05,
      "loss": 1.0347,
      "step": 7451
    },
    {
      "epoch": 0.4420453197295053,
      "grad_norm": 0.1452530324459076,
      "learning_rate": 1.2399156340627472e-05,
      "loss": 0.003,
      "step": 7452
    },
    {
      "epoch": 0.44210463874718237,
      "grad_norm": 0.2718069851398468,
      "learning_rate": 1.2397838122857896e-05,
      "loss": 0.0052,
      "step": 7453
    },
    {
      "epoch": 0.4421639577648594,
      "grad_norm": 5.619988918304443,
      "learning_rate": 1.2396519905088322e-05,
      "loss": 0.1958,
      "step": 7454
    },
    {
      "epoch": 0.4422232767825365,
      "grad_norm": 8.071632385253906,
      "learning_rate": 1.2395201687318745e-05,
      "loss": 0.0787,
      "step": 7455
    },
    {
      "epoch": 0.44228259580021356,
      "grad_norm": 2.230454921722412,
      "learning_rate": 1.239388346954917e-05,
      "loss": 0.0747,
      "step": 7456
    },
    {
      "epoch": 0.4423419148178906,
      "grad_norm": 0.6266900300979614,
      "learning_rate": 1.2392565251779596e-05,
      "loss": 0.0123,
      "step": 7457
    },
    {
      "epoch": 0.4424012338355677,
      "grad_norm": 0.0461265966296196,
      "learning_rate": 1.2391247034010019e-05,
      "loss": 0.001,
      "step": 7458
    },
    {
      "epoch": 0.44246055285324476,
      "grad_norm": 1.0574932098388672,
      "learning_rate": 1.2389928816240445e-05,
      "loss": 0.0248,
      "step": 7459
    },
    {
      "epoch": 0.44251987187092184,
      "grad_norm": 0.8480384349822998,
      "learning_rate": 1.2388610598470869e-05,
      "loss": 0.0173,
      "step": 7460
    },
    {
      "epoch": 0.4425791908885989,
      "grad_norm": 0.038198553025722504,
      "learning_rate": 1.2387292380701293e-05,
      "loss": 0.0006,
      "step": 7461
    },
    {
      "epoch": 0.44263850990627596,
      "grad_norm": 1.6041007041931152,
      "learning_rate": 1.2385974162931717e-05,
      "loss": 0.0196,
      "step": 7462
    },
    {
      "epoch": 0.44269782892395304,
      "grad_norm": 3.1760761737823486,
      "learning_rate": 1.2384655945162143e-05,
      "loss": 0.0301,
      "step": 7463
    },
    {
      "epoch": 0.44275714794163007,
      "grad_norm": 22.204320907592773,
      "learning_rate": 1.2383337727392566e-05,
      "loss": 0.7722,
      "step": 7464
    },
    {
      "epoch": 0.44281646695930715,
      "grad_norm": 0.7152690887451172,
      "learning_rate": 1.2382019509622992e-05,
      "loss": 0.013,
      "step": 7465
    },
    {
      "epoch": 0.44287578597698424,
      "grad_norm": 9.358878135681152,
      "learning_rate": 1.2380701291853414e-05,
      "loss": 0.0088,
      "step": 7466
    },
    {
      "epoch": 0.44293510499466127,
      "grad_norm": 0.04812091961503029,
      "learning_rate": 1.237938307408384e-05,
      "loss": 0.0014,
      "step": 7467
    },
    {
      "epoch": 0.44299442401233835,
      "grad_norm": 2.762284517288208,
      "learning_rate": 1.2378064856314264e-05,
      "loss": 0.0351,
      "step": 7468
    },
    {
      "epoch": 0.44305374303001543,
      "grad_norm": 0.02127673663198948,
      "learning_rate": 1.2376746638544688e-05,
      "loss": 0.0005,
      "step": 7469
    },
    {
      "epoch": 0.44311306204769246,
      "grad_norm": 0.1298772245645523,
      "learning_rate": 1.2375428420775113e-05,
      "loss": 0.0019,
      "step": 7470
    },
    {
      "epoch": 0.44317238106536955,
      "grad_norm": 0.339864045381546,
      "learning_rate": 1.2374110203005538e-05,
      "loss": 0.0024,
      "step": 7471
    },
    {
      "epoch": 0.44323170008304663,
      "grad_norm": 0.08562693744897842,
      "learning_rate": 1.2372791985235961e-05,
      "loss": 0.0023,
      "step": 7472
    },
    {
      "epoch": 0.4432910191007237,
      "grad_norm": 4.549990177154541,
      "learning_rate": 1.2371473767466387e-05,
      "loss": 0.0468,
      "step": 7473
    },
    {
      "epoch": 0.44335033811840074,
      "grad_norm": 0.08762476593255997,
      "learning_rate": 1.2370155549696811e-05,
      "loss": 0.002,
      "step": 7474
    },
    {
      "epoch": 0.44340965713607783,
      "grad_norm": 0.02424926497042179,
      "learning_rate": 1.2368837331927235e-05,
      "loss": 0.0007,
      "step": 7475
    },
    {
      "epoch": 0.4434689761537549,
      "grad_norm": 4.531181812286377,
      "learning_rate": 1.236751911415766e-05,
      "loss": 0.1334,
      "step": 7476
    },
    {
      "epoch": 0.44352829517143194,
      "grad_norm": 4.000734806060791,
      "learning_rate": 1.2366200896388085e-05,
      "loss": 0.0724,
      "step": 7477
    },
    {
      "epoch": 0.443587614189109,
      "grad_norm": 23.943588256835938,
      "learning_rate": 1.2364882678618508e-05,
      "loss": 0.5934,
      "step": 7478
    },
    {
      "epoch": 0.4436469332067861,
      "grad_norm": 0.2837679386138916,
      "learning_rate": 1.2363564460848934e-05,
      "loss": 0.0036,
      "step": 7479
    },
    {
      "epoch": 0.44370625222446314,
      "grad_norm": 0.024073360487818718,
      "learning_rate": 1.2362246243079356e-05,
      "loss": 0.0008,
      "step": 7480
    },
    {
      "epoch": 0.4437655712421402,
      "grad_norm": 0.3822809159755707,
      "learning_rate": 1.2360928025309782e-05,
      "loss": 0.0033,
      "step": 7481
    },
    {
      "epoch": 0.4438248902598173,
      "grad_norm": 0.08120737969875336,
      "learning_rate": 1.2359609807540208e-05,
      "loss": 0.0017,
      "step": 7482
    },
    {
      "epoch": 0.4438842092774944,
      "grad_norm": 7.385203838348389,
      "learning_rate": 1.235829158977063e-05,
      "loss": 0.116,
      "step": 7483
    },
    {
      "epoch": 0.4439435282951714,
      "grad_norm": 3.7370598316192627,
      "learning_rate": 1.2356973372001056e-05,
      "loss": 0.0556,
      "step": 7484
    },
    {
      "epoch": 0.4440028473128485,
      "grad_norm": 12.079875946044922,
      "learning_rate": 1.235565515423148e-05,
      "loss": 0.787,
      "step": 7485
    },
    {
      "epoch": 0.4440621663305256,
      "grad_norm": 0.3571954667568207,
      "learning_rate": 1.2354336936461903e-05,
      "loss": 0.0094,
      "step": 7486
    },
    {
      "epoch": 0.4441214853482026,
      "grad_norm": 0.06426295638084412,
      "learning_rate": 1.2353018718692329e-05,
      "loss": 0.0009,
      "step": 7487
    },
    {
      "epoch": 0.4441808043658797,
      "grad_norm": 0.9426748156547546,
      "learning_rate": 1.2351700500922755e-05,
      "loss": 0.0137,
      "step": 7488
    },
    {
      "epoch": 0.4442401233835568,
      "grad_norm": 7.237443447113037,
      "learning_rate": 1.2350382283153177e-05,
      "loss": 0.2621,
      "step": 7489
    },
    {
      "epoch": 0.4442994424012338,
      "grad_norm": 31.98073387145996,
      "learning_rate": 1.2349064065383603e-05,
      "loss": 0.1903,
      "step": 7490
    },
    {
      "epoch": 0.4443587614189109,
      "grad_norm": 0.4736093282699585,
      "learning_rate": 1.2347745847614027e-05,
      "loss": 0.0067,
      "step": 7491
    },
    {
      "epoch": 0.444418080436588,
      "grad_norm": 2.4382541179656982,
      "learning_rate": 1.2346427629844451e-05,
      "loss": 0.0289,
      "step": 7492
    },
    {
      "epoch": 0.444477399454265,
      "grad_norm": 11.774748802185059,
      "learning_rate": 1.2345109412074876e-05,
      "loss": 0.327,
      "step": 7493
    },
    {
      "epoch": 0.4445367184719421,
      "grad_norm": 0.015072808600962162,
      "learning_rate": 1.2343791194305301e-05,
      "loss": 0.0004,
      "step": 7494
    },
    {
      "epoch": 0.4445960374896192,
      "grad_norm": 0.032822370529174805,
      "learning_rate": 1.2342472976535724e-05,
      "loss": 0.0006,
      "step": 7495
    },
    {
      "epoch": 0.44465535650729626,
      "grad_norm": 0.09117437154054642,
      "learning_rate": 1.234115475876615e-05,
      "loss": 0.0021,
      "step": 7496
    },
    {
      "epoch": 0.4447146755249733,
      "grad_norm": 16.086265563964844,
      "learning_rate": 1.2339836540996572e-05,
      "loss": 0.8649,
      "step": 7497
    },
    {
      "epoch": 0.4447739945426504,
      "grad_norm": 0.11171502619981766,
      "learning_rate": 1.2338518323226998e-05,
      "loss": 0.0008,
      "step": 7498
    },
    {
      "epoch": 0.44483331356032746,
      "grad_norm": 10.669835090637207,
      "learning_rate": 1.2337200105457422e-05,
      "loss": 0.3095,
      "step": 7499
    },
    {
      "epoch": 0.4448926325780045,
      "grad_norm": 75.45497131347656,
      "learning_rate": 1.2335881887687847e-05,
      "loss": 0.5685,
      "step": 7500
    },
    {
      "epoch": 0.44495195159568157,
      "grad_norm": 0.08980756253004074,
      "learning_rate": 1.233456366991827e-05,
      "loss": 0.0017,
      "step": 7501
    },
    {
      "epoch": 0.44501127061335866,
      "grad_norm": 8.5043363571167,
      "learning_rate": 1.2333245452148697e-05,
      "loss": 0.2941,
      "step": 7502
    },
    {
      "epoch": 0.4450705896310357,
      "grad_norm": 8.276439666748047,
      "learning_rate": 1.233192723437912e-05,
      "loss": 0.2427,
      "step": 7503
    },
    {
      "epoch": 0.44512990864871277,
      "grad_norm": 0.657200276851654,
      "learning_rate": 1.2330609016609545e-05,
      "loss": 0.0101,
      "step": 7504
    },
    {
      "epoch": 0.44518922766638985,
      "grad_norm": 14.277363777160645,
      "learning_rate": 1.2329290798839971e-05,
      "loss": 0.6456,
      "step": 7505
    },
    {
      "epoch": 0.44524854668406694,
      "grad_norm": 14.91501235961914,
      "learning_rate": 1.2327972581070393e-05,
      "loss": 0.6187,
      "step": 7506
    },
    {
      "epoch": 0.44530786570174397,
      "grad_norm": 0.01021384634077549,
      "learning_rate": 1.2326654363300818e-05,
      "loss": 0.0003,
      "step": 7507
    },
    {
      "epoch": 0.44536718471942105,
      "grad_norm": 7.347465515136719,
      "learning_rate": 1.2325336145531244e-05,
      "loss": 0.0956,
      "step": 7508
    },
    {
      "epoch": 0.44542650373709813,
      "grad_norm": 1.155089020729065,
      "learning_rate": 1.2324017927761666e-05,
      "loss": 0.0193,
      "step": 7509
    },
    {
      "epoch": 0.44548582275477516,
      "grad_norm": 0.06992418318986893,
      "learning_rate": 1.2322699709992092e-05,
      "loss": 0.0008,
      "step": 7510
    },
    {
      "epoch": 0.44554514177245225,
      "grad_norm": 21.776809692382812,
      "learning_rate": 1.2321381492222518e-05,
      "loss": 0.7641,
      "step": 7511
    },
    {
      "epoch": 0.44560446079012933,
      "grad_norm": 0.009109907783567905,
      "learning_rate": 1.232006327445294e-05,
      "loss": 0.0003,
      "step": 7512
    },
    {
      "epoch": 0.44566377980780636,
      "grad_norm": 0.014677290804684162,
      "learning_rate": 1.2318745056683366e-05,
      "loss": 0.0004,
      "step": 7513
    },
    {
      "epoch": 0.44572309882548344,
      "grad_norm": 17.83187484741211,
      "learning_rate": 1.2317426838913789e-05,
      "loss": 0.6034,
      "step": 7514
    },
    {
      "epoch": 0.44578241784316053,
      "grad_norm": 4.093709468841553,
      "learning_rate": 1.2316108621144215e-05,
      "loss": 0.1584,
      "step": 7515
    },
    {
      "epoch": 0.4458417368608376,
      "grad_norm": 8.754609107971191,
      "learning_rate": 1.2314790403374639e-05,
      "loss": 0.2426,
      "step": 7516
    },
    {
      "epoch": 0.44590105587851464,
      "grad_norm": 0.013127467595040798,
      "learning_rate": 1.2313472185605063e-05,
      "loss": 0.0005,
      "step": 7517
    },
    {
      "epoch": 0.4459603748961917,
      "grad_norm": 1.8650821447372437,
      "learning_rate": 1.2312153967835487e-05,
      "loss": 0.0248,
      "step": 7518
    },
    {
      "epoch": 0.4460196939138688,
      "grad_norm": 0.07946411520242691,
      "learning_rate": 1.2310835750065913e-05,
      "loss": 0.0015,
      "step": 7519
    },
    {
      "epoch": 0.44607901293154584,
      "grad_norm": 11.822235107421875,
      "learning_rate": 1.2309517532296335e-05,
      "loss": 0.0514,
      "step": 7520
    },
    {
      "epoch": 0.4461383319492229,
      "grad_norm": 20.888444900512695,
      "learning_rate": 1.2308199314526761e-05,
      "loss": 0.1719,
      "step": 7521
    },
    {
      "epoch": 0.4461976509669,
      "grad_norm": 0.3883528411388397,
      "learning_rate": 1.2306881096757186e-05,
      "loss": 0.0054,
      "step": 7522
    },
    {
      "epoch": 0.44625696998457703,
      "grad_norm": 40.97043228149414,
      "learning_rate": 1.230556287898761e-05,
      "loss": 0.459,
      "step": 7523
    },
    {
      "epoch": 0.4463162890022541,
      "grad_norm": 0.6793896555900574,
      "learning_rate": 1.2304244661218034e-05,
      "loss": 0.0082,
      "step": 7524
    },
    {
      "epoch": 0.4463756080199312,
      "grad_norm": 0.04251953586935997,
      "learning_rate": 1.230292644344846e-05,
      "loss": 0.0006,
      "step": 7525
    },
    {
      "epoch": 0.44643492703760823,
      "grad_norm": 0.3369089663028717,
      "learning_rate": 1.2301608225678882e-05,
      "loss": 0.0061,
      "step": 7526
    },
    {
      "epoch": 0.4464942460552853,
      "grad_norm": 0.033089037984609604,
      "learning_rate": 1.2300290007909308e-05,
      "loss": 0.0009,
      "step": 7527
    },
    {
      "epoch": 0.4465535650729624,
      "grad_norm": 0.03942669555544853,
      "learning_rate": 1.2298971790139734e-05,
      "loss": 0.0008,
      "step": 7528
    },
    {
      "epoch": 0.4466128840906395,
      "grad_norm": 11.694964408874512,
      "learning_rate": 1.2297653572370157e-05,
      "loss": 0.7973,
      "step": 7529
    },
    {
      "epoch": 0.4466722031083165,
      "grad_norm": 0.048082444816827774,
      "learning_rate": 1.229633535460058e-05,
      "loss": 0.0017,
      "step": 7530
    },
    {
      "epoch": 0.4467315221259936,
      "grad_norm": 10.211755752563477,
      "learning_rate": 1.2295017136831005e-05,
      "loss": 0.4511,
      "step": 7531
    },
    {
      "epoch": 0.4467908411436707,
      "grad_norm": 1.0056182146072388,
      "learning_rate": 1.2293698919061429e-05,
      "loss": 0.0085,
      "step": 7532
    },
    {
      "epoch": 0.4468501601613477,
      "grad_norm": 4.375853061676025,
      "learning_rate": 1.2292380701291855e-05,
      "loss": 0.0425,
      "step": 7533
    },
    {
      "epoch": 0.4469094791790248,
      "grad_norm": 0.9430896639823914,
      "learning_rate": 1.2291062483522277e-05,
      "loss": 0.0101,
      "step": 7534
    },
    {
      "epoch": 0.4469687981967019,
      "grad_norm": 0.7165107131004333,
      "learning_rate": 1.2289744265752703e-05,
      "loss": 0.0116,
      "step": 7535
    },
    {
      "epoch": 0.4470281172143789,
      "grad_norm": 7.510099411010742,
      "learning_rate": 1.228842604798313e-05,
      "loss": 0.2754,
      "step": 7536
    },
    {
      "epoch": 0.447087436232056,
      "grad_norm": 3.551813840866089,
      "learning_rate": 1.2287107830213552e-05,
      "loss": 0.0339,
      "step": 7537
    },
    {
      "epoch": 0.4471467552497331,
      "grad_norm": 4.323081970214844,
      "learning_rate": 1.2285789612443978e-05,
      "loss": 0.0747,
      "step": 7538
    },
    {
      "epoch": 0.44720607426741016,
      "grad_norm": 1.2908258438110352,
      "learning_rate": 1.2284471394674402e-05,
      "loss": 0.0139,
      "step": 7539
    },
    {
      "epoch": 0.4472653932850872,
      "grad_norm": 0.025828460231423378,
      "learning_rate": 1.2283153176904826e-05,
      "loss": 0.0006,
      "step": 7540
    },
    {
      "epoch": 0.44732471230276427,
      "grad_norm": 0.928970456123352,
      "learning_rate": 1.228183495913525e-05,
      "loss": 0.0034,
      "step": 7541
    },
    {
      "epoch": 0.44738403132044136,
      "grad_norm": 3.8048815727233887,
      "learning_rate": 1.2280516741365676e-05,
      "loss": 0.3917,
      "step": 7542
    },
    {
      "epoch": 0.4474433503381184,
      "grad_norm": 0.00859290175139904,
      "learning_rate": 1.2279198523596099e-05,
      "loss": 0.0003,
      "step": 7543
    },
    {
      "epoch": 0.44750266935579547,
      "grad_norm": 0.06696286797523499,
      "learning_rate": 1.2277880305826524e-05,
      "loss": 0.0013,
      "step": 7544
    },
    {
      "epoch": 0.44756198837347255,
      "grad_norm": 26.713911056518555,
      "learning_rate": 1.2276562088056947e-05,
      "loss": 0.1995,
      "step": 7545
    },
    {
      "epoch": 0.4476213073911496,
      "grad_norm": 2.5583434104919434,
      "learning_rate": 1.2275243870287373e-05,
      "loss": 0.0244,
      "step": 7546
    },
    {
      "epoch": 0.44768062640882667,
      "grad_norm": 0.151903435587883,
      "learning_rate": 1.2273925652517797e-05,
      "loss": 0.0027,
      "step": 7547
    },
    {
      "epoch": 0.44773994542650375,
      "grad_norm": 0.5110072493553162,
      "learning_rate": 1.2272607434748221e-05,
      "loss": 0.0041,
      "step": 7548
    },
    {
      "epoch": 0.4477992644441808,
      "grad_norm": 11.707120895385742,
      "learning_rate": 1.2271289216978645e-05,
      "loss": 0.1769,
      "step": 7549
    },
    {
      "epoch": 0.44785858346185786,
      "grad_norm": 0.1062120869755745,
      "learning_rate": 1.2269970999209071e-05,
      "loss": 0.0012,
      "step": 7550
    },
    {
      "epoch": 0.44791790247953495,
      "grad_norm": 0.664919376373291,
      "learning_rate": 1.2268652781439494e-05,
      "loss": 0.004,
      "step": 7551
    },
    {
      "epoch": 0.44797722149721203,
      "grad_norm": 22.032684326171875,
      "learning_rate": 1.226733456366992e-05,
      "loss": 0.2584,
      "step": 7552
    },
    {
      "epoch": 0.44803654051488906,
      "grad_norm": 0.09985233843326569,
      "learning_rate": 1.2266016345900344e-05,
      "loss": 0.0013,
      "step": 7553
    },
    {
      "epoch": 0.44809585953256614,
      "grad_norm": 1.0113110542297363,
      "learning_rate": 1.2264698128130768e-05,
      "loss": 0.0049,
      "step": 7554
    },
    {
      "epoch": 0.4481551785502432,
      "grad_norm": 9.82304573059082,
      "learning_rate": 1.2263379910361192e-05,
      "loss": 0.1134,
      "step": 7555
    },
    {
      "epoch": 0.44821449756792026,
      "grad_norm": 0.33631691336631775,
      "learning_rate": 1.2262061692591618e-05,
      "loss": 0.0044,
      "step": 7556
    },
    {
      "epoch": 0.44827381658559734,
      "grad_norm": 38.41515350341797,
      "learning_rate": 1.226074347482204e-05,
      "loss": 0.9564,
      "step": 7557
    },
    {
      "epoch": 0.4483331356032744,
      "grad_norm": 4.048004150390625,
      "learning_rate": 1.2259425257052466e-05,
      "loss": 0.0546,
      "step": 7558
    },
    {
      "epoch": 0.44839245462095145,
      "grad_norm": 10.542078971862793,
      "learning_rate": 1.2258107039282892e-05,
      "loss": 0.0779,
      "step": 7559
    },
    {
      "epoch": 0.44845177363862854,
      "grad_norm": 2.6784608364105225,
      "learning_rate": 1.2256788821513315e-05,
      "loss": 0.13,
      "step": 7560
    },
    {
      "epoch": 0.4485110926563056,
      "grad_norm": 9.35299301147461,
      "learning_rate": 1.225547060374374e-05,
      "loss": 0.1349,
      "step": 7561
    },
    {
      "epoch": 0.4485704116739827,
      "grad_norm": 0.014062830246984959,
      "learning_rate": 1.2254152385974163e-05,
      "loss": 0.0004,
      "step": 7562
    },
    {
      "epoch": 0.44862973069165973,
      "grad_norm": 0.21857395768165588,
      "learning_rate": 1.2252834168204587e-05,
      "loss": 0.0024,
      "step": 7563
    },
    {
      "epoch": 0.4486890497093368,
      "grad_norm": 7.824548721313477,
      "learning_rate": 1.2251515950435013e-05,
      "loss": 0.0768,
      "step": 7564
    },
    {
      "epoch": 0.4487483687270139,
      "grad_norm": 2.821234703063965,
      "learning_rate": 1.2250197732665436e-05,
      "loss": 0.016,
      "step": 7565
    },
    {
      "epoch": 0.44880768774469093,
      "grad_norm": 15.165633201599121,
      "learning_rate": 1.2248879514895862e-05,
      "loss": 0.3367,
      "step": 7566
    },
    {
      "epoch": 0.448867006762368,
      "grad_norm": 16.895904541015625,
      "learning_rate": 1.2247561297126287e-05,
      "loss": 0.2175,
      "step": 7567
    },
    {
      "epoch": 0.4489263257800451,
      "grad_norm": 8.395105361938477,
      "learning_rate": 1.224624307935671e-05,
      "loss": 0.1501,
      "step": 7568
    },
    {
      "epoch": 0.4489856447977221,
      "grad_norm": 0.06841330975294113,
      "learning_rate": 1.2244924861587136e-05,
      "loss": 0.001,
      "step": 7569
    },
    {
      "epoch": 0.4490449638153992,
      "grad_norm": 0.04922223836183548,
      "learning_rate": 1.224360664381756e-05,
      "loss": 0.0008,
      "step": 7570
    },
    {
      "epoch": 0.4491042828330763,
      "grad_norm": 6.901581287384033,
      "learning_rate": 1.2242288426047984e-05,
      "loss": 0.0583,
      "step": 7571
    },
    {
      "epoch": 0.4491636018507533,
      "grad_norm": 0.0231326911598444,
      "learning_rate": 1.2240970208278408e-05,
      "loss": 0.0003,
      "step": 7572
    },
    {
      "epoch": 0.4492229208684304,
      "grad_norm": 6.403688430786133,
      "learning_rate": 1.2239651990508834e-05,
      "loss": 0.4713,
      "step": 7573
    },
    {
      "epoch": 0.4492822398861075,
      "grad_norm": 7.427799224853516,
      "learning_rate": 1.2238333772739257e-05,
      "loss": 0.2164,
      "step": 7574
    },
    {
      "epoch": 0.4493415589037846,
      "grad_norm": 0.016021082177758217,
      "learning_rate": 1.2237015554969683e-05,
      "loss": 0.0005,
      "step": 7575
    },
    {
      "epoch": 0.4494008779214616,
      "grad_norm": 0.013891423121094704,
      "learning_rate": 1.2235697337200107e-05,
      "loss": 0.0004,
      "step": 7576
    },
    {
      "epoch": 0.4494601969391387,
      "grad_norm": 2.0557572841644287,
      "learning_rate": 1.2234379119430531e-05,
      "loss": 0.028,
      "step": 7577
    },
    {
      "epoch": 0.4495195159568158,
      "grad_norm": 0.022527821362018585,
      "learning_rate": 1.2233060901660955e-05,
      "loss": 0.0004,
      "step": 7578
    },
    {
      "epoch": 0.4495788349744928,
      "grad_norm": 1.9011768102645874,
      "learning_rate": 1.223174268389138e-05,
      "loss": 0.0342,
      "step": 7579
    },
    {
      "epoch": 0.4496381539921699,
      "grad_norm": 4.337442398071289,
      "learning_rate": 1.2230424466121804e-05,
      "loss": 0.0847,
      "step": 7580
    },
    {
      "epoch": 0.44969747300984697,
      "grad_norm": 13.587510108947754,
      "learning_rate": 1.222910624835223e-05,
      "loss": 0.274,
      "step": 7581
    },
    {
      "epoch": 0.449756792027524,
      "grad_norm": 15.522912979125977,
      "learning_rate": 1.2227788030582652e-05,
      "loss": 0.2213,
      "step": 7582
    },
    {
      "epoch": 0.4498161110452011,
      "grad_norm": 9.125208854675293,
      "learning_rate": 1.2226469812813078e-05,
      "loss": 0.075,
      "step": 7583
    },
    {
      "epoch": 0.44987543006287817,
      "grad_norm": 17.872289657592773,
      "learning_rate": 1.2225151595043504e-05,
      "loss": 0.3864,
      "step": 7584
    },
    {
      "epoch": 0.44993474908055525,
      "grad_norm": 25.81981086730957,
      "learning_rate": 1.2223833377273926e-05,
      "loss": 0.4187,
      "step": 7585
    },
    {
      "epoch": 0.4499940680982323,
      "grad_norm": 22.124174118041992,
      "learning_rate": 1.222251515950435e-05,
      "loss": 0.7091,
      "step": 7586
    },
    {
      "epoch": 0.45005338711590936,
      "grad_norm": 15.496609687805176,
      "learning_rate": 1.2221196941734776e-05,
      "loss": 0.2278,
      "step": 7587
    },
    {
      "epoch": 0.45011270613358645,
      "grad_norm": 6.047239780426025,
      "learning_rate": 1.2219878723965199e-05,
      "loss": 0.0495,
      "step": 7588
    },
    {
      "epoch": 0.4501720251512635,
      "grad_norm": 4.984198570251465,
      "learning_rate": 1.2218560506195625e-05,
      "loss": 0.4261,
      "step": 7589
    },
    {
      "epoch": 0.45023134416894056,
      "grad_norm": 25.551021575927734,
      "learning_rate": 1.221724228842605e-05,
      "loss": 0.7163,
      "step": 7590
    },
    {
      "epoch": 0.45029066318661765,
      "grad_norm": 0.13996993005275726,
      "learning_rate": 1.2215924070656473e-05,
      "loss": 0.0027,
      "step": 7591
    },
    {
      "epoch": 0.4503499822042947,
      "grad_norm": 0.4026792347431183,
      "learning_rate": 1.2214605852886899e-05,
      "loss": 0.0061,
      "step": 7592
    },
    {
      "epoch": 0.45040930122197176,
      "grad_norm": 16.192928314208984,
      "learning_rate": 1.2213287635117321e-05,
      "loss": 0.7654,
      "step": 7593
    },
    {
      "epoch": 0.45046862023964884,
      "grad_norm": 9.110383033752441,
      "learning_rate": 1.2211969417347747e-05,
      "loss": 0.192,
      "step": 7594
    },
    {
      "epoch": 0.45052793925732587,
      "grad_norm": 2.3215456008911133,
      "learning_rate": 1.2210651199578171e-05,
      "loss": 0.0147,
      "step": 7595
    },
    {
      "epoch": 0.45058725827500296,
      "grad_norm": 11.583072662353516,
      "learning_rate": 1.2209332981808594e-05,
      "loss": 0.2693,
      "step": 7596
    },
    {
      "epoch": 0.45064657729268004,
      "grad_norm": 38.109195709228516,
      "learning_rate": 1.220801476403902e-05,
      "loss": 0.1028,
      "step": 7597
    },
    {
      "epoch": 0.4507058963103571,
      "grad_norm": 0.053414199501276016,
      "learning_rate": 1.2206696546269446e-05,
      "loss": 0.0009,
      "step": 7598
    },
    {
      "epoch": 0.45076521532803415,
      "grad_norm": 0.625333309173584,
      "learning_rate": 1.2205378328499868e-05,
      "loss": 0.0095,
      "step": 7599
    },
    {
      "epoch": 0.45082453434571124,
      "grad_norm": 1.692754864692688,
      "learning_rate": 1.2204060110730294e-05,
      "loss": 0.0207,
      "step": 7600
    },
    {
      "epoch": 0.4508838533633883,
      "grad_norm": 0.02296256646513939,
      "learning_rate": 1.2202741892960718e-05,
      "loss": 0.0005,
      "step": 7601
    },
    {
      "epoch": 0.45094317238106535,
      "grad_norm": 1.117540717124939,
      "learning_rate": 1.2201423675191143e-05,
      "loss": 0.0141,
      "step": 7602
    },
    {
      "epoch": 0.45100249139874243,
      "grad_norm": 0.3579956889152527,
      "learning_rate": 1.2200105457421567e-05,
      "loss": 0.0038,
      "step": 7603
    },
    {
      "epoch": 0.4510618104164195,
      "grad_norm": 2.970710515975952,
      "learning_rate": 1.2198787239651993e-05,
      "loss": 0.0617,
      "step": 7604
    },
    {
      "epoch": 0.45112112943409655,
      "grad_norm": 0.16044124960899353,
      "learning_rate": 1.2197469021882415e-05,
      "loss": 0.0031,
      "step": 7605
    },
    {
      "epoch": 0.45118044845177363,
      "grad_norm": 12.923182487487793,
      "learning_rate": 1.2196150804112841e-05,
      "loss": 0.8432,
      "step": 7606
    },
    {
      "epoch": 0.4512397674694507,
      "grad_norm": 18.648103713989258,
      "learning_rate": 1.2194832586343265e-05,
      "loss": 0.8833,
      "step": 7607
    },
    {
      "epoch": 0.4512990864871278,
      "grad_norm": 0.1620863378047943,
      "learning_rate": 1.219351436857369e-05,
      "loss": 0.0015,
      "step": 7608
    },
    {
      "epoch": 0.4513584055048048,
      "grad_norm": 0.06332211196422577,
      "learning_rate": 1.2192196150804114e-05,
      "loss": 0.0014,
      "step": 7609
    },
    {
      "epoch": 0.4514177245224819,
      "grad_norm": 6.446246147155762,
      "learning_rate": 1.2190877933034538e-05,
      "loss": 0.1128,
      "step": 7610
    },
    {
      "epoch": 0.451477043540159,
      "grad_norm": 4.953686714172363,
      "learning_rate": 1.2189559715264962e-05,
      "loss": 0.0833,
      "step": 7611
    },
    {
      "epoch": 0.451536362557836,
      "grad_norm": 4.3716630935668945,
      "learning_rate": 1.2188241497495388e-05,
      "loss": 0.063,
      "step": 7612
    },
    {
      "epoch": 0.4515956815755131,
      "grad_norm": 5.8242998123168945,
      "learning_rate": 1.218692327972581e-05,
      "loss": 0.1662,
      "step": 7613
    },
    {
      "epoch": 0.4516550005931902,
      "grad_norm": 0.010983404703438282,
      "learning_rate": 1.2185605061956236e-05,
      "loss": 0.0004,
      "step": 7614
    },
    {
      "epoch": 0.4517143196108672,
      "grad_norm": 1.763217568397522,
      "learning_rate": 1.2184286844186662e-05,
      "loss": 0.0102,
      "step": 7615
    },
    {
      "epoch": 0.4517736386285443,
      "grad_norm": 0.013909988105297089,
      "learning_rate": 1.2182968626417085e-05,
      "loss": 0.0005,
      "step": 7616
    },
    {
      "epoch": 0.4518329576462214,
      "grad_norm": 14.50387191772461,
      "learning_rate": 1.218165040864751e-05,
      "loss": 0.2163,
      "step": 7617
    },
    {
      "epoch": 0.4518922766638985,
      "grad_norm": 0.15481309592723846,
      "learning_rate": 1.2180332190877935e-05,
      "loss": 0.0015,
      "step": 7618
    },
    {
      "epoch": 0.4519515956815755,
      "grad_norm": 40.18976974487305,
      "learning_rate": 1.2179013973108357e-05,
      "loss": 0.8543,
      "step": 7619
    },
    {
      "epoch": 0.4520109146992526,
      "grad_norm": 28.066843032836914,
      "learning_rate": 1.2177695755338783e-05,
      "loss": 0.8282,
      "step": 7620
    },
    {
      "epoch": 0.45207023371692967,
      "grad_norm": 1.9279793500900269,
      "learning_rate": 1.2176377537569209e-05,
      "loss": 0.028,
      "step": 7621
    },
    {
      "epoch": 0.4521295527346067,
      "grad_norm": 0.011588544584810734,
      "learning_rate": 1.2175059319799631e-05,
      "loss": 0.0003,
      "step": 7622
    },
    {
      "epoch": 0.4521888717522838,
      "grad_norm": 4.952866077423096,
      "learning_rate": 1.2173741102030057e-05,
      "loss": 0.1146,
      "step": 7623
    },
    {
      "epoch": 0.45224819076996087,
      "grad_norm": 21.311426162719727,
      "learning_rate": 1.2172422884260481e-05,
      "loss": 0.3719,
      "step": 7624
    },
    {
      "epoch": 0.4523075097876379,
      "grad_norm": 4.406495571136475,
      "learning_rate": 1.2171104666490906e-05,
      "loss": 0.1698,
      "step": 7625
    },
    {
      "epoch": 0.452366828805315,
      "grad_norm": 0.26465630531311035,
      "learning_rate": 1.216978644872133e-05,
      "loss": 0.0046,
      "step": 7626
    },
    {
      "epoch": 0.45242614782299206,
      "grad_norm": 6.3651123046875,
      "learning_rate": 1.2168468230951754e-05,
      "loss": 0.1081,
      "step": 7627
    },
    {
      "epoch": 0.4524854668406691,
      "grad_norm": 0.6768677830696106,
      "learning_rate": 1.2167150013182178e-05,
      "loss": 0.0112,
      "step": 7628
    },
    {
      "epoch": 0.4525447858583462,
      "grad_norm": 0.20776642858982086,
      "learning_rate": 1.2165831795412604e-05,
      "loss": 0.0054,
      "step": 7629
    },
    {
      "epoch": 0.45260410487602326,
      "grad_norm": 0.4309746325016022,
      "learning_rate": 1.2164513577643027e-05,
      "loss": 0.008,
      "step": 7630
    },
    {
      "epoch": 0.45266342389370035,
      "grad_norm": 2.2175562381744385,
      "learning_rate": 1.2163195359873452e-05,
      "loss": 0.0457,
      "step": 7631
    },
    {
      "epoch": 0.4527227429113774,
      "grad_norm": 2.261199951171875,
      "learning_rate": 1.2161877142103877e-05,
      "loss": 0.0412,
      "step": 7632
    },
    {
      "epoch": 0.45278206192905446,
      "grad_norm": 0.7415763139724731,
      "learning_rate": 1.21605589243343e-05,
      "loss": 0.0074,
      "step": 7633
    },
    {
      "epoch": 0.45284138094673154,
      "grad_norm": 8.632431983947754,
      "learning_rate": 1.2159240706564725e-05,
      "loss": 0.2841,
      "step": 7634
    },
    {
      "epoch": 0.45290069996440857,
      "grad_norm": 4.3567328453063965,
      "learning_rate": 1.215792248879515e-05,
      "loss": 0.0701,
      "step": 7635
    },
    {
      "epoch": 0.45296001898208565,
      "grad_norm": 0.566556453704834,
      "learning_rate": 1.2156604271025573e-05,
      "loss": 0.0037,
      "step": 7636
    },
    {
      "epoch": 0.45301933799976274,
      "grad_norm": 20.878620147705078,
      "learning_rate": 1.2155286053256e-05,
      "loss": 0.495,
      "step": 7637
    },
    {
      "epoch": 0.45307865701743977,
      "grad_norm": 0.01863935776054859,
      "learning_rate": 1.2153967835486425e-05,
      "loss": 0.0004,
      "step": 7638
    },
    {
      "epoch": 0.45313797603511685,
      "grad_norm": 0.6844785213470459,
      "learning_rate": 1.2152649617716848e-05,
      "loss": 0.0133,
      "step": 7639
    },
    {
      "epoch": 0.45319729505279394,
      "grad_norm": 2.863218069076538,
      "learning_rate": 1.2151331399947272e-05,
      "loss": 0.0601,
      "step": 7640
    },
    {
      "epoch": 0.453256614070471,
      "grad_norm": 0.011256953701376915,
      "learning_rate": 1.2150013182177696e-05,
      "loss": 0.0004,
      "step": 7641
    },
    {
      "epoch": 0.45331593308814805,
      "grad_norm": 0.012486848048865795,
      "learning_rate": 1.214869496440812e-05,
      "loss": 0.0005,
      "step": 7642
    },
    {
      "epoch": 0.45337525210582513,
      "grad_norm": 6.084192752838135,
      "learning_rate": 1.2147376746638546e-05,
      "loss": 0.2403,
      "step": 7643
    },
    {
      "epoch": 0.4534345711235022,
      "grad_norm": 0.6466208696365356,
      "learning_rate": 1.2146058528868969e-05,
      "loss": 0.0028,
      "step": 7644
    },
    {
      "epoch": 0.45349389014117925,
      "grad_norm": 56.7216682434082,
      "learning_rate": 1.2144740311099394e-05,
      "loss": 0.8666,
      "step": 7645
    },
    {
      "epoch": 0.45355320915885633,
      "grad_norm": 33.70406723022461,
      "learning_rate": 1.214342209332982e-05,
      "loss": 0.3267,
      "step": 7646
    },
    {
      "epoch": 0.4536125281765334,
      "grad_norm": 5.425261497497559,
      "learning_rate": 1.2142103875560243e-05,
      "loss": 0.0893,
      "step": 7647
    },
    {
      "epoch": 0.45367184719421044,
      "grad_norm": 5.788773059844971,
      "learning_rate": 1.2140785657790669e-05,
      "loss": 0.0478,
      "step": 7648
    },
    {
      "epoch": 0.4537311662118875,
      "grad_norm": 0.42422768473625183,
      "learning_rate": 1.2139467440021093e-05,
      "loss": 0.0089,
      "step": 7649
    },
    {
      "epoch": 0.4537904852295646,
      "grad_norm": 20.783620834350586,
      "learning_rate": 1.2138149222251517e-05,
      "loss": 1.3057,
      "step": 7650
    },
    {
      "epoch": 0.45384980424724164,
      "grad_norm": 0.1546955108642578,
      "learning_rate": 1.2136831004481941e-05,
      "loss": 0.0017,
      "step": 7651
    },
    {
      "epoch": 0.4539091232649187,
      "grad_norm": 0.13962092995643616,
      "learning_rate": 1.2135512786712367e-05,
      "loss": 0.001,
      "step": 7652
    },
    {
      "epoch": 0.4539684422825958,
      "grad_norm": 0.05072988197207451,
      "learning_rate": 1.213419456894279e-05,
      "loss": 0.001,
      "step": 7653
    },
    {
      "epoch": 0.4540277613002729,
      "grad_norm": 6.266993999481201,
      "learning_rate": 1.2132876351173215e-05,
      "loss": 0.137,
      "step": 7654
    },
    {
      "epoch": 0.4540870803179499,
      "grad_norm": 14.300202369689941,
      "learning_rate": 1.213155813340364e-05,
      "loss": 0.3778,
      "step": 7655
    },
    {
      "epoch": 0.454146399335627,
      "grad_norm": 0.920016348361969,
      "learning_rate": 1.2130239915634064e-05,
      "loss": 0.0057,
      "step": 7656
    },
    {
      "epoch": 0.4542057183533041,
      "grad_norm": 16.67490577697754,
      "learning_rate": 1.2128921697864488e-05,
      "loss": 0.5905,
      "step": 7657
    },
    {
      "epoch": 0.4542650373709811,
      "grad_norm": 0.15294893085956573,
      "learning_rate": 1.2127603480094912e-05,
      "loss": 0.0018,
      "step": 7658
    },
    {
      "epoch": 0.4543243563886582,
      "grad_norm": 0.002836322644725442,
      "learning_rate": 1.2126285262325336e-05,
      "loss": 0.0001,
      "step": 7659
    },
    {
      "epoch": 0.4543836754063353,
      "grad_norm": 0.400007963180542,
      "learning_rate": 1.2124967044555762e-05,
      "loss": 0.0057,
      "step": 7660
    },
    {
      "epoch": 0.4544429944240123,
      "grad_norm": 0.359744668006897,
      "learning_rate": 1.2123648826786185e-05,
      "loss": 0.0038,
      "step": 7661
    },
    {
      "epoch": 0.4545023134416894,
      "grad_norm": 14.824085235595703,
      "learning_rate": 1.212233060901661e-05,
      "loss": 0.1247,
      "step": 7662
    },
    {
      "epoch": 0.4545616324593665,
      "grad_norm": 3.6462714672088623,
      "learning_rate": 1.2121012391247035e-05,
      "loss": 0.0366,
      "step": 7663
    },
    {
      "epoch": 0.45462095147704357,
      "grad_norm": 14.6859130859375,
      "learning_rate": 1.2119694173477459e-05,
      "loss": 0.5433,
      "step": 7664
    },
    {
      "epoch": 0.4546802704947206,
      "grad_norm": 0.2365584522485733,
      "learning_rate": 1.2118375955707883e-05,
      "loss": 0.0032,
      "step": 7665
    },
    {
      "epoch": 0.4547395895123977,
      "grad_norm": 1.3607875108718872,
      "learning_rate": 1.2117057737938309e-05,
      "loss": 0.0211,
      "step": 7666
    },
    {
      "epoch": 0.45479890853007476,
      "grad_norm": 0.06294586509466171,
      "learning_rate": 1.2115739520168732e-05,
      "loss": 0.0014,
      "step": 7667
    },
    {
      "epoch": 0.4548582275477518,
      "grad_norm": 7.406433582305908,
      "learning_rate": 1.2114421302399157e-05,
      "loss": 0.2603,
      "step": 7668
    },
    {
      "epoch": 0.4549175465654289,
      "grad_norm": 0.17401088774204254,
      "learning_rate": 1.2113103084629583e-05,
      "loss": 0.0013,
      "step": 7669
    },
    {
      "epoch": 0.45497686558310596,
      "grad_norm": 0.3433115780353546,
      "learning_rate": 1.2111784866860006e-05,
      "loss": 0.0044,
      "step": 7670
    },
    {
      "epoch": 0.455036184600783,
      "grad_norm": 39.804290771484375,
      "learning_rate": 1.2110466649090432e-05,
      "loss": 1.8676,
      "step": 7671
    },
    {
      "epoch": 0.4550955036184601,
      "grad_norm": 23.653005599975586,
      "learning_rate": 1.2109148431320856e-05,
      "loss": 0.3295,
      "step": 7672
    },
    {
      "epoch": 0.45515482263613716,
      "grad_norm": 3.9950389862060547,
      "learning_rate": 1.210783021355128e-05,
      "loss": 0.0333,
      "step": 7673
    },
    {
      "epoch": 0.4552141416538142,
      "grad_norm": 0.008902452886104584,
      "learning_rate": 1.2106511995781704e-05,
      "loss": 0.0004,
      "step": 7674
    },
    {
      "epoch": 0.45527346067149127,
      "grad_norm": 49.898006439208984,
      "learning_rate": 1.2105193778012127e-05,
      "loss": 0.4666,
      "step": 7675
    },
    {
      "epoch": 0.45533277968916835,
      "grad_norm": 0.023072585463523865,
      "learning_rate": 1.2103875560242553e-05,
      "loss": 0.0006,
      "step": 7676
    },
    {
      "epoch": 0.45539209870684544,
      "grad_norm": 1.005994200706482,
      "learning_rate": 1.2102557342472979e-05,
      "loss": 0.0167,
      "step": 7677
    },
    {
      "epoch": 0.45545141772452247,
      "grad_norm": 18.560089111328125,
      "learning_rate": 1.2101239124703401e-05,
      "loss": 0.5807,
      "step": 7678
    },
    {
      "epoch": 0.45551073674219955,
      "grad_norm": 0.018402544781565666,
      "learning_rate": 1.2099920906933827e-05,
      "loss": 0.0006,
      "step": 7679
    },
    {
      "epoch": 0.45557005575987664,
      "grad_norm": 0.13861526548862457,
      "learning_rate": 1.2098602689164251e-05,
      "loss": 0.001,
      "step": 7680
    },
    {
      "epoch": 0.45562937477755366,
      "grad_norm": 3.892805576324463,
      "learning_rate": 1.2097284471394675e-05,
      "loss": 0.0452,
      "step": 7681
    },
    {
      "epoch": 0.45568869379523075,
      "grad_norm": 0.9055204391479492,
      "learning_rate": 1.20959662536251e-05,
      "loss": 0.0108,
      "step": 7682
    },
    {
      "epoch": 0.45574801281290783,
      "grad_norm": 0.03360946103930473,
      "learning_rate": 1.2094648035855525e-05,
      "loss": 0.0013,
      "step": 7683
    },
    {
      "epoch": 0.45580733183058486,
      "grad_norm": 13.63420295715332,
      "learning_rate": 1.2093329818085948e-05,
      "loss": 0.4208,
      "step": 7684
    },
    {
      "epoch": 0.45586665084826195,
      "grad_norm": 0.00505938520655036,
      "learning_rate": 1.2092011600316374e-05,
      "loss": 0.0003,
      "step": 7685
    },
    {
      "epoch": 0.45592596986593903,
      "grad_norm": 15.371551513671875,
      "learning_rate": 1.2090693382546798e-05,
      "loss": 0.1798,
      "step": 7686
    },
    {
      "epoch": 0.4559852888836161,
      "grad_norm": 1.6445051431655884,
      "learning_rate": 1.2089375164777222e-05,
      "loss": 0.0305,
      "step": 7687
    },
    {
      "epoch": 0.45604460790129314,
      "grad_norm": 7.575461387634277,
      "learning_rate": 1.2088056947007646e-05,
      "loss": 0.3706,
      "step": 7688
    },
    {
      "epoch": 0.4561039269189702,
      "grad_norm": 3.4048924446105957,
      "learning_rate": 1.208673872923807e-05,
      "loss": 0.1073,
      "step": 7689
    },
    {
      "epoch": 0.4561632459366473,
      "grad_norm": 8.22054386138916,
      "learning_rate": 1.2085420511468495e-05,
      "loss": 0.0303,
      "step": 7690
    },
    {
      "epoch": 0.45622256495432434,
      "grad_norm": 0.025774359703063965,
      "learning_rate": 1.208410229369892e-05,
      "loss": 0.0005,
      "step": 7691
    },
    {
      "epoch": 0.4562818839720014,
      "grad_norm": 0.3152836859226227,
      "learning_rate": 1.2082784075929343e-05,
      "loss": 0.0025,
      "step": 7692
    },
    {
      "epoch": 0.4563412029896785,
      "grad_norm": 1.3326572179794312,
      "learning_rate": 1.2081465858159769e-05,
      "loss": 0.0145,
      "step": 7693
    },
    {
      "epoch": 0.45640052200735554,
      "grad_norm": 0.07025545835494995,
      "learning_rate": 1.2080147640390195e-05,
      "loss": 0.001,
      "step": 7694
    },
    {
      "epoch": 0.4564598410250326,
      "grad_norm": 0.9642071723937988,
      "learning_rate": 1.2078829422620617e-05,
      "loss": 0.0173,
      "step": 7695
    },
    {
      "epoch": 0.4565191600427097,
      "grad_norm": 10.583847045898438,
      "learning_rate": 1.2077511204851042e-05,
      "loss": 0.2309,
      "step": 7696
    },
    {
      "epoch": 0.45657847906038673,
      "grad_norm": 0.2523874044418335,
      "learning_rate": 1.2076192987081467e-05,
      "loss": 0.0021,
      "step": 7697
    },
    {
      "epoch": 0.4566377980780638,
      "grad_norm": 8.60928726196289,
      "learning_rate": 1.207487476931189e-05,
      "loss": 0.0989,
      "step": 7698
    },
    {
      "epoch": 0.4566971170957409,
      "grad_norm": 0.05202021822333336,
      "learning_rate": 1.2073556551542316e-05,
      "loss": 0.001,
      "step": 7699
    },
    {
      "epoch": 0.456756436113418,
      "grad_norm": 5.531080722808838,
      "learning_rate": 1.2072238333772742e-05,
      "loss": 0.0591,
      "step": 7700
    },
    {
      "epoch": 0.456815755131095,
      "grad_norm": 0.014009613543748856,
      "learning_rate": 1.2070920116003164e-05,
      "loss": 0.0003,
      "step": 7701
    },
    {
      "epoch": 0.4568750741487721,
      "grad_norm": 5.232548713684082,
      "learning_rate": 1.206960189823359e-05,
      "loss": 0.062,
      "step": 7702
    },
    {
      "epoch": 0.4569343931664492,
      "grad_norm": 0.6766079664230347,
      "learning_rate": 1.2068283680464014e-05,
      "loss": 0.0055,
      "step": 7703
    },
    {
      "epoch": 0.4569937121841262,
      "grad_norm": 0.7069604396820068,
      "learning_rate": 1.2066965462694438e-05,
      "loss": 0.0154,
      "step": 7704
    },
    {
      "epoch": 0.4570530312018033,
      "grad_norm": 115.8655776977539,
      "learning_rate": 1.2065647244924863e-05,
      "loss": 0.4627,
      "step": 7705
    },
    {
      "epoch": 0.4571123502194804,
      "grad_norm": 2.063309669494629,
      "learning_rate": 1.2064329027155287e-05,
      "loss": 0.0088,
      "step": 7706
    },
    {
      "epoch": 0.4571716692371574,
      "grad_norm": 6.04901123046875,
      "learning_rate": 1.2063010809385711e-05,
      "loss": 0.027,
      "step": 7707
    },
    {
      "epoch": 0.4572309882548345,
      "grad_norm": 0.7159992456436157,
      "learning_rate": 1.2061692591616137e-05,
      "loss": 0.0108,
      "step": 7708
    },
    {
      "epoch": 0.4572903072725116,
      "grad_norm": 0.05905929580330849,
      "learning_rate": 1.206037437384656e-05,
      "loss": 0.0005,
      "step": 7709
    },
    {
      "epoch": 0.45734962629018866,
      "grad_norm": 33.27431106567383,
      "learning_rate": 1.2059056156076985e-05,
      "loss": 0.4599,
      "step": 7710
    },
    {
      "epoch": 0.4574089453078657,
      "grad_norm": 0.5439749956130981,
      "learning_rate": 1.205773793830741e-05,
      "loss": 0.0054,
      "step": 7711
    },
    {
      "epoch": 0.4574682643255428,
      "grad_norm": 0.019895439967513084,
      "learning_rate": 1.2056419720537834e-05,
      "loss": 0.0005,
      "step": 7712
    },
    {
      "epoch": 0.45752758334321986,
      "grad_norm": 0.07178555428981781,
      "learning_rate": 1.2055101502768258e-05,
      "loss": 0.0013,
      "step": 7713
    },
    {
      "epoch": 0.4575869023608969,
      "grad_norm": 0.1338973045349121,
      "learning_rate": 1.2053783284998684e-05,
      "loss": 0.0023,
      "step": 7714
    },
    {
      "epoch": 0.45764622137857397,
      "grad_norm": 10.505338668823242,
      "learning_rate": 1.2052465067229106e-05,
      "loss": 0.4432,
      "step": 7715
    },
    {
      "epoch": 0.45770554039625105,
      "grad_norm": 39.92121505737305,
      "learning_rate": 1.2051146849459532e-05,
      "loss": 0.3056,
      "step": 7716
    },
    {
      "epoch": 0.4577648594139281,
      "grad_norm": 7.782238960266113,
      "learning_rate": 1.2049828631689958e-05,
      "loss": 0.1741,
      "step": 7717
    },
    {
      "epoch": 0.45782417843160517,
      "grad_norm": 0.04724785313010216,
      "learning_rate": 1.204851041392038e-05,
      "loss": 0.0009,
      "step": 7718
    },
    {
      "epoch": 0.45788349744928225,
      "grad_norm": 12.38209342956543,
      "learning_rate": 1.2047192196150805e-05,
      "loss": 0.244,
      "step": 7719
    },
    {
      "epoch": 0.45794281646695933,
      "grad_norm": 3.9253146648406982,
      "learning_rate": 1.204587397838123e-05,
      "loss": 0.4575,
      "step": 7720
    },
    {
      "epoch": 0.45800213548463636,
      "grad_norm": 0.31597691774368286,
      "learning_rate": 1.2044555760611653e-05,
      "loss": 0.0056,
      "step": 7721
    },
    {
      "epoch": 0.45806145450231345,
      "grad_norm": 7.323680400848389,
      "learning_rate": 1.2043237542842079e-05,
      "loss": 0.0889,
      "step": 7722
    },
    {
      "epoch": 0.45812077351999053,
      "grad_norm": 8.952438354492188,
      "learning_rate": 1.2041919325072501e-05,
      "loss": 0.1492,
      "step": 7723
    },
    {
      "epoch": 0.45818009253766756,
      "grad_norm": 10.393306732177734,
      "learning_rate": 1.2040601107302927e-05,
      "loss": 0.0368,
      "step": 7724
    },
    {
      "epoch": 0.45823941155534464,
      "grad_norm": 0.05212054401636124,
      "learning_rate": 1.2039282889533353e-05,
      "loss": 0.0014,
      "step": 7725
    },
    {
      "epoch": 0.45829873057302173,
      "grad_norm": 11.449617385864258,
      "learning_rate": 1.2037964671763776e-05,
      "loss": 0.3892,
      "step": 7726
    },
    {
      "epoch": 0.45835804959069876,
      "grad_norm": 0.2630951404571533,
      "learning_rate": 1.2036646453994201e-05,
      "loss": 0.0038,
      "step": 7727
    },
    {
      "epoch": 0.45841736860837584,
      "grad_norm": 0.008891665376722813,
      "learning_rate": 1.2035328236224626e-05,
      "loss": 0.0003,
      "step": 7728
    },
    {
      "epoch": 0.4584766876260529,
      "grad_norm": 0.08696340024471283,
      "learning_rate": 1.203401001845505e-05,
      "loss": 0.0016,
      "step": 7729
    },
    {
      "epoch": 0.45853600664372995,
      "grad_norm": 1.8915503025054932,
      "learning_rate": 1.2032691800685474e-05,
      "loss": 0.0166,
      "step": 7730
    },
    {
      "epoch": 0.45859532566140704,
      "grad_norm": 6.472018718719482,
      "learning_rate": 1.20313735829159e-05,
      "loss": 0.0971,
      "step": 7731
    },
    {
      "epoch": 0.4586546446790841,
      "grad_norm": 35.12845230102539,
      "learning_rate": 1.2030055365146322e-05,
      "loss": 3.0202,
      "step": 7732
    },
    {
      "epoch": 0.4587139636967612,
      "grad_norm": 34.745025634765625,
      "learning_rate": 1.2028737147376748e-05,
      "loss": 0.8081,
      "step": 7733
    },
    {
      "epoch": 0.45877328271443824,
      "grad_norm": 0.006997931748628616,
      "learning_rate": 1.2027418929607172e-05,
      "loss": 0.0003,
      "step": 7734
    },
    {
      "epoch": 0.4588326017321153,
      "grad_norm": 1.941744327545166,
      "learning_rate": 1.2026100711837597e-05,
      "loss": 0.0311,
      "step": 7735
    },
    {
      "epoch": 0.4588919207497924,
      "grad_norm": 0.2716355621814728,
      "learning_rate": 1.202478249406802e-05,
      "loss": 0.0018,
      "step": 7736
    },
    {
      "epoch": 0.45895123976746943,
      "grad_norm": 0.13672733306884766,
      "learning_rate": 1.2023464276298447e-05,
      "loss": 0.0026,
      "step": 7737
    },
    {
      "epoch": 0.4590105587851465,
      "grad_norm": 7.047097682952881,
      "learning_rate": 1.202214605852887e-05,
      "loss": 0.4688,
      "step": 7738
    },
    {
      "epoch": 0.4590698778028236,
      "grad_norm": 11.091604232788086,
      "learning_rate": 1.2020827840759295e-05,
      "loss": 0.2342,
      "step": 7739
    },
    {
      "epoch": 0.45912919682050063,
      "grad_norm": 11.306901931762695,
      "learning_rate": 1.2019509622989718e-05,
      "loss": 0.3471,
      "step": 7740
    },
    {
      "epoch": 0.4591885158381777,
      "grad_norm": 15.525057792663574,
      "learning_rate": 1.2018191405220143e-05,
      "loss": 0.648,
      "step": 7741
    },
    {
      "epoch": 0.4592478348558548,
      "grad_norm": 0.36849328875541687,
      "learning_rate": 1.2016873187450568e-05,
      "loss": 0.0031,
      "step": 7742
    },
    {
      "epoch": 0.4593071538735319,
      "grad_norm": 0.16686582565307617,
      "learning_rate": 1.2015554969680992e-05,
      "loss": 0.0024,
      "step": 7743
    },
    {
      "epoch": 0.4593664728912089,
      "grad_norm": 0.028158921748399734,
      "learning_rate": 1.2014236751911416e-05,
      "loss": 0.0005,
      "step": 7744
    },
    {
      "epoch": 0.459425791908886,
      "grad_norm": 0.04328349977731705,
      "learning_rate": 1.2012918534141842e-05,
      "loss": 0.0011,
      "step": 7745
    },
    {
      "epoch": 0.4594851109265631,
      "grad_norm": 0.155114084482193,
      "learning_rate": 1.2011600316372264e-05,
      "loss": 0.0028,
      "step": 7746
    },
    {
      "epoch": 0.4595444299442401,
      "grad_norm": 9.828397750854492,
      "learning_rate": 1.201028209860269e-05,
      "loss": 0.5267,
      "step": 7747
    },
    {
      "epoch": 0.4596037489619172,
      "grad_norm": 0.2549879252910614,
      "learning_rate": 1.2008963880833116e-05,
      "loss": 0.0027,
      "step": 7748
    },
    {
      "epoch": 0.4596630679795943,
      "grad_norm": 19.308584213256836,
      "learning_rate": 1.2007645663063539e-05,
      "loss": 0.2075,
      "step": 7749
    },
    {
      "epoch": 0.4597223869972713,
      "grad_norm": 0.014048425480723381,
      "learning_rate": 1.2006327445293965e-05,
      "loss": 0.0003,
      "step": 7750
    },
    {
      "epoch": 0.4597817060149484,
      "grad_norm": 2.339445114135742,
      "learning_rate": 1.2005009227524389e-05,
      "loss": 0.0417,
      "step": 7751
    },
    {
      "epoch": 0.45984102503262547,
      "grad_norm": 0.7105470299720764,
      "learning_rate": 1.2003691009754811e-05,
      "loss": 0.0081,
      "step": 7752
    },
    {
      "epoch": 0.4599003440503025,
      "grad_norm": 0.24673625826835632,
      "learning_rate": 1.2002372791985237e-05,
      "loss": 0.0034,
      "step": 7753
    },
    {
      "epoch": 0.4599596630679796,
      "grad_norm": 5.2305097579956055,
      "learning_rate": 1.200105457421566e-05,
      "loss": 0.0236,
      "step": 7754
    },
    {
      "epoch": 0.46001898208565667,
      "grad_norm": 0.04601112753152847,
      "learning_rate": 1.1999736356446085e-05,
      "loss": 0.001,
      "step": 7755
    },
    {
      "epoch": 0.46007830110333375,
      "grad_norm": 24.779014587402344,
      "learning_rate": 1.1998418138676511e-05,
      "loss": 1.2344,
      "step": 7756
    },
    {
      "epoch": 0.4601376201210108,
      "grad_norm": 0.2431187927722931,
      "learning_rate": 1.1997099920906934e-05,
      "loss": 0.0017,
      "step": 7757
    },
    {
      "epoch": 0.46019693913868787,
      "grad_norm": 22.233179092407227,
      "learning_rate": 1.199578170313736e-05,
      "loss": 0.6389,
      "step": 7758
    },
    {
      "epoch": 0.46025625815636495,
      "grad_norm": 8.350089073181152,
      "learning_rate": 1.1994463485367784e-05,
      "loss": 0.3542,
      "step": 7759
    },
    {
      "epoch": 0.460315577174042,
      "grad_norm": 7.209755897521973,
      "learning_rate": 1.1993145267598208e-05,
      "loss": 0.3044,
      "step": 7760
    },
    {
      "epoch": 0.46037489619171906,
      "grad_norm": 0.052626319229602814,
      "learning_rate": 1.1991827049828632e-05,
      "loss": 0.0015,
      "step": 7761
    },
    {
      "epoch": 0.46043421520939615,
      "grad_norm": 0.5632632374763489,
      "learning_rate": 1.1990508832059058e-05,
      "loss": 0.005,
      "step": 7762
    },
    {
      "epoch": 0.4604935342270732,
      "grad_norm": 4.103601932525635,
      "learning_rate": 1.198919061428948e-05,
      "loss": 0.1009,
      "step": 7763
    },
    {
      "epoch": 0.46055285324475026,
      "grad_norm": 0.07986471056938171,
      "learning_rate": 1.1987872396519907e-05,
      "loss": 0.0014,
      "step": 7764
    },
    {
      "epoch": 0.46061217226242734,
      "grad_norm": 0.051403820514678955,
      "learning_rate": 1.198655417875033e-05,
      "loss": 0.0009,
      "step": 7765
    },
    {
      "epoch": 0.46067149128010443,
      "grad_norm": 0.01937083713710308,
      "learning_rate": 1.1985235960980755e-05,
      "loss": 0.0007,
      "step": 7766
    },
    {
      "epoch": 0.46073081029778146,
      "grad_norm": 9.42719841003418,
      "learning_rate": 1.1983917743211179e-05,
      "loss": 0.3428,
      "step": 7767
    },
    {
      "epoch": 0.46079012931545854,
      "grad_norm": 0.20819362998008728,
      "learning_rate": 1.1982599525441605e-05,
      "loss": 0.0025,
      "step": 7768
    },
    {
      "epoch": 0.4608494483331356,
      "grad_norm": 0.011484349146485329,
      "learning_rate": 1.1981281307672027e-05,
      "loss": 0.0003,
      "step": 7769
    },
    {
      "epoch": 0.46090876735081265,
      "grad_norm": 0.013855179771780968,
      "learning_rate": 1.1979963089902453e-05,
      "loss": 0.0004,
      "step": 7770
    },
    {
      "epoch": 0.46096808636848974,
      "grad_norm": 0.0056792511604726315,
      "learning_rate": 1.1978644872132876e-05,
      "loss": 0.0003,
      "step": 7771
    },
    {
      "epoch": 0.4610274053861668,
      "grad_norm": 19.383737564086914,
      "learning_rate": 1.1977326654363302e-05,
      "loss": 0.2536,
      "step": 7772
    },
    {
      "epoch": 0.46108672440384385,
      "grad_norm": 6.795319080352783,
      "learning_rate": 1.1976008436593728e-05,
      "loss": 0.1874,
      "step": 7773
    },
    {
      "epoch": 0.46114604342152093,
      "grad_norm": 2.957484722137451,
      "learning_rate": 1.197469021882415e-05,
      "loss": 0.0291,
      "step": 7774
    },
    {
      "epoch": 0.461205362439198,
      "grad_norm": 8.783005714416504,
      "learning_rate": 1.1973372001054574e-05,
      "loss": 0.817,
      "step": 7775
    },
    {
      "epoch": 0.46126468145687505,
      "grad_norm": 0.009430408477783203,
      "learning_rate": 1.1972053783285e-05,
      "loss": 0.0003,
      "step": 7776
    },
    {
      "epoch": 0.46132400047455213,
      "grad_norm": 7.088296890258789,
      "learning_rate": 1.1970735565515423e-05,
      "loss": 0.2033,
      "step": 7777
    },
    {
      "epoch": 0.4613833194922292,
      "grad_norm": 0.34298276901245117,
      "learning_rate": 1.1969417347745849e-05,
      "loss": 0.0049,
      "step": 7778
    },
    {
      "epoch": 0.4614426385099063,
      "grad_norm": 0.10405702888965607,
      "learning_rate": 1.1968099129976274e-05,
      "loss": 0.0017,
      "step": 7779
    },
    {
      "epoch": 0.46150195752758333,
      "grad_norm": 10.978744506835938,
      "learning_rate": 1.1966780912206697e-05,
      "loss": 0.1492,
      "step": 7780
    },
    {
      "epoch": 0.4615612765452604,
      "grad_norm": 3.6407339572906494,
      "learning_rate": 1.1965462694437123e-05,
      "loss": 0.0635,
      "step": 7781
    },
    {
      "epoch": 0.4616205955629375,
      "grad_norm": 14.086642265319824,
      "learning_rate": 1.1964144476667547e-05,
      "loss": 0.6542,
      "step": 7782
    },
    {
      "epoch": 0.4616799145806145,
      "grad_norm": 7.229271411895752,
      "learning_rate": 1.1962826258897971e-05,
      "loss": 0.2094,
      "step": 7783
    },
    {
      "epoch": 0.4617392335982916,
      "grad_norm": 0.7676666975021362,
      "learning_rate": 1.1961508041128395e-05,
      "loss": 0.0154,
      "step": 7784
    },
    {
      "epoch": 0.4617985526159687,
      "grad_norm": 10.573938369750977,
      "learning_rate": 1.1960189823358821e-05,
      "loss": 0.2931,
      "step": 7785
    },
    {
      "epoch": 0.4618578716336457,
      "grad_norm": 4.5484514236450195,
      "learning_rate": 1.1958871605589244e-05,
      "loss": 0.083,
      "step": 7786
    },
    {
      "epoch": 0.4619171906513228,
      "grad_norm": 0.5523191690444946,
      "learning_rate": 1.195755338781967e-05,
      "loss": 0.0075,
      "step": 7787
    },
    {
      "epoch": 0.4619765096689999,
      "grad_norm": 7.200437545776367,
      "learning_rate": 1.1956235170050092e-05,
      "loss": 0.0772,
      "step": 7788
    },
    {
      "epoch": 0.462035828686677,
      "grad_norm": 2.799210786819458,
      "learning_rate": 1.1954916952280518e-05,
      "loss": 0.077,
      "step": 7789
    },
    {
      "epoch": 0.462095147704354,
      "grad_norm": 0.08120202273130417,
      "learning_rate": 1.1953598734510942e-05,
      "loss": 0.0009,
      "step": 7790
    },
    {
      "epoch": 0.4621544667220311,
      "grad_norm": 14.309706687927246,
      "learning_rate": 1.1952280516741366e-05,
      "loss": 0.8922,
      "step": 7791
    },
    {
      "epoch": 0.46221378573970817,
      "grad_norm": 6.5085930824279785,
      "learning_rate": 1.195096229897179e-05,
      "loss": 0.2632,
      "step": 7792
    },
    {
      "epoch": 0.4622731047573852,
      "grad_norm": 0.08884815126657486,
      "learning_rate": 1.1949644081202216e-05,
      "loss": 0.0013,
      "step": 7793
    },
    {
      "epoch": 0.4623324237750623,
      "grad_norm": 14.227360725402832,
      "learning_rate": 1.1948325863432639e-05,
      "loss": 0.3514,
      "step": 7794
    },
    {
      "epoch": 0.46239174279273937,
      "grad_norm": 6.106563091278076,
      "learning_rate": 1.1947007645663065e-05,
      "loss": 0.0612,
      "step": 7795
    },
    {
      "epoch": 0.4624510618104164,
      "grad_norm": 0.057884156703948975,
      "learning_rate": 1.1945689427893489e-05,
      "loss": 0.0017,
      "step": 7796
    },
    {
      "epoch": 0.4625103808280935,
      "grad_norm": 0.1783657968044281,
      "learning_rate": 1.1944371210123913e-05,
      "loss": 0.0037,
      "step": 7797
    },
    {
      "epoch": 0.46256969984577057,
      "grad_norm": 0.19283877313137054,
      "learning_rate": 1.1943052992354337e-05,
      "loss": 0.0037,
      "step": 7798
    },
    {
      "epoch": 0.4626290188634476,
      "grad_norm": 9.053614616394043,
      "learning_rate": 1.1941734774584763e-05,
      "loss": 0.2552,
      "step": 7799
    },
    {
      "epoch": 0.4626883378811247,
      "grad_norm": 0.5169469714164734,
      "learning_rate": 1.1940416556815186e-05,
      "loss": 0.0045,
      "step": 7800
    },
    {
      "epoch": 0.46274765689880176,
      "grad_norm": 1.8976000547409058,
      "learning_rate": 1.1939098339045612e-05,
      "loss": 0.0358,
      "step": 7801
    },
    {
      "epoch": 0.46280697591647885,
      "grad_norm": 1.5278520584106445,
      "learning_rate": 1.1937780121276034e-05,
      "loss": 0.0224,
      "step": 7802
    },
    {
      "epoch": 0.4628662949341559,
      "grad_norm": 5.163230895996094,
      "learning_rate": 1.193646190350646e-05,
      "loss": 0.0867,
      "step": 7803
    },
    {
      "epoch": 0.46292561395183296,
      "grad_norm": 15.167482376098633,
      "learning_rate": 1.1935143685736886e-05,
      "loss": 0.5205,
      "step": 7804
    },
    {
      "epoch": 0.46298493296951004,
      "grad_norm": 0.4027327597141266,
      "learning_rate": 1.1933825467967308e-05,
      "loss": 0.0077,
      "step": 7805
    },
    {
      "epoch": 0.46304425198718707,
      "grad_norm": 14.658151626586914,
      "learning_rate": 1.1932507250197734e-05,
      "loss": 0.6783,
      "step": 7806
    },
    {
      "epoch": 0.46310357100486416,
      "grad_norm": 0.00924106314778328,
      "learning_rate": 1.1931189032428158e-05,
      "loss": 0.0003,
      "step": 7807
    },
    {
      "epoch": 0.46316289002254124,
      "grad_norm": 1.273410677909851,
      "learning_rate": 1.1929870814658581e-05,
      "loss": 0.0239,
      "step": 7808
    },
    {
      "epoch": 0.46322220904021827,
      "grad_norm": 16.838327407836914,
      "learning_rate": 1.1928552596889007e-05,
      "loss": 0.3314,
      "step": 7809
    },
    {
      "epoch": 0.46328152805789535,
      "grad_norm": 5.572896480560303,
      "learning_rate": 1.1927234379119433e-05,
      "loss": 0.0702,
      "step": 7810
    },
    {
      "epoch": 0.46334084707557244,
      "grad_norm": 0.5347616672515869,
      "learning_rate": 1.1925916161349855e-05,
      "loss": 0.0086,
      "step": 7811
    },
    {
      "epoch": 0.4634001660932495,
      "grad_norm": 16.03620147705078,
      "learning_rate": 1.1924597943580281e-05,
      "loss": 0.282,
      "step": 7812
    },
    {
      "epoch": 0.46345948511092655,
      "grad_norm": 0.754336953163147,
      "learning_rate": 1.1923279725810705e-05,
      "loss": 0.0158,
      "step": 7813
    },
    {
      "epoch": 0.46351880412860363,
      "grad_norm": 1.0237126350402832,
      "learning_rate": 1.192196150804113e-05,
      "loss": 0.0094,
      "step": 7814
    },
    {
      "epoch": 0.4635781231462807,
      "grad_norm": 0.025173937901854515,
      "learning_rate": 1.1920643290271554e-05,
      "loss": 0.0007,
      "step": 7815
    },
    {
      "epoch": 0.46363744216395775,
      "grad_norm": 7.7249755859375,
      "learning_rate": 1.191932507250198e-05,
      "loss": 0.8048,
      "step": 7816
    },
    {
      "epoch": 0.46369676118163483,
      "grad_norm": 1.3830024003982544,
      "learning_rate": 1.1918006854732402e-05,
      "loss": 0.017,
      "step": 7817
    },
    {
      "epoch": 0.4637560801993119,
      "grad_norm": 22.328231811523438,
      "learning_rate": 1.1916688636962828e-05,
      "loss": 1.7628,
      "step": 7818
    },
    {
      "epoch": 0.46381539921698894,
      "grad_norm": 1.7768515348434448,
      "learning_rate": 1.191537041919325e-05,
      "loss": 0.0192,
      "step": 7819
    },
    {
      "epoch": 0.46387471823466603,
      "grad_norm": 2.9549624919891357,
      "learning_rate": 1.1914052201423676e-05,
      "loss": 0.0477,
      "step": 7820
    },
    {
      "epoch": 0.4639340372523431,
      "grad_norm": 4.7764763832092285,
      "learning_rate": 1.19127339836541e-05,
      "loss": 0.1693,
      "step": 7821
    },
    {
      "epoch": 0.46399335627002014,
      "grad_norm": 10.729659080505371,
      "learning_rate": 1.1911415765884525e-05,
      "loss": 0.1746,
      "step": 7822
    },
    {
      "epoch": 0.4640526752876972,
      "grad_norm": 3.021456241607666,
      "learning_rate": 1.1910097548114949e-05,
      "loss": 0.1067,
      "step": 7823
    },
    {
      "epoch": 0.4641119943053743,
      "grad_norm": 0.48249515891075134,
      "learning_rate": 1.1908779330345375e-05,
      "loss": 0.0083,
      "step": 7824
    },
    {
      "epoch": 0.4641713133230514,
      "grad_norm": 11.534692764282227,
      "learning_rate": 1.1907461112575797e-05,
      "loss": 0.5905,
      "step": 7825
    },
    {
      "epoch": 0.4642306323407284,
      "grad_norm": 0.43531960248947144,
      "learning_rate": 1.1906142894806223e-05,
      "loss": 0.0059,
      "step": 7826
    },
    {
      "epoch": 0.4642899513584055,
      "grad_norm": 0.0033073686063289642,
      "learning_rate": 1.1904824677036649e-05,
      "loss": 0.0001,
      "step": 7827
    },
    {
      "epoch": 0.4643492703760826,
      "grad_norm": 9.471248626708984,
      "learning_rate": 1.1903506459267071e-05,
      "loss": 0.0219,
      "step": 7828
    },
    {
      "epoch": 0.4644085893937596,
      "grad_norm": 12.933387756347656,
      "learning_rate": 1.1902188241497497e-05,
      "loss": 0.1665,
      "step": 7829
    },
    {
      "epoch": 0.4644679084114367,
      "grad_norm": 0.049715690314769745,
      "learning_rate": 1.1900870023727922e-05,
      "loss": 0.0017,
      "step": 7830
    },
    {
      "epoch": 0.4645272274291138,
      "grad_norm": 20.946062088012695,
      "learning_rate": 1.1899551805958344e-05,
      "loss": 1.1035,
      "step": 7831
    },
    {
      "epoch": 0.4645865464467908,
      "grad_norm": 10.397370338439941,
      "learning_rate": 1.189823358818877e-05,
      "loss": 0.1232,
      "step": 7832
    },
    {
      "epoch": 0.4646458654644679,
      "grad_norm": 2.437321662902832,
      "learning_rate": 1.1896915370419196e-05,
      "loss": 0.0282,
      "step": 7833
    },
    {
      "epoch": 0.464705184482145,
      "grad_norm": 1.741029143333435,
      "learning_rate": 1.1895597152649618e-05,
      "loss": 0.0189,
      "step": 7834
    },
    {
      "epoch": 0.46476450349982207,
      "grad_norm": 0.46273544430732727,
      "learning_rate": 1.1894278934880044e-05,
      "loss": 0.0038,
      "step": 7835
    },
    {
      "epoch": 0.4648238225174991,
      "grad_norm": 0.03104781173169613,
      "learning_rate": 1.1892960717110467e-05,
      "loss": 0.0006,
      "step": 7836
    },
    {
      "epoch": 0.4648831415351762,
      "grad_norm": 0.05300096049904823,
      "learning_rate": 1.1891642499340893e-05,
      "loss": 0.0015,
      "step": 7837
    },
    {
      "epoch": 0.46494246055285327,
      "grad_norm": 2.9778740406036377,
      "learning_rate": 1.1890324281571317e-05,
      "loss": 0.0324,
      "step": 7838
    },
    {
      "epoch": 0.4650017795705303,
      "grad_norm": 0.9484930634498596,
      "learning_rate": 1.1889006063801741e-05,
      "loss": 0.0108,
      "step": 7839
    },
    {
      "epoch": 0.4650610985882074,
      "grad_norm": 53.90492248535156,
      "learning_rate": 1.1887687846032165e-05,
      "loss": 0.5226,
      "step": 7840
    },
    {
      "epoch": 0.46512041760588446,
      "grad_norm": 2.2541005611419678,
      "learning_rate": 1.1886369628262591e-05,
      "loss": 0.0277,
      "step": 7841
    },
    {
      "epoch": 0.4651797366235615,
      "grad_norm": 13.344419479370117,
      "learning_rate": 1.1885051410493013e-05,
      "loss": 0.7673,
      "step": 7842
    },
    {
      "epoch": 0.4652390556412386,
      "grad_norm": 0.021395478397607803,
      "learning_rate": 1.188373319272344e-05,
      "loss": 0.0007,
      "step": 7843
    },
    {
      "epoch": 0.46529837465891566,
      "grad_norm": 0.05310366302728653,
      "learning_rate": 1.1882414974953864e-05,
      "loss": 0.0007,
      "step": 7844
    },
    {
      "epoch": 0.46535769367659274,
      "grad_norm": 5.915778160095215,
      "learning_rate": 1.1881096757184288e-05,
      "loss": 0.1323,
      "step": 7845
    },
    {
      "epoch": 0.46541701269426977,
      "grad_norm": 1.409867525100708,
      "learning_rate": 1.1879778539414712e-05,
      "loss": 0.0093,
      "step": 7846
    },
    {
      "epoch": 0.46547633171194686,
      "grad_norm": 0.04706045985221863,
      "learning_rate": 1.1878460321645138e-05,
      "loss": 0.0008,
      "step": 7847
    },
    {
      "epoch": 0.46553565072962394,
      "grad_norm": 19.9282283782959,
      "learning_rate": 1.187714210387556e-05,
      "loss": 0.7629,
      "step": 7848
    },
    {
      "epoch": 0.46559496974730097,
      "grad_norm": 12.243675231933594,
      "learning_rate": 1.1875823886105986e-05,
      "loss": 0.2551,
      "step": 7849
    },
    {
      "epoch": 0.46565428876497805,
      "grad_norm": 0.45105037093162537,
      "learning_rate": 1.1874505668336409e-05,
      "loss": 0.0045,
      "step": 7850
    },
    {
      "epoch": 0.46571360778265514,
      "grad_norm": 0.022391170263290405,
      "learning_rate": 1.1873187450566835e-05,
      "loss": 0.0006,
      "step": 7851
    },
    {
      "epoch": 0.46577292680033217,
      "grad_norm": 0.010135257616639137,
      "learning_rate": 1.1871869232797259e-05,
      "loss": 0.0003,
      "step": 7852
    },
    {
      "epoch": 0.46583224581800925,
      "grad_norm": 13.05141544342041,
      "learning_rate": 1.1870551015027683e-05,
      "loss": 0.1165,
      "step": 7853
    },
    {
      "epoch": 0.46589156483568633,
      "grad_norm": 0.4813865125179291,
      "learning_rate": 1.1869232797258107e-05,
      "loss": 0.0067,
      "step": 7854
    },
    {
      "epoch": 0.46595088385336336,
      "grad_norm": 17.424768447875977,
      "learning_rate": 1.1867914579488533e-05,
      "loss": 0.7204,
      "step": 7855
    },
    {
      "epoch": 0.46601020287104045,
      "grad_norm": 0.4361872375011444,
      "learning_rate": 1.1866596361718955e-05,
      "loss": 0.0023,
      "step": 7856
    },
    {
      "epoch": 0.46606952188871753,
      "grad_norm": 0.042913179844617844,
      "learning_rate": 1.1865278143949381e-05,
      "loss": 0.0009,
      "step": 7857
    },
    {
      "epoch": 0.4661288409063946,
      "grad_norm": 2.137399435043335,
      "learning_rate": 1.1863959926179807e-05,
      "loss": 0.0358,
      "step": 7858
    },
    {
      "epoch": 0.46618815992407164,
      "grad_norm": 0.2600751519203186,
      "learning_rate": 1.186264170841023e-05,
      "loss": 0.0029,
      "step": 7859
    },
    {
      "epoch": 0.4662474789417487,
      "grad_norm": 2.849931478500366,
      "learning_rate": 1.1861323490640656e-05,
      "loss": 0.0679,
      "step": 7860
    },
    {
      "epoch": 0.4663067979594258,
      "grad_norm": 0.0889471024274826,
      "learning_rate": 1.186000527287108e-05,
      "loss": 0.001,
      "step": 7861
    },
    {
      "epoch": 0.46636611697710284,
      "grad_norm": 9.885258674621582,
      "learning_rate": 1.1858687055101504e-05,
      "loss": 0.4565,
      "step": 7862
    },
    {
      "epoch": 0.4664254359947799,
      "grad_norm": 0.1801859438419342,
      "learning_rate": 1.1857368837331928e-05,
      "loss": 0.0021,
      "step": 7863
    },
    {
      "epoch": 0.466484755012457,
      "grad_norm": 0.5136191248893738,
      "learning_rate": 1.1856050619562354e-05,
      "loss": 0.0023,
      "step": 7864
    },
    {
      "epoch": 0.46654407403013404,
      "grad_norm": 1.0750561952590942,
      "learning_rate": 1.1854732401792777e-05,
      "loss": 0.0148,
      "step": 7865
    },
    {
      "epoch": 0.4666033930478111,
      "grad_norm": 14.377935409545898,
      "learning_rate": 1.1853414184023202e-05,
      "loss": 0.0704,
      "step": 7866
    },
    {
      "epoch": 0.4666627120654882,
      "grad_norm": 0.04037174955010414,
      "learning_rate": 1.1852095966253625e-05,
      "loss": 0.0004,
      "step": 7867
    },
    {
      "epoch": 0.4667220310831653,
      "grad_norm": 1.7701306343078613,
      "learning_rate": 1.185077774848405e-05,
      "loss": 0.0271,
      "step": 7868
    },
    {
      "epoch": 0.4667813501008423,
      "grad_norm": 16.55185317993164,
      "learning_rate": 1.1849459530714475e-05,
      "loss": 0.265,
      "step": 7869
    },
    {
      "epoch": 0.4668406691185194,
      "grad_norm": 18.806964874267578,
      "learning_rate": 1.18481413129449e-05,
      "loss": 0.9477,
      "step": 7870
    },
    {
      "epoch": 0.4668999881361965,
      "grad_norm": 2.5265064239501953,
      "learning_rate": 1.1846823095175323e-05,
      "loss": 0.0154,
      "step": 7871
    },
    {
      "epoch": 0.4669593071538735,
      "grad_norm": 1.0173457860946655,
      "learning_rate": 1.184550487740575e-05,
      "loss": 0.004,
      "step": 7872
    },
    {
      "epoch": 0.4670186261715506,
      "grad_norm": 0.2372168004512787,
      "learning_rate": 1.1844186659636172e-05,
      "loss": 0.0051,
      "step": 7873
    },
    {
      "epoch": 0.4670779451892277,
      "grad_norm": 2.022456645965576,
      "learning_rate": 1.1842868441866598e-05,
      "loss": 0.0081,
      "step": 7874
    },
    {
      "epoch": 0.4671372642069047,
      "grad_norm": 4.29229736328125,
      "learning_rate": 1.1841550224097022e-05,
      "loss": 0.0321,
      "step": 7875
    },
    {
      "epoch": 0.4671965832245818,
      "grad_norm": 8.766008377075195,
      "learning_rate": 1.1840232006327446e-05,
      "loss": 0.8548,
      "step": 7876
    },
    {
      "epoch": 0.4672559022422589,
      "grad_norm": 7.9063720703125,
      "learning_rate": 1.183891378855787e-05,
      "loss": 0.7959,
      "step": 7877
    },
    {
      "epoch": 0.4673152212599359,
      "grad_norm": 4.199879169464111,
      "learning_rate": 1.1837595570788296e-05,
      "loss": 0.0482,
      "step": 7878
    },
    {
      "epoch": 0.467374540277613,
      "grad_norm": 0.34037935733795166,
      "learning_rate": 1.1836277353018719e-05,
      "loss": 0.0028,
      "step": 7879
    },
    {
      "epoch": 0.4674338592952901,
      "grad_norm": 3.7859010696411133,
      "learning_rate": 1.1834959135249144e-05,
      "loss": 0.0151,
      "step": 7880
    },
    {
      "epoch": 0.46749317831296716,
      "grad_norm": 1.5537158250808716,
      "learning_rate": 1.183364091747957e-05,
      "loss": 0.0186,
      "step": 7881
    },
    {
      "epoch": 0.4675524973306442,
      "grad_norm": 0.014675939455628395,
      "learning_rate": 1.1832322699709993e-05,
      "loss": 0.0003,
      "step": 7882
    },
    {
      "epoch": 0.4676118163483213,
      "grad_norm": 5.722776412963867,
      "learning_rate": 1.1831004481940419e-05,
      "loss": 0.1111,
      "step": 7883
    },
    {
      "epoch": 0.46767113536599836,
      "grad_norm": 1.6480762958526611,
      "learning_rate": 1.1829686264170841e-05,
      "loss": 0.0114,
      "step": 7884
    },
    {
      "epoch": 0.4677304543836754,
      "grad_norm": 3.5136497020721436,
      "learning_rate": 1.1828368046401267e-05,
      "loss": 0.0891,
      "step": 7885
    },
    {
      "epoch": 0.46778977340135247,
      "grad_norm": 0.6749348044395447,
      "learning_rate": 1.1827049828631691e-05,
      "loss": 0.0071,
      "step": 7886
    },
    {
      "epoch": 0.46784909241902956,
      "grad_norm": 10.395659446716309,
      "learning_rate": 1.1825731610862114e-05,
      "loss": 0.2908,
      "step": 7887
    },
    {
      "epoch": 0.4679084114367066,
      "grad_norm": 2.2213568687438965,
      "learning_rate": 1.182441339309254e-05,
      "loss": 0.0993,
      "step": 7888
    },
    {
      "epoch": 0.46796773045438367,
      "grad_norm": 0.7671390175819397,
      "learning_rate": 1.1823095175322966e-05,
      "loss": 0.0041,
      "step": 7889
    },
    {
      "epoch": 0.46802704947206075,
      "grad_norm": 2.953909397125244,
      "learning_rate": 1.1821776957553388e-05,
      "loss": 0.0362,
      "step": 7890
    },
    {
      "epoch": 0.46808636848973784,
      "grad_norm": 2.3531649112701416,
      "learning_rate": 1.1820458739783814e-05,
      "loss": 0.0315,
      "step": 7891
    },
    {
      "epoch": 0.46814568750741486,
      "grad_norm": 0.0692700669169426,
      "learning_rate": 1.1819140522014238e-05,
      "loss": 0.0016,
      "step": 7892
    },
    {
      "epoch": 0.46820500652509195,
      "grad_norm": 15.838923454284668,
      "learning_rate": 1.1817822304244662e-05,
      "loss": 0.6441,
      "step": 7893
    },
    {
      "epoch": 0.46826432554276903,
      "grad_norm": 17.668560028076172,
      "learning_rate": 1.1816504086475086e-05,
      "loss": 0.4518,
      "step": 7894
    },
    {
      "epoch": 0.46832364456044606,
      "grad_norm": 0.11551778763532639,
      "learning_rate": 1.1815185868705512e-05,
      "loss": 0.0025,
      "step": 7895
    },
    {
      "epoch": 0.46838296357812315,
      "grad_norm": 2.0355982780456543,
      "learning_rate": 1.1813867650935935e-05,
      "loss": 0.0209,
      "step": 7896
    },
    {
      "epoch": 0.46844228259580023,
      "grad_norm": 12.59495735168457,
      "learning_rate": 1.181254943316636e-05,
      "loss": 0.1243,
      "step": 7897
    },
    {
      "epoch": 0.46850160161347726,
      "grad_norm": 4.7868804931640625,
      "learning_rate": 1.1811231215396783e-05,
      "loss": 0.0555,
      "step": 7898
    },
    {
      "epoch": 0.46856092063115434,
      "grad_norm": 0.887973964214325,
      "learning_rate": 1.1809912997627209e-05,
      "loss": 0.0106,
      "step": 7899
    },
    {
      "epoch": 0.4686202396488314,
      "grad_norm": 0.16385184228420258,
      "learning_rate": 1.1808594779857633e-05,
      "loss": 0.0022,
      "step": 7900
    },
    {
      "epoch": 0.46867955866650846,
      "grad_norm": 0.2970137596130371,
      "learning_rate": 1.1807276562088057e-05,
      "loss": 0.0035,
      "step": 7901
    },
    {
      "epoch": 0.46873887768418554,
      "grad_norm": 20.899688720703125,
      "learning_rate": 1.1805958344318482e-05,
      "loss": 0.4894,
      "step": 7902
    },
    {
      "epoch": 0.4687981967018626,
      "grad_norm": 9.917606353759766,
      "learning_rate": 1.1804640126548908e-05,
      "loss": 0.1217,
      "step": 7903
    },
    {
      "epoch": 0.4688575157195397,
      "grad_norm": 0.013650890439748764,
      "learning_rate": 1.180332190877933e-05,
      "loss": 0.0007,
      "step": 7904
    },
    {
      "epoch": 0.46891683473721674,
      "grad_norm": 0.04463943839073181,
      "learning_rate": 1.1802003691009756e-05,
      "loss": 0.0008,
      "step": 7905
    },
    {
      "epoch": 0.4689761537548938,
      "grad_norm": 0.20614489912986755,
      "learning_rate": 1.1800685473240182e-05,
      "loss": 0.0026,
      "step": 7906
    },
    {
      "epoch": 0.4690354727725709,
      "grad_norm": 0.06198510527610779,
      "learning_rate": 1.1799367255470604e-05,
      "loss": 0.0011,
      "step": 7907
    },
    {
      "epoch": 0.46909479179024793,
      "grad_norm": 9.664826393127441,
      "learning_rate": 1.1798049037701028e-05,
      "loss": 0.3466,
      "step": 7908
    },
    {
      "epoch": 0.469154110807925,
      "grad_norm": 0.6637457609176636,
      "learning_rate": 1.1796730819931454e-05,
      "loss": 0.0064,
      "step": 7909
    },
    {
      "epoch": 0.4692134298256021,
      "grad_norm": 0.13814054429531097,
      "learning_rate": 1.1795412602161877e-05,
      "loss": 0.0018,
      "step": 7910
    },
    {
      "epoch": 0.46927274884327913,
      "grad_norm": 3.181035041809082,
      "learning_rate": 1.1794094384392303e-05,
      "loss": 0.0422,
      "step": 7911
    },
    {
      "epoch": 0.4693320678609562,
      "grad_norm": 15.303845405578613,
      "learning_rate": 1.1792776166622729e-05,
      "loss": 0.206,
      "step": 7912
    },
    {
      "epoch": 0.4693913868786333,
      "grad_norm": 9.347821235656738,
      "learning_rate": 1.1791457948853151e-05,
      "loss": 0.4011,
      "step": 7913
    },
    {
      "epoch": 0.4694507058963104,
      "grad_norm": 9.448616027832031,
      "learning_rate": 1.1790139731083577e-05,
      "loss": 0.0138,
      "step": 7914
    },
    {
      "epoch": 0.4695100249139874,
      "grad_norm": 10.810108184814453,
      "learning_rate": 1.1788821513314e-05,
      "loss": 0.2244,
      "step": 7915
    },
    {
      "epoch": 0.4695693439316645,
      "grad_norm": 0.016243821009993553,
      "learning_rate": 1.1787503295544425e-05,
      "loss": 0.0005,
      "step": 7916
    },
    {
      "epoch": 0.4696286629493416,
      "grad_norm": 1.5365041494369507,
      "learning_rate": 1.178618507777485e-05,
      "loss": 0.0098,
      "step": 7917
    },
    {
      "epoch": 0.4696879819670186,
      "grad_norm": 0.05932053551077843,
      "learning_rate": 1.1784866860005274e-05,
      "loss": 0.0009,
      "step": 7918
    },
    {
      "epoch": 0.4697473009846957,
      "grad_norm": 0.02129436656832695,
      "learning_rate": 1.1783548642235698e-05,
      "loss": 0.0005,
      "step": 7919
    },
    {
      "epoch": 0.4698066200023728,
      "grad_norm": 0.16484466195106506,
      "learning_rate": 1.1782230424466124e-05,
      "loss": 0.0022,
      "step": 7920
    },
    {
      "epoch": 0.4698659390200498,
      "grad_norm": 8.882582664489746,
      "learning_rate": 1.1780912206696546e-05,
      "loss": 0.0605,
      "step": 7921
    },
    {
      "epoch": 0.4699252580377269,
      "grad_norm": 12.763846397399902,
      "learning_rate": 1.1779593988926972e-05,
      "loss": 0.3228,
      "step": 7922
    },
    {
      "epoch": 0.469984577055404,
      "grad_norm": 9.579453468322754,
      "learning_rate": 1.1778275771157396e-05,
      "loss": 0.6827,
      "step": 7923
    },
    {
      "epoch": 0.470043896073081,
      "grad_norm": 0.11434782296419144,
      "learning_rate": 1.177695755338782e-05,
      "loss": 0.0016,
      "step": 7924
    },
    {
      "epoch": 0.4701032150907581,
      "grad_norm": 15.855541229248047,
      "learning_rate": 1.1775639335618245e-05,
      "loss": 0.2279,
      "step": 7925
    },
    {
      "epoch": 0.47016253410843517,
      "grad_norm": 2.2130415439605713,
      "learning_rate": 1.177432111784867e-05,
      "loss": 0.0263,
      "step": 7926
    },
    {
      "epoch": 0.47022185312611225,
      "grad_norm": 1.535134196281433,
      "learning_rate": 1.1773002900079093e-05,
      "loss": 0.0065,
      "step": 7927
    },
    {
      "epoch": 0.4702811721437893,
      "grad_norm": 24.29522132873535,
      "learning_rate": 1.1771684682309519e-05,
      "loss": 0.1511,
      "step": 7928
    },
    {
      "epoch": 0.47034049116146637,
      "grad_norm": 0.545191764831543,
      "learning_rate": 1.1770366464539945e-05,
      "loss": 0.0021,
      "step": 7929
    },
    {
      "epoch": 0.47039981017914345,
      "grad_norm": 0.0332794263958931,
      "learning_rate": 1.1769048246770367e-05,
      "loss": 0.0008,
      "step": 7930
    },
    {
      "epoch": 0.4704591291968205,
      "grad_norm": 0.15317656099796295,
      "learning_rate": 1.1767730029000792e-05,
      "loss": 0.0016,
      "step": 7931
    },
    {
      "epoch": 0.47051844821449756,
      "grad_norm": 0.3416287899017334,
      "learning_rate": 1.1766411811231216e-05,
      "loss": 0.002,
      "step": 7932
    },
    {
      "epoch": 0.47057776723217465,
      "grad_norm": 1.4546860456466675,
      "learning_rate": 1.176509359346164e-05,
      "loss": 0.0215,
      "step": 7933
    },
    {
      "epoch": 0.4706370862498517,
      "grad_norm": 24.70240592956543,
      "learning_rate": 1.1763775375692066e-05,
      "loss": 0.1823,
      "step": 7934
    },
    {
      "epoch": 0.47069640526752876,
      "grad_norm": 1.8919659852981567,
      "learning_rate": 1.1762457157922488e-05,
      "loss": 0.0104,
      "step": 7935
    },
    {
      "epoch": 0.47075572428520585,
      "grad_norm": 10.878273963928223,
      "learning_rate": 1.1761138940152914e-05,
      "loss": 0.3355,
      "step": 7936
    },
    {
      "epoch": 0.47081504330288293,
      "grad_norm": 0.057087790220975876,
      "learning_rate": 1.175982072238334e-05,
      "loss": 0.001,
      "step": 7937
    },
    {
      "epoch": 0.47087436232055996,
      "grad_norm": 0.01192737277597189,
      "learning_rate": 1.1758502504613763e-05,
      "loss": 0.0003,
      "step": 7938
    },
    {
      "epoch": 0.47093368133823704,
      "grad_norm": 63.60938262939453,
      "learning_rate": 1.1757184286844188e-05,
      "loss": 1.588,
      "step": 7939
    },
    {
      "epoch": 0.4709930003559141,
      "grad_norm": 9.559536933898926,
      "learning_rate": 1.1755866069074613e-05,
      "loss": 0.2593,
      "step": 7940
    },
    {
      "epoch": 0.47105231937359116,
      "grad_norm": 12.066696166992188,
      "learning_rate": 1.1754547851305037e-05,
      "loss": 0.1308,
      "step": 7941
    },
    {
      "epoch": 0.47111163839126824,
      "grad_norm": 0.024781903252005577,
      "learning_rate": 1.1753229633535461e-05,
      "loss": 0.0007,
      "step": 7942
    },
    {
      "epoch": 0.4711709574089453,
      "grad_norm": 32.6061897277832,
      "learning_rate": 1.1751911415765887e-05,
      "loss": 0.2305,
      "step": 7943
    },
    {
      "epoch": 0.47123027642662235,
      "grad_norm": 7.219752788543701,
      "learning_rate": 1.175059319799631e-05,
      "loss": 0.693,
      "step": 7944
    },
    {
      "epoch": 0.47128959544429944,
      "grad_norm": 0.23360584676265717,
      "learning_rate": 1.1749274980226735e-05,
      "loss": 0.0022,
      "step": 7945
    },
    {
      "epoch": 0.4713489144619765,
      "grad_norm": 16.279272079467773,
      "learning_rate": 1.174795676245716e-05,
      "loss": 0.4609,
      "step": 7946
    },
    {
      "epoch": 0.4714082334796536,
      "grad_norm": 0.3429228663444519,
      "learning_rate": 1.1746638544687584e-05,
      "loss": 0.0025,
      "step": 7947
    },
    {
      "epoch": 0.47146755249733063,
      "grad_norm": 7.649932384490967,
      "learning_rate": 1.1745320326918008e-05,
      "loss": 0.3759,
      "step": 7948
    },
    {
      "epoch": 0.4715268715150077,
      "grad_norm": 0.022304300218820572,
      "learning_rate": 1.1744002109148432e-05,
      "loss": 0.0006,
      "step": 7949
    },
    {
      "epoch": 0.4715861905326848,
      "grad_norm": 15.2222900390625,
      "learning_rate": 1.1742683891378856e-05,
      "loss": 0.2082,
      "step": 7950
    },
    {
      "epoch": 0.47164550955036183,
      "grad_norm": 4.639157772064209,
      "learning_rate": 1.1741365673609282e-05,
      "loss": 0.0582,
      "step": 7951
    },
    {
      "epoch": 0.4717048285680389,
      "grad_norm": 1.7352877855300903,
      "learning_rate": 1.1740047455839705e-05,
      "loss": 0.0202,
      "step": 7952
    },
    {
      "epoch": 0.471764147585716,
      "grad_norm": 14.458661079406738,
      "learning_rate": 1.173872923807013e-05,
      "loss": 0.623,
      "step": 7953
    },
    {
      "epoch": 0.471823466603393,
      "grad_norm": 0.474357545375824,
      "learning_rate": 1.1737411020300555e-05,
      "loss": 0.0034,
      "step": 7954
    },
    {
      "epoch": 0.4718827856210701,
      "grad_norm": 1.6524468660354614,
      "learning_rate": 1.1736092802530979e-05,
      "loss": 0.0273,
      "step": 7955
    },
    {
      "epoch": 0.4719421046387472,
      "grad_norm": 2.277716875076294,
      "learning_rate": 1.1734774584761403e-05,
      "loss": 0.0343,
      "step": 7956
    },
    {
      "epoch": 0.4720014236564242,
      "grad_norm": 1.3472654819488525,
      "learning_rate": 1.1733456366991829e-05,
      "loss": 0.0148,
      "step": 7957
    },
    {
      "epoch": 0.4720607426741013,
      "grad_norm": 3.882197380065918,
      "learning_rate": 1.1732138149222251e-05,
      "loss": 0.0481,
      "step": 7958
    },
    {
      "epoch": 0.4721200616917784,
      "grad_norm": 7.841294288635254,
      "learning_rate": 1.1730819931452677e-05,
      "loss": 0.2656,
      "step": 7959
    },
    {
      "epoch": 0.4721793807094555,
      "grad_norm": 11.30140209197998,
      "learning_rate": 1.1729501713683103e-05,
      "loss": 0.3622,
      "step": 7960
    },
    {
      "epoch": 0.4722386997271325,
      "grad_norm": 13.788878440856934,
      "learning_rate": 1.1728183495913526e-05,
      "loss": 0.1469,
      "step": 7961
    },
    {
      "epoch": 0.4722980187448096,
      "grad_norm": 3.6157050132751465,
      "learning_rate": 1.1726865278143952e-05,
      "loss": 0.1127,
      "step": 7962
    },
    {
      "epoch": 0.4723573377624867,
      "grad_norm": 0.04143183305859566,
      "learning_rate": 1.1725547060374374e-05,
      "loss": 0.0005,
      "step": 7963
    },
    {
      "epoch": 0.4724166567801637,
      "grad_norm": 0.056965362280607224,
      "learning_rate": 1.1724228842604798e-05,
      "loss": 0.0013,
      "step": 7964
    },
    {
      "epoch": 0.4724759757978408,
      "grad_norm": 0.44203823804855347,
      "learning_rate": 1.1722910624835224e-05,
      "loss": 0.0055,
      "step": 7965
    },
    {
      "epoch": 0.47253529481551787,
      "grad_norm": 5.853917598724365,
      "learning_rate": 1.1721592407065647e-05,
      "loss": 0.0867,
      "step": 7966
    },
    {
      "epoch": 0.4725946138331949,
      "grad_norm": 24.326404571533203,
      "learning_rate": 1.1720274189296072e-05,
      "loss": 0.2436,
      "step": 7967
    },
    {
      "epoch": 0.472653932850872,
      "grad_norm": 10.086267471313477,
      "learning_rate": 1.1718955971526498e-05,
      "loss": 0.6174,
      "step": 7968
    },
    {
      "epoch": 0.47271325186854907,
      "grad_norm": 1.7885291576385498,
      "learning_rate": 1.171763775375692e-05,
      "loss": 0.0162,
      "step": 7969
    },
    {
      "epoch": 0.47277257088622615,
      "grad_norm": 0.2783440351486206,
      "learning_rate": 1.1716319535987347e-05,
      "loss": 0.0025,
      "step": 7970
    },
    {
      "epoch": 0.4728318899039032,
      "grad_norm": 41.38077163696289,
      "learning_rate": 1.1715001318217771e-05,
      "loss": 0.6159,
      "step": 7971
    },
    {
      "epoch": 0.47289120892158026,
      "grad_norm": 0.01742514781653881,
      "learning_rate": 1.1713683100448195e-05,
      "loss": 0.0005,
      "step": 7972
    },
    {
      "epoch": 0.47295052793925735,
      "grad_norm": 7.438634395599365,
      "learning_rate": 1.171236488267862e-05,
      "loss": 0.088,
      "step": 7973
    },
    {
      "epoch": 0.4730098469569344,
      "grad_norm": 0.011163689196109772,
      "learning_rate": 1.1711046664909045e-05,
      "loss": 0.0004,
      "step": 7974
    },
    {
      "epoch": 0.47306916597461146,
      "grad_norm": 0.7151399254798889,
      "learning_rate": 1.1709728447139468e-05,
      "loss": 0.0086,
      "step": 7975
    },
    {
      "epoch": 0.47312848499228854,
      "grad_norm": 0.177596315741539,
      "learning_rate": 1.1708410229369894e-05,
      "loss": 0.0042,
      "step": 7976
    },
    {
      "epoch": 0.4731878040099656,
      "grad_norm": 0.0491221584379673,
      "learning_rate": 1.1707092011600318e-05,
      "loss": 0.0009,
      "step": 7977
    },
    {
      "epoch": 0.47324712302764266,
      "grad_norm": 11.882611274719238,
      "learning_rate": 1.1705773793830742e-05,
      "loss": 0.096,
      "step": 7978
    },
    {
      "epoch": 0.47330644204531974,
      "grad_norm": 15.518096923828125,
      "learning_rate": 1.1704455576061166e-05,
      "loss": 1.2015,
      "step": 7979
    },
    {
      "epoch": 0.47336576106299677,
      "grad_norm": 8.949139595031738,
      "learning_rate": 1.170313735829159e-05,
      "loss": 0.1982,
      "step": 7980
    },
    {
      "epoch": 0.47342508008067385,
      "grad_norm": 11.976741790771484,
      "learning_rate": 1.1701819140522014e-05,
      "loss": 0.4137,
      "step": 7981
    },
    {
      "epoch": 0.47348439909835094,
      "grad_norm": 8.804027557373047,
      "learning_rate": 1.170050092275244e-05,
      "loss": 0.5987,
      "step": 7982
    },
    {
      "epoch": 0.473543718116028,
      "grad_norm": 0.019843731075525284,
      "learning_rate": 1.1699182704982863e-05,
      "loss": 0.0005,
      "step": 7983
    },
    {
      "epoch": 0.47360303713370505,
      "grad_norm": 0.054180774837732315,
      "learning_rate": 1.1697864487213289e-05,
      "loss": 0.001,
      "step": 7984
    },
    {
      "epoch": 0.47366235615138214,
      "grad_norm": 8.905962944030762,
      "learning_rate": 1.1696546269443715e-05,
      "loss": 0.3172,
      "step": 7985
    },
    {
      "epoch": 0.4737216751690592,
      "grad_norm": 0.5967577695846558,
      "learning_rate": 1.1695228051674137e-05,
      "loss": 0.0072,
      "step": 7986
    },
    {
      "epoch": 0.47378099418673625,
      "grad_norm": 8.641744613647461,
      "learning_rate": 1.1693909833904561e-05,
      "loss": 0.5375,
      "step": 7987
    },
    {
      "epoch": 0.47384031320441333,
      "grad_norm": 41.626426696777344,
      "learning_rate": 1.1692591616134987e-05,
      "loss": 2.1137,
      "step": 7988
    },
    {
      "epoch": 0.4738996322220904,
      "grad_norm": 0.013511230237782001,
      "learning_rate": 1.169127339836541e-05,
      "loss": 0.0004,
      "step": 7989
    },
    {
      "epoch": 0.47395895123976745,
      "grad_norm": 1.8533514738082886,
      "learning_rate": 1.1689955180595836e-05,
      "loss": 0.0204,
      "step": 7990
    },
    {
      "epoch": 0.47401827025744453,
      "grad_norm": 0.7142041921615601,
      "learning_rate": 1.1688636962826261e-05,
      "loss": 0.0204,
      "step": 7991
    },
    {
      "epoch": 0.4740775892751216,
      "grad_norm": 1.4736909866333008,
      "learning_rate": 1.1687318745056684e-05,
      "loss": 0.0087,
      "step": 7992
    },
    {
      "epoch": 0.4741369082927987,
      "grad_norm": 1.1967873573303223,
      "learning_rate": 1.168600052728711e-05,
      "loss": 0.0099,
      "step": 7993
    },
    {
      "epoch": 0.4741962273104757,
      "grad_norm": 0.03787921369075775,
      "learning_rate": 1.1684682309517534e-05,
      "loss": 0.0011,
      "step": 7994
    },
    {
      "epoch": 0.4742555463281528,
      "grad_norm": 13.799347877502441,
      "learning_rate": 1.1683364091747958e-05,
      "loss": 0.1182,
      "step": 7995
    },
    {
      "epoch": 0.4743148653458299,
      "grad_norm": 0.36438488960266113,
      "learning_rate": 1.1682045873978382e-05,
      "loss": 0.0038,
      "step": 7996
    },
    {
      "epoch": 0.4743741843635069,
      "grad_norm": 0.27289071679115295,
      "learning_rate": 1.1680727656208805e-05,
      "loss": 0.0024,
      "step": 7997
    },
    {
      "epoch": 0.474433503381184,
      "grad_norm": 0.32898077368736267,
      "learning_rate": 1.167940943843923e-05,
      "loss": 0.0023,
      "step": 7998
    },
    {
      "epoch": 0.4744928223988611,
      "grad_norm": 12.907736778259277,
      "learning_rate": 1.1678091220669657e-05,
      "loss": 0.218,
      "step": 7999
    },
    {
      "epoch": 0.4745521414165381,
      "grad_norm": 14.613128662109375,
      "learning_rate": 1.1676773002900079e-05,
      "loss": 0.475,
      "step": 8000
    },
    {
      "epoch": 0.4746114604342152,
      "grad_norm": 8.445932388305664,
      "learning_rate": 1.1675454785130505e-05,
      "loss": 0.3069,
      "step": 8001
    },
    {
      "epoch": 0.4746707794518923,
      "grad_norm": 3.150261402130127,
      "learning_rate": 1.1674136567360929e-05,
      "loss": 0.0261,
      "step": 8002
    },
    {
      "epoch": 0.4747300984695693,
      "grad_norm": 12.586771965026855,
      "learning_rate": 1.1672818349591353e-05,
      "loss": 0.1423,
      "step": 8003
    },
    {
      "epoch": 0.4747894174872464,
      "grad_norm": 5.340322017669678,
      "learning_rate": 1.1671500131821778e-05,
      "loss": 0.0941,
      "step": 8004
    },
    {
      "epoch": 0.4748487365049235,
      "grad_norm": 0.8741593360900879,
      "learning_rate": 1.1670181914052203e-05,
      "loss": 0.0099,
      "step": 8005
    },
    {
      "epoch": 0.47490805552260057,
      "grad_norm": 0.6519774794578552,
      "learning_rate": 1.1668863696282626e-05,
      "loss": 0.0055,
      "step": 8006
    },
    {
      "epoch": 0.4749673745402776,
      "grad_norm": 3.997995615005493,
      "learning_rate": 1.1667545478513052e-05,
      "loss": 0.492,
      "step": 8007
    },
    {
      "epoch": 0.4750266935579547,
      "grad_norm": 0.01884823478758335,
      "learning_rate": 1.1666227260743476e-05,
      "loss": 0.0003,
      "step": 8008
    },
    {
      "epoch": 0.47508601257563177,
      "grad_norm": 10.73056697845459,
      "learning_rate": 1.16649090429739e-05,
      "loss": 0.4956,
      "step": 8009
    },
    {
      "epoch": 0.4751453315933088,
      "grad_norm": 25.786754608154297,
      "learning_rate": 1.1663590825204324e-05,
      "loss": 0.9283,
      "step": 8010
    },
    {
      "epoch": 0.4752046506109859,
      "grad_norm": 2.3845231533050537,
      "learning_rate": 1.1662272607434749e-05,
      "loss": 0.0327,
      "step": 8011
    },
    {
      "epoch": 0.47526396962866296,
      "grad_norm": 2.9734723567962646,
      "learning_rate": 1.1660954389665173e-05,
      "loss": 0.0244,
      "step": 8012
    },
    {
      "epoch": 0.47532328864634,
      "grad_norm": 17.097070693969727,
      "learning_rate": 1.1659636171895599e-05,
      "loss": 0.2206,
      "step": 8013
    },
    {
      "epoch": 0.4753826076640171,
      "grad_norm": 14.671150207519531,
      "learning_rate": 1.1658317954126021e-05,
      "loss": 0.4986,
      "step": 8014
    },
    {
      "epoch": 0.47544192668169416,
      "grad_norm": 2.3411879539489746,
      "learning_rate": 1.1656999736356447e-05,
      "loss": 0.033,
      "step": 8015
    },
    {
      "epoch": 0.47550124569937124,
      "grad_norm": 3.2123489379882812,
      "learning_rate": 1.1655681518586873e-05,
      "loss": 0.0358,
      "step": 8016
    },
    {
      "epoch": 0.4755605647170483,
      "grad_norm": 0.7336075901985168,
      "learning_rate": 1.1654363300817295e-05,
      "loss": 0.0117,
      "step": 8017
    },
    {
      "epoch": 0.47561988373472536,
      "grad_norm": 1.2987306118011475,
      "learning_rate": 1.1653045083047721e-05,
      "loss": 0.0106,
      "step": 8018
    },
    {
      "epoch": 0.47567920275240244,
      "grad_norm": 3.523270845413208,
      "learning_rate": 1.1651726865278145e-05,
      "loss": 0.1851,
      "step": 8019
    },
    {
      "epoch": 0.47573852177007947,
      "grad_norm": 0.042798422276973724,
      "learning_rate": 1.1650408647508568e-05,
      "loss": 0.0011,
      "step": 8020
    },
    {
      "epoch": 0.47579784078775655,
      "grad_norm": 1.7086008787155151,
      "learning_rate": 1.1649090429738994e-05,
      "loss": 0.0097,
      "step": 8021
    },
    {
      "epoch": 0.47585715980543364,
      "grad_norm": 0.17104636132717133,
      "learning_rate": 1.164777221196942e-05,
      "loss": 0.0021,
      "step": 8022
    },
    {
      "epoch": 0.47591647882311067,
      "grad_norm": 0.6901227235794067,
      "learning_rate": 1.1646453994199842e-05,
      "loss": 0.0077,
      "step": 8023
    },
    {
      "epoch": 0.47597579784078775,
      "grad_norm": 14.952271461486816,
      "learning_rate": 1.1645135776430268e-05,
      "loss": 0.6447,
      "step": 8024
    },
    {
      "epoch": 0.47603511685846484,
      "grad_norm": 31.00429344177246,
      "learning_rate": 1.1643817558660692e-05,
      "loss": 0.5381,
      "step": 8025
    },
    {
      "epoch": 0.47609443587614186,
      "grad_norm": 6.800888538360596,
      "learning_rate": 1.1642499340891116e-05,
      "loss": 0.1322,
      "step": 8026
    },
    {
      "epoch": 0.47615375489381895,
      "grad_norm": 9.270965576171875,
      "learning_rate": 1.164118112312154e-05,
      "loss": 0.7043,
      "step": 8027
    },
    {
      "epoch": 0.47621307391149603,
      "grad_norm": 7.332754611968994,
      "learning_rate": 1.1639862905351965e-05,
      "loss": 0.1236,
      "step": 8028
    },
    {
      "epoch": 0.4762723929291731,
      "grad_norm": 0.5889912247657776,
      "learning_rate": 1.1638544687582389e-05,
      "loss": 0.0113,
      "step": 8029
    },
    {
      "epoch": 0.47633171194685014,
      "grad_norm": 1.9469259977340698,
      "learning_rate": 1.1637226469812815e-05,
      "loss": 0.0097,
      "step": 8030
    },
    {
      "epoch": 0.47639103096452723,
      "grad_norm": 0.04007573798298836,
      "learning_rate": 1.1635908252043237e-05,
      "loss": 0.0005,
      "step": 8031
    },
    {
      "epoch": 0.4764503499822043,
      "grad_norm": 0.009738677181303501,
      "learning_rate": 1.1634590034273663e-05,
      "loss": 0.0004,
      "step": 8032
    },
    {
      "epoch": 0.47650966899988134,
      "grad_norm": 5.5460333824157715,
      "learning_rate": 1.1633271816504087e-05,
      "loss": 0.1197,
      "step": 8033
    },
    {
      "epoch": 0.4765689880175584,
      "grad_norm": 0.0811842828989029,
      "learning_rate": 1.1631953598734512e-05,
      "loss": 0.0012,
      "step": 8034
    },
    {
      "epoch": 0.4766283070352355,
      "grad_norm": 0.21108274161815643,
      "learning_rate": 1.1630635380964936e-05,
      "loss": 0.0024,
      "step": 8035
    },
    {
      "epoch": 0.47668762605291254,
      "grad_norm": 8.376439094543457,
      "learning_rate": 1.1629317163195362e-05,
      "loss": 0.0696,
      "step": 8036
    },
    {
      "epoch": 0.4767469450705896,
      "grad_norm": 36.970664978027344,
      "learning_rate": 1.1627998945425784e-05,
      "loss": 1.0641,
      "step": 8037
    },
    {
      "epoch": 0.4768062640882667,
      "grad_norm": 0.3487875759601593,
      "learning_rate": 1.162668072765621e-05,
      "loss": 0.0042,
      "step": 8038
    },
    {
      "epoch": 0.4768655831059438,
      "grad_norm": 16.42621612548828,
      "learning_rate": 1.1625362509886636e-05,
      "loss": 0.5043,
      "step": 8039
    },
    {
      "epoch": 0.4769249021236208,
      "grad_norm": 5.409397125244141,
      "learning_rate": 1.1624044292117058e-05,
      "loss": 0.0389,
      "step": 8040
    },
    {
      "epoch": 0.4769842211412979,
      "grad_norm": 0.10035679489374161,
      "learning_rate": 1.1622726074347483e-05,
      "loss": 0.0024,
      "step": 8041
    },
    {
      "epoch": 0.477043540158975,
      "grad_norm": 3.3254754543304443,
      "learning_rate": 1.1621407856577908e-05,
      "loss": 0.2371,
      "step": 8042
    },
    {
      "epoch": 0.477102859176652,
      "grad_norm": 0.9166010022163391,
      "learning_rate": 1.1620089638808331e-05,
      "loss": 0.0183,
      "step": 8043
    },
    {
      "epoch": 0.4771621781943291,
      "grad_norm": 0.02904762141406536,
      "learning_rate": 1.1618771421038757e-05,
      "loss": 0.0006,
      "step": 8044
    },
    {
      "epoch": 0.4772214972120062,
      "grad_norm": 0.4849204421043396,
      "learning_rate": 1.161745320326918e-05,
      "loss": 0.0057,
      "step": 8045
    },
    {
      "epoch": 0.4772808162296832,
      "grad_norm": 0.005187524016946554,
      "learning_rate": 1.1616134985499605e-05,
      "loss": 0.0002,
      "step": 8046
    },
    {
      "epoch": 0.4773401352473603,
      "grad_norm": 0.1674032062292099,
      "learning_rate": 1.1614816767730031e-05,
      "loss": 0.0033,
      "step": 8047
    },
    {
      "epoch": 0.4773994542650374,
      "grad_norm": 4.182593822479248,
      "learning_rate": 1.1613498549960454e-05,
      "loss": 0.0564,
      "step": 8048
    },
    {
      "epoch": 0.47745877328271447,
      "grad_norm": 12.920751571655273,
      "learning_rate": 1.161218033219088e-05,
      "loss": 0.1807,
      "step": 8049
    },
    {
      "epoch": 0.4775180923003915,
      "grad_norm": 8.457406044006348,
      "learning_rate": 1.1610862114421304e-05,
      "loss": 0.1759,
      "step": 8050
    },
    {
      "epoch": 0.4775774113180686,
      "grad_norm": 0.007190500386059284,
      "learning_rate": 1.1609543896651728e-05,
      "loss": 0.0002,
      "step": 8051
    },
    {
      "epoch": 0.47763673033574566,
      "grad_norm": 21.02871322631836,
      "learning_rate": 1.1608225678882152e-05,
      "loss": 0.2942,
      "step": 8052
    },
    {
      "epoch": 0.4776960493534227,
      "grad_norm": 0.010424485430121422,
      "learning_rate": 1.1606907461112578e-05,
      "loss": 0.0004,
      "step": 8053
    },
    {
      "epoch": 0.4777553683710998,
      "grad_norm": 0.745772123336792,
      "learning_rate": 1.1605589243343e-05,
      "loss": 0.0068,
      "step": 8054
    },
    {
      "epoch": 0.47781468738877686,
      "grad_norm": 15.70529556274414,
      "learning_rate": 1.1604271025573426e-05,
      "loss": 0.5974,
      "step": 8055
    },
    {
      "epoch": 0.4778740064064539,
      "grad_norm": 63.17398452758789,
      "learning_rate": 1.160295280780385e-05,
      "loss": 0.6583,
      "step": 8056
    },
    {
      "epoch": 0.477933325424131,
      "grad_norm": 1.2304167747497559,
      "learning_rate": 1.1601634590034275e-05,
      "loss": 0.01,
      "step": 8057
    },
    {
      "epoch": 0.47799264444180806,
      "grad_norm": 4.7543206214904785,
      "learning_rate": 1.1600316372264699e-05,
      "loss": 0.3227,
      "step": 8058
    },
    {
      "epoch": 0.4780519634594851,
      "grad_norm": 0.026118233799934387,
      "learning_rate": 1.1598998154495123e-05,
      "loss": 0.0006,
      "step": 8059
    },
    {
      "epoch": 0.47811128247716217,
      "grad_norm": 14.052733421325684,
      "learning_rate": 1.1597679936725547e-05,
      "loss": 0.1301,
      "step": 8060
    },
    {
      "epoch": 0.47817060149483925,
      "grad_norm": 4.850780487060547,
      "learning_rate": 1.1596361718955973e-05,
      "loss": 0.2009,
      "step": 8061
    },
    {
      "epoch": 0.47822992051251634,
      "grad_norm": 7.067989826202393,
      "learning_rate": 1.1595043501186396e-05,
      "loss": 0.3013,
      "step": 8062
    },
    {
      "epoch": 0.47828923953019337,
      "grad_norm": 0.0061046467162668705,
      "learning_rate": 1.1593725283416822e-05,
      "loss": 0.0002,
      "step": 8063
    },
    {
      "epoch": 0.47834855854787045,
      "grad_norm": 0.6848585605621338,
      "learning_rate": 1.1592407065647246e-05,
      "loss": 0.0072,
      "step": 8064
    },
    {
      "epoch": 0.47840787756554753,
      "grad_norm": 0.183802530169487,
      "learning_rate": 1.159108884787767e-05,
      "loss": 0.0024,
      "step": 8065
    },
    {
      "epoch": 0.47846719658322456,
      "grad_norm": 0.07288384437561035,
      "learning_rate": 1.1589770630108094e-05,
      "loss": 0.0014,
      "step": 8066
    },
    {
      "epoch": 0.47852651560090165,
      "grad_norm": 7.214820384979248,
      "learning_rate": 1.158845241233852e-05,
      "loss": 0.282,
      "step": 8067
    },
    {
      "epoch": 0.47858583461857873,
      "grad_norm": 26.341259002685547,
      "learning_rate": 1.1587134194568942e-05,
      "loss": 1.1842,
      "step": 8068
    },
    {
      "epoch": 0.47864515363625576,
      "grad_norm": 0.20816762745380402,
      "learning_rate": 1.1585815976799368e-05,
      "loss": 0.0037,
      "step": 8069
    },
    {
      "epoch": 0.47870447265393284,
      "grad_norm": 0.03052617982029915,
      "learning_rate": 1.1584497759029794e-05,
      "loss": 0.0009,
      "step": 8070
    },
    {
      "epoch": 0.47876379167160993,
      "grad_norm": 0.867635190486908,
      "learning_rate": 1.1583179541260217e-05,
      "loss": 0.0083,
      "step": 8071
    },
    {
      "epoch": 0.478823110689287,
      "grad_norm": 13.124080657958984,
      "learning_rate": 1.1581861323490643e-05,
      "loss": 0.1281,
      "step": 8072
    },
    {
      "epoch": 0.47888242970696404,
      "grad_norm": 5.376345634460449,
      "learning_rate": 1.1580543105721067e-05,
      "loss": 0.0571,
      "step": 8073
    },
    {
      "epoch": 0.4789417487246411,
      "grad_norm": 0.02756248041987419,
      "learning_rate": 1.1579224887951491e-05,
      "loss": 0.0005,
      "step": 8074
    },
    {
      "epoch": 0.4790010677423182,
      "grad_norm": 0.34238654375076294,
      "learning_rate": 1.1577906670181915e-05,
      "loss": 0.0029,
      "step": 8075
    },
    {
      "epoch": 0.47906038675999524,
      "grad_norm": 0.3033027946949005,
      "learning_rate": 1.1576588452412338e-05,
      "loss": 0.0037,
      "step": 8076
    },
    {
      "epoch": 0.4791197057776723,
      "grad_norm": 0.0457046739757061,
      "learning_rate": 1.1575270234642764e-05,
      "loss": 0.0009,
      "step": 8077
    },
    {
      "epoch": 0.4791790247953494,
      "grad_norm": 1.2689324617385864,
      "learning_rate": 1.157395201687319e-05,
      "loss": 0.0174,
      "step": 8078
    },
    {
      "epoch": 0.47923834381302644,
      "grad_norm": 9.5127534866333,
      "learning_rate": 1.1572633799103612e-05,
      "loss": 0.5842,
      "step": 8079
    },
    {
      "epoch": 0.4792976628307035,
      "grad_norm": 4.090610027313232,
      "learning_rate": 1.1571315581334038e-05,
      "loss": 0.2461,
      "step": 8080
    },
    {
      "epoch": 0.4793569818483806,
      "grad_norm": 0.5409618020057678,
      "learning_rate": 1.1569997363564462e-05,
      "loss": 0.0075,
      "step": 8081
    },
    {
      "epoch": 0.47941630086605763,
      "grad_norm": 0.07585057616233826,
      "learning_rate": 1.1568679145794886e-05,
      "loss": 0.0019,
      "step": 8082
    },
    {
      "epoch": 0.4794756198837347,
      "grad_norm": 0.16803915798664093,
      "learning_rate": 1.156736092802531e-05,
      "loss": 0.0031,
      "step": 8083
    },
    {
      "epoch": 0.4795349389014118,
      "grad_norm": 0.21892616152763367,
      "learning_rate": 1.1566042710255736e-05,
      "loss": 0.0032,
      "step": 8084
    },
    {
      "epoch": 0.4795942579190889,
      "grad_norm": 0.020149780437350273,
      "learning_rate": 1.1564724492486159e-05,
      "loss": 0.0005,
      "step": 8085
    },
    {
      "epoch": 0.4796535769367659,
      "grad_norm": 5.242621421813965,
      "learning_rate": 1.1563406274716585e-05,
      "loss": 0.3043,
      "step": 8086
    },
    {
      "epoch": 0.479712895954443,
      "grad_norm": 13.829689979553223,
      "learning_rate": 1.1562088056947009e-05,
      "loss": 0.1274,
      "step": 8087
    },
    {
      "epoch": 0.4797722149721201,
      "grad_norm": 0.01291075348854065,
      "learning_rate": 1.1560769839177433e-05,
      "loss": 0.0004,
      "step": 8088
    },
    {
      "epoch": 0.4798315339897971,
      "grad_norm": 12.137420654296875,
      "learning_rate": 1.1559451621407857e-05,
      "loss": 0.3481,
      "step": 8089
    },
    {
      "epoch": 0.4798908530074742,
      "grad_norm": 21.19107437133789,
      "learning_rate": 1.1558133403638283e-05,
      "loss": 0.9751,
      "step": 8090
    },
    {
      "epoch": 0.4799501720251513,
      "grad_norm": 1.2834159135818481,
      "learning_rate": 1.1556815185868706e-05,
      "loss": 0.0094,
      "step": 8091
    },
    {
      "epoch": 0.4800094910428283,
      "grad_norm": 0.13696156442165375,
      "learning_rate": 1.1555496968099131e-05,
      "loss": 0.0027,
      "step": 8092
    },
    {
      "epoch": 0.4800688100605054,
      "grad_norm": 40.27865219116211,
      "learning_rate": 1.1554178750329554e-05,
      "loss": 0.1244,
      "step": 8093
    },
    {
      "epoch": 0.4801281290781825,
      "grad_norm": 0.9264419674873352,
      "learning_rate": 1.155286053255998e-05,
      "loss": 0.0112,
      "step": 8094
    },
    {
      "epoch": 0.48018744809585956,
      "grad_norm": 0.05939004197716713,
      "learning_rate": 1.1551542314790406e-05,
      "loss": 0.001,
      "step": 8095
    },
    {
      "epoch": 0.4802467671135366,
      "grad_norm": 0.7482256293296814,
      "learning_rate": 1.1550224097020828e-05,
      "loss": 0.0106,
      "step": 8096
    },
    {
      "epoch": 0.48030608613121367,
      "grad_norm": 3.572866678237915,
      "learning_rate": 1.1548905879251252e-05,
      "loss": 0.0238,
      "step": 8097
    },
    {
      "epoch": 0.48036540514889076,
      "grad_norm": 4.911509037017822,
      "learning_rate": 1.1547587661481678e-05,
      "loss": 0.3228,
      "step": 8098
    },
    {
      "epoch": 0.4804247241665678,
      "grad_norm": 0.029932426288723946,
      "learning_rate": 1.15462694437121e-05,
      "loss": 0.0008,
      "step": 8099
    },
    {
      "epoch": 0.48048404318424487,
      "grad_norm": 7.846895694732666,
      "learning_rate": 1.1544951225942527e-05,
      "loss": 0.0413,
      "step": 8100
    },
    {
      "epoch": 0.48054336220192195,
      "grad_norm": 16.636585235595703,
      "learning_rate": 1.1543633008172952e-05,
      "loss": 0.5044,
      "step": 8101
    },
    {
      "epoch": 0.480602681219599,
      "grad_norm": 9.249361038208008,
      "learning_rate": 1.1542314790403375e-05,
      "loss": 0.169,
      "step": 8102
    },
    {
      "epoch": 0.48066200023727607,
      "grad_norm": 0.029842345044016838,
      "learning_rate": 1.15409965726338e-05,
      "loss": 0.0005,
      "step": 8103
    },
    {
      "epoch": 0.48072131925495315,
      "grad_norm": 0.17668598890304565,
      "learning_rate": 1.1539678354864225e-05,
      "loss": 0.0022,
      "step": 8104
    },
    {
      "epoch": 0.4807806382726302,
      "grad_norm": 0.014010914601385593,
      "learning_rate": 1.153836013709465e-05,
      "loss": 0.0003,
      "step": 8105
    },
    {
      "epoch": 0.48083995729030726,
      "grad_norm": 2.1890952587127686,
      "learning_rate": 1.1537041919325073e-05,
      "loss": 0.0612,
      "step": 8106
    },
    {
      "epoch": 0.48089927630798435,
      "grad_norm": 0.09794716536998749,
      "learning_rate": 1.1535723701555498e-05,
      "loss": 0.0011,
      "step": 8107
    },
    {
      "epoch": 0.48095859532566143,
      "grad_norm": 0.009226369671523571,
      "learning_rate": 1.1534405483785922e-05,
      "loss": 0.0002,
      "step": 8108
    },
    {
      "epoch": 0.48101791434333846,
      "grad_norm": 7.377968788146973,
      "learning_rate": 1.1533087266016348e-05,
      "loss": 0.4627,
      "step": 8109
    },
    {
      "epoch": 0.48107723336101554,
      "grad_norm": 0.04010939970612526,
      "learning_rate": 1.153176904824677e-05,
      "loss": 0.0011,
      "step": 8110
    },
    {
      "epoch": 0.48113655237869263,
      "grad_norm": 0.05371289327740669,
      "learning_rate": 1.1530450830477196e-05,
      "loss": 0.0012,
      "step": 8111
    },
    {
      "epoch": 0.48119587139636966,
      "grad_norm": 0.4408079981803894,
      "learning_rate": 1.152913261270762e-05,
      "loss": 0.0038,
      "step": 8112
    },
    {
      "epoch": 0.48125519041404674,
      "grad_norm": 4.842446804046631,
      "learning_rate": 1.1527814394938044e-05,
      "loss": 0.0193,
      "step": 8113
    },
    {
      "epoch": 0.4813145094317238,
      "grad_norm": 6.189944744110107,
      "learning_rate": 1.1526496177168469e-05,
      "loss": 0.1358,
      "step": 8114
    },
    {
      "epoch": 0.48137382844940085,
      "grad_norm": 0.014245852828025818,
      "learning_rate": 1.1525177959398894e-05,
      "loss": 0.0005,
      "step": 8115
    },
    {
      "epoch": 0.48143314746707794,
      "grad_norm": 10.656808853149414,
      "learning_rate": 1.1523859741629317e-05,
      "loss": 0.3154,
      "step": 8116
    },
    {
      "epoch": 0.481492466484755,
      "grad_norm": 31.231239318847656,
      "learning_rate": 1.1522541523859743e-05,
      "loss": 0.3027,
      "step": 8117
    },
    {
      "epoch": 0.4815517855024321,
      "grad_norm": 0.10263818502426147,
      "learning_rate": 1.1521223306090169e-05,
      "loss": 0.0014,
      "step": 8118
    },
    {
      "epoch": 0.48161110452010913,
      "grad_norm": 6.95077657699585,
      "learning_rate": 1.1519905088320591e-05,
      "loss": 0.6273,
      "step": 8119
    },
    {
      "epoch": 0.4816704235377862,
      "grad_norm": 13.022056579589844,
      "learning_rate": 1.1518586870551015e-05,
      "loss": 0.3321,
      "step": 8120
    },
    {
      "epoch": 0.4817297425554633,
      "grad_norm": 0.012193339876830578,
      "learning_rate": 1.1517268652781441e-05,
      "loss": 0.0004,
      "step": 8121
    },
    {
      "epoch": 0.48178906157314033,
      "grad_norm": 6.381526947021484,
      "learning_rate": 1.1515950435011864e-05,
      "loss": 0.0629,
      "step": 8122
    },
    {
      "epoch": 0.4818483805908174,
      "grad_norm": 14.553059577941895,
      "learning_rate": 1.151463221724229e-05,
      "loss": 0.2184,
      "step": 8123
    },
    {
      "epoch": 0.4819076996084945,
      "grad_norm": 12.230521202087402,
      "learning_rate": 1.1513313999472712e-05,
      "loss": 0.1545,
      "step": 8124
    },
    {
      "epoch": 0.48196701862617153,
      "grad_norm": 0.09993867576122284,
      "learning_rate": 1.1511995781703138e-05,
      "loss": 0.0012,
      "step": 8125
    },
    {
      "epoch": 0.4820263376438486,
      "grad_norm": 0.1641681045293808,
      "learning_rate": 1.1510677563933564e-05,
      "loss": 0.0018,
      "step": 8126
    },
    {
      "epoch": 0.4820856566615257,
      "grad_norm": 0.37092551589012146,
      "learning_rate": 1.1509359346163986e-05,
      "loss": 0.0057,
      "step": 8127
    },
    {
      "epoch": 0.4821449756792027,
      "grad_norm": 8.383131980895996,
      "learning_rate": 1.1508041128394412e-05,
      "loss": 0.1955,
      "step": 8128
    },
    {
      "epoch": 0.4822042946968798,
      "grad_norm": 20.65209197998047,
      "learning_rate": 1.1506722910624836e-05,
      "loss": 0.3907,
      "step": 8129
    },
    {
      "epoch": 0.4822636137145569,
      "grad_norm": 0.250127375125885,
      "learning_rate": 1.150540469285526e-05,
      "loss": 0.0021,
      "step": 8130
    },
    {
      "epoch": 0.482322932732234,
      "grad_norm": 0.2896215617656708,
      "learning_rate": 1.1504086475085685e-05,
      "loss": 0.0018,
      "step": 8131
    },
    {
      "epoch": 0.482382251749911,
      "grad_norm": 0.22972995042800903,
      "learning_rate": 1.150276825731611e-05,
      "loss": 0.0029,
      "step": 8132
    },
    {
      "epoch": 0.4824415707675881,
      "grad_norm": 0.29818180203437805,
      "learning_rate": 1.1501450039546533e-05,
      "loss": 0.0037,
      "step": 8133
    },
    {
      "epoch": 0.4825008897852652,
      "grad_norm": 0.5293298959732056,
      "learning_rate": 1.1500131821776959e-05,
      "loss": 0.0047,
      "step": 8134
    },
    {
      "epoch": 0.4825602088029422,
      "grad_norm": 13.63662052154541,
      "learning_rate": 1.1498813604007383e-05,
      "loss": 0.6949,
      "step": 8135
    },
    {
      "epoch": 0.4826195278206193,
      "grad_norm": 0.08632031083106995,
      "learning_rate": 1.1497495386237807e-05,
      "loss": 0.0017,
      "step": 8136
    },
    {
      "epoch": 0.48267884683829637,
      "grad_norm": 1.7387436628341675,
      "learning_rate": 1.1496177168468232e-05,
      "loss": 0.0151,
      "step": 8137
    },
    {
      "epoch": 0.4827381658559734,
      "grad_norm": 6.2844624519348145,
      "learning_rate": 1.1494858950698658e-05,
      "loss": 0.1158,
      "step": 8138
    },
    {
      "epoch": 0.4827974848736505,
      "grad_norm": 0.012868362478911877,
      "learning_rate": 1.149354073292908e-05,
      "loss": 0.0003,
      "step": 8139
    },
    {
      "epoch": 0.48285680389132757,
      "grad_norm": 6.666425704956055,
      "learning_rate": 1.1492222515159506e-05,
      "loss": 0.1465,
      "step": 8140
    },
    {
      "epoch": 0.48291612290900465,
      "grad_norm": 0.3170150816440582,
      "learning_rate": 1.1490904297389928e-05,
      "loss": 0.0047,
      "step": 8141
    },
    {
      "epoch": 0.4829754419266817,
      "grad_norm": 31.015888214111328,
      "learning_rate": 1.1489586079620354e-05,
      "loss": 0.2129,
      "step": 8142
    },
    {
      "epoch": 0.48303476094435877,
      "grad_norm": 9.986664772033691,
      "learning_rate": 1.1488267861850778e-05,
      "loss": 0.6934,
      "step": 8143
    },
    {
      "epoch": 0.48309407996203585,
      "grad_norm": 10.653594970703125,
      "learning_rate": 1.1486949644081203e-05,
      "loss": 0.1696,
      "step": 8144
    },
    {
      "epoch": 0.4831533989797129,
      "grad_norm": 16.679950714111328,
      "learning_rate": 1.1485631426311627e-05,
      "loss": 0.1446,
      "step": 8145
    },
    {
      "epoch": 0.48321271799738996,
      "grad_norm": 9.51630687713623,
      "learning_rate": 1.1484313208542053e-05,
      "loss": 0.1607,
      "step": 8146
    },
    {
      "epoch": 0.48327203701506705,
      "grad_norm": 8.552639961242676,
      "learning_rate": 1.1482994990772475e-05,
      "loss": 0.5442,
      "step": 8147
    },
    {
      "epoch": 0.4833313560327441,
      "grad_norm": 0.11209646612405777,
      "learning_rate": 1.1481676773002901e-05,
      "loss": 0.0024,
      "step": 8148
    },
    {
      "epoch": 0.48339067505042116,
      "grad_norm": 0.2537441551685333,
      "learning_rate": 1.1480358555233327e-05,
      "loss": 0.0033,
      "step": 8149
    },
    {
      "epoch": 0.48344999406809824,
      "grad_norm": 2.7208142280578613,
      "learning_rate": 1.147904033746375e-05,
      "loss": 0.0166,
      "step": 8150
    },
    {
      "epoch": 0.48350931308577527,
      "grad_norm": 5.358729839324951,
      "learning_rate": 1.1477722119694175e-05,
      "loss": 0.0365,
      "step": 8151
    },
    {
      "epoch": 0.48356863210345236,
      "grad_norm": 0.0608547069132328,
      "learning_rate": 1.14764039019246e-05,
      "loss": 0.0005,
      "step": 8152
    },
    {
      "epoch": 0.48362795112112944,
      "grad_norm": 12.019505500793457,
      "learning_rate": 1.1475085684155022e-05,
      "loss": 0.1458,
      "step": 8153
    },
    {
      "epoch": 0.4836872701388065,
      "grad_norm": 20.565109252929688,
      "learning_rate": 1.1473767466385448e-05,
      "loss": 0.0892,
      "step": 8154
    },
    {
      "epoch": 0.48374658915648355,
      "grad_norm": 18.35384750366211,
      "learning_rate": 1.147244924861587e-05,
      "loss": 0.5816,
      "step": 8155
    },
    {
      "epoch": 0.48380590817416064,
      "grad_norm": 0.012820718809962273,
      "learning_rate": 1.1471131030846296e-05,
      "loss": 0.0003,
      "step": 8156
    },
    {
      "epoch": 0.4838652271918377,
      "grad_norm": 4.188677787780762,
      "learning_rate": 1.1469812813076722e-05,
      "loss": 0.067,
      "step": 8157
    },
    {
      "epoch": 0.48392454620951475,
      "grad_norm": 6.554516315460205,
      "learning_rate": 1.1468494595307145e-05,
      "loss": 0.0903,
      "step": 8158
    },
    {
      "epoch": 0.48398386522719183,
      "grad_norm": 18.274629592895508,
      "learning_rate": 1.146717637753757e-05,
      "loss": 0.2235,
      "step": 8159
    },
    {
      "epoch": 0.4840431842448689,
      "grad_norm": 22.330371856689453,
      "learning_rate": 1.1465858159767995e-05,
      "loss": 0.1189,
      "step": 8160
    },
    {
      "epoch": 0.48410250326254595,
      "grad_norm": 0.016178132966160774,
      "learning_rate": 1.1464539941998419e-05,
      "loss": 0.0004,
      "step": 8161
    },
    {
      "epoch": 0.48416182228022303,
      "grad_norm": 0.01542116329073906,
      "learning_rate": 1.1463221724228843e-05,
      "loss": 0.0003,
      "step": 8162
    },
    {
      "epoch": 0.4842211412979001,
      "grad_norm": 4.3129191398620605,
      "learning_rate": 1.1461903506459269e-05,
      "loss": 0.3208,
      "step": 8163
    },
    {
      "epoch": 0.4842804603155772,
      "grad_norm": 0.5332498550415039,
      "learning_rate": 1.1460585288689692e-05,
      "loss": 0.0118,
      "step": 8164
    },
    {
      "epoch": 0.48433977933325423,
      "grad_norm": 0.013221317902207375,
      "learning_rate": 1.1459267070920117e-05,
      "loss": 0.0003,
      "step": 8165
    },
    {
      "epoch": 0.4843990983509313,
      "grad_norm": 11.363821983337402,
      "learning_rate": 1.1457948853150542e-05,
      "loss": 0.306,
      "step": 8166
    },
    {
      "epoch": 0.4844584173686084,
      "grad_norm": 10.620003700256348,
      "learning_rate": 1.1456630635380966e-05,
      "loss": 0.8327,
      "step": 8167
    },
    {
      "epoch": 0.4845177363862854,
      "grad_norm": 14.507621765136719,
      "learning_rate": 1.145531241761139e-05,
      "loss": 0.0654,
      "step": 8168
    },
    {
      "epoch": 0.4845770554039625,
      "grad_norm": 4.582154273986816,
      "learning_rate": 1.1453994199841816e-05,
      "loss": 0.1006,
      "step": 8169
    },
    {
      "epoch": 0.4846363744216396,
      "grad_norm": 18.60161018371582,
      "learning_rate": 1.1452675982072238e-05,
      "loss": 0.1655,
      "step": 8170
    },
    {
      "epoch": 0.4846956934393166,
      "grad_norm": 1.1183528900146484,
      "learning_rate": 1.1451357764302664e-05,
      "loss": 0.0109,
      "step": 8171
    },
    {
      "epoch": 0.4847550124569937,
      "grad_norm": 13.061548233032227,
      "learning_rate": 1.1450039546533087e-05,
      "loss": 0.3196,
      "step": 8172
    },
    {
      "epoch": 0.4848143314746708,
      "grad_norm": 0.3553895056247711,
      "learning_rate": 1.1448721328763513e-05,
      "loss": 0.0045,
      "step": 8173
    },
    {
      "epoch": 0.4848736504923479,
      "grad_norm": 12.73409366607666,
      "learning_rate": 1.1447403110993938e-05,
      "loss": 0.3376,
      "step": 8174
    },
    {
      "epoch": 0.4849329695100249,
      "grad_norm": 0.18849390745162964,
      "learning_rate": 1.1446084893224361e-05,
      "loss": 0.0052,
      "step": 8175
    },
    {
      "epoch": 0.484992288527702,
      "grad_norm": 0.0957343727350235,
      "learning_rate": 1.1444766675454785e-05,
      "loss": 0.0008,
      "step": 8176
    },
    {
      "epoch": 0.48505160754537907,
      "grad_norm": 2.0021564960479736,
      "learning_rate": 1.1443448457685211e-05,
      "loss": 0.0157,
      "step": 8177
    },
    {
      "epoch": 0.4851109265630561,
      "grad_norm": 17.56563377380371,
      "learning_rate": 1.1442130239915634e-05,
      "loss": 0.5412,
      "step": 8178
    },
    {
      "epoch": 0.4851702455807332,
      "grad_norm": 0.7014024257659912,
      "learning_rate": 1.144081202214606e-05,
      "loss": 0.0113,
      "step": 8179
    },
    {
      "epoch": 0.48522956459841027,
      "grad_norm": 0.010171833448112011,
      "learning_rate": 1.1439493804376485e-05,
      "loss": 0.0004,
      "step": 8180
    },
    {
      "epoch": 0.4852888836160873,
      "grad_norm": 27.793773651123047,
      "learning_rate": 1.1438175586606908e-05,
      "loss": 1.261,
      "step": 8181
    },
    {
      "epoch": 0.4853482026337644,
      "grad_norm": 1.1850905418395996,
      "learning_rate": 1.1436857368837334e-05,
      "loss": 0.0107,
      "step": 8182
    },
    {
      "epoch": 0.48540752165144146,
      "grad_norm": 6.504929542541504,
      "learning_rate": 1.1435539151067758e-05,
      "loss": 0.1338,
      "step": 8183
    },
    {
      "epoch": 0.4854668406691185,
      "grad_norm": 1.884029507637024,
      "learning_rate": 1.1434220933298182e-05,
      "loss": 0.0169,
      "step": 8184
    },
    {
      "epoch": 0.4855261596867956,
      "grad_norm": 15.312273979187012,
      "learning_rate": 1.1432902715528606e-05,
      "loss": 1.2207,
      "step": 8185
    },
    {
      "epoch": 0.48558547870447266,
      "grad_norm": 0.023433079943060875,
      "learning_rate": 1.1431584497759032e-05,
      "loss": 0.0006,
      "step": 8186
    },
    {
      "epoch": 0.48564479772214975,
      "grad_norm": 9.17973518371582,
      "learning_rate": 1.1430266279989455e-05,
      "loss": 0.4886,
      "step": 8187
    },
    {
      "epoch": 0.4857041167398268,
      "grad_norm": 0.021266458556056023,
      "learning_rate": 1.142894806221988e-05,
      "loss": 0.0006,
      "step": 8188
    },
    {
      "epoch": 0.48576343575750386,
      "grad_norm": 0.1163778007030487,
      "learning_rate": 1.1427629844450303e-05,
      "loss": 0.0026,
      "step": 8189
    },
    {
      "epoch": 0.48582275477518094,
      "grad_norm": 3.4221510887145996,
      "learning_rate": 1.1426311626680729e-05,
      "loss": 0.1983,
      "step": 8190
    },
    {
      "epoch": 0.48588207379285797,
      "grad_norm": 0.1191442608833313,
      "learning_rate": 1.1424993408911153e-05,
      "loss": 0.0024,
      "step": 8191
    },
    {
      "epoch": 0.48594139281053506,
      "grad_norm": 0.20275698602199554,
      "learning_rate": 1.1423675191141577e-05,
      "loss": 0.0023,
      "step": 8192
    },
    {
      "epoch": 0.48600071182821214,
      "grad_norm": 0.05434103682637215,
      "learning_rate": 1.1422356973372001e-05,
      "loss": 0.0007,
      "step": 8193
    },
    {
      "epoch": 0.48606003084588917,
      "grad_norm": 16.489547729492188,
      "learning_rate": 1.1421038755602427e-05,
      "loss": 0.7296,
      "step": 8194
    },
    {
      "epoch": 0.48611934986356625,
      "grad_norm": 0.3153870105743408,
      "learning_rate": 1.141972053783285e-05,
      "loss": 0.0052,
      "step": 8195
    },
    {
      "epoch": 0.48617866888124334,
      "grad_norm": 3.8204853534698486,
      "learning_rate": 1.1418402320063276e-05,
      "loss": 0.241,
      "step": 8196
    },
    {
      "epoch": 0.4862379878989204,
      "grad_norm": 2.3258275985717773,
      "learning_rate": 1.14170841022937e-05,
      "loss": 0.0383,
      "step": 8197
    },
    {
      "epoch": 0.48629730691659745,
      "grad_norm": 20.96339225769043,
      "learning_rate": 1.1415765884524124e-05,
      "loss": 0.2122,
      "step": 8198
    },
    {
      "epoch": 0.48635662593427453,
      "grad_norm": 0.49313297867774963,
      "learning_rate": 1.1414447666754548e-05,
      "loss": 0.0068,
      "step": 8199
    },
    {
      "epoch": 0.4864159449519516,
      "grad_norm": 3.8017046451568604,
      "learning_rate": 1.1413129448984974e-05,
      "loss": 1.0731,
      "step": 8200
    },
    {
      "epoch": 0.48647526396962865,
      "grad_norm": 1.8950587511062622,
      "learning_rate": 1.1411811231215397e-05,
      "loss": 0.0154,
      "step": 8201
    },
    {
      "epoch": 0.48653458298730573,
      "grad_norm": 1.1969878673553467,
      "learning_rate": 1.1410493013445822e-05,
      "loss": 0.0103,
      "step": 8202
    },
    {
      "epoch": 0.4865939020049828,
      "grad_norm": 11.535245895385742,
      "learning_rate": 1.1409174795676248e-05,
      "loss": 0.3051,
      "step": 8203
    },
    {
      "epoch": 0.48665322102265984,
      "grad_norm": 3.915379285812378,
      "learning_rate": 1.140785657790667e-05,
      "loss": 0.0908,
      "step": 8204
    },
    {
      "epoch": 0.4867125400403369,
      "grad_norm": 14.643492698669434,
      "learning_rate": 1.1406538360137097e-05,
      "loss": 0.8263,
      "step": 8205
    },
    {
      "epoch": 0.486771859058014,
      "grad_norm": 0.5017790198326111,
      "learning_rate": 1.140522014236752e-05,
      "loss": 0.0038,
      "step": 8206
    },
    {
      "epoch": 0.48683117807569104,
      "grad_norm": 36.23414993286133,
      "learning_rate": 1.1403901924597945e-05,
      "loss": 0.5093,
      "step": 8207
    },
    {
      "epoch": 0.4868904970933681,
      "grad_norm": 0.07147455960512161,
      "learning_rate": 1.140258370682837e-05,
      "loss": 0.0019,
      "step": 8208
    },
    {
      "epoch": 0.4869498161110452,
      "grad_norm": 6.472638130187988,
      "learning_rate": 1.1401265489058792e-05,
      "loss": 0.053,
      "step": 8209
    },
    {
      "epoch": 0.4870091351287223,
      "grad_norm": 10.839784622192383,
      "learning_rate": 1.1399947271289218e-05,
      "loss": 0.2563,
      "step": 8210
    },
    {
      "epoch": 0.4870684541463993,
      "grad_norm": 1.686005711555481,
      "learning_rate": 1.1398629053519644e-05,
      "loss": 0.0097,
      "step": 8211
    },
    {
      "epoch": 0.4871277731640764,
      "grad_norm": 6.0494065284729,
      "learning_rate": 1.1397310835750066e-05,
      "loss": 0.189,
      "step": 8212
    },
    {
      "epoch": 0.4871870921817535,
      "grad_norm": 4.746725559234619,
      "learning_rate": 1.1395992617980492e-05,
      "loss": 0.2968,
      "step": 8213
    },
    {
      "epoch": 0.4872464111994305,
      "grad_norm": 0.1573581099510193,
      "learning_rate": 1.1394674400210916e-05,
      "loss": 0.0035,
      "step": 8214
    },
    {
      "epoch": 0.4873057302171076,
      "grad_norm": 0.07438205927610397,
      "learning_rate": 1.139335618244134e-05,
      "loss": 0.0017,
      "step": 8215
    },
    {
      "epoch": 0.4873650492347847,
      "grad_norm": 1.1118265390396118,
      "learning_rate": 1.1392037964671764e-05,
      "loss": 0.0053,
      "step": 8216
    },
    {
      "epoch": 0.4874243682524617,
      "grad_norm": 16.0324649810791,
      "learning_rate": 1.139071974690219e-05,
      "loss": 0.7046,
      "step": 8217
    },
    {
      "epoch": 0.4874836872701388,
      "grad_norm": 10.610668182373047,
      "learning_rate": 1.1389401529132613e-05,
      "loss": 0.2999,
      "step": 8218
    },
    {
      "epoch": 0.4875430062878159,
      "grad_norm": 1.6130284070968628,
      "learning_rate": 1.1388083311363039e-05,
      "loss": 0.0136,
      "step": 8219
    },
    {
      "epoch": 0.48760232530549297,
      "grad_norm": 2.791006088256836,
      "learning_rate": 1.1386765093593461e-05,
      "loss": 0.0378,
      "step": 8220
    },
    {
      "epoch": 0.48766164432317,
      "grad_norm": 33.08274459838867,
      "learning_rate": 1.1385446875823887e-05,
      "loss": 0.6867,
      "step": 8221
    },
    {
      "epoch": 0.4877209633408471,
      "grad_norm": 7.763669013977051,
      "learning_rate": 1.1384128658054311e-05,
      "loss": 0.2974,
      "step": 8222
    },
    {
      "epoch": 0.48778028235852416,
      "grad_norm": 14.759586334228516,
      "learning_rate": 1.1382810440284735e-05,
      "loss": 0.2143,
      "step": 8223
    },
    {
      "epoch": 0.4878396013762012,
      "grad_norm": 7.786929130554199,
      "learning_rate": 1.138149222251516e-05,
      "loss": 0.1744,
      "step": 8224
    },
    {
      "epoch": 0.4878989203938783,
      "grad_norm": 78.31464385986328,
      "learning_rate": 1.1380174004745586e-05,
      "loss": 1.1761,
      "step": 8225
    },
    {
      "epoch": 0.48795823941155536,
      "grad_norm": 0.05812089145183563,
      "learning_rate": 1.1378855786976008e-05,
      "loss": 0.0012,
      "step": 8226
    },
    {
      "epoch": 0.4880175584292324,
      "grad_norm": 16.00815773010254,
      "learning_rate": 1.1377537569206434e-05,
      "loss": 1.0665,
      "step": 8227
    },
    {
      "epoch": 0.4880768774469095,
      "grad_norm": 1.1584373712539673,
      "learning_rate": 1.137621935143686e-05,
      "loss": 0.015,
      "step": 8228
    },
    {
      "epoch": 0.48813619646458656,
      "grad_norm": 0.6033231019973755,
      "learning_rate": 1.1374901133667282e-05,
      "loss": 0.005,
      "step": 8229
    },
    {
      "epoch": 0.4881955154822636,
      "grad_norm": 3.7392804622650146,
      "learning_rate": 1.1373582915897708e-05,
      "loss": 0.0962,
      "step": 8230
    },
    {
      "epoch": 0.48825483449994067,
      "grad_norm": 5.280735969543457,
      "learning_rate": 1.1372264698128132e-05,
      "loss": 0.1196,
      "step": 8231
    },
    {
      "epoch": 0.48831415351761776,
      "grad_norm": 0.0183925349265337,
      "learning_rate": 1.1370946480358555e-05,
      "loss": 0.0006,
      "step": 8232
    },
    {
      "epoch": 0.48837347253529484,
      "grad_norm": 3.535125494003296,
      "learning_rate": 1.136962826258898e-05,
      "loss": 0.0525,
      "step": 8233
    },
    {
      "epoch": 0.48843279155297187,
      "grad_norm": 3.3903746604919434,
      "learning_rate": 1.1368310044819407e-05,
      "loss": 0.1019,
      "step": 8234
    },
    {
      "epoch": 0.48849211057064895,
      "grad_norm": 13.346680641174316,
      "learning_rate": 1.1366991827049829e-05,
      "loss": 0.1921,
      "step": 8235
    },
    {
      "epoch": 0.48855142958832604,
      "grad_norm": 15.663032531738281,
      "learning_rate": 1.1365673609280255e-05,
      "loss": 0.5783,
      "step": 8236
    },
    {
      "epoch": 0.48861074860600306,
      "grad_norm": 0.9446811676025391,
      "learning_rate": 1.1364355391510677e-05,
      "loss": 0.0108,
      "step": 8237
    },
    {
      "epoch": 0.48867006762368015,
      "grad_norm": 0.3115731477737427,
      "learning_rate": 1.1363037173741103e-05,
      "loss": 0.0039,
      "step": 8238
    },
    {
      "epoch": 0.48872938664135723,
      "grad_norm": 3.545835494995117,
      "learning_rate": 1.1361718955971528e-05,
      "loss": 0.0522,
      "step": 8239
    },
    {
      "epoch": 0.48878870565903426,
      "grad_norm": 0.012930484488606453,
      "learning_rate": 1.1360400738201952e-05,
      "loss": 0.0004,
      "step": 8240
    },
    {
      "epoch": 0.48884802467671135,
      "grad_norm": 17.536909103393555,
      "learning_rate": 1.1359082520432376e-05,
      "loss": 1.406,
      "step": 8241
    },
    {
      "epoch": 0.48890734369438843,
      "grad_norm": 0.4377761781215668,
      "learning_rate": 1.1357764302662802e-05,
      "loss": 0.0027,
      "step": 8242
    },
    {
      "epoch": 0.4889666627120655,
      "grad_norm": 12.32207202911377,
      "learning_rate": 1.1356446084893224e-05,
      "loss": 0.1044,
      "step": 8243
    },
    {
      "epoch": 0.48902598172974254,
      "grad_norm": 0.3896006941795349,
      "learning_rate": 1.135512786712365e-05,
      "loss": 0.0038,
      "step": 8244
    },
    {
      "epoch": 0.4890853007474196,
      "grad_norm": 2.050351858139038,
      "learning_rate": 1.1353809649354074e-05,
      "loss": 0.0225,
      "step": 8245
    },
    {
      "epoch": 0.4891446197650967,
      "grad_norm": 7.5851521492004395,
      "learning_rate": 1.1352491431584499e-05,
      "loss": 0.074,
      "step": 8246
    },
    {
      "epoch": 0.48920393878277374,
      "grad_norm": 3.0783679485321045,
      "learning_rate": 1.1351173213814923e-05,
      "loss": 0.0832,
      "step": 8247
    },
    {
      "epoch": 0.4892632578004508,
      "grad_norm": 8.756370544433594,
      "learning_rate": 1.1349854996045349e-05,
      "loss": 0.7402,
      "step": 8248
    },
    {
      "epoch": 0.4893225768181279,
      "grad_norm": 8.90654468536377,
      "learning_rate": 1.1348536778275771e-05,
      "loss": 0.4197,
      "step": 8249
    },
    {
      "epoch": 0.48938189583580494,
      "grad_norm": 2.683257818222046,
      "learning_rate": 1.1347218560506197e-05,
      "loss": 0.0307,
      "step": 8250
    },
    {
      "epoch": 0.489441214853482,
      "grad_norm": 0.015543770976364613,
      "learning_rate": 1.1345900342736623e-05,
      "loss": 0.0005,
      "step": 8251
    },
    {
      "epoch": 0.4895005338711591,
      "grad_norm": 0.25343772768974304,
      "learning_rate": 1.1344582124967045e-05,
      "loss": 0.0033,
      "step": 8252
    },
    {
      "epoch": 0.48955985288883613,
      "grad_norm": 8.095892906188965,
      "learning_rate": 1.134326390719747e-05,
      "loss": 0.308,
      "step": 8253
    },
    {
      "epoch": 0.4896191719065132,
      "grad_norm": 1.756807804107666,
      "learning_rate": 1.1341945689427894e-05,
      "loss": 0.0186,
      "step": 8254
    },
    {
      "epoch": 0.4896784909241903,
      "grad_norm": 12.85481071472168,
      "learning_rate": 1.1340627471658318e-05,
      "loss": 0.351,
      "step": 8255
    },
    {
      "epoch": 0.4897378099418674,
      "grad_norm": 1.267968773841858,
      "learning_rate": 1.1339309253888744e-05,
      "loss": 0.0179,
      "step": 8256
    },
    {
      "epoch": 0.4897971289595444,
      "grad_norm": 20.56623077392578,
      "learning_rate": 1.1337991036119166e-05,
      "loss": 0.3676,
      "step": 8257
    },
    {
      "epoch": 0.4898564479772215,
      "grad_norm": 0.029015960171818733,
      "learning_rate": 1.1336672818349592e-05,
      "loss": 0.0008,
      "step": 8258
    },
    {
      "epoch": 0.4899157669948986,
      "grad_norm": 3.2239692211151123,
      "learning_rate": 1.1335354600580018e-05,
      "loss": 0.0496,
      "step": 8259
    },
    {
      "epoch": 0.4899750860125756,
      "grad_norm": 0.2523464262485504,
      "learning_rate": 1.133403638281044e-05,
      "loss": 0.0031,
      "step": 8260
    },
    {
      "epoch": 0.4900344050302527,
      "grad_norm": 1.3645788431167603,
      "learning_rate": 1.1332718165040866e-05,
      "loss": 0.0075,
      "step": 8261
    },
    {
      "epoch": 0.4900937240479298,
      "grad_norm": 8.925869941711426,
      "learning_rate": 1.133139994727129e-05,
      "loss": 0.3106,
      "step": 8262
    },
    {
      "epoch": 0.4901530430656068,
      "grad_norm": 0.11442052572965622,
      "learning_rate": 1.1330081729501715e-05,
      "loss": 0.0014,
      "step": 8263
    },
    {
      "epoch": 0.4902123620832839,
      "grad_norm": 0.7655219435691833,
      "learning_rate": 1.1328763511732139e-05,
      "loss": 0.0145,
      "step": 8264
    },
    {
      "epoch": 0.490271681100961,
      "grad_norm": 0.018142512068152428,
      "learning_rate": 1.1327445293962565e-05,
      "loss": 0.0005,
      "step": 8265
    },
    {
      "epoch": 0.49033100011863806,
      "grad_norm": 4.563846111297607,
      "learning_rate": 1.1326127076192987e-05,
      "loss": 0.0711,
      "step": 8266
    },
    {
      "epoch": 0.4903903191363151,
      "grad_norm": 1.9521267414093018,
      "learning_rate": 1.1324808858423413e-05,
      "loss": 0.017,
      "step": 8267
    },
    {
      "epoch": 0.4904496381539922,
      "grad_norm": 5.384331226348877,
      "learning_rate": 1.1323490640653836e-05,
      "loss": 0.3754,
      "step": 8268
    },
    {
      "epoch": 0.49050895717166926,
      "grad_norm": 12.499229431152344,
      "learning_rate": 1.1322172422884262e-05,
      "loss": 0.7985,
      "step": 8269
    },
    {
      "epoch": 0.4905682761893463,
      "grad_norm": 9.677775382995605,
      "learning_rate": 1.1320854205114686e-05,
      "loss": 0.3324,
      "step": 8270
    },
    {
      "epoch": 0.49062759520702337,
      "grad_norm": 4.685587406158447,
      "learning_rate": 1.131953598734511e-05,
      "loss": 0.0534,
      "step": 8271
    },
    {
      "epoch": 0.49068691422470045,
      "grad_norm": 2.029015302658081,
      "learning_rate": 1.1318217769575534e-05,
      "loss": 0.0173,
      "step": 8272
    },
    {
      "epoch": 0.4907462332423775,
      "grad_norm": 0.0296203400939703,
      "learning_rate": 1.131689955180596e-05,
      "loss": 0.0006,
      "step": 8273
    },
    {
      "epoch": 0.49080555226005457,
      "grad_norm": 0.05994769185781479,
      "learning_rate": 1.1315581334036383e-05,
      "loss": 0.0012,
      "step": 8274
    },
    {
      "epoch": 0.49086487127773165,
      "grad_norm": 0.6011844277381897,
      "learning_rate": 1.1314263116266808e-05,
      "loss": 0.0054,
      "step": 8275
    },
    {
      "epoch": 0.49092419029540874,
      "grad_norm": 3.099207878112793,
      "learning_rate": 1.1312944898497233e-05,
      "loss": 0.0225,
      "step": 8276
    },
    {
      "epoch": 0.49098350931308576,
      "grad_norm": 1.398807406425476,
      "learning_rate": 1.1311626680727657e-05,
      "loss": 0.0155,
      "step": 8277
    },
    {
      "epoch": 0.49104282833076285,
      "grad_norm": 29.791358947753906,
      "learning_rate": 1.1310308462958081e-05,
      "loss": 0.731,
      "step": 8278
    },
    {
      "epoch": 0.49110214734843993,
      "grad_norm": 0.10329325497150421,
      "learning_rate": 1.1308990245188507e-05,
      "loss": 0.0014,
      "step": 8279
    },
    {
      "epoch": 0.49116146636611696,
      "grad_norm": 6.913047790527344,
      "learning_rate": 1.130767202741893e-05,
      "loss": 0.1751,
      "step": 8280
    },
    {
      "epoch": 0.49122078538379405,
      "grad_norm": 0.7128986716270447,
      "learning_rate": 1.1306353809649355e-05,
      "loss": 0.0075,
      "step": 8281
    },
    {
      "epoch": 0.49128010440147113,
      "grad_norm": 0.41741839051246643,
      "learning_rate": 1.1305035591879781e-05,
      "loss": 0.007,
      "step": 8282
    },
    {
      "epoch": 0.49133942341914816,
      "grad_norm": 11.513094902038574,
      "learning_rate": 1.1303717374110204e-05,
      "loss": 0.0389,
      "step": 8283
    },
    {
      "epoch": 0.49139874243682524,
      "grad_norm": 3.2936060428619385,
      "learning_rate": 1.130239915634063e-05,
      "loss": 0.0176,
      "step": 8284
    },
    {
      "epoch": 0.4914580614545023,
      "grad_norm": 0.02382476255297661,
      "learning_rate": 1.1301080938571052e-05,
      "loss": 0.0008,
      "step": 8285
    },
    {
      "epoch": 0.49151738047217935,
      "grad_norm": 13.302971839904785,
      "learning_rate": 1.1299762720801478e-05,
      "loss": 0.6002,
      "step": 8286
    },
    {
      "epoch": 0.49157669948985644,
      "grad_norm": 38.600135803222656,
      "learning_rate": 1.1298444503031902e-05,
      "loss": 0.1348,
      "step": 8287
    },
    {
      "epoch": 0.4916360185075335,
      "grad_norm": 2.578176736831665,
      "learning_rate": 1.1297126285262325e-05,
      "loss": 0.0394,
      "step": 8288
    },
    {
      "epoch": 0.4916953375252106,
      "grad_norm": 5.937337398529053,
      "learning_rate": 1.129580806749275e-05,
      "loss": 0.0569,
      "step": 8289
    },
    {
      "epoch": 0.49175465654288764,
      "grad_norm": 1.5704505443572998,
      "learning_rate": 1.1294489849723176e-05,
      "loss": 0.0143,
      "step": 8290
    },
    {
      "epoch": 0.4918139755605647,
      "grad_norm": 0.051067329943180084,
      "learning_rate": 1.1293171631953599e-05,
      "loss": 0.0008,
      "step": 8291
    },
    {
      "epoch": 0.4918732945782418,
      "grad_norm": 4.619975566864014,
      "learning_rate": 1.1291853414184025e-05,
      "loss": 0.0891,
      "step": 8292
    },
    {
      "epoch": 0.49193261359591883,
      "grad_norm": 3.8909785747528076,
      "learning_rate": 1.1290535196414449e-05,
      "loss": 0.0258,
      "step": 8293
    },
    {
      "epoch": 0.4919919326135959,
      "grad_norm": 0.031358927488327026,
      "learning_rate": 1.1289216978644873e-05,
      "loss": 0.0006,
      "step": 8294
    },
    {
      "epoch": 0.492051251631273,
      "grad_norm": 9.451702117919922,
      "learning_rate": 1.1287898760875297e-05,
      "loss": 0.4386,
      "step": 8295
    },
    {
      "epoch": 0.49211057064895003,
      "grad_norm": 0.6520276665687561,
      "learning_rate": 1.1286580543105723e-05,
      "loss": 0.0095,
      "step": 8296
    },
    {
      "epoch": 0.4921698896666271,
      "grad_norm": 13.022485733032227,
      "learning_rate": 1.1285262325336146e-05,
      "loss": 0.5186,
      "step": 8297
    },
    {
      "epoch": 0.4922292086843042,
      "grad_norm": 0.9778079986572266,
      "learning_rate": 1.1283944107566572e-05,
      "loss": 0.0133,
      "step": 8298
    },
    {
      "epoch": 0.4922885277019813,
      "grad_norm": 0.03515584021806717,
      "learning_rate": 1.1282625889796996e-05,
      "loss": 0.0008,
      "step": 8299
    },
    {
      "epoch": 0.4923478467196583,
      "grad_norm": 1.3579634428024292,
      "learning_rate": 1.128130767202742e-05,
      "loss": 0.0201,
      "step": 8300
    },
    {
      "epoch": 0.4924071657373354,
      "grad_norm": 0.08627773076295853,
      "learning_rate": 1.1279989454257844e-05,
      "loss": 0.0009,
      "step": 8301
    },
    {
      "epoch": 0.4924664847550125,
      "grad_norm": 4.397329807281494,
      "learning_rate": 1.1278671236488268e-05,
      "loss": 0.0201,
      "step": 8302
    },
    {
      "epoch": 0.4925258037726895,
      "grad_norm": 0.05884799361228943,
      "learning_rate": 1.1277353018718692e-05,
      "loss": 0.0012,
      "step": 8303
    },
    {
      "epoch": 0.4925851227903666,
      "grad_norm": 12.004779815673828,
      "learning_rate": 1.1276034800949118e-05,
      "loss": 0.1587,
      "step": 8304
    },
    {
      "epoch": 0.4926444418080437,
      "grad_norm": 0.15381932258605957,
      "learning_rate": 1.1274716583179541e-05,
      "loss": 0.0017,
      "step": 8305
    },
    {
      "epoch": 0.4927037608257207,
      "grad_norm": 0.2665354609489441,
      "learning_rate": 1.1273398365409967e-05,
      "loss": 0.0046,
      "step": 8306
    },
    {
      "epoch": 0.4927630798433978,
      "grad_norm": 0.08015981316566467,
      "learning_rate": 1.1272080147640393e-05,
      "loss": 0.001,
      "step": 8307
    },
    {
      "epoch": 0.4928223988610749,
      "grad_norm": 13.598871231079102,
      "learning_rate": 1.1270761929870815e-05,
      "loss": 0.2169,
      "step": 8308
    },
    {
      "epoch": 0.4928817178787519,
      "grad_norm": 13.930882453918457,
      "learning_rate": 1.126944371210124e-05,
      "loss": 0.387,
      "step": 8309
    },
    {
      "epoch": 0.492941036896429,
      "grad_norm": 5.455435276031494,
      "learning_rate": 1.1268125494331665e-05,
      "loss": 0.125,
      "step": 8310
    },
    {
      "epoch": 0.49300035591410607,
      "grad_norm": 0.19840127229690552,
      "learning_rate": 1.1266807276562088e-05,
      "loss": 0.003,
      "step": 8311
    },
    {
      "epoch": 0.49305967493178315,
      "grad_norm": 3.156480073928833,
      "learning_rate": 1.1265489058792514e-05,
      "loss": 0.1371,
      "step": 8312
    },
    {
      "epoch": 0.4931189939494602,
      "grad_norm": 33.271705627441406,
      "learning_rate": 1.126417084102294e-05,
      "loss": 0.7381,
      "step": 8313
    },
    {
      "epoch": 0.49317831296713727,
      "grad_norm": 1.5532511472702026,
      "learning_rate": 1.1262852623253362e-05,
      "loss": 0.0138,
      "step": 8314
    },
    {
      "epoch": 0.49323763198481435,
      "grad_norm": 2.475245475769043,
      "learning_rate": 1.1261534405483788e-05,
      "loss": 0.024,
      "step": 8315
    },
    {
      "epoch": 0.4932969510024914,
      "grad_norm": 0.016842829063534737,
      "learning_rate": 1.126021618771421e-05,
      "loss": 0.0004,
      "step": 8316
    },
    {
      "epoch": 0.49335627002016846,
      "grad_norm": 12.519744873046875,
      "learning_rate": 1.1258897969944636e-05,
      "loss": 0.5305,
      "step": 8317
    },
    {
      "epoch": 0.49341558903784555,
      "grad_norm": 11.344944953918457,
      "learning_rate": 1.125757975217506e-05,
      "loss": 0.1222,
      "step": 8318
    },
    {
      "epoch": 0.4934749080555226,
      "grad_norm": 0.15799662470817566,
      "learning_rate": 1.1256261534405485e-05,
      "loss": 0.0029,
      "step": 8319
    },
    {
      "epoch": 0.49353422707319966,
      "grad_norm": 0.15999957919120789,
      "learning_rate": 1.1254943316635909e-05,
      "loss": 0.0015,
      "step": 8320
    },
    {
      "epoch": 0.49359354609087674,
      "grad_norm": 6.776697158813477,
      "learning_rate": 1.1253625098866335e-05,
      "loss": 0.1941,
      "step": 8321
    },
    {
      "epoch": 0.49365286510855383,
      "grad_norm": 0.26715242862701416,
      "learning_rate": 1.1252306881096757e-05,
      "loss": 0.0031,
      "step": 8322
    },
    {
      "epoch": 0.49371218412623086,
      "grad_norm": 0.31218841671943665,
      "learning_rate": 1.1250988663327183e-05,
      "loss": 0.0049,
      "step": 8323
    },
    {
      "epoch": 0.49377150314390794,
      "grad_norm": 9.35436725616455,
      "learning_rate": 1.1249670445557607e-05,
      "loss": 0.4465,
      "step": 8324
    },
    {
      "epoch": 0.493830822161585,
      "grad_norm": 21.784473419189453,
      "learning_rate": 1.1248352227788031e-05,
      "loss": 1.5714,
      "step": 8325
    },
    {
      "epoch": 0.49389014117926205,
      "grad_norm": 0.7734765410423279,
      "learning_rate": 1.1247034010018456e-05,
      "loss": 0.0191,
      "step": 8326
    },
    {
      "epoch": 0.49394946019693914,
      "grad_norm": 4.060985565185547,
      "learning_rate": 1.1245715792248881e-05,
      "loss": 0.0879,
      "step": 8327
    },
    {
      "epoch": 0.4940087792146162,
      "grad_norm": 1.4931329488754272,
      "learning_rate": 1.1244397574479304e-05,
      "loss": 0.0113,
      "step": 8328
    },
    {
      "epoch": 0.49406809823229325,
      "grad_norm": 7.167798042297363,
      "learning_rate": 1.124307935670973e-05,
      "loss": 0.0527,
      "step": 8329
    },
    {
      "epoch": 0.49412741724997034,
      "grad_norm": 0.2852064371109009,
      "learning_rate": 1.1241761138940156e-05,
      "loss": 0.0035,
      "step": 8330
    },
    {
      "epoch": 0.4941867362676474,
      "grad_norm": 31.38313865661621,
      "learning_rate": 1.1240442921170578e-05,
      "loss": 0.034,
      "step": 8331
    },
    {
      "epoch": 0.49424605528532445,
      "grad_norm": 5.342339992523193,
      "learning_rate": 1.1239124703401002e-05,
      "loss": 0.2538,
      "step": 8332
    },
    {
      "epoch": 0.49430537430300153,
      "grad_norm": 8.572467803955078,
      "learning_rate": 1.1237806485631427e-05,
      "loss": 0.1363,
      "step": 8333
    },
    {
      "epoch": 0.4943646933206786,
      "grad_norm": 10.113264083862305,
      "learning_rate": 1.123648826786185e-05,
      "loss": 0.1541,
      "step": 8334
    },
    {
      "epoch": 0.4944240123383557,
      "grad_norm": 9.892902374267578,
      "learning_rate": 1.1235170050092277e-05,
      "loss": 0.0279,
      "step": 8335
    },
    {
      "epoch": 0.49448333135603273,
      "grad_norm": 2.104785680770874,
      "learning_rate": 1.1233851832322699e-05,
      "loss": 0.0248,
      "step": 8336
    },
    {
      "epoch": 0.4945426503737098,
      "grad_norm": 24.399641036987305,
      "learning_rate": 1.1232533614553125e-05,
      "loss": 0.1834,
      "step": 8337
    },
    {
      "epoch": 0.4946019693913869,
      "grad_norm": 0.13179665803909302,
      "learning_rate": 1.1231215396783551e-05,
      "loss": 0.0028,
      "step": 8338
    },
    {
      "epoch": 0.4946612884090639,
      "grad_norm": 0.6433049440383911,
      "learning_rate": 1.1229897179013973e-05,
      "loss": 0.011,
      "step": 8339
    },
    {
      "epoch": 0.494720607426741,
      "grad_norm": 0.03344804048538208,
      "learning_rate": 1.12285789612444e-05,
      "loss": 0.001,
      "step": 8340
    },
    {
      "epoch": 0.4947799264444181,
      "grad_norm": 0.009253359399735928,
      "learning_rate": 1.1227260743474823e-05,
      "loss": 0.0002,
      "step": 8341
    },
    {
      "epoch": 0.4948392454620951,
      "grad_norm": 0.6376729607582092,
      "learning_rate": 1.1225942525705248e-05,
      "loss": 0.0074,
      "step": 8342
    },
    {
      "epoch": 0.4948985644797722,
      "grad_norm": 7.468533992767334,
      "learning_rate": 1.1224624307935672e-05,
      "loss": 0.0571,
      "step": 8343
    },
    {
      "epoch": 0.4949578834974493,
      "grad_norm": 3.174687385559082,
      "learning_rate": 1.1223306090166098e-05,
      "loss": 0.0541,
      "step": 8344
    },
    {
      "epoch": 0.4950172025151264,
      "grad_norm": 0.6815892457962036,
      "learning_rate": 1.122198787239652e-05,
      "loss": 0.0065,
      "step": 8345
    },
    {
      "epoch": 0.4950765215328034,
      "grad_norm": 15.073063850402832,
      "learning_rate": 1.1220669654626946e-05,
      "loss": 0.5903,
      "step": 8346
    },
    {
      "epoch": 0.4951358405504805,
      "grad_norm": 0.13083145022392273,
      "learning_rate": 1.121935143685737e-05,
      "loss": 0.0016,
      "step": 8347
    },
    {
      "epoch": 0.4951951595681576,
      "grad_norm": 7.768073558807373,
      "learning_rate": 1.1218033219087794e-05,
      "loss": 0.2884,
      "step": 8348
    },
    {
      "epoch": 0.4952544785858346,
      "grad_norm": 12.635238647460938,
      "learning_rate": 1.1216715001318219e-05,
      "loss": 0.4374,
      "step": 8349
    },
    {
      "epoch": 0.4953137976035117,
      "grad_norm": 0.524810791015625,
      "learning_rate": 1.1215396783548643e-05,
      "loss": 0.0054,
      "step": 8350
    },
    {
      "epoch": 0.49537311662118877,
      "grad_norm": 0.053556907922029495,
      "learning_rate": 1.1214078565779067e-05,
      "loss": 0.0016,
      "step": 8351
    },
    {
      "epoch": 0.4954324356388658,
      "grad_norm": 8.263134956359863,
      "learning_rate": 1.1212760348009493e-05,
      "loss": 0.4927,
      "step": 8352
    },
    {
      "epoch": 0.4954917546565429,
      "grad_norm": 0.01967346854507923,
      "learning_rate": 1.1211442130239915e-05,
      "loss": 0.0005,
      "step": 8353
    },
    {
      "epoch": 0.49555107367421997,
      "grad_norm": 0.44133707880973816,
      "learning_rate": 1.1210123912470341e-05,
      "loss": 0.0063,
      "step": 8354
    },
    {
      "epoch": 0.495610392691897,
      "grad_norm": 0.39709970355033875,
      "learning_rate": 1.1208805694700765e-05,
      "loss": 0.0082,
      "step": 8355
    },
    {
      "epoch": 0.4956697117095741,
      "grad_norm": 10.42516040802002,
      "learning_rate": 1.120748747693119e-05,
      "loss": 0.7307,
      "step": 8356
    },
    {
      "epoch": 0.49572903072725116,
      "grad_norm": 15.029265403747559,
      "learning_rate": 1.1206169259161614e-05,
      "loss": 1.3566,
      "step": 8357
    },
    {
      "epoch": 0.49578834974492825,
      "grad_norm": 0.11082243919372559,
      "learning_rate": 1.120485104139204e-05,
      "loss": 0.0011,
      "step": 8358
    },
    {
      "epoch": 0.4958476687626053,
      "grad_norm": 2.390639305114746,
      "learning_rate": 1.1203532823622462e-05,
      "loss": 0.0409,
      "step": 8359
    },
    {
      "epoch": 0.49590698778028236,
      "grad_norm": 0.08034636080265045,
      "learning_rate": 1.1202214605852888e-05,
      "loss": 0.0013,
      "step": 8360
    },
    {
      "epoch": 0.49596630679795944,
      "grad_norm": 39.9189338684082,
      "learning_rate": 1.1200896388083314e-05,
      "loss": 0.4959,
      "step": 8361
    },
    {
      "epoch": 0.4960256258156365,
      "grad_norm": 0.13290053606033325,
      "learning_rate": 1.1199578170313736e-05,
      "loss": 0.0019,
      "step": 8362
    },
    {
      "epoch": 0.49608494483331356,
      "grad_norm": 3.9106414318084717,
      "learning_rate": 1.1198259952544162e-05,
      "loss": 0.5644,
      "step": 8363
    },
    {
      "epoch": 0.49614426385099064,
      "grad_norm": 0.0645722821354866,
      "learning_rate": 1.1196941734774585e-05,
      "loss": 0.002,
      "step": 8364
    },
    {
      "epoch": 0.49620358286866767,
      "grad_norm": 16.341402053833008,
      "learning_rate": 1.1195623517005009e-05,
      "loss": 0.3455,
      "step": 8365
    },
    {
      "epoch": 0.49626290188634475,
      "grad_norm": 0.0337916724383831,
      "learning_rate": 1.1194305299235435e-05,
      "loss": 0.0005,
      "step": 8366
    },
    {
      "epoch": 0.49632222090402184,
      "grad_norm": 0.03427976369857788,
      "learning_rate": 1.1192987081465857e-05,
      "loss": 0.0008,
      "step": 8367
    },
    {
      "epoch": 0.4963815399216989,
      "grad_norm": 4.120926856994629,
      "learning_rate": 1.1191668863696283e-05,
      "loss": 0.3204,
      "step": 8368
    },
    {
      "epoch": 0.49644085893937595,
      "grad_norm": 0.06886883080005646,
      "learning_rate": 1.1190350645926709e-05,
      "loss": 0.001,
      "step": 8369
    },
    {
      "epoch": 0.49650017795705303,
      "grad_norm": 0.3017786741256714,
      "learning_rate": 1.1189032428157132e-05,
      "loss": 0.0029,
      "step": 8370
    },
    {
      "epoch": 0.4965594969747301,
      "grad_norm": 2.3245761394500732,
      "learning_rate": 1.1187714210387558e-05,
      "loss": 0.0222,
      "step": 8371
    },
    {
      "epoch": 0.49661881599240715,
      "grad_norm": 25.326932907104492,
      "learning_rate": 1.1186395992617982e-05,
      "loss": 0.4397,
      "step": 8372
    },
    {
      "epoch": 0.49667813501008423,
      "grad_norm": 10.273159980773926,
      "learning_rate": 1.1185077774848406e-05,
      "loss": 0.1032,
      "step": 8373
    },
    {
      "epoch": 0.4967374540277613,
      "grad_norm": 2.529254198074341,
      "learning_rate": 1.118375955707883e-05,
      "loss": 0.0123,
      "step": 8374
    },
    {
      "epoch": 0.49679677304543834,
      "grad_norm": 11.866618156433105,
      "learning_rate": 1.1182441339309256e-05,
      "loss": 0.1037,
      "step": 8375
    },
    {
      "epoch": 0.49685609206311543,
      "grad_norm": 0.21415705978870392,
      "learning_rate": 1.1181123121539678e-05,
      "loss": 0.0019,
      "step": 8376
    },
    {
      "epoch": 0.4969154110807925,
      "grad_norm": 0.030294030904769897,
      "learning_rate": 1.1179804903770104e-05,
      "loss": 0.0008,
      "step": 8377
    },
    {
      "epoch": 0.4969747300984696,
      "grad_norm": 0.3573742210865021,
      "learning_rate": 1.1178486686000529e-05,
      "loss": 0.0041,
      "step": 8378
    },
    {
      "epoch": 0.4970340491161466,
      "grad_norm": 0.6399633884429932,
      "learning_rate": 1.1177168468230953e-05,
      "loss": 0.0063,
      "step": 8379
    },
    {
      "epoch": 0.4970933681338237,
      "grad_norm": 0.2805914282798767,
      "learning_rate": 1.1175850250461377e-05,
      "loss": 0.004,
      "step": 8380
    },
    {
      "epoch": 0.4971526871515008,
      "grad_norm": 4.127614974975586,
      "learning_rate": 1.1174532032691801e-05,
      "loss": 0.047,
      "step": 8381
    },
    {
      "epoch": 0.4972120061691778,
      "grad_norm": 0.2815316915512085,
      "learning_rate": 1.1173213814922225e-05,
      "loss": 0.0022,
      "step": 8382
    },
    {
      "epoch": 0.4972713251868549,
      "grad_norm": 0.030354471877217293,
      "learning_rate": 1.1171895597152651e-05,
      "loss": 0.0009,
      "step": 8383
    },
    {
      "epoch": 0.497330644204532,
      "grad_norm": 0.032655853778123856,
      "learning_rate": 1.1170577379383074e-05,
      "loss": 0.0006,
      "step": 8384
    },
    {
      "epoch": 0.497389963222209,
      "grad_norm": 0.014911916106939316,
      "learning_rate": 1.11692591616135e-05,
      "loss": 0.0004,
      "step": 8385
    },
    {
      "epoch": 0.4974492822398861,
      "grad_norm": 5.883203029632568,
      "learning_rate": 1.1167940943843925e-05,
      "loss": 0.0627,
      "step": 8386
    },
    {
      "epoch": 0.4975086012575632,
      "grad_norm": 1.153452754020691,
      "learning_rate": 1.1166622726074348e-05,
      "loss": 0.0109,
      "step": 8387
    },
    {
      "epoch": 0.4975679202752402,
      "grad_norm": 0.13003009557724,
      "learning_rate": 1.1165304508304772e-05,
      "loss": 0.0013,
      "step": 8388
    },
    {
      "epoch": 0.4976272392929173,
      "grad_norm": 0.04262737184762955,
      "learning_rate": 1.1163986290535198e-05,
      "loss": 0.0011,
      "step": 8389
    },
    {
      "epoch": 0.4976865583105944,
      "grad_norm": 0.023675529286265373,
      "learning_rate": 1.116266807276562e-05,
      "loss": 0.0007,
      "step": 8390
    },
    {
      "epoch": 0.49774587732827147,
      "grad_norm": 4.6336259841918945,
      "learning_rate": 1.1161349854996046e-05,
      "loss": 0.0797,
      "step": 8391
    },
    {
      "epoch": 0.4978051963459485,
      "grad_norm": 0.08637599647045135,
      "learning_rate": 1.1160031637226472e-05,
      "loss": 0.0009,
      "step": 8392
    },
    {
      "epoch": 0.4978645153636256,
      "grad_norm": 6.2613525390625,
      "learning_rate": 1.1158713419456895e-05,
      "loss": 0.0835,
      "step": 8393
    },
    {
      "epoch": 0.49792383438130267,
      "grad_norm": 1.3978883028030396,
      "learning_rate": 1.115739520168732e-05,
      "loss": 0.0249,
      "step": 8394
    },
    {
      "epoch": 0.4979831533989797,
      "grad_norm": 0.03148471936583519,
      "learning_rate": 1.1156076983917745e-05,
      "loss": 0.0009,
      "step": 8395
    },
    {
      "epoch": 0.4980424724166568,
      "grad_norm": 2.0868892669677734,
      "learning_rate": 1.1154758766148169e-05,
      "loss": 0.2425,
      "step": 8396
    },
    {
      "epoch": 0.49810179143433386,
      "grad_norm": 3.264382839202881,
      "learning_rate": 1.1153440548378593e-05,
      "loss": 0.0323,
      "step": 8397
    },
    {
      "epoch": 0.4981611104520109,
      "grad_norm": 15.535752296447754,
      "learning_rate": 1.1152122330609016e-05,
      "loss": 0.217,
      "step": 8398
    },
    {
      "epoch": 0.498220429469688,
      "grad_norm": 15.02920913696289,
      "learning_rate": 1.1150804112839442e-05,
      "loss": 0.4729,
      "step": 8399
    },
    {
      "epoch": 0.49827974848736506,
      "grad_norm": 0.016710901632905006,
      "learning_rate": 1.1149485895069867e-05,
      "loss": 0.0004,
      "step": 8400
    },
    {
      "epoch": 0.49833906750504214,
      "grad_norm": 3.828465700149536,
      "learning_rate": 1.114816767730029e-05,
      "loss": 0.0765,
      "step": 8401
    },
    {
      "epoch": 0.4983983865227192,
      "grad_norm": 0.014728154987096786,
      "learning_rate": 1.1146849459530716e-05,
      "loss": 0.0003,
      "step": 8402
    },
    {
      "epoch": 0.49845770554039626,
      "grad_norm": 1.3722296953201294,
      "learning_rate": 1.114553124176114e-05,
      "loss": 0.015,
      "step": 8403
    },
    {
      "epoch": 0.49851702455807334,
      "grad_norm": 0.049371857196092606,
      "learning_rate": 1.1144213023991564e-05,
      "loss": 0.001,
      "step": 8404
    },
    {
      "epoch": 0.49857634357575037,
      "grad_norm": 8.571260452270508,
      "learning_rate": 1.1142894806221988e-05,
      "loss": 0.369,
      "step": 8405
    },
    {
      "epoch": 0.49863566259342745,
      "grad_norm": 17.774770736694336,
      "learning_rate": 1.1141576588452414e-05,
      "loss": 0.5281,
      "step": 8406
    },
    {
      "epoch": 0.49869498161110454,
      "grad_norm": 0.6104124188423157,
      "learning_rate": 1.1140258370682837e-05,
      "loss": 0.0075,
      "step": 8407
    },
    {
      "epoch": 0.49875430062878157,
      "grad_norm": 0.9530866146087646,
      "learning_rate": 1.1138940152913263e-05,
      "loss": 0.0108,
      "step": 8408
    },
    {
      "epoch": 0.49881361964645865,
      "grad_norm": 0.012837104499340057,
      "learning_rate": 1.1137621935143687e-05,
      "loss": 0.0005,
      "step": 8409
    },
    {
      "epoch": 0.49887293866413573,
      "grad_norm": 2.14194655418396,
      "learning_rate": 1.1136303717374111e-05,
      "loss": 0.019,
      "step": 8410
    },
    {
      "epoch": 0.49893225768181276,
      "grad_norm": 2.0509188175201416,
      "learning_rate": 1.1134985499604535e-05,
      "loss": 0.0156,
      "step": 8411
    },
    {
      "epoch": 0.49899157669948985,
      "grad_norm": 9.75340461730957,
      "learning_rate": 1.1133667281834961e-05,
      "loss": 0.6171,
      "step": 8412
    },
    {
      "epoch": 0.49905089571716693,
      "grad_norm": 63.753028869628906,
      "learning_rate": 1.1132349064065384e-05,
      "loss": 1.9587,
      "step": 8413
    },
    {
      "epoch": 0.499110214734844,
      "grad_norm": 7.5917863845825195,
      "learning_rate": 1.113103084629581e-05,
      "loss": 0.1007,
      "step": 8414
    },
    {
      "epoch": 0.49916953375252104,
      "grad_norm": 11.273893356323242,
      "learning_rate": 1.1129712628526232e-05,
      "loss": 0.2877,
      "step": 8415
    },
    {
      "epoch": 0.49922885277019813,
      "grad_norm": 15.860942840576172,
      "learning_rate": 1.1128394410756658e-05,
      "loss": 0.5287,
      "step": 8416
    },
    {
      "epoch": 0.4992881717878752,
      "grad_norm": 7.781676292419434,
      "learning_rate": 1.1127076192987084e-05,
      "loss": 0.5739,
      "step": 8417
    },
    {
      "epoch": 0.49934749080555224,
      "grad_norm": 0.27972084283828735,
      "learning_rate": 1.1125757975217506e-05,
      "loss": 0.004,
      "step": 8418
    },
    {
      "epoch": 0.4994068098232293,
      "grad_norm": 0.004459668882191181,
      "learning_rate": 1.1124439757447932e-05,
      "loss": 0.0002,
      "step": 8419
    },
    {
      "epoch": 0.4994661288409064,
      "grad_norm": 1.6124595403671265,
      "learning_rate": 1.1123121539678356e-05,
      "loss": 0.0135,
      "step": 8420
    },
    {
      "epoch": 0.49952544785858344,
      "grad_norm": 0.09207538515329361,
      "learning_rate": 1.1121803321908779e-05,
      "loss": 0.0013,
      "step": 8421
    },
    {
      "epoch": 0.4995847668762605,
      "grad_norm": 4.699219226837158,
      "learning_rate": 1.1120485104139205e-05,
      "loss": 0.1459,
      "step": 8422
    },
    {
      "epoch": 0.4996440858939376,
      "grad_norm": 0.7767560482025146,
      "learning_rate": 1.111916688636963e-05,
      "loss": 0.0183,
      "step": 8423
    },
    {
      "epoch": 0.4997034049116147,
      "grad_norm": 12.277469635009766,
      "learning_rate": 1.1117848668600053e-05,
      "loss": 0.1841,
      "step": 8424
    },
    {
      "epoch": 0.4997627239292917,
      "grad_norm": 7.337950706481934,
      "learning_rate": 1.1116530450830479e-05,
      "loss": 0.133,
      "step": 8425
    },
    {
      "epoch": 0.4998220429469688,
      "grad_norm": 1.8867206573486328,
      "learning_rate": 1.1115212233060903e-05,
      "loss": 0.0227,
      "step": 8426
    },
    {
      "epoch": 0.4998813619646459,
      "grad_norm": 0.009212927892804146,
      "learning_rate": 1.1113894015291327e-05,
      "loss": 0.0004,
      "step": 8427
    },
    {
      "epoch": 0.4999406809823229,
      "grad_norm": 1.6176066398620605,
      "learning_rate": 1.1112575797521751e-05,
      "loss": 0.0152,
      "step": 8428
    },
    {
      "epoch": 0.5,
      "grad_norm": 17.349401473999023,
      "learning_rate": 1.1111257579752176e-05,
      "loss": 0.0986,
      "step": 8429
    },
    {
      "epoch": 0.5000593190176771,
      "grad_norm": 0.02369863912463188,
      "learning_rate": 1.11099393619826e-05,
      "loss": 0.0005,
      "step": 8430
    },
    {
      "epoch": 0.5001186380353542,
      "grad_norm": 0.027466116473078728,
      "learning_rate": 1.1108621144213026e-05,
      "loss": 0.0008,
      "step": 8431
    },
    {
      "epoch": 0.5001779570530313,
      "grad_norm": 1.064719796180725,
      "learning_rate": 1.1107302926443448e-05,
      "loss": 0.0207,
      "step": 8432
    },
    {
      "epoch": 0.5002372760707082,
      "grad_norm": 0.017881231382489204,
      "learning_rate": 1.1105984708673874e-05,
      "loss": 0.0006,
      "step": 8433
    },
    {
      "epoch": 0.5002965950883853,
      "grad_norm": 0.16495440900325775,
      "learning_rate": 1.1104666490904298e-05,
      "loss": 0.0017,
      "step": 8434
    },
    {
      "epoch": 0.5003559141060624,
      "grad_norm": 11.9871244430542,
      "learning_rate": 1.1103348273134722e-05,
      "loss": 0.6461,
      "step": 8435
    },
    {
      "epoch": 0.5004152331237395,
      "grad_norm": 0.0442219004034996,
      "learning_rate": 1.1102030055365147e-05,
      "loss": 0.0008,
      "step": 8436
    },
    {
      "epoch": 0.5004745521414166,
      "grad_norm": 6.701050281524658,
      "learning_rate": 1.1100711837595573e-05,
      "loss": 0.3822,
      "step": 8437
    },
    {
      "epoch": 0.5005338711590936,
      "grad_norm": 11.578062057495117,
      "learning_rate": 1.1099393619825995e-05,
      "loss": 0.2553,
      "step": 8438
    },
    {
      "epoch": 0.5005931901767706,
      "grad_norm": 0.6704713702201843,
      "learning_rate": 1.1098075402056421e-05,
      "loss": 0.0052,
      "step": 8439
    },
    {
      "epoch": 0.5006525091944477,
      "grad_norm": 1.476023554801941,
      "learning_rate": 1.1096757184286847e-05,
      "loss": 0.0096,
      "step": 8440
    },
    {
      "epoch": 0.5007118282121248,
      "grad_norm": 0.28898900747299194,
      "learning_rate": 1.109543896651727e-05,
      "loss": 0.0026,
      "step": 8441
    },
    {
      "epoch": 0.5007711472298019,
      "grad_norm": 17.578998565673828,
      "learning_rate": 1.1094120748747695e-05,
      "loss": 0.4528,
      "step": 8442
    },
    {
      "epoch": 0.500830466247479,
      "grad_norm": 3.9312307834625244,
      "learning_rate": 1.109280253097812e-05,
      "loss": 0.0253,
      "step": 8443
    },
    {
      "epoch": 0.500889785265156,
      "grad_norm": 0.2277376651763916,
      "learning_rate": 1.1091484313208542e-05,
      "loss": 0.0034,
      "step": 8444
    },
    {
      "epoch": 0.5009491042828331,
      "grad_norm": 8.184953689575195,
      "learning_rate": 1.1090166095438968e-05,
      "loss": 0.1699,
      "step": 8445
    },
    {
      "epoch": 0.5010084233005101,
      "grad_norm": 2.099351167678833,
      "learning_rate": 1.108884787766939e-05,
      "loss": 0.064,
      "step": 8446
    },
    {
      "epoch": 0.5010677423181872,
      "grad_norm": 0.03004474937915802,
      "learning_rate": 1.1087529659899816e-05,
      "loss": 0.0004,
      "step": 8447
    },
    {
      "epoch": 0.5011270613358643,
      "grad_norm": 4.413609504699707,
      "learning_rate": 1.1086211442130242e-05,
      "loss": 0.0333,
      "step": 8448
    },
    {
      "epoch": 0.5011863803535413,
      "grad_norm": 0.7639375925064087,
      "learning_rate": 1.1084893224360664e-05,
      "loss": 0.0099,
      "step": 8449
    },
    {
      "epoch": 0.5012456993712184,
      "grad_norm": 0.13278816640377045,
      "learning_rate": 1.108357500659109e-05,
      "loss": 0.0017,
      "step": 8450
    },
    {
      "epoch": 0.5013050183888955,
      "grad_norm": 30.938230514526367,
      "learning_rate": 1.1082256788821515e-05,
      "loss": 0.0489,
      "step": 8451
    },
    {
      "epoch": 0.5013643374065726,
      "grad_norm": 5.5756707191467285,
      "learning_rate": 1.1080938571051939e-05,
      "loss": 0.1806,
      "step": 8452
    },
    {
      "epoch": 0.5014236564242496,
      "grad_norm": 8.134614944458008,
      "learning_rate": 1.1079620353282363e-05,
      "loss": 0.1449,
      "step": 8453
    },
    {
      "epoch": 0.5014829754419267,
      "grad_norm": 5.829858779907227,
      "learning_rate": 1.1078302135512789e-05,
      "loss": 0.0346,
      "step": 8454
    },
    {
      "epoch": 0.5015422944596037,
      "grad_norm": 22.98179817199707,
      "learning_rate": 1.1076983917743211e-05,
      "loss": 0.9695,
      "step": 8455
    },
    {
      "epoch": 0.5016016134772808,
      "grad_norm": 0.5050269365310669,
      "learning_rate": 1.1075665699973637e-05,
      "loss": 0.0036,
      "step": 8456
    },
    {
      "epoch": 0.5016609324949579,
      "grad_norm": 5.789331912994385,
      "learning_rate": 1.1074347482204061e-05,
      "loss": 0.2656,
      "step": 8457
    },
    {
      "epoch": 0.501720251512635,
      "grad_norm": 0.2317311018705368,
      "learning_rate": 1.1073029264434486e-05,
      "loss": 0.0032,
      "step": 8458
    },
    {
      "epoch": 0.501779570530312,
      "grad_norm": 27.800405502319336,
      "learning_rate": 1.107171104666491e-05,
      "loss": 1.132,
      "step": 8459
    },
    {
      "epoch": 0.501838889547989,
      "grad_norm": 0.01739056594669819,
      "learning_rate": 1.1070392828895336e-05,
      "loss": 0.0004,
      "step": 8460
    },
    {
      "epoch": 0.5018982085656661,
      "grad_norm": 2.04872465133667,
      "learning_rate": 1.1069074611125758e-05,
      "loss": 0.0053,
      "step": 8461
    },
    {
      "epoch": 0.5019575275833432,
      "grad_norm": 4.923789978027344,
      "learning_rate": 1.1067756393356184e-05,
      "loss": 0.0563,
      "step": 8462
    },
    {
      "epoch": 0.5020168466010203,
      "grad_norm": 0.8652389049530029,
      "learning_rate": 1.1066438175586606e-05,
      "loss": 0.0135,
      "step": 8463
    },
    {
      "epoch": 0.5020761656186974,
      "grad_norm": 2.063383102416992,
      "learning_rate": 1.1065119957817032e-05,
      "loss": 0.0175,
      "step": 8464
    },
    {
      "epoch": 0.5021354846363745,
      "grad_norm": 0.608689546585083,
      "learning_rate": 1.1063801740047457e-05,
      "loss": 0.0077,
      "step": 8465
    },
    {
      "epoch": 0.5021948036540514,
      "grad_norm": 3.1213278770446777,
      "learning_rate": 1.106248352227788e-05,
      "loss": 0.5252,
      "step": 8466
    },
    {
      "epoch": 0.5022541226717285,
      "grad_norm": 7.65170955657959,
      "learning_rate": 1.1061165304508305e-05,
      "loss": 0.1177,
      "step": 8467
    },
    {
      "epoch": 0.5023134416894056,
      "grad_norm": 0.01810315065085888,
      "learning_rate": 1.105984708673873e-05,
      "loss": 0.0005,
      "step": 8468
    },
    {
      "epoch": 0.5023727607070827,
      "grad_norm": 2.8155593872070312,
      "learning_rate": 1.1058528868969153e-05,
      "loss": 0.0419,
      "step": 8469
    },
    {
      "epoch": 0.5024320797247598,
      "grad_norm": 7.836465835571289,
      "learning_rate": 1.1057210651199579e-05,
      "loss": 0.3476,
      "step": 8470
    },
    {
      "epoch": 0.5024913987424369,
      "grad_norm": 6.42543363571167,
      "learning_rate": 1.1055892433430005e-05,
      "loss": 0.3825,
      "step": 8471
    },
    {
      "epoch": 0.5025507177601138,
      "grad_norm": 0.07001980394124985,
      "learning_rate": 1.1054574215660428e-05,
      "loss": 0.001,
      "step": 8472
    },
    {
      "epoch": 0.5026100367777909,
      "grad_norm": 0.02365497127175331,
      "learning_rate": 1.1053255997890853e-05,
      "loss": 0.0007,
      "step": 8473
    },
    {
      "epoch": 0.502669355795468,
      "grad_norm": 0.02665107510983944,
      "learning_rate": 1.1051937780121278e-05,
      "loss": 0.0006,
      "step": 8474
    },
    {
      "epoch": 0.5027286748131451,
      "grad_norm": 5.192366123199463,
      "learning_rate": 1.1050619562351702e-05,
      "loss": 0.2246,
      "step": 8475
    },
    {
      "epoch": 0.5027879938308222,
      "grad_norm": 0.9784720540046692,
      "learning_rate": 1.1049301344582126e-05,
      "loss": 0.0112,
      "step": 8476
    },
    {
      "epoch": 0.5028473128484993,
      "grad_norm": 6.505825996398926,
      "learning_rate": 1.1047983126812548e-05,
      "loss": 0.0908,
      "step": 8477
    },
    {
      "epoch": 0.5029066318661763,
      "grad_norm": 7.264365196228027,
      "learning_rate": 1.1046664909042974e-05,
      "loss": 0.3257,
      "step": 8478
    },
    {
      "epoch": 0.5029659508838533,
      "grad_norm": 0.045126885175704956,
      "learning_rate": 1.10453466912734e-05,
      "loss": 0.0007,
      "step": 8479
    },
    {
      "epoch": 0.5030252699015304,
      "grad_norm": 0.08607681095600128,
      "learning_rate": 1.1044028473503823e-05,
      "loss": 0.0006,
      "step": 8480
    },
    {
      "epoch": 0.5030845889192075,
      "grad_norm": 2.809744358062744,
      "learning_rate": 1.1042710255734249e-05,
      "loss": 0.0308,
      "step": 8481
    },
    {
      "epoch": 0.5031439079368846,
      "grad_norm": 0.05420292913913727,
      "learning_rate": 1.1041392037964673e-05,
      "loss": 0.001,
      "step": 8482
    },
    {
      "epoch": 0.5032032269545617,
      "grad_norm": 0.03984919562935829,
      "learning_rate": 1.1040073820195097e-05,
      "loss": 0.0005,
      "step": 8483
    },
    {
      "epoch": 0.5032625459722387,
      "grad_norm": 0.8576728105545044,
      "learning_rate": 1.1038755602425521e-05,
      "loss": 0.0114,
      "step": 8484
    },
    {
      "epoch": 0.5033218649899157,
      "grad_norm": 6.176737308502197,
      "learning_rate": 1.1037437384655947e-05,
      "loss": 0.1881,
      "step": 8485
    },
    {
      "epoch": 0.5033811840075928,
      "grad_norm": 10.150883674621582,
      "learning_rate": 1.103611916688637e-05,
      "loss": 0.4689,
      "step": 8486
    },
    {
      "epoch": 0.5034405030252699,
      "grad_norm": 13.145820617675781,
      "learning_rate": 1.1034800949116795e-05,
      "loss": 0.017,
      "step": 8487
    },
    {
      "epoch": 0.503499822042947,
      "grad_norm": 18.805835723876953,
      "learning_rate": 1.103348273134722e-05,
      "loss": 0.4873,
      "step": 8488
    },
    {
      "epoch": 0.503559141060624,
      "grad_norm": 18.614686965942383,
      "learning_rate": 1.1032164513577644e-05,
      "loss": 1.2657,
      "step": 8489
    },
    {
      "epoch": 0.5036184600783011,
      "grad_norm": 16.671274185180664,
      "learning_rate": 1.1030846295808068e-05,
      "loss": 0.8668,
      "step": 8490
    },
    {
      "epoch": 0.5036777790959782,
      "grad_norm": 1.226138710975647,
      "learning_rate": 1.1029528078038494e-05,
      "loss": 0.0103,
      "step": 8491
    },
    {
      "epoch": 0.5037370981136552,
      "grad_norm": 0.05683177709579468,
      "learning_rate": 1.1028209860268916e-05,
      "loss": 0.0016,
      "step": 8492
    },
    {
      "epoch": 0.5037964171313323,
      "grad_norm": 2.0675835609436035,
      "learning_rate": 1.1026891642499342e-05,
      "loss": 0.1125,
      "step": 8493
    },
    {
      "epoch": 0.5038557361490094,
      "grad_norm": 23.91985511779785,
      "learning_rate": 1.1025573424729765e-05,
      "loss": 1.3952,
      "step": 8494
    },
    {
      "epoch": 0.5039150551666864,
      "grad_norm": 10.483007431030273,
      "learning_rate": 1.102425520696019e-05,
      "loss": 0.9424,
      "step": 8495
    },
    {
      "epoch": 0.5039743741843635,
      "grad_norm": 0.1421370953321457,
      "learning_rate": 1.1022936989190616e-05,
      "loss": 0.0013,
      "step": 8496
    },
    {
      "epoch": 0.5040336932020406,
      "grad_norm": 12.590766906738281,
      "learning_rate": 1.1021618771421039e-05,
      "loss": 0.262,
      "step": 8497
    },
    {
      "epoch": 0.5040930122197177,
      "grad_norm": 24.136138916015625,
      "learning_rate": 1.1020300553651463e-05,
      "loss": 1.3395,
      "step": 8498
    },
    {
      "epoch": 0.5041523312373947,
      "grad_norm": 0.10441805422306061,
      "learning_rate": 1.1018982335881889e-05,
      "loss": 0.0028,
      "step": 8499
    },
    {
      "epoch": 0.5042116502550718,
      "grad_norm": 1.7021158933639526,
      "learning_rate": 1.1017664118112312e-05,
      "loss": 0.013,
      "step": 8500
    },
    {
      "epoch": 0.5042709692727488,
      "grad_norm": 3.1670615673065186,
      "learning_rate": 1.1016345900342737e-05,
      "loss": 0.0296,
      "step": 8501
    },
    {
      "epoch": 0.5043302882904259,
      "grad_norm": 3.196977138519287,
      "learning_rate": 1.1015027682573163e-05,
      "loss": 0.0293,
      "step": 8502
    },
    {
      "epoch": 0.504389607308103,
      "grad_norm": 3.9932682514190674,
      "learning_rate": 1.1013709464803586e-05,
      "loss": 0.0051,
      "step": 8503
    },
    {
      "epoch": 0.5044489263257801,
      "grad_norm": 0.9210492968559265,
      "learning_rate": 1.1012391247034012e-05,
      "loss": 0.004,
      "step": 8504
    },
    {
      "epoch": 0.5045082453434571,
      "grad_norm": 3.0326085090637207,
      "learning_rate": 1.1011073029264436e-05,
      "loss": 0.0114,
      "step": 8505
    },
    {
      "epoch": 0.5045675643611341,
      "grad_norm": 20.062135696411133,
      "learning_rate": 1.100975481149486e-05,
      "loss": 0.7456,
      "step": 8506
    },
    {
      "epoch": 0.5046268833788112,
      "grad_norm": 1.755859613418579,
      "learning_rate": 1.1008436593725284e-05,
      "loss": 0.0065,
      "step": 8507
    },
    {
      "epoch": 0.5046862023964883,
      "grad_norm": 0.029827596619725227,
      "learning_rate": 1.100711837595571e-05,
      "loss": 0.0006,
      "step": 8508
    },
    {
      "epoch": 0.5047455214141654,
      "grad_norm": 8.505495071411133,
      "learning_rate": 1.1005800158186133e-05,
      "loss": 0.0995,
      "step": 8509
    },
    {
      "epoch": 0.5048048404318425,
      "grad_norm": 5.322393417358398,
      "learning_rate": 1.1004481940416558e-05,
      "loss": 0.3556,
      "step": 8510
    },
    {
      "epoch": 0.5048641594495196,
      "grad_norm": 18.494998931884766,
      "learning_rate": 1.1003163722646981e-05,
      "loss": 0.3791,
      "step": 8511
    },
    {
      "epoch": 0.5049234784671965,
      "grad_norm": 5.6313300132751465,
      "learning_rate": 1.1001845504877407e-05,
      "loss": 0.0966,
      "step": 8512
    },
    {
      "epoch": 0.5049827974848736,
      "grad_norm": 0.0726604014635086,
      "learning_rate": 1.1000527287107831e-05,
      "loss": 0.0016,
      "step": 8513
    },
    {
      "epoch": 0.5050421165025507,
      "grad_norm": 2.0638272762298584,
      "learning_rate": 1.0999209069338255e-05,
      "loss": 0.0241,
      "step": 8514
    },
    {
      "epoch": 0.5051014355202278,
      "grad_norm": 13.980950355529785,
      "learning_rate": 1.099789085156868e-05,
      "loss": 0.9417,
      "step": 8515
    },
    {
      "epoch": 0.5051607545379049,
      "grad_norm": 0.0303543321788311,
      "learning_rate": 1.0996572633799105e-05,
      "loss": 0.0008,
      "step": 8516
    },
    {
      "epoch": 0.505220073555582,
      "grad_norm": 0.02885918691754341,
      "learning_rate": 1.0995254416029528e-05,
      "loss": 0.0005,
      "step": 8517
    },
    {
      "epoch": 0.5052793925732589,
      "grad_norm": 0.08745819330215454,
      "learning_rate": 1.0993936198259954e-05,
      "loss": 0.0016,
      "step": 8518
    },
    {
      "epoch": 0.505338711590936,
      "grad_norm": 30.03864860534668,
      "learning_rate": 1.099261798049038e-05,
      "loss": 0.2924,
      "step": 8519
    },
    {
      "epoch": 0.5053980306086131,
      "grad_norm": 0.16277596354484558,
      "learning_rate": 1.0991299762720802e-05,
      "loss": 0.0038,
      "step": 8520
    },
    {
      "epoch": 0.5054573496262902,
      "grad_norm": 0.028012944385409355,
      "learning_rate": 1.0989981544951226e-05,
      "loss": 0.0007,
      "step": 8521
    },
    {
      "epoch": 0.5055166686439673,
      "grad_norm": 0.0699709877371788,
      "learning_rate": 1.0988663327181652e-05,
      "loss": 0.0013,
      "step": 8522
    },
    {
      "epoch": 0.5055759876616444,
      "grad_norm": 0.0570320226252079,
      "learning_rate": 1.0987345109412075e-05,
      "loss": 0.0012,
      "step": 8523
    },
    {
      "epoch": 0.5056353066793214,
      "grad_norm": 13.074149131774902,
      "learning_rate": 1.09860268916425e-05,
      "loss": 0.5159,
      "step": 8524
    },
    {
      "epoch": 0.5056946256969984,
      "grad_norm": 7.696793556213379,
      "learning_rate": 1.0984708673872923e-05,
      "loss": 0.2044,
      "step": 8525
    },
    {
      "epoch": 0.5057539447146755,
      "grad_norm": 0.9187893867492676,
      "learning_rate": 1.0983390456103349e-05,
      "loss": 0.0143,
      "step": 8526
    },
    {
      "epoch": 0.5058132637323526,
      "grad_norm": 0.03726634755730629,
      "learning_rate": 1.0982072238333775e-05,
      "loss": 0.001,
      "step": 8527
    },
    {
      "epoch": 0.5058725827500297,
      "grad_norm": 0.09186524152755737,
      "learning_rate": 1.0980754020564197e-05,
      "loss": 0.0012,
      "step": 8528
    },
    {
      "epoch": 0.5059319017677067,
      "grad_norm": 0.19905543327331543,
      "learning_rate": 1.0979435802794623e-05,
      "loss": 0.0031,
      "step": 8529
    },
    {
      "epoch": 0.5059912207853838,
      "grad_norm": 33.78515625,
      "learning_rate": 1.0978117585025047e-05,
      "loss": 0.3769,
      "step": 8530
    },
    {
      "epoch": 0.5060505398030608,
      "grad_norm": 12.644881248474121,
      "learning_rate": 1.0976799367255472e-05,
      "loss": 0.3011,
      "step": 8531
    },
    {
      "epoch": 0.5061098588207379,
      "grad_norm": 2.173305034637451,
      "learning_rate": 1.0975481149485896e-05,
      "loss": 0.0146,
      "step": 8532
    },
    {
      "epoch": 0.506169177838415,
      "grad_norm": 0.03192912042140961,
      "learning_rate": 1.0974162931716322e-05,
      "loss": 0.0006,
      "step": 8533
    },
    {
      "epoch": 0.5062284968560921,
      "grad_norm": 0.20406295359134674,
      "learning_rate": 1.0972844713946744e-05,
      "loss": 0.0025,
      "step": 8534
    },
    {
      "epoch": 0.5062878158737691,
      "grad_norm": 0.7836157083511353,
      "learning_rate": 1.097152649617717e-05,
      "loss": 0.0094,
      "step": 8535
    },
    {
      "epoch": 0.5063471348914462,
      "grad_norm": 9.039039611816406,
      "learning_rate": 1.0970208278407594e-05,
      "loss": 0.7613,
      "step": 8536
    },
    {
      "epoch": 0.5064064539091233,
      "grad_norm": 18.665496826171875,
      "learning_rate": 1.0968890060638018e-05,
      "loss": 0.2855,
      "step": 8537
    },
    {
      "epoch": 0.5064657729268003,
      "grad_norm": 13.63433837890625,
      "learning_rate": 1.0967571842868443e-05,
      "loss": 0.4704,
      "step": 8538
    },
    {
      "epoch": 0.5065250919444774,
      "grad_norm": 0.029606761410832405,
      "learning_rate": 1.0966253625098868e-05,
      "loss": 0.0007,
      "step": 8539
    },
    {
      "epoch": 0.5065844109621545,
      "grad_norm": 8.564101219177246,
      "learning_rate": 1.0964935407329291e-05,
      "loss": 0.5013,
      "step": 8540
    },
    {
      "epoch": 0.5066437299798315,
      "grad_norm": 8.331637382507324,
      "learning_rate": 1.0963617189559717e-05,
      "loss": 0.4672,
      "step": 8541
    },
    {
      "epoch": 0.5067030489975086,
      "grad_norm": 0.11543744057416916,
      "learning_rate": 1.096229897179014e-05,
      "loss": 0.001,
      "step": 8542
    },
    {
      "epoch": 0.5067623680151857,
      "grad_norm": 9.8567533493042,
      "learning_rate": 1.0960980754020565e-05,
      "loss": 0.2544,
      "step": 8543
    },
    {
      "epoch": 0.5068216870328628,
      "grad_norm": 10.559136390686035,
      "learning_rate": 1.095966253625099e-05,
      "loss": 0.253,
      "step": 8544
    },
    {
      "epoch": 0.5068810060505398,
      "grad_norm": 4.569481372833252,
      "learning_rate": 1.0958344318481414e-05,
      "loss": 0.1528,
      "step": 8545
    },
    {
      "epoch": 0.5069403250682168,
      "grad_norm": 23.096149444580078,
      "learning_rate": 1.0957026100711838e-05,
      "loss": 0.3424,
      "step": 8546
    },
    {
      "epoch": 0.5069996440858939,
      "grad_norm": 4.175853729248047,
      "learning_rate": 1.0955707882942264e-05,
      "loss": 0.1355,
      "step": 8547
    },
    {
      "epoch": 0.507058963103571,
      "grad_norm": 10.819415092468262,
      "learning_rate": 1.0954389665172686e-05,
      "loss": 0.1114,
      "step": 8548
    },
    {
      "epoch": 0.5071182821212481,
      "grad_norm": 1.5009881258010864,
      "learning_rate": 1.0953071447403112e-05,
      "loss": 0.0373,
      "step": 8549
    },
    {
      "epoch": 0.5071776011389252,
      "grad_norm": 6.336913585662842,
      "learning_rate": 1.0951753229633538e-05,
      "loss": 0.027,
      "step": 8550
    },
    {
      "epoch": 0.5072369201566022,
      "grad_norm": 0.6535090804100037,
      "learning_rate": 1.095043501186396e-05,
      "loss": 0.0063,
      "step": 8551
    },
    {
      "epoch": 0.5072962391742792,
      "grad_norm": 6.397334575653076,
      "learning_rate": 1.0949116794094386e-05,
      "loss": 0.0439,
      "step": 8552
    },
    {
      "epoch": 0.5073555581919563,
      "grad_norm": 0.005680460948497057,
      "learning_rate": 1.094779857632481e-05,
      "loss": 0.0002,
      "step": 8553
    },
    {
      "epoch": 0.5074148772096334,
      "grad_norm": 0.037376657128334045,
      "learning_rate": 1.0946480358555233e-05,
      "loss": 0.0011,
      "step": 8554
    },
    {
      "epoch": 0.5074741962273105,
      "grad_norm": 3.541118621826172,
      "learning_rate": 1.0945162140785659e-05,
      "loss": 0.6088,
      "step": 8555
    },
    {
      "epoch": 0.5075335152449876,
      "grad_norm": 6.930386543273926,
      "learning_rate": 1.0943843923016085e-05,
      "loss": 0.0468,
      "step": 8556
    },
    {
      "epoch": 0.5075928342626647,
      "grad_norm": 0.13113032281398773,
      "learning_rate": 1.0942525705246507e-05,
      "loss": 0.0013,
      "step": 8557
    },
    {
      "epoch": 0.5076521532803416,
      "grad_norm": 13.50830364227295,
      "learning_rate": 1.0941207487476933e-05,
      "loss": 0.099,
      "step": 8558
    },
    {
      "epoch": 0.5077114722980187,
      "grad_norm": 31.22781753540039,
      "learning_rate": 1.0939889269707356e-05,
      "loss": 0.0622,
      "step": 8559
    },
    {
      "epoch": 0.5077707913156958,
      "grad_norm": 0.11405913531780243,
      "learning_rate": 1.0938571051937781e-05,
      "loss": 0.0019,
      "step": 8560
    },
    {
      "epoch": 0.5078301103333729,
      "grad_norm": 10.81037712097168,
      "learning_rate": 1.0937252834168206e-05,
      "loss": 0.7257,
      "step": 8561
    },
    {
      "epoch": 0.50788942935105,
      "grad_norm": 7.7187089920043945,
      "learning_rate": 1.093593461639863e-05,
      "loss": 0.1155,
      "step": 8562
    },
    {
      "epoch": 0.507948748368727,
      "grad_norm": 0.024885348975658417,
      "learning_rate": 1.0934616398629054e-05,
      "loss": 0.0008,
      "step": 8563
    },
    {
      "epoch": 0.508008067386404,
      "grad_norm": 8.169700622558594,
      "learning_rate": 1.093329818085948e-05,
      "loss": 0.1147,
      "step": 8564
    },
    {
      "epoch": 0.5080673864040811,
      "grad_norm": 0.2750648260116577,
      "learning_rate": 1.0931979963089902e-05,
      "loss": 0.004,
      "step": 8565
    },
    {
      "epoch": 0.5081267054217582,
      "grad_norm": 3.2631447315216064,
      "learning_rate": 1.0930661745320328e-05,
      "loss": 0.0473,
      "step": 8566
    },
    {
      "epoch": 0.5081860244394353,
      "grad_norm": 0.2240004986524582,
      "learning_rate": 1.0929343527550752e-05,
      "loss": 0.0033,
      "step": 8567
    },
    {
      "epoch": 0.5082453434571124,
      "grad_norm": 19.34635353088379,
      "learning_rate": 1.0928025309781177e-05,
      "loss": 0.8733,
      "step": 8568
    },
    {
      "epoch": 0.5083046624747894,
      "grad_norm": 9.039205551147461,
      "learning_rate": 1.09267070920116e-05,
      "loss": 0.0817,
      "step": 8569
    },
    {
      "epoch": 0.5083639814924665,
      "grad_norm": 0.1989762783050537,
      "learning_rate": 1.0925388874242027e-05,
      "loss": 0.0031,
      "step": 8570
    },
    {
      "epoch": 0.5084233005101435,
      "grad_norm": 20.204498291015625,
      "learning_rate": 1.092407065647245e-05,
      "loss": 0.5695,
      "step": 8571
    },
    {
      "epoch": 0.5084826195278206,
      "grad_norm": 0.788544237613678,
      "learning_rate": 1.0922752438702875e-05,
      "loss": 0.0107,
      "step": 8572
    },
    {
      "epoch": 0.5085419385454977,
      "grad_norm": 0.9299301505088806,
      "learning_rate": 1.0921434220933298e-05,
      "loss": 0.0095,
      "step": 8573
    },
    {
      "epoch": 0.5086012575631748,
      "grad_norm": 20.23377227783203,
      "learning_rate": 1.0920116003163723e-05,
      "loss": 0.3052,
      "step": 8574
    },
    {
      "epoch": 0.5086605765808518,
      "grad_norm": 3.6877989768981934,
      "learning_rate": 1.091879778539415e-05,
      "loss": 0.0576,
      "step": 8575
    },
    {
      "epoch": 0.5087198955985289,
      "grad_norm": 2.1382927894592285,
      "learning_rate": 1.0917479567624572e-05,
      "loss": 0.0276,
      "step": 8576
    },
    {
      "epoch": 0.508779214616206,
      "grad_norm": 0.02837260253727436,
      "learning_rate": 1.0916161349854996e-05,
      "loss": 0.0008,
      "step": 8577
    },
    {
      "epoch": 0.508838533633883,
      "grad_norm": 5.25780725479126,
      "learning_rate": 1.0914843132085422e-05,
      "loss": 0.0841,
      "step": 8578
    },
    {
      "epoch": 0.5088978526515601,
      "grad_norm": 8.975408554077148,
      "learning_rate": 1.0913524914315844e-05,
      "loss": 0.1955,
      "step": 8579
    },
    {
      "epoch": 0.5089571716692372,
      "grad_norm": 0.22293239831924438,
      "learning_rate": 1.091220669654627e-05,
      "loss": 0.0032,
      "step": 8580
    },
    {
      "epoch": 0.5090164906869142,
      "grad_norm": 0.02527438849210739,
      "learning_rate": 1.0910888478776696e-05,
      "loss": 0.001,
      "step": 8581
    },
    {
      "epoch": 0.5090758097045913,
      "grad_norm": 20.367597579956055,
      "learning_rate": 1.0909570261007119e-05,
      "loss": 0.4259,
      "step": 8582
    },
    {
      "epoch": 0.5091351287222684,
      "grad_norm": 6.236671447753906,
      "learning_rate": 1.0908252043237544e-05,
      "loss": 0.0596,
      "step": 8583
    },
    {
      "epoch": 0.5091944477399454,
      "grad_norm": 2.586275100708008,
      "learning_rate": 1.0906933825467969e-05,
      "loss": 0.0551,
      "step": 8584
    },
    {
      "epoch": 0.5092537667576225,
      "grad_norm": 1.4105417728424072,
      "learning_rate": 1.0905615607698393e-05,
      "loss": 0.0273,
      "step": 8585
    },
    {
      "epoch": 0.5093130857752995,
      "grad_norm": 0.13999004662036896,
      "learning_rate": 1.0904297389928817e-05,
      "loss": 0.0022,
      "step": 8586
    },
    {
      "epoch": 0.5093724047929766,
      "grad_norm": 1.0926365852355957,
      "learning_rate": 1.0902979172159243e-05,
      "loss": 0.0203,
      "step": 8587
    },
    {
      "epoch": 0.5094317238106537,
      "grad_norm": 0.09337320178747177,
      "learning_rate": 1.0901660954389665e-05,
      "loss": 0.0019,
      "step": 8588
    },
    {
      "epoch": 0.5094910428283308,
      "grad_norm": 0.13888543844223022,
      "learning_rate": 1.0900342736620091e-05,
      "loss": 0.0036,
      "step": 8589
    },
    {
      "epoch": 0.5095503618460079,
      "grad_norm": 0.9909214973449707,
      "learning_rate": 1.0899024518850514e-05,
      "loss": 0.0139,
      "step": 8590
    },
    {
      "epoch": 0.5096096808636849,
      "grad_norm": 1.9540477991104126,
      "learning_rate": 1.089770630108094e-05,
      "loss": 0.0275,
      "step": 8591
    },
    {
      "epoch": 0.5096689998813619,
      "grad_norm": 2.1200497150421143,
      "learning_rate": 1.0896388083311364e-05,
      "loss": 0.1693,
      "step": 8592
    },
    {
      "epoch": 0.509728318899039,
      "grad_norm": 8.64317512512207,
      "learning_rate": 1.0895069865541788e-05,
      "loss": 0.7539,
      "step": 8593
    },
    {
      "epoch": 0.5097876379167161,
      "grad_norm": 3.1107425689697266,
      "learning_rate": 1.0893751647772212e-05,
      "loss": 0.0237,
      "step": 8594
    },
    {
      "epoch": 0.5098469569343932,
      "grad_norm": 0.11873846501111984,
      "learning_rate": 1.0892433430002638e-05,
      "loss": 0.0018,
      "step": 8595
    },
    {
      "epoch": 0.5099062759520703,
      "grad_norm": 0.16376402974128723,
      "learning_rate": 1.089111521223306e-05,
      "loss": 0.0026,
      "step": 8596
    },
    {
      "epoch": 0.5099655949697472,
      "grad_norm": 0.344089150428772,
      "learning_rate": 1.0889796994463486e-05,
      "loss": 0.0051,
      "step": 8597
    },
    {
      "epoch": 0.5100249139874243,
      "grad_norm": 6.977766513824463,
      "learning_rate": 1.088847877669391e-05,
      "loss": 0.101,
      "step": 8598
    },
    {
      "epoch": 0.5100842330051014,
      "grad_norm": 0.21024096012115479,
      "learning_rate": 1.0887160558924335e-05,
      "loss": 0.004,
      "step": 8599
    },
    {
      "epoch": 0.5101435520227785,
      "grad_norm": 3.6382596492767334,
      "learning_rate": 1.0885842341154759e-05,
      "loss": 0.0655,
      "step": 8600
    },
    {
      "epoch": 0.5102028710404556,
      "grad_norm": 0.2786114811897278,
      "learning_rate": 1.0884524123385185e-05,
      "loss": 0.0066,
      "step": 8601
    },
    {
      "epoch": 0.5102621900581327,
      "grad_norm": 6.764211654663086,
      "learning_rate": 1.0883205905615607e-05,
      "loss": 0.0871,
      "step": 8602
    },
    {
      "epoch": 0.5103215090758098,
      "grad_norm": 0.19452109932899475,
      "learning_rate": 1.0881887687846033e-05,
      "loss": 0.0034,
      "step": 8603
    },
    {
      "epoch": 0.5103808280934867,
      "grad_norm": 0.1338261216878891,
      "learning_rate": 1.088056947007646e-05,
      "loss": 0.0023,
      "step": 8604
    },
    {
      "epoch": 0.5104401471111638,
      "grad_norm": 3.657716751098633,
      "learning_rate": 1.0879251252306882e-05,
      "loss": 0.3489,
      "step": 8605
    },
    {
      "epoch": 0.5104994661288409,
      "grad_norm": 4.17348051071167,
      "learning_rate": 1.0877933034537308e-05,
      "loss": 0.0173,
      "step": 8606
    },
    {
      "epoch": 0.510558785146518,
      "grad_norm": 0.5711323618888855,
      "learning_rate": 1.087661481676773e-05,
      "loss": 0.0092,
      "step": 8607
    },
    {
      "epoch": 0.5106181041641951,
      "grad_norm": 5.681066036224365,
      "learning_rate": 1.0875296598998156e-05,
      "loss": 0.0937,
      "step": 8608
    },
    {
      "epoch": 0.5106774231818721,
      "grad_norm": 0.01327312272042036,
      "learning_rate": 1.087397838122858e-05,
      "loss": 0.0004,
      "step": 8609
    },
    {
      "epoch": 0.5107367421995491,
      "grad_norm": 0.1428852081298828,
      "learning_rate": 1.0872660163459003e-05,
      "loss": 0.0023,
      "step": 8610
    },
    {
      "epoch": 0.5107960612172262,
      "grad_norm": 2.989309549331665,
      "learning_rate": 1.0871341945689428e-05,
      "loss": 0.0073,
      "step": 8611
    },
    {
      "epoch": 0.5108553802349033,
      "grad_norm": 5.4944167137146,
      "learning_rate": 1.0870023727919854e-05,
      "loss": 0.1799,
      "step": 8612
    },
    {
      "epoch": 0.5109146992525804,
      "grad_norm": 0.2813839018344879,
      "learning_rate": 1.0868705510150277e-05,
      "loss": 0.0046,
      "step": 8613
    },
    {
      "epoch": 0.5109740182702575,
      "grad_norm": 2.1064207553863525,
      "learning_rate": 1.0867387292380703e-05,
      "loss": 0.0232,
      "step": 8614
    },
    {
      "epoch": 0.5110333372879345,
      "grad_norm": 0.6372193098068237,
      "learning_rate": 1.0866069074611127e-05,
      "loss": 0.0046,
      "step": 8615
    },
    {
      "epoch": 0.5110926563056116,
      "grad_norm": 7.2734808921813965,
      "learning_rate": 1.0864750856841551e-05,
      "loss": 0.0666,
      "step": 8616
    },
    {
      "epoch": 0.5111519753232886,
      "grad_norm": 0.2629203498363495,
      "learning_rate": 1.0863432639071975e-05,
      "loss": 0.0028,
      "step": 8617
    },
    {
      "epoch": 0.5112112943409657,
      "grad_norm": 0.19316986203193665,
      "learning_rate": 1.0862114421302401e-05,
      "loss": 0.0028,
      "step": 8618
    },
    {
      "epoch": 0.5112706133586428,
      "grad_norm": 0.11355751007795334,
      "learning_rate": 1.0860796203532824e-05,
      "loss": 0.0028,
      "step": 8619
    },
    {
      "epoch": 0.5113299323763199,
      "grad_norm": 52.11806869506836,
      "learning_rate": 1.085947798576325e-05,
      "loss": 2.0316,
      "step": 8620
    },
    {
      "epoch": 0.5113892513939969,
      "grad_norm": 3.6757566928863525,
      "learning_rate": 1.0858159767993674e-05,
      "loss": 0.0409,
      "step": 8621
    },
    {
      "epoch": 0.511448570411674,
      "grad_norm": 2.301290988922119,
      "learning_rate": 1.0856841550224098e-05,
      "loss": 0.0588,
      "step": 8622
    },
    {
      "epoch": 0.5115078894293511,
      "grad_norm": 3.7820687294006348,
      "learning_rate": 1.0855523332454522e-05,
      "loss": 0.0297,
      "step": 8623
    },
    {
      "epoch": 0.5115672084470281,
      "grad_norm": 2.928459644317627,
      "learning_rate": 1.0854205114684946e-05,
      "loss": 0.0926,
      "step": 8624
    },
    {
      "epoch": 0.5116265274647052,
      "grad_norm": 7.364078521728516,
      "learning_rate": 1.085288689691537e-05,
      "loss": 0.0981,
      "step": 8625
    },
    {
      "epoch": 0.5116858464823822,
      "grad_norm": 3.48284649848938,
      "learning_rate": 1.0851568679145796e-05,
      "loss": 0.0299,
      "step": 8626
    },
    {
      "epoch": 0.5117451655000593,
      "grad_norm": 8.145045280456543,
      "learning_rate": 1.0850250461376219e-05,
      "loss": 0.0902,
      "step": 8627
    },
    {
      "epoch": 0.5118044845177364,
      "grad_norm": 0.5094738006591797,
      "learning_rate": 1.0848932243606645e-05,
      "loss": 0.0105,
      "step": 8628
    },
    {
      "epoch": 0.5118638035354135,
      "grad_norm": 2.903859853744507,
      "learning_rate": 1.084761402583707e-05,
      "loss": 0.0367,
      "step": 8629
    },
    {
      "epoch": 0.5119231225530905,
      "grad_norm": 0.370540589094162,
      "learning_rate": 1.0846295808067493e-05,
      "loss": 0.0072,
      "step": 8630
    },
    {
      "epoch": 0.5119824415707676,
      "grad_norm": 0.6133731603622437,
      "learning_rate": 1.0844977590297919e-05,
      "loss": 0.01,
      "step": 8631
    },
    {
      "epoch": 0.5120417605884446,
      "grad_norm": 0.0897490456700325,
      "learning_rate": 1.0843659372528343e-05,
      "loss": 0.0015,
      "step": 8632
    },
    {
      "epoch": 0.5121010796061217,
      "grad_norm": 8.114335060119629,
      "learning_rate": 1.0842341154758766e-05,
      "loss": 0.3227,
      "step": 8633
    },
    {
      "epoch": 0.5121603986237988,
      "grad_norm": 0.47746413946151733,
      "learning_rate": 1.0841022936989192e-05,
      "loss": 0.0028,
      "step": 8634
    },
    {
      "epoch": 0.5122197176414759,
      "grad_norm": 93.38587188720703,
      "learning_rate": 1.0839704719219617e-05,
      "loss": 0.5819,
      "step": 8635
    },
    {
      "epoch": 0.512279036659153,
      "grad_norm": 1.1433489322662354,
      "learning_rate": 1.083838650145004e-05,
      "loss": 0.0078,
      "step": 8636
    },
    {
      "epoch": 0.51233835567683,
      "grad_norm": 0.05855007842183113,
      "learning_rate": 1.0837068283680466e-05,
      "loss": 0.0011,
      "step": 8637
    },
    {
      "epoch": 0.512397674694507,
      "grad_norm": 0.625411868095398,
      "learning_rate": 1.0835750065910888e-05,
      "loss": 0.0089,
      "step": 8638
    },
    {
      "epoch": 0.5124569937121841,
      "grad_norm": 1.4232103824615479,
      "learning_rate": 1.0834431848141314e-05,
      "loss": 0.0093,
      "step": 8639
    },
    {
      "epoch": 0.5125163127298612,
      "grad_norm": 3.327735662460327,
      "learning_rate": 1.0833113630371738e-05,
      "loss": 0.0371,
      "step": 8640
    },
    {
      "epoch": 0.5125756317475383,
      "grad_norm": 1.5833680629730225,
      "learning_rate": 1.0831795412602163e-05,
      "loss": 0.0244,
      "step": 8641
    },
    {
      "epoch": 0.5126349507652154,
      "grad_norm": 0.6139832139015198,
      "learning_rate": 1.0830477194832587e-05,
      "loss": 0.0126,
      "step": 8642
    },
    {
      "epoch": 0.5126942697828923,
      "grad_norm": 6.046427249908447,
      "learning_rate": 1.0829158977063013e-05,
      "loss": 0.1181,
      "step": 8643
    },
    {
      "epoch": 0.5127535888005694,
      "grad_norm": 18.331022262573242,
      "learning_rate": 1.0827840759293435e-05,
      "loss": 0.6841,
      "step": 8644
    },
    {
      "epoch": 0.5128129078182465,
      "grad_norm": 1.2876012325286865,
      "learning_rate": 1.0826522541523861e-05,
      "loss": 0.0111,
      "step": 8645
    },
    {
      "epoch": 0.5128722268359236,
      "grad_norm": 18.033842086791992,
      "learning_rate": 1.0825204323754285e-05,
      "loss": 0.6527,
      "step": 8646
    },
    {
      "epoch": 0.5129315458536007,
      "grad_norm": 5.287355899810791,
      "learning_rate": 1.082388610598471e-05,
      "loss": 0.0472,
      "step": 8647
    },
    {
      "epoch": 0.5129908648712778,
      "grad_norm": 4.895611763000488,
      "learning_rate": 1.0822567888215134e-05,
      "loss": 0.0076,
      "step": 8648
    },
    {
      "epoch": 0.5130501838889548,
      "grad_norm": 15.65196704864502,
      "learning_rate": 1.082124967044556e-05,
      "loss": 0.4218,
      "step": 8649
    },
    {
      "epoch": 0.5131095029066318,
      "grad_norm": 0.4355004131793976,
      "learning_rate": 1.0819931452675982e-05,
      "loss": 0.0034,
      "step": 8650
    },
    {
      "epoch": 0.5131688219243089,
      "grad_norm": 0.7951112389564514,
      "learning_rate": 1.0818613234906408e-05,
      "loss": 0.009,
      "step": 8651
    },
    {
      "epoch": 0.513228140941986,
      "grad_norm": 6.456158638000488,
      "learning_rate": 1.0817295017136834e-05,
      "loss": 0.6084,
      "step": 8652
    },
    {
      "epoch": 0.5132874599596631,
      "grad_norm": 1.5458552837371826,
      "learning_rate": 1.0815976799367256e-05,
      "loss": 0.0276,
      "step": 8653
    },
    {
      "epoch": 0.5133467789773402,
      "grad_norm": 4.48415470123291,
      "learning_rate": 1.081465858159768e-05,
      "loss": 0.0338,
      "step": 8654
    },
    {
      "epoch": 0.5134060979950172,
      "grad_norm": 13.160394668579102,
      "learning_rate": 1.0813340363828105e-05,
      "loss": 0.1679,
      "step": 8655
    },
    {
      "epoch": 0.5134654170126943,
      "grad_norm": 0.06605571508407593,
      "learning_rate": 1.0812022146058529e-05,
      "loss": 0.0008,
      "step": 8656
    },
    {
      "epoch": 0.5135247360303713,
      "grad_norm": 8.226327896118164,
      "learning_rate": 1.0810703928288955e-05,
      "loss": 0.1631,
      "step": 8657
    },
    {
      "epoch": 0.5135840550480484,
      "grad_norm": 0.039955127984285355,
      "learning_rate": 1.0809385710519377e-05,
      "loss": 0.0008,
      "step": 8658
    },
    {
      "epoch": 0.5136433740657255,
      "grad_norm": 4.5606842041015625,
      "learning_rate": 1.0808067492749803e-05,
      "loss": 0.0696,
      "step": 8659
    },
    {
      "epoch": 0.5137026930834026,
      "grad_norm": 0.9259499311447144,
      "learning_rate": 1.0806749274980229e-05,
      "loss": 0.0107,
      "step": 8660
    },
    {
      "epoch": 0.5137620121010796,
      "grad_norm": 5.36762809753418,
      "learning_rate": 1.0805431057210651e-05,
      "loss": 0.088,
      "step": 8661
    },
    {
      "epoch": 0.5138213311187567,
      "grad_norm": 5.346138000488281,
      "learning_rate": 1.0804112839441077e-05,
      "loss": 0.0724,
      "step": 8662
    },
    {
      "epoch": 0.5138806501364337,
      "grad_norm": 5.104770660400391,
      "learning_rate": 1.0802794621671501e-05,
      "loss": 0.1042,
      "step": 8663
    },
    {
      "epoch": 0.5139399691541108,
      "grad_norm": 18.55388832092285,
      "learning_rate": 1.0801476403901926e-05,
      "loss": 0.055,
      "step": 8664
    },
    {
      "epoch": 0.5139992881717879,
      "grad_norm": 10.28879165649414,
      "learning_rate": 1.080015818613235e-05,
      "loss": 0.1062,
      "step": 8665
    },
    {
      "epoch": 0.5140586071894649,
      "grad_norm": 2.2785568237304688,
      "learning_rate": 1.0798839968362776e-05,
      "loss": 0.0528,
      "step": 8666
    },
    {
      "epoch": 0.514117926207142,
      "grad_norm": 0.7091808319091797,
      "learning_rate": 1.0797521750593198e-05,
      "loss": 0.008,
      "step": 8667
    },
    {
      "epoch": 0.5141772452248191,
      "grad_norm": 2.5196635723114014,
      "learning_rate": 1.0796203532823624e-05,
      "loss": 0.0078,
      "step": 8668
    },
    {
      "epoch": 0.5142365642424962,
      "grad_norm": 17.650991439819336,
      "learning_rate": 1.0794885315054048e-05,
      "loss": 0.8667,
      "step": 8669
    },
    {
      "epoch": 0.5142958832601732,
      "grad_norm": 3.8027570247650146,
      "learning_rate": 1.0793567097284472e-05,
      "loss": 0.0635,
      "step": 8670
    },
    {
      "epoch": 0.5143552022778503,
      "grad_norm": 0.004835943691432476,
      "learning_rate": 1.0792248879514897e-05,
      "loss": 0.0002,
      "step": 8671
    },
    {
      "epoch": 0.5144145212955273,
      "grad_norm": 0.20320120453834534,
      "learning_rate": 1.0790930661745321e-05,
      "loss": 0.0023,
      "step": 8672
    },
    {
      "epoch": 0.5144738403132044,
      "grad_norm": 0.03633509576320648,
      "learning_rate": 1.0789612443975745e-05,
      "loss": 0.0004,
      "step": 8673
    },
    {
      "epoch": 0.5145331593308815,
      "grad_norm": 0.6888647079467773,
      "learning_rate": 1.0788294226206171e-05,
      "loss": 0.0074,
      "step": 8674
    },
    {
      "epoch": 0.5145924783485586,
      "grad_norm": 1.2158952951431274,
      "learning_rate": 1.0786976008436593e-05,
      "loss": 0.0077,
      "step": 8675
    },
    {
      "epoch": 0.5146517973662356,
      "grad_norm": 0.017798975110054016,
      "learning_rate": 1.078565779066702e-05,
      "loss": 0.0006,
      "step": 8676
    },
    {
      "epoch": 0.5147111163839126,
      "grad_norm": 15.284745216369629,
      "learning_rate": 1.0784339572897443e-05,
      "loss": 0.1055,
      "step": 8677
    },
    {
      "epoch": 0.5147704354015897,
      "grad_norm": 6.937142848968506,
      "learning_rate": 1.0783021355127868e-05,
      "loss": 0.1921,
      "step": 8678
    },
    {
      "epoch": 0.5148297544192668,
      "grad_norm": 0.165530726313591,
      "learning_rate": 1.0781703137358292e-05,
      "loss": 0.0026,
      "step": 8679
    },
    {
      "epoch": 0.5148890734369439,
      "grad_norm": 4.50993537902832,
      "learning_rate": 1.0780384919588718e-05,
      "loss": 0.4622,
      "step": 8680
    },
    {
      "epoch": 0.514948392454621,
      "grad_norm": 8.617619514465332,
      "learning_rate": 1.077906670181914e-05,
      "loss": 0.1565,
      "step": 8681
    },
    {
      "epoch": 0.5150077114722981,
      "grad_norm": 0.015053615905344486,
      "learning_rate": 1.0777748484049566e-05,
      "loss": 0.0005,
      "step": 8682
    },
    {
      "epoch": 0.515067030489975,
      "grad_norm": 14.19649600982666,
      "learning_rate": 1.0776430266279992e-05,
      "loss": 0.1552,
      "step": 8683
    },
    {
      "epoch": 0.5151263495076521,
      "grad_norm": 7.9986701011657715,
      "learning_rate": 1.0775112048510414e-05,
      "loss": 0.098,
      "step": 8684
    },
    {
      "epoch": 0.5151856685253292,
      "grad_norm": 10.532456398010254,
      "learning_rate": 1.077379383074084e-05,
      "loss": 0.1306,
      "step": 8685
    },
    {
      "epoch": 0.5152449875430063,
      "grad_norm": 18.851816177368164,
      "learning_rate": 1.0772475612971263e-05,
      "loss": 0.9307,
      "step": 8686
    },
    {
      "epoch": 0.5153043065606834,
      "grad_norm": 0.3261790871620178,
      "learning_rate": 1.0771157395201689e-05,
      "loss": 0.0077,
      "step": 8687
    },
    {
      "epoch": 0.5153636255783605,
      "grad_norm": 8.076205253601074,
      "learning_rate": 1.0769839177432113e-05,
      "loss": 0.2309,
      "step": 8688
    },
    {
      "epoch": 0.5154229445960374,
      "grad_norm": 0.060446612536907196,
      "learning_rate": 1.0768520959662535e-05,
      "loss": 0.0011,
      "step": 8689
    },
    {
      "epoch": 0.5154822636137145,
      "grad_norm": 12.958653450012207,
      "learning_rate": 1.0767202741892961e-05,
      "loss": 0.6027,
      "step": 8690
    },
    {
      "epoch": 0.5155415826313916,
      "grad_norm": 0.2936534285545349,
      "learning_rate": 1.0765884524123387e-05,
      "loss": 0.0068,
      "step": 8691
    },
    {
      "epoch": 0.5156009016490687,
      "grad_norm": 0.09920065850019455,
      "learning_rate": 1.076456630635381e-05,
      "loss": 0.0028,
      "step": 8692
    },
    {
      "epoch": 0.5156602206667458,
      "grad_norm": 24.89098358154297,
      "learning_rate": 1.0763248088584236e-05,
      "loss": 0.4252,
      "step": 8693
    },
    {
      "epoch": 0.5157195396844229,
      "grad_norm": 11.83284854888916,
      "learning_rate": 1.076192987081466e-05,
      "loss": 0.5939,
      "step": 8694
    },
    {
      "epoch": 0.5157788587020999,
      "grad_norm": 19.750919342041016,
      "learning_rate": 1.0760611653045084e-05,
      "loss": 1.0254,
      "step": 8695
    },
    {
      "epoch": 0.5158381777197769,
      "grad_norm": 0.07525243610143661,
      "learning_rate": 1.0759293435275508e-05,
      "loss": 0.0012,
      "step": 8696
    },
    {
      "epoch": 0.515897496737454,
      "grad_norm": 0.029042923822999,
      "learning_rate": 1.0757975217505934e-05,
      "loss": 0.0007,
      "step": 8697
    },
    {
      "epoch": 0.5159568157551311,
      "grad_norm": 0.05782619118690491,
      "learning_rate": 1.0756656999736356e-05,
      "loss": 0.001,
      "step": 8698
    },
    {
      "epoch": 0.5160161347728082,
      "grad_norm": 6.8639912605285645,
      "learning_rate": 1.0755338781966782e-05,
      "loss": 0.3056,
      "step": 8699
    },
    {
      "epoch": 0.5160754537904853,
      "grad_norm": 1.0997092723846436,
      "learning_rate": 1.0754020564197207e-05,
      "loss": 0.0065,
      "step": 8700
    },
    {
      "epoch": 0.5161347728081623,
      "grad_norm": 12.46163272857666,
      "learning_rate": 1.075270234642763e-05,
      "loss": 0.3067,
      "step": 8701
    },
    {
      "epoch": 0.5161940918258394,
      "grad_norm": 15.522279739379883,
      "learning_rate": 1.0751384128658055e-05,
      "loss": 0.5707,
      "step": 8702
    },
    {
      "epoch": 0.5162534108435164,
      "grad_norm": 0.012496835552155972,
      "learning_rate": 1.0750065910888479e-05,
      "loss": 0.0005,
      "step": 8703
    },
    {
      "epoch": 0.5163127298611935,
      "grad_norm": 3.745279550552368,
      "learning_rate": 1.0748747693118903e-05,
      "loss": 0.0055,
      "step": 8704
    },
    {
      "epoch": 0.5163720488788706,
      "grad_norm": 9.602972030639648,
      "learning_rate": 1.074742947534933e-05,
      "loss": 1.0861,
      "step": 8705
    },
    {
      "epoch": 0.5164313678965476,
      "grad_norm": 0.030870551243424416,
      "learning_rate": 1.0746111257579752e-05,
      "loss": 0.0005,
      "step": 8706
    },
    {
      "epoch": 0.5164906869142247,
      "grad_norm": 2.0655691623687744,
      "learning_rate": 1.0744793039810178e-05,
      "loss": 0.0465,
      "step": 8707
    },
    {
      "epoch": 0.5165500059319018,
      "grad_norm": 5.992122173309326,
      "learning_rate": 1.0743474822040603e-05,
      "loss": 0.1959,
      "step": 8708
    },
    {
      "epoch": 0.5166093249495788,
      "grad_norm": 0.03705711290240288,
      "learning_rate": 1.0742156604271026e-05,
      "loss": 0.0011,
      "step": 8709
    },
    {
      "epoch": 0.5166686439672559,
      "grad_norm": 0.8351556062698364,
      "learning_rate": 1.074083838650145e-05,
      "loss": 0.0097,
      "step": 8710
    },
    {
      "epoch": 0.516727962984933,
      "grad_norm": 10.797866821289062,
      "learning_rate": 1.0739520168731876e-05,
      "loss": 0.4115,
      "step": 8711
    },
    {
      "epoch": 0.51678728200261,
      "grad_norm": 0.1037963256239891,
      "learning_rate": 1.0738201950962298e-05,
      "loss": 0.0016,
      "step": 8712
    },
    {
      "epoch": 0.5168466010202871,
      "grad_norm": 5.347833633422852,
      "learning_rate": 1.0736883733192724e-05,
      "loss": 0.0861,
      "step": 8713
    },
    {
      "epoch": 0.5169059200379642,
      "grad_norm": 13.993185997009277,
      "learning_rate": 1.073556551542315e-05,
      "loss": 0.3941,
      "step": 8714
    },
    {
      "epoch": 0.5169652390556413,
      "grad_norm": 0.021895362064242363,
      "learning_rate": 1.0734247297653573e-05,
      "loss": 0.0006,
      "step": 8715
    },
    {
      "epoch": 0.5170245580733183,
      "grad_norm": 14.106595039367676,
      "learning_rate": 1.0732929079883999e-05,
      "loss": 0.5762,
      "step": 8716
    },
    {
      "epoch": 0.5170838770909953,
      "grad_norm": 11.83928108215332,
      "learning_rate": 1.0731610862114423e-05,
      "loss": 0.4877,
      "step": 8717
    },
    {
      "epoch": 0.5171431961086724,
      "grad_norm": 1.0446357727050781,
      "learning_rate": 1.0730292644344847e-05,
      "loss": 0.0198,
      "step": 8718
    },
    {
      "epoch": 0.5172025151263495,
      "grad_norm": 0.06259427964687347,
      "learning_rate": 1.0728974426575271e-05,
      "loss": 0.0011,
      "step": 8719
    },
    {
      "epoch": 0.5172618341440266,
      "grad_norm": 24.931665420532227,
      "learning_rate": 1.0727656208805695e-05,
      "loss": 1.2245,
      "step": 8720
    },
    {
      "epoch": 0.5173211531617037,
      "grad_norm": 16.585683822631836,
      "learning_rate": 1.072633799103612e-05,
      "loss": 0.1258,
      "step": 8721
    },
    {
      "epoch": 0.5173804721793807,
      "grad_norm": 0.013923566788434982,
      "learning_rate": 1.0725019773266545e-05,
      "loss": 0.0004,
      "step": 8722
    },
    {
      "epoch": 0.5174397911970577,
      "grad_norm": 13.201852798461914,
      "learning_rate": 1.0723701555496968e-05,
      "loss": 0.1454,
      "step": 8723
    },
    {
      "epoch": 0.5174991102147348,
      "grad_norm": 0.8242571949958801,
      "learning_rate": 1.0722383337727394e-05,
      "loss": 0.0098,
      "step": 8724
    },
    {
      "epoch": 0.5175584292324119,
      "grad_norm": 0.07490134984254837,
      "learning_rate": 1.0721065119957818e-05,
      "loss": 0.0013,
      "step": 8725
    },
    {
      "epoch": 0.517617748250089,
      "grad_norm": 0.5004618763923645,
      "learning_rate": 1.0719746902188242e-05,
      "loss": 0.0075,
      "step": 8726
    },
    {
      "epoch": 0.5176770672677661,
      "grad_norm": 0.5567525625228882,
      "learning_rate": 1.0718428684418666e-05,
      "loss": 0.0039,
      "step": 8727
    },
    {
      "epoch": 0.5177363862854432,
      "grad_norm": 0.3550645112991333,
      "learning_rate": 1.0717110466649092e-05,
      "loss": 0.0062,
      "step": 8728
    },
    {
      "epoch": 0.5177957053031201,
      "grad_norm": 0.1311320811510086,
      "learning_rate": 1.0715792248879515e-05,
      "loss": 0.0023,
      "step": 8729
    },
    {
      "epoch": 0.5178550243207972,
      "grad_norm": 0.02527741529047489,
      "learning_rate": 1.071447403110994e-05,
      "loss": 0.0009,
      "step": 8730
    },
    {
      "epoch": 0.5179143433384743,
      "grad_norm": 0.38260766863822937,
      "learning_rate": 1.0713155813340367e-05,
      "loss": 0.0043,
      "step": 8731
    },
    {
      "epoch": 0.5179736623561514,
      "grad_norm": 4.795318126678467,
      "learning_rate": 1.0711837595570789e-05,
      "loss": 0.0771,
      "step": 8732
    },
    {
      "epoch": 0.5180329813738285,
      "grad_norm": 11.269465446472168,
      "learning_rate": 1.0710519377801213e-05,
      "loss": 1.2829,
      "step": 8733
    },
    {
      "epoch": 0.5180923003915056,
      "grad_norm": 8.931563377380371,
      "learning_rate": 1.0709201160031637e-05,
      "loss": 0.1649,
      "step": 8734
    },
    {
      "epoch": 0.5181516194091825,
      "grad_norm": 0.1440550833940506,
      "learning_rate": 1.0707882942262062e-05,
      "loss": 0.0036,
      "step": 8735
    },
    {
      "epoch": 0.5182109384268596,
      "grad_norm": 0.05181196704506874,
      "learning_rate": 1.0706564724492487e-05,
      "loss": 0.0007,
      "step": 8736
    },
    {
      "epoch": 0.5182702574445367,
      "grad_norm": 5.416806221008301,
      "learning_rate": 1.070524650672291e-05,
      "loss": 0.0448,
      "step": 8737
    },
    {
      "epoch": 0.5183295764622138,
      "grad_norm": 11.72220516204834,
      "learning_rate": 1.0703928288953336e-05,
      "loss": 0.4662,
      "step": 8738
    },
    {
      "epoch": 0.5183888954798909,
      "grad_norm": 20.807838439941406,
      "learning_rate": 1.0702610071183762e-05,
      "loss": 0.6052,
      "step": 8739
    },
    {
      "epoch": 0.518448214497568,
      "grad_norm": 6.280491352081299,
      "learning_rate": 1.0701291853414184e-05,
      "loss": 0.0671,
      "step": 8740
    },
    {
      "epoch": 0.518507533515245,
      "grad_norm": 21.39186668395996,
      "learning_rate": 1.069997363564461e-05,
      "loss": 0.2632,
      "step": 8741
    },
    {
      "epoch": 0.518566852532922,
      "grad_norm": 35.96199035644531,
      "learning_rate": 1.0698655417875034e-05,
      "loss": 0.9158,
      "step": 8742
    },
    {
      "epoch": 0.5186261715505991,
      "grad_norm": 2.236746311187744,
      "learning_rate": 1.0697337200105458e-05,
      "loss": 0.0047,
      "step": 8743
    },
    {
      "epoch": 0.5186854905682762,
      "grad_norm": 2.3227744102478027,
      "learning_rate": 1.0696018982335883e-05,
      "loss": 0.0384,
      "step": 8744
    },
    {
      "epoch": 0.5187448095859533,
      "grad_norm": 5.248034477233887,
      "learning_rate": 1.0694700764566309e-05,
      "loss": 0.1003,
      "step": 8745
    },
    {
      "epoch": 0.5188041286036303,
      "grad_norm": 16.312437057495117,
      "learning_rate": 1.0693382546796731e-05,
      "loss": 0.3365,
      "step": 8746
    },
    {
      "epoch": 0.5188634476213074,
      "grad_norm": 5.528448104858398,
      "learning_rate": 1.0692064329027157e-05,
      "loss": 0.1359,
      "step": 8747
    },
    {
      "epoch": 0.5189227666389845,
      "grad_norm": 0.12094811350107193,
      "learning_rate": 1.0690746111257581e-05,
      "loss": 0.0013,
      "step": 8748
    },
    {
      "epoch": 0.5189820856566615,
      "grad_norm": 0.02974727377295494,
      "learning_rate": 1.0689427893488005e-05,
      "loss": 0.0005,
      "step": 8749
    },
    {
      "epoch": 0.5190414046743386,
      "grad_norm": 1.9033783674240112,
      "learning_rate": 1.068810967571843e-05,
      "loss": 0.0079,
      "step": 8750
    },
    {
      "epoch": 0.5191007236920157,
      "grad_norm": 2.4342446327209473,
      "learning_rate": 1.0686791457948854e-05,
      "loss": 0.0353,
      "step": 8751
    },
    {
      "epoch": 0.5191600427096927,
      "grad_norm": 0.0854937806725502,
      "learning_rate": 1.0685473240179278e-05,
      "loss": 0.0012,
      "step": 8752
    },
    {
      "epoch": 0.5192193617273698,
      "grad_norm": 16.24932289123535,
      "learning_rate": 1.0684155022409704e-05,
      "loss": 0.154,
      "step": 8753
    },
    {
      "epoch": 0.5192786807450469,
      "grad_norm": 0.025293035432696342,
      "learning_rate": 1.0682836804640126e-05,
      "loss": 0.0005,
      "step": 8754
    },
    {
      "epoch": 0.5193379997627239,
      "grad_norm": 0.4380493462085724,
      "learning_rate": 1.0681518586870552e-05,
      "loss": 0.0052,
      "step": 8755
    },
    {
      "epoch": 0.519397318780401,
      "grad_norm": 4.326351165771484,
      "learning_rate": 1.0680200369100976e-05,
      "loss": 0.0506,
      "step": 8756
    },
    {
      "epoch": 0.519456637798078,
      "grad_norm": 0.019254222512245178,
      "learning_rate": 1.06788821513314e-05,
      "loss": 0.0005,
      "step": 8757
    },
    {
      "epoch": 0.5195159568157551,
      "grad_norm": 0.046858444809913635,
      "learning_rate": 1.0677563933561825e-05,
      "loss": 0.0007,
      "step": 8758
    },
    {
      "epoch": 0.5195752758334322,
      "grad_norm": 4.5380754470825195,
      "learning_rate": 1.067624571579225e-05,
      "loss": 0.0809,
      "step": 8759
    },
    {
      "epoch": 0.5196345948511093,
      "grad_norm": 0.024882156401872635,
      "learning_rate": 1.0674927498022673e-05,
      "loss": 0.0006,
      "step": 8760
    },
    {
      "epoch": 0.5196939138687864,
      "grad_norm": 14.573637008666992,
      "learning_rate": 1.0673609280253099e-05,
      "loss": 0.1389,
      "step": 8761
    },
    {
      "epoch": 0.5197532328864634,
      "grad_norm": 7.093824863433838,
      "learning_rate": 1.0672291062483525e-05,
      "loss": 0.0322,
      "step": 8762
    },
    {
      "epoch": 0.5198125519041404,
      "grad_norm": 0.17631617188453674,
      "learning_rate": 1.0670972844713947e-05,
      "loss": 0.003,
      "step": 8763
    },
    {
      "epoch": 0.5198718709218175,
      "grad_norm": 0.04588634893298149,
      "learning_rate": 1.0669654626944373e-05,
      "loss": 0.0007,
      "step": 8764
    },
    {
      "epoch": 0.5199311899394946,
      "grad_norm": 0.01508271787315607,
      "learning_rate": 1.0668336409174797e-05,
      "loss": 0.0004,
      "step": 8765
    },
    {
      "epoch": 0.5199905089571717,
      "grad_norm": 18.27690315246582,
      "learning_rate": 1.066701819140522e-05,
      "loss": 0.1307,
      "step": 8766
    },
    {
      "epoch": 0.5200498279748488,
      "grad_norm": 1.5365656614303589,
      "learning_rate": 1.0665699973635646e-05,
      "loss": 0.0096,
      "step": 8767
    },
    {
      "epoch": 0.5201091469925258,
      "grad_norm": 2.890460729598999,
      "learning_rate": 1.0664381755866068e-05,
      "loss": 0.0159,
      "step": 8768
    },
    {
      "epoch": 0.5201684660102028,
      "grad_norm": 0.8891174793243408,
      "learning_rate": 1.0663063538096494e-05,
      "loss": 0.0129,
      "step": 8769
    },
    {
      "epoch": 0.5202277850278799,
      "grad_norm": 21.41660499572754,
      "learning_rate": 1.066174532032692e-05,
      "loss": 0.4584,
      "step": 8770
    },
    {
      "epoch": 0.520287104045557,
      "grad_norm": 0.32856401801109314,
      "learning_rate": 1.0660427102557342e-05,
      "loss": 0.0034,
      "step": 8771
    },
    {
      "epoch": 0.5203464230632341,
      "grad_norm": 0.32717588543891907,
      "learning_rate": 1.0659108884787768e-05,
      "loss": 0.0045,
      "step": 8772
    },
    {
      "epoch": 0.5204057420809112,
      "grad_norm": 4.908407688140869,
      "learning_rate": 1.0657790667018193e-05,
      "loss": 0.1063,
      "step": 8773
    },
    {
      "epoch": 0.5204650610985883,
      "grad_norm": 0.01396233681589365,
      "learning_rate": 1.0656472449248617e-05,
      "loss": 0.0004,
      "step": 8774
    },
    {
      "epoch": 0.5205243801162652,
      "grad_norm": 0.013547993265092373,
      "learning_rate": 1.0655154231479041e-05,
      "loss": 0.0004,
      "step": 8775
    },
    {
      "epoch": 0.5205836991339423,
      "grad_norm": 1.6081970930099487,
      "learning_rate": 1.0653836013709467e-05,
      "loss": 0.0142,
      "step": 8776
    },
    {
      "epoch": 0.5206430181516194,
      "grad_norm": 30.386945724487305,
      "learning_rate": 1.065251779593989e-05,
      "loss": 0.7748,
      "step": 8777
    },
    {
      "epoch": 0.5207023371692965,
      "grad_norm": 2.2991652488708496,
      "learning_rate": 1.0651199578170315e-05,
      "loss": 0.0144,
      "step": 8778
    },
    {
      "epoch": 0.5207616561869736,
      "grad_norm": 0.04566516727209091,
      "learning_rate": 1.064988136040074e-05,
      "loss": 0.0012,
      "step": 8779
    },
    {
      "epoch": 0.5208209752046506,
      "grad_norm": 32.43153381347656,
      "learning_rate": 1.0648563142631164e-05,
      "loss": 0.4285,
      "step": 8780
    },
    {
      "epoch": 0.5208802942223277,
      "grad_norm": 1.6193400621414185,
      "learning_rate": 1.0647244924861588e-05,
      "loss": 0.0168,
      "step": 8781
    },
    {
      "epoch": 0.5209396132400047,
      "grad_norm": 4.837785720825195,
      "learning_rate": 1.0645926707092012e-05,
      "loss": 0.1654,
      "step": 8782
    },
    {
      "epoch": 0.5209989322576818,
      "grad_norm": 12.744475364685059,
      "learning_rate": 1.0644608489322436e-05,
      "loss": 0.685,
      "step": 8783
    },
    {
      "epoch": 0.5210582512753589,
      "grad_norm": 2.2870755195617676,
      "learning_rate": 1.0643290271552862e-05,
      "loss": 0.0222,
      "step": 8784
    },
    {
      "epoch": 0.521117570293036,
      "grad_norm": 1.1559631824493408,
      "learning_rate": 1.0641972053783284e-05,
      "loss": 0.0071,
      "step": 8785
    },
    {
      "epoch": 0.521176889310713,
      "grad_norm": 5.498431205749512,
      "learning_rate": 1.064065383601371e-05,
      "loss": 0.0758,
      "step": 8786
    },
    {
      "epoch": 0.5212362083283901,
      "grad_norm": 0.11846459656953812,
      "learning_rate": 1.0639335618244136e-05,
      "loss": 0.0015,
      "step": 8787
    },
    {
      "epoch": 0.5212955273460671,
      "grad_norm": 5.950619220733643,
      "learning_rate": 1.0638017400474559e-05,
      "loss": 0.0497,
      "step": 8788
    },
    {
      "epoch": 0.5213548463637442,
      "grad_norm": 0.005390588194131851,
      "learning_rate": 1.0636699182704983e-05,
      "loss": 0.0002,
      "step": 8789
    },
    {
      "epoch": 0.5214141653814213,
      "grad_norm": 0.9306762218475342,
      "learning_rate": 1.0635380964935409e-05,
      "loss": 0.0048,
      "step": 8790
    },
    {
      "epoch": 0.5214734843990984,
      "grad_norm": 0.11702874302864075,
      "learning_rate": 1.0634062747165831e-05,
      "loss": 0.0006,
      "step": 8791
    },
    {
      "epoch": 0.5215328034167754,
      "grad_norm": 9.713214874267578,
      "learning_rate": 1.0632744529396257e-05,
      "loss": 0.1803,
      "step": 8792
    },
    {
      "epoch": 0.5215921224344525,
      "grad_norm": 3.116513729095459,
      "learning_rate": 1.0631426311626683e-05,
      "loss": 0.037,
      "step": 8793
    },
    {
      "epoch": 0.5216514414521296,
      "grad_norm": 40.03371047973633,
      "learning_rate": 1.0630108093857106e-05,
      "loss": 0.0601,
      "step": 8794
    },
    {
      "epoch": 0.5217107604698066,
      "grad_norm": 15.397343635559082,
      "learning_rate": 1.0628789876087531e-05,
      "loss": 0.397,
      "step": 8795
    },
    {
      "epoch": 0.5217700794874837,
      "grad_norm": 10.087180137634277,
      "learning_rate": 1.0627471658317956e-05,
      "loss": 0.4089,
      "step": 8796
    },
    {
      "epoch": 0.5218293985051607,
      "grad_norm": 0.2821376621723175,
      "learning_rate": 1.062615344054838e-05,
      "loss": 0.0035,
      "step": 8797
    },
    {
      "epoch": 0.5218887175228378,
      "grad_norm": 23.659374237060547,
      "learning_rate": 1.0624835222778804e-05,
      "loss": 0.3636,
      "step": 8798
    },
    {
      "epoch": 0.5219480365405149,
      "grad_norm": 1.5331320762634277,
      "learning_rate": 1.0623517005009226e-05,
      "loss": 0.04,
      "step": 8799
    },
    {
      "epoch": 0.522007355558192,
      "grad_norm": 0.1032392606139183,
      "learning_rate": 1.0622198787239652e-05,
      "loss": 0.0011,
      "step": 8800
    },
    {
      "epoch": 0.522066674575869,
      "grad_norm": 0.3811693787574768,
      "learning_rate": 1.0620880569470078e-05,
      "loss": 0.0055,
      "step": 8801
    },
    {
      "epoch": 0.5221259935935461,
      "grad_norm": 7.276703357696533,
      "learning_rate": 1.06195623517005e-05,
      "loss": 0.5243,
      "step": 8802
    },
    {
      "epoch": 0.5221853126112231,
      "grad_norm": 13.016222953796387,
      "learning_rate": 1.0618244133930927e-05,
      "loss": 0.0911,
      "step": 8803
    },
    {
      "epoch": 0.5222446316289002,
      "grad_norm": 2.948685884475708,
      "learning_rate": 1.061692591616135e-05,
      "loss": 0.0267,
      "step": 8804
    },
    {
      "epoch": 0.5223039506465773,
      "grad_norm": 2.1364691257476807,
      "learning_rate": 1.0615607698391775e-05,
      "loss": 0.0128,
      "step": 8805
    },
    {
      "epoch": 0.5223632696642544,
      "grad_norm": 8.289563179016113,
      "learning_rate": 1.06142894806222e-05,
      "loss": 0.0419,
      "step": 8806
    },
    {
      "epoch": 0.5224225886819315,
      "grad_norm": 0.3536723554134369,
      "learning_rate": 1.0612971262852625e-05,
      "loss": 0.0045,
      "step": 8807
    },
    {
      "epoch": 0.5224819076996084,
      "grad_norm": 8.234668731689453,
      "learning_rate": 1.0611653045083048e-05,
      "loss": 0.3533,
      "step": 8808
    },
    {
      "epoch": 0.5225412267172855,
      "grad_norm": 17.203306198120117,
      "learning_rate": 1.0610334827313473e-05,
      "loss": 0.2801,
      "step": 8809
    },
    {
      "epoch": 0.5226005457349626,
      "grad_norm": 42.93647766113281,
      "learning_rate": 1.0609016609543898e-05,
      "loss": 0.2755,
      "step": 8810
    },
    {
      "epoch": 0.5226598647526397,
      "grad_norm": 0.4317830801010132,
      "learning_rate": 1.0607698391774322e-05,
      "loss": 0.0027,
      "step": 8811
    },
    {
      "epoch": 0.5227191837703168,
      "grad_norm": 2.8824410438537598,
      "learning_rate": 1.0606380174004746e-05,
      "loss": 0.0437,
      "step": 8812
    },
    {
      "epoch": 0.5227785027879939,
      "grad_norm": 4.897972583770752,
      "learning_rate": 1.0605061956235172e-05,
      "loss": 0.0455,
      "step": 8813
    },
    {
      "epoch": 0.5228378218056708,
      "grad_norm": 6.927589416503906,
      "learning_rate": 1.0603743738465594e-05,
      "loss": 0.0425,
      "step": 8814
    },
    {
      "epoch": 0.5228971408233479,
      "grad_norm": 0.2782805263996124,
      "learning_rate": 1.060242552069602e-05,
      "loss": 0.0026,
      "step": 8815
    },
    {
      "epoch": 0.522956459841025,
      "grad_norm": 0.3683871924877167,
      "learning_rate": 1.0601107302926443e-05,
      "loss": 0.0049,
      "step": 8816
    },
    {
      "epoch": 0.5230157788587021,
      "grad_norm": 0.4959616959095001,
      "learning_rate": 1.0599789085156869e-05,
      "loss": 0.0048,
      "step": 8817
    },
    {
      "epoch": 0.5230750978763792,
      "grad_norm": 0.014831377193331718,
      "learning_rate": 1.0598470867387295e-05,
      "loss": 0.0004,
      "step": 8818
    },
    {
      "epoch": 0.5231344168940563,
      "grad_norm": 0.07133349031209946,
      "learning_rate": 1.0597152649617717e-05,
      "loss": 0.0009,
      "step": 8819
    },
    {
      "epoch": 0.5231937359117333,
      "grad_norm": 2.4720489978790283,
      "learning_rate": 1.0595834431848143e-05,
      "loss": 0.0254,
      "step": 8820
    },
    {
      "epoch": 0.5232530549294103,
      "grad_norm": 0.005669906735420227,
      "learning_rate": 1.0594516214078567e-05,
      "loss": 0.0003,
      "step": 8821
    },
    {
      "epoch": 0.5233123739470874,
      "grad_norm": 0.20833085477352142,
      "learning_rate": 1.059319799630899e-05,
      "loss": 0.0047,
      "step": 8822
    },
    {
      "epoch": 0.5233716929647645,
      "grad_norm": 19.508773803710938,
      "learning_rate": 1.0591879778539415e-05,
      "loss": 0.3154,
      "step": 8823
    },
    {
      "epoch": 0.5234310119824416,
      "grad_norm": 14.088266372680664,
      "learning_rate": 1.0590561560769841e-05,
      "loss": 0.2878,
      "step": 8824
    },
    {
      "epoch": 0.5234903310001187,
      "grad_norm": 0.016970137134194374,
      "learning_rate": 1.0589243343000264e-05,
      "loss": 0.0005,
      "step": 8825
    },
    {
      "epoch": 0.5235496500177957,
      "grad_norm": 0.012289267033338547,
      "learning_rate": 1.058792512523069e-05,
      "loss": 0.0004,
      "step": 8826
    },
    {
      "epoch": 0.5236089690354728,
      "grad_norm": 0.034724339842796326,
      "learning_rate": 1.0586606907461114e-05,
      "loss": 0.0007,
      "step": 8827
    },
    {
      "epoch": 0.5236682880531498,
      "grad_norm": 1.1744920015335083,
      "learning_rate": 1.0585288689691538e-05,
      "loss": 0.0126,
      "step": 8828
    },
    {
      "epoch": 0.5237276070708269,
      "grad_norm": 9.882390975952148,
      "learning_rate": 1.0583970471921962e-05,
      "loss": 0.0581,
      "step": 8829
    },
    {
      "epoch": 0.523786926088504,
      "grad_norm": 0.11720339953899384,
      "learning_rate": 1.0582652254152388e-05,
      "loss": 0.0009,
      "step": 8830
    },
    {
      "epoch": 0.523846245106181,
      "grad_norm": 0.015843527391552925,
      "learning_rate": 1.058133403638281e-05,
      "loss": 0.0003,
      "step": 8831
    },
    {
      "epoch": 0.5239055641238581,
      "grad_norm": 49.103519439697266,
      "learning_rate": 1.0580015818613237e-05,
      "loss": 0.1718,
      "step": 8832
    },
    {
      "epoch": 0.5239648831415352,
      "grad_norm": 0.0762677863240242,
      "learning_rate": 1.0578697600843659e-05,
      "loss": 0.0009,
      "step": 8833
    },
    {
      "epoch": 0.5240242021592122,
      "grad_norm": 0.18370948731899261,
      "learning_rate": 1.0577379383074085e-05,
      "loss": 0.0023,
      "step": 8834
    },
    {
      "epoch": 0.5240835211768893,
      "grad_norm": 24.538087844848633,
      "learning_rate": 1.0576061165304509e-05,
      "loss": 0.5651,
      "step": 8835
    },
    {
      "epoch": 0.5241428401945664,
      "grad_norm": 20.0953369140625,
      "learning_rate": 1.0574742947534933e-05,
      "loss": 1.4067,
      "step": 8836
    },
    {
      "epoch": 0.5242021592122434,
      "grad_norm": 0.040581196546554565,
      "learning_rate": 1.0573424729765357e-05,
      "loss": 0.0012,
      "step": 8837
    },
    {
      "epoch": 0.5242614782299205,
      "grad_norm": 0.6891219019889832,
      "learning_rate": 1.0572106511995783e-05,
      "loss": 0.0033,
      "step": 8838
    },
    {
      "epoch": 0.5243207972475976,
      "grad_norm": 0.1126733049750328,
      "learning_rate": 1.0570788294226206e-05,
      "loss": 0.0014,
      "step": 8839
    },
    {
      "epoch": 0.5243801162652747,
      "grad_norm": 0.4292466342449188,
      "learning_rate": 1.0569470076456632e-05,
      "loss": 0.0053,
      "step": 8840
    },
    {
      "epoch": 0.5244394352829517,
      "grad_norm": 1.3434418439865112,
      "learning_rate": 1.0568151858687058e-05,
      "loss": 0.0276,
      "step": 8841
    },
    {
      "epoch": 0.5244987543006288,
      "grad_norm": 13.105023384094238,
      "learning_rate": 1.056683364091748e-05,
      "loss": 1.0861,
      "step": 8842
    },
    {
      "epoch": 0.5245580733183058,
      "grad_norm": 0.2752610146999359,
      "learning_rate": 1.0565515423147906e-05,
      "loss": 0.0025,
      "step": 8843
    },
    {
      "epoch": 0.5246173923359829,
      "grad_norm": 0.22666585445404053,
      "learning_rate": 1.056419720537833e-05,
      "loss": 0.0028,
      "step": 8844
    },
    {
      "epoch": 0.52467671135366,
      "grad_norm": 0.19364804029464722,
      "learning_rate": 1.0562878987608753e-05,
      "loss": 0.0028,
      "step": 8845
    },
    {
      "epoch": 0.5247360303713371,
      "grad_norm": 16.120332717895508,
      "learning_rate": 1.0561560769839179e-05,
      "loss": 0.2685,
      "step": 8846
    },
    {
      "epoch": 0.5247953493890141,
      "grad_norm": 3.443652629852295,
      "learning_rate": 1.0560242552069601e-05,
      "loss": 0.1977,
      "step": 8847
    },
    {
      "epoch": 0.5248546684066911,
      "grad_norm": 14.24393081665039,
      "learning_rate": 1.0558924334300027e-05,
      "loss": 0.4019,
      "step": 8848
    },
    {
      "epoch": 0.5249139874243682,
      "grad_norm": 0.07773653417825699,
      "learning_rate": 1.0557606116530453e-05,
      "loss": 0.0013,
      "step": 8849
    },
    {
      "epoch": 0.5249733064420453,
      "grad_norm": 17.980199813842773,
      "learning_rate": 1.0556287898760875e-05,
      "loss": 0.064,
      "step": 8850
    },
    {
      "epoch": 0.5250326254597224,
      "grad_norm": 0.06354919075965881,
      "learning_rate": 1.0554969680991301e-05,
      "loss": 0.0006,
      "step": 8851
    },
    {
      "epoch": 0.5250919444773995,
      "grad_norm": 0.011780199594795704,
      "learning_rate": 1.0553651463221725e-05,
      "loss": 0.0005,
      "step": 8852
    },
    {
      "epoch": 0.5251512634950766,
      "grad_norm": 0.03679367154836655,
      "learning_rate": 1.055233324545215e-05,
      "loss": 0.0007,
      "step": 8853
    },
    {
      "epoch": 0.5252105825127535,
      "grad_norm": 0.008452951908111572,
      "learning_rate": 1.0551015027682574e-05,
      "loss": 0.0003,
      "step": 8854
    },
    {
      "epoch": 0.5252699015304306,
      "grad_norm": 0.18787620961666107,
      "learning_rate": 1.0549696809913e-05,
      "loss": 0.0036,
      "step": 8855
    },
    {
      "epoch": 0.5253292205481077,
      "grad_norm": 0.004743464756757021,
      "learning_rate": 1.0548378592143422e-05,
      "loss": 0.0002,
      "step": 8856
    },
    {
      "epoch": 0.5253885395657848,
      "grad_norm": 57.64419174194336,
      "learning_rate": 1.0547060374373848e-05,
      "loss": 1.067,
      "step": 8857
    },
    {
      "epoch": 0.5254478585834619,
      "grad_norm": 0.23972554504871368,
      "learning_rate": 1.0545742156604272e-05,
      "loss": 0.0045,
      "step": 8858
    },
    {
      "epoch": 0.525507177601139,
      "grad_norm": 4.050394535064697,
      "learning_rate": 1.0544423938834696e-05,
      "loss": 0.1899,
      "step": 8859
    },
    {
      "epoch": 0.5255664966188159,
      "grad_norm": 0.003940468654036522,
      "learning_rate": 1.054310572106512e-05,
      "loss": 0.0001,
      "step": 8860
    },
    {
      "epoch": 0.525625815636493,
      "grad_norm": 0.024698784574866295,
      "learning_rate": 1.0541787503295546e-05,
      "loss": 0.0006,
      "step": 8861
    },
    {
      "epoch": 0.5256851346541701,
      "grad_norm": 7.068741321563721,
      "learning_rate": 1.0540469285525969e-05,
      "loss": 0.0372,
      "step": 8862
    },
    {
      "epoch": 0.5257444536718472,
      "grad_norm": 0.03334180265665054,
      "learning_rate": 1.0539151067756395e-05,
      "loss": 0.0007,
      "step": 8863
    },
    {
      "epoch": 0.5258037726895243,
      "grad_norm": 0.07570977509021759,
      "learning_rate": 1.0537832849986817e-05,
      "loss": 0.0007,
      "step": 8864
    },
    {
      "epoch": 0.5258630917072014,
      "grad_norm": 0.12530860304832458,
      "learning_rate": 1.0536514632217243e-05,
      "loss": 0.0036,
      "step": 8865
    },
    {
      "epoch": 0.5259224107248784,
      "grad_norm": 0.8787882924079895,
      "learning_rate": 1.0535196414447667e-05,
      "loss": 0.0094,
      "step": 8866
    },
    {
      "epoch": 0.5259817297425554,
      "grad_norm": 3.20666241645813,
      "learning_rate": 1.0533878196678092e-05,
      "loss": 0.0349,
      "step": 8867
    },
    {
      "epoch": 0.5260410487602325,
      "grad_norm": 6.87400484085083,
      "learning_rate": 1.0532559978908516e-05,
      "loss": 0.0264,
      "step": 8868
    },
    {
      "epoch": 0.5261003677779096,
      "grad_norm": 0.24789759516716003,
      "learning_rate": 1.0531241761138942e-05,
      "loss": 0.0032,
      "step": 8869
    },
    {
      "epoch": 0.5261596867955867,
      "grad_norm": 0.01375579833984375,
      "learning_rate": 1.0529923543369364e-05,
      "loss": 0.0004,
      "step": 8870
    },
    {
      "epoch": 0.5262190058132638,
      "grad_norm": 0.01656837947666645,
      "learning_rate": 1.052860532559979e-05,
      "loss": 0.0005,
      "step": 8871
    },
    {
      "epoch": 0.5262783248309408,
      "grad_norm": 0.027650143951177597,
      "learning_rate": 1.0527287107830216e-05,
      "loss": 0.0008,
      "step": 8872
    },
    {
      "epoch": 0.5263376438486179,
      "grad_norm": 0.010961638763546944,
      "learning_rate": 1.0525968890060638e-05,
      "loss": 0.0003,
      "step": 8873
    },
    {
      "epoch": 0.5263969628662949,
      "grad_norm": 2.2714052200317383,
      "learning_rate": 1.0524650672291064e-05,
      "loss": 0.0591,
      "step": 8874
    },
    {
      "epoch": 0.526456281883972,
      "grad_norm": 20.40292739868164,
      "learning_rate": 1.0523332454521488e-05,
      "loss": 0.075,
      "step": 8875
    },
    {
      "epoch": 0.5265156009016491,
      "grad_norm": 5.84208345413208,
      "learning_rate": 1.0522014236751913e-05,
      "loss": 0.083,
      "step": 8876
    },
    {
      "epoch": 0.5265749199193261,
      "grad_norm": 0.29638293385505676,
      "learning_rate": 1.0520696018982337e-05,
      "loss": 0.0041,
      "step": 8877
    },
    {
      "epoch": 0.5266342389370032,
      "grad_norm": 8.915959358215332,
      "learning_rate": 1.0519377801212763e-05,
      "loss": 0.0786,
      "step": 8878
    },
    {
      "epoch": 0.5266935579546803,
      "grad_norm": 0.19568853080272675,
      "learning_rate": 1.0518059583443185e-05,
      "loss": 0.0016,
      "step": 8879
    },
    {
      "epoch": 0.5267528769723573,
      "grad_norm": 19.296911239624023,
      "learning_rate": 1.0516741365673611e-05,
      "loss": 0.8074,
      "step": 8880
    },
    {
      "epoch": 0.5268121959900344,
      "grad_norm": 41.49654769897461,
      "learning_rate": 1.0515423147904034e-05,
      "loss": 0.8873,
      "step": 8881
    },
    {
      "epoch": 0.5268715150077115,
      "grad_norm": 0.005263747181743383,
      "learning_rate": 1.051410493013446e-05,
      "loss": 0.0002,
      "step": 8882
    },
    {
      "epoch": 0.5269308340253885,
      "grad_norm": 0.08620703965425491,
      "learning_rate": 1.0512786712364884e-05,
      "loss": 0.0018,
      "step": 8883
    },
    {
      "epoch": 0.5269901530430656,
      "grad_norm": 3.247753381729126,
      "learning_rate": 1.0511468494595308e-05,
      "loss": 0.0401,
      "step": 8884
    },
    {
      "epoch": 0.5270494720607427,
      "grad_norm": 2.0249109268188477,
      "learning_rate": 1.0510150276825732e-05,
      "loss": 0.0159,
      "step": 8885
    },
    {
      "epoch": 0.5271087910784198,
      "grad_norm": 0.8117473721504211,
      "learning_rate": 1.0508832059056158e-05,
      "loss": 0.011,
      "step": 8886
    },
    {
      "epoch": 0.5271681100960968,
      "grad_norm": 3.5140163898468018,
      "learning_rate": 1.050751384128658e-05,
      "loss": 0.0406,
      "step": 8887
    },
    {
      "epoch": 0.5272274291137738,
      "grad_norm": 4.167945384979248,
      "learning_rate": 1.0506195623517006e-05,
      "loss": 0.3713,
      "step": 8888
    },
    {
      "epoch": 0.5272867481314509,
      "grad_norm": 14.648455619812012,
      "learning_rate": 1.050487740574743e-05,
      "loss": 2.1165,
      "step": 8889
    },
    {
      "epoch": 0.527346067149128,
      "grad_norm": 0.4801279604434967,
      "learning_rate": 1.0503559187977855e-05,
      "loss": 0.0024,
      "step": 8890
    },
    {
      "epoch": 0.5274053861668051,
      "grad_norm": 0.03491233289241791,
      "learning_rate": 1.0502240970208279e-05,
      "loss": 0.0005,
      "step": 8891
    },
    {
      "epoch": 0.5274647051844822,
      "grad_norm": 0.07083923369646072,
      "learning_rate": 1.0500922752438705e-05,
      "loss": 0.0005,
      "step": 8892
    },
    {
      "epoch": 0.5275240242021592,
      "grad_norm": 5.645211696624756,
      "learning_rate": 1.0499604534669127e-05,
      "loss": 0.1288,
      "step": 8893
    },
    {
      "epoch": 0.5275833432198362,
      "grad_norm": 1.251039981842041,
      "learning_rate": 1.0498286316899553e-05,
      "loss": 0.0234,
      "step": 8894
    },
    {
      "epoch": 0.5276426622375133,
      "grad_norm": 0.18819838762283325,
      "learning_rate": 1.0496968099129976e-05,
      "loss": 0.002,
      "step": 8895
    },
    {
      "epoch": 0.5277019812551904,
      "grad_norm": 2.0986931324005127,
      "learning_rate": 1.0495649881360401e-05,
      "loss": 0.0201,
      "step": 8896
    },
    {
      "epoch": 0.5277613002728675,
      "grad_norm": 7.583250045776367,
      "learning_rate": 1.0494331663590827e-05,
      "loss": 0.0756,
      "step": 8897
    },
    {
      "epoch": 0.5278206192905446,
      "grad_norm": 15.650297164916992,
      "learning_rate": 1.049301344582125e-05,
      "loss": 0.2916,
      "step": 8898
    },
    {
      "epoch": 0.5278799383082217,
      "grad_norm": 0.005307395942509174,
      "learning_rate": 1.0491695228051674e-05,
      "loss": 0.0002,
      "step": 8899
    },
    {
      "epoch": 0.5279392573258986,
      "grad_norm": 0.40342995524406433,
      "learning_rate": 1.04903770102821e-05,
      "loss": 0.0037,
      "step": 8900
    },
    {
      "epoch": 0.5279985763435757,
      "grad_norm": 16.352794647216797,
      "learning_rate": 1.0489058792512522e-05,
      "loss": 0.4737,
      "step": 8901
    },
    {
      "epoch": 0.5280578953612528,
      "grad_norm": 9.318445205688477,
      "learning_rate": 1.0487740574742948e-05,
      "loss": 0.3246,
      "step": 8902
    },
    {
      "epoch": 0.5281172143789299,
      "grad_norm": 35.97797393798828,
      "learning_rate": 1.0486422356973374e-05,
      "loss": 0.3084,
      "step": 8903
    },
    {
      "epoch": 0.528176533396607,
      "grad_norm": 1.3395798206329346,
      "learning_rate": 1.0485104139203797e-05,
      "loss": 0.0074,
      "step": 8904
    },
    {
      "epoch": 0.5282358524142841,
      "grad_norm": 1.974660038948059,
      "learning_rate": 1.0483785921434223e-05,
      "loss": 0.0254,
      "step": 8905
    },
    {
      "epoch": 0.5282951714319611,
      "grad_norm": 4.150999546051025,
      "learning_rate": 1.0482467703664647e-05,
      "loss": 0.3374,
      "step": 8906
    },
    {
      "epoch": 0.5283544904496381,
      "grad_norm": 4.684935569763184,
      "learning_rate": 1.0481149485895071e-05,
      "loss": 0.1032,
      "step": 8907
    },
    {
      "epoch": 0.5284138094673152,
      "grad_norm": 3.0280966758728027,
      "learning_rate": 1.0479831268125495e-05,
      "loss": 0.0255,
      "step": 8908
    },
    {
      "epoch": 0.5284731284849923,
      "grad_norm": 0.1801525354385376,
      "learning_rate": 1.0478513050355921e-05,
      "loss": 0.002,
      "step": 8909
    },
    {
      "epoch": 0.5285324475026694,
      "grad_norm": 16.3531551361084,
      "learning_rate": 1.0477194832586343e-05,
      "loss": 0.258,
      "step": 8910
    },
    {
      "epoch": 0.5285917665203465,
      "grad_norm": 0.15870583057403564,
      "learning_rate": 1.047587661481677e-05,
      "loss": 0.0026,
      "step": 8911
    },
    {
      "epoch": 0.5286510855380235,
      "grad_norm": 3.760124444961548,
      "learning_rate": 1.0474558397047192e-05,
      "loss": 0.1385,
      "step": 8912
    },
    {
      "epoch": 0.5287104045557005,
      "grad_norm": 4.309624671936035,
      "learning_rate": 1.0473240179277618e-05,
      "loss": 0.0204,
      "step": 8913
    },
    {
      "epoch": 0.5287697235733776,
      "grad_norm": 1.778117299079895,
      "learning_rate": 1.0471921961508042e-05,
      "loss": 0.0113,
      "step": 8914
    },
    {
      "epoch": 0.5288290425910547,
      "grad_norm": 3.684481620788574,
      "learning_rate": 1.0470603743738466e-05,
      "loss": 0.019,
      "step": 8915
    },
    {
      "epoch": 0.5288883616087318,
      "grad_norm": 1.5474516153335571,
      "learning_rate": 1.046928552596889e-05,
      "loss": 0.0169,
      "step": 8916
    },
    {
      "epoch": 0.5289476806264088,
      "grad_norm": 23.862071990966797,
      "learning_rate": 1.0467967308199316e-05,
      "loss": 0.1575,
      "step": 8917
    },
    {
      "epoch": 0.5290069996440859,
      "grad_norm": 0.08907634764909744,
      "learning_rate": 1.0466649090429739e-05,
      "loss": 0.001,
      "step": 8918
    },
    {
      "epoch": 0.529066318661763,
      "grad_norm": 6.876157760620117,
      "learning_rate": 1.0465330872660165e-05,
      "loss": 0.2339,
      "step": 8919
    },
    {
      "epoch": 0.52912563767944,
      "grad_norm": 11.638021469116211,
      "learning_rate": 1.046401265489059e-05,
      "loss": 0.3747,
      "step": 8920
    },
    {
      "epoch": 0.5291849566971171,
      "grad_norm": 12.927645683288574,
      "learning_rate": 1.0462694437121013e-05,
      "loss": 0.7253,
      "step": 8921
    },
    {
      "epoch": 0.5292442757147942,
      "grad_norm": 0.025673018768429756,
      "learning_rate": 1.0461376219351437e-05,
      "loss": 0.0006,
      "step": 8922
    },
    {
      "epoch": 0.5293035947324712,
      "grad_norm": 12.591229438781738,
      "learning_rate": 1.0460058001581863e-05,
      "loss": 0.134,
      "step": 8923
    },
    {
      "epoch": 0.5293629137501483,
      "grad_norm": 1.078281283378601,
      "learning_rate": 1.0458739783812285e-05,
      "loss": 0.0062,
      "step": 8924
    },
    {
      "epoch": 0.5294222327678254,
      "grad_norm": 0.010393566451966763,
      "learning_rate": 1.0457421566042711e-05,
      "loss": 0.0003,
      "step": 8925
    },
    {
      "epoch": 0.5294815517855024,
      "grad_norm": 0.07701452076435089,
      "learning_rate": 1.0456103348273137e-05,
      "loss": 0.0008,
      "step": 8926
    },
    {
      "epoch": 0.5295408708031795,
      "grad_norm": 0.007484803441911936,
      "learning_rate": 1.045478513050356e-05,
      "loss": 0.0003,
      "step": 8927
    },
    {
      "epoch": 0.5296001898208565,
      "grad_norm": 28.818601608276367,
      "learning_rate": 1.0453466912733986e-05,
      "loss": 0.5671,
      "step": 8928
    },
    {
      "epoch": 0.5296595088385336,
      "grad_norm": 0.2178329974412918,
      "learning_rate": 1.0452148694964408e-05,
      "loss": 0.0045,
      "step": 8929
    },
    {
      "epoch": 0.5297188278562107,
      "grad_norm": 13.651092529296875,
      "learning_rate": 1.0450830477194834e-05,
      "loss": 0.353,
      "step": 8930
    },
    {
      "epoch": 0.5297781468738878,
      "grad_norm": 0.38173121213912964,
      "learning_rate": 1.0449512259425258e-05,
      "loss": 0.0042,
      "step": 8931
    },
    {
      "epoch": 0.5298374658915649,
      "grad_norm": 3.7069895267486572,
      "learning_rate": 1.0448194041655682e-05,
      "loss": 0.0573,
      "step": 8932
    },
    {
      "epoch": 0.5298967849092419,
      "grad_norm": 3.429661989212036,
      "learning_rate": 1.0446875823886107e-05,
      "loss": 0.024,
      "step": 8933
    },
    {
      "epoch": 0.5299561039269189,
      "grad_norm": 9.423665046691895,
      "learning_rate": 1.0445557606116532e-05,
      "loss": 0.1993,
      "step": 8934
    },
    {
      "epoch": 0.530015422944596,
      "grad_norm": 1.8488101959228516,
      "learning_rate": 1.0444239388346955e-05,
      "loss": 0.0151,
      "step": 8935
    },
    {
      "epoch": 0.5300747419622731,
      "grad_norm": 6.313451766967773,
      "learning_rate": 1.044292117057738e-05,
      "loss": 0.0957,
      "step": 8936
    },
    {
      "epoch": 0.5301340609799502,
      "grad_norm": 10.244174003601074,
      "learning_rate": 1.0441602952807805e-05,
      "loss": 0.3525,
      "step": 8937
    },
    {
      "epoch": 0.5301933799976273,
      "grad_norm": 0.06603953242301941,
      "learning_rate": 1.044028473503823e-05,
      "loss": 0.0016,
      "step": 8938
    },
    {
      "epoch": 0.5302526990153043,
      "grad_norm": 4.736054420471191,
      "learning_rate": 1.0438966517268653e-05,
      "loss": 0.0657,
      "step": 8939
    },
    {
      "epoch": 0.5303120180329813,
      "grad_norm": 3.8843514919281006,
      "learning_rate": 1.043764829949908e-05,
      "loss": 0.1157,
      "step": 8940
    },
    {
      "epoch": 0.5303713370506584,
      "grad_norm": 1.583263635635376,
      "learning_rate": 1.0436330081729502e-05,
      "loss": 0.0075,
      "step": 8941
    },
    {
      "epoch": 0.5304306560683355,
      "grad_norm": 5.087820529937744,
      "learning_rate": 1.0435011863959928e-05,
      "loss": 0.1711,
      "step": 8942
    },
    {
      "epoch": 0.5304899750860126,
      "grad_norm": 14.427986145019531,
      "learning_rate": 1.043369364619035e-05,
      "loss": 0.1341,
      "step": 8943
    },
    {
      "epoch": 0.5305492941036897,
      "grad_norm": 21.588682174682617,
      "learning_rate": 1.0432375428420776e-05,
      "loss": 0.4581,
      "step": 8944
    },
    {
      "epoch": 0.5306086131213668,
      "grad_norm": 7.917831897735596,
      "learning_rate": 1.04310572106512e-05,
      "loss": 0.1548,
      "step": 8945
    },
    {
      "epoch": 0.5306679321390437,
      "grad_norm": 9.245613098144531,
      "learning_rate": 1.0429738992881624e-05,
      "loss": 0.2233,
      "step": 8946
    },
    {
      "epoch": 0.5307272511567208,
      "grad_norm": 0.22025422751903534,
      "learning_rate": 1.0428420775112049e-05,
      "loss": 0.0025,
      "step": 8947
    },
    {
      "epoch": 0.5307865701743979,
      "grad_norm": 5.828711032867432,
      "learning_rate": 1.0427102557342474e-05,
      "loss": 0.0779,
      "step": 8948
    },
    {
      "epoch": 0.530845889192075,
      "grad_norm": 0.463174045085907,
      "learning_rate": 1.0425784339572897e-05,
      "loss": 0.0025,
      "step": 8949
    },
    {
      "epoch": 0.5309052082097521,
      "grad_norm": 3.1782944202423096,
      "learning_rate": 1.0424466121803323e-05,
      "loss": 0.122,
      "step": 8950
    },
    {
      "epoch": 0.5309645272274292,
      "grad_norm": 0.38027438521385193,
      "learning_rate": 1.0423147904033749e-05,
      "loss": 0.005,
      "step": 8951
    },
    {
      "epoch": 0.5310238462451062,
      "grad_norm": 4.852755546569824,
      "learning_rate": 1.0421829686264171e-05,
      "loss": 0.0895,
      "step": 8952
    },
    {
      "epoch": 0.5310831652627832,
      "grad_norm": 5.024633407592773,
      "learning_rate": 1.0420511468494597e-05,
      "loss": 0.0351,
      "step": 8953
    },
    {
      "epoch": 0.5311424842804603,
      "grad_norm": 0.3532593846321106,
      "learning_rate": 1.0419193250725021e-05,
      "loss": 0.005,
      "step": 8954
    },
    {
      "epoch": 0.5312018032981374,
      "grad_norm": 0.4380497336387634,
      "learning_rate": 1.0417875032955444e-05,
      "loss": 0.0044,
      "step": 8955
    },
    {
      "epoch": 0.5312611223158145,
      "grad_norm": 3.2259068489074707,
      "learning_rate": 1.041655681518587e-05,
      "loss": 0.219,
      "step": 8956
    },
    {
      "epoch": 0.5313204413334915,
      "grad_norm": 0.23234765231609344,
      "learning_rate": 1.0415238597416295e-05,
      "loss": 0.0046,
      "step": 8957
    },
    {
      "epoch": 0.5313797603511686,
      "grad_norm": 7.938940525054932,
      "learning_rate": 1.0413920379646718e-05,
      "loss": 0.1902,
      "step": 8958
    },
    {
      "epoch": 0.5314390793688456,
      "grad_norm": 3.2257139682769775,
      "learning_rate": 1.0412602161877144e-05,
      "loss": 0.0277,
      "step": 8959
    },
    {
      "epoch": 0.5314983983865227,
      "grad_norm": 0.008447582833468914,
      "learning_rate": 1.0411283944107566e-05,
      "loss": 0.0002,
      "step": 8960
    },
    {
      "epoch": 0.5315577174041998,
      "grad_norm": 0.04209977388381958,
      "learning_rate": 1.0409965726337992e-05,
      "loss": 0.001,
      "step": 8961
    },
    {
      "epoch": 0.5316170364218769,
      "grad_norm": 0.030597418546676636,
      "learning_rate": 1.0408647508568416e-05,
      "loss": 0.0007,
      "step": 8962
    },
    {
      "epoch": 0.5316763554395539,
      "grad_norm": 3.2973716259002686,
      "learning_rate": 1.040732929079884e-05,
      "loss": 0.0251,
      "step": 8963
    },
    {
      "epoch": 0.531735674457231,
      "grad_norm": 5.893241882324219,
      "learning_rate": 1.0406011073029265e-05,
      "loss": 0.1693,
      "step": 8964
    },
    {
      "epoch": 0.5317949934749081,
      "grad_norm": 12.82164192199707,
      "learning_rate": 1.040469285525969e-05,
      "loss": 0.1604,
      "step": 8965
    },
    {
      "epoch": 0.5318543124925851,
      "grad_norm": 18.733064651489258,
      "learning_rate": 1.0403374637490113e-05,
      "loss": 0.1026,
      "step": 8966
    },
    {
      "epoch": 0.5319136315102622,
      "grad_norm": 22.24599266052246,
      "learning_rate": 1.0402056419720539e-05,
      "loss": 0.7908,
      "step": 8967
    },
    {
      "epoch": 0.5319729505279392,
      "grad_norm": 16.586463928222656,
      "learning_rate": 1.0400738201950963e-05,
      "loss": 0.339,
      "step": 8968
    },
    {
      "epoch": 0.5320322695456163,
      "grad_norm": 0.2377772331237793,
      "learning_rate": 1.0399419984181387e-05,
      "loss": 0.0028,
      "step": 8969
    },
    {
      "epoch": 0.5320915885632934,
      "grad_norm": 0.009881201200187206,
      "learning_rate": 1.0398101766411812e-05,
      "loss": 0.0004,
      "step": 8970
    },
    {
      "epoch": 0.5321509075809705,
      "grad_norm": 0.8292089700698853,
      "learning_rate": 1.0396783548642237e-05,
      "loss": 0.0093,
      "step": 8971
    },
    {
      "epoch": 0.5322102265986475,
      "grad_norm": 0.20545567572116852,
      "learning_rate": 1.039546533087266e-05,
      "loss": 0.0042,
      "step": 8972
    },
    {
      "epoch": 0.5322695456163246,
      "grad_norm": 0.18695834279060364,
      "learning_rate": 1.0394147113103086e-05,
      "loss": 0.0013,
      "step": 8973
    },
    {
      "epoch": 0.5323288646340016,
      "grad_norm": 22.26592254638672,
      "learning_rate": 1.0392828895333512e-05,
      "loss": 0.4819,
      "step": 8974
    },
    {
      "epoch": 0.5323881836516787,
      "grad_norm": 1.314615249633789,
      "learning_rate": 1.0391510677563934e-05,
      "loss": 0.0167,
      "step": 8975
    },
    {
      "epoch": 0.5324475026693558,
      "grad_norm": 6.913329601287842,
      "learning_rate": 1.039019245979436e-05,
      "loss": 0.1749,
      "step": 8976
    },
    {
      "epoch": 0.5325068216870329,
      "grad_norm": 0.029736682772636414,
      "learning_rate": 1.0388874242024783e-05,
      "loss": 0.0008,
      "step": 8977
    },
    {
      "epoch": 0.53256614070471,
      "grad_norm": 21.814666748046875,
      "learning_rate": 1.0387556024255207e-05,
      "loss": 1.0831,
      "step": 8978
    },
    {
      "epoch": 0.532625459722387,
      "grad_norm": 18.710044860839844,
      "learning_rate": 1.0386237806485633e-05,
      "loss": 0.321,
      "step": 8979
    },
    {
      "epoch": 0.532684778740064,
      "grad_norm": 11.414567947387695,
      "learning_rate": 1.0384919588716055e-05,
      "loss": 0.3556,
      "step": 8980
    },
    {
      "epoch": 0.5327440977577411,
      "grad_norm": 0.05820384994149208,
      "learning_rate": 1.0383601370946481e-05,
      "loss": 0.0016,
      "step": 8981
    },
    {
      "epoch": 0.5328034167754182,
      "grad_norm": 2.5978379249572754,
      "learning_rate": 1.0382283153176907e-05,
      "loss": 0.0405,
      "step": 8982
    },
    {
      "epoch": 0.5328627357930953,
      "grad_norm": 0.7795313596725464,
      "learning_rate": 1.038096493540733e-05,
      "loss": 0.0166,
      "step": 8983
    },
    {
      "epoch": 0.5329220548107724,
      "grad_norm": 10.493354797363281,
      "learning_rate": 1.0379646717637755e-05,
      "loss": 0.2989,
      "step": 8984
    },
    {
      "epoch": 0.5329813738284495,
      "grad_norm": 18.506351470947266,
      "learning_rate": 1.037832849986818e-05,
      "loss": 0.5876,
      "step": 8985
    },
    {
      "epoch": 0.5330406928461264,
      "grad_norm": 0.3257941007614136,
      "learning_rate": 1.0377010282098604e-05,
      "loss": 0.0036,
      "step": 8986
    },
    {
      "epoch": 0.5331000118638035,
      "grad_norm": 3.241727352142334,
      "learning_rate": 1.0375692064329028e-05,
      "loss": 0.0258,
      "step": 8987
    },
    {
      "epoch": 0.5331593308814806,
      "grad_norm": 0.2560279071331024,
      "learning_rate": 1.0374373846559454e-05,
      "loss": 0.0059,
      "step": 8988
    },
    {
      "epoch": 0.5332186498991577,
      "grad_norm": 4.398800849914551,
      "learning_rate": 1.0373055628789876e-05,
      "loss": 0.022,
      "step": 8989
    },
    {
      "epoch": 0.5332779689168348,
      "grad_norm": 0.0768083781003952,
      "learning_rate": 1.0371737411020302e-05,
      "loss": 0.0006,
      "step": 8990
    },
    {
      "epoch": 0.5333372879345119,
      "grad_norm": 7.165376663208008,
      "learning_rate": 1.0370419193250725e-05,
      "loss": 0.0651,
      "step": 8991
    },
    {
      "epoch": 0.5333966069521888,
      "grad_norm": 1.9660179615020752,
      "learning_rate": 1.036910097548115e-05,
      "loss": 0.0188,
      "step": 8992
    },
    {
      "epoch": 0.5334559259698659,
      "grad_norm": 2.7794952392578125,
      "learning_rate": 1.0367782757711575e-05,
      "loss": 0.0147,
      "step": 8993
    },
    {
      "epoch": 0.533515244987543,
      "grad_norm": 0.01458705123513937,
      "learning_rate": 1.0366464539941999e-05,
      "loss": 0.0004,
      "step": 8994
    },
    {
      "epoch": 0.5335745640052201,
      "grad_norm": 0.023170461878180504,
      "learning_rate": 1.0365146322172423e-05,
      "loss": 0.0005,
      "step": 8995
    },
    {
      "epoch": 0.5336338830228972,
      "grad_norm": 1.6843167543411255,
      "learning_rate": 1.0363828104402849e-05,
      "loss": 0.02,
      "step": 8996
    },
    {
      "epoch": 0.5336932020405742,
      "grad_norm": 3.4950788021087646,
      "learning_rate": 1.0362509886633271e-05,
      "loss": 0.0594,
      "step": 8997
    },
    {
      "epoch": 0.5337525210582513,
      "grad_norm": 0.17066392302513123,
      "learning_rate": 1.0361191668863697e-05,
      "loss": 0.002,
      "step": 8998
    },
    {
      "epoch": 0.5338118400759283,
      "grad_norm": 0.17503955960273743,
      "learning_rate": 1.0359873451094122e-05,
      "loss": 0.0019,
      "step": 8999
    },
    {
      "epoch": 0.5338711590936054,
      "grad_norm": 0.2655556797981262,
      "learning_rate": 1.0358555233324546e-05,
      "loss": 0.0037,
      "step": 9000
    },
    {
      "epoch": 0.5339304781112825,
      "grad_norm": 2.8314425945281982,
      "learning_rate": 1.035723701555497e-05,
      "loss": 0.0348,
      "step": 9001
    },
    {
      "epoch": 0.5339897971289596,
      "grad_norm": 0.026187535375356674,
      "learning_rate": 1.0355918797785396e-05,
      "loss": 0.0005,
      "step": 9002
    },
    {
      "epoch": 0.5340491161466366,
      "grad_norm": 0.47413700819015503,
      "learning_rate": 1.0354600580015818e-05,
      "loss": 0.0085,
      "step": 9003
    },
    {
      "epoch": 0.5341084351643137,
      "grad_norm": 0.003568913321942091,
      "learning_rate": 1.0353282362246244e-05,
      "loss": 0.0001,
      "step": 9004
    },
    {
      "epoch": 0.5341677541819907,
      "grad_norm": 0.011310485191643238,
      "learning_rate": 1.035196414447667e-05,
      "loss": 0.0003,
      "step": 9005
    },
    {
      "epoch": 0.5342270731996678,
      "grad_norm": 0.015357154421508312,
      "learning_rate": 1.0350645926707093e-05,
      "loss": 0.0003,
      "step": 9006
    },
    {
      "epoch": 0.5342863922173449,
      "grad_norm": 4.003145217895508,
      "learning_rate": 1.0349327708937518e-05,
      "loss": 0.2267,
      "step": 9007
    },
    {
      "epoch": 0.534345711235022,
      "grad_norm": 7.553072929382324,
      "learning_rate": 1.0348009491167941e-05,
      "loss": 0.048,
      "step": 9008
    },
    {
      "epoch": 0.534405030252699,
      "grad_norm": 0.8235647678375244,
      "learning_rate": 1.0346691273398367e-05,
      "loss": 0.0091,
      "step": 9009
    },
    {
      "epoch": 0.5344643492703761,
      "grad_norm": 1.981998324394226,
      "learning_rate": 1.0345373055628791e-05,
      "loss": 0.0203,
      "step": 9010
    },
    {
      "epoch": 0.5345236682880532,
      "grad_norm": 0.16478535532951355,
      "learning_rate": 1.0344054837859213e-05,
      "loss": 0.0021,
      "step": 9011
    },
    {
      "epoch": 0.5345829873057302,
      "grad_norm": 16.07492446899414,
      "learning_rate": 1.034273662008964e-05,
      "loss": 0.1942,
      "step": 9012
    },
    {
      "epoch": 0.5346423063234073,
      "grad_norm": 9.177726745605469,
      "learning_rate": 1.0341418402320065e-05,
      "loss": 0.7009,
      "step": 9013
    },
    {
      "epoch": 0.5347016253410843,
      "grad_norm": 0.34126850962638855,
      "learning_rate": 1.0340100184550488e-05,
      "loss": 0.0044,
      "step": 9014
    },
    {
      "epoch": 0.5347609443587614,
      "grad_norm": 0.008972185663878918,
      "learning_rate": 1.0338781966780914e-05,
      "loss": 0.0003,
      "step": 9015
    },
    {
      "epoch": 0.5348202633764385,
      "grad_norm": 4.079963207244873,
      "learning_rate": 1.0337463749011338e-05,
      "loss": 0.0993,
      "step": 9016
    },
    {
      "epoch": 0.5348795823941156,
      "grad_norm": 0.08992794156074524,
      "learning_rate": 1.0336145531241762e-05,
      "loss": 0.0017,
      "step": 9017
    },
    {
      "epoch": 0.5349389014117926,
      "grad_norm": 1.5110849142074585,
      "learning_rate": 1.0334827313472186e-05,
      "loss": 0.0179,
      "step": 9018
    },
    {
      "epoch": 0.5349982204294697,
      "grad_norm": 1.665164589881897,
      "learning_rate": 1.0333509095702612e-05,
      "loss": 0.0176,
      "step": 9019
    },
    {
      "epoch": 0.5350575394471467,
      "grad_norm": 0.39099550247192383,
      "learning_rate": 1.0332190877933035e-05,
      "loss": 0.007,
      "step": 9020
    },
    {
      "epoch": 0.5351168584648238,
      "grad_norm": 0.06568189710378647,
      "learning_rate": 1.033087266016346e-05,
      "loss": 0.0012,
      "step": 9021
    },
    {
      "epoch": 0.5351761774825009,
      "grad_norm": 4.564544200897217,
      "learning_rate": 1.0329554442393885e-05,
      "loss": 0.0452,
      "step": 9022
    },
    {
      "epoch": 0.535235496500178,
      "grad_norm": 42.1165771484375,
      "learning_rate": 1.0328236224624309e-05,
      "loss": 0.0517,
      "step": 9023
    },
    {
      "epoch": 0.5352948155178551,
      "grad_norm": 2.231837511062622,
      "learning_rate": 1.0326918006854733e-05,
      "loss": 0.0106,
      "step": 9024
    },
    {
      "epoch": 0.535354134535532,
      "grad_norm": 0.1030321717262268,
      "learning_rate": 1.0325599789085157e-05,
      "loss": 0.002,
      "step": 9025
    },
    {
      "epoch": 0.5354134535532091,
      "grad_norm": 0.14383652806282043,
      "learning_rate": 1.0324281571315581e-05,
      "loss": 0.0023,
      "step": 9026
    },
    {
      "epoch": 0.5354727725708862,
      "grad_norm": 9.541653633117676,
      "learning_rate": 1.0322963353546007e-05,
      "loss": 0.3463,
      "step": 9027
    },
    {
      "epoch": 0.5355320915885633,
      "grad_norm": 0.0866035744547844,
      "learning_rate": 1.032164513577643e-05,
      "loss": 0.0016,
      "step": 9028
    },
    {
      "epoch": 0.5355914106062404,
      "grad_norm": 3.3923096656799316,
      "learning_rate": 1.0320326918006856e-05,
      "loss": 0.0424,
      "step": 9029
    },
    {
      "epoch": 0.5356507296239175,
      "grad_norm": 6.826251983642578,
      "learning_rate": 1.0319008700237281e-05,
      "loss": 0.072,
      "step": 9030
    },
    {
      "epoch": 0.5357100486415945,
      "grad_norm": 0.6455338597297668,
      "learning_rate": 1.0317690482467704e-05,
      "loss": 0.0065,
      "step": 9031
    },
    {
      "epoch": 0.5357693676592715,
      "grad_norm": 0.02458403818309307,
      "learning_rate": 1.031637226469813e-05,
      "loss": 0.0005,
      "step": 9032
    },
    {
      "epoch": 0.5358286866769486,
      "grad_norm": 0.012417775578796864,
      "learning_rate": 1.0315054046928554e-05,
      "loss": 0.0003,
      "step": 9033
    },
    {
      "epoch": 0.5358880056946257,
      "grad_norm": 20.875516891479492,
      "learning_rate": 1.0313735829158977e-05,
      "loss": 0.9073,
      "step": 9034
    },
    {
      "epoch": 0.5359473247123028,
      "grad_norm": 2.9500370025634766,
      "learning_rate": 1.0312417611389402e-05,
      "loss": 0.0303,
      "step": 9035
    },
    {
      "epoch": 0.5360066437299799,
      "grad_norm": 2.151444435119629,
      "learning_rate": 1.0311099393619828e-05,
      "loss": 0.0217,
      "step": 9036
    },
    {
      "epoch": 0.5360659627476569,
      "grad_norm": 3.0761969089508057,
      "learning_rate": 1.030978117585025e-05,
      "loss": 0.0394,
      "step": 9037
    },
    {
      "epoch": 0.5361252817653339,
      "grad_norm": 0.007540459278970957,
      "learning_rate": 1.0308462958080677e-05,
      "loss": 0.0002,
      "step": 9038
    },
    {
      "epoch": 0.536184600783011,
      "grad_norm": 4.186990737915039,
      "learning_rate": 1.03071447403111e-05,
      "loss": 0.0437,
      "step": 9039
    },
    {
      "epoch": 0.5362439198006881,
      "grad_norm": 13.73546028137207,
      "learning_rate": 1.0305826522541525e-05,
      "loss": 0.1394,
      "step": 9040
    },
    {
      "epoch": 0.5363032388183652,
      "grad_norm": 1.668227195739746,
      "learning_rate": 1.030450830477195e-05,
      "loss": 0.0093,
      "step": 9041
    },
    {
      "epoch": 0.5363625578360423,
      "grad_norm": 7.629101753234863,
      "learning_rate": 1.0303190087002373e-05,
      "loss": 0.3028,
      "step": 9042
    },
    {
      "epoch": 0.5364218768537193,
      "grad_norm": 0.014990514144301414,
      "learning_rate": 1.0301871869232798e-05,
      "loss": 0.0006,
      "step": 9043
    },
    {
      "epoch": 0.5364811958713964,
      "grad_norm": 3.7070958614349365,
      "learning_rate": 1.0300553651463223e-05,
      "loss": 0.0219,
      "step": 9044
    },
    {
      "epoch": 0.5365405148890734,
      "grad_norm": 0.1973688006401062,
      "learning_rate": 1.0299235433693646e-05,
      "loss": 0.0031,
      "step": 9045
    },
    {
      "epoch": 0.5365998339067505,
      "grad_norm": 28.390220642089844,
      "learning_rate": 1.0297917215924072e-05,
      "loss": 0.5759,
      "step": 9046
    },
    {
      "epoch": 0.5366591529244276,
      "grad_norm": 0.22136564552783966,
      "learning_rate": 1.0296598998154496e-05,
      "loss": 0.0024,
      "step": 9047
    },
    {
      "epoch": 0.5367184719421046,
      "grad_norm": 0.008762032724916935,
      "learning_rate": 1.029528078038492e-05,
      "loss": 0.0003,
      "step": 9048
    },
    {
      "epoch": 0.5367777909597817,
      "grad_norm": 0.15341436862945557,
      "learning_rate": 1.0293962562615344e-05,
      "loss": 0.0015,
      "step": 9049
    },
    {
      "epoch": 0.5368371099774588,
      "grad_norm": 3.5332324504852295,
      "learning_rate": 1.029264434484577e-05,
      "loss": 0.0419,
      "step": 9050
    },
    {
      "epoch": 0.5368964289951358,
      "grad_norm": 0.05523541942238808,
      "learning_rate": 1.0291326127076193e-05,
      "loss": 0.0007,
      "step": 9051
    },
    {
      "epoch": 0.5369557480128129,
      "grad_norm": 1.1161599159240723,
      "learning_rate": 1.0290007909306619e-05,
      "loss": 0.013,
      "step": 9052
    },
    {
      "epoch": 0.53701506703049,
      "grad_norm": 1.102102279663086,
      "learning_rate": 1.0288689691537045e-05,
      "loss": 0.0083,
      "step": 9053
    },
    {
      "epoch": 0.537074386048167,
      "grad_norm": 0.07176288217306137,
      "learning_rate": 1.0287371473767467e-05,
      "loss": 0.0014,
      "step": 9054
    },
    {
      "epoch": 0.5371337050658441,
      "grad_norm": 1.1201575994491577,
      "learning_rate": 1.0286053255997891e-05,
      "loss": 0.0115,
      "step": 9055
    },
    {
      "epoch": 0.5371930240835212,
      "grad_norm": 0.6172360777854919,
      "learning_rate": 1.0284735038228315e-05,
      "loss": 0.0105,
      "step": 9056
    },
    {
      "epoch": 0.5372523431011983,
      "grad_norm": 11.220122337341309,
      "learning_rate": 1.028341682045874e-05,
      "loss": 0.3176,
      "step": 9057
    },
    {
      "epoch": 0.5373116621188753,
      "grad_norm": 18.088727951049805,
      "learning_rate": 1.0282098602689165e-05,
      "loss": 0.1711,
      "step": 9058
    },
    {
      "epoch": 0.5373709811365524,
      "grad_norm": 0.17057135701179504,
      "learning_rate": 1.0280780384919588e-05,
      "loss": 0.002,
      "step": 9059
    },
    {
      "epoch": 0.5374303001542294,
      "grad_norm": 5.002381801605225,
      "learning_rate": 1.0279462167150014e-05,
      "loss": 0.0695,
      "step": 9060
    },
    {
      "epoch": 0.5374896191719065,
      "grad_norm": 0.1506514698266983,
      "learning_rate": 1.027814394938044e-05,
      "loss": 0.0024,
      "step": 9061
    },
    {
      "epoch": 0.5375489381895836,
      "grad_norm": 11.403497695922852,
      "learning_rate": 1.0276825731610862e-05,
      "loss": 0.2352,
      "step": 9062
    },
    {
      "epoch": 0.5376082572072607,
      "grad_norm": 6.046470642089844,
      "learning_rate": 1.0275507513841288e-05,
      "loss": 0.0957,
      "step": 9063
    },
    {
      "epoch": 0.5376675762249377,
      "grad_norm": 0.0594186931848526,
      "learning_rate": 1.0274189296071712e-05,
      "loss": 0.0007,
      "step": 9064
    },
    {
      "epoch": 0.5377268952426147,
      "grad_norm": 12.727922439575195,
      "learning_rate": 1.0272871078302136e-05,
      "loss": 0.0996,
      "step": 9065
    },
    {
      "epoch": 0.5377862142602918,
      "grad_norm": 0.08800715208053589,
      "learning_rate": 1.027155286053256e-05,
      "loss": 0.0014,
      "step": 9066
    },
    {
      "epoch": 0.5378455332779689,
      "grad_norm": 0.007649519946426153,
      "learning_rate": 1.0270234642762987e-05,
      "loss": 0.0002,
      "step": 9067
    },
    {
      "epoch": 0.537904852295646,
      "grad_norm": 0.006912359967827797,
      "learning_rate": 1.0268916424993409e-05,
      "loss": 0.0002,
      "step": 9068
    },
    {
      "epoch": 0.5379641713133231,
      "grad_norm": 0.03626464307308197,
      "learning_rate": 1.0267598207223835e-05,
      "loss": 0.0006,
      "step": 9069
    },
    {
      "epoch": 0.5380234903310002,
      "grad_norm": 7.2796149253845215,
      "learning_rate": 1.0266279989454259e-05,
      "loss": 0.1818,
      "step": 9070
    },
    {
      "epoch": 0.5380828093486771,
      "grad_norm": 0.13078968226909637,
      "learning_rate": 1.0264961771684683e-05,
      "loss": 0.0018,
      "step": 9071
    },
    {
      "epoch": 0.5381421283663542,
      "grad_norm": 9.594724655151367,
      "learning_rate": 1.0263643553915107e-05,
      "loss": 0.1945,
      "step": 9072
    },
    {
      "epoch": 0.5382014473840313,
      "grad_norm": 0.05198841542005539,
      "learning_rate": 1.0262325336145532e-05,
      "loss": 0.0007,
      "step": 9073
    },
    {
      "epoch": 0.5382607664017084,
      "grad_norm": 0.676289975643158,
      "learning_rate": 1.0261007118375956e-05,
      "loss": 0.0093,
      "step": 9074
    },
    {
      "epoch": 0.5383200854193855,
      "grad_norm": 3.6678578853607178,
      "learning_rate": 1.0259688900606382e-05,
      "loss": 0.1491,
      "step": 9075
    },
    {
      "epoch": 0.5383794044370626,
      "grad_norm": 19.3574275970459,
      "learning_rate": 1.0258370682836804e-05,
      "loss": 0.0955,
      "step": 9076
    },
    {
      "epoch": 0.5384387234547396,
      "grad_norm": 4.663119316101074,
      "learning_rate": 1.025705246506723e-05,
      "loss": 0.4509,
      "step": 9077
    },
    {
      "epoch": 0.5384980424724166,
      "grad_norm": 0.2639281451702118,
      "learning_rate": 1.0255734247297654e-05,
      "loss": 0.0031,
      "step": 9078
    },
    {
      "epoch": 0.5385573614900937,
      "grad_norm": 0.6721555590629578,
      "learning_rate": 1.0254416029528078e-05,
      "loss": 0.0098,
      "step": 9079
    },
    {
      "epoch": 0.5386166805077708,
      "grad_norm": 0.010022434405982494,
      "learning_rate": 1.0253097811758503e-05,
      "loss": 0.0002,
      "step": 9080
    },
    {
      "epoch": 0.5386759995254479,
      "grad_norm": 23.769521713256836,
      "learning_rate": 1.0251779593988929e-05,
      "loss": 1.6984,
      "step": 9081
    },
    {
      "epoch": 0.538735318543125,
      "grad_norm": 10.162365913391113,
      "learning_rate": 1.0250461376219351e-05,
      "loss": 0.1833,
      "step": 9082
    },
    {
      "epoch": 0.538794637560802,
      "grad_norm": 0.5346088409423828,
      "learning_rate": 1.0249143158449777e-05,
      "loss": 0.0069,
      "step": 9083
    },
    {
      "epoch": 0.538853956578479,
      "grad_norm": 0.20663847029209137,
      "learning_rate": 1.0247824940680203e-05,
      "loss": 0.0029,
      "step": 9084
    },
    {
      "epoch": 0.5389132755961561,
      "grad_norm": 1.6067681312561035,
      "learning_rate": 1.0246506722910625e-05,
      "loss": 0.0162,
      "step": 9085
    },
    {
      "epoch": 0.5389725946138332,
      "grad_norm": 33.75685501098633,
      "learning_rate": 1.0245188505141051e-05,
      "loss": 1.5028,
      "step": 9086
    },
    {
      "epoch": 0.5390319136315103,
      "grad_norm": 17.919876098632812,
      "learning_rate": 1.0243870287371475e-05,
      "loss": 0.2564,
      "step": 9087
    },
    {
      "epoch": 0.5390912326491873,
      "grad_norm": 0.3046814501285553,
      "learning_rate": 1.02425520696019e-05,
      "loss": 0.0049,
      "step": 9088
    },
    {
      "epoch": 0.5391505516668644,
      "grad_norm": 3.458970546722412,
      "learning_rate": 1.0241233851832324e-05,
      "loss": 0.2088,
      "step": 9089
    },
    {
      "epoch": 0.5392098706845415,
      "grad_norm": 0.015494792722165585,
      "learning_rate": 1.0239915634062746e-05,
      "loss": 0.0003,
      "step": 9090
    },
    {
      "epoch": 0.5392691897022185,
      "grad_norm": 13.885485649108887,
      "learning_rate": 1.0238597416293172e-05,
      "loss": 0.2365,
      "step": 9091
    },
    {
      "epoch": 0.5393285087198956,
      "grad_norm": 1.8620784282684326,
      "learning_rate": 1.0237279198523598e-05,
      "loss": 0.0093,
      "step": 9092
    },
    {
      "epoch": 0.5393878277375727,
      "grad_norm": 0.628722071647644,
      "learning_rate": 1.023596098075402e-05,
      "loss": 0.0054,
      "step": 9093
    },
    {
      "epoch": 0.5394471467552497,
      "grad_norm": 2.8870816230773926,
      "learning_rate": 1.0234642762984446e-05,
      "loss": 0.0151,
      "step": 9094
    },
    {
      "epoch": 0.5395064657729268,
      "grad_norm": 0.028245428577065468,
      "learning_rate": 1.023332454521487e-05,
      "loss": 0.0006,
      "step": 9095
    },
    {
      "epoch": 0.5395657847906039,
      "grad_norm": 11.461637496948242,
      "learning_rate": 1.0232006327445295e-05,
      "loss": 0.5124,
      "step": 9096
    },
    {
      "epoch": 0.5396251038082809,
      "grad_norm": 0.31250613927841187,
      "learning_rate": 1.0230688109675719e-05,
      "loss": 0.0033,
      "step": 9097
    },
    {
      "epoch": 0.539684422825958,
      "grad_norm": 7.366960048675537,
      "learning_rate": 1.0229369891906145e-05,
      "loss": 0.1412,
      "step": 9098
    },
    {
      "epoch": 0.539743741843635,
      "grad_norm": 1.3380131721496582,
      "learning_rate": 1.0228051674136567e-05,
      "loss": 0.0159,
      "step": 9099
    },
    {
      "epoch": 0.5398030608613121,
      "grad_norm": 0.14919734001159668,
      "learning_rate": 1.0226733456366993e-05,
      "loss": 0.0031,
      "step": 9100
    },
    {
      "epoch": 0.5398623798789892,
      "grad_norm": 0.0032003256492316723,
      "learning_rate": 1.0225415238597417e-05,
      "loss": 0.0001,
      "step": 9101
    },
    {
      "epoch": 0.5399216988966663,
      "grad_norm": 34.412296295166016,
      "learning_rate": 1.0224097020827842e-05,
      "loss": 0.2048,
      "step": 9102
    },
    {
      "epoch": 0.5399810179143434,
      "grad_norm": 7.035274028778076,
      "learning_rate": 1.0222778803058266e-05,
      "loss": 0.0704,
      "step": 9103
    },
    {
      "epoch": 0.5400403369320204,
      "grad_norm": 17.204360961914062,
      "learning_rate": 1.022146058528869e-05,
      "loss": 0.7769,
      "step": 9104
    },
    {
      "epoch": 0.5400996559496974,
      "grad_norm": 3.670984983444214,
      "learning_rate": 1.0220142367519114e-05,
      "loss": 0.0561,
      "step": 9105
    },
    {
      "epoch": 0.5401589749673745,
      "grad_norm": 2.3060638904571533,
      "learning_rate": 1.021882414974954e-05,
      "loss": 0.0131,
      "step": 9106
    },
    {
      "epoch": 0.5402182939850516,
      "grad_norm": 0.07042726129293442,
      "learning_rate": 1.0217505931979963e-05,
      "loss": 0.001,
      "step": 9107
    },
    {
      "epoch": 0.5402776130027287,
      "grad_norm": 0.046302780508995056,
      "learning_rate": 1.0216187714210388e-05,
      "loss": 0.0007,
      "step": 9108
    },
    {
      "epoch": 0.5403369320204058,
      "grad_norm": 11.093745231628418,
      "learning_rate": 1.0214869496440814e-05,
      "loss": 0.1066,
      "step": 9109
    },
    {
      "epoch": 0.5403962510380829,
      "grad_norm": 3.032134771347046,
      "learning_rate": 1.0213551278671237e-05,
      "loss": 0.0215,
      "step": 9110
    },
    {
      "epoch": 0.5404555700557598,
      "grad_norm": 0.1252565234899521,
      "learning_rate": 1.0212233060901661e-05,
      "loss": 0.0011,
      "step": 9111
    },
    {
      "epoch": 0.5405148890734369,
      "grad_norm": 11.527904510498047,
      "learning_rate": 1.0210914843132087e-05,
      "loss": 0.2431,
      "step": 9112
    },
    {
      "epoch": 0.540574208091114,
      "grad_norm": 0.2152239829301834,
      "learning_rate": 1.020959662536251e-05,
      "loss": 0.003,
      "step": 9113
    },
    {
      "epoch": 0.5406335271087911,
      "grad_norm": 0.004623289220035076,
      "learning_rate": 1.0208278407592935e-05,
      "loss": 0.0001,
      "step": 9114
    },
    {
      "epoch": 0.5406928461264682,
      "grad_norm": 2.841010808944702,
      "learning_rate": 1.0206960189823361e-05,
      "loss": 0.0223,
      "step": 9115
    },
    {
      "epoch": 0.5407521651441453,
      "grad_norm": 0.30173054337501526,
      "learning_rate": 1.0205641972053784e-05,
      "loss": 0.0019,
      "step": 9116
    },
    {
      "epoch": 0.5408114841618222,
      "grad_norm": 11.625974655151367,
      "learning_rate": 1.020432375428421e-05,
      "loss": 0.3125,
      "step": 9117
    },
    {
      "epoch": 0.5408708031794993,
      "grad_norm": 16.865249633789062,
      "learning_rate": 1.0203005536514634e-05,
      "loss": 0.4663,
      "step": 9118
    },
    {
      "epoch": 0.5409301221971764,
      "grad_norm": 0.19725489616394043,
      "learning_rate": 1.0201687318745058e-05,
      "loss": 0.0031,
      "step": 9119
    },
    {
      "epoch": 0.5409894412148535,
      "grad_norm": 0.2990201711654663,
      "learning_rate": 1.0200369100975482e-05,
      "loss": 0.0033,
      "step": 9120
    },
    {
      "epoch": 0.5410487602325306,
      "grad_norm": 0.05714353546500206,
      "learning_rate": 1.0199050883205906e-05,
      "loss": 0.0006,
      "step": 9121
    },
    {
      "epoch": 0.5411080792502077,
      "grad_norm": 4.5489182472229,
      "learning_rate": 1.019773266543633e-05,
      "loss": 0.0917,
      "step": 9122
    },
    {
      "epoch": 0.5411673982678847,
      "grad_norm": 0.007569844834506512,
      "learning_rate": 1.0196414447666756e-05,
      "loss": 0.0003,
      "step": 9123
    },
    {
      "epoch": 0.5412267172855617,
      "grad_norm": 21.94351577758789,
      "learning_rate": 1.0195096229897179e-05,
      "loss": 0.492,
      "step": 9124
    },
    {
      "epoch": 0.5412860363032388,
      "grad_norm": 8.633746147155762,
      "learning_rate": 1.0193778012127605e-05,
      "loss": 0.3656,
      "step": 9125
    },
    {
      "epoch": 0.5413453553209159,
      "grad_norm": 0.17159101366996765,
      "learning_rate": 1.0192459794358029e-05,
      "loss": 0.0019,
      "step": 9126
    },
    {
      "epoch": 0.541404674338593,
      "grad_norm": 0.2407502681016922,
      "learning_rate": 1.0191141576588453e-05,
      "loss": 0.0036,
      "step": 9127
    },
    {
      "epoch": 0.54146399335627,
      "grad_norm": 7.313138008117676,
      "learning_rate": 1.0189823358818877e-05,
      "loss": 0.1083,
      "step": 9128
    },
    {
      "epoch": 0.5415233123739471,
      "grad_norm": 0.845632016658783,
      "learning_rate": 1.0188505141049303e-05,
      "loss": 0.0106,
      "step": 9129
    },
    {
      "epoch": 0.5415826313916241,
      "grad_norm": 0.045651473104953766,
      "learning_rate": 1.0187186923279726e-05,
      "loss": 0.0008,
      "step": 9130
    },
    {
      "epoch": 0.5416419504093012,
      "grad_norm": 0.012218916788697243,
      "learning_rate": 1.0185868705510151e-05,
      "loss": 0.0004,
      "step": 9131
    },
    {
      "epoch": 0.5417012694269783,
      "grad_norm": 0.03752753511071205,
      "learning_rate": 1.0184550487740577e-05,
      "loss": 0.0005,
      "step": 9132
    },
    {
      "epoch": 0.5417605884446554,
      "grad_norm": 0.2055390626192093,
      "learning_rate": 1.0183232269971e-05,
      "loss": 0.0032,
      "step": 9133
    },
    {
      "epoch": 0.5418199074623324,
      "grad_norm": 6.346316337585449,
      "learning_rate": 1.0181914052201424e-05,
      "loss": 0.0372,
      "step": 9134
    },
    {
      "epoch": 0.5418792264800095,
      "grad_norm": 1.9657161235809326,
      "learning_rate": 1.018059583443185e-05,
      "loss": 0.0499,
      "step": 9135
    },
    {
      "epoch": 0.5419385454976866,
      "grad_norm": 0.25215238332748413,
      "learning_rate": 1.0179277616662272e-05,
      "loss": 0.0035,
      "step": 9136
    },
    {
      "epoch": 0.5419978645153636,
      "grad_norm": 5.42344856262207,
      "learning_rate": 1.0177959398892698e-05,
      "loss": 0.1403,
      "step": 9137
    },
    {
      "epoch": 0.5420571835330407,
      "grad_norm": 26.6431941986084,
      "learning_rate": 1.017664118112312e-05,
      "loss": 0.447,
      "step": 9138
    },
    {
      "epoch": 0.5421165025507177,
      "grad_norm": 0.08652552217245102,
      "learning_rate": 1.0175322963353547e-05,
      "loss": 0.0005,
      "step": 9139
    },
    {
      "epoch": 0.5421758215683948,
      "grad_norm": 6.8361334800720215,
      "learning_rate": 1.0174004745583973e-05,
      "loss": 0.0801,
      "step": 9140
    },
    {
      "epoch": 0.5422351405860719,
      "grad_norm": 14.577160835266113,
      "learning_rate": 1.0172686527814395e-05,
      "loss": 0.9555,
      "step": 9141
    },
    {
      "epoch": 0.542294459603749,
      "grad_norm": 5.934706211090088,
      "learning_rate": 1.0171368310044821e-05,
      "loss": 0.2114,
      "step": 9142
    },
    {
      "epoch": 0.542353778621426,
      "grad_norm": 3.915283203125,
      "learning_rate": 1.0170050092275245e-05,
      "loss": 0.0952,
      "step": 9143
    },
    {
      "epoch": 0.5424130976391031,
      "grad_norm": 10.158119201660156,
      "learning_rate": 1.016873187450567e-05,
      "loss": 0.1984,
      "step": 9144
    },
    {
      "epoch": 0.5424724166567801,
      "grad_norm": 21.716257095336914,
      "learning_rate": 1.0167413656736093e-05,
      "loss": 0.1451,
      "step": 9145
    },
    {
      "epoch": 0.5425317356744572,
      "grad_norm": 1.4959923028945923,
      "learning_rate": 1.016609543896652e-05,
      "loss": 0.0177,
      "step": 9146
    },
    {
      "epoch": 0.5425910546921343,
      "grad_norm": 0.0992729514837265,
      "learning_rate": 1.0164777221196942e-05,
      "loss": 0.0018,
      "step": 9147
    },
    {
      "epoch": 0.5426503737098114,
      "grad_norm": 0.040978554636240005,
      "learning_rate": 1.0163459003427368e-05,
      "loss": 0.0007,
      "step": 9148
    },
    {
      "epoch": 0.5427096927274885,
      "grad_norm": 0.292226642370224,
      "learning_rate": 1.0162140785657792e-05,
      "loss": 0.003,
      "step": 9149
    },
    {
      "epoch": 0.5427690117451655,
      "grad_norm": 0.009442336857318878,
      "learning_rate": 1.0160822567888216e-05,
      "loss": 0.0002,
      "step": 9150
    },
    {
      "epoch": 0.5428283307628425,
      "grad_norm": 0.005744130816310644,
      "learning_rate": 1.015950435011864e-05,
      "loss": 0.0002,
      "step": 9151
    },
    {
      "epoch": 0.5428876497805196,
      "grad_norm": 0.009948545135557652,
      "learning_rate": 1.0158186132349064e-05,
      "loss": 0.0002,
      "step": 9152
    },
    {
      "epoch": 0.5429469687981967,
      "grad_norm": 7.650521755218506,
      "learning_rate": 1.0156867914579489e-05,
      "loss": 0.0609,
      "step": 9153
    },
    {
      "epoch": 0.5430062878158738,
      "grad_norm": 61.49155044555664,
      "learning_rate": 1.0155549696809915e-05,
      "loss": 0.129,
      "step": 9154
    },
    {
      "epoch": 0.5430656068335509,
      "grad_norm": 0.014098870567977428,
      "learning_rate": 1.0154231479040337e-05,
      "loss": 0.0004,
      "step": 9155
    },
    {
      "epoch": 0.543124925851228,
      "grad_norm": 0.35098060965538025,
      "learning_rate": 1.0152913261270763e-05,
      "loss": 0.0027,
      "step": 9156
    },
    {
      "epoch": 0.5431842448689049,
      "grad_norm": 0.18699324131011963,
      "learning_rate": 1.0151595043501187e-05,
      "loss": 0.0025,
      "step": 9157
    },
    {
      "epoch": 0.543243563886582,
      "grad_norm": 2.427259683609009,
      "learning_rate": 1.0150276825731611e-05,
      "loss": 0.0144,
      "step": 9158
    },
    {
      "epoch": 0.5433028829042591,
      "grad_norm": 12.254646301269531,
      "learning_rate": 1.0148958607962035e-05,
      "loss": 0.1258,
      "step": 9159
    },
    {
      "epoch": 0.5433622019219362,
      "grad_norm": 1.1986132860183716,
      "learning_rate": 1.0147640390192461e-05,
      "loss": 0.0108,
      "step": 9160
    },
    {
      "epoch": 0.5434215209396133,
      "grad_norm": 3.4119014739990234,
      "learning_rate": 1.0146322172422884e-05,
      "loss": 0.0979,
      "step": 9161
    },
    {
      "epoch": 0.5434808399572904,
      "grad_norm": 1.2118057012557983,
      "learning_rate": 1.014500395465331e-05,
      "loss": 0.02,
      "step": 9162
    },
    {
      "epoch": 0.5435401589749673,
      "grad_norm": 21.21995735168457,
      "learning_rate": 1.0143685736883736e-05,
      "loss": 0.6936,
      "step": 9163
    },
    {
      "epoch": 0.5435994779926444,
      "grad_norm": 4.881699562072754,
      "learning_rate": 1.0142367519114158e-05,
      "loss": 0.035,
      "step": 9164
    },
    {
      "epoch": 0.5436587970103215,
      "grad_norm": 0.039888910949230194,
      "learning_rate": 1.0141049301344584e-05,
      "loss": 0.0011,
      "step": 9165
    },
    {
      "epoch": 0.5437181160279986,
      "grad_norm": 0.10790598392486572,
      "learning_rate": 1.0139731083575008e-05,
      "loss": 0.0013,
      "step": 9166
    },
    {
      "epoch": 0.5437774350456757,
      "grad_norm": 24.8446044921875,
      "learning_rate": 1.013841286580543e-05,
      "loss": 0.3532,
      "step": 9167
    },
    {
      "epoch": 0.5438367540633527,
      "grad_norm": 0.008731270208954811,
      "learning_rate": 1.0137094648035857e-05,
      "loss": 0.0004,
      "step": 9168
    },
    {
      "epoch": 0.5438960730810298,
      "grad_norm": 6.889904022216797,
      "learning_rate": 1.0135776430266279e-05,
      "loss": 0.1552,
      "step": 9169
    },
    {
      "epoch": 0.5439553920987068,
      "grad_norm": 1.6106895208358765,
      "learning_rate": 1.0134458212496705e-05,
      "loss": 0.013,
      "step": 9170
    },
    {
      "epoch": 0.5440147111163839,
      "grad_norm": 5.784997940063477,
      "learning_rate": 1.013313999472713e-05,
      "loss": 0.0412,
      "step": 9171
    },
    {
      "epoch": 0.544074030134061,
      "grad_norm": 4.3368330001831055,
      "learning_rate": 1.0131821776957553e-05,
      "loss": 0.126,
      "step": 9172
    },
    {
      "epoch": 0.544133349151738,
      "grad_norm": 0.4898875653743744,
      "learning_rate": 1.013050355918798e-05,
      "loss": 0.0074,
      "step": 9173
    },
    {
      "epoch": 0.5441926681694151,
      "grad_norm": 0.06887015700340271,
      "learning_rate": 1.0129185341418403e-05,
      "loss": 0.0016,
      "step": 9174
    },
    {
      "epoch": 0.5442519871870922,
      "grad_norm": 1.5198079347610474,
      "learning_rate": 1.0127867123648828e-05,
      "loss": 0.0136,
      "step": 9175
    },
    {
      "epoch": 0.5443113062047692,
      "grad_norm": 8.145441055297852,
      "learning_rate": 1.0126548905879252e-05,
      "loss": 0.2045,
      "step": 9176
    },
    {
      "epoch": 0.5443706252224463,
      "grad_norm": 0.009778921492397785,
      "learning_rate": 1.0125230688109678e-05,
      "loss": 0.0003,
      "step": 9177
    },
    {
      "epoch": 0.5444299442401234,
      "grad_norm": 1.247717022895813,
      "learning_rate": 1.01239124703401e-05,
      "loss": 0.0131,
      "step": 9178
    },
    {
      "epoch": 0.5444892632578004,
      "grad_norm": 11.047205924987793,
      "learning_rate": 1.0122594252570526e-05,
      "loss": 0.2872,
      "step": 9179
    },
    {
      "epoch": 0.5445485822754775,
      "grad_norm": 17.2843074798584,
      "learning_rate": 1.012127603480095e-05,
      "loss": 1.2211,
      "step": 9180
    },
    {
      "epoch": 0.5446079012931546,
      "grad_norm": 14.81617259979248,
      "learning_rate": 1.0119957817031374e-05,
      "loss": 0.8362,
      "step": 9181
    },
    {
      "epoch": 0.5446672203108317,
      "grad_norm": 0.6769915819168091,
      "learning_rate": 1.0118639599261799e-05,
      "loss": 0.0046,
      "step": 9182
    },
    {
      "epoch": 0.5447265393285087,
      "grad_norm": 0.313688725233078,
      "learning_rate": 1.0117321381492224e-05,
      "loss": 0.0035,
      "step": 9183
    },
    {
      "epoch": 0.5447858583461858,
      "grad_norm": 18.385522842407227,
      "learning_rate": 1.0116003163722647e-05,
      "loss": 0.4146,
      "step": 9184
    },
    {
      "epoch": 0.5448451773638628,
      "grad_norm": 9.895641326904297,
      "learning_rate": 1.0114684945953073e-05,
      "loss": 0.3771,
      "step": 9185
    },
    {
      "epoch": 0.5449044963815399,
      "grad_norm": 1.059333324432373,
      "learning_rate": 1.0113366728183495e-05,
      "loss": 0.0105,
      "step": 9186
    },
    {
      "epoch": 0.544963815399217,
      "grad_norm": 0.07468803972005844,
      "learning_rate": 1.0112048510413921e-05,
      "loss": 0.0009,
      "step": 9187
    },
    {
      "epoch": 0.5450231344168941,
      "grad_norm": 0.5177656412124634,
      "learning_rate": 1.0110730292644347e-05,
      "loss": 0.0086,
      "step": 9188
    },
    {
      "epoch": 0.5450824534345711,
      "grad_norm": 0.4313316345214844,
      "learning_rate": 1.010941207487477e-05,
      "loss": 0.0055,
      "step": 9189
    },
    {
      "epoch": 0.5451417724522482,
      "grad_norm": 2.285991907119751,
      "learning_rate": 1.0108093857105194e-05,
      "loss": 0.016,
      "step": 9190
    },
    {
      "epoch": 0.5452010914699252,
      "grad_norm": 9.539112091064453,
      "learning_rate": 1.010677563933562e-05,
      "loss": 0.5172,
      "step": 9191
    },
    {
      "epoch": 0.5452604104876023,
      "grad_norm": 0.013923159800469875,
      "learning_rate": 1.0105457421566042e-05,
      "loss": 0.0003,
      "step": 9192
    },
    {
      "epoch": 0.5453197295052794,
      "grad_norm": 0.054724354296922684,
      "learning_rate": 1.0104139203796468e-05,
      "loss": 0.0008,
      "step": 9193
    },
    {
      "epoch": 0.5453790485229565,
      "grad_norm": 2.278247117996216,
      "learning_rate": 1.0102820986026894e-05,
      "loss": 0.0259,
      "step": 9194
    },
    {
      "epoch": 0.5454383675406336,
      "grad_norm": 0.03216984122991562,
      "learning_rate": 1.0101502768257316e-05,
      "loss": 0.0008,
      "step": 9195
    },
    {
      "epoch": 0.5454976865583105,
      "grad_norm": 12.156099319458008,
      "learning_rate": 1.0100184550487742e-05,
      "loss": 0.0714,
      "step": 9196
    },
    {
      "epoch": 0.5455570055759876,
      "grad_norm": 0.23518116772174835,
      "learning_rate": 1.0098866332718166e-05,
      "loss": 0.0034,
      "step": 9197
    },
    {
      "epoch": 0.5456163245936647,
      "grad_norm": 0.18263545632362366,
      "learning_rate": 1.009754811494859e-05,
      "loss": 0.0026,
      "step": 9198
    },
    {
      "epoch": 0.5456756436113418,
      "grad_norm": 0.11428140848875046,
      "learning_rate": 1.0096229897179015e-05,
      "loss": 0.0019,
      "step": 9199
    },
    {
      "epoch": 0.5457349626290189,
      "grad_norm": 0.004878278821706772,
      "learning_rate": 1.0094911679409437e-05,
      "loss": 0.0002,
      "step": 9200
    },
    {
      "epoch": 0.545794281646696,
      "grad_norm": 0.009376832284033298,
      "learning_rate": 1.0093593461639863e-05,
      "loss": 0.0004,
      "step": 9201
    },
    {
      "epoch": 0.545853600664373,
      "grad_norm": 0.8564284443855286,
      "learning_rate": 1.0092275243870289e-05,
      "loss": 0.006,
      "step": 9202
    },
    {
      "epoch": 0.54591291968205,
      "grad_norm": 7.5482683181762695,
      "learning_rate": 1.0090957026100712e-05,
      "loss": 0.1003,
      "step": 9203
    },
    {
      "epoch": 0.5459722386997271,
      "grad_norm": 0.04107268154621124,
      "learning_rate": 1.0089638808331137e-05,
      "loss": 0.0006,
      "step": 9204
    },
    {
      "epoch": 0.5460315577174042,
      "grad_norm": 0.016452675685286522,
      "learning_rate": 1.0088320590561562e-05,
      "loss": 0.0004,
      "step": 9205
    },
    {
      "epoch": 0.5460908767350813,
      "grad_norm": 4.039618968963623,
      "learning_rate": 1.0087002372791986e-05,
      "loss": 0.0101,
      "step": 9206
    },
    {
      "epoch": 0.5461501957527584,
      "grad_norm": 10.047643661499023,
      "learning_rate": 1.008568415502241e-05,
      "loss": 0.106,
      "step": 9207
    },
    {
      "epoch": 0.5462095147704354,
      "grad_norm": 0.016976119950413704,
      "learning_rate": 1.0084365937252836e-05,
      "loss": 0.0003,
      "step": 9208
    },
    {
      "epoch": 0.5462688337881124,
      "grad_norm": 2.1376209259033203,
      "learning_rate": 1.0083047719483258e-05,
      "loss": 0.0257,
      "step": 9209
    },
    {
      "epoch": 0.5463281528057895,
      "grad_norm": 0.4210982620716095,
      "learning_rate": 1.0081729501713684e-05,
      "loss": 0.0021,
      "step": 9210
    },
    {
      "epoch": 0.5463874718234666,
      "grad_norm": 0.5891010165214539,
      "learning_rate": 1.0080411283944108e-05,
      "loss": 0.0053,
      "step": 9211
    },
    {
      "epoch": 0.5464467908411437,
      "grad_norm": 21.353458404541016,
      "learning_rate": 1.0079093066174533e-05,
      "loss": 0.5065,
      "step": 9212
    },
    {
      "epoch": 0.5465061098588208,
      "grad_norm": 0.022860491648316383,
      "learning_rate": 1.0077774848404957e-05,
      "loss": 0.0006,
      "step": 9213
    },
    {
      "epoch": 0.5465654288764978,
      "grad_norm": 7.751796245574951,
      "learning_rate": 1.0076456630635383e-05,
      "loss": 0.3029,
      "step": 9214
    },
    {
      "epoch": 0.5466247478941749,
      "grad_norm": 0.002370328875258565,
      "learning_rate": 1.0075138412865805e-05,
      "loss": 0.0001,
      "step": 9215
    },
    {
      "epoch": 0.5466840669118519,
      "grad_norm": 8.08794116973877,
      "learning_rate": 1.0073820195096231e-05,
      "loss": 0.1011,
      "step": 9216
    },
    {
      "epoch": 0.546743385929529,
      "grad_norm": 3.630570888519287,
      "learning_rate": 1.0072501977326654e-05,
      "loss": 0.0231,
      "step": 9217
    },
    {
      "epoch": 0.5468027049472061,
      "grad_norm": 15.135659217834473,
      "learning_rate": 1.007118375955708e-05,
      "loss": 0.1574,
      "step": 9218
    },
    {
      "epoch": 0.5468620239648831,
      "grad_norm": 0.0709138810634613,
      "learning_rate": 1.0069865541787505e-05,
      "loss": 0.0013,
      "step": 9219
    },
    {
      "epoch": 0.5469213429825602,
      "grad_norm": 0.7437117695808411,
      "learning_rate": 1.0068547324017928e-05,
      "loss": 0.0075,
      "step": 9220
    },
    {
      "epoch": 0.5469806620002373,
      "grad_norm": 0.04630068317055702,
      "learning_rate": 1.0067229106248354e-05,
      "loss": 0.0007,
      "step": 9221
    },
    {
      "epoch": 0.5470399810179143,
      "grad_norm": 1.4509506225585938,
      "learning_rate": 1.0065910888478778e-05,
      "loss": 0.0163,
      "step": 9222
    },
    {
      "epoch": 0.5470993000355914,
      "grad_norm": 0.22905637323856354,
      "learning_rate": 1.00645926707092e-05,
      "loss": 0.0015,
      "step": 9223
    },
    {
      "epoch": 0.5471586190532685,
      "grad_norm": 0.01453864574432373,
      "learning_rate": 1.0063274452939626e-05,
      "loss": 0.0004,
      "step": 9224
    },
    {
      "epoch": 0.5472179380709455,
      "grad_norm": 0.5934414267539978,
      "learning_rate": 1.0061956235170052e-05,
      "loss": 0.0092,
      "step": 9225
    },
    {
      "epoch": 0.5472772570886226,
      "grad_norm": 14.697760581970215,
      "learning_rate": 1.0060638017400475e-05,
      "loss": 0.8518,
      "step": 9226
    },
    {
      "epoch": 0.5473365761062997,
      "grad_norm": 0.10593979805707932,
      "learning_rate": 1.00593197996309e-05,
      "loss": 0.002,
      "step": 9227
    },
    {
      "epoch": 0.5473958951239768,
      "grad_norm": 4.1962151527404785,
      "learning_rate": 1.0058001581861325e-05,
      "loss": 0.0379,
      "step": 9228
    },
    {
      "epoch": 0.5474552141416538,
      "grad_norm": 0.026280635967850685,
      "learning_rate": 1.0056683364091749e-05,
      "loss": 0.0007,
      "step": 9229
    },
    {
      "epoch": 0.5475145331593309,
      "grad_norm": 15.234556198120117,
      "learning_rate": 1.0055365146322173e-05,
      "loss": 0.1057,
      "step": 9230
    },
    {
      "epoch": 0.5475738521770079,
      "grad_norm": 0.022492675110697746,
      "learning_rate": 1.0054046928552599e-05,
      "loss": 0.0005,
      "step": 9231
    },
    {
      "epoch": 0.547633171194685,
      "grad_norm": 28.04061508178711,
      "learning_rate": 1.0052728710783021e-05,
      "loss": 0.4082,
      "step": 9232
    },
    {
      "epoch": 0.5476924902123621,
      "grad_norm": 6.1245903968811035,
      "learning_rate": 1.0051410493013447e-05,
      "loss": 0.5663,
      "step": 9233
    },
    {
      "epoch": 0.5477518092300392,
      "grad_norm": 0.43772992491722107,
      "learning_rate": 1.005009227524387e-05,
      "loss": 0.003,
      "step": 9234
    },
    {
      "epoch": 0.5478111282477163,
      "grad_norm": 0.0017098976531997323,
      "learning_rate": 1.0048774057474296e-05,
      "loss": 0.0001,
      "step": 9235
    },
    {
      "epoch": 0.5478704472653932,
      "grad_norm": 0.023397205397486687,
      "learning_rate": 1.004745583970472e-05,
      "loss": 0.0007,
      "step": 9236
    },
    {
      "epoch": 0.5479297662830703,
      "grad_norm": 4.264458656311035,
      "learning_rate": 1.0046137621935144e-05,
      "loss": 0.1944,
      "step": 9237
    },
    {
      "epoch": 0.5479890853007474,
      "grad_norm": 6.044768333435059,
      "learning_rate": 1.0044819404165568e-05,
      "loss": 0.08,
      "step": 9238
    },
    {
      "epoch": 0.5480484043184245,
      "grad_norm": 0.008194854483008385,
      "learning_rate": 1.0043501186395994e-05,
      "loss": 0.0003,
      "step": 9239
    },
    {
      "epoch": 0.5481077233361016,
      "grad_norm": 0.04609033465385437,
      "learning_rate": 1.0042182968626417e-05,
      "loss": 0.0012,
      "step": 9240
    },
    {
      "epoch": 0.5481670423537787,
      "grad_norm": 2.224994421005249,
      "learning_rate": 1.0040864750856843e-05,
      "loss": 0.0387,
      "step": 9241
    },
    {
      "epoch": 0.5482263613714556,
      "grad_norm": 13.744261741638184,
      "learning_rate": 1.0039546533087268e-05,
      "loss": 0.28,
      "step": 9242
    },
    {
      "epoch": 0.5482856803891327,
      "grad_norm": 1.0465905666351318,
      "learning_rate": 1.0038228315317691e-05,
      "loss": 0.0058,
      "step": 9243
    },
    {
      "epoch": 0.5483449994068098,
      "grad_norm": 7.2473249435424805,
      "learning_rate": 1.0036910097548117e-05,
      "loss": 0.0886,
      "step": 9244
    },
    {
      "epoch": 0.5484043184244869,
      "grad_norm": 8.910168647766113,
      "learning_rate": 1.0035591879778541e-05,
      "loss": 0.2094,
      "step": 9245
    },
    {
      "epoch": 0.548463637442164,
      "grad_norm": 0.15343819558620453,
      "learning_rate": 1.0034273662008963e-05,
      "loss": 0.0025,
      "step": 9246
    },
    {
      "epoch": 0.5485229564598411,
      "grad_norm": 1.6768462657928467,
      "learning_rate": 1.003295544423939e-05,
      "loss": 0.021,
      "step": 9247
    },
    {
      "epoch": 0.5485822754775181,
      "grad_norm": 0.32811716198921204,
      "learning_rate": 1.0031637226469812e-05,
      "loss": 0.0018,
      "step": 9248
    },
    {
      "epoch": 0.5486415944951951,
      "grad_norm": 13.165395736694336,
      "learning_rate": 1.0030319008700238e-05,
      "loss": 0.6977,
      "step": 9249
    },
    {
      "epoch": 0.5487009135128722,
      "grad_norm": 19.787551879882812,
      "learning_rate": 1.0029000790930664e-05,
      "loss": 2.2378,
      "step": 9250
    },
    {
      "epoch": 0.5487602325305493,
      "grad_norm": 7.735302448272705,
      "learning_rate": 1.0027682573161086e-05,
      "loss": 0.1356,
      "step": 9251
    },
    {
      "epoch": 0.5488195515482264,
      "grad_norm": 30.915882110595703,
      "learning_rate": 1.0026364355391512e-05,
      "loss": 0.1966,
      "step": 9252
    },
    {
      "epoch": 0.5488788705659035,
      "grad_norm": 0.06202627718448639,
      "learning_rate": 1.0025046137621936e-05,
      "loss": 0.0007,
      "step": 9253
    },
    {
      "epoch": 0.5489381895835805,
      "grad_norm": 16.77729034423828,
      "learning_rate": 1.002372791985236e-05,
      "loss": 0.3726,
      "step": 9254
    },
    {
      "epoch": 0.5489975086012575,
      "grad_norm": 0.6139621734619141,
      "learning_rate": 1.0022409702082785e-05,
      "loss": 0.0069,
      "step": 9255
    },
    {
      "epoch": 0.5490568276189346,
      "grad_norm": 1.8145427703857422,
      "learning_rate": 1.002109148431321e-05,
      "loss": 0.015,
      "step": 9256
    },
    {
      "epoch": 0.5491161466366117,
      "grad_norm": 0.5211234092712402,
      "learning_rate": 1.0019773266543633e-05,
      "loss": 0.0049,
      "step": 9257
    },
    {
      "epoch": 0.5491754656542888,
      "grad_norm": 5.062577724456787,
      "learning_rate": 1.0018455048774059e-05,
      "loss": 0.1884,
      "step": 9258
    },
    {
      "epoch": 0.5492347846719658,
      "grad_norm": 0.06417183578014374,
      "learning_rate": 1.0017136831004483e-05,
      "loss": 0.001,
      "step": 9259
    },
    {
      "epoch": 0.5492941036896429,
      "grad_norm": 5.66124153137207,
      "learning_rate": 1.0015818613234907e-05,
      "loss": 0.1045,
      "step": 9260
    },
    {
      "epoch": 0.54935342270732,
      "grad_norm": 13.590737342834473,
      "learning_rate": 1.0014500395465331e-05,
      "loss": 0.1165,
      "step": 9261
    },
    {
      "epoch": 0.549412741724997,
      "grad_norm": 0.4989483058452606,
      "learning_rate": 1.0013182177695757e-05,
      "loss": 0.0048,
      "step": 9262
    },
    {
      "epoch": 0.5494720607426741,
      "grad_norm": 45.80944061279297,
      "learning_rate": 1.001186395992618e-05,
      "loss": 1.2389,
      "step": 9263
    },
    {
      "epoch": 0.5495313797603512,
      "grad_norm": 1.9361655712127686,
      "learning_rate": 1.0010545742156606e-05,
      "loss": 0.0112,
      "step": 9264
    },
    {
      "epoch": 0.5495906987780282,
      "grad_norm": 1.6180286407470703,
      "learning_rate": 1.0009227524387028e-05,
      "loss": 0.0215,
      "step": 9265
    },
    {
      "epoch": 0.5496500177957053,
      "grad_norm": 1.0653891563415527,
      "learning_rate": 1.0007909306617454e-05,
      "loss": 0.0073,
      "step": 9266
    },
    {
      "epoch": 0.5497093368133824,
      "grad_norm": 9.533875465393066,
      "learning_rate": 1.0006591088847878e-05,
      "loss": 0.126,
      "step": 9267
    },
    {
      "epoch": 0.5497686558310594,
      "grad_norm": 0.024785099551081657,
      "learning_rate": 1.0005272871078302e-05,
      "loss": 0.0002,
      "step": 9268
    },
    {
      "epoch": 0.5498279748487365,
      "grad_norm": 0.01868908852338791,
      "learning_rate": 1.0003954653308727e-05,
      "loss": 0.0004,
      "step": 9269
    },
    {
      "epoch": 0.5498872938664136,
      "grad_norm": 0.061538949608802795,
      "learning_rate": 1.0002636435539152e-05,
      "loss": 0.0005,
      "step": 9270
    },
    {
      "epoch": 0.5499466128840906,
      "grad_norm": 9.375049591064453,
      "learning_rate": 1.0001318217769575e-05,
      "loss": 0.1643,
      "step": 9271
    },
    {
      "epoch": 0.5500059319017677,
      "grad_norm": 1.2556906938552856,
      "learning_rate": 1e-05,
      "loss": 0.009,
      "step": 9272
    },
    {
      "epoch": 0.5500652509194448,
      "grad_norm": 0.03651919215917587,
      "learning_rate": 9.998681782230425e-06,
      "loss": 0.0006,
      "step": 9273
    },
    {
      "epoch": 0.5501245699371219,
      "grad_norm": 0.02422236278653145,
      "learning_rate": 9.997363564460851e-06,
      "loss": 0.0004,
      "step": 9274
    },
    {
      "epoch": 0.5501838889547989,
      "grad_norm": 0.793639063835144,
      "learning_rate": 9.996045346691275e-06,
      "loss": 0.0035,
      "step": 9275
    },
    {
      "epoch": 0.550243207972476,
      "grad_norm": 6.609981060028076,
      "learning_rate": 9.9947271289217e-06,
      "loss": 0.6878,
      "step": 9276
    },
    {
      "epoch": 0.550302526990153,
      "grad_norm": 0.5350382924079895,
      "learning_rate": 9.993408911152123e-06,
      "loss": 0.0079,
      "step": 9277
    },
    {
      "epoch": 0.5503618460078301,
      "grad_norm": 0.1319969892501831,
      "learning_rate": 9.992090693382548e-06,
      "loss": 0.0022,
      "step": 9278
    },
    {
      "epoch": 0.5504211650255072,
      "grad_norm": 4.321513652801514,
      "learning_rate": 9.990772475612972e-06,
      "loss": 0.0261,
      "step": 9279
    },
    {
      "epoch": 0.5504804840431843,
      "grad_norm": 0.05725543200969696,
      "learning_rate": 9.989454257843396e-06,
      "loss": 0.0011,
      "step": 9280
    },
    {
      "epoch": 0.5505398030608614,
      "grad_norm": 4.314244270324707,
      "learning_rate": 9.988136040073822e-06,
      "loss": 0.5358,
      "step": 9281
    },
    {
      "epoch": 0.5505991220785383,
      "grad_norm": 0.28291162848472595,
      "learning_rate": 9.986817822304246e-06,
      "loss": 0.0033,
      "step": 9282
    },
    {
      "epoch": 0.5506584410962154,
      "grad_norm": 0.1555953472852707,
      "learning_rate": 9.98549960453467e-06,
      "loss": 0.0036,
      "step": 9283
    },
    {
      "epoch": 0.5507177601138925,
      "grad_norm": 0.012191630899906158,
      "learning_rate": 9.984181386765094e-06,
      "loss": 0.0003,
      "step": 9284
    },
    {
      "epoch": 0.5507770791315696,
      "grad_norm": 2.0153000354766846,
      "learning_rate": 9.982863168995519e-06,
      "loss": 0.2229,
      "step": 9285
    },
    {
      "epoch": 0.5508363981492467,
      "grad_norm": 0.08716502785682678,
      "learning_rate": 9.981544951225943e-06,
      "loss": 0.0013,
      "step": 9286
    },
    {
      "epoch": 0.5508957171669238,
      "grad_norm": 4.7038397789001465,
      "learning_rate": 9.980226733456367e-06,
      "loss": 0.1349,
      "step": 9287
    },
    {
      "epoch": 0.5509550361846007,
      "grad_norm": 1.974853754043579,
      "learning_rate": 9.978908515686793e-06,
      "loss": 0.0278,
      "step": 9288
    },
    {
      "epoch": 0.5510143552022778,
      "grad_norm": 18.11890983581543,
      "learning_rate": 9.977590297917217e-06,
      "loss": 0.1473,
      "step": 9289
    },
    {
      "epoch": 0.5510736742199549,
      "grad_norm": 13.816455841064453,
      "learning_rate": 9.976272080147641e-06,
      "loss": 0.4321,
      "step": 9290
    },
    {
      "epoch": 0.551132993237632,
      "grad_norm": 2.033803939819336,
      "learning_rate": 9.974953862378065e-06,
      "loss": 0.0126,
      "step": 9291
    },
    {
      "epoch": 0.5511923122553091,
      "grad_norm": 2.3236100673675537,
      "learning_rate": 9.97363564460849e-06,
      "loss": 0.0186,
      "step": 9292
    },
    {
      "epoch": 0.5512516312729862,
      "grad_norm": 3.0429043769836426,
      "learning_rate": 9.972317426838914e-06,
      "loss": 0.0255,
      "step": 9293
    },
    {
      "epoch": 0.5513109502906632,
      "grad_norm": 1.3720608949661255,
      "learning_rate": 9.970999209069338e-06,
      "loss": 0.0123,
      "step": 9294
    },
    {
      "epoch": 0.5513702693083402,
      "grad_norm": 6.519920349121094,
      "learning_rate": 9.969680991299764e-06,
      "loss": 0.4254,
      "step": 9295
    },
    {
      "epoch": 0.5514295883260173,
      "grad_norm": 15.684385299682617,
      "learning_rate": 9.968362773530188e-06,
      "loss": 0.1664,
      "step": 9296
    },
    {
      "epoch": 0.5514889073436944,
      "grad_norm": 2.1435117721557617,
      "learning_rate": 9.967044555760612e-06,
      "loss": 0.0364,
      "step": 9297
    },
    {
      "epoch": 0.5515482263613715,
      "grad_norm": 0.056677356362342834,
      "learning_rate": 9.965726337991038e-06,
      "loss": 0.0008,
      "step": 9298
    },
    {
      "epoch": 0.5516075453790485,
      "grad_norm": 26.149980545043945,
      "learning_rate": 9.964408120221462e-06,
      "loss": 0.6321,
      "step": 9299
    },
    {
      "epoch": 0.5516668643967256,
      "grad_norm": 2.374140739440918,
      "learning_rate": 9.963089902451885e-06,
      "loss": 0.0135,
      "step": 9300
    },
    {
      "epoch": 0.5517261834144026,
      "grad_norm": 0.2627977430820465,
      "learning_rate": 9.961771684682309e-06,
      "loss": 0.0029,
      "step": 9301
    },
    {
      "epoch": 0.5517855024320797,
      "grad_norm": 0.03725796192884445,
      "learning_rate": 9.960453466912735e-06,
      "loss": 0.001,
      "step": 9302
    },
    {
      "epoch": 0.5518448214497568,
      "grad_norm": 42.60652160644531,
      "learning_rate": 9.959135249143159e-06,
      "loss": 0.6246,
      "step": 9303
    },
    {
      "epoch": 0.5519041404674339,
      "grad_norm": 5.6914167404174805,
      "learning_rate": 9.957817031373583e-06,
      "loss": 0.0185,
      "step": 9304
    },
    {
      "epoch": 0.5519634594851109,
      "grad_norm": 0.17241813242435455,
      "learning_rate": 9.95649881360401e-06,
      "loss": 0.0016,
      "step": 9305
    },
    {
      "epoch": 0.552022778502788,
      "grad_norm": 0.0794658213853836,
      "learning_rate": 9.955180595834433e-06,
      "loss": 0.0014,
      "step": 9306
    },
    {
      "epoch": 0.5520820975204651,
      "grad_norm": 5.994905948638916,
      "learning_rate": 9.953862378064858e-06,
      "loss": 0.9254,
      "step": 9307
    },
    {
      "epoch": 0.5521414165381421,
      "grad_norm": 1.1355754137039185,
      "learning_rate": 9.952544160295282e-06,
      "loss": 0.0228,
      "step": 9308
    },
    {
      "epoch": 0.5522007355558192,
      "grad_norm": 0.12866449356079102,
      "learning_rate": 9.951225942525706e-06,
      "loss": 0.0015,
      "step": 9309
    },
    {
      "epoch": 0.5522600545734963,
      "grad_norm": 28.69171142578125,
      "learning_rate": 9.94990772475613e-06,
      "loss": 0.2802,
      "step": 9310
    },
    {
      "epoch": 0.5523193735911733,
      "grad_norm": 10.431571006774902,
      "learning_rate": 9.948589506986554e-06,
      "loss": 0.336,
      "step": 9311
    },
    {
      "epoch": 0.5523786926088504,
      "grad_norm": 9.854243278503418,
      "learning_rate": 9.94727128921698e-06,
      "loss": 0.2892,
      "step": 9312
    },
    {
      "epoch": 0.5524380116265275,
      "grad_norm": 15.969402313232422,
      "learning_rate": 9.945953071447404e-06,
      "loss": 0.6215,
      "step": 9313
    },
    {
      "epoch": 0.5524973306442046,
      "grad_norm": 0.17462265491485596,
      "learning_rate": 9.944634853677829e-06,
      "loss": 0.0008,
      "step": 9314
    },
    {
      "epoch": 0.5525566496618816,
      "grad_norm": 1.1586782932281494,
      "learning_rate": 9.943316635908253e-06,
      "loss": 0.0104,
      "step": 9315
    },
    {
      "epoch": 0.5526159686795586,
      "grad_norm": 0.8272350430488586,
      "learning_rate": 9.941998418138677e-06,
      "loss": 0.009,
      "step": 9316
    },
    {
      "epoch": 0.5526752876972357,
      "grad_norm": 0.031574588268995285,
      "learning_rate": 9.940680200369101e-06,
      "loss": 0.0007,
      "step": 9317
    },
    {
      "epoch": 0.5527346067149128,
      "grad_norm": 34.465824127197266,
      "learning_rate": 9.939361982599525e-06,
      "loss": 1.0904,
      "step": 9318
    },
    {
      "epoch": 0.5527939257325899,
      "grad_norm": 0.34056082367897034,
      "learning_rate": 9.938043764829951e-06,
      "loss": 0.0023,
      "step": 9319
    },
    {
      "epoch": 0.552853244750267,
      "grad_norm": 3.3652241230010986,
      "learning_rate": 9.936725547060375e-06,
      "loss": 0.5392,
      "step": 9320
    },
    {
      "epoch": 0.552912563767944,
      "grad_norm": 1.245658278465271,
      "learning_rate": 9.9354073292908e-06,
      "loss": 0.0098,
      "step": 9321
    },
    {
      "epoch": 0.552971882785621,
      "grad_norm": 0.40147122740745544,
      "learning_rate": 9.934089111521224e-06,
      "loss": 0.0046,
      "step": 9322
    },
    {
      "epoch": 0.5530312018032981,
      "grad_norm": 4.315642833709717,
      "learning_rate": 9.932770893751648e-06,
      "loss": 0.2157,
      "step": 9323
    },
    {
      "epoch": 0.5530905208209752,
      "grad_norm": 0.02065020054578781,
      "learning_rate": 9.931452675982072e-06,
      "loss": 0.0004,
      "step": 9324
    },
    {
      "epoch": 0.5531498398386523,
      "grad_norm": 17.068422317504883,
      "learning_rate": 9.930134458212496e-06,
      "loss": 0.1062,
      "step": 9325
    },
    {
      "epoch": 0.5532091588563294,
      "grad_norm": 0.2097591906785965,
      "learning_rate": 9.928816240442922e-06,
      "loss": 0.0027,
      "step": 9326
    },
    {
      "epoch": 0.5532684778740065,
      "grad_norm": 0.24502865970134735,
      "learning_rate": 9.927498022673346e-06,
      "loss": 0.0021,
      "step": 9327
    },
    {
      "epoch": 0.5533277968916834,
      "grad_norm": 0.01774090714752674,
      "learning_rate": 9.92617980490377e-06,
      "loss": 0.0005,
      "step": 9328
    },
    {
      "epoch": 0.5533871159093605,
      "grad_norm": 14.766196250915527,
      "learning_rate": 9.924861587134196e-06,
      "loss": 0.0929,
      "step": 9329
    },
    {
      "epoch": 0.5534464349270376,
      "grad_norm": 8.895137786865234,
      "learning_rate": 9.92354336936462e-06,
      "loss": 0.1009,
      "step": 9330
    },
    {
      "epoch": 0.5535057539447147,
      "grad_norm": 0.1597224920988083,
      "learning_rate": 9.922225151595045e-06,
      "loss": 0.0021,
      "step": 9331
    },
    {
      "epoch": 0.5535650729623918,
      "grad_norm": 0.03200144320726395,
      "learning_rate": 9.920906933825469e-06,
      "loss": 0.0007,
      "step": 9332
    },
    {
      "epoch": 0.5536243919800689,
      "grad_norm": 4.39730167388916,
      "learning_rate": 9.919588716055893e-06,
      "loss": 0.1073,
      "step": 9333
    },
    {
      "epoch": 0.5536837109977458,
      "grad_norm": 0.2749318778514862,
      "learning_rate": 9.918270498286317e-06,
      "loss": 0.0035,
      "step": 9334
    },
    {
      "epoch": 0.5537430300154229,
      "grad_norm": 1.8468595743179321,
      "learning_rate": 9.916952280516742e-06,
      "loss": 0.0816,
      "step": 9335
    },
    {
      "epoch": 0.5538023490331,
      "grad_norm": 3.697087049484253,
      "learning_rate": 9.915634062747167e-06,
      "loss": 0.0819,
      "step": 9336
    },
    {
      "epoch": 0.5538616680507771,
      "grad_norm": 1.4440926313400269,
      "learning_rate": 9.914315844977592e-06,
      "loss": 0.027,
      "step": 9337
    },
    {
      "epoch": 0.5539209870684542,
      "grad_norm": 9.184704780578613,
      "learning_rate": 9.912997627208016e-06,
      "loss": 0.7429,
      "step": 9338
    },
    {
      "epoch": 0.5539803060861312,
      "grad_norm": 0.06907057762145996,
      "learning_rate": 9.91167940943844e-06,
      "loss": 0.0009,
      "step": 9339
    },
    {
      "epoch": 0.5540396251038083,
      "grad_norm": 4.725258827209473,
      "learning_rate": 9.910361191668864e-06,
      "loss": 0.0254,
      "step": 9340
    },
    {
      "epoch": 0.5540989441214853,
      "grad_norm": 0.7892773151397705,
      "learning_rate": 9.909042973899288e-06,
      "loss": 0.0055,
      "step": 9341
    },
    {
      "epoch": 0.5541582631391624,
      "grad_norm": 0.012370478361845016,
      "learning_rate": 9.907724756129713e-06,
      "loss": 0.0004,
      "step": 9342
    },
    {
      "epoch": 0.5542175821568395,
      "grad_norm": 13.128484725952148,
      "learning_rate": 9.906406538360138e-06,
      "loss": 0.3744,
      "step": 9343
    },
    {
      "epoch": 0.5542769011745166,
      "grad_norm": 8.818408012390137,
      "learning_rate": 9.905088320590563e-06,
      "loss": 0.2988,
      "step": 9344
    },
    {
      "epoch": 0.5543362201921936,
      "grad_norm": 0.02357441745698452,
      "learning_rate": 9.903770102820987e-06,
      "loss": 0.0004,
      "step": 9345
    },
    {
      "epoch": 0.5543955392098707,
      "grad_norm": 0.009914214722812176,
      "learning_rate": 9.902451885051411e-06,
      "loss": 0.0003,
      "step": 9346
    },
    {
      "epoch": 0.5544548582275477,
      "grad_norm": 0.20222532749176025,
      "learning_rate": 9.901133667281835e-06,
      "loss": 0.0023,
      "step": 9347
    },
    {
      "epoch": 0.5545141772452248,
      "grad_norm": 7.933455467224121,
      "learning_rate": 9.89981544951226e-06,
      "loss": 0.082,
      "step": 9348
    },
    {
      "epoch": 0.5545734962629019,
      "grad_norm": 18.337522506713867,
      "learning_rate": 9.898497231742684e-06,
      "loss": 0.7028,
      "step": 9349
    },
    {
      "epoch": 0.554632815280579,
      "grad_norm": 1.4268450736999512,
      "learning_rate": 9.89717901397311e-06,
      "loss": 0.0164,
      "step": 9350
    },
    {
      "epoch": 0.554692134298256,
      "grad_norm": 30.34083366394043,
      "learning_rate": 9.895860796203534e-06,
      "loss": 0.8192,
      "step": 9351
    },
    {
      "epoch": 0.5547514533159331,
      "grad_norm": 0.81275475025177,
      "learning_rate": 9.894542578433958e-06,
      "loss": 0.0057,
      "step": 9352
    },
    {
      "epoch": 0.5548107723336102,
      "grad_norm": 21.59326171875,
      "learning_rate": 9.893224360664384e-06,
      "loss": 0.9819,
      "step": 9353
    },
    {
      "epoch": 0.5548700913512872,
      "grad_norm": 13.416481971740723,
      "learning_rate": 9.891906142894808e-06,
      "loss": 0.9112,
      "step": 9354
    },
    {
      "epoch": 0.5549294103689643,
      "grad_norm": 0.010533151216804981,
      "learning_rate": 9.890587925125232e-06,
      "loss": 0.0005,
      "step": 9355
    },
    {
      "epoch": 0.5549887293866413,
      "grad_norm": 15.380295753479004,
      "learning_rate": 9.889269707355656e-06,
      "loss": 0.343,
      "step": 9356
    },
    {
      "epoch": 0.5550480484043184,
      "grad_norm": 0.5166506171226501,
      "learning_rate": 9.88795148958608e-06,
      "loss": 0.0048,
      "step": 9357
    },
    {
      "epoch": 0.5551073674219955,
      "grad_norm": 0.3300594687461853,
      "learning_rate": 9.886633271816505e-06,
      "loss": 0.0066,
      "step": 9358
    },
    {
      "epoch": 0.5551666864396726,
      "grad_norm": 0.05065212398767471,
      "learning_rate": 9.885315054046929e-06,
      "loss": 0.0006,
      "step": 9359
    },
    {
      "epoch": 0.5552260054573497,
      "grad_norm": 0.3877929747104645,
      "learning_rate": 9.883996836277355e-06,
      "loss": 0.0044,
      "step": 9360
    },
    {
      "epoch": 0.5552853244750267,
      "grad_norm": 20.198522567749023,
      "learning_rate": 9.882678618507779e-06,
      "loss": 0.7111,
      "step": 9361
    },
    {
      "epoch": 0.5553446434927037,
      "grad_norm": 0.1042906865477562,
      "learning_rate": 9.881360400738203e-06,
      "loss": 0.0013,
      "step": 9362
    },
    {
      "epoch": 0.5554039625103808,
      "grad_norm": 5.90421724319458,
      "learning_rate": 9.880042182968627e-06,
      "loss": 0.0584,
      "step": 9363
    },
    {
      "epoch": 0.5554632815280579,
      "grad_norm": 0.7558565139770508,
      "learning_rate": 9.878723965199051e-06,
      "loss": 0.0091,
      "step": 9364
    },
    {
      "epoch": 0.555522600545735,
      "grad_norm": 0.018616680055856705,
      "learning_rate": 9.877405747429476e-06,
      "loss": 0.0004,
      "step": 9365
    },
    {
      "epoch": 0.5555819195634121,
      "grad_norm": 14.507047653198242,
      "learning_rate": 9.8760875296599e-06,
      "loss": 0.2189,
      "step": 9366
    },
    {
      "epoch": 0.555641238581089,
      "grad_norm": 0.07189154624938965,
      "learning_rate": 9.874769311890326e-06,
      "loss": 0.0009,
      "step": 9367
    },
    {
      "epoch": 0.5557005575987661,
      "grad_norm": 68.06282043457031,
      "learning_rate": 9.87345109412075e-06,
      "loss": 1.0982,
      "step": 9368
    },
    {
      "epoch": 0.5557598766164432,
      "grad_norm": 12.519575119018555,
      "learning_rate": 9.872132876351174e-06,
      "loss": 0.2484,
      "step": 9369
    },
    {
      "epoch": 0.5558191956341203,
      "grad_norm": 0.09838442504405975,
      "learning_rate": 9.870814658581598e-06,
      "loss": 0.0019,
      "step": 9370
    },
    {
      "epoch": 0.5558785146517974,
      "grad_norm": 0.011307892389595509,
      "learning_rate": 9.869496440812022e-06,
      "loss": 0.0003,
      "step": 9371
    },
    {
      "epoch": 0.5559378336694745,
      "grad_norm": 7.375270366668701,
      "learning_rate": 9.868178223042447e-06,
      "loss": 0.0941,
      "step": 9372
    },
    {
      "epoch": 0.5559971526871516,
      "grad_norm": 0.23647040128707886,
      "learning_rate": 9.86686000527287e-06,
      "loss": 0.0019,
      "step": 9373
    },
    {
      "epoch": 0.5560564717048285,
      "grad_norm": 1.9395878314971924,
      "learning_rate": 9.865541787503297e-06,
      "loss": 0.0219,
      "step": 9374
    },
    {
      "epoch": 0.5561157907225056,
      "grad_norm": 7.707444190979004,
      "learning_rate": 9.864223569733721e-06,
      "loss": 0.0539,
      "step": 9375
    },
    {
      "epoch": 0.5561751097401827,
      "grad_norm": 1.7350636720657349,
      "learning_rate": 9.862905351964145e-06,
      "loss": 0.0121,
      "step": 9376
    },
    {
      "epoch": 0.5562344287578598,
      "grad_norm": 23.545351028442383,
      "learning_rate": 9.861587134194571e-06,
      "loss": 0.1708,
      "step": 9377
    },
    {
      "epoch": 0.5562937477755369,
      "grad_norm": 21.27946662902832,
      "learning_rate": 9.860268916424993e-06,
      "loss": 0.304,
      "step": 9378
    },
    {
      "epoch": 0.556353066793214,
      "grad_norm": 2.2538857460021973,
      "learning_rate": 9.858950698655418e-06,
      "loss": 0.0354,
      "step": 9379
    },
    {
      "epoch": 0.5564123858108909,
      "grad_norm": 7.88907527923584,
      "learning_rate": 9.857632480885844e-06,
      "loss": 0.2161,
      "step": 9380
    },
    {
      "epoch": 0.556471704828568,
      "grad_norm": 0.0372551865875721,
      "learning_rate": 9.856314263116268e-06,
      "loss": 0.0006,
      "step": 9381
    },
    {
      "epoch": 0.5565310238462451,
      "grad_norm": 1.1571283340454102,
      "learning_rate": 9.854996045346692e-06,
      "loss": 0.0067,
      "step": 9382
    },
    {
      "epoch": 0.5565903428639222,
      "grad_norm": 2.182537078857422,
      "learning_rate": 9.853677827577116e-06,
      "loss": 0.0202,
      "step": 9383
    },
    {
      "epoch": 0.5566496618815993,
      "grad_norm": 0.009050481952726841,
      "learning_rate": 9.852359609807542e-06,
      "loss": 0.0002,
      "step": 9384
    },
    {
      "epoch": 0.5567089808992763,
      "grad_norm": 2.3721930980682373,
      "learning_rate": 9.851041392037966e-06,
      "loss": 0.026,
      "step": 9385
    },
    {
      "epoch": 0.5567682999169534,
      "grad_norm": 8.055737495422363,
      "learning_rate": 9.84972317426839e-06,
      "loss": 0.1952,
      "step": 9386
    },
    {
      "epoch": 0.5568276189346304,
      "grad_norm": 10.702349662780762,
      "learning_rate": 9.848404956498815e-06,
      "loss": 0.1583,
      "step": 9387
    },
    {
      "epoch": 0.5568869379523075,
      "grad_norm": 13.09649658203125,
      "learning_rate": 9.847086738729239e-06,
      "loss": 1.058,
      "step": 9388
    },
    {
      "epoch": 0.5569462569699846,
      "grad_norm": 16.9531307220459,
      "learning_rate": 9.845768520959663e-06,
      "loss": 0.5945,
      "step": 9389
    },
    {
      "epoch": 0.5570055759876616,
      "grad_norm": 0.15734101831912994,
      "learning_rate": 9.844450303190087e-06,
      "loss": 0.0018,
      "step": 9390
    },
    {
      "epoch": 0.5570648950053387,
      "grad_norm": 0.15174561738967896,
      "learning_rate": 9.843132085420513e-06,
      "loss": 0.0017,
      "step": 9391
    },
    {
      "epoch": 0.5571242140230158,
      "grad_norm": 24.353918075561523,
      "learning_rate": 9.841813867650937e-06,
      "loss": 0.3276,
      "step": 9392
    },
    {
      "epoch": 0.5571835330406928,
      "grad_norm": 9.488670349121094,
      "learning_rate": 9.840495649881361e-06,
      "loss": 0.2559,
      "step": 9393
    },
    {
      "epoch": 0.5572428520583699,
      "grad_norm": 0.16381984949111938,
      "learning_rate": 9.839177432111786e-06,
      "loss": 0.0045,
      "step": 9394
    },
    {
      "epoch": 0.557302171076047,
      "grad_norm": 17.660261154174805,
      "learning_rate": 9.83785921434221e-06,
      "loss": 0.391,
      "step": 9395
    },
    {
      "epoch": 0.557361490093724,
      "grad_norm": 7.996488094329834,
      "learning_rate": 9.836540996572634e-06,
      "loss": 0.0351,
      "step": 9396
    },
    {
      "epoch": 0.5574208091114011,
      "grad_norm": 11.517892837524414,
      "learning_rate": 9.835222778803058e-06,
      "loss": 0.2981,
      "step": 9397
    },
    {
      "epoch": 0.5574801281290782,
      "grad_norm": 0.0799451395869255,
      "learning_rate": 9.833904561033484e-06,
      "loss": 0.0007,
      "step": 9398
    },
    {
      "epoch": 0.5575394471467553,
      "grad_norm": 1.064040184020996,
      "learning_rate": 9.832586343263908e-06,
      "loss": 0.0211,
      "step": 9399
    },
    {
      "epoch": 0.5575987661644323,
      "grad_norm": 4.996151924133301,
      "learning_rate": 9.831268125494332e-06,
      "loss": 0.0527,
      "step": 9400
    },
    {
      "epoch": 0.5576580851821094,
      "grad_norm": 10.255946159362793,
      "learning_rate": 9.829949907724757e-06,
      "loss": 1.367,
      "step": 9401
    },
    {
      "epoch": 0.5577174041997864,
      "grad_norm": 0.2738514840602875,
      "learning_rate": 9.82863168995518e-06,
      "loss": 0.0023,
      "step": 9402
    },
    {
      "epoch": 0.5577767232174635,
      "grad_norm": 0.0228258203715086,
      "learning_rate": 9.827313472185605e-06,
      "loss": 0.0006,
      "step": 9403
    },
    {
      "epoch": 0.5578360422351406,
      "grad_norm": 0.015607855282723904,
      "learning_rate": 9.82599525441603e-06,
      "loss": 0.0004,
      "step": 9404
    },
    {
      "epoch": 0.5578953612528177,
      "grad_norm": 0.7837399840354919,
      "learning_rate": 9.824677036646455e-06,
      "loss": 0.0081,
      "step": 9405
    },
    {
      "epoch": 0.5579546802704948,
      "grad_norm": 5.902401447296143,
      "learning_rate": 9.82335881887688e-06,
      "loss": 0.5144,
      "step": 9406
    },
    {
      "epoch": 0.5580139992881717,
      "grad_norm": 0.2776041626930237,
      "learning_rate": 9.822040601107303e-06,
      "loss": 0.0035,
      "step": 9407
    },
    {
      "epoch": 0.5580733183058488,
      "grad_norm": 0.06736696511507034,
      "learning_rate": 9.82072238333773e-06,
      "loss": 0.001,
      "step": 9408
    },
    {
      "epoch": 0.5581326373235259,
      "grad_norm": 0.6303055286407471,
      "learning_rate": 9.819404165568153e-06,
      "loss": 0.0053,
      "step": 9409
    },
    {
      "epoch": 0.558191956341203,
      "grad_norm": 0.030427780002355576,
      "learning_rate": 9.818085947798578e-06,
      "loss": 0.0008,
      "step": 9410
    },
    {
      "epoch": 0.5582512753588801,
      "grad_norm": 9.804140090942383,
      "learning_rate": 9.816767730029002e-06,
      "loss": 0.3706,
      "step": 9411
    },
    {
      "epoch": 0.5583105943765572,
      "grad_norm": 36.4876594543457,
      "learning_rate": 9.815449512259426e-06,
      "loss": 0.9221,
      "step": 9412
    },
    {
      "epoch": 0.5583699133942341,
      "grad_norm": 0.24810153245925903,
      "learning_rate": 9.81413129448985e-06,
      "loss": 0.0029,
      "step": 9413
    },
    {
      "epoch": 0.5584292324119112,
      "grad_norm": 0.014124673791229725,
      "learning_rate": 9.812813076720274e-06,
      "loss": 0.0005,
      "step": 9414
    },
    {
      "epoch": 0.5584885514295883,
      "grad_norm": 5.260893821716309,
      "learning_rate": 9.8114948589507e-06,
      "loss": 0.8241,
      "step": 9415
    },
    {
      "epoch": 0.5585478704472654,
      "grad_norm": 2.0482585430145264,
      "learning_rate": 9.810176641181124e-06,
      "loss": 0.048,
      "step": 9416
    },
    {
      "epoch": 0.5586071894649425,
      "grad_norm": 0.02552894316613674,
      "learning_rate": 9.808858423411549e-06,
      "loss": 0.0005,
      "step": 9417
    },
    {
      "epoch": 0.5586665084826196,
      "grad_norm": 5.43867826461792,
      "learning_rate": 9.807540205641973e-06,
      "loss": 0.2074,
      "step": 9418
    },
    {
      "epoch": 0.5587258275002966,
      "grad_norm": 4.771927833557129,
      "learning_rate": 9.806221987872397e-06,
      "loss": 0.0368,
      "step": 9419
    },
    {
      "epoch": 0.5587851465179736,
      "grad_norm": 3.227081775665283,
      "learning_rate": 9.804903770102821e-06,
      "loss": 0.0176,
      "step": 9420
    },
    {
      "epoch": 0.5588444655356507,
      "grad_norm": 0.5494650602340698,
      "learning_rate": 9.803585552333245e-06,
      "loss": 0.006,
      "step": 9421
    },
    {
      "epoch": 0.5589037845533278,
      "grad_norm": 4.000884056091309,
      "learning_rate": 9.802267334563671e-06,
      "loss": 0.4148,
      "step": 9422
    },
    {
      "epoch": 0.5589631035710049,
      "grad_norm": 11.815958976745605,
      "learning_rate": 9.800949116794095e-06,
      "loss": 0.454,
      "step": 9423
    },
    {
      "epoch": 0.559022422588682,
      "grad_norm": 9.214582443237305,
      "learning_rate": 9.79963089902452e-06,
      "loss": 0.1254,
      "step": 9424
    },
    {
      "epoch": 0.559081741606359,
      "grad_norm": 2.86173939704895,
      "learning_rate": 9.798312681254944e-06,
      "loss": 0.4408,
      "step": 9425
    },
    {
      "epoch": 0.559141060624036,
      "grad_norm": 1.0731658935546875,
      "learning_rate": 9.796994463485368e-06,
      "loss": 0.0118,
      "step": 9426
    },
    {
      "epoch": 0.5592003796417131,
      "grad_norm": 15.513694763183594,
      "learning_rate": 9.795676245715792e-06,
      "loss": 1.3792,
      "step": 9427
    },
    {
      "epoch": 0.5592596986593902,
      "grad_norm": 0.8207564949989319,
      "learning_rate": 9.794358027946218e-06,
      "loss": 0.0061,
      "step": 9428
    },
    {
      "epoch": 0.5593190176770673,
      "grad_norm": 0.21593530476093292,
      "learning_rate": 9.793039810176642e-06,
      "loss": 0.0041,
      "step": 9429
    },
    {
      "epoch": 0.5593783366947443,
      "grad_norm": 0.09744905680418015,
      "learning_rate": 9.791721592407066e-06,
      "loss": 0.0014,
      "step": 9430
    },
    {
      "epoch": 0.5594376557124214,
      "grad_norm": 6.7307329177856445,
      "learning_rate": 9.79040337463749e-06,
      "loss": 0.0652,
      "step": 9431
    },
    {
      "epoch": 0.5594969747300985,
      "grad_norm": 0.3803890645503998,
      "learning_rate": 9.789085156867916e-06,
      "loss": 0.0052,
      "step": 9432
    },
    {
      "epoch": 0.5595562937477755,
      "grad_norm": 0.09312787652015686,
      "learning_rate": 9.78776693909834e-06,
      "loss": 0.0016,
      "step": 9433
    },
    {
      "epoch": 0.5596156127654526,
      "grad_norm": 3.3578453063964844,
      "learning_rate": 9.786448721328763e-06,
      "loss": 0.0514,
      "step": 9434
    },
    {
      "epoch": 0.5596749317831297,
      "grad_norm": 1.0343414545059204,
      "learning_rate": 9.785130503559189e-06,
      "loss": 0.0085,
      "step": 9435
    },
    {
      "epoch": 0.5597342508008067,
      "grad_norm": 0.7824479937553406,
      "learning_rate": 9.783812285789613e-06,
      "loss": 0.0062,
      "step": 9436
    },
    {
      "epoch": 0.5597935698184838,
      "grad_norm": 7.6755547523498535,
      "learning_rate": 9.782494068020037e-06,
      "loss": 0.3594,
      "step": 9437
    },
    {
      "epoch": 0.5598528888361609,
      "grad_norm": 5.990300178527832,
      "learning_rate": 9.781175850250462e-06,
      "loss": 0.3944,
      "step": 9438
    },
    {
      "epoch": 0.559912207853838,
      "grad_norm": 16.89361572265625,
      "learning_rate": 9.779857632480887e-06,
      "loss": 0.2656,
      "step": 9439
    },
    {
      "epoch": 0.559971526871515,
      "grad_norm": 12.14065170288086,
      "learning_rate": 9.778539414711312e-06,
      "loss": 0.6457,
      "step": 9440
    },
    {
      "epoch": 0.560030845889192,
      "grad_norm": 23.241228103637695,
      "learning_rate": 9.777221196941736e-06,
      "loss": 0.9834,
      "step": 9441
    },
    {
      "epoch": 0.5600901649068691,
      "grad_norm": 0.010176672600209713,
      "learning_rate": 9.77590297917216e-06,
      "loss": 0.0003,
      "step": 9442
    },
    {
      "epoch": 0.5601494839245462,
      "grad_norm": 13.574926376342773,
      "learning_rate": 9.774584761402584e-06,
      "loss": 0.5976,
      "step": 9443
    },
    {
      "epoch": 0.5602088029422233,
      "grad_norm": 1.4172757863998413,
      "learning_rate": 9.773266543633008e-06,
      "loss": 0.0125,
      "step": 9444
    },
    {
      "epoch": 0.5602681219599004,
      "grad_norm": 15.737449645996094,
      "learning_rate": 9.771948325863433e-06,
      "loss": 0.9811,
      "step": 9445
    },
    {
      "epoch": 0.5603274409775774,
      "grad_norm": 0.44374871253967285,
      "learning_rate": 9.770630108093859e-06,
      "loss": 0.0057,
      "step": 9446
    },
    {
      "epoch": 0.5603867599952544,
      "grad_norm": 0.011298313736915588,
      "learning_rate": 9.769311890324283e-06,
      "loss": 0.0002,
      "step": 9447
    },
    {
      "epoch": 0.5604460790129315,
      "grad_norm": 6.256599426269531,
      "learning_rate": 9.767993672554707e-06,
      "loss": 0.026,
      "step": 9448
    },
    {
      "epoch": 0.5605053980306086,
      "grad_norm": 0.1530483216047287,
      "learning_rate": 9.766675454785131e-06,
      "loss": 0.0022,
      "step": 9449
    },
    {
      "epoch": 0.5605647170482857,
      "grad_norm": 1.510095477104187,
      "learning_rate": 9.765357237015555e-06,
      "loss": 0.0172,
      "step": 9450
    },
    {
      "epoch": 0.5606240360659628,
      "grad_norm": 0.7500826716423035,
      "learning_rate": 9.76403901924598e-06,
      "loss": 0.0062,
      "step": 9451
    },
    {
      "epoch": 0.5606833550836399,
      "grad_norm": 0.24144159257411957,
      "learning_rate": 9.762720801476405e-06,
      "loss": 0.0021,
      "step": 9452
    },
    {
      "epoch": 0.5607426741013168,
      "grad_norm": 1.9053446054458618,
      "learning_rate": 9.76140258370683e-06,
      "loss": 0.0106,
      "step": 9453
    },
    {
      "epoch": 0.5608019931189939,
      "grad_norm": 1.6509060859680176,
      "learning_rate": 9.760084365937254e-06,
      "loss": 0.0254,
      "step": 9454
    },
    {
      "epoch": 0.560861312136671,
      "grad_norm": 1.4070059061050415,
      "learning_rate": 9.758766148167678e-06,
      "loss": 0.0136,
      "step": 9455
    },
    {
      "epoch": 0.5609206311543481,
      "grad_norm": 7.180419445037842,
      "learning_rate": 9.757447930398102e-06,
      "loss": 0.0276,
      "step": 9456
    },
    {
      "epoch": 0.5609799501720252,
      "grad_norm": 0.007297041360288858,
      "learning_rate": 9.756129712628526e-06,
      "loss": 0.0002,
      "step": 9457
    },
    {
      "epoch": 0.5610392691897023,
      "grad_norm": 0.11997831612825394,
      "learning_rate": 9.75481149485895e-06,
      "loss": 0.0012,
      "step": 9458
    },
    {
      "epoch": 0.5610985882073792,
      "grad_norm": 0.010183150880038738,
      "learning_rate": 9.753493277089376e-06,
      "loss": 0.0005,
      "step": 9459
    },
    {
      "epoch": 0.5611579072250563,
      "grad_norm": 2.168858528137207,
      "learning_rate": 9.7521750593198e-06,
      "loss": 0.0171,
      "step": 9460
    },
    {
      "epoch": 0.5612172262427334,
      "grad_norm": 0.025226620957255363,
      "learning_rate": 9.750856841550225e-06,
      "loss": 0.0008,
      "step": 9461
    },
    {
      "epoch": 0.5612765452604105,
      "grad_norm": 40.6781120300293,
      "learning_rate": 9.749538623780649e-06,
      "loss": 0.9049,
      "step": 9462
    },
    {
      "epoch": 0.5613358642780876,
      "grad_norm": 4.453366756439209,
      "learning_rate": 9.748220406011075e-06,
      "loss": 0.0866,
      "step": 9463
    },
    {
      "epoch": 0.5613951832957647,
      "grad_norm": 0.021651357412338257,
      "learning_rate": 9.746902188241499e-06,
      "loss": 0.0007,
      "step": 9464
    },
    {
      "epoch": 0.5614545023134417,
      "grad_norm": 0.2457428127527237,
      "learning_rate": 9.745583970471923e-06,
      "loss": 0.0023,
      "step": 9465
    },
    {
      "epoch": 0.5615138213311187,
      "grad_norm": 0.05259963497519493,
      "learning_rate": 9.744265752702347e-06,
      "loss": 0.0011,
      "step": 9466
    },
    {
      "epoch": 0.5615731403487958,
      "grad_norm": 0.23609843850135803,
      "learning_rate": 9.742947534932772e-06,
      "loss": 0.0028,
      "step": 9467
    },
    {
      "epoch": 0.5616324593664729,
      "grad_norm": 0.03504694253206253,
      "learning_rate": 9.741629317163196e-06,
      "loss": 0.001,
      "step": 9468
    },
    {
      "epoch": 0.56169177838415,
      "grad_norm": 8.676132202148438,
      "learning_rate": 9.74031109939362e-06,
      "loss": 0.0312,
      "step": 9469
    },
    {
      "epoch": 0.561751097401827,
      "grad_norm": 0.6125187873840332,
      "learning_rate": 9.738992881624046e-06,
      "loss": 0.0051,
      "step": 9470
    },
    {
      "epoch": 0.5618104164195041,
      "grad_norm": 0.030974294990301132,
      "learning_rate": 9.73767466385447e-06,
      "loss": 0.0006,
      "step": 9471
    },
    {
      "epoch": 0.5618697354371811,
      "grad_norm": 0.39583253860473633,
      "learning_rate": 9.736356446084894e-06,
      "loss": 0.0047,
      "step": 9472
    },
    {
      "epoch": 0.5619290544548582,
      "grad_norm": 12.412845611572266,
      "learning_rate": 9.735038228315318e-06,
      "loss": 0.1706,
      "step": 9473
    },
    {
      "epoch": 0.5619883734725353,
      "grad_norm": 0.6263121962547302,
      "learning_rate": 9.733720010545743e-06,
      "loss": 0.0046,
      "step": 9474
    },
    {
      "epoch": 0.5620476924902124,
      "grad_norm": 0.08755143731832504,
      "learning_rate": 9.732401792776167e-06,
      "loss": 0.0024,
      "step": 9475
    },
    {
      "epoch": 0.5621070115078894,
      "grad_norm": 0.016673384234309196,
      "learning_rate": 9.731083575006593e-06,
      "loss": 0.0005,
      "step": 9476
    },
    {
      "epoch": 0.5621663305255665,
      "grad_norm": 0.614468514919281,
      "learning_rate": 9.729765357237017e-06,
      "loss": 0.0086,
      "step": 9477
    },
    {
      "epoch": 0.5622256495432436,
      "grad_norm": 0.05965189263224602,
      "learning_rate": 9.728447139467441e-06,
      "loss": 0.001,
      "step": 9478
    },
    {
      "epoch": 0.5622849685609206,
      "grad_norm": 0.057696472853422165,
      "learning_rate": 9.727128921697865e-06,
      "loss": 0.0007,
      "step": 9479
    },
    {
      "epoch": 0.5623442875785977,
      "grad_norm": 1.360512614250183,
      "learning_rate": 9.72581070392829e-06,
      "loss": 0.0245,
      "step": 9480
    },
    {
      "epoch": 0.5624036065962748,
      "grad_norm": 5.092972755432129,
      "learning_rate": 9.724492486158714e-06,
      "loss": 0.0709,
      "step": 9481
    },
    {
      "epoch": 0.5624629256139518,
      "grad_norm": 4.705258369445801,
      "learning_rate": 9.723174268389138e-06,
      "loss": 0.2978,
      "step": 9482
    },
    {
      "epoch": 0.5625222446316289,
      "grad_norm": 9.215696334838867,
      "learning_rate": 9.721856050619564e-06,
      "loss": 0.5103,
      "step": 9483
    },
    {
      "epoch": 0.562581563649306,
      "grad_norm": 4.155086040496826,
      "learning_rate": 9.720537832849988e-06,
      "loss": 0.0383,
      "step": 9484
    },
    {
      "epoch": 0.5626408826669831,
      "grad_norm": 0.11511187255382538,
      "learning_rate": 9.719219615080412e-06,
      "loss": 0.0019,
      "step": 9485
    },
    {
      "epoch": 0.5627002016846601,
      "grad_norm": 0.045418430119752884,
      "learning_rate": 9.717901397310836e-06,
      "loss": 0.0009,
      "step": 9486
    },
    {
      "epoch": 0.5627595207023371,
      "grad_norm": 0.03016451559960842,
      "learning_rate": 9.716583179541262e-06,
      "loss": 0.0008,
      "step": 9487
    },
    {
      "epoch": 0.5628188397200142,
      "grad_norm": 15.01601505279541,
      "learning_rate": 9.715264961771686e-06,
      "loss": 0.2784,
      "step": 9488
    },
    {
      "epoch": 0.5628781587376913,
      "grad_norm": 6.5112385749816895,
      "learning_rate": 9.71394674400211e-06,
      "loss": 0.0648,
      "step": 9489
    },
    {
      "epoch": 0.5629374777553684,
      "grad_norm": 75.40287017822266,
      "learning_rate": 9.712628526232535e-06,
      "loss": 2.1317,
      "step": 9490
    },
    {
      "epoch": 0.5629967967730455,
      "grad_norm": 3.482954740524292,
      "learning_rate": 9.711310308462959e-06,
      "loss": 0.0371,
      "step": 9491
    },
    {
      "epoch": 0.5630561157907225,
      "grad_norm": 3.1200878620147705,
      "learning_rate": 9.709992090693383e-06,
      "loss": 0.0652,
      "step": 9492
    },
    {
      "epoch": 0.5631154348083995,
      "grad_norm": 0.41917696595191956,
      "learning_rate": 9.708673872923807e-06,
      "loss": 0.0045,
      "step": 9493
    },
    {
      "epoch": 0.5631747538260766,
      "grad_norm": 0.1384250670671463,
      "learning_rate": 9.707355655154233e-06,
      "loss": 0.0013,
      "step": 9494
    },
    {
      "epoch": 0.5632340728437537,
      "grad_norm": 7.324204921722412,
      "learning_rate": 9.706037437384657e-06,
      "loss": 0.3457,
      "step": 9495
    },
    {
      "epoch": 0.5632933918614308,
      "grad_norm": 0.021803580224514008,
      "learning_rate": 9.704719219615081e-06,
      "loss": 0.0008,
      "step": 9496
    },
    {
      "epoch": 0.5633527108791079,
      "grad_norm": 8.7310791015625,
      "learning_rate": 9.703401001845506e-06,
      "loss": 0.2318,
      "step": 9497
    },
    {
      "epoch": 0.563412029896785,
      "grad_norm": 4.344463348388672,
      "learning_rate": 9.70208278407593e-06,
      "loss": 0.2245,
      "step": 9498
    },
    {
      "epoch": 0.5634713489144619,
      "grad_norm": 10.355549812316895,
      "learning_rate": 9.700764566306354e-06,
      "loss": 0.1579,
      "step": 9499
    },
    {
      "epoch": 0.563530667932139,
      "grad_norm": 8.185638427734375,
      "learning_rate": 9.69944634853678e-06,
      "loss": 0.0516,
      "step": 9500
    },
    {
      "epoch": 0.5635899869498161,
      "grad_norm": 0.26524806022644043,
      "learning_rate": 9.698128130767204e-06,
      "loss": 0.0024,
      "step": 9501
    },
    {
      "epoch": 0.5636493059674932,
      "grad_norm": 2.3486855030059814,
      "learning_rate": 9.696809912997628e-06,
      "loss": 0.0148,
      "step": 9502
    },
    {
      "epoch": 0.5637086249851703,
      "grad_norm": 3.2722249031066895,
      "learning_rate": 9.695491695228052e-06,
      "loss": 0.0462,
      "step": 9503
    },
    {
      "epoch": 0.5637679440028474,
      "grad_norm": 0.011989893391728401,
      "learning_rate": 9.694173477458477e-06,
      "loss": 0.0003,
      "step": 9504
    },
    {
      "epoch": 0.5638272630205243,
      "grad_norm": 5.2863078117370605,
      "learning_rate": 9.6928552596889e-06,
      "loss": 0.2523,
      "step": 9505
    },
    {
      "epoch": 0.5638865820382014,
      "grad_norm": 0.01714513637125492,
      "learning_rate": 9.691537041919325e-06,
      "loss": 0.0004,
      "step": 9506
    },
    {
      "epoch": 0.5639459010558785,
      "grad_norm": 2.135737180709839,
      "learning_rate": 9.690218824149751e-06,
      "loss": 0.0237,
      "step": 9507
    },
    {
      "epoch": 0.5640052200735556,
      "grad_norm": 0.012891808524727821,
      "learning_rate": 9.688900606380175e-06,
      "loss": 0.0004,
      "step": 9508
    },
    {
      "epoch": 0.5640645390912327,
      "grad_norm": 22.52921485900879,
      "learning_rate": 9.6875823886106e-06,
      "loss": 0.1645,
      "step": 9509
    },
    {
      "epoch": 0.5641238581089097,
      "grad_norm": 9.295645713806152,
      "learning_rate": 9.686264170841023e-06,
      "loss": 0.1859,
      "step": 9510
    },
    {
      "epoch": 0.5641831771265868,
      "grad_norm": 0.011755229905247688,
      "learning_rate": 9.68494595307145e-06,
      "loss": 0.0004,
      "step": 9511
    },
    {
      "epoch": 0.5642424961442638,
      "grad_norm": 5.815618515014648,
      "learning_rate": 9.683627735301872e-06,
      "loss": 0.0603,
      "step": 9512
    },
    {
      "epoch": 0.5643018151619409,
      "grad_norm": 11.272512435913086,
      "learning_rate": 9.682309517532296e-06,
      "loss": 0.124,
      "step": 9513
    },
    {
      "epoch": 0.564361134179618,
      "grad_norm": 5.29586935043335,
      "learning_rate": 9.680991299762722e-06,
      "loss": 0.1416,
      "step": 9514
    },
    {
      "epoch": 0.5644204531972951,
      "grad_norm": 8.887792587280273,
      "learning_rate": 9.679673081993146e-06,
      "loss": 0.0806,
      "step": 9515
    },
    {
      "epoch": 0.5644797722149721,
      "grad_norm": 7.005425453186035,
      "learning_rate": 9.67835486422357e-06,
      "loss": 0.1446,
      "step": 9516
    },
    {
      "epoch": 0.5645390912326492,
      "grad_norm": 0.13549679517745972,
      "learning_rate": 9.677036646453996e-06,
      "loss": 0.0011,
      "step": 9517
    },
    {
      "epoch": 0.5645984102503262,
      "grad_norm": 7.820150375366211,
      "learning_rate": 9.67571842868442e-06,
      "loss": 0.4415,
      "step": 9518
    },
    {
      "epoch": 0.5646577292680033,
      "grad_norm": 0.09991057962179184,
      "learning_rate": 9.674400210914844e-06,
      "loss": 0.0015,
      "step": 9519
    },
    {
      "epoch": 0.5647170482856804,
      "grad_norm": 1.505618929862976,
      "learning_rate": 9.673081993145269e-06,
      "loss": 0.0132,
      "step": 9520
    },
    {
      "epoch": 0.5647763673033575,
      "grad_norm": 0.12358264625072479,
      "learning_rate": 9.671763775375693e-06,
      "loss": 0.0015,
      "step": 9521
    },
    {
      "epoch": 0.5648356863210345,
      "grad_norm": 11.730623245239258,
      "learning_rate": 9.670445557606117e-06,
      "loss": 0.7211,
      "step": 9522
    },
    {
      "epoch": 0.5648950053387116,
      "grad_norm": 2.944186210632324,
      "learning_rate": 9.669127339836541e-06,
      "loss": 0.0443,
      "step": 9523
    },
    {
      "epoch": 0.5649543243563887,
      "grad_norm": 4.573016166687012,
      "learning_rate": 9.667809122066967e-06,
      "loss": 0.0639,
      "step": 9524
    },
    {
      "epoch": 0.5650136433740657,
      "grad_norm": 2.4721763134002686,
      "learning_rate": 9.666490904297391e-06,
      "loss": 0.117,
      "step": 9525
    },
    {
      "epoch": 0.5650729623917428,
      "grad_norm": 5.551878929138184,
      "learning_rate": 9.665172686527815e-06,
      "loss": 0.1235,
      "step": 9526
    },
    {
      "epoch": 0.5651322814094198,
      "grad_norm": 11.622363090515137,
      "learning_rate": 9.66385446875824e-06,
      "loss": 0.7483,
      "step": 9527
    },
    {
      "epoch": 0.5651916004270969,
      "grad_norm": 8.723217964172363,
      "learning_rate": 9.662536250988664e-06,
      "loss": 0.0723,
      "step": 9528
    },
    {
      "epoch": 0.565250919444774,
      "grad_norm": 0.10298972576856613,
      "learning_rate": 9.661218033219088e-06,
      "loss": 0.0012,
      "step": 9529
    },
    {
      "epoch": 0.5653102384624511,
      "grad_norm": 0.053254786878824234,
      "learning_rate": 9.659899815449512e-06,
      "loss": 0.0005,
      "step": 9530
    },
    {
      "epoch": 0.5653695574801282,
      "grad_norm": 0.6356398463249207,
      "learning_rate": 9.658581597679938e-06,
      "loss": 0.0131,
      "step": 9531
    },
    {
      "epoch": 0.5654288764978052,
      "grad_norm": 0.570665717124939,
      "learning_rate": 9.657263379910362e-06,
      "loss": 0.0133,
      "step": 9532
    },
    {
      "epoch": 0.5654881955154822,
      "grad_norm": 0.3232775330543518,
      "learning_rate": 9.655945162140786e-06,
      "loss": 0.004,
      "step": 9533
    },
    {
      "epoch": 0.5655475145331593,
      "grad_norm": 16.42222023010254,
      "learning_rate": 9.65462694437121e-06,
      "loss": 0.4555,
      "step": 9534
    },
    {
      "epoch": 0.5656068335508364,
      "grad_norm": 19.852798461914062,
      "learning_rate": 9.653308726601635e-06,
      "loss": 0.328,
      "step": 9535
    },
    {
      "epoch": 0.5656661525685135,
      "grad_norm": 0.007955572567880154,
      "learning_rate": 9.651990508832059e-06,
      "loss": 0.0004,
      "step": 9536
    },
    {
      "epoch": 0.5657254715861906,
      "grad_norm": 2.2012274265289307,
      "learning_rate": 9.650672291062483e-06,
      "loss": 0.0281,
      "step": 9537
    },
    {
      "epoch": 0.5657847906038675,
      "grad_norm": 0.5874864459037781,
      "learning_rate": 9.649354073292909e-06,
      "loss": 0.0036,
      "step": 9538
    },
    {
      "epoch": 0.5658441096215446,
      "grad_norm": 0.26175254583358765,
      "learning_rate": 9.648035855523333e-06,
      "loss": 0.0042,
      "step": 9539
    },
    {
      "epoch": 0.5659034286392217,
      "grad_norm": 0.02765885926783085,
      "learning_rate": 9.646717637753757e-06,
      "loss": 0.0003,
      "step": 9540
    },
    {
      "epoch": 0.5659627476568988,
      "grad_norm": 0.021502716466784477,
      "learning_rate": 9.645399419984183e-06,
      "loss": 0.0005,
      "step": 9541
    },
    {
      "epoch": 0.5660220666745759,
      "grad_norm": 0.02661905623972416,
      "learning_rate": 9.644081202214608e-06,
      "loss": 0.0007,
      "step": 9542
    },
    {
      "epoch": 0.566081385692253,
      "grad_norm": 6.517080307006836,
      "learning_rate": 9.642762984445032e-06,
      "loss": 0.5692,
      "step": 9543
    },
    {
      "epoch": 0.56614070470993,
      "grad_norm": 0.006710101384669542,
      "learning_rate": 9.641444766675456e-06,
      "loss": 0.0002,
      "step": 9544
    },
    {
      "epoch": 0.566200023727607,
      "grad_norm": 1.5019397735595703,
      "learning_rate": 9.64012654890588e-06,
      "loss": 0.0095,
      "step": 9545
    },
    {
      "epoch": 0.5662593427452841,
      "grad_norm": 0.2806810438632965,
      "learning_rate": 9.638808331136304e-06,
      "loss": 0.004,
      "step": 9546
    },
    {
      "epoch": 0.5663186617629612,
      "grad_norm": 0.17184849083423615,
      "learning_rate": 9.637490113366729e-06,
      "loss": 0.0036,
      "step": 9547
    },
    {
      "epoch": 0.5663779807806383,
      "grad_norm": 4.648735523223877,
      "learning_rate": 9.636171895597154e-06,
      "loss": 0.1153,
      "step": 9548
    },
    {
      "epoch": 0.5664372997983154,
      "grad_norm": 4.324699401855469,
      "learning_rate": 9.634853677827579e-06,
      "loss": 0.0967,
      "step": 9549
    },
    {
      "epoch": 0.5664966188159924,
      "grad_norm": 0.07491435110569,
      "learning_rate": 9.633535460058003e-06,
      "loss": 0.001,
      "step": 9550
    },
    {
      "epoch": 0.5665559378336694,
      "grad_norm": 7.438564300537109,
      "learning_rate": 9.632217242288427e-06,
      "loss": 0.3033,
      "step": 9551
    },
    {
      "epoch": 0.5666152568513465,
      "grad_norm": 0.012685634195804596,
      "learning_rate": 9.630899024518851e-06,
      "loss": 0.0004,
      "step": 9552
    },
    {
      "epoch": 0.5666745758690236,
      "grad_norm": 4.091619491577148,
      "learning_rate": 9.629580806749275e-06,
      "loss": 0.0556,
      "step": 9553
    },
    {
      "epoch": 0.5667338948867007,
      "grad_norm": 5.306160926818848,
      "learning_rate": 9.6282625889797e-06,
      "loss": 0.0594,
      "step": 9554
    },
    {
      "epoch": 0.5667932139043778,
      "grad_norm": 0.35229676961898804,
      "learning_rate": 9.626944371210125e-06,
      "loss": 0.0028,
      "step": 9555
    },
    {
      "epoch": 0.5668525329220548,
      "grad_norm": 11.747645378112793,
      "learning_rate": 9.62562615344055e-06,
      "loss": 0.9499,
      "step": 9556
    },
    {
      "epoch": 0.5669118519397319,
      "grad_norm": 14.243182182312012,
      "learning_rate": 9.624307935670974e-06,
      "loss": 1.3165,
      "step": 9557
    },
    {
      "epoch": 0.5669711709574089,
      "grad_norm": 1.0597630739212036,
      "learning_rate": 9.622989717901398e-06,
      "loss": 0.0035,
      "step": 9558
    },
    {
      "epoch": 0.567030489975086,
      "grad_norm": 1.8292938470840454,
      "learning_rate": 9.621671500131822e-06,
      "loss": 0.0361,
      "step": 9559
    },
    {
      "epoch": 0.5670898089927631,
      "grad_norm": 6.562512397766113,
      "learning_rate": 9.620353282362246e-06,
      "loss": 0.7407,
      "step": 9560
    },
    {
      "epoch": 0.5671491280104402,
      "grad_norm": 0.4142512083053589,
      "learning_rate": 9.61903506459267e-06,
      "loss": 0.0063,
      "step": 9561
    },
    {
      "epoch": 0.5672084470281172,
      "grad_norm": 2.904402256011963,
      "learning_rate": 9.617716846823096e-06,
      "loss": 0.1046,
      "step": 9562
    },
    {
      "epoch": 0.5672677660457943,
      "grad_norm": 9.060541152954102,
      "learning_rate": 9.61639862905352e-06,
      "loss": 0.4175,
      "step": 9563
    },
    {
      "epoch": 0.5673270850634714,
      "grad_norm": 1.2893487215042114,
      "learning_rate": 9.615080411283945e-06,
      "loss": 0.0189,
      "step": 9564
    },
    {
      "epoch": 0.5673864040811484,
      "grad_norm": 0.02192859910428524,
      "learning_rate": 9.61376219351437e-06,
      "loss": 0.0003,
      "step": 9565
    },
    {
      "epoch": 0.5674457230988255,
      "grad_norm": 62.46467590332031,
      "learning_rate": 9.612443975744795e-06,
      "loss": 0.2287,
      "step": 9566
    },
    {
      "epoch": 0.5675050421165025,
      "grad_norm": 0.00949467159807682,
      "learning_rate": 9.611125757975219e-06,
      "loss": 0.0003,
      "step": 9567
    },
    {
      "epoch": 0.5675643611341796,
      "grad_norm": 8.543649673461914,
      "learning_rate": 9.609807540205642e-06,
      "loss": 0.2356,
      "step": 9568
    },
    {
      "epoch": 0.5676236801518567,
      "grad_norm": 0.16357780992984772,
      "learning_rate": 9.608489322436067e-06,
      "loss": 0.0025,
      "step": 9569
    },
    {
      "epoch": 0.5676829991695338,
      "grad_norm": 0.058868929743766785,
      "learning_rate": 9.607171104666492e-06,
      "loss": 0.0015,
      "step": 9570
    },
    {
      "epoch": 0.5677423181872108,
      "grad_norm": 17.74150848388672,
      "learning_rate": 9.605852886896916e-06,
      "loss": 0.1928,
      "step": 9571
    },
    {
      "epoch": 0.5678016372048879,
      "grad_norm": 9.60102653503418,
      "learning_rate": 9.604534669127342e-06,
      "loss": 0.1245,
      "step": 9572
    },
    {
      "epoch": 0.5678609562225649,
      "grad_norm": 1.084911823272705,
      "learning_rate": 9.603216451357766e-06,
      "loss": 0.006,
      "step": 9573
    },
    {
      "epoch": 0.567920275240242,
      "grad_norm": 0.0258384607732296,
      "learning_rate": 9.60189823358819e-06,
      "loss": 0.0005,
      "step": 9574
    },
    {
      "epoch": 0.5679795942579191,
      "grad_norm": 2.4308416843414307,
      "learning_rate": 9.600580015818614e-06,
      "loss": 0.0513,
      "step": 9575
    },
    {
      "epoch": 0.5680389132755962,
      "grad_norm": 5.567564487457275,
      "learning_rate": 9.599261798049038e-06,
      "loss": 0.3814,
      "step": 9576
    },
    {
      "epoch": 0.5680982322932733,
      "grad_norm": 14.170988082885742,
      "learning_rate": 9.597943580279463e-06,
      "loss": 0.1628,
      "step": 9577
    },
    {
      "epoch": 0.5681575513109502,
      "grad_norm": 49.89692687988281,
      "learning_rate": 9.596625362509887e-06,
      "loss": 2.5739,
      "step": 9578
    },
    {
      "epoch": 0.5682168703286273,
      "grad_norm": 0.7076706886291504,
      "learning_rate": 9.595307144740313e-06,
      "loss": 0.0137,
      "step": 9579
    },
    {
      "epoch": 0.5682761893463044,
      "grad_norm": 0.6496638059616089,
      "learning_rate": 9.593988926970737e-06,
      "loss": 0.0074,
      "step": 9580
    },
    {
      "epoch": 0.5683355083639815,
      "grad_norm": 5.610514163970947,
      "learning_rate": 9.592670709201161e-06,
      "loss": 0.3797,
      "step": 9581
    },
    {
      "epoch": 0.5683948273816586,
      "grad_norm": 0.8867301940917969,
      "learning_rate": 9.591352491431585e-06,
      "loss": 0.0124,
      "step": 9582
    },
    {
      "epoch": 0.5684541463993357,
      "grad_norm": 0.14500664174556732,
      "learning_rate": 9.59003427366201e-06,
      "loss": 0.0037,
      "step": 9583
    },
    {
      "epoch": 0.5685134654170126,
      "grad_norm": 0.18504275381565094,
      "learning_rate": 9.588716055892434e-06,
      "loss": 0.0049,
      "step": 9584
    },
    {
      "epoch": 0.5685727844346897,
      "grad_norm": 0.2244979292154312,
      "learning_rate": 9.587397838122858e-06,
      "loss": 0.0045,
      "step": 9585
    },
    {
      "epoch": 0.5686321034523668,
      "grad_norm": 1.7699916362762451,
      "learning_rate": 9.586079620353284e-06,
      "loss": 0.0262,
      "step": 9586
    },
    {
      "epoch": 0.5686914224700439,
      "grad_norm": 17.840726852416992,
      "learning_rate": 9.584761402583708e-06,
      "loss": 1.4963,
      "step": 9587
    },
    {
      "epoch": 0.568750741487721,
      "grad_norm": 11.571027755737305,
      "learning_rate": 9.583443184814132e-06,
      "loss": 0.1983,
      "step": 9588
    },
    {
      "epoch": 0.5688100605053981,
      "grad_norm": 0.3348962962627411,
      "learning_rate": 9.582124967044558e-06,
      "loss": 0.0024,
      "step": 9589
    },
    {
      "epoch": 0.5688693795230751,
      "grad_norm": 2.221679210662842,
      "learning_rate": 9.58080674927498e-06,
      "loss": 0.0471,
      "step": 9590
    },
    {
      "epoch": 0.5689286985407521,
      "grad_norm": 2.460050344467163,
      "learning_rate": 9.579488531505405e-06,
      "loss": 0.0501,
      "step": 9591
    },
    {
      "epoch": 0.5689880175584292,
      "grad_norm": 7.527531147003174,
      "learning_rate": 9.578170313735829e-06,
      "loss": 0.0892,
      "step": 9592
    },
    {
      "epoch": 0.5690473365761063,
      "grad_norm": 0.0194872859865427,
      "learning_rate": 9.576852095966255e-06,
      "loss": 0.0005,
      "step": 9593
    },
    {
      "epoch": 0.5691066555937834,
      "grad_norm": 0.005881255492568016,
      "learning_rate": 9.575533878196679e-06,
      "loss": 0.0002,
      "step": 9594
    },
    {
      "epoch": 0.5691659746114605,
      "grad_norm": 0.2033541053533554,
      "learning_rate": 9.574215660427103e-06,
      "loss": 0.001,
      "step": 9595
    },
    {
      "epoch": 0.5692252936291375,
      "grad_norm": 7.862110137939453,
      "learning_rate": 9.572897442657529e-06,
      "loss": 0.4131,
      "step": 9596
    },
    {
      "epoch": 0.5692846126468145,
      "grad_norm": 0.07776054739952087,
      "learning_rate": 9.571579224887953e-06,
      "loss": 0.0009,
      "step": 9597
    },
    {
      "epoch": 0.5693439316644916,
      "grad_norm": 0.01867632567882538,
      "learning_rate": 9.570261007118377e-06,
      "loss": 0.0005,
      "step": 9598
    },
    {
      "epoch": 0.5694032506821687,
      "grad_norm": 9.890368461608887,
      "learning_rate": 9.568942789348801e-06,
      "loss": 0.1475,
      "step": 9599
    },
    {
      "epoch": 0.5694625696998458,
      "grad_norm": 0.08033336699008942,
      "learning_rate": 9.567624571579226e-06,
      "loss": 0.0016,
      "step": 9600
    },
    {
      "epoch": 0.5695218887175229,
      "grad_norm": 1.5983179807662964,
      "learning_rate": 9.56630635380965e-06,
      "loss": 0.0207,
      "step": 9601
    },
    {
      "epoch": 0.5695812077351999,
      "grad_norm": 0.08301365375518799,
      "learning_rate": 9.564988136040074e-06,
      "loss": 0.0012,
      "step": 9602
    },
    {
      "epoch": 0.569640526752877,
      "grad_norm": 28.96619987487793,
      "learning_rate": 9.5636699182705e-06,
      "loss": 0.1257,
      "step": 9603
    },
    {
      "epoch": 0.569699845770554,
      "grad_norm": 4.746364593505859,
      "learning_rate": 9.562351700500924e-06,
      "loss": 0.1902,
      "step": 9604
    },
    {
      "epoch": 0.5697591647882311,
      "grad_norm": 2.787810802459717,
      "learning_rate": 9.561033482731348e-06,
      "loss": 0.0177,
      "step": 9605
    },
    {
      "epoch": 0.5698184838059082,
      "grad_norm": 0.8190733194351196,
      "learning_rate": 9.559715264961772e-06,
      "loss": 0.0062,
      "step": 9606
    },
    {
      "epoch": 0.5698778028235852,
      "grad_norm": 6.386715888977051,
      "learning_rate": 9.558397047192197e-06,
      "loss": 0.1225,
      "step": 9607
    },
    {
      "epoch": 0.5699371218412623,
      "grad_norm": 6.158292770385742,
      "learning_rate": 9.557078829422621e-06,
      "loss": 0.1782,
      "step": 9608
    },
    {
      "epoch": 0.5699964408589394,
      "grad_norm": 4.166764259338379,
      "learning_rate": 9.555760611653045e-06,
      "loss": 0.0529,
      "step": 9609
    },
    {
      "epoch": 0.5700557598766165,
      "grad_norm": 10.047804832458496,
      "learning_rate": 9.554442393883471e-06,
      "loss": 1.2921,
      "step": 9610
    },
    {
      "epoch": 0.5701150788942935,
      "grad_norm": 0.10045050084590912,
      "learning_rate": 9.553124176113895e-06,
      "loss": 0.0019,
      "step": 9611
    },
    {
      "epoch": 0.5701743979119706,
      "grad_norm": 1.4579929113388062,
      "learning_rate": 9.55180595834432e-06,
      "loss": 0.014,
      "step": 9612
    },
    {
      "epoch": 0.5702337169296476,
      "grad_norm": 3.1075198650360107,
      "learning_rate": 9.550487740574743e-06,
      "loss": 0.0122,
      "step": 9613
    },
    {
      "epoch": 0.5702930359473247,
      "grad_norm": 1.64521324634552,
      "learning_rate": 9.549169522805168e-06,
      "loss": 0.0133,
      "step": 9614
    },
    {
      "epoch": 0.5703523549650018,
      "grad_norm": 0.011544089764356613,
      "learning_rate": 9.547851305035592e-06,
      "loss": 0.0003,
      "step": 9615
    },
    {
      "epoch": 0.5704116739826789,
      "grad_norm": 0.04796614125370979,
      "learning_rate": 9.546533087266016e-06,
      "loss": 0.0008,
      "step": 9616
    },
    {
      "epoch": 0.5704709930003559,
      "grad_norm": 0.02073671855032444,
      "learning_rate": 9.545214869496442e-06,
      "loss": 0.0007,
      "step": 9617
    },
    {
      "epoch": 0.570530312018033,
      "grad_norm": 22.290515899658203,
      "learning_rate": 9.543896651726866e-06,
      "loss": 2.7598,
      "step": 9618
    },
    {
      "epoch": 0.57058963103571,
      "grad_norm": 16.03404426574707,
      "learning_rate": 9.54257843395729e-06,
      "loss": 0.1421,
      "step": 9619
    },
    {
      "epoch": 0.5706489500533871,
      "grad_norm": 0.012703652493655682,
      "learning_rate": 9.541260216187716e-06,
      "loss": 0.0004,
      "step": 9620
    },
    {
      "epoch": 0.5707082690710642,
      "grad_norm": 4.471900939941406,
      "learning_rate": 9.53994199841814e-06,
      "loss": 0.0224,
      "step": 9621
    },
    {
      "epoch": 0.5707675880887413,
      "grad_norm": 0.9047333598136902,
      "learning_rate": 9.538623780648565e-06,
      "loss": 0.0214,
      "step": 9622
    },
    {
      "epoch": 0.5708269071064184,
      "grad_norm": 0.27202531695365906,
      "learning_rate": 9.537305562878989e-06,
      "loss": 0.0029,
      "step": 9623
    },
    {
      "epoch": 0.5708862261240953,
      "grad_norm": 0.5357927680015564,
      "learning_rate": 9.535987345109413e-06,
      "loss": 0.0034,
      "step": 9624
    },
    {
      "epoch": 0.5709455451417724,
      "grad_norm": 16.017908096313477,
      "learning_rate": 9.534669127339837e-06,
      "loss": 1.386,
      "step": 9625
    },
    {
      "epoch": 0.5710048641594495,
      "grad_norm": 8.990694046020508,
      "learning_rate": 9.533350909570261e-06,
      "loss": 0.3677,
      "step": 9626
    },
    {
      "epoch": 0.5710641831771266,
      "grad_norm": 0.03213108703494072,
      "learning_rate": 9.532032691800687e-06,
      "loss": 0.0008,
      "step": 9627
    },
    {
      "epoch": 0.5711235021948037,
      "grad_norm": 0.994281530380249,
      "learning_rate": 9.530714474031111e-06,
      "loss": 0.0109,
      "step": 9628
    },
    {
      "epoch": 0.5711828212124808,
      "grad_norm": 10.46597957611084,
      "learning_rate": 9.529396256261536e-06,
      "loss": 0.5703,
      "step": 9629
    },
    {
      "epoch": 0.5712421402301577,
      "grad_norm": 6.837907791137695,
      "learning_rate": 9.52807803849196e-06,
      "loss": 0.305,
      "step": 9630
    },
    {
      "epoch": 0.5713014592478348,
      "grad_norm": 8.041889190673828,
      "learning_rate": 9.526759820722384e-06,
      "loss": 0.1995,
      "step": 9631
    },
    {
      "epoch": 0.5713607782655119,
      "grad_norm": 28.704118728637695,
      "learning_rate": 9.525441602952808e-06,
      "loss": 0.6382,
      "step": 9632
    },
    {
      "epoch": 0.571420097283189,
      "grad_norm": 0.20286257565021515,
      "learning_rate": 9.524123385183232e-06,
      "loss": 0.0022,
      "step": 9633
    },
    {
      "epoch": 0.5714794163008661,
      "grad_norm": 1.7919641733169556,
      "learning_rate": 9.522805167413658e-06,
      "loss": 0.0414,
      "step": 9634
    },
    {
      "epoch": 0.5715387353185432,
      "grad_norm": 1.1153323650360107,
      "learning_rate": 9.521486949644082e-06,
      "loss": 0.0154,
      "step": 9635
    },
    {
      "epoch": 0.5715980543362202,
      "grad_norm": 0.010575428605079651,
      "learning_rate": 9.520168731874507e-06,
      "loss": 0.0003,
      "step": 9636
    },
    {
      "epoch": 0.5716573733538972,
      "grad_norm": 2.5039451122283936,
      "learning_rate": 9.51885051410493e-06,
      "loss": 0.0273,
      "step": 9637
    },
    {
      "epoch": 0.5717166923715743,
      "grad_norm": 0.06702051311731339,
      "learning_rate": 9.517532296335355e-06,
      "loss": 0.0015,
      "step": 9638
    },
    {
      "epoch": 0.5717760113892514,
      "grad_norm": 1.042411208152771,
      "learning_rate": 9.516214078565779e-06,
      "loss": 0.0096,
      "step": 9639
    },
    {
      "epoch": 0.5718353304069285,
      "grad_norm": 1.768550992012024,
      "learning_rate": 9.514895860796203e-06,
      "loss": 0.015,
      "step": 9640
    },
    {
      "epoch": 0.5718946494246056,
      "grad_norm": 0.22455979883670807,
      "learning_rate": 9.51357764302663e-06,
      "loss": 0.0016,
      "step": 9641
    },
    {
      "epoch": 0.5719539684422826,
      "grad_norm": 6.51263427734375,
      "learning_rate": 9.512259425257053e-06,
      "loss": 0.1254,
      "step": 9642
    },
    {
      "epoch": 0.5720132874599597,
      "grad_norm": 6.664307594299316,
      "learning_rate": 9.510941207487478e-06,
      "loss": 0.0845,
      "step": 9643
    },
    {
      "epoch": 0.5720726064776367,
      "grad_norm": 0.033631615340709686,
      "learning_rate": 9.509622989717903e-06,
      "loss": 0.0003,
      "step": 9644
    },
    {
      "epoch": 0.5721319254953138,
      "grad_norm": 13.814606666564941,
      "learning_rate": 9.508304771948328e-06,
      "loss": 0.1953,
      "step": 9645
    },
    {
      "epoch": 0.5721912445129909,
      "grad_norm": 0.1123584434390068,
      "learning_rate": 9.50698655417875e-06,
      "loss": 0.0027,
      "step": 9646
    },
    {
      "epoch": 0.5722505635306679,
      "grad_norm": 1.4315125942230225,
      "learning_rate": 9.505668336409174e-06,
      "loss": 0.0268,
      "step": 9647
    },
    {
      "epoch": 0.572309882548345,
      "grad_norm": 18.400386810302734,
      "learning_rate": 9.5043501186396e-06,
      "loss": 0.2217,
      "step": 9648
    },
    {
      "epoch": 0.5723692015660221,
      "grad_norm": 0.0546967051923275,
      "learning_rate": 9.503031900870024e-06,
      "loss": 0.0012,
      "step": 9649
    },
    {
      "epoch": 0.5724285205836991,
      "grad_norm": 0.04628019034862518,
      "learning_rate": 9.501713683100449e-06,
      "loss": 0.001,
      "step": 9650
    },
    {
      "epoch": 0.5724878396013762,
      "grad_norm": 0.12364792078733444,
      "learning_rate": 9.500395465330874e-06,
      "loss": 0.0021,
      "step": 9651
    },
    {
      "epoch": 0.5725471586190533,
      "grad_norm": 8.77497386932373,
      "learning_rate": 9.499077247561299e-06,
      "loss": 0.4387,
      "step": 9652
    },
    {
      "epoch": 0.5726064776367303,
      "grad_norm": 0.09689899533987045,
      "learning_rate": 9.497759029791723e-06,
      "loss": 0.0022,
      "step": 9653
    },
    {
      "epoch": 0.5726657966544074,
      "grad_norm": 0.1808461844921112,
      "learning_rate": 9.496440812022147e-06,
      "loss": 0.0023,
      "step": 9654
    },
    {
      "epoch": 0.5727251156720845,
      "grad_norm": 0.013479668647050858,
      "learning_rate": 9.495122594252571e-06,
      "loss": 0.0005,
      "step": 9655
    },
    {
      "epoch": 0.5727844346897616,
      "grad_norm": 0.04579146206378937,
      "learning_rate": 9.493804376482995e-06,
      "loss": 0.0012,
      "step": 9656
    },
    {
      "epoch": 0.5728437537074386,
      "grad_norm": 0.14210213720798492,
      "learning_rate": 9.49248615871342e-06,
      "loss": 0.0017,
      "step": 9657
    },
    {
      "epoch": 0.5729030727251156,
      "grad_norm": 0.26326534152030945,
      "learning_rate": 9.491167940943845e-06,
      "loss": 0.0034,
      "step": 9658
    },
    {
      "epoch": 0.5729623917427927,
      "grad_norm": 1.2813044786453247,
      "learning_rate": 9.48984972317427e-06,
      "loss": 0.0142,
      "step": 9659
    },
    {
      "epoch": 0.5730217107604698,
      "grad_norm": 0.3110367953777313,
      "learning_rate": 9.488531505404694e-06,
      "loss": 0.0043,
      "step": 9660
    },
    {
      "epoch": 0.5730810297781469,
      "grad_norm": 1.0366193056106567,
      "learning_rate": 9.487213287635118e-06,
      "loss": 0.0124,
      "step": 9661
    },
    {
      "epoch": 0.573140348795824,
      "grad_norm": 0.9475212693214417,
      "learning_rate": 9.485895069865542e-06,
      "loss": 0.009,
      "step": 9662
    },
    {
      "epoch": 0.573199667813501,
      "grad_norm": 0.08191006630659103,
      "learning_rate": 9.484576852095966e-06,
      "loss": 0.0016,
      "step": 9663
    },
    {
      "epoch": 0.573258986831178,
      "grad_norm": 1.2392566204071045,
      "learning_rate": 9.48325863432639e-06,
      "loss": 0.0146,
      "step": 9664
    },
    {
      "epoch": 0.5733183058488551,
      "grad_norm": 13.751830101013184,
      "learning_rate": 9.481940416556816e-06,
      "loss": 0.3229,
      "step": 9665
    },
    {
      "epoch": 0.5733776248665322,
      "grad_norm": 0.3928864300251007,
      "learning_rate": 9.48062219878724e-06,
      "loss": 0.0064,
      "step": 9666
    },
    {
      "epoch": 0.5734369438842093,
      "grad_norm": 5.63209867477417,
      "learning_rate": 9.479303981017665e-06,
      "loss": 0.2204,
      "step": 9667
    },
    {
      "epoch": 0.5734962629018864,
      "grad_norm": 9.64083194732666,
      "learning_rate": 9.477985763248089e-06,
      "loss": 0.0843,
      "step": 9668
    },
    {
      "epoch": 0.5735555819195635,
      "grad_norm": 0.004895904567092657,
      "learning_rate": 9.476667545478513e-06,
      "loss": 0.0002,
      "step": 9669
    },
    {
      "epoch": 0.5736149009372404,
      "grad_norm": 0.2151816338300705,
      "learning_rate": 9.475349327708937e-06,
      "loss": 0.0025,
      "step": 9670
    },
    {
      "epoch": 0.5736742199549175,
      "grad_norm": 21.134477615356445,
      "learning_rate": 9.474031109939362e-06,
      "loss": 0.7093,
      "step": 9671
    },
    {
      "epoch": 0.5737335389725946,
      "grad_norm": 1.456666350364685,
      "learning_rate": 9.472712892169787e-06,
      "loss": 0.0275,
      "step": 9672
    },
    {
      "epoch": 0.5737928579902717,
      "grad_norm": 8.65091609954834,
      "learning_rate": 9.471394674400212e-06,
      "loss": 0.1086,
      "step": 9673
    },
    {
      "epoch": 0.5738521770079488,
      "grad_norm": 0.17762279510498047,
      "learning_rate": 9.470076456630636e-06,
      "loss": 0.0022,
      "step": 9674
    },
    {
      "epoch": 0.5739114960256259,
      "grad_norm": 0.1997089385986328,
      "learning_rate": 9.468758238861062e-06,
      "loss": 0.002,
      "step": 9675
    },
    {
      "epoch": 0.5739708150433028,
      "grad_norm": 28.123708724975586,
      "learning_rate": 9.467440021091486e-06,
      "loss": 0.195,
      "step": 9676
    },
    {
      "epoch": 0.5740301340609799,
      "grad_norm": 10.090803146362305,
      "learning_rate": 9.46612180332191e-06,
      "loss": 0.1228,
      "step": 9677
    },
    {
      "epoch": 0.574089453078657,
      "grad_norm": 20.291921615600586,
      "learning_rate": 9.464803585552334e-06,
      "loss": 0.4729,
      "step": 9678
    },
    {
      "epoch": 0.5741487720963341,
      "grad_norm": 2.7789254188537598,
      "learning_rate": 9.463485367782758e-06,
      "loss": 0.0251,
      "step": 9679
    },
    {
      "epoch": 0.5742080911140112,
      "grad_norm": 8.730467796325684,
      "learning_rate": 9.462167150013183e-06,
      "loss": 0.9841,
      "step": 9680
    },
    {
      "epoch": 0.5742674101316882,
      "grad_norm": 0.22507217526435852,
      "learning_rate": 9.460848932243607e-06,
      "loss": 0.0033,
      "step": 9681
    },
    {
      "epoch": 0.5743267291493653,
      "grad_norm": 5.248076438903809,
      "learning_rate": 9.459530714474033e-06,
      "loss": 0.0612,
      "step": 9682
    },
    {
      "epoch": 0.5743860481670423,
      "grad_norm": 5.007900238037109,
      "learning_rate": 9.458212496704457e-06,
      "loss": 0.0504,
      "step": 9683
    },
    {
      "epoch": 0.5744453671847194,
      "grad_norm": 11.663174629211426,
      "learning_rate": 9.456894278934881e-06,
      "loss": 0.3165,
      "step": 9684
    },
    {
      "epoch": 0.5745046862023965,
      "grad_norm": 9.16263198852539,
      "learning_rate": 9.455576061165305e-06,
      "loss": 0.0836,
      "step": 9685
    },
    {
      "epoch": 0.5745640052200736,
      "grad_norm": 0.9253851175308228,
      "learning_rate": 9.45425784339573e-06,
      "loss": 0.0095,
      "step": 9686
    },
    {
      "epoch": 0.5746233242377506,
      "grad_norm": 2.987653970718384,
      "learning_rate": 9.452939625626154e-06,
      "loss": 0.0234,
      "step": 9687
    },
    {
      "epoch": 0.5746826432554277,
      "grad_norm": 0.019511625170707703,
      "learning_rate": 9.451621407856578e-06,
      "loss": 0.0004,
      "step": 9688
    },
    {
      "epoch": 0.5747419622731048,
      "grad_norm": 19.711929321289062,
      "learning_rate": 9.450303190087004e-06,
      "loss": 0.1317,
      "step": 9689
    },
    {
      "epoch": 0.5748012812907818,
      "grad_norm": 15.523300170898438,
      "learning_rate": 9.448984972317428e-06,
      "loss": 0.5515,
      "step": 9690
    },
    {
      "epoch": 0.5748606003084589,
      "grad_norm": 0.03643544018268585,
      "learning_rate": 9.447666754547852e-06,
      "loss": 0.0006,
      "step": 9691
    },
    {
      "epoch": 0.574919919326136,
      "grad_norm": 1.823470950126648,
      "learning_rate": 9.446348536778276e-06,
      "loss": 0.0237,
      "step": 9692
    },
    {
      "epoch": 0.574979238343813,
      "grad_norm": 7.2120442390441895,
      "learning_rate": 9.4450303190087e-06,
      "loss": 0.04,
      "step": 9693
    },
    {
      "epoch": 0.5750385573614901,
      "grad_norm": 0.02904164418578148,
      "learning_rate": 9.443712101239125e-06,
      "loss": 0.0011,
      "step": 9694
    },
    {
      "epoch": 0.5750978763791672,
      "grad_norm": 20.469907760620117,
      "learning_rate": 9.442393883469549e-06,
      "loss": 0.1167,
      "step": 9695
    },
    {
      "epoch": 0.5751571953968442,
      "grad_norm": 7.955621242523193,
      "learning_rate": 9.441075665699975e-06,
      "loss": 0.8264,
      "step": 9696
    },
    {
      "epoch": 0.5752165144145213,
      "grad_norm": 0.02045484073460102,
      "learning_rate": 9.439757447930399e-06,
      "loss": 0.0004,
      "step": 9697
    },
    {
      "epoch": 0.5752758334321983,
      "grad_norm": 5.138143539428711,
      "learning_rate": 9.438439230160823e-06,
      "loss": 0.0243,
      "step": 9698
    },
    {
      "epoch": 0.5753351524498754,
      "grad_norm": 16.26070785522461,
      "learning_rate": 9.437121012391249e-06,
      "loss": 0.2026,
      "step": 9699
    },
    {
      "epoch": 0.5753944714675525,
      "grad_norm": 0.6144748330116272,
      "learning_rate": 9.435802794621673e-06,
      "loss": 0.0058,
      "step": 9700
    },
    {
      "epoch": 0.5754537904852296,
      "grad_norm": 0.28554677963256836,
      "learning_rate": 9.434484576852096e-06,
      "loss": 0.001,
      "step": 9701
    },
    {
      "epoch": 0.5755131095029067,
      "grad_norm": 0.020093552768230438,
      "learning_rate": 9.43316635908252e-06,
      "loss": 0.0003,
      "step": 9702
    },
    {
      "epoch": 0.5755724285205837,
      "grad_norm": 0.08781129121780396,
      "learning_rate": 9.431848141312946e-06,
      "loss": 0.0005,
      "step": 9703
    },
    {
      "epoch": 0.5756317475382607,
      "grad_norm": 0.43118250370025635,
      "learning_rate": 9.43052992354337e-06,
      "loss": 0.0046,
      "step": 9704
    },
    {
      "epoch": 0.5756910665559378,
      "grad_norm": 10.894745826721191,
      "learning_rate": 9.429211705773794e-06,
      "loss": 0.3054,
      "step": 9705
    },
    {
      "epoch": 0.5757503855736149,
      "grad_norm": 0.15763796865940094,
      "learning_rate": 9.42789348800422e-06,
      "loss": 0.0033,
      "step": 9706
    },
    {
      "epoch": 0.575809704591292,
      "grad_norm": 5.33260440826416,
      "learning_rate": 9.426575270234644e-06,
      "loss": 0.0721,
      "step": 9707
    },
    {
      "epoch": 0.5758690236089691,
      "grad_norm": 11.971549034118652,
      "learning_rate": 9.425257052465068e-06,
      "loss": 0.5643,
      "step": 9708
    },
    {
      "epoch": 0.575928342626646,
      "grad_norm": 4.102314472198486,
      "learning_rate": 9.423938834695493e-06,
      "loss": 0.0163,
      "step": 9709
    },
    {
      "epoch": 0.5759876616443231,
      "grad_norm": 0.04378316551446915,
      "learning_rate": 9.422620616925917e-06,
      "loss": 0.0005,
      "step": 9710
    },
    {
      "epoch": 0.5760469806620002,
      "grad_norm": 0.03882031515240669,
      "learning_rate": 9.421302399156341e-06,
      "loss": 0.0007,
      "step": 9711
    },
    {
      "epoch": 0.5761062996796773,
      "grad_norm": 0.016756979748606682,
      "learning_rate": 9.419984181386765e-06,
      "loss": 0.0004,
      "step": 9712
    },
    {
      "epoch": 0.5761656186973544,
      "grad_norm": 1.2995400428771973,
      "learning_rate": 9.418665963617191e-06,
      "loss": 0.0039,
      "step": 9713
    },
    {
      "epoch": 0.5762249377150315,
      "grad_norm": 0.010451501235365868,
      "learning_rate": 9.417347745847615e-06,
      "loss": 0.0002,
      "step": 9714
    },
    {
      "epoch": 0.5762842567327086,
      "grad_norm": 8.769490242004395,
      "learning_rate": 9.41602952807804e-06,
      "loss": 0.3096,
      "step": 9715
    },
    {
      "epoch": 0.5763435757503855,
      "grad_norm": 0.1586349606513977,
      "learning_rate": 9.414711310308464e-06,
      "loss": 0.0024,
      "step": 9716
    },
    {
      "epoch": 0.5764028947680626,
      "grad_norm": 0.13511215150356293,
      "learning_rate": 9.413393092538888e-06,
      "loss": 0.0007,
      "step": 9717
    },
    {
      "epoch": 0.5764622137857397,
      "grad_norm": 3.3239452838897705,
      "learning_rate": 9.412074874769312e-06,
      "loss": 0.0204,
      "step": 9718
    },
    {
      "epoch": 0.5765215328034168,
      "grad_norm": 0.008911209180951118,
      "learning_rate": 9.410756656999736e-06,
      "loss": 0.0003,
      "step": 9719
    },
    {
      "epoch": 0.5765808518210939,
      "grad_norm": 8.95073127746582,
      "learning_rate": 9.409438439230162e-06,
      "loss": 0.0802,
      "step": 9720
    },
    {
      "epoch": 0.576640170838771,
      "grad_norm": 1.6730883121490479,
      "learning_rate": 9.408120221460586e-06,
      "loss": 0.0157,
      "step": 9721
    },
    {
      "epoch": 0.5766994898564479,
      "grad_norm": 0.6762014031410217,
      "learning_rate": 9.40680200369101e-06,
      "loss": 0.0115,
      "step": 9722
    },
    {
      "epoch": 0.576758808874125,
      "grad_norm": 0.4028650224208832,
      "learning_rate": 9.405483785921436e-06,
      "loss": 0.0039,
      "step": 9723
    },
    {
      "epoch": 0.5768181278918021,
      "grad_norm": 8.840126991271973,
      "learning_rate": 9.404165568151859e-06,
      "loss": 0.0975,
      "step": 9724
    },
    {
      "epoch": 0.5768774469094792,
      "grad_norm": 0.9255788922309875,
      "learning_rate": 9.402847350382283e-06,
      "loss": 0.01,
      "step": 9725
    },
    {
      "epoch": 0.5769367659271563,
      "grad_norm": 7.682030200958252,
      "learning_rate": 9.401529132612709e-06,
      "loss": 0.2642,
      "step": 9726
    },
    {
      "epoch": 0.5769960849448333,
      "grad_norm": 32.806243896484375,
      "learning_rate": 9.400210914843133e-06,
      "loss": 1.3439,
      "step": 9727
    },
    {
      "epoch": 0.5770554039625104,
      "grad_norm": 4.5183939933776855,
      "learning_rate": 9.398892697073557e-06,
      "loss": 0.5018,
      "step": 9728
    },
    {
      "epoch": 0.5771147229801874,
      "grad_norm": 0.6467530727386475,
      "learning_rate": 9.397574479303981e-06,
      "loss": 0.009,
      "step": 9729
    },
    {
      "epoch": 0.5771740419978645,
      "grad_norm": 0.008176112547516823,
      "learning_rate": 9.396256261534407e-06,
      "loss": 0.0002,
      "step": 9730
    },
    {
      "epoch": 0.5772333610155416,
      "grad_norm": 8.853635787963867,
      "learning_rate": 9.394938043764831e-06,
      "loss": 0.0673,
      "step": 9731
    },
    {
      "epoch": 0.5772926800332187,
      "grad_norm": 10.030387878417969,
      "learning_rate": 9.393619825995256e-06,
      "loss": 0.0722,
      "step": 9732
    },
    {
      "epoch": 0.5773519990508957,
      "grad_norm": 14.066851615905762,
      "learning_rate": 9.39230160822568e-06,
      "loss": 0.7005,
      "step": 9733
    },
    {
      "epoch": 0.5774113180685728,
      "grad_norm": 1.4074397087097168,
      "learning_rate": 9.390983390456104e-06,
      "loss": 0.009,
      "step": 9734
    },
    {
      "epoch": 0.5774706370862499,
      "grad_norm": 14.21012020111084,
      "learning_rate": 9.389665172686528e-06,
      "loss": 0.6268,
      "step": 9735
    },
    {
      "epoch": 0.5775299561039269,
      "grad_norm": 0.2616395056247711,
      "learning_rate": 9.388346954916952e-06,
      "loss": 0.0042,
      "step": 9736
    },
    {
      "epoch": 0.577589275121604,
      "grad_norm": 3.5225026607513428,
      "learning_rate": 9.387028737147378e-06,
      "loss": 0.0802,
      "step": 9737
    },
    {
      "epoch": 0.577648594139281,
      "grad_norm": 8.334811210632324,
      "learning_rate": 9.385710519377802e-06,
      "loss": 0.0914,
      "step": 9738
    },
    {
      "epoch": 0.5777079131569581,
      "grad_norm": 0.01344746071845293,
      "learning_rate": 9.384392301608227e-06,
      "loss": 0.0003,
      "step": 9739
    },
    {
      "epoch": 0.5777672321746352,
      "grad_norm": 0.14594516158103943,
      "learning_rate": 9.38307408383865e-06,
      "loss": 0.0018,
      "step": 9740
    },
    {
      "epoch": 0.5778265511923123,
      "grad_norm": 0.6361384987831116,
      "learning_rate": 9.381755866069075e-06,
      "loss": 0.0089,
      "step": 9741
    },
    {
      "epoch": 0.5778858702099893,
      "grad_norm": 2.6079907417297363,
      "learning_rate": 9.3804376482995e-06,
      "loss": 0.0569,
      "step": 9742
    },
    {
      "epoch": 0.5779451892276664,
      "grad_norm": 0.29816174507141113,
      "learning_rate": 9.379119430529923e-06,
      "loss": 0.0024,
      "step": 9743
    },
    {
      "epoch": 0.5780045082453434,
      "grad_norm": 1.3706058263778687,
      "learning_rate": 9.37780121276035e-06,
      "loss": 0.005,
      "step": 9744
    },
    {
      "epoch": 0.5780638272630205,
      "grad_norm": 5.9026923179626465,
      "learning_rate": 9.376482994990773e-06,
      "loss": 0.065,
      "step": 9745
    },
    {
      "epoch": 0.5781231462806976,
      "grad_norm": 54.39182662963867,
      "learning_rate": 9.375164777221198e-06,
      "loss": 0.1606,
      "step": 9746
    },
    {
      "epoch": 0.5781824652983747,
      "grad_norm": 7.476098537445068,
      "learning_rate": 9.373846559451622e-06,
      "loss": 0.455,
      "step": 9747
    },
    {
      "epoch": 0.5782417843160518,
      "grad_norm": 0.05129692330956459,
      "learning_rate": 9.372528341682046e-06,
      "loss": 0.0007,
      "step": 9748
    },
    {
      "epoch": 0.5783011033337287,
      "grad_norm": 58.147216796875,
      "learning_rate": 9.37121012391247e-06,
      "loss": 0.7227,
      "step": 9749
    },
    {
      "epoch": 0.5783604223514058,
      "grad_norm": 0.018690094351768494,
      "learning_rate": 9.369891906142896e-06,
      "loss": 0.0005,
      "step": 9750
    },
    {
      "epoch": 0.5784197413690829,
      "grad_norm": 3.5320675373077393,
      "learning_rate": 9.36857368837332e-06,
      "loss": 0.0727,
      "step": 9751
    },
    {
      "epoch": 0.57847906038676,
      "grad_norm": 0.0729779526591301,
      "learning_rate": 9.367255470603744e-06,
      "loss": 0.0014,
      "step": 9752
    },
    {
      "epoch": 0.5785383794044371,
      "grad_norm": 14.729598999023438,
      "learning_rate": 9.365937252834169e-06,
      "loss": 0.1112,
      "step": 9753
    },
    {
      "epoch": 0.5785976984221142,
      "grad_norm": 7.002166748046875,
      "learning_rate": 9.364619035064595e-06,
      "loss": 0.153,
      "step": 9754
    },
    {
      "epoch": 0.5786570174397911,
      "grad_norm": 0.7516993284225464,
      "learning_rate": 9.363300817295019e-06,
      "loss": 0.0057,
      "step": 9755
    },
    {
      "epoch": 0.5787163364574682,
      "grad_norm": 1.5743790864944458,
      "learning_rate": 9.361982599525443e-06,
      "loss": 0.0333,
      "step": 9756
    },
    {
      "epoch": 0.5787756554751453,
      "grad_norm": 1.3462146520614624,
      "learning_rate": 9.360664381755867e-06,
      "loss": 0.0158,
      "step": 9757
    },
    {
      "epoch": 0.5788349744928224,
      "grad_norm": 0.018773389980196953,
      "learning_rate": 9.359346163986291e-06,
      "loss": 0.0005,
      "step": 9758
    },
    {
      "epoch": 0.5788942935104995,
      "grad_norm": 7.471104621887207,
      "learning_rate": 9.358027946216715e-06,
      "loss": 0.2046,
      "step": 9759
    },
    {
      "epoch": 0.5789536125281766,
      "grad_norm": 0.12545950710773468,
      "learning_rate": 9.35670972844714e-06,
      "loss": 0.0014,
      "step": 9760
    },
    {
      "epoch": 0.5790129315458536,
      "grad_norm": 13.470907211303711,
      "learning_rate": 9.355391510677566e-06,
      "loss": 0.2773,
      "step": 9761
    },
    {
      "epoch": 0.5790722505635306,
      "grad_norm": 0.01210475992411375,
      "learning_rate": 9.35407329290799e-06,
      "loss": 0.0003,
      "step": 9762
    },
    {
      "epoch": 0.5791315695812077,
      "grad_norm": 0.20655684173107147,
      "learning_rate": 9.352755075138414e-06,
      "loss": 0.0032,
      "step": 9763
    },
    {
      "epoch": 0.5791908885988848,
      "grad_norm": 0.41022035479545593,
      "learning_rate": 9.351436857368838e-06,
      "loss": 0.0091,
      "step": 9764
    },
    {
      "epoch": 0.5792502076165619,
      "grad_norm": 1.3550333976745605,
      "learning_rate": 9.350118639599262e-06,
      "loss": 0.0203,
      "step": 9765
    },
    {
      "epoch": 0.579309526634239,
      "grad_norm": 22.689647674560547,
      "learning_rate": 9.348800421829686e-06,
      "loss": 1.148,
      "step": 9766
    },
    {
      "epoch": 0.579368845651916,
      "grad_norm": 25.49839210510254,
      "learning_rate": 9.34748220406011e-06,
      "loss": 0.3297,
      "step": 9767
    },
    {
      "epoch": 0.5794281646695931,
      "grad_norm": 0.9457220435142517,
      "learning_rate": 9.346163986290537e-06,
      "loss": 0.0193,
      "step": 9768
    },
    {
      "epoch": 0.5794874836872701,
      "grad_norm": 10.35243034362793,
      "learning_rate": 9.34484576852096e-06,
      "loss": 0.1092,
      "step": 9769
    },
    {
      "epoch": 0.5795468027049472,
      "grad_norm": 0.01494911964982748,
      "learning_rate": 9.343527550751385e-06,
      "loss": 0.0004,
      "step": 9770
    },
    {
      "epoch": 0.5796061217226243,
      "grad_norm": 0.025223182514309883,
      "learning_rate": 9.342209332981809e-06,
      "loss": 0.0004,
      "step": 9771
    },
    {
      "epoch": 0.5796654407403014,
      "grad_norm": 0.3058357834815979,
      "learning_rate": 9.340891115212233e-06,
      "loss": 0.0049,
      "step": 9772
    },
    {
      "epoch": 0.5797247597579784,
      "grad_norm": 0.026082633063197136,
      "learning_rate": 9.339572897442657e-06,
      "loss": 0.0006,
      "step": 9773
    },
    {
      "epoch": 0.5797840787756555,
      "grad_norm": 5.095308780670166,
      "learning_rate": 9.338254679673083e-06,
      "loss": 0.0776,
      "step": 9774
    },
    {
      "epoch": 0.5798433977933325,
      "grad_norm": 6.485548496246338,
      "learning_rate": 9.336936461903508e-06,
      "loss": 0.4951,
      "step": 9775
    },
    {
      "epoch": 0.5799027168110096,
      "grad_norm": 37.822750091552734,
      "learning_rate": 9.335618244133932e-06,
      "loss": 1.4905,
      "step": 9776
    },
    {
      "epoch": 0.5799620358286867,
      "grad_norm": 0.40092238783836365,
      "learning_rate": 9.334300026364356e-06,
      "loss": 0.0033,
      "step": 9777
    },
    {
      "epoch": 0.5800213548463637,
      "grad_norm": 0.013853638432919979,
      "learning_rate": 9.332981808594782e-06,
      "loss": 0.0003,
      "step": 9778
    },
    {
      "epoch": 0.5800806738640408,
      "grad_norm": 0.06913267821073532,
      "learning_rate": 9.331663590825204e-06,
      "loss": 0.0013,
      "step": 9779
    },
    {
      "epoch": 0.5801399928817179,
      "grad_norm": 7.225592136383057,
      "learning_rate": 9.330345373055628e-06,
      "loss": 0.1566,
      "step": 9780
    },
    {
      "epoch": 0.580199311899395,
      "grad_norm": 0.016119038686156273,
      "learning_rate": 9.329027155286054e-06,
      "loss": 0.0002,
      "step": 9781
    },
    {
      "epoch": 0.580258630917072,
      "grad_norm": 8.072907447814941,
      "learning_rate": 9.327708937516479e-06,
      "loss": 0.5036,
      "step": 9782
    },
    {
      "epoch": 0.5803179499347491,
      "grad_norm": 0.010269859805703163,
      "learning_rate": 9.326390719746903e-06,
      "loss": 0.0003,
      "step": 9783
    },
    {
      "epoch": 0.5803772689524261,
      "grad_norm": 0.2794373631477356,
      "learning_rate": 9.325072501977327e-06,
      "loss": 0.0035,
      "step": 9784
    },
    {
      "epoch": 0.5804365879701032,
      "grad_norm": 0.20217497646808624,
      "learning_rate": 9.323754284207753e-06,
      "loss": 0.0025,
      "step": 9785
    },
    {
      "epoch": 0.5804959069877803,
      "grad_norm": 1.7080072164535522,
      "learning_rate": 9.322436066438177e-06,
      "loss": 0.0152,
      "step": 9786
    },
    {
      "epoch": 0.5805552260054574,
      "grad_norm": 0.08160851895809174,
      "learning_rate": 9.321117848668601e-06,
      "loss": 0.0016,
      "step": 9787
    },
    {
      "epoch": 0.5806145450231344,
      "grad_norm": 2.218492031097412,
      "learning_rate": 9.319799630899025e-06,
      "loss": 0.0145,
      "step": 9788
    },
    {
      "epoch": 0.5806738640408114,
      "grad_norm": 19.2749080657959,
      "learning_rate": 9.31848141312945e-06,
      "loss": 0.2195,
      "step": 9789
    },
    {
      "epoch": 0.5807331830584885,
      "grad_norm": 4.11622428894043,
      "learning_rate": 9.317163195359874e-06,
      "loss": 0.3216,
      "step": 9790
    },
    {
      "epoch": 0.5807925020761656,
      "grad_norm": 30.68130874633789,
      "learning_rate": 9.315844977590298e-06,
      "loss": 0.4609,
      "step": 9791
    },
    {
      "epoch": 0.5808518210938427,
      "grad_norm": 0.6348788738250732,
      "learning_rate": 9.314526759820724e-06,
      "loss": 0.0113,
      "step": 9792
    },
    {
      "epoch": 0.5809111401115198,
      "grad_norm": 0.014231759123504162,
      "learning_rate": 9.313208542051148e-06,
      "loss": 0.0003,
      "step": 9793
    },
    {
      "epoch": 0.5809704591291969,
      "grad_norm": 0.006038305349647999,
      "learning_rate": 9.311890324281572e-06,
      "loss": 0.0002,
      "step": 9794
    },
    {
      "epoch": 0.5810297781468738,
      "grad_norm": 8.99130630493164,
      "learning_rate": 9.310572106511996e-06,
      "loss": 0.3063,
      "step": 9795
    },
    {
      "epoch": 0.5810890971645509,
      "grad_norm": 26.875041961669922,
      "learning_rate": 9.30925388874242e-06,
      "loss": 1.3038,
      "step": 9796
    },
    {
      "epoch": 0.581148416182228,
      "grad_norm": 15.898311614990234,
      "learning_rate": 9.307935670972845e-06,
      "loss": 0.233,
      "step": 9797
    },
    {
      "epoch": 0.5812077351999051,
      "grad_norm": 0.04920503497123718,
      "learning_rate": 9.30661745320327e-06,
      "loss": 0.0009,
      "step": 9798
    },
    {
      "epoch": 0.5812670542175822,
      "grad_norm": 1.7639447450637817,
      "learning_rate": 9.305299235433695e-06,
      "loss": 0.0162,
      "step": 9799
    },
    {
      "epoch": 0.5813263732352593,
      "grad_norm": 10.148460388183594,
      "learning_rate": 9.303981017664119e-06,
      "loss": 0.5086,
      "step": 9800
    },
    {
      "epoch": 0.5813856922529362,
      "grad_norm": 13.008389472961426,
      "learning_rate": 9.302662799894543e-06,
      "loss": 0.6392,
      "step": 9801
    },
    {
      "epoch": 0.5814450112706133,
      "grad_norm": 0.0063374531455338,
      "learning_rate": 9.301344582124967e-06,
      "loss": 0.0002,
      "step": 9802
    },
    {
      "epoch": 0.5815043302882904,
      "grad_norm": 0.21685178577899933,
      "learning_rate": 9.300026364355392e-06,
      "loss": 0.0048,
      "step": 9803
    },
    {
      "epoch": 0.5815636493059675,
      "grad_norm": 14.429193496704102,
      "learning_rate": 9.298708146585816e-06,
      "loss": 1.4814,
      "step": 9804
    },
    {
      "epoch": 0.5816229683236446,
      "grad_norm": 3.8898978233337402,
      "learning_rate": 9.297389928816242e-06,
      "loss": 0.0267,
      "step": 9805
    },
    {
      "epoch": 0.5816822873413217,
      "grad_norm": 1.3581607341766357,
      "learning_rate": 9.296071711046666e-06,
      "loss": 0.017,
      "step": 9806
    },
    {
      "epoch": 0.5817416063589987,
      "grad_norm": 12.23101806640625,
      "learning_rate": 9.29475349327709e-06,
      "loss": 0.2603,
      "step": 9807
    },
    {
      "epoch": 0.5818009253766757,
      "grad_norm": 17.549819946289062,
      "learning_rate": 9.293435275507514e-06,
      "loss": 0.3816,
      "step": 9808
    },
    {
      "epoch": 0.5818602443943528,
      "grad_norm": 0.013826688751578331,
      "learning_rate": 9.29211705773794e-06,
      "loss": 0.0004,
      "step": 9809
    },
    {
      "epoch": 0.5819195634120299,
      "grad_norm": 0.7570182085037231,
      "learning_rate": 9.290798839968364e-06,
      "loss": 0.0056,
      "step": 9810
    },
    {
      "epoch": 0.581978882429707,
      "grad_norm": 0.018776170909404755,
      "learning_rate": 9.289480622198788e-06,
      "loss": 0.0005,
      "step": 9811
    },
    {
      "epoch": 0.582038201447384,
      "grad_norm": 9.203617095947266,
      "learning_rate": 9.288162404429213e-06,
      "loss": 0.4323,
      "step": 9812
    },
    {
      "epoch": 0.5820975204650611,
      "grad_norm": 2.04996657371521,
      "learning_rate": 9.286844186659637e-06,
      "loss": 0.0158,
      "step": 9813
    },
    {
      "epoch": 0.5821568394827382,
      "grad_norm": 0.06872237473726273,
      "learning_rate": 9.285525968890061e-06,
      "loss": 0.0013,
      "step": 9814
    },
    {
      "epoch": 0.5822161585004152,
      "grad_norm": 28.420917510986328,
      "learning_rate": 9.284207751120485e-06,
      "loss": 0.3505,
      "step": 9815
    },
    {
      "epoch": 0.5822754775180923,
      "grad_norm": 0.015653692185878754,
      "learning_rate": 9.282889533350911e-06,
      "loss": 0.0004,
      "step": 9816
    },
    {
      "epoch": 0.5823347965357694,
      "grad_norm": 18.820642471313477,
      "learning_rate": 9.281571315581335e-06,
      "loss": 0.9296,
      "step": 9817
    },
    {
      "epoch": 0.5823941155534464,
      "grad_norm": 0.007445068564265966,
      "learning_rate": 9.28025309781176e-06,
      "loss": 0.0002,
      "step": 9818
    },
    {
      "epoch": 0.5824534345711235,
      "grad_norm": 16.950275421142578,
      "learning_rate": 9.278934880042184e-06,
      "loss": 0.1681,
      "step": 9819
    },
    {
      "epoch": 0.5825127535888006,
      "grad_norm": 0.013191206380724907,
      "learning_rate": 9.277616662272608e-06,
      "loss": 0.0004,
      "step": 9820
    },
    {
      "epoch": 0.5825720726064776,
      "grad_norm": 7.123395919799805,
      "learning_rate": 9.276298444503032e-06,
      "loss": 0.1589,
      "step": 9821
    },
    {
      "epoch": 0.5826313916241547,
      "grad_norm": 0.02216540463268757,
      "learning_rate": 9.274980226733458e-06,
      "loss": 0.0005,
      "step": 9822
    },
    {
      "epoch": 0.5826907106418318,
      "grad_norm": 5.410620212554932,
      "learning_rate": 9.273662008963882e-06,
      "loss": 0.0506,
      "step": 9823
    },
    {
      "epoch": 0.5827500296595088,
      "grad_norm": 9.602282524108887,
      "learning_rate": 9.272343791194306e-06,
      "loss": 0.2671,
      "step": 9824
    },
    {
      "epoch": 0.5828093486771859,
      "grad_norm": 2.1207921504974365,
      "learning_rate": 9.27102557342473e-06,
      "loss": 0.0339,
      "step": 9825
    },
    {
      "epoch": 0.582868667694863,
      "grad_norm": 0.4043663442134857,
      "learning_rate": 9.269707355655155e-06,
      "loss": 0.0046,
      "step": 9826
    },
    {
      "epoch": 0.5829279867125401,
      "grad_norm": 6.011895179748535,
      "learning_rate": 9.268389137885579e-06,
      "loss": 0.1852,
      "step": 9827
    },
    {
      "epoch": 0.5829873057302171,
      "grad_norm": 0.326442152261734,
      "learning_rate": 9.267070920116003e-06,
      "loss": 0.0019,
      "step": 9828
    },
    {
      "epoch": 0.5830466247478941,
      "grad_norm": 0.07746542245149612,
      "learning_rate": 9.265752702346429e-06,
      "loss": 0.0018,
      "step": 9829
    },
    {
      "epoch": 0.5831059437655712,
      "grad_norm": 13.999334335327148,
      "learning_rate": 9.264434484576853e-06,
      "loss": 0.1731,
      "step": 9830
    },
    {
      "epoch": 0.5831652627832483,
      "grad_norm": 79.0460433959961,
      "learning_rate": 9.263116266807277e-06,
      "loss": 0.2436,
      "step": 9831
    },
    {
      "epoch": 0.5832245818009254,
      "grad_norm": 0.0188364926725626,
      "learning_rate": 9.261798049037701e-06,
      "loss": 0.0003,
      "step": 9832
    },
    {
      "epoch": 0.5832839008186025,
      "grad_norm": 5.733943939208984,
      "learning_rate": 9.260479831268127e-06,
      "loss": 0.0522,
      "step": 9833
    },
    {
      "epoch": 0.5833432198362795,
      "grad_norm": 0.5665681958198547,
      "learning_rate": 9.259161613498552e-06,
      "loss": 0.0068,
      "step": 9834
    },
    {
      "epoch": 0.5834025388539565,
      "grad_norm": 0.06071227416396141,
      "learning_rate": 9.257843395728974e-06,
      "loss": 0.0009,
      "step": 9835
    },
    {
      "epoch": 0.5834618578716336,
      "grad_norm": 0.16873390972614288,
      "learning_rate": 9.2565251779594e-06,
      "loss": 0.001,
      "step": 9836
    },
    {
      "epoch": 0.5835211768893107,
      "grad_norm": 0.03837304934859276,
      "learning_rate": 9.255206960189824e-06,
      "loss": 0.0006,
      "step": 9837
    },
    {
      "epoch": 0.5835804959069878,
      "grad_norm": 16.50166893005371,
      "learning_rate": 9.253888742420248e-06,
      "loss": 0.6832,
      "step": 9838
    },
    {
      "epoch": 0.5836398149246649,
      "grad_norm": 0.47650912404060364,
      "learning_rate": 9.252570524650672e-06,
      "loss": 0.0019,
      "step": 9839
    },
    {
      "epoch": 0.583699133942342,
      "grad_norm": 12.194756507873535,
      "learning_rate": 9.251252306881098e-06,
      "loss": 0.6748,
      "step": 9840
    },
    {
      "epoch": 0.5837584529600189,
      "grad_norm": 13.295665740966797,
      "learning_rate": 9.249934089111523e-06,
      "loss": 0.0373,
      "step": 9841
    },
    {
      "epoch": 0.583817771977696,
      "grad_norm": 3.142256498336792,
      "learning_rate": 9.248615871341947e-06,
      "loss": 0.0601,
      "step": 9842
    },
    {
      "epoch": 0.5838770909953731,
      "grad_norm": 0.009477713145315647,
      "learning_rate": 9.247297653572371e-06,
      "loss": 0.0003,
      "step": 9843
    },
    {
      "epoch": 0.5839364100130502,
      "grad_norm": 4.398242473602295,
      "learning_rate": 9.245979435802795e-06,
      "loss": 0.2059,
      "step": 9844
    },
    {
      "epoch": 0.5839957290307273,
      "grad_norm": 0.1574692279100418,
      "learning_rate": 9.24466121803322e-06,
      "loss": 0.0017,
      "step": 9845
    },
    {
      "epoch": 0.5840550480484044,
      "grad_norm": 1.3140186071395874,
      "learning_rate": 9.243343000263645e-06,
      "loss": 0.0103,
      "step": 9846
    },
    {
      "epoch": 0.5841143670660813,
      "grad_norm": 2.4683523178100586,
      "learning_rate": 9.24202478249407e-06,
      "loss": 0.013,
      "step": 9847
    },
    {
      "epoch": 0.5841736860837584,
      "grad_norm": 0.4998190402984619,
      "learning_rate": 9.240706564724494e-06,
      "loss": 0.0057,
      "step": 9848
    },
    {
      "epoch": 0.5842330051014355,
      "grad_norm": 119.95037078857422,
      "learning_rate": 9.239388346954918e-06,
      "loss": 0.3149,
      "step": 9849
    },
    {
      "epoch": 0.5842923241191126,
      "grad_norm": 0.1750985085964203,
      "learning_rate": 9.238070129185342e-06,
      "loss": 0.0023,
      "step": 9850
    },
    {
      "epoch": 0.5843516431367897,
      "grad_norm": 0.009269357658922672,
      "learning_rate": 9.236751911415766e-06,
      "loss": 0.0003,
      "step": 9851
    },
    {
      "epoch": 0.5844109621544668,
      "grad_norm": 0.04281289130449295,
      "learning_rate": 9.23543369364619e-06,
      "loss": 0.001,
      "step": 9852
    },
    {
      "epoch": 0.5844702811721438,
      "grad_norm": 4.586974143981934,
      "learning_rate": 9.234115475876616e-06,
      "loss": 0.0345,
      "step": 9853
    },
    {
      "epoch": 0.5845296001898208,
      "grad_norm": 0.03551146760582924,
      "learning_rate": 9.23279725810704e-06,
      "loss": 0.0008,
      "step": 9854
    },
    {
      "epoch": 0.5845889192074979,
      "grad_norm": 0.13577038049697876,
      "learning_rate": 9.231479040337465e-06,
      "loss": 0.0019,
      "step": 9855
    },
    {
      "epoch": 0.584648238225175,
      "grad_norm": 5.954051971435547,
      "learning_rate": 9.230160822567889e-06,
      "loss": 0.0933,
      "step": 9856
    },
    {
      "epoch": 0.5847075572428521,
      "grad_norm": 4.987928867340088,
      "learning_rate": 9.228842604798313e-06,
      "loss": 0.0756,
      "step": 9857
    },
    {
      "epoch": 0.5847668762605291,
      "grad_norm": 0.019663413986563683,
      "learning_rate": 9.227524387028737e-06,
      "loss": 0.0004,
      "step": 9858
    },
    {
      "epoch": 0.5848261952782062,
      "grad_norm": 10.737298965454102,
      "learning_rate": 9.226206169259161e-06,
      "loss": 0.157,
      "step": 9859
    },
    {
      "epoch": 0.5848855142958833,
      "grad_norm": 4.660739421844482,
      "learning_rate": 9.224887951489587e-06,
      "loss": 0.0357,
      "step": 9860
    },
    {
      "epoch": 0.5849448333135603,
      "grad_norm": 0.06109089031815529,
      "learning_rate": 9.223569733720011e-06,
      "loss": 0.0014,
      "step": 9861
    },
    {
      "epoch": 0.5850041523312374,
      "grad_norm": 0.0356336310505867,
      "learning_rate": 9.222251515950436e-06,
      "loss": 0.0008,
      "step": 9862
    },
    {
      "epoch": 0.5850634713489145,
      "grad_norm": 0.15548990666866302,
      "learning_rate": 9.22093329818086e-06,
      "loss": 0.0023,
      "step": 9863
    },
    {
      "epoch": 0.5851227903665915,
      "grad_norm": 14.626120567321777,
      "learning_rate": 9.219615080411286e-06,
      "loss": 0.5284,
      "step": 9864
    },
    {
      "epoch": 0.5851821093842686,
      "grad_norm": 1.2069480419158936,
      "learning_rate": 9.21829686264171e-06,
      "loss": 0.0078,
      "step": 9865
    },
    {
      "epoch": 0.5852414284019457,
      "grad_norm": 1.7821061611175537,
      "learning_rate": 9.216978644872134e-06,
      "loss": 0.0199,
      "step": 9866
    },
    {
      "epoch": 0.5853007474196227,
      "grad_norm": 7.726004600524902,
      "learning_rate": 9.215660427102558e-06,
      "loss": 0.1187,
      "step": 9867
    },
    {
      "epoch": 0.5853600664372998,
      "grad_norm": 0.03676015883684158,
      "learning_rate": 9.214342209332982e-06,
      "loss": 0.0007,
      "step": 9868
    },
    {
      "epoch": 0.5854193854549768,
      "grad_norm": 2.943617105484009,
      "learning_rate": 9.213023991563407e-06,
      "loss": 0.0188,
      "step": 9869
    },
    {
      "epoch": 0.5854787044726539,
      "grad_norm": 0.2051321119070053,
      "learning_rate": 9.211705773793832e-06,
      "loss": 0.0041,
      "step": 9870
    },
    {
      "epoch": 0.585538023490331,
      "grad_norm": 10.177398681640625,
      "learning_rate": 9.210387556024257e-06,
      "loss": 0.0613,
      "step": 9871
    },
    {
      "epoch": 0.5855973425080081,
      "grad_norm": 6.201839447021484,
      "learning_rate": 9.20906933825468e-06,
      "loss": 0.1122,
      "step": 9872
    },
    {
      "epoch": 0.5856566615256852,
      "grad_norm": 17.972007751464844,
      "learning_rate": 9.207751120485105e-06,
      "loss": 0.0397,
      "step": 9873
    },
    {
      "epoch": 0.5857159805433622,
      "grad_norm": 0.6923136115074158,
      "learning_rate": 9.20643290271553e-06,
      "loss": 0.0046,
      "step": 9874
    },
    {
      "epoch": 0.5857752995610392,
      "grad_norm": 0.1002890095114708,
      "learning_rate": 9.205114684945953e-06,
      "loss": 0.0024,
      "step": 9875
    },
    {
      "epoch": 0.5858346185787163,
      "grad_norm": 0.014172066934406757,
      "learning_rate": 9.203796467176378e-06,
      "loss": 0.0003,
      "step": 9876
    },
    {
      "epoch": 0.5858939375963934,
      "grad_norm": 29.813684463500977,
      "learning_rate": 9.202478249406803e-06,
      "loss": 1.5372,
      "step": 9877
    },
    {
      "epoch": 0.5859532566140705,
      "grad_norm": 4.005810260772705,
      "learning_rate": 9.201160031637228e-06,
      "loss": 0.0681,
      "step": 9878
    },
    {
      "epoch": 0.5860125756317476,
      "grad_norm": 0.014225125312805176,
      "learning_rate": 9.199841813867652e-06,
      "loss": 0.0004,
      "step": 9879
    },
    {
      "epoch": 0.5860718946494246,
      "grad_norm": 0.9928058385848999,
      "learning_rate": 9.198523596098076e-06,
      "loss": 0.0083,
      "step": 9880
    },
    {
      "epoch": 0.5861312136671016,
      "grad_norm": 0.11593614518642426,
      "learning_rate": 9.1972053783285e-06,
      "loss": 0.0009,
      "step": 9881
    },
    {
      "epoch": 0.5861905326847787,
      "grad_norm": 10.068391799926758,
      "learning_rate": 9.195887160558924e-06,
      "loss": 0.3501,
      "step": 9882
    },
    {
      "epoch": 0.5862498517024558,
      "grad_norm": 0.18390654027462006,
      "learning_rate": 9.194568942789349e-06,
      "loss": 0.0032,
      "step": 9883
    },
    {
      "epoch": 0.5863091707201329,
      "grad_norm": 3.677825689315796,
      "learning_rate": 9.193250725019774e-06,
      "loss": 0.0399,
      "step": 9884
    },
    {
      "epoch": 0.58636848973781,
      "grad_norm": 0.012548092752695084,
      "learning_rate": 9.191932507250199e-06,
      "loss": 0.0005,
      "step": 9885
    },
    {
      "epoch": 0.5864278087554871,
      "grad_norm": 5.687105655670166,
      "learning_rate": 9.190614289480623e-06,
      "loss": 0.3915,
      "step": 9886
    },
    {
      "epoch": 0.586487127773164,
      "grad_norm": 0.11917652934789658,
      "learning_rate": 9.189296071711047e-06,
      "loss": 0.0015,
      "step": 9887
    },
    {
      "epoch": 0.5865464467908411,
      "grad_norm": 0.047185804694890976,
      "learning_rate": 9.187977853941473e-06,
      "loss": 0.0011,
      "step": 9888
    },
    {
      "epoch": 0.5866057658085182,
      "grad_norm": 0.07018104195594788,
      "learning_rate": 9.186659636171897e-06,
      "loss": 0.0012,
      "step": 9889
    },
    {
      "epoch": 0.5866650848261953,
      "grad_norm": 1.4648189544677734,
      "learning_rate": 9.185341418402321e-06,
      "loss": 0.0209,
      "step": 9890
    },
    {
      "epoch": 0.5867244038438724,
      "grad_norm": 0.3992186188697815,
      "learning_rate": 9.184023200632745e-06,
      "loss": 0.0054,
      "step": 9891
    },
    {
      "epoch": 0.5867837228615495,
      "grad_norm": 5.879071235656738,
      "learning_rate": 9.18270498286317e-06,
      "loss": 0.1163,
      "step": 9892
    },
    {
      "epoch": 0.5868430418792265,
      "grad_norm": 0.880728542804718,
      "learning_rate": 9.181386765093594e-06,
      "loss": 0.0087,
      "step": 9893
    },
    {
      "epoch": 0.5869023608969035,
      "grad_norm": 7.800078392028809,
      "learning_rate": 9.18006854732402e-06,
      "loss": 0.1279,
      "step": 9894
    },
    {
      "epoch": 0.5869616799145806,
      "grad_norm": 0.3064473569393158,
      "learning_rate": 9.178750329554444e-06,
      "loss": 0.0021,
      "step": 9895
    },
    {
      "epoch": 0.5870209989322577,
      "grad_norm": 0.003370878519490361,
      "learning_rate": 9.177432111784868e-06,
      "loss": 0.0001,
      "step": 9896
    },
    {
      "epoch": 0.5870803179499348,
      "grad_norm": 1.8512333631515503,
      "learning_rate": 9.176113894015292e-06,
      "loss": 0.0065,
      "step": 9897
    },
    {
      "epoch": 0.5871396369676118,
      "grad_norm": 24.740930557250977,
      "learning_rate": 9.174795676245716e-06,
      "loss": 0.1699,
      "step": 9898
    },
    {
      "epoch": 0.5871989559852889,
      "grad_norm": 6.213970184326172,
      "learning_rate": 9.17347745847614e-06,
      "loss": 0.57,
      "step": 9899
    },
    {
      "epoch": 0.5872582750029659,
      "grad_norm": 0.013825208880007267,
      "learning_rate": 9.172159240706565e-06,
      "loss": 0.0003,
      "step": 9900
    },
    {
      "epoch": 0.587317594020643,
      "grad_norm": 0.0044473884627223015,
      "learning_rate": 9.17084102293699e-06,
      "loss": 0.0002,
      "step": 9901
    },
    {
      "epoch": 0.5873769130383201,
      "grad_norm": 1.718878984451294,
      "learning_rate": 9.169522805167415e-06,
      "loss": 0.0045,
      "step": 9902
    },
    {
      "epoch": 0.5874362320559972,
      "grad_norm": 0.07623043656349182,
      "learning_rate": 9.168204587397839e-06,
      "loss": 0.0015,
      "step": 9903
    },
    {
      "epoch": 0.5874955510736742,
      "grad_norm": 0.05822589620947838,
      "learning_rate": 9.166886369628263e-06,
      "loss": 0.0007,
      "step": 9904
    },
    {
      "epoch": 0.5875548700913513,
      "grad_norm": 0.00898337084800005,
      "learning_rate": 9.165568151858687e-06,
      "loss": 0.0003,
      "step": 9905
    },
    {
      "epoch": 0.5876141891090284,
      "grad_norm": 0.27732527256011963,
      "learning_rate": 9.164249934089112e-06,
      "loss": 0.0021,
      "step": 9906
    },
    {
      "epoch": 0.5876735081267054,
      "grad_norm": 8.988533973693848,
      "learning_rate": 9.162931716319536e-06,
      "loss": 0.0508,
      "step": 9907
    },
    {
      "epoch": 0.5877328271443825,
      "grad_norm": 11.47018814086914,
      "learning_rate": 9.161613498549962e-06,
      "loss": 0.1721,
      "step": 9908
    },
    {
      "epoch": 0.5877921461620595,
      "grad_norm": 12.202997207641602,
      "learning_rate": 9.160295280780386e-06,
      "loss": 0.171,
      "step": 9909
    },
    {
      "epoch": 0.5878514651797366,
      "grad_norm": 3.0358126163482666,
      "learning_rate": 9.15897706301081e-06,
      "loss": 0.1291,
      "step": 9910
    },
    {
      "epoch": 0.5879107841974137,
      "grad_norm": 16.312170028686523,
      "learning_rate": 9.157658845241234e-06,
      "loss": 0.0585,
      "step": 9911
    },
    {
      "epoch": 0.5879701032150908,
      "grad_norm": 0.057331494987010956,
      "learning_rate": 9.15634062747166e-06,
      "loss": 0.001,
      "step": 9912
    },
    {
      "epoch": 0.5880294222327678,
      "grad_norm": 0.067438043653965,
      "learning_rate": 9.155022409702083e-06,
      "loss": 0.0009,
      "step": 9913
    },
    {
      "epoch": 0.5880887412504449,
      "grad_norm": 0.011875314638018608,
      "learning_rate": 9.153704191932507e-06,
      "loss": 0.0003,
      "step": 9914
    },
    {
      "epoch": 0.5881480602681219,
      "grad_norm": 0.06402066349983215,
      "learning_rate": 9.152385974162933e-06,
      "loss": 0.001,
      "step": 9915
    },
    {
      "epoch": 0.588207379285799,
      "grad_norm": 29.908477783203125,
      "learning_rate": 9.151067756393357e-06,
      "loss": 0.0721,
      "step": 9916
    },
    {
      "epoch": 0.5882666983034761,
      "grad_norm": 10.407684326171875,
      "learning_rate": 9.149749538623781e-06,
      "loss": 0.3583,
      "step": 9917
    },
    {
      "epoch": 0.5883260173211532,
      "grad_norm": 8.258974075317383,
      "learning_rate": 9.148431320854207e-06,
      "loss": 0.5368,
      "step": 9918
    },
    {
      "epoch": 0.5883853363388303,
      "grad_norm": 0.14919210970401764,
      "learning_rate": 9.147113103084631e-06,
      "loss": 0.0029,
      "step": 9919
    },
    {
      "epoch": 0.5884446553565073,
      "grad_norm": 0.017087502405047417,
      "learning_rate": 9.145794885315055e-06,
      "loss": 0.0006,
      "step": 9920
    },
    {
      "epoch": 0.5885039743741843,
      "grad_norm": 0.0480538085103035,
      "learning_rate": 9.14447666754548e-06,
      "loss": 0.0006,
      "step": 9921
    },
    {
      "epoch": 0.5885632933918614,
      "grad_norm": 0.5732530951499939,
      "learning_rate": 9.143158449775904e-06,
      "loss": 0.0058,
      "step": 9922
    },
    {
      "epoch": 0.5886226124095385,
      "grad_norm": 1.9322760105133057,
      "learning_rate": 9.141840232006328e-06,
      "loss": 0.0054,
      "step": 9923
    },
    {
      "epoch": 0.5886819314272156,
      "grad_norm": 0.007969298399984837,
      "learning_rate": 9.140522014236752e-06,
      "loss": 0.0002,
      "step": 9924
    },
    {
      "epoch": 0.5887412504448927,
      "grad_norm": 0.13350149989128113,
      "learning_rate": 9.139203796467178e-06,
      "loss": 0.0014,
      "step": 9925
    },
    {
      "epoch": 0.5888005694625696,
      "grad_norm": 10.257803916931152,
      "learning_rate": 9.137885578697602e-06,
      "loss": 0.612,
      "step": 9926
    },
    {
      "epoch": 0.5888598884802467,
      "grad_norm": 9.775671005249023,
      "learning_rate": 9.136567360928026e-06,
      "loss": 0.4496,
      "step": 9927
    },
    {
      "epoch": 0.5889192074979238,
      "grad_norm": 51.90172576904297,
      "learning_rate": 9.13524914315845e-06,
      "loss": 1.6413,
      "step": 9928
    },
    {
      "epoch": 0.5889785265156009,
      "grad_norm": 22.454830169677734,
      "learning_rate": 9.133930925388875e-06,
      "loss": 1.9034,
      "step": 9929
    },
    {
      "epoch": 0.589037845533278,
      "grad_norm": 7.161713123321533,
      "learning_rate": 9.132612707619299e-06,
      "loss": 0.2845,
      "step": 9930
    },
    {
      "epoch": 0.5890971645509551,
      "grad_norm": 10.999932289123535,
      "learning_rate": 9.131294489849723e-06,
      "loss": 0.1359,
      "step": 9931
    },
    {
      "epoch": 0.5891564835686321,
      "grad_norm": 0.3113206624984741,
      "learning_rate": 9.129976272080149e-06,
      "loss": 0.0057,
      "step": 9932
    },
    {
      "epoch": 0.5892158025863091,
      "grad_norm": 0.672701895236969,
      "learning_rate": 9.128658054310573e-06,
      "loss": 0.0056,
      "step": 9933
    },
    {
      "epoch": 0.5892751216039862,
      "grad_norm": 17.560935974121094,
      "learning_rate": 9.127339836540997e-06,
      "loss": 0.9886,
      "step": 9934
    },
    {
      "epoch": 0.5893344406216633,
      "grad_norm": 3.635728120803833,
      "learning_rate": 9.126021618771422e-06,
      "loss": 0.0434,
      "step": 9935
    },
    {
      "epoch": 0.5893937596393404,
      "grad_norm": 0.009361911565065384,
      "learning_rate": 9.124703401001846e-06,
      "loss": 0.0003,
      "step": 9936
    },
    {
      "epoch": 0.5894530786570175,
      "grad_norm": 0.16900157928466797,
      "learning_rate": 9.12338518323227e-06,
      "loss": 0.0038,
      "step": 9937
    },
    {
      "epoch": 0.5895123976746945,
      "grad_norm": 0.008036788552999496,
      "learning_rate": 9.122066965462694e-06,
      "loss": 0.0002,
      "step": 9938
    },
    {
      "epoch": 0.5895717166923716,
      "grad_norm": 0.4808412790298462,
      "learning_rate": 9.12074874769312e-06,
      "loss": 0.0051,
      "step": 9939
    },
    {
      "epoch": 0.5896310357100486,
      "grad_norm": 0.06808040291070938,
      "learning_rate": 9.119430529923544e-06,
      "loss": 0.0013,
      "step": 9940
    },
    {
      "epoch": 0.5896903547277257,
      "grad_norm": 0.00920756347477436,
      "learning_rate": 9.118112312153968e-06,
      "loss": 0.0004,
      "step": 9941
    },
    {
      "epoch": 0.5897496737454028,
      "grad_norm": 3.877359628677368,
      "learning_rate": 9.116794094384394e-06,
      "loss": 0.5203,
      "step": 9942
    },
    {
      "epoch": 0.5898089927630799,
      "grad_norm": 10.597576141357422,
      "learning_rate": 9.115475876614818e-06,
      "loss": 0.2908,
      "step": 9943
    },
    {
      "epoch": 0.5898683117807569,
      "grad_norm": 6.711259365081787,
      "learning_rate": 9.114157658845243e-06,
      "loss": 0.3723,
      "step": 9944
    },
    {
      "epoch": 0.589927630798434,
      "grad_norm": 1.0135071277618408,
      "learning_rate": 9.112839441075667e-06,
      "loss": 0.009,
      "step": 9945
    },
    {
      "epoch": 0.589986949816111,
      "grad_norm": 0.051594458520412445,
      "learning_rate": 9.111521223306091e-06,
      "loss": 0.0011,
      "step": 9946
    },
    {
      "epoch": 0.5900462688337881,
      "grad_norm": 10.852158546447754,
      "learning_rate": 9.110203005536515e-06,
      "loss": 0.2074,
      "step": 9947
    },
    {
      "epoch": 0.5901055878514652,
      "grad_norm": 3.288203239440918,
      "learning_rate": 9.10888478776694e-06,
      "loss": 0.0298,
      "step": 9948
    },
    {
      "epoch": 0.5901649068691422,
      "grad_norm": 14.461454391479492,
      "learning_rate": 9.107566569997365e-06,
      "loss": 0.444,
      "step": 9949
    },
    {
      "epoch": 0.5902242258868193,
      "grad_norm": 6.952427864074707,
      "learning_rate": 9.10624835222779e-06,
      "loss": 0.1915,
      "step": 9950
    },
    {
      "epoch": 0.5902835449044964,
      "grad_norm": 8.5620756149292,
      "learning_rate": 9.104930134458214e-06,
      "loss": 0.5756,
      "step": 9951
    },
    {
      "epoch": 0.5903428639221735,
      "grad_norm": 3.783909559249878,
      "learning_rate": 9.103611916688638e-06,
      "loss": 0.1496,
      "step": 9952
    },
    {
      "epoch": 0.5904021829398505,
      "grad_norm": 0.013070868328213692,
      "learning_rate": 9.102293698919062e-06,
      "loss": 0.0004,
      "step": 9953
    },
    {
      "epoch": 0.5904615019575276,
      "grad_norm": 12.546913146972656,
      "learning_rate": 9.100975481149486e-06,
      "loss": 0.379,
      "step": 9954
    },
    {
      "epoch": 0.5905208209752046,
      "grad_norm": 7.7039008140563965,
      "learning_rate": 9.09965726337991e-06,
      "loss": 0.0688,
      "step": 9955
    },
    {
      "epoch": 0.5905801399928817,
      "grad_norm": 5.4624738693237305,
      "learning_rate": 9.098339045610336e-06,
      "loss": 0.1366,
      "step": 9956
    },
    {
      "epoch": 0.5906394590105588,
      "grad_norm": 0.12553377449512482,
      "learning_rate": 9.09702082784076e-06,
      "loss": 0.0019,
      "step": 9957
    },
    {
      "epoch": 0.5906987780282359,
      "grad_norm": 2.469060182571411,
      "learning_rate": 9.095702610071185e-06,
      "loss": 0.0157,
      "step": 9958
    },
    {
      "epoch": 0.5907580970459129,
      "grad_norm": 8.221363067626953,
      "learning_rate": 9.094384392301609e-06,
      "loss": 0.0727,
      "step": 9959
    },
    {
      "epoch": 0.59081741606359,
      "grad_norm": 0.47361865639686584,
      "learning_rate": 9.093066174532033e-06,
      "loss": 0.0055,
      "step": 9960
    },
    {
      "epoch": 0.590876735081267,
      "grad_norm": 0.05664190277457237,
      "learning_rate": 9.091747956762457e-06,
      "loss": 0.0016,
      "step": 9961
    },
    {
      "epoch": 0.5909360540989441,
      "grad_norm": 12.387655258178711,
      "learning_rate": 9.090429738992881e-06,
      "loss": 0.224,
      "step": 9962
    },
    {
      "epoch": 0.5909953731166212,
      "grad_norm": 0.04619870334863663,
      "learning_rate": 9.089111521223307e-06,
      "loss": 0.001,
      "step": 9963
    },
    {
      "epoch": 0.5910546921342983,
      "grad_norm": 9.176823616027832,
      "learning_rate": 9.087793303453731e-06,
      "loss": 0.1013,
      "step": 9964
    },
    {
      "epoch": 0.5911140111519754,
      "grad_norm": 0.8329952955245972,
      "learning_rate": 9.086475085684156e-06,
      "loss": 0.0095,
      "step": 9965
    },
    {
      "epoch": 0.5911733301696523,
      "grad_norm": 0.07939749956130981,
      "learning_rate": 9.085156867914581e-06,
      "loss": 0.0014,
      "step": 9966
    },
    {
      "epoch": 0.5912326491873294,
      "grad_norm": 0.08515755832195282,
      "learning_rate": 9.083838650145006e-06,
      "loss": 0.0018,
      "step": 9967
    },
    {
      "epoch": 0.5912919682050065,
      "grad_norm": 13.884202003479004,
      "learning_rate": 9.08252043237543e-06,
      "loss": 0.1661,
      "step": 9968
    },
    {
      "epoch": 0.5913512872226836,
      "grad_norm": 6.279419898986816,
      "learning_rate": 9.081202214605852e-06,
      "loss": 0.1013,
      "step": 9969
    },
    {
      "epoch": 0.5914106062403607,
      "grad_norm": 15.512154579162598,
      "learning_rate": 9.079883996836278e-06,
      "loss": 0.599,
      "step": 9970
    },
    {
      "epoch": 0.5914699252580378,
      "grad_norm": 2.593700647354126,
      "learning_rate": 9.078565779066702e-06,
      "loss": 0.0174,
      "step": 9971
    },
    {
      "epoch": 0.5915292442757148,
      "grad_norm": 0.04143644496798515,
      "learning_rate": 9.077247561297127e-06,
      "loss": 0.001,
      "step": 9972
    },
    {
      "epoch": 0.5915885632933918,
      "grad_norm": 2.4190480709075928,
      "learning_rate": 9.075929343527552e-06,
      "loss": 0.0242,
      "step": 9973
    },
    {
      "epoch": 0.5916478823110689,
      "grad_norm": 6.0356011390686035,
      "learning_rate": 9.074611125757977e-06,
      "loss": 0.1056,
      "step": 9974
    },
    {
      "epoch": 0.591707201328746,
      "grad_norm": 0.417264848947525,
      "learning_rate": 9.073292907988401e-06,
      "loss": 0.0066,
      "step": 9975
    },
    {
      "epoch": 0.5917665203464231,
      "grad_norm": 4.7182087898254395,
      "learning_rate": 9.071974690218825e-06,
      "loss": 0.1425,
      "step": 9976
    },
    {
      "epoch": 0.5918258393641002,
      "grad_norm": 0.1667400449514389,
      "learning_rate": 9.07065647244925e-06,
      "loss": 0.0036,
      "step": 9977
    },
    {
      "epoch": 0.5918851583817772,
      "grad_norm": 0.0704660564661026,
      "learning_rate": 9.069338254679673e-06,
      "loss": 0.0011,
      "step": 9978
    },
    {
      "epoch": 0.5919444773994542,
      "grad_norm": 0.18664567172527313,
      "learning_rate": 9.068020036910098e-06,
      "loss": 0.0017,
      "step": 9979
    },
    {
      "epoch": 0.5920037964171313,
      "grad_norm": 14.172197341918945,
      "learning_rate": 9.066701819140523e-06,
      "loss": 0.5203,
      "step": 9980
    },
    {
      "epoch": 0.5920631154348084,
      "grad_norm": 4.930548667907715,
      "learning_rate": 9.065383601370948e-06,
      "loss": 0.2663,
      "step": 9981
    },
    {
      "epoch": 0.5921224344524855,
      "grad_norm": 0.8130232691764832,
      "learning_rate": 9.064065383601372e-06,
      "loss": 0.0055,
      "step": 9982
    },
    {
      "epoch": 0.5921817534701626,
      "grad_norm": 0.7394506931304932,
      "learning_rate": 9.062747165831796e-06,
      "loss": 0.0079,
      "step": 9983
    },
    {
      "epoch": 0.5922410724878396,
      "grad_norm": 0.020376058295369148,
      "learning_rate": 9.06142894806222e-06,
      "loss": 0.0004,
      "step": 9984
    },
    {
      "epoch": 0.5923003915055167,
      "grad_norm": 0.33884936571121216,
      "learning_rate": 9.060110730292644e-06,
      "loss": 0.0059,
      "step": 9985
    },
    {
      "epoch": 0.5923597105231937,
      "grad_norm": 1.8222203254699707,
      "learning_rate": 9.058792512523069e-06,
      "loss": 0.0214,
      "step": 9986
    },
    {
      "epoch": 0.5924190295408708,
      "grad_norm": 0.4228017032146454,
      "learning_rate": 9.057474294753494e-06,
      "loss": 0.0057,
      "step": 9987
    },
    {
      "epoch": 0.5924783485585479,
      "grad_norm": 14.864360809326172,
      "learning_rate": 9.056156076983919e-06,
      "loss": 0.9757,
      "step": 9988
    },
    {
      "epoch": 0.592537667576225,
      "grad_norm": 22.913976669311523,
      "learning_rate": 9.054837859214343e-06,
      "loss": 0.2612,
      "step": 9989
    },
    {
      "epoch": 0.592596986593902,
      "grad_norm": 4.626495838165283,
      "learning_rate": 9.053519641444769e-06,
      "loss": 0.0412,
      "step": 9990
    },
    {
      "epoch": 0.5926563056115791,
      "grad_norm": 2.279693126678467,
      "learning_rate": 9.052201423675191e-06,
      "loss": 0.0245,
      "step": 9991
    },
    {
      "epoch": 0.5927156246292561,
      "grad_norm": 0.056438904255628586,
      "learning_rate": 9.050883205905615e-06,
      "loss": 0.0013,
      "step": 9992
    },
    {
      "epoch": 0.5927749436469332,
      "grad_norm": 0.13631317019462585,
      "learning_rate": 9.04956498813604e-06,
      "loss": 0.002,
      "step": 9993
    },
    {
      "epoch": 0.5928342626646103,
      "grad_norm": 0.010506803169846535,
      "learning_rate": 9.048246770366465e-06,
      "loss": 0.0003,
      "step": 9994
    },
    {
      "epoch": 0.5928935816822873,
      "grad_norm": 4.237727165222168,
      "learning_rate": 9.04692855259689e-06,
      "loss": 0.0266,
      "step": 9995
    },
    {
      "epoch": 0.5929529006999644,
      "grad_norm": 5.735754489898682,
      "learning_rate": 9.045610334827314e-06,
      "loss": 0.0417,
      "step": 9996
    },
    {
      "epoch": 0.5930122197176415,
      "grad_norm": 1.773733377456665,
      "learning_rate": 9.04429211705774e-06,
      "loss": 0.0193,
      "step": 9997
    },
    {
      "epoch": 0.5930715387353186,
      "grad_norm": 0.0123348543420434,
      "learning_rate": 9.042973899288164e-06,
      "loss": 0.0003,
      "step": 9998
    },
    {
      "epoch": 0.5931308577529956,
      "grad_norm": 0.07025617361068726,
      "learning_rate": 9.041655681518588e-06,
      "loss": 0.0016,
      "step": 9999
    },
    {
      "epoch": 0.5931901767706727,
      "grad_norm": 0.035442251712083817,
      "learning_rate": 9.040337463749012e-06,
      "loss": 0.0006,
      "step": 10000
    },
    {
      "epoch": 0.5932494957883497,
      "grad_norm": 8.017963409423828,
      "learning_rate": 9.039019245979436e-06,
      "loss": 0.2843,
      "step": 10001
    },
    {
      "epoch": 0.5933088148060268,
      "grad_norm": 14.712136268615723,
      "learning_rate": 9.03770102820986e-06,
      "loss": 0.489,
      "step": 10002
    },
    {
      "epoch": 0.5933681338237039,
      "grad_norm": 0.6640461087226868,
      "learning_rate": 9.036382810440285e-06,
      "loss": 0.0063,
      "step": 10003
    },
    {
      "epoch": 0.593427452841381,
      "grad_norm": 0.3882432281970978,
      "learning_rate": 9.03506459267071e-06,
      "loss": 0.0046,
      "step": 10004
    },
    {
      "epoch": 0.593486771859058,
      "grad_norm": 1.2932803630828857,
      "learning_rate": 9.033746374901135e-06,
      "loss": 0.0178,
      "step": 10005
    },
    {
      "epoch": 0.593546090876735,
      "grad_norm": 20.25831413269043,
      "learning_rate": 9.032428157131559e-06,
      "loss": 0.0758,
      "step": 10006
    },
    {
      "epoch": 0.5936054098944121,
      "grad_norm": 0.20767700672149658,
      "learning_rate": 9.031109939361983e-06,
      "loss": 0.0022,
      "step": 10007
    },
    {
      "epoch": 0.5936647289120892,
      "grad_norm": 20.906034469604492,
      "learning_rate": 9.029791721592408e-06,
      "loss": 0.9989,
      "step": 10008
    },
    {
      "epoch": 0.5937240479297663,
      "grad_norm": 4.002023696899414,
      "learning_rate": 9.028473503822832e-06,
      "loss": 0.0486,
      "step": 10009
    },
    {
      "epoch": 0.5937833669474434,
      "grad_norm": 6.407402038574219,
      "learning_rate": 9.027155286053256e-06,
      "loss": 0.0322,
      "step": 10010
    },
    {
      "epoch": 0.5938426859651205,
      "grad_norm": 5.281009197235107,
      "learning_rate": 9.025837068283682e-06,
      "loss": 0.0171,
      "step": 10011
    },
    {
      "epoch": 0.5939020049827974,
      "grad_norm": 15.197821617126465,
      "learning_rate": 9.024518850514106e-06,
      "loss": 0.4614,
      "step": 10012
    },
    {
      "epoch": 0.5939613240004745,
      "grad_norm": 22.577211380004883,
      "learning_rate": 9.02320063274453e-06,
      "loss": 0.08,
      "step": 10013
    },
    {
      "epoch": 0.5940206430181516,
      "grad_norm": 7.977503299713135,
      "learning_rate": 9.021882414974954e-06,
      "loss": 0.185,
      "step": 10014
    },
    {
      "epoch": 0.5940799620358287,
      "grad_norm": 0.035398900508880615,
      "learning_rate": 9.020564197205379e-06,
      "loss": 0.0003,
      "step": 10015
    },
    {
      "epoch": 0.5941392810535058,
      "grad_norm": 6.223907470703125,
      "learning_rate": 9.019245979435803e-06,
      "loss": 0.0783,
      "step": 10016
    },
    {
      "epoch": 0.5941986000711829,
      "grad_norm": 0.5404805541038513,
      "learning_rate": 9.017927761666227e-06,
      "loss": 0.0045,
      "step": 10017
    },
    {
      "epoch": 0.5942579190888599,
      "grad_norm": 6.147233963012695,
      "learning_rate": 9.016609543896653e-06,
      "loss": 0.0974,
      "step": 10018
    },
    {
      "epoch": 0.5943172381065369,
      "grad_norm": 0.06303837895393372,
      "learning_rate": 9.015291326127077e-06,
      "loss": 0.0016,
      "step": 10019
    },
    {
      "epoch": 0.594376557124214,
      "grad_norm": 3.0272114276885986,
      "learning_rate": 9.013973108357501e-06,
      "loss": 0.0325,
      "step": 10020
    },
    {
      "epoch": 0.5944358761418911,
      "grad_norm": 0.04363128915429115,
      "learning_rate": 9.012654890587927e-06,
      "loss": 0.0009,
      "step": 10021
    },
    {
      "epoch": 0.5944951951595682,
      "grad_norm": 0.09174780547618866,
      "learning_rate": 9.011336672818351e-06,
      "loss": 0.0019,
      "step": 10022
    },
    {
      "epoch": 0.5945545141772453,
      "grad_norm": 0.15099415183067322,
      "learning_rate": 9.010018455048775e-06,
      "loss": 0.0028,
      "step": 10023
    },
    {
      "epoch": 0.5946138331949223,
      "grad_norm": 40.348758697509766,
      "learning_rate": 9.0087002372792e-06,
      "loss": 2.4574,
      "step": 10024
    },
    {
      "epoch": 0.5946731522125993,
      "grad_norm": 10.756999969482422,
      "learning_rate": 9.007382019509624e-06,
      "loss": 1.099,
      "step": 10025
    },
    {
      "epoch": 0.5947324712302764,
      "grad_norm": 25.138141632080078,
      "learning_rate": 9.006063801740048e-06,
      "loss": 0.2652,
      "step": 10026
    },
    {
      "epoch": 0.5947917902479535,
      "grad_norm": 0.08207358419895172,
      "learning_rate": 9.004745583970472e-06,
      "loss": 0.0016,
      "step": 10027
    },
    {
      "epoch": 0.5948511092656306,
      "grad_norm": 4.634793758392334,
      "learning_rate": 9.003427366200898e-06,
      "loss": 0.0368,
      "step": 10028
    },
    {
      "epoch": 0.5949104282833076,
      "grad_norm": 0.2661501169204712,
      "learning_rate": 9.002109148431322e-06,
      "loss": 0.0069,
      "step": 10029
    },
    {
      "epoch": 0.5949697473009847,
      "grad_norm": 0.45875313878059387,
      "learning_rate": 9.000790930661746e-06,
      "loss": 0.0047,
      "step": 10030
    },
    {
      "epoch": 0.5950290663186618,
      "grad_norm": 37.050682067871094,
      "learning_rate": 8.99947271289217e-06,
      "loss": 0.3236,
      "step": 10031
    },
    {
      "epoch": 0.5950883853363388,
      "grad_norm": 7.13693904876709,
      "learning_rate": 8.998154495122595e-06,
      "loss": 0.1085,
      "step": 10032
    },
    {
      "epoch": 0.5951477043540159,
      "grad_norm": 17.544471740722656,
      "learning_rate": 8.996836277353019e-06,
      "loss": 0.6372,
      "step": 10033
    },
    {
      "epoch": 0.595207023371693,
      "grad_norm": 0.03179875388741493,
      "learning_rate": 8.995518059583443e-06,
      "loss": 0.0009,
      "step": 10034
    },
    {
      "epoch": 0.59526634238937,
      "grad_norm": 5.924609661102295,
      "learning_rate": 8.994199841813869e-06,
      "loss": 0.1581,
      "step": 10035
    },
    {
      "epoch": 0.5953256614070471,
      "grad_norm": 0.015317856334149837,
      "learning_rate": 8.992881624044293e-06,
      "loss": 0.0006,
      "step": 10036
    },
    {
      "epoch": 0.5953849804247242,
      "grad_norm": 5.760956764221191,
      "learning_rate": 8.991563406274717e-06,
      "loss": 0.013,
      "step": 10037
    },
    {
      "epoch": 0.5954442994424012,
      "grad_norm": 0.27433013916015625,
      "learning_rate": 8.990245188505142e-06,
      "loss": 0.0035,
      "step": 10038
    },
    {
      "epoch": 0.5955036184600783,
      "grad_norm": 4.934425354003906,
      "learning_rate": 8.988926970735566e-06,
      "loss": 0.0576,
      "step": 10039
    },
    {
      "epoch": 0.5955629374777553,
      "grad_norm": 0.037667468190193176,
      "learning_rate": 8.98760875296599e-06,
      "loss": 0.001,
      "step": 10040
    },
    {
      "epoch": 0.5956222564954324,
      "grad_norm": 0.014037123881280422,
      "learning_rate": 8.986290535196414e-06,
      "loss": 0.0004,
      "step": 10041
    },
    {
      "epoch": 0.5956815755131095,
      "grad_norm": 4.25445032119751,
      "learning_rate": 8.98497231742684e-06,
      "loss": 0.1687,
      "step": 10042
    },
    {
      "epoch": 0.5957408945307866,
      "grad_norm": 3.517850637435913,
      "learning_rate": 8.983654099657264e-06,
      "loss": 0.0192,
      "step": 10043
    },
    {
      "epoch": 0.5958002135484637,
      "grad_norm": 0.4001010060310364,
      "learning_rate": 8.982335881887688e-06,
      "loss": 0.0045,
      "step": 10044
    },
    {
      "epoch": 0.5958595325661407,
      "grad_norm": 3.3753790855407715,
      "learning_rate": 8.981017664118114e-06,
      "loss": 0.0229,
      "step": 10045
    },
    {
      "epoch": 0.5959188515838177,
      "grad_norm": 15.288605690002441,
      "learning_rate": 8.979699446348538e-06,
      "loss": 0.7596,
      "step": 10046
    },
    {
      "epoch": 0.5959781706014948,
      "grad_norm": 2.0651350021362305,
      "learning_rate": 8.978381228578961e-06,
      "loss": 0.0369,
      "step": 10047
    },
    {
      "epoch": 0.5960374896191719,
      "grad_norm": 1.823447585105896,
      "learning_rate": 8.977063010809385e-06,
      "loss": 0.0301,
      "step": 10048
    },
    {
      "epoch": 0.596096808636849,
      "grad_norm": 3.5341596603393555,
      "learning_rate": 8.975744793039811e-06,
      "loss": 0.0317,
      "step": 10049
    },
    {
      "epoch": 0.5961561276545261,
      "grad_norm": 17.11316680908203,
      "learning_rate": 8.974426575270235e-06,
      "loss": 1.504,
      "step": 10050
    },
    {
      "epoch": 0.596215446672203,
      "grad_norm": 16.33495330810547,
      "learning_rate": 8.97310835750066e-06,
      "loss": 0.2795,
      "step": 10051
    },
    {
      "epoch": 0.5962747656898801,
      "grad_norm": 15.283797264099121,
      "learning_rate": 8.971790139731085e-06,
      "loss": 0.1721,
      "step": 10052
    },
    {
      "epoch": 0.5963340847075572,
      "grad_norm": 1.3615952730178833,
      "learning_rate": 8.97047192196151e-06,
      "loss": 0.0253,
      "step": 10053
    },
    {
      "epoch": 0.5963934037252343,
      "grad_norm": 0.143875852227211,
      "learning_rate": 8.969153704191934e-06,
      "loss": 0.0015,
      "step": 10054
    },
    {
      "epoch": 0.5964527227429114,
      "grad_norm": 1.7681547403335571,
      "learning_rate": 8.967835486422358e-06,
      "loss": 0.0549,
      "step": 10055
    },
    {
      "epoch": 0.5965120417605885,
      "grad_norm": 0.7854150533676147,
      "learning_rate": 8.966517268652782e-06,
      "loss": 0.0114,
      "step": 10056
    },
    {
      "epoch": 0.5965713607782656,
      "grad_norm": 4.811150074005127,
      "learning_rate": 8.965199050883206e-06,
      "loss": 0.0507,
      "step": 10057
    },
    {
      "epoch": 0.5966306797959425,
      "grad_norm": 4.1601152420043945,
      "learning_rate": 8.96388083311363e-06,
      "loss": 0.6332,
      "step": 10058
    },
    {
      "epoch": 0.5966899988136196,
      "grad_norm": 0.6412257552146912,
      "learning_rate": 8.962562615344056e-06,
      "loss": 0.0106,
      "step": 10059
    },
    {
      "epoch": 0.5967493178312967,
      "grad_norm": 18.26220703125,
      "learning_rate": 8.96124439757448e-06,
      "loss": 1.3426,
      "step": 10060
    },
    {
      "epoch": 0.5968086368489738,
      "grad_norm": 4.959152698516846,
      "learning_rate": 8.959926179804905e-06,
      "loss": 0.0564,
      "step": 10061
    },
    {
      "epoch": 0.5968679558666509,
      "grad_norm": 2.243725299835205,
      "learning_rate": 8.958607962035329e-06,
      "loss": 0.0338,
      "step": 10062
    },
    {
      "epoch": 0.596927274884328,
      "grad_norm": 0.41471073031425476,
      "learning_rate": 8.957289744265753e-06,
      "loss": 0.007,
      "step": 10063
    },
    {
      "epoch": 0.596986593902005,
      "grad_norm": 14.025782585144043,
      "learning_rate": 8.955971526496177e-06,
      "loss": 0.188,
      "step": 10064
    },
    {
      "epoch": 0.597045912919682,
      "grad_norm": 0.09200224280357361,
      "learning_rate": 8.954653308726601e-06,
      "loss": 0.0019,
      "step": 10065
    },
    {
      "epoch": 0.5971052319373591,
      "grad_norm": 16.64868927001953,
      "learning_rate": 8.953335090957027e-06,
      "loss": 0.3733,
      "step": 10066
    },
    {
      "epoch": 0.5971645509550362,
      "grad_norm": 0.04668256267905235,
      "learning_rate": 8.952016873187451e-06,
      "loss": 0.0009,
      "step": 10067
    },
    {
      "epoch": 0.5972238699727133,
      "grad_norm": 0.10642916709184647,
      "learning_rate": 8.950698655417876e-06,
      "loss": 0.0019,
      "step": 10068
    },
    {
      "epoch": 0.5972831889903903,
      "grad_norm": 2.2930753231048584,
      "learning_rate": 8.9493804376483e-06,
      "loss": 0.0196,
      "step": 10069
    },
    {
      "epoch": 0.5973425080080674,
      "grad_norm": 1.2987709045410156,
      "learning_rate": 8.948062219878724e-06,
      "loss": 0.0143,
      "step": 10070
    },
    {
      "epoch": 0.5974018270257444,
      "grad_norm": 0.05708803981542587,
      "learning_rate": 8.946744002109148e-06,
      "loss": 0.0009,
      "step": 10071
    },
    {
      "epoch": 0.5974611460434215,
      "grad_norm": 14.423678398132324,
      "learning_rate": 8.945425784339572e-06,
      "loss": 0.2535,
      "step": 10072
    },
    {
      "epoch": 0.5975204650610986,
      "grad_norm": 2.4833462238311768,
      "learning_rate": 8.944107566569998e-06,
      "loss": 0.0464,
      "step": 10073
    },
    {
      "epoch": 0.5975797840787757,
      "grad_norm": 10.687204360961914,
      "learning_rate": 8.942789348800422e-06,
      "loss": 0.1121,
      "step": 10074
    },
    {
      "epoch": 0.5976391030964527,
      "grad_norm": 0.09973490983247757,
      "learning_rate": 8.941471131030847e-06,
      "loss": 0.0013,
      "step": 10075
    },
    {
      "epoch": 0.5976984221141298,
      "grad_norm": 1.2761743068695068,
      "learning_rate": 8.940152913261273e-06,
      "loss": 0.0167,
      "step": 10076
    },
    {
      "epoch": 0.5977577411318069,
      "grad_norm": 0.6134698987007141,
      "learning_rate": 8.938834695491697e-06,
      "loss": 0.0103,
      "step": 10077
    },
    {
      "epoch": 0.5978170601494839,
      "grad_norm": 6.981590270996094,
      "learning_rate": 8.937516477722121e-06,
      "loss": 0.3041,
      "step": 10078
    },
    {
      "epoch": 0.597876379167161,
      "grad_norm": 1.3220843076705933,
      "learning_rate": 8.936198259952545e-06,
      "loss": 0.0059,
      "step": 10079
    },
    {
      "epoch": 0.597935698184838,
      "grad_norm": 2.213122606277466,
      "learning_rate": 8.93488004218297e-06,
      "loss": 0.0081,
      "step": 10080
    },
    {
      "epoch": 0.5979950172025151,
      "grad_norm": 15.64783000946045,
      "learning_rate": 8.933561824413393e-06,
      "loss": 0.0787,
      "step": 10081
    },
    {
      "epoch": 0.5980543362201922,
      "grad_norm": 8.757448196411133,
      "learning_rate": 8.932243606643818e-06,
      "loss": 0.2473,
      "step": 10082
    },
    {
      "epoch": 0.5981136552378693,
      "grad_norm": 13.867300033569336,
      "learning_rate": 8.930925388874244e-06,
      "loss": 0.4407,
      "step": 10083
    },
    {
      "epoch": 0.5981729742555463,
      "grad_norm": 0.01766044832766056,
      "learning_rate": 8.929607171104668e-06,
      "loss": 0.0005,
      "step": 10084
    },
    {
      "epoch": 0.5982322932732234,
      "grad_norm": 7.529348850250244,
      "learning_rate": 8.928288953335092e-06,
      "loss": 0.2347,
      "step": 10085
    },
    {
      "epoch": 0.5982916122909004,
      "grad_norm": 29.245983123779297,
      "learning_rate": 8.926970735565516e-06,
      "loss": 0.4165,
      "step": 10086
    },
    {
      "epoch": 0.5983509313085775,
      "grad_norm": 0.041087765246629715,
      "learning_rate": 8.92565251779594e-06,
      "loss": 0.0009,
      "step": 10087
    },
    {
      "epoch": 0.5984102503262546,
      "grad_norm": 1.2027169466018677,
      "learning_rate": 8.924334300026364e-06,
      "loss": 0.007,
      "step": 10088
    },
    {
      "epoch": 0.5984695693439317,
      "grad_norm": 1.3884150981903076,
      "learning_rate": 8.923016082256789e-06,
      "loss": 0.0211,
      "step": 10089
    },
    {
      "epoch": 0.5985288883616088,
      "grad_norm": 4.560023307800293,
      "learning_rate": 8.921697864487215e-06,
      "loss": 0.5697,
      "step": 10090
    },
    {
      "epoch": 0.5985882073792858,
      "grad_norm": 0.6933189034461975,
      "learning_rate": 8.920379646717639e-06,
      "loss": 0.0059,
      "step": 10091
    },
    {
      "epoch": 0.5986475263969628,
      "grad_norm": 0.0275138970464468,
      "learning_rate": 8.919061428948063e-06,
      "loss": 0.0009,
      "step": 10092
    },
    {
      "epoch": 0.5987068454146399,
      "grad_norm": 0.07154775410890579,
      "learning_rate": 8.917743211178487e-06,
      "loss": 0.0014,
      "step": 10093
    },
    {
      "epoch": 0.598766164432317,
      "grad_norm": 0.22437720000743866,
      "learning_rate": 8.916424993408911e-06,
      "loss": 0.0028,
      "step": 10094
    },
    {
      "epoch": 0.5988254834499941,
      "grad_norm": 0.1032906100153923,
      "learning_rate": 8.915106775639335e-06,
      "loss": 0.0014,
      "step": 10095
    },
    {
      "epoch": 0.5988848024676712,
      "grad_norm": 0.6923241019248962,
      "learning_rate": 8.91378855786976e-06,
      "loss": 0.0065,
      "step": 10096
    },
    {
      "epoch": 0.5989441214853483,
      "grad_norm": 0.2365543693304062,
      "learning_rate": 8.912470340100186e-06,
      "loss": 0.0045,
      "step": 10097
    },
    {
      "epoch": 0.5990034405030252,
      "grad_norm": 0.06850945204496384,
      "learning_rate": 8.91115212233061e-06,
      "loss": 0.0014,
      "step": 10098
    },
    {
      "epoch": 0.5990627595207023,
      "grad_norm": 0.04761116951704025,
      "learning_rate": 8.909833904561034e-06,
      "loss": 0.0013,
      "step": 10099
    },
    {
      "epoch": 0.5991220785383794,
      "grad_norm": 3.944532632827759,
      "learning_rate": 8.90851568679146e-06,
      "loss": 0.0448,
      "step": 10100
    },
    {
      "epoch": 0.5991813975560565,
      "grad_norm": 11.465215682983398,
      "learning_rate": 8.907197469021884e-06,
      "loss": 0.3161,
      "step": 10101
    },
    {
      "epoch": 0.5992407165737336,
      "grad_norm": 0.6979992985725403,
      "learning_rate": 8.905879251252306e-06,
      "loss": 0.0071,
      "step": 10102
    },
    {
      "epoch": 0.5993000355914107,
      "grad_norm": 0.036204271018505096,
      "learning_rate": 8.904561033482732e-06,
      "loss": 0.0006,
      "step": 10103
    },
    {
      "epoch": 0.5993593546090876,
      "grad_norm": 7.584045886993408,
      "learning_rate": 8.903242815713157e-06,
      "loss": 0.1459,
      "step": 10104
    },
    {
      "epoch": 0.5994186736267647,
      "grad_norm": 0.039386916905641556,
      "learning_rate": 8.90192459794358e-06,
      "loss": 0.0012,
      "step": 10105
    },
    {
      "epoch": 0.5994779926444418,
      "grad_norm": 3.2660441398620605,
      "learning_rate": 8.900606380174005e-06,
      "loss": 0.147,
      "step": 10106
    },
    {
      "epoch": 0.5995373116621189,
      "grad_norm": 0.6637600660324097,
      "learning_rate": 8.89928816240443e-06,
      "loss": 0.0043,
      "step": 10107
    },
    {
      "epoch": 0.599596630679796,
      "grad_norm": 8.558391571044922,
      "learning_rate": 8.897969944634855e-06,
      "loss": 0.7059,
      "step": 10108
    },
    {
      "epoch": 0.599655949697473,
      "grad_norm": 0.5329118371009827,
      "learning_rate": 8.89665172686528e-06,
      "loss": 0.0066,
      "step": 10109
    },
    {
      "epoch": 0.5997152687151501,
      "grad_norm": 0.10706184804439545,
      "learning_rate": 8.895333509095703e-06,
      "loss": 0.0015,
      "step": 10110
    },
    {
      "epoch": 0.5997745877328271,
      "grad_norm": 12.205706596374512,
      "learning_rate": 8.894015291326128e-06,
      "loss": 0.4376,
      "step": 10111
    },
    {
      "epoch": 0.5998339067505042,
      "grad_norm": 0.1497274786233902,
      "learning_rate": 8.892697073556552e-06,
      "loss": 0.0021,
      "step": 10112
    },
    {
      "epoch": 0.5998932257681813,
      "grad_norm": 0.14500153064727783,
      "learning_rate": 8.891378855786976e-06,
      "loss": 0.0032,
      "step": 10113
    },
    {
      "epoch": 0.5999525447858584,
      "grad_norm": 0.03159591928124428,
      "learning_rate": 8.890060638017402e-06,
      "loss": 0.0007,
      "step": 10114
    },
    {
      "epoch": 0.6000118638035354,
      "grad_norm": 19.171159744262695,
      "learning_rate": 8.888742420247826e-06,
      "loss": 0.3286,
      "step": 10115
    },
    {
      "epoch": 0.6000711828212125,
      "grad_norm": 0.4652272164821625,
      "learning_rate": 8.88742420247825e-06,
      "loss": 0.0056,
      "step": 10116
    },
    {
      "epoch": 0.6001305018388895,
      "grad_norm": 1.1409577131271362,
      "learning_rate": 8.886105984708674e-06,
      "loss": 0.02,
      "step": 10117
    },
    {
      "epoch": 0.6001898208565666,
      "grad_norm": 1.7650785446166992,
      "learning_rate": 8.884787766939099e-06,
      "loss": 0.0237,
      "step": 10118
    },
    {
      "epoch": 0.6002491398742437,
      "grad_norm": 0.021186208352446556,
      "learning_rate": 8.883469549169523e-06,
      "loss": 0.0005,
      "step": 10119
    },
    {
      "epoch": 0.6003084588919207,
      "grad_norm": 0.037887092679739,
      "learning_rate": 8.882151331399947e-06,
      "loss": 0.001,
      "step": 10120
    },
    {
      "epoch": 0.6003677779095978,
      "grad_norm": 5.7053680419921875,
      "learning_rate": 8.880833113630373e-06,
      "loss": 0.6171,
      "step": 10121
    },
    {
      "epoch": 0.6004270969272749,
      "grad_norm": 8.95599365234375,
      "learning_rate": 8.879514895860797e-06,
      "loss": 0.7919,
      "step": 10122
    },
    {
      "epoch": 0.600486415944952,
      "grad_norm": 0.8586402535438538,
      "learning_rate": 8.878196678091221e-06,
      "loss": 0.017,
      "step": 10123
    },
    {
      "epoch": 0.600545734962629,
      "grad_norm": 0.007993839681148529,
      "learning_rate": 8.876878460321647e-06,
      "loss": 0.0003,
      "step": 10124
    },
    {
      "epoch": 0.6006050539803061,
      "grad_norm": 0.09017657488584518,
      "learning_rate": 8.87556024255207e-06,
      "loss": 0.002,
      "step": 10125
    },
    {
      "epoch": 0.6006643729979831,
      "grad_norm": 7.921603202819824,
      "learning_rate": 8.874242024782494e-06,
      "loss": 0.0807,
      "step": 10126
    },
    {
      "epoch": 0.6007236920156602,
      "grad_norm": 0.15383118391036987,
      "learning_rate": 8.87292380701292e-06,
      "loss": 0.0021,
      "step": 10127
    },
    {
      "epoch": 0.6007830110333373,
      "grad_norm": 0.09964682161808014,
      "learning_rate": 8.871605589243344e-06,
      "loss": 0.0019,
      "step": 10128
    },
    {
      "epoch": 0.6008423300510144,
      "grad_norm": 16.067514419555664,
      "learning_rate": 8.870287371473768e-06,
      "loss": 0.4491,
      "step": 10129
    },
    {
      "epoch": 0.6009016490686914,
      "grad_norm": 7.854375839233398,
      "learning_rate": 8.868969153704192e-06,
      "loss": 0.0666,
      "step": 10130
    },
    {
      "epoch": 0.6009609680863685,
      "grad_norm": 24.57548713684082,
      "learning_rate": 8.867650935934618e-06,
      "loss": 0.559,
      "step": 10131
    },
    {
      "epoch": 0.6010202871040455,
      "grad_norm": 6.148445129394531,
      "learning_rate": 8.866332718165042e-06,
      "loss": 0.1874,
      "step": 10132
    },
    {
      "epoch": 0.6010796061217226,
      "grad_norm": 7.467164039611816,
      "learning_rate": 8.865014500395466e-06,
      "loss": 0.0333,
      "step": 10133
    },
    {
      "epoch": 0.6011389251393997,
      "grad_norm": 1.8400583267211914,
      "learning_rate": 8.86369628262589e-06,
      "loss": 0.0113,
      "step": 10134
    },
    {
      "epoch": 0.6011982441570768,
      "grad_norm": 2.1454391479492188,
      "learning_rate": 8.862378064856315e-06,
      "loss": 0.0157,
      "step": 10135
    },
    {
      "epoch": 0.6012575631747539,
      "grad_norm": 0.03736047446727753,
      "learning_rate": 8.861059847086739e-06,
      "loss": 0.0008,
      "step": 10136
    },
    {
      "epoch": 0.6013168821924308,
      "grad_norm": 5.451520919799805,
      "learning_rate": 8.859741629317163e-06,
      "loss": 0.0727,
      "step": 10137
    },
    {
      "epoch": 0.6013762012101079,
      "grad_norm": 0.0060175154358148575,
      "learning_rate": 8.858423411547589e-06,
      "loss": 0.0002,
      "step": 10138
    },
    {
      "epoch": 0.601435520227785,
      "grad_norm": 0.019251398742198944,
      "learning_rate": 8.857105193778013e-06,
      "loss": 0.0006,
      "step": 10139
    },
    {
      "epoch": 0.6014948392454621,
      "grad_norm": 12.953043937683105,
      "learning_rate": 8.855786976008437e-06,
      "loss": 0.2148,
      "step": 10140
    },
    {
      "epoch": 0.6015541582631392,
      "grad_norm": 1.4576120376586914,
      "learning_rate": 8.854468758238862e-06,
      "loss": 0.0064,
      "step": 10141
    },
    {
      "epoch": 0.6016134772808163,
      "grad_norm": 2.8952174186706543,
      "learning_rate": 8.853150540469286e-06,
      "loss": 0.0175,
      "step": 10142
    },
    {
      "epoch": 0.6016727962984934,
      "grad_norm": 0.01584305241703987,
      "learning_rate": 8.85183232269971e-06,
      "loss": 0.0004,
      "step": 10143
    },
    {
      "epoch": 0.6017321153161703,
      "grad_norm": 0.17612376809120178,
      "learning_rate": 8.850514104930134e-06,
      "loss": 0.0032,
      "step": 10144
    },
    {
      "epoch": 0.6017914343338474,
      "grad_norm": 0.038106415420770645,
      "learning_rate": 8.84919588716056e-06,
      "loss": 0.001,
      "step": 10145
    },
    {
      "epoch": 0.6018507533515245,
      "grad_norm": 13.566997528076172,
      "learning_rate": 8.847877669390984e-06,
      "loss": 0.1983,
      "step": 10146
    },
    {
      "epoch": 0.6019100723692016,
      "grad_norm": 19.848102569580078,
      "learning_rate": 8.846559451621408e-06,
      "loss": 1.4433,
      "step": 10147
    },
    {
      "epoch": 0.6019693913868787,
      "grad_norm": 5.347858428955078,
      "learning_rate": 8.845241233851833e-06,
      "loss": 0.1104,
      "step": 10148
    },
    {
      "epoch": 0.6020287104045557,
      "grad_norm": 10.361820220947266,
      "learning_rate": 8.843923016082257e-06,
      "loss": 0.1099,
      "step": 10149
    },
    {
      "epoch": 0.6020880294222327,
      "grad_norm": 0.04328000172972679,
      "learning_rate": 8.842604798312681e-06,
      "loss": 0.0009,
      "step": 10150
    },
    {
      "epoch": 0.6021473484399098,
      "grad_norm": 12.949735641479492,
      "learning_rate": 8.841286580543107e-06,
      "loss": 0.2826,
      "step": 10151
    },
    {
      "epoch": 0.6022066674575869,
      "grad_norm": 0.17712360620498657,
      "learning_rate": 8.839968362773531e-06,
      "loss": 0.0038,
      "step": 10152
    },
    {
      "epoch": 0.602265986475264,
      "grad_norm": 3.229220151901245,
      "learning_rate": 8.838650145003955e-06,
      "loss": 0.071,
      "step": 10153
    },
    {
      "epoch": 0.602325305492941,
      "grad_norm": 4.828908920288086,
      "learning_rate": 8.83733192723438e-06,
      "loss": 0.0781,
      "step": 10154
    },
    {
      "epoch": 0.6023846245106181,
      "grad_norm": 3.3705461025238037,
      "learning_rate": 8.836013709464805e-06,
      "loss": 0.0404,
      "step": 10155
    },
    {
      "epoch": 0.6024439435282952,
      "grad_norm": 0.20786957442760468,
      "learning_rate": 8.83469549169523e-06,
      "loss": 0.0027,
      "step": 10156
    },
    {
      "epoch": 0.6025032625459722,
      "grad_norm": 10.935243606567383,
      "learning_rate": 8.833377273925654e-06,
      "loss": 0.4613,
      "step": 10157
    },
    {
      "epoch": 0.6025625815636493,
      "grad_norm": 10.625025749206543,
      "learning_rate": 8.832059056156078e-06,
      "loss": 0.0925,
      "step": 10158
    },
    {
      "epoch": 0.6026219005813264,
      "grad_norm": 10.707931518554688,
      "learning_rate": 8.830740838386502e-06,
      "loss": 0.2499,
      "step": 10159
    },
    {
      "epoch": 0.6026812195990034,
      "grad_norm": 0.10749021172523499,
      "learning_rate": 8.829422620616926e-06,
      "loss": 0.0019,
      "step": 10160
    },
    {
      "epoch": 0.6027405386166805,
      "grad_norm": 0.033475495874881744,
      "learning_rate": 8.82810440284735e-06,
      "loss": 0.0005,
      "step": 10161
    },
    {
      "epoch": 0.6027998576343576,
      "grad_norm": 12.909515380859375,
      "learning_rate": 8.826786185077776e-06,
      "loss": 1.1286,
      "step": 10162
    },
    {
      "epoch": 0.6028591766520346,
      "grad_norm": 29.655473709106445,
      "learning_rate": 8.8254679673082e-06,
      "loss": 1.4351,
      "step": 10163
    },
    {
      "epoch": 0.6029184956697117,
      "grad_norm": 17.720449447631836,
      "learning_rate": 8.824149749538625e-06,
      "loss": 0.1451,
      "step": 10164
    },
    {
      "epoch": 0.6029778146873888,
      "grad_norm": 0.8085152506828308,
      "learning_rate": 8.822831531769049e-06,
      "loss": 0.0081,
      "step": 10165
    },
    {
      "epoch": 0.6030371337050658,
      "grad_norm": 3.6196377277374268,
      "learning_rate": 8.821513313999473e-06,
      "loss": 0.8849,
      "step": 10166
    },
    {
      "epoch": 0.6030964527227429,
      "grad_norm": 7.2548322677612305,
      "learning_rate": 8.820195096229897e-06,
      "loss": 0.1881,
      "step": 10167
    },
    {
      "epoch": 0.60315577174042,
      "grad_norm": 2.7121005058288574,
      "learning_rate": 8.818876878460323e-06,
      "loss": 0.0299,
      "step": 10168
    },
    {
      "epoch": 0.6032150907580971,
      "grad_norm": 0.1593490093946457,
      "learning_rate": 8.817558660690747e-06,
      "loss": 0.0022,
      "step": 10169
    },
    {
      "epoch": 0.6032744097757741,
      "grad_norm": 13.539045333862305,
      "learning_rate": 8.816240442921172e-06,
      "loss": 0.3881,
      "step": 10170
    },
    {
      "epoch": 0.6033337287934512,
      "grad_norm": 8.241698265075684,
      "learning_rate": 8.814922225151596e-06,
      "loss": 0.4662,
      "step": 10171
    },
    {
      "epoch": 0.6033930478111282,
      "grad_norm": 12.748571395874023,
      "learning_rate": 8.81360400738202e-06,
      "loss": 0.5515,
      "step": 10172
    },
    {
      "epoch": 0.6034523668288053,
      "grad_norm": 7.538358688354492,
      "learning_rate": 8.812285789612444e-06,
      "loss": 0.1422,
      "step": 10173
    },
    {
      "epoch": 0.6035116858464824,
      "grad_norm": 22.807954788208008,
      "learning_rate": 8.810967571842868e-06,
      "loss": 0.5154,
      "step": 10174
    },
    {
      "epoch": 0.6035710048641595,
      "grad_norm": 5.8495965003967285,
      "learning_rate": 8.809649354073294e-06,
      "loss": 0.0684,
      "step": 10175
    },
    {
      "epoch": 0.6036303238818365,
      "grad_norm": 25.745256423950195,
      "learning_rate": 8.808331136303718e-06,
      "loss": 0.9252,
      "step": 10176
    },
    {
      "epoch": 0.6036896428995135,
      "grad_norm": 0.07582730054855347,
      "learning_rate": 8.807012918534143e-06,
      "loss": 0.0012,
      "step": 10177
    },
    {
      "epoch": 0.6037489619171906,
      "grad_norm": 0.11823350936174393,
      "learning_rate": 8.805694700764567e-06,
      "loss": 0.0015,
      "step": 10178
    },
    {
      "epoch": 0.6038082809348677,
      "grad_norm": 0.4567416310310364,
      "learning_rate": 8.804376482994993e-06,
      "loss": 0.0038,
      "step": 10179
    },
    {
      "epoch": 0.6038675999525448,
      "grad_norm": 6.130756855010986,
      "learning_rate": 8.803058265225415e-06,
      "loss": 0.0941,
      "step": 10180
    },
    {
      "epoch": 0.6039269189702219,
      "grad_norm": 1.1599568128585815,
      "learning_rate": 8.80174004745584e-06,
      "loss": 0.0244,
      "step": 10181
    },
    {
      "epoch": 0.603986237987899,
      "grad_norm": 1.49269700050354,
      "learning_rate": 8.800421829686265e-06,
      "loss": 0.0151,
      "step": 10182
    },
    {
      "epoch": 0.6040455570055759,
      "grad_norm": 9.530083656311035,
      "learning_rate": 8.79910361191669e-06,
      "loss": 0.1448,
      "step": 10183
    },
    {
      "epoch": 0.604104876023253,
      "grad_norm": 0.03942263126373291,
      "learning_rate": 8.797785394147114e-06,
      "loss": 0.0011,
      "step": 10184
    },
    {
      "epoch": 0.6041641950409301,
      "grad_norm": 19.154966354370117,
      "learning_rate": 8.796467176377538e-06,
      "loss": 0.2053,
      "step": 10185
    },
    {
      "epoch": 0.6042235140586072,
      "grad_norm": 16.058347702026367,
      "learning_rate": 8.795148958607964e-06,
      "loss": 0.7521,
      "step": 10186
    },
    {
      "epoch": 0.6042828330762843,
      "grad_norm": 0.02635890059173107,
      "learning_rate": 8.793830740838388e-06,
      "loss": 0.0009,
      "step": 10187
    },
    {
      "epoch": 0.6043421520939614,
      "grad_norm": 5.366044521331787,
      "learning_rate": 8.792512523068812e-06,
      "loss": 0.1581,
      "step": 10188
    },
    {
      "epoch": 0.6044014711116384,
      "grad_norm": 0.7343262434005737,
      "learning_rate": 8.791194305299236e-06,
      "loss": 0.007,
      "step": 10189
    },
    {
      "epoch": 0.6044607901293154,
      "grad_norm": 0.038484323769807816,
      "learning_rate": 8.78987608752966e-06,
      "loss": 0.0012,
      "step": 10190
    },
    {
      "epoch": 0.6045201091469925,
      "grad_norm": 0.9660018682479858,
      "learning_rate": 8.788557869760085e-06,
      "loss": 0.0119,
      "step": 10191
    },
    {
      "epoch": 0.6045794281646696,
      "grad_norm": 0.06134422868490219,
      "learning_rate": 8.78723965199051e-06,
      "loss": 0.0014,
      "step": 10192
    },
    {
      "epoch": 0.6046387471823467,
      "grad_norm": 0.03621714562177658,
      "learning_rate": 8.785921434220935e-06,
      "loss": 0.0008,
      "step": 10193
    },
    {
      "epoch": 0.6046980662000238,
      "grad_norm": 0.06389627605676651,
      "learning_rate": 8.784603216451359e-06,
      "loss": 0.0015,
      "step": 10194
    },
    {
      "epoch": 0.6047573852177008,
      "grad_norm": 2.70450496673584,
      "learning_rate": 8.783284998681783e-06,
      "loss": 0.0417,
      "step": 10195
    },
    {
      "epoch": 0.6048167042353778,
      "grad_norm": 21.840267181396484,
      "learning_rate": 8.781966780912207e-06,
      "loss": 0.2419,
      "step": 10196
    },
    {
      "epoch": 0.6048760232530549,
      "grad_norm": 0.6344531774520874,
      "learning_rate": 8.780648563142631e-06,
      "loss": 0.0066,
      "step": 10197
    },
    {
      "epoch": 0.604935342270732,
      "grad_norm": 16.847702026367188,
      "learning_rate": 8.779330345373056e-06,
      "loss": 0.2342,
      "step": 10198
    },
    {
      "epoch": 0.6049946612884091,
      "grad_norm": 0.21189598739147186,
      "learning_rate": 8.778012127603481e-06,
      "loss": 0.0024,
      "step": 10199
    },
    {
      "epoch": 0.6050539803060861,
      "grad_norm": 2.0191636085510254,
      "learning_rate": 8.776693909833906e-06,
      "loss": 0.0077,
      "step": 10200
    },
    {
      "epoch": 0.6051132993237632,
      "grad_norm": 4.292887210845947,
      "learning_rate": 8.77537569206433e-06,
      "loss": 0.169,
      "step": 10201
    },
    {
      "epoch": 0.6051726183414403,
      "grad_norm": 1.1222000122070312,
      "learning_rate": 8.774057474294754e-06,
      "loss": 0.0155,
      "step": 10202
    },
    {
      "epoch": 0.6052319373591173,
      "grad_norm": 10.058511734008789,
      "learning_rate": 8.772739256525178e-06,
      "loss": 0.5986,
      "step": 10203
    },
    {
      "epoch": 0.6052912563767944,
      "grad_norm": 22.159582138061523,
      "learning_rate": 8.771421038755602e-06,
      "loss": 1.0195,
      "step": 10204
    },
    {
      "epoch": 0.6053505753944715,
      "grad_norm": 4.388538360595703,
      "learning_rate": 8.770102820986027e-06,
      "loss": 0.1175,
      "step": 10205
    },
    {
      "epoch": 0.6054098944121485,
      "grad_norm": 1.3472959995269775,
      "learning_rate": 8.768784603216452e-06,
      "loss": 0.02,
      "step": 10206
    },
    {
      "epoch": 0.6054692134298256,
      "grad_norm": 0.016672488301992416,
      "learning_rate": 8.767466385446877e-06,
      "loss": 0.0006,
      "step": 10207
    },
    {
      "epoch": 0.6055285324475027,
      "grad_norm": 0.20596054196357727,
      "learning_rate": 8.7661481676773e-06,
      "loss": 0.0037,
      "step": 10208
    },
    {
      "epoch": 0.6055878514651797,
      "grad_norm": 10.48826789855957,
      "learning_rate": 8.764829949907725e-06,
      "loss": 0.3694,
      "step": 10209
    },
    {
      "epoch": 0.6056471704828568,
      "grad_norm": 11.09737777709961,
      "learning_rate": 8.763511732138151e-06,
      "loss": 0.2657,
      "step": 10210
    },
    {
      "epoch": 0.6057064895005339,
      "grad_norm": 13.05312728881836,
      "learning_rate": 8.762193514368575e-06,
      "loss": 0.5272,
      "step": 10211
    },
    {
      "epoch": 0.6057658085182109,
      "grad_norm": 12.775633811950684,
      "learning_rate": 8.760875296599e-06,
      "loss": 0.1746,
      "step": 10212
    },
    {
      "epoch": 0.605825127535888,
      "grad_norm": 0.12936849892139435,
      "learning_rate": 8.759557078829423e-06,
      "loss": 0.0022,
      "step": 10213
    },
    {
      "epoch": 0.6058844465535651,
      "grad_norm": 12.354239463806152,
      "learning_rate": 8.758238861059848e-06,
      "loss": 0.3529,
      "step": 10214
    },
    {
      "epoch": 0.6059437655712422,
      "grad_norm": 19.07484245300293,
      "learning_rate": 8.756920643290272e-06,
      "loss": 0.5486,
      "step": 10215
    },
    {
      "epoch": 0.6060030845889192,
      "grad_norm": 3.024386405944824,
      "learning_rate": 8.755602425520698e-06,
      "loss": 0.0314,
      "step": 10216
    },
    {
      "epoch": 0.6060624036065962,
      "grad_norm": 0.23243944346904755,
      "learning_rate": 8.754284207751122e-06,
      "loss": 0.005,
      "step": 10217
    },
    {
      "epoch": 0.6061217226242733,
      "grad_norm": 0.04089999571442604,
      "learning_rate": 8.752965989981546e-06,
      "loss": 0.0008,
      "step": 10218
    },
    {
      "epoch": 0.6061810416419504,
      "grad_norm": 0.4732099175453186,
      "learning_rate": 8.75164777221197e-06,
      "loss": 0.0079,
      "step": 10219
    },
    {
      "epoch": 0.6062403606596275,
      "grad_norm": 0.028938785195350647,
      "learning_rate": 8.750329554442394e-06,
      "loss": 0.0005,
      "step": 10220
    },
    {
      "epoch": 0.6062996796773046,
      "grad_norm": 0.8375733494758606,
      "learning_rate": 8.749011336672819e-06,
      "loss": 0.0108,
      "step": 10221
    },
    {
      "epoch": 0.6063589986949817,
      "grad_norm": 5.752594947814941,
      "learning_rate": 8.747693118903243e-06,
      "loss": 0.0944,
      "step": 10222
    },
    {
      "epoch": 0.6064183177126586,
      "grad_norm": 0.9624077677726746,
      "learning_rate": 8.746374901133669e-06,
      "loss": 0.0087,
      "step": 10223
    },
    {
      "epoch": 0.6064776367303357,
      "grad_norm": 15.137821197509766,
      "learning_rate": 8.745056683364093e-06,
      "loss": 0.0544,
      "step": 10224
    },
    {
      "epoch": 0.6065369557480128,
      "grad_norm": 7.397128582000732,
      "learning_rate": 8.743738465594517e-06,
      "loss": 0.0482,
      "step": 10225
    },
    {
      "epoch": 0.6065962747656899,
      "grad_norm": 23.56005096435547,
      "learning_rate": 8.742420247824941e-06,
      "loss": 0.2736,
      "step": 10226
    },
    {
      "epoch": 0.606655593783367,
      "grad_norm": 17.009769439697266,
      "learning_rate": 8.741102030055365e-06,
      "loss": 0.2597,
      "step": 10227
    },
    {
      "epoch": 0.6067149128010441,
      "grad_norm": 0.08573909103870392,
      "learning_rate": 8.73978381228579e-06,
      "loss": 0.0015,
      "step": 10228
    },
    {
      "epoch": 0.606774231818721,
      "grad_norm": 2.218532085418701,
      "learning_rate": 8.738465594516214e-06,
      "loss": 0.0238,
      "step": 10229
    },
    {
      "epoch": 0.6068335508363981,
      "grad_norm": 0.1260680854320526,
      "learning_rate": 8.73714737674664e-06,
      "loss": 0.003,
      "step": 10230
    },
    {
      "epoch": 0.6068928698540752,
      "grad_norm": 1.4466196298599243,
      "learning_rate": 8.735829158977064e-06,
      "loss": 0.0162,
      "step": 10231
    },
    {
      "epoch": 0.6069521888717523,
      "grad_norm": 1.9677985906600952,
      "learning_rate": 8.734510941207488e-06,
      "loss": 0.027,
      "step": 10232
    },
    {
      "epoch": 0.6070115078894294,
      "grad_norm": 7.559375762939453,
      "learning_rate": 8.733192723437912e-06,
      "loss": 0.4227,
      "step": 10233
    },
    {
      "epoch": 0.6070708269071065,
      "grad_norm": 2.451587438583374,
      "learning_rate": 8.731874505668338e-06,
      "loss": 0.0409,
      "step": 10234
    },
    {
      "epoch": 0.6071301459247835,
      "grad_norm": 3.8404877185821533,
      "learning_rate": 8.730556287898762e-06,
      "loss": 0.0502,
      "step": 10235
    },
    {
      "epoch": 0.6071894649424605,
      "grad_norm": 0.021866289898753166,
      "learning_rate": 8.729238070129185e-06,
      "loss": 0.0005,
      "step": 10236
    },
    {
      "epoch": 0.6072487839601376,
      "grad_norm": 3.9135453701019287,
      "learning_rate": 8.72791985235961e-06,
      "loss": 0.1018,
      "step": 10237
    },
    {
      "epoch": 0.6073081029778147,
      "grad_norm": 35.46274185180664,
      "learning_rate": 8.726601634590035e-06,
      "loss": 0.8101,
      "step": 10238
    },
    {
      "epoch": 0.6073674219954918,
      "grad_norm": 0.054758209735155106,
      "learning_rate": 8.725283416820459e-06,
      "loss": 0.0012,
      "step": 10239
    },
    {
      "epoch": 0.6074267410131688,
      "grad_norm": 0.14029693603515625,
      "learning_rate": 8.723965199050885e-06,
      "loss": 0.0011,
      "step": 10240
    },
    {
      "epoch": 0.6074860600308459,
      "grad_norm": 0.7429916858673096,
      "learning_rate": 8.72264698128131e-06,
      "loss": 0.0112,
      "step": 10241
    },
    {
      "epoch": 0.6075453790485229,
      "grad_norm": 0.14190053939819336,
      "learning_rate": 8.721328763511733e-06,
      "loss": 0.0017,
      "step": 10242
    },
    {
      "epoch": 0.6076046980662,
      "grad_norm": 29.900535583496094,
      "learning_rate": 8.720010545742158e-06,
      "loss": 1.0453,
      "step": 10243
    },
    {
      "epoch": 0.6076640170838771,
      "grad_norm": 10.704402923583984,
      "learning_rate": 8.718692327972582e-06,
      "loss": 0.3805,
      "step": 10244
    },
    {
      "epoch": 0.6077233361015542,
      "grad_norm": 5.944164276123047,
      "learning_rate": 8.717374110203006e-06,
      "loss": 0.4177,
      "step": 10245
    },
    {
      "epoch": 0.6077826551192312,
      "grad_norm": 2.39738392829895,
      "learning_rate": 8.71605589243343e-06,
      "loss": 0.0203,
      "step": 10246
    },
    {
      "epoch": 0.6078419741369083,
      "grad_norm": 24.104089736938477,
      "learning_rate": 8.714737674663856e-06,
      "loss": 0.8331,
      "step": 10247
    },
    {
      "epoch": 0.6079012931545854,
      "grad_norm": 0.05593262240290642,
      "learning_rate": 8.71341945689428e-06,
      "loss": 0.0015,
      "step": 10248
    },
    {
      "epoch": 0.6079606121722624,
      "grad_norm": 0.02213050052523613,
      "learning_rate": 8.712101239124704e-06,
      "loss": 0.0008,
      "step": 10249
    },
    {
      "epoch": 0.6080199311899395,
      "grad_norm": 1.7398614883422852,
      "learning_rate": 8.710783021355129e-06,
      "loss": 0.0236,
      "step": 10250
    },
    {
      "epoch": 0.6080792502076166,
      "grad_norm": 0.9032294750213623,
      "learning_rate": 8.709464803585553e-06,
      "loss": 0.0134,
      "step": 10251
    },
    {
      "epoch": 0.6081385692252936,
      "grad_norm": 18.624719619750977,
      "learning_rate": 8.708146585815977e-06,
      "loss": 0.3227,
      "step": 10252
    },
    {
      "epoch": 0.6081978882429707,
      "grad_norm": 0.012348500080406666,
      "learning_rate": 8.706828368046401e-06,
      "loss": 0.0003,
      "step": 10253
    },
    {
      "epoch": 0.6082572072606478,
      "grad_norm": 0.010311156511306763,
      "learning_rate": 8.705510150276827e-06,
      "loss": 0.0003,
      "step": 10254
    },
    {
      "epoch": 0.6083165262783248,
      "grad_norm": 0.032703954726457596,
      "learning_rate": 8.704191932507251e-06,
      "loss": 0.0011,
      "step": 10255
    },
    {
      "epoch": 0.6083758452960019,
      "grad_norm": 0.012942293658852577,
      "learning_rate": 8.702873714737675e-06,
      "loss": 0.0005,
      "step": 10256
    },
    {
      "epoch": 0.6084351643136789,
      "grad_norm": 12.76461410522461,
      "learning_rate": 8.7015554969681e-06,
      "loss": 0.1334,
      "step": 10257
    },
    {
      "epoch": 0.608494483331356,
      "grad_norm": 0.9454842209815979,
      "learning_rate": 8.700237279198524e-06,
      "loss": 0.0146,
      "step": 10258
    },
    {
      "epoch": 0.6085538023490331,
      "grad_norm": 0.17015859484672546,
      "learning_rate": 8.698919061428948e-06,
      "loss": 0.0026,
      "step": 10259
    },
    {
      "epoch": 0.6086131213667102,
      "grad_norm": 0.21001650393009186,
      "learning_rate": 8.697600843659372e-06,
      "loss": 0.003,
      "step": 10260
    },
    {
      "epoch": 0.6086724403843873,
      "grad_norm": 0.9265197515487671,
      "learning_rate": 8.696282625889798e-06,
      "loss": 0.0151,
      "step": 10261
    },
    {
      "epoch": 0.6087317594020643,
      "grad_norm": 0.9798187017440796,
      "learning_rate": 8.694964408120222e-06,
      "loss": 0.0078,
      "step": 10262
    },
    {
      "epoch": 0.6087910784197413,
      "grad_norm": 0.05027449503540993,
      "learning_rate": 8.693646190350646e-06,
      "loss": 0.0013,
      "step": 10263
    },
    {
      "epoch": 0.6088503974374184,
      "grad_norm": 0.3574880361557007,
      "learning_rate": 8.692327972581072e-06,
      "loss": 0.0054,
      "step": 10264
    },
    {
      "epoch": 0.6089097164550955,
      "grad_norm": 17.853435516357422,
      "learning_rate": 8.691009754811496e-06,
      "loss": 0.7021,
      "step": 10265
    },
    {
      "epoch": 0.6089690354727726,
      "grad_norm": 22.859577178955078,
      "learning_rate": 8.68969153704192e-06,
      "loss": 0.1598,
      "step": 10266
    },
    {
      "epoch": 0.6090283544904497,
      "grad_norm": 0.34183230996131897,
      "learning_rate": 8.688373319272345e-06,
      "loss": 0.004,
      "step": 10267
    },
    {
      "epoch": 0.6090876735081268,
      "grad_norm": 0.03932933136820793,
      "learning_rate": 8.687055101502769e-06,
      "loss": 0.0009,
      "step": 10268
    },
    {
      "epoch": 0.6091469925258037,
      "grad_norm": 10.670440673828125,
      "learning_rate": 8.685736883733193e-06,
      "loss": 0.3473,
      "step": 10269
    },
    {
      "epoch": 0.6092063115434808,
      "grad_norm": 0.7689849734306335,
      "learning_rate": 8.684418665963617e-06,
      "loss": 0.0091,
      "step": 10270
    },
    {
      "epoch": 0.6092656305611579,
      "grad_norm": 0.6222162842750549,
      "learning_rate": 8.683100448194043e-06,
      "loss": 0.0079,
      "step": 10271
    },
    {
      "epoch": 0.609324949578835,
      "grad_norm": 21.683082580566406,
      "learning_rate": 8.681782230424467e-06,
      "loss": 0.5089,
      "step": 10272
    },
    {
      "epoch": 0.6093842685965121,
      "grad_norm": 11.713630676269531,
      "learning_rate": 8.680464012654892e-06,
      "loss": 0.1893,
      "step": 10273
    },
    {
      "epoch": 0.6094435876141892,
      "grad_norm": 10.016725540161133,
      "learning_rate": 8.679145794885316e-06,
      "loss": 0.0439,
      "step": 10274
    },
    {
      "epoch": 0.6095029066318661,
      "grad_norm": 13.52352237701416,
      "learning_rate": 8.67782757711574e-06,
      "loss": 1.1519,
      "step": 10275
    },
    {
      "epoch": 0.6095622256495432,
      "grad_norm": 6.044893741607666,
      "learning_rate": 8.676509359346164e-06,
      "loss": 0.2046,
      "step": 10276
    },
    {
      "epoch": 0.6096215446672203,
      "grad_norm": 0.8016545176506042,
      "learning_rate": 8.675191141576588e-06,
      "loss": 0.0085,
      "step": 10277
    },
    {
      "epoch": 0.6096808636848974,
      "grad_norm": 1.8337254524230957,
      "learning_rate": 8.673872923807014e-06,
      "loss": 0.0355,
      "step": 10278
    },
    {
      "epoch": 0.6097401827025745,
      "grad_norm": 8.477160453796387,
      "learning_rate": 8.672554706037438e-06,
      "loss": 0.4776,
      "step": 10279
    },
    {
      "epoch": 0.6097995017202515,
      "grad_norm": 3.0649983882904053,
      "learning_rate": 8.671236488267863e-06,
      "loss": 0.0322,
      "step": 10280
    },
    {
      "epoch": 0.6098588207379286,
      "grad_norm": 0.14003701508045197,
      "learning_rate": 8.669918270498287e-06,
      "loss": 0.0026,
      "step": 10281
    },
    {
      "epoch": 0.6099181397556056,
      "grad_norm": 6.40755558013916,
      "learning_rate": 8.668600052728711e-06,
      "loss": 0.2506,
      "step": 10282
    },
    {
      "epoch": 0.6099774587732827,
      "grad_norm": 11.487170219421387,
      "learning_rate": 8.667281834959135e-06,
      "loss": 0.3486,
      "step": 10283
    },
    {
      "epoch": 0.6100367777909598,
      "grad_norm": 23.39913558959961,
      "learning_rate": 8.66596361718956e-06,
      "loss": 0.9784,
      "step": 10284
    },
    {
      "epoch": 0.6100960968086369,
      "grad_norm": 2.956347703933716,
      "learning_rate": 8.664645399419985e-06,
      "loss": 0.0472,
      "step": 10285
    },
    {
      "epoch": 0.6101554158263139,
      "grad_norm": 8.808557510375977,
      "learning_rate": 8.66332718165041e-06,
      "loss": 0.4573,
      "step": 10286
    },
    {
      "epoch": 0.610214734843991,
      "grad_norm": 1.2415229082107544,
      "learning_rate": 8.662008963880834e-06,
      "loss": 0.0208,
      "step": 10287
    },
    {
      "epoch": 0.610274053861668,
      "grad_norm": 0.3391936719417572,
      "learning_rate": 8.66069074611126e-06,
      "loss": 0.0055,
      "step": 10288
    },
    {
      "epoch": 0.6103333728793451,
      "grad_norm": 0.4595218896865845,
      "learning_rate": 8.659372528341684e-06,
      "loss": 0.0067,
      "step": 10289
    },
    {
      "epoch": 0.6103926918970222,
      "grad_norm": 0.34419265389442444,
      "learning_rate": 8.658054310572108e-06,
      "loss": 0.0033,
      "step": 10290
    },
    {
      "epoch": 0.6104520109146993,
      "grad_norm": 10.997934341430664,
      "learning_rate": 8.656736092802532e-06,
      "loss": 0.2701,
      "step": 10291
    },
    {
      "epoch": 0.6105113299323763,
      "grad_norm": 0.12239263951778412,
      "learning_rate": 8.655417875032956e-06,
      "loss": 0.002,
      "step": 10292
    },
    {
      "epoch": 0.6105706489500534,
      "grad_norm": 3.983380079269409,
      "learning_rate": 8.65409965726338e-06,
      "loss": 0.0427,
      "step": 10293
    },
    {
      "epoch": 0.6106299679677305,
      "grad_norm": 0.02973521687090397,
      "learning_rate": 8.652781439493805e-06,
      "loss": 0.0008,
      "step": 10294
    },
    {
      "epoch": 0.6106892869854075,
      "grad_norm": 21.364219665527344,
      "learning_rate": 8.65146322172423e-06,
      "loss": 0.2073,
      "step": 10295
    },
    {
      "epoch": 0.6107486060030846,
      "grad_norm": 5.4144792556762695,
      "learning_rate": 8.650145003954655e-06,
      "loss": 0.4486,
      "step": 10296
    },
    {
      "epoch": 0.6108079250207616,
      "grad_norm": 0.29964274168014526,
      "learning_rate": 8.648826786185079e-06,
      "loss": 0.0049,
      "step": 10297
    },
    {
      "epoch": 0.6108672440384387,
      "grad_norm": 61.254302978515625,
      "learning_rate": 8.647508568415503e-06,
      "loss": 0.2416,
      "step": 10298
    },
    {
      "epoch": 0.6109265630561158,
      "grad_norm": 5.015518665313721,
      "learning_rate": 8.646190350645927e-06,
      "loss": 0.0139,
      "step": 10299
    },
    {
      "epoch": 0.6109858820737929,
      "grad_norm": 2.3130266666412354,
      "learning_rate": 8.644872132876351e-06,
      "loss": 0.0281,
      "step": 10300
    },
    {
      "epoch": 0.61104520109147,
      "grad_norm": 5.540855407714844,
      "learning_rate": 8.643553915106776e-06,
      "loss": 0.1257,
      "step": 10301
    },
    {
      "epoch": 0.611104520109147,
      "grad_norm": 2.3582122325897217,
      "learning_rate": 8.642235697337202e-06,
      "loss": 0.024,
      "step": 10302
    },
    {
      "epoch": 0.611163839126824,
      "grad_norm": 0.13511408865451813,
      "learning_rate": 8.640917479567626e-06,
      "loss": 0.0024,
      "step": 10303
    },
    {
      "epoch": 0.6112231581445011,
      "grad_norm": 0.005832972005009651,
      "learning_rate": 8.63959926179805e-06,
      "loss": 0.0003,
      "step": 10304
    },
    {
      "epoch": 0.6112824771621782,
      "grad_norm": 1.4083731174468994,
      "learning_rate": 8.638281044028474e-06,
      "loss": 0.0102,
      "step": 10305
    },
    {
      "epoch": 0.6113417961798553,
      "grad_norm": 0.02141265571117401,
      "learning_rate": 8.636962826258898e-06,
      "loss": 0.0004,
      "step": 10306
    },
    {
      "epoch": 0.6114011151975324,
      "grad_norm": 0.026461398229002953,
      "learning_rate": 8.635644608489322e-06,
      "loss": 0.0005,
      "step": 10307
    },
    {
      "epoch": 0.6114604342152093,
      "grad_norm": 0.5627217292785645,
      "learning_rate": 8.634326390719747e-06,
      "loss": 0.0063,
      "step": 10308
    },
    {
      "epoch": 0.6115197532328864,
      "grad_norm": 0.36359164118766785,
      "learning_rate": 8.633008172950173e-06,
      "loss": 0.0038,
      "step": 10309
    },
    {
      "epoch": 0.6115790722505635,
      "grad_norm": 0.12404096126556396,
      "learning_rate": 8.631689955180597e-06,
      "loss": 0.0016,
      "step": 10310
    },
    {
      "epoch": 0.6116383912682406,
      "grad_norm": 0.8678545951843262,
      "learning_rate": 8.630371737411021e-06,
      "loss": 0.0123,
      "step": 10311
    },
    {
      "epoch": 0.6116977102859177,
      "grad_norm": 5.069107532501221,
      "learning_rate": 8.629053519641447e-06,
      "loss": 0.0701,
      "step": 10312
    },
    {
      "epoch": 0.6117570293035948,
      "grad_norm": 0.3037191927433014,
      "learning_rate": 8.627735301871871e-06,
      "loss": 0.0048,
      "step": 10313
    },
    {
      "epoch": 0.6118163483212719,
      "grad_norm": 5.000094890594482,
      "learning_rate": 8.626417084102293e-06,
      "loss": 0.2216,
      "step": 10314
    },
    {
      "epoch": 0.6118756673389488,
      "grad_norm": 0.06570913642644882,
      "learning_rate": 8.625098866332718e-06,
      "loss": 0.0011,
      "step": 10315
    },
    {
      "epoch": 0.6119349863566259,
      "grad_norm": 0.00858317781239748,
      "learning_rate": 8.623780648563144e-06,
      "loss": 0.0003,
      "step": 10316
    },
    {
      "epoch": 0.611994305374303,
      "grad_norm": 18.771068572998047,
      "learning_rate": 8.622462430793568e-06,
      "loss": 0.3298,
      "step": 10317
    },
    {
      "epoch": 0.6120536243919801,
      "grad_norm": 13.039995193481445,
      "learning_rate": 8.621144213023992e-06,
      "loss": 0.2146,
      "step": 10318
    },
    {
      "epoch": 0.6121129434096572,
      "grad_norm": 14.289605140686035,
      "learning_rate": 8.619825995254418e-06,
      "loss": 0.7452,
      "step": 10319
    },
    {
      "epoch": 0.6121722624273342,
      "grad_norm": 0.6095305681228638,
      "learning_rate": 8.618507777484842e-06,
      "loss": 0.0063,
      "step": 10320
    },
    {
      "epoch": 0.6122315814450112,
      "grad_norm": 12.851699829101562,
      "learning_rate": 8.617189559715266e-06,
      "loss": 0.1954,
      "step": 10321
    },
    {
      "epoch": 0.6122909004626883,
      "grad_norm": 13.128392219543457,
      "learning_rate": 8.61587134194569e-06,
      "loss": 0.9613,
      "step": 10322
    },
    {
      "epoch": 0.6123502194803654,
      "grad_norm": 3.6142163276672363,
      "learning_rate": 8.614553124176115e-06,
      "loss": 0.2828,
      "step": 10323
    },
    {
      "epoch": 0.6124095384980425,
      "grad_norm": 0.08744476735591888,
      "learning_rate": 8.613234906406539e-06,
      "loss": 0.0003,
      "step": 10324
    },
    {
      "epoch": 0.6124688575157196,
      "grad_norm": 5.265995025634766,
      "learning_rate": 8.611916688636963e-06,
      "loss": 0.3406,
      "step": 10325
    },
    {
      "epoch": 0.6125281765333966,
      "grad_norm": 0.9590238332748413,
      "learning_rate": 8.610598470867389e-06,
      "loss": 0.0128,
      "step": 10326
    },
    {
      "epoch": 0.6125874955510737,
      "grad_norm": 0.4504740536212921,
      "learning_rate": 8.609280253097813e-06,
      "loss": 0.0063,
      "step": 10327
    },
    {
      "epoch": 0.6126468145687507,
      "grad_norm": 18.99185562133789,
      "learning_rate": 8.607962035328237e-06,
      "loss": 0.8689,
      "step": 10328
    },
    {
      "epoch": 0.6127061335864278,
      "grad_norm": 0.6868666410446167,
      "learning_rate": 8.606643817558661e-06,
      "loss": 0.0124,
      "step": 10329
    },
    {
      "epoch": 0.6127654526041049,
      "grad_norm": 0.35279330611228943,
      "learning_rate": 8.605325599789086e-06,
      "loss": 0.0041,
      "step": 10330
    },
    {
      "epoch": 0.612824771621782,
      "grad_norm": 33.108646392822266,
      "learning_rate": 8.60400738201951e-06,
      "loss": 0.0987,
      "step": 10331
    },
    {
      "epoch": 0.612884090639459,
      "grad_norm": 5.652512073516846,
      "learning_rate": 8.602689164249934e-06,
      "loss": 0.1629,
      "step": 10332
    },
    {
      "epoch": 0.6129434096571361,
      "grad_norm": 0.016148364171385765,
      "learning_rate": 8.60137094648036e-06,
      "loss": 0.0005,
      "step": 10333
    },
    {
      "epoch": 0.6130027286748131,
      "grad_norm": 0.1144154742360115,
      "learning_rate": 8.600052728710784e-06,
      "loss": 0.0022,
      "step": 10334
    },
    {
      "epoch": 0.6130620476924902,
      "grad_norm": 0.0508747324347496,
      "learning_rate": 8.598734510941208e-06,
      "loss": 0.0012,
      "step": 10335
    },
    {
      "epoch": 0.6131213667101673,
      "grad_norm": 9.035524368286133,
      "learning_rate": 8.597416293171632e-06,
      "loss": 0.2276,
      "step": 10336
    },
    {
      "epoch": 0.6131806857278443,
      "grad_norm": 38.94361877441406,
      "learning_rate": 8.596098075402057e-06,
      "loss": 0.6821,
      "step": 10337
    },
    {
      "epoch": 0.6132400047455214,
      "grad_norm": 0.24928277730941772,
      "learning_rate": 8.59477985763248e-06,
      "loss": 0.005,
      "step": 10338
    },
    {
      "epoch": 0.6132993237631985,
      "grad_norm": 10.337677955627441,
      "learning_rate": 8.593461639862905e-06,
      "loss": 0.1651,
      "step": 10339
    },
    {
      "epoch": 0.6133586427808756,
      "grad_norm": 14.451495170593262,
      "learning_rate": 8.59214342209333e-06,
      "loss": 0.1695,
      "step": 10340
    },
    {
      "epoch": 0.6134179617985526,
      "grad_norm": 9.127079010009766,
      "learning_rate": 8.590825204323755e-06,
      "loss": 0.3402,
      "step": 10341
    },
    {
      "epoch": 0.6134772808162297,
      "grad_norm": 0.8828815817832947,
      "learning_rate": 8.58950698655418e-06,
      "loss": 0.0061,
      "step": 10342
    },
    {
      "epoch": 0.6135365998339067,
      "grad_norm": 5.5808587074279785,
      "learning_rate": 8.588188768784605e-06,
      "loss": 0.1934,
      "step": 10343
    },
    {
      "epoch": 0.6135959188515838,
      "grad_norm": 4.459232807159424,
      "learning_rate": 8.58687055101503e-06,
      "loss": 0.0312,
      "step": 10344
    },
    {
      "epoch": 0.6136552378692609,
      "grad_norm": 0.06641712039709091,
      "learning_rate": 8.585552333245453e-06,
      "loss": 0.0014,
      "step": 10345
    },
    {
      "epoch": 0.613714556886938,
      "grad_norm": 5.229404449462891,
      "learning_rate": 8.584234115475878e-06,
      "loss": 0.0843,
      "step": 10346
    },
    {
      "epoch": 0.6137738759046151,
      "grad_norm": 0.04923459142446518,
      "learning_rate": 8.582915897706302e-06,
      "loss": 0.0007,
      "step": 10347
    },
    {
      "epoch": 0.613833194922292,
      "grad_norm": 0.023351406678557396,
      "learning_rate": 8.581597679936726e-06,
      "loss": 0.0006,
      "step": 10348
    },
    {
      "epoch": 0.6138925139399691,
      "grad_norm": 0.12788549065589905,
      "learning_rate": 8.58027946216715e-06,
      "loss": 0.0029,
      "step": 10349
    },
    {
      "epoch": 0.6139518329576462,
      "grad_norm": 4.831256866455078,
      "learning_rate": 8.578961244397576e-06,
      "loss": 0.0315,
      "step": 10350
    },
    {
      "epoch": 0.6140111519753233,
      "grad_norm": 0.016567425802350044,
      "learning_rate": 8.577643026628e-06,
      "loss": 0.0005,
      "step": 10351
    },
    {
      "epoch": 0.6140704709930004,
      "grad_norm": 0.2355785071849823,
      "learning_rate": 8.576324808858424e-06,
      "loss": 0.0031,
      "step": 10352
    },
    {
      "epoch": 0.6141297900106775,
      "grad_norm": 1.8078190088272095,
      "learning_rate": 8.575006591088849e-06,
      "loss": 0.0121,
      "step": 10353
    },
    {
      "epoch": 0.6141891090283544,
      "grad_norm": 0.6349819898605347,
      "learning_rate": 8.573688373319273e-06,
      "loss": 0.013,
      "step": 10354
    },
    {
      "epoch": 0.6142484280460315,
      "grad_norm": 0.35143136978149414,
      "learning_rate": 8.572370155549697e-06,
      "loss": 0.0063,
      "step": 10355
    },
    {
      "epoch": 0.6143077470637086,
      "grad_norm": 0.5199744701385498,
      "learning_rate": 8.571051937780121e-06,
      "loss": 0.009,
      "step": 10356
    },
    {
      "epoch": 0.6143670660813857,
      "grad_norm": 20.924692153930664,
      "learning_rate": 8.569733720010547e-06,
      "loss": 0.5781,
      "step": 10357
    },
    {
      "epoch": 0.6144263850990628,
      "grad_norm": 22.295610427856445,
      "learning_rate": 8.568415502240971e-06,
      "loss": 0.0637,
      "step": 10358
    },
    {
      "epoch": 0.6144857041167399,
      "grad_norm": 22.506160736083984,
      "learning_rate": 8.567097284471395e-06,
      "loss": 0.6686,
      "step": 10359
    },
    {
      "epoch": 0.614545023134417,
      "grad_norm": 1.8805646896362305,
      "learning_rate": 8.56577906670182e-06,
      "loss": 0.0053,
      "step": 10360
    },
    {
      "epoch": 0.6146043421520939,
      "grad_norm": 5.114954948425293,
      "learning_rate": 8.564460848932244e-06,
      "loss": 0.0521,
      "step": 10361
    },
    {
      "epoch": 0.614663661169771,
      "grad_norm": 11.307326316833496,
      "learning_rate": 8.563142631162668e-06,
      "loss": 0.7065,
      "step": 10362
    },
    {
      "epoch": 0.6147229801874481,
      "grad_norm": 0.09275271743535995,
      "learning_rate": 8.561824413393092e-06,
      "loss": 0.0018,
      "step": 10363
    },
    {
      "epoch": 0.6147822992051252,
      "grad_norm": 14.696995735168457,
      "learning_rate": 8.560506195623518e-06,
      "loss": 0.2107,
      "step": 10364
    },
    {
      "epoch": 0.6148416182228023,
      "grad_norm": 7.06178617477417,
      "learning_rate": 8.559187977853942e-06,
      "loss": 0.1091,
      "step": 10365
    },
    {
      "epoch": 0.6149009372404793,
      "grad_norm": 3.1182098388671875,
      "learning_rate": 8.557869760084366e-06,
      "loss": 0.2036,
      "step": 10366
    },
    {
      "epoch": 0.6149602562581563,
      "grad_norm": 3.8644156455993652,
      "learning_rate": 8.556551542314792e-06,
      "loss": 0.0766,
      "step": 10367
    },
    {
      "epoch": 0.6150195752758334,
      "grad_norm": 5.303585529327393,
      "learning_rate": 8.555233324545216e-06,
      "loss": 0.0996,
      "step": 10368
    },
    {
      "epoch": 0.6150788942935105,
      "grad_norm": 22.171794891357422,
      "learning_rate": 8.55391510677564e-06,
      "loss": 0.9582,
      "step": 10369
    },
    {
      "epoch": 0.6151382133111876,
      "grad_norm": 0.48622018098831177,
      "learning_rate": 8.552596889006063e-06,
      "loss": 0.0027,
      "step": 10370
    },
    {
      "epoch": 0.6151975323288646,
      "grad_norm": 3.227466344833374,
      "learning_rate": 8.551278671236489e-06,
      "loss": 0.036,
      "step": 10371
    },
    {
      "epoch": 0.6152568513465417,
      "grad_norm": 0.34078553318977356,
      "learning_rate": 8.549960453466913e-06,
      "loss": 0.0031,
      "step": 10372
    },
    {
      "epoch": 0.6153161703642188,
      "grad_norm": 33.49686813354492,
      "learning_rate": 8.548642235697337e-06,
      "loss": 0.6469,
      "step": 10373
    },
    {
      "epoch": 0.6153754893818958,
      "grad_norm": 3.2679286003112793,
      "learning_rate": 8.547324017927763e-06,
      "loss": 0.2485,
      "step": 10374
    },
    {
      "epoch": 0.6154348083995729,
      "grad_norm": 21.544784545898438,
      "learning_rate": 8.546005800158188e-06,
      "loss": 0.8808,
      "step": 10375
    },
    {
      "epoch": 0.61549412741725,
      "grad_norm": 0.02003330923616886,
      "learning_rate": 8.544687582388612e-06,
      "loss": 0.0006,
      "step": 10376
    },
    {
      "epoch": 0.615553446434927,
      "grad_norm": 0.03171428665518761,
      "learning_rate": 8.543369364619036e-06,
      "loss": 0.0007,
      "step": 10377
    },
    {
      "epoch": 0.6156127654526041,
      "grad_norm": 18.204288482666016,
      "learning_rate": 8.54205114684946e-06,
      "loss": 0.5532,
      "step": 10378
    },
    {
      "epoch": 0.6156720844702812,
      "grad_norm": 5.274148941040039,
      "learning_rate": 8.540732929079884e-06,
      "loss": 0.0335,
      "step": 10379
    },
    {
      "epoch": 0.6157314034879582,
      "grad_norm": 2.9839518070220947,
      "learning_rate": 8.539414711310308e-06,
      "loss": 0.043,
      "step": 10380
    },
    {
      "epoch": 0.6157907225056353,
      "grad_norm": 2.1934049129486084,
      "learning_rate": 8.538096493540734e-06,
      "loss": 0.0138,
      "step": 10381
    },
    {
      "epoch": 0.6158500415233124,
      "grad_norm": 3.4202733039855957,
      "learning_rate": 8.536778275771159e-06,
      "loss": 0.0215,
      "step": 10382
    },
    {
      "epoch": 0.6159093605409894,
      "grad_norm": 10.05953311920166,
      "learning_rate": 8.535460058001583e-06,
      "loss": 0.5138,
      "step": 10383
    },
    {
      "epoch": 0.6159686795586665,
      "grad_norm": 0.021258126944303513,
      "learning_rate": 8.534141840232007e-06,
      "loss": 0.0008,
      "step": 10384
    },
    {
      "epoch": 0.6160279985763436,
      "grad_norm": 0.03473399952054024,
      "learning_rate": 8.532823622462431e-06,
      "loss": 0.0009,
      "step": 10385
    },
    {
      "epoch": 0.6160873175940207,
      "grad_norm": 5.44335412979126,
      "learning_rate": 8.531505404692855e-06,
      "loss": 0.0647,
      "step": 10386
    },
    {
      "epoch": 0.6161466366116977,
      "grad_norm": 0.6640881896018982,
      "learning_rate": 8.53018718692328e-06,
      "loss": 0.0094,
      "step": 10387
    },
    {
      "epoch": 0.6162059556293747,
      "grad_norm": 15.889827728271484,
      "learning_rate": 8.528868969153705e-06,
      "loss": 0.1587,
      "step": 10388
    },
    {
      "epoch": 0.6162652746470518,
      "grad_norm": 0.0052163065411150455,
      "learning_rate": 8.52755075138413e-06,
      "loss": 0.0001,
      "step": 10389
    },
    {
      "epoch": 0.6163245936647289,
      "grad_norm": 0.043046653270721436,
      "learning_rate": 8.526232533614554e-06,
      "loss": 0.0013,
      "step": 10390
    },
    {
      "epoch": 0.616383912682406,
      "grad_norm": 1.2746412754058838,
      "learning_rate": 8.52491431584498e-06,
      "loss": 0.013,
      "step": 10391
    },
    {
      "epoch": 0.6164432317000831,
      "grad_norm": 14.625906944274902,
      "learning_rate": 8.523596098075402e-06,
      "loss": 0.1258,
      "step": 10392
    },
    {
      "epoch": 0.6165025507177602,
      "grad_norm": 0.13719506561756134,
      "learning_rate": 8.522277880305826e-06,
      "loss": 0.0018,
      "step": 10393
    },
    {
      "epoch": 0.6165618697354371,
      "grad_norm": 3.9548215866088867,
      "learning_rate": 8.52095966253625e-06,
      "loss": 0.0814,
      "step": 10394
    },
    {
      "epoch": 0.6166211887531142,
      "grad_norm": 2.062427043914795,
      "learning_rate": 8.519641444766676e-06,
      "loss": 0.0297,
      "step": 10395
    },
    {
      "epoch": 0.6166805077707913,
      "grad_norm": 0.42179203033447266,
      "learning_rate": 8.5183232269971e-06,
      "loss": 0.0036,
      "step": 10396
    },
    {
      "epoch": 0.6167398267884684,
      "grad_norm": 19.741825103759766,
      "learning_rate": 8.517005009227525e-06,
      "loss": 0.4406,
      "step": 10397
    },
    {
      "epoch": 0.6167991458061455,
      "grad_norm": 23.32150650024414,
      "learning_rate": 8.51568679145795e-06,
      "loss": 0.2688,
      "step": 10398
    },
    {
      "epoch": 0.6168584648238226,
      "grad_norm": 0.013319017365574837,
      "learning_rate": 8.514368573688375e-06,
      "loss": 0.0003,
      "step": 10399
    },
    {
      "epoch": 0.6169177838414995,
      "grad_norm": 0.024650814011693,
      "learning_rate": 8.513050355918799e-06,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 0.6169771028591766,
      "grad_norm": 0.5170271992683411,
      "learning_rate": 8.511732138149223e-06,
      "loss": 0.0076,
      "step": 10401
    },
    {
      "epoch": 0.6170364218768537,
      "grad_norm": 7.172309875488281,
      "learning_rate": 8.510413920379647e-06,
      "loss": 0.155,
      "step": 10402
    },
    {
      "epoch": 0.6170957408945308,
      "grad_norm": 3.729663610458374,
      "learning_rate": 8.509095702610072e-06,
      "loss": 0.0489,
      "step": 10403
    },
    {
      "epoch": 0.6171550599122079,
      "grad_norm": 13.971182823181152,
      "learning_rate": 8.507777484840496e-06,
      "loss": 0.4846,
      "step": 10404
    },
    {
      "epoch": 0.617214378929885,
      "grad_norm": 0.12097294628620148,
      "learning_rate": 8.506459267070922e-06,
      "loss": 0.0025,
      "step": 10405
    },
    {
      "epoch": 0.617273697947562,
      "grad_norm": 0.021353716030716896,
      "learning_rate": 8.505141049301346e-06,
      "loss": 0.0007,
      "step": 10406
    },
    {
      "epoch": 0.617333016965239,
      "grad_norm": 2.2493391036987305,
      "learning_rate": 8.50382283153177e-06,
      "loss": 0.0305,
      "step": 10407
    },
    {
      "epoch": 0.6173923359829161,
      "grad_norm": 0.26287275552749634,
      "learning_rate": 8.502504613762194e-06,
      "loss": 0.0044,
      "step": 10408
    },
    {
      "epoch": 0.6174516550005932,
      "grad_norm": 0.008831607177853584,
      "learning_rate": 8.501186395992618e-06,
      "loss": 0.0003,
      "step": 10409
    },
    {
      "epoch": 0.6175109740182703,
      "grad_norm": 0.044502004981040955,
      "learning_rate": 8.499868178223043e-06,
      "loss": 0.0012,
      "step": 10410
    },
    {
      "epoch": 0.6175702930359473,
      "grad_norm": 0.007562670391052961,
      "learning_rate": 8.498549960453467e-06,
      "loss": 0.0002,
      "step": 10411
    },
    {
      "epoch": 0.6176296120536244,
      "grad_norm": 1.0284899473190308,
      "learning_rate": 8.497231742683893e-06,
      "loss": 0.0179,
      "step": 10412
    },
    {
      "epoch": 0.6176889310713014,
      "grad_norm": 0.019353721290826797,
      "learning_rate": 8.495913524914317e-06,
      "loss": 0.0003,
      "step": 10413
    },
    {
      "epoch": 0.6177482500889785,
      "grad_norm": 0.035856008529663086,
      "learning_rate": 8.494595307144741e-06,
      "loss": 0.0007,
      "step": 10414
    },
    {
      "epoch": 0.6178075691066556,
      "grad_norm": 0.23598942160606384,
      "learning_rate": 8.493277089375165e-06,
      "loss": 0.0038,
      "step": 10415
    },
    {
      "epoch": 0.6178668881243327,
      "grad_norm": 43.02973556518555,
      "learning_rate": 8.49195887160559e-06,
      "loss": 0.4557,
      "step": 10416
    },
    {
      "epoch": 0.6179262071420097,
      "grad_norm": 0.10659053921699524,
      "learning_rate": 8.490640653836014e-06,
      "loss": 0.0013,
      "step": 10417
    },
    {
      "epoch": 0.6179855261596868,
      "grad_norm": 0.1739494502544403,
      "learning_rate": 8.489322436066438e-06,
      "loss": 0.0028,
      "step": 10418
    },
    {
      "epoch": 0.6180448451773639,
      "grad_norm": 4.444590091705322,
      "learning_rate": 8.488004218296864e-06,
      "loss": 0.0929,
      "step": 10419
    },
    {
      "epoch": 0.6181041641950409,
      "grad_norm": 0.6641959547996521,
      "learning_rate": 8.486686000527288e-06,
      "loss": 0.0119,
      "step": 10420
    },
    {
      "epoch": 0.618163483212718,
      "grad_norm": 37.08224105834961,
      "learning_rate": 8.485367782757712e-06,
      "loss": 0.2681,
      "step": 10421
    },
    {
      "epoch": 0.618222802230395,
      "grad_norm": 2.1204168796539307,
      "learning_rate": 8.484049564988138e-06,
      "loss": 0.023,
      "step": 10422
    },
    {
      "epoch": 0.6182821212480721,
      "grad_norm": 20.26478385925293,
      "learning_rate": 8.482731347218562e-06,
      "loss": 0.7919,
      "step": 10423
    },
    {
      "epoch": 0.6183414402657492,
      "grad_norm": 0.4511008560657501,
      "learning_rate": 8.481413129448986e-06,
      "loss": 0.0056,
      "step": 10424
    },
    {
      "epoch": 0.6184007592834263,
      "grad_norm": 5.894170761108398,
      "learning_rate": 8.48009491167941e-06,
      "loss": 0.0443,
      "step": 10425
    },
    {
      "epoch": 0.6184600783011034,
      "grad_norm": 0.013070843182504177,
      "learning_rate": 8.478776693909835e-06,
      "loss": 0.0004,
      "step": 10426
    },
    {
      "epoch": 0.6185193973187804,
      "grad_norm": 11.626517295837402,
      "learning_rate": 8.477458476140259e-06,
      "loss": 0.2046,
      "step": 10427
    },
    {
      "epoch": 0.6185787163364574,
      "grad_norm": 4.04063081741333,
      "learning_rate": 8.476140258370683e-06,
      "loss": 0.1137,
      "step": 10428
    },
    {
      "epoch": 0.6186380353541345,
      "grad_norm": 6.131133556365967,
      "learning_rate": 8.474822040601109e-06,
      "loss": 0.335,
      "step": 10429
    },
    {
      "epoch": 0.6186973543718116,
      "grad_norm": 0.21234874427318573,
      "learning_rate": 8.473503822831533e-06,
      "loss": 0.0029,
      "step": 10430
    },
    {
      "epoch": 0.6187566733894887,
      "grad_norm": 0.3112757205963135,
      "learning_rate": 8.472185605061957e-06,
      "loss": 0.0055,
      "step": 10431
    },
    {
      "epoch": 0.6188159924071658,
      "grad_norm": 0.4389621913433075,
      "learning_rate": 8.470867387292381e-06,
      "loss": 0.0054,
      "step": 10432
    },
    {
      "epoch": 0.6188753114248428,
      "grad_norm": 0.0675768330693245,
      "learning_rate": 8.469549169522806e-06,
      "loss": 0.0007,
      "step": 10433
    },
    {
      "epoch": 0.6189346304425198,
      "grad_norm": 23.007301330566406,
      "learning_rate": 8.46823095175323e-06,
      "loss": 0.2096,
      "step": 10434
    },
    {
      "epoch": 0.6189939494601969,
      "grad_norm": 0.011698220856487751,
      "learning_rate": 8.466912733983654e-06,
      "loss": 0.0004,
      "step": 10435
    },
    {
      "epoch": 0.619053268477874,
      "grad_norm": 0.03762238845229149,
      "learning_rate": 8.46559451621408e-06,
      "loss": 0.001,
      "step": 10436
    },
    {
      "epoch": 0.6191125874955511,
      "grad_norm": 0.05779626592993736,
      "learning_rate": 8.464276298444504e-06,
      "loss": 0.0018,
      "step": 10437
    },
    {
      "epoch": 0.6191719065132282,
      "grad_norm": 0.15875060856342316,
      "learning_rate": 8.462958080674928e-06,
      "loss": 0.0017,
      "step": 10438
    },
    {
      "epoch": 0.6192312255309053,
      "grad_norm": 0.03941088169813156,
      "learning_rate": 8.461639862905352e-06,
      "loss": 0.0009,
      "step": 10439
    },
    {
      "epoch": 0.6192905445485822,
      "grad_norm": 0.016063757240772247,
      "learning_rate": 8.460321645135777e-06,
      "loss": 0.0004,
      "step": 10440
    },
    {
      "epoch": 0.6193498635662593,
      "grad_norm": 0.28049731254577637,
      "learning_rate": 8.4590034273662e-06,
      "loss": 0.0025,
      "step": 10441
    },
    {
      "epoch": 0.6194091825839364,
      "grad_norm": 0.19960282742977142,
      "learning_rate": 8.457685209596625e-06,
      "loss": 0.0034,
      "step": 10442
    },
    {
      "epoch": 0.6194685016016135,
      "grad_norm": 0.005255513824522495,
      "learning_rate": 8.456366991827051e-06,
      "loss": 0.0002,
      "step": 10443
    },
    {
      "epoch": 0.6195278206192906,
      "grad_norm": 0.0551329180598259,
      "learning_rate": 8.455048774057475e-06,
      "loss": 0.0013,
      "step": 10444
    },
    {
      "epoch": 0.6195871396369677,
      "grad_norm": 1.6216621398925781,
      "learning_rate": 8.4537305562879e-06,
      "loss": 0.0121,
      "step": 10445
    },
    {
      "epoch": 0.6196464586546446,
      "grad_norm": 5.119240760803223,
      "learning_rate": 8.452412338518325e-06,
      "loss": 0.0237,
      "step": 10446
    },
    {
      "epoch": 0.6197057776723217,
      "grad_norm": 0.16590505838394165,
      "learning_rate": 8.45109412074875e-06,
      "loss": 0.0036,
      "step": 10447
    },
    {
      "epoch": 0.6197650966899988,
      "grad_norm": 7.681148052215576,
      "learning_rate": 8.449775902979172e-06,
      "loss": 0.075,
      "step": 10448
    },
    {
      "epoch": 0.6198244157076759,
      "grad_norm": 13.619640350341797,
      "learning_rate": 8.448457685209598e-06,
      "loss": 0.306,
      "step": 10449
    },
    {
      "epoch": 0.619883734725353,
      "grad_norm": 15.198867797851562,
      "learning_rate": 8.447139467440022e-06,
      "loss": 0.4016,
      "step": 10450
    },
    {
      "epoch": 0.61994305374303,
      "grad_norm": 10.500059127807617,
      "learning_rate": 8.445821249670446e-06,
      "loss": 0.2602,
      "step": 10451
    },
    {
      "epoch": 0.6200023727607071,
      "grad_norm": 7.958594799041748,
      "learning_rate": 8.44450303190087e-06,
      "loss": 0.123,
      "step": 10452
    },
    {
      "epoch": 0.6200616917783841,
      "grad_norm": 0.6750802993774414,
      "learning_rate": 8.443184814131296e-06,
      "loss": 0.0029,
      "step": 10453
    },
    {
      "epoch": 0.6201210107960612,
      "grad_norm": 14.3827486038208,
      "learning_rate": 8.44186659636172e-06,
      "loss": 0.8495,
      "step": 10454
    },
    {
      "epoch": 0.6201803298137383,
      "grad_norm": 3.4047200679779053,
      "learning_rate": 8.440548378592144e-06,
      "loss": 0.0608,
      "step": 10455
    },
    {
      "epoch": 0.6202396488314154,
      "grad_norm": 6.540656089782715,
      "learning_rate": 8.439230160822569e-06,
      "loss": 0.0302,
      "step": 10456
    },
    {
      "epoch": 0.6202989678490924,
      "grad_norm": 0.5595133304595947,
      "learning_rate": 8.437911943052993e-06,
      "loss": 0.0037,
      "step": 10457
    },
    {
      "epoch": 0.6203582868667695,
      "grad_norm": 0.2873595058917999,
      "learning_rate": 8.436593725283417e-06,
      "loss": 0.0049,
      "step": 10458
    },
    {
      "epoch": 0.6204176058844465,
      "grad_norm": 0.010735190473496914,
      "learning_rate": 8.435275507513841e-06,
      "loss": 0.0004,
      "step": 10459
    },
    {
      "epoch": 0.6204769249021236,
      "grad_norm": 0.036707211285829544,
      "learning_rate": 8.433957289744267e-06,
      "loss": 0.0009,
      "step": 10460
    },
    {
      "epoch": 0.6205362439198007,
      "grad_norm": 21.635263442993164,
      "learning_rate": 8.432639071974691e-06,
      "loss": 1.0903,
      "step": 10461
    },
    {
      "epoch": 0.6205955629374778,
      "grad_norm": 0.033792249858379364,
      "learning_rate": 8.431320854205115e-06,
      "loss": 0.001,
      "step": 10462
    },
    {
      "epoch": 0.6206548819551548,
      "grad_norm": 0.6551222205162048,
      "learning_rate": 8.43000263643554e-06,
      "loss": 0.0073,
      "step": 10463
    },
    {
      "epoch": 0.6207142009728319,
      "grad_norm": 4.722231388092041,
      "learning_rate": 8.428684418665964e-06,
      "loss": 0.0954,
      "step": 10464
    },
    {
      "epoch": 0.620773519990509,
      "grad_norm": 0.8578413724899292,
      "learning_rate": 8.427366200896388e-06,
      "loss": 0.0073,
      "step": 10465
    },
    {
      "epoch": 0.620832839008186,
      "grad_norm": 15.253169059753418,
      "learning_rate": 8.426047983126812e-06,
      "loss": 0.2376,
      "step": 10466
    },
    {
      "epoch": 0.6208921580258631,
      "grad_norm": 0.018878156319260597,
      "learning_rate": 8.424729765357238e-06,
      "loss": 0.0005,
      "step": 10467
    },
    {
      "epoch": 0.6209514770435401,
      "grad_norm": 0.05653434619307518,
      "learning_rate": 8.423411547587662e-06,
      "loss": 0.0009,
      "step": 10468
    },
    {
      "epoch": 0.6210107960612172,
      "grad_norm": 1.4692046642303467,
      "learning_rate": 8.422093329818087e-06,
      "loss": 0.0148,
      "step": 10469
    },
    {
      "epoch": 0.6210701150788943,
      "grad_norm": 0.015655027702450752,
      "learning_rate": 8.42077511204851e-06,
      "loss": 0.0003,
      "step": 10470
    },
    {
      "epoch": 0.6211294340965714,
      "grad_norm": 4.3614397048950195,
      "learning_rate": 8.419456894278935e-06,
      "loss": 0.0505,
      "step": 10471
    },
    {
      "epoch": 0.6211887531142485,
      "grad_norm": 4.9414896965026855,
      "learning_rate": 8.418138676509359e-06,
      "loss": 0.0848,
      "step": 10472
    },
    {
      "epoch": 0.6212480721319255,
      "grad_norm": 2.9084701538085938,
      "learning_rate": 8.416820458739785e-06,
      "loss": 0.0355,
      "step": 10473
    },
    {
      "epoch": 0.6213073911496025,
      "grad_norm": 0.21114103496074677,
      "learning_rate": 8.415502240970209e-06,
      "loss": 0.004,
      "step": 10474
    },
    {
      "epoch": 0.6213667101672796,
      "grad_norm": 0.029008403420448303,
      "learning_rate": 8.414184023200633e-06,
      "loss": 0.0006,
      "step": 10475
    },
    {
      "epoch": 0.6214260291849567,
      "grad_norm": 0.8526064157485962,
      "learning_rate": 8.412865805431058e-06,
      "loss": 0.011,
      "step": 10476
    },
    {
      "epoch": 0.6214853482026338,
      "grad_norm": 8.35555362701416,
      "learning_rate": 8.411547587661483e-06,
      "loss": 0.0591,
      "step": 10477
    },
    {
      "epoch": 0.6215446672203109,
      "grad_norm": 7.377104759216309,
      "learning_rate": 8.410229369891908e-06,
      "loss": 0.1716,
      "step": 10478
    },
    {
      "epoch": 0.6216039862379878,
      "grad_norm": 0.008779346942901611,
      "learning_rate": 8.408911152122332e-06,
      "loss": 0.0002,
      "step": 10479
    },
    {
      "epoch": 0.6216633052556649,
      "grad_norm": 1.0845720767974854,
      "learning_rate": 8.407592934352756e-06,
      "loss": 0.0101,
      "step": 10480
    },
    {
      "epoch": 0.621722624273342,
      "grad_norm": 2.286327362060547,
      "learning_rate": 8.40627471658318e-06,
      "loss": 0.0187,
      "step": 10481
    },
    {
      "epoch": 0.6217819432910191,
      "grad_norm": 0.009180616587400436,
      "learning_rate": 8.404956498813604e-06,
      "loss": 0.0002,
      "step": 10482
    },
    {
      "epoch": 0.6218412623086962,
      "grad_norm": 10.585999488830566,
      "learning_rate": 8.403638281044029e-06,
      "loss": 0.9162,
      "step": 10483
    },
    {
      "epoch": 0.6219005813263733,
      "grad_norm": 20.333505630493164,
      "learning_rate": 8.402320063274454e-06,
      "loss": 0.6235,
      "step": 10484
    },
    {
      "epoch": 0.6219599003440504,
      "grad_norm": 0.9810482859611511,
      "learning_rate": 8.401001845504879e-06,
      "loss": 0.0063,
      "step": 10485
    },
    {
      "epoch": 0.6220192193617273,
      "grad_norm": 5.953394889831543,
      "learning_rate": 8.399683627735303e-06,
      "loss": 0.0697,
      "step": 10486
    },
    {
      "epoch": 0.6220785383794044,
      "grad_norm": 0.1131325215101242,
      "learning_rate": 8.398365409965727e-06,
      "loss": 0.0011,
      "step": 10487
    },
    {
      "epoch": 0.6221378573970815,
      "grad_norm": 0.762710452079773,
      "learning_rate": 8.397047192196151e-06,
      "loss": 0.0083,
      "step": 10488
    },
    {
      "epoch": 0.6221971764147586,
      "grad_norm": 1.0922422409057617,
      "learning_rate": 8.395728974426575e-06,
      "loss": 0.0093,
      "step": 10489
    },
    {
      "epoch": 0.6222564954324357,
      "grad_norm": 3.477773666381836,
      "learning_rate": 8.394410756657e-06,
      "loss": 0.0949,
      "step": 10490
    },
    {
      "epoch": 0.6223158144501127,
      "grad_norm": 6.410592079162598,
      "learning_rate": 8.393092538887425e-06,
      "loss": 0.6286,
      "step": 10491
    },
    {
      "epoch": 0.6223751334677897,
      "grad_norm": 0.2648611068725586,
      "learning_rate": 8.39177432111785e-06,
      "loss": 0.0017,
      "step": 10492
    },
    {
      "epoch": 0.6224344524854668,
      "grad_norm": 0.007693131919950247,
      "learning_rate": 8.390456103348274e-06,
      "loss": 0.0003,
      "step": 10493
    },
    {
      "epoch": 0.6224937715031439,
      "grad_norm": 1.0672913789749146,
      "learning_rate": 8.389137885578698e-06,
      "loss": 0.0097,
      "step": 10494
    },
    {
      "epoch": 0.622553090520821,
      "grad_norm": 12.164167404174805,
      "learning_rate": 8.387819667809122e-06,
      "loss": 0.0484,
      "step": 10495
    },
    {
      "epoch": 0.6226124095384981,
      "grad_norm": 31.513671875,
      "learning_rate": 8.386501450039546e-06,
      "loss": 0.4316,
      "step": 10496
    },
    {
      "epoch": 0.6226717285561751,
      "grad_norm": 11.166536331176758,
      "learning_rate": 8.385183232269972e-06,
      "loss": 0.4805,
      "step": 10497
    },
    {
      "epoch": 0.6227310475738522,
      "grad_norm": 20.15597152709961,
      "learning_rate": 8.383865014500396e-06,
      "loss": 0.4487,
      "step": 10498
    },
    {
      "epoch": 0.6227903665915292,
      "grad_norm": 0.011794688180088997,
      "learning_rate": 8.38254679673082e-06,
      "loss": 0.0004,
      "step": 10499
    },
    {
      "epoch": 0.6228496856092063,
      "grad_norm": 33.27290725708008,
      "learning_rate": 8.381228578961245e-06,
      "loss": 0.6276,
      "step": 10500
    },
    {
      "epoch": 0.6229090046268834,
      "grad_norm": 12.124343872070312,
      "learning_rate": 8.37991036119167e-06,
      "loss": 0.4101,
      "step": 10501
    },
    {
      "epoch": 0.6229683236445605,
      "grad_norm": 19.4816951751709,
      "learning_rate": 8.378592143422095e-06,
      "loss": 0.957,
      "step": 10502
    },
    {
      "epoch": 0.6230276426622375,
      "grad_norm": 2.3043744564056396,
      "learning_rate": 8.377273925652519e-06,
      "loss": 0.0226,
      "step": 10503
    },
    {
      "epoch": 0.6230869616799146,
      "grad_norm": 0.9834518432617188,
      "learning_rate": 8.375955707882943e-06,
      "loss": 0.0036,
      "step": 10504
    },
    {
      "epoch": 0.6231462806975916,
      "grad_norm": 0.09132254868745804,
      "learning_rate": 8.374637490113367e-06,
      "loss": 0.001,
      "step": 10505
    },
    {
      "epoch": 0.6232055997152687,
      "grad_norm": 0.0038680885918438435,
      "learning_rate": 8.373319272343792e-06,
      "loss": 0.0002,
      "step": 10506
    },
    {
      "epoch": 0.6232649187329458,
      "grad_norm": 39.400230407714844,
      "learning_rate": 8.372001054574216e-06,
      "loss": 0.1292,
      "step": 10507
    },
    {
      "epoch": 0.6233242377506228,
      "grad_norm": 25.64066505432129,
      "learning_rate": 8.370682836804642e-06,
      "loss": 0.9556,
      "step": 10508
    },
    {
      "epoch": 0.6233835567682999,
      "grad_norm": 0.05533350631594658,
      "learning_rate": 8.369364619035066e-06,
      "loss": 0.001,
      "step": 10509
    },
    {
      "epoch": 0.623442875785977,
      "grad_norm": 0.023592274636030197,
      "learning_rate": 8.36804640126549e-06,
      "loss": 0.0004,
      "step": 10510
    },
    {
      "epoch": 0.6235021948036541,
      "grad_norm": 0.02093854732811451,
      "learning_rate": 8.366728183495914e-06,
      "loss": 0.0006,
      "step": 10511
    },
    {
      "epoch": 0.6235615138213311,
      "grad_norm": 9.460013389587402,
      "learning_rate": 8.365409965726338e-06,
      "loss": 0.411,
      "step": 10512
    },
    {
      "epoch": 0.6236208328390082,
      "grad_norm": 27.694820404052734,
      "learning_rate": 8.364091747956763e-06,
      "loss": 0.4773,
      "step": 10513
    },
    {
      "epoch": 0.6236801518566852,
      "grad_norm": 0.09995783120393753,
      "learning_rate": 8.362773530187187e-06,
      "loss": 0.0011,
      "step": 10514
    },
    {
      "epoch": 0.6237394708743623,
      "grad_norm": 0.00940650049597025,
      "learning_rate": 8.361455312417613e-06,
      "loss": 0.0004,
      "step": 10515
    },
    {
      "epoch": 0.6237987898920394,
      "grad_norm": 0.12599554657936096,
      "learning_rate": 8.360137094648037e-06,
      "loss": 0.0025,
      "step": 10516
    },
    {
      "epoch": 0.6238581089097165,
      "grad_norm": 3.858713150024414,
      "learning_rate": 8.358818876878461e-06,
      "loss": 0.1013,
      "step": 10517
    },
    {
      "epoch": 0.6239174279273936,
      "grad_norm": 0.03245561197400093,
      "learning_rate": 8.357500659108885e-06,
      "loss": 0.0007,
      "step": 10518
    },
    {
      "epoch": 0.6239767469450705,
      "grad_norm": 0.44221654534339905,
      "learning_rate": 8.35618244133931e-06,
      "loss": 0.0045,
      "step": 10519
    },
    {
      "epoch": 0.6240360659627476,
      "grad_norm": 2.4438910484313965,
      "learning_rate": 8.354864223569734e-06,
      "loss": 0.0148,
      "step": 10520
    },
    {
      "epoch": 0.6240953849804247,
      "grad_norm": 17.583850860595703,
      "learning_rate": 8.35354600580016e-06,
      "loss": 0.1095,
      "step": 10521
    },
    {
      "epoch": 0.6241547039981018,
      "grad_norm": 0.015862245112657547,
      "learning_rate": 8.352227788030584e-06,
      "loss": 0.0004,
      "step": 10522
    },
    {
      "epoch": 0.6242140230157789,
      "grad_norm": 0.09666391462087631,
      "learning_rate": 8.350909570261008e-06,
      "loss": 0.0017,
      "step": 10523
    },
    {
      "epoch": 0.624273342033456,
      "grad_norm": 9.90848159790039,
      "learning_rate": 8.349591352491432e-06,
      "loss": 0.1798,
      "step": 10524
    },
    {
      "epoch": 0.6243326610511329,
      "grad_norm": 1.200539231300354,
      "learning_rate": 8.348273134721858e-06,
      "loss": 0.0114,
      "step": 10525
    },
    {
      "epoch": 0.62439198006881,
      "grad_norm": 2.7051773071289062,
      "learning_rate": 8.34695491695228e-06,
      "loss": 0.1652,
      "step": 10526
    },
    {
      "epoch": 0.6244512990864871,
      "grad_norm": 0.012780806981027126,
      "learning_rate": 8.345636699182705e-06,
      "loss": 0.0003,
      "step": 10527
    },
    {
      "epoch": 0.6245106181041642,
      "grad_norm": 0.051744554191827774,
      "learning_rate": 8.34431848141313e-06,
      "loss": 0.0011,
      "step": 10528
    },
    {
      "epoch": 0.6245699371218413,
      "grad_norm": 6.8630475997924805,
      "learning_rate": 8.343000263643555e-06,
      "loss": 0.3274,
      "step": 10529
    },
    {
      "epoch": 0.6246292561395184,
      "grad_norm": 0.05881881341338158,
      "learning_rate": 8.341682045873979e-06,
      "loss": 0.0011,
      "step": 10530
    },
    {
      "epoch": 0.6246885751571954,
      "grad_norm": 91.0400619506836,
      "learning_rate": 8.340363828104403e-06,
      "loss": 0.7161,
      "step": 10531
    },
    {
      "epoch": 0.6247478941748724,
      "grad_norm": 3.900134801864624,
      "learning_rate": 8.339045610334829e-06,
      "loss": 0.0682,
      "step": 10532
    },
    {
      "epoch": 0.6248072131925495,
      "grad_norm": 13.533965110778809,
      "learning_rate": 8.337727392565253e-06,
      "loss": 0.2549,
      "step": 10533
    },
    {
      "epoch": 0.6248665322102266,
      "grad_norm": 2.0814037322998047,
      "learning_rate": 8.336409174795677e-06,
      "loss": 0.0216,
      "step": 10534
    },
    {
      "epoch": 0.6249258512279037,
      "grad_norm": 10.520471572875977,
      "learning_rate": 8.335090957026101e-06,
      "loss": 0.2039,
      "step": 10535
    },
    {
      "epoch": 0.6249851702455808,
      "grad_norm": 0.02500491961836815,
      "learning_rate": 8.333772739256526e-06,
      "loss": 0.0003,
      "step": 10536
    },
    {
      "epoch": 0.6250444892632578,
      "grad_norm": 15.338528633117676,
      "learning_rate": 8.33245452148695e-06,
      "loss": 1.9871,
      "step": 10537
    },
    {
      "epoch": 0.6251038082809348,
      "grad_norm": 1.1593406200408936,
      "learning_rate": 8.331136303717374e-06,
      "loss": 0.0075,
      "step": 10538
    },
    {
      "epoch": 0.6251631272986119,
      "grad_norm": 8.802315711975098,
      "learning_rate": 8.3298180859478e-06,
      "loss": 0.4122,
      "step": 10539
    },
    {
      "epoch": 0.625222446316289,
      "grad_norm": 0.2030772715806961,
      "learning_rate": 8.328499868178224e-06,
      "loss": 0.0031,
      "step": 10540
    },
    {
      "epoch": 0.6252817653339661,
      "grad_norm": 0.2952234447002411,
      "learning_rate": 8.327181650408648e-06,
      "loss": 0.003,
      "step": 10541
    },
    {
      "epoch": 0.6253410843516432,
      "grad_norm": 0.005671372637152672,
      "learning_rate": 8.325863432639072e-06,
      "loss": 0.0002,
      "step": 10542
    },
    {
      "epoch": 0.6254004033693202,
      "grad_norm": 1.697413682937622,
      "learning_rate": 8.324545214869497e-06,
      "loss": 0.0181,
      "step": 10543
    },
    {
      "epoch": 0.6254597223869973,
      "grad_norm": 0.10085456818342209,
      "learning_rate": 8.323226997099921e-06,
      "loss": 0.001,
      "step": 10544
    },
    {
      "epoch": 0.6255190414046743,
      "grad_norm": 0.0781949982047081,
      "learning_rate": 8.321908779330347e-06,
      "loss": 0.0017,
      "step": 10545
    },
    {
      "epoch": 0.6255783604223514,
      "grad_norm": 5.831352233886719,
      "learning_rate": 8.320590561560771e-06,
      "loss": 0.7473,
      "step": 10546
    },
    {
      "epoch": 0.6256376794400285,
      "grad_norm": 46.35679626464844,
      "learning_rate": 8.319272343791195e-06,
      "loss": 1.1339,
      "step": 10547
    },
    {
      "epoch": 0.6256969984577055,
      "grad_norm": 0.5327154994010925,
      "learning_rate": 8.31795412602162e-06,
      "loss": 0.0064,
      "step": 10548
    },
    {
      "epoch": 0.6257563174753826,
      "grad_norm": 9.088702201843262,
      "learning_rate": 8.316635908252043e-06,
      "loss": 0.1337,
      "step": 10549
    },
    {
      "epoch": 0.6258156364930597,
      "grad_norm": 0.6540058851242065,
      "learning_rate": 8.315317690482468e-06,
      "loss": 0.0099,
      "step": 10550
    },
    {
      "epoch": 0.6258749555107368,
      "grad_norm": 0.21466773748397827,
      "learning_rate": 8.313999472712892e-06,
      "loss": 0.0024,
      "step": 10551
    },
    {
      "epoch": 0.6259342745284138,
      "grad_norm": 0.02091323584318161,
      "learning_rate": 8.312681254943318e-06,
      "loss": 0.0007,
      "step": 10552
    },
    {
      "epoch": 0.6259935935460909,
      "grad_norm": 3.3857479095458984,
      "learning_rate": 8.311363037173742e-06,
      "loss": 0.0219,
      "step": 10553
    },
    {
      "epoch": 0.6260529125637679,
      "grad_norm": 0.9860278367996216,
      "learning_rate": 8.310044819404166e-06,
      "loss": 0.0176,
      "step": 10554
    },
    {
      "epoch": 0.626112231581445,
      "grad_norm": 0.04058843106031418,
      "learning_rate": 8.30872660163459e-06,
      "loss": 0.0009,
      "step": 10555
    },
    {
      "epoch": 0.6261715505991221,
      "grad_norm": 7.728074550628662,
      "learning_rate": 8.307408383865016e-06,
      "loss": 0.056,
      "step": 10556
    },
    {
      "epoch": 0.6262308696167992,
      "grad_norm": 1.8866424560546875,
      "learning_rate": 8.30609016609544e-06,
      "loss": 0.1042,
      "step": 10557
    },
    {
      "epoch": 0.6262901886344762,
      "grad_norm": 0.023271260783076286,
      "learning_rate": 8.304771948325865e-06,
      "loss": 0.0004,
      "step": 10558
    },
    {
      "epoch": 0.6263495076521532,
      "grad_norm": 0.04248490929603577,
      "learning_rate": 8.303453730556289e-06,
      "loss": 0.0008,
      "step": 10559
    },
    {
      "epoch": 0.6264088266698303,
      "grad_norm": 0.02944614738225937,
      "learning_rate": 8.302135512786713e-06,
      "loss": 0.0009,
      "step": 10560
    },
    {
      "epoch": 0.6264681456875074,
      "grad_norm": 0.01771470159292221,
      "learning_rate": 8.300817295017137e-06,
      "loss": 0.0007,
      "step": 10561
    },
    {
      "epoch": 0.6265274647051845,
      "grad_norm": 7.713698863983154,
      "learning_rate": 8.299499077247561e-06,
      "loss": 0.1327,
      "step": 10562
    },
    {
      "epoch": 0.6265867837228616,
      "grad_norm": 0.03202388808131218,
      "learning_rate": 8.298180859477987e-06,
      "loss": 0.0008,
      "step": 10563
    },
    {
      "epoch": 0.6266461027405387,
      "grad_norm": 13.388788223266602,
      "learning_rate": 8.296862641708411e-06,
      "loss": 0.1998,
      "step": 10564
    },
    {
      "epoch": 0.6267054217582156,
      "grad_norm": 6.11785888671875,
      "learning_rate": 8.295544423938836e-06,
      "loss": 0.0103,
      "step": 10565
    },
    {
      "epoch": 0.6267647407758927,
      "grad_norm": 6.4374470710754395,
      "learning_rate": 8.29422620616926e-06,
      "loss": 0.0325,
      "step": 10566
    },
    {
      "epoch": 0.6268240597935698,
      "grad_norm": 0.03817742317914963,
      "learning_rate": 8.292907988399684e-06,
      "loss": 0.0015,
      "step": 10567
    },
    {
      "epoch": 0.6268833788112469,
      "grad_norm": 27.45875358581543,
      "learning_rate": 8.291589770630108e-06,
      "loss": 1.7899,
      "step": 10568
    },
    {
      "epoch": 0.626942697828924,
      "grad_norm": 11.379014015197754,
      "learning_rate": 8.290271552860534e-06,
      "loss": 0.5265,
      "step": 10569
    },
    {
      "epoch": 0.6270020168466011,
      "grad_norm": 1.005355954170227,
      "learning_rate": 8.288953335090958e-06,
      "loss": 0.0098,
      "step": 10570
    },
    {
      "epoch": 0.627061335864278,
      "grad_norm": 0.2300417572259903,
      "learning_rate": 8.287635117321382e-06,
      "loss": 0.0038,
      "step": 10571
    },
    {
      "epoch": 0.6271206548819551,
      "grad_norm": 9.114543914794922,
      "learning_rate": 8.286316899551807e-06,
      "loss": 0.1225,
      "step": 10572
    },
    {
      "epoch": 0.6271799738996322,
      "grad_norm": 9.792280197143555,
      "learning_rate": 8.28499868178223e-06,
      "loss": 0.0597,
      "step": 10573
    },
    {
      "epoch": 0.6272392929173093,
      "grad_norm": 1.131758451461792,
      "learning_rate": 8.283680464012655e-06,
      "loss": 0.006,
      "step": 10574
    },
    {
      "epoch": 0.6272986119349864,
      "grad_norm": 7.598330497741699,
      "learning_rate": 8.282362246243079e-06,
      "loss": 0.1989,
      "step": 10575
    },
    {
      "epoch": 0.6273579309526635,
      "grad_norm": 0.34967681765556335,
      "learning_rate": 8.281044028473505e-06,
      "loss": 0.0039,
      "step": 10576
    },
    {
      "epoch": 0.6274172499703405,
      "grad_norm": 1.268628478050232,
      "learning_rate": 8.27972581070393e-06,
      "loss": 0.0123,
      "step": 10577
    },
    {
      "epoch": 0.6274765689880175,
      "grad_norm": 2.35233473777771,
      "learning_rate": 8.278407592934353e-06,
      "loss": 0.0232,
      "step": 10578
    },
    {
      "epoch": 0.6275358880056946,
      "grad_norm": 0.046999938786029816,
      "learning_rate": 8.277089375164778e-06,
      "loss": 0.0006,
      "step": 10579
    },
    {
      "epoch": 0.6275952070233717,
      "grad_norm": 1.459023356437683,
      "learning_rate": 8.275771157395203e-06,
      "loss": 0.0097,
      "step": 10580
    },
    {
      "epoch": 0.6276545260410488,
      "grad_norm": 4.316972255706787,
      "learning_rate": 8.274452939625626e-06,
      "loss": 0.0262,
      "step": 10581
    },
    {
      "epoch": 0.6277138450587259,
      "grad_norm": 6.119185924530029,
      "learning_rate": 8.27313472185605e-06,
      "loss": 0.1152,
      "step": 10582
    },
    {
      "epoch": 0.6277731640764029,
      "grad_norm": 0.1329643577337265,
      "learning_rate": 8.271816504086476e-06,
      "loss": 0.0017,
      "step": 10583
    },
    {
      "epoch": 0.6278324830940799,
      "grad_norm": 7.8791184425354,
      "learning_rate": 8.2704982863169e-06,
      "loss": 0.0728,
      "step": 10584
    },
    {
      "epoch": 0.627891802111757,
      "grad_norm": 2.5138092041015625,
      "learning_rate": 8.269180068547324e-06,
      "loss": 0.0155,
      "step": 10585
    },
    {
      "epoch": 0.6279511211294341,
      "grad_norm": 52.81633758544922,
      "learning_rate": 8.267861850777749e-06,
      "loss": 0.8064,
      "step": 10586
    },
    {
      "epoch": 0.6280104401471112,
      "grad_norm": 0.021028148010373116,
      "learning_rate": 8.266543633008174e-06,
      "loss": 0.0008,
      "step": 10587
    },
    {
      "epoch": 0.6280697591647882,
      "grad_norm": 18.997264862060547,
      "learning_rate": 8.265225415238599e-06,
      "loss": 0.7232,
      "step": 10588
    },
    {
      "epoch": 0.6281290781824653,
      "grad_norm": 4.287102222442627,
      "learning_rate": 8.263907197469023e-06,
      "loss": 0.0753,
      "step": 10589
    },
    {
      "epoch": 0.6281883972001424,
      "grad_norm": 0.030833814293146133,
      "learning_rate": 8.262588979699447e-06,
      "loss": 0.0007,
      "step": 10590
    },
    {
      "epoch": 0.6282477162178194,
      "grad_norm": 4.393757343292236,
      "learning_rate": 8.261270761929871e-06,
      "loss": 0.306,
      "step": 10591
    },
    {
      "epoch": 0.6283070352354965,
      "grad_norm": 20.795549392700195,
      "learning_rate": 8.259952544160295e-06,
      "loss": 1.3853,
      "step": 10592
    },
    {
      "epoch": 0.6283663542531736,
      "grad_norm": 0.02732149511575699,
      "learning_rate": 8.258634326390721e-06,
      "loss": 0.0008,
      "step": 10593
    },
    {
      "epoch": 0.6284256732708506,
      "grad_norm": 37.665809631347656,
      "learning_rate": 8.257316108621145e-06,
      "loss": 0.8471,
      "step": 10594
    },
    {
      "epoch": 0.6284849922885277,
      "grad_norm": 67.94239807128906,
      "learning_rate": 8.25599789085157e-06,
      "loss": 0.425,
      "step": 10595
    },
    {
      "epoch": 0.6285443113062048,
      "grad_norm": 0.008411110378801823,
      "learning_rate": 8.254679673081994e-06,
      "loss": 0.0003,
      "step": 10596
    },
    {
      "epoch": 0.6286036303238819,
      "grad_norm": 0.16907209157943726,
      "learning_rate": 8.253361455312418e-06,
      "loss": 0.0026,
      "step": 10597
    },
    {
      "epoch": 0.6286629493415589,
      "grad_norm": 0.48684293031692505,
      "learning_rate": 8.252043237542842e-06,
      "loss": 0.0068,
      "step": 10598
    },
    {
      "epoch": 0.628722268359236,
      "grad_norm": 11.711068153381348,
      "learning_rate": 8.250725019773266e-06,
      "loss": 0.7205,
      "step": 10599
    },
    {
      "epoch": 0.628781587376913,
      "grad_norm": 7.73905086517334,
      "learning_rate": 8.249406802003692e-06,
      "loss": 0.2129,
      "step": 10600
    },
    {
      "epoch": 0.6288409063945901,
      "grad_norm": 2.084902048110962,
      "learning_rate": 8.248088584234116e-06,
      "loss": 0.0108,
      "step": 10601
    },
    {
      "epoch": 0.6289002254122672,
      "grad_norm": 7.287819862365723,
      "learning_rate": 8.24677036646454e-06,
      "loss": 0.3328,
      "step": 10602
    },
    {
      "epoch": 0.6289595444299443,
      "grad_norm": 0.5723208785057068,
      "learning_rate": 8.245452148694965e-06,
      "loss": 0.0123,
      "step": 10603
    },
    {
      "epoch": 0.6290188634476213,
      "grad_norm": 0.008334786631166935,
      "learning_rate": 8.244133930925389e-06,
      "loss": 0.0003,
      "step": 10604
    },
    {
      "epoch": 0.6290781824652983,
      "grad_norm": 0.04865868389606476,
      "learning_rate": 8.242815713155813e-06,
      "loss": 0.0014,
      "step": 10605
    },
    {
      "epoch": 0.6291375014829754,
      "grad_norm": 11.011824607849121,
      "learning_rate": 8.241497495386237e-06,
      "loss": 1.025,
      "step": 10606
    },
    {
      "epoch": 0.6291968205006525,
      "grad_norm": 0.08287275582551956,
      "learning_rate": 8.240179277616663e-06,
      "loss": 0.0013,
      "step": 10607
    },
    {
      "epoch": 0.6292561395183296,
      "grad_norm": 0.18423308432102203,
      "learning_rate": 8.238861059847087e-06,
      "loss": 0.0023,
      "step": 10608
    },
    {
      "epoch": 0.6293154585360067,
      "grad_norm": 7.1778998374938965,
      "learning_rate": 8.237542842077512e-06,
      "loss": 0.3894,
      "step": 10609
    },
    {
      "epoch": 0.6293747775536838,
      "grad_norm": 0.15988430380821228,
      "learning_rate": 8.236224624307936e-06,
      "loss": 0.0024,
      "step": 10610
    },
    {
      "epoch": 0.6294340965713607,
      "grad_norm": 9.510141372680664,
      "learning_rate": 8.234906406538362e-06,
      "loss": 0.3366,
      "step": 10611
    },
    {
      "epoch": 0.6294934155890378,
      "grad_norm": 2.7409908771514893,
      "learning_rate": 8.233588188768786e-06,
      "loss": 0.0204,
      "step": 10612
    },
    {
      "epoch": 0.6295527346067149,
      "grad_norm": 10.816595077514648,
      "learning_rate": 8.23226997099921e-06,
      "loss": 0.5855,
      "step": 10613
    },
    {
      "epoch": 0.629612053624392,
      "grad_norm": 0.026138700544834137,
      "learning_rate": 8.230951753229634e-06,
      "loss": 0.0006,
      "step": 10614
    },
    {
      "epoch": 0.6296713726420691,
      "grad_norm": 2.7345917224884033,
      "learning_rate": 8.229633535460058e-06,
      "loss": 0.0331,
      "step": 10615
    },
    {
      "epoch": 0.6297306916597462,
      "grad_norm": 0.6384407877922058,
      "learning_rate": 8.228315317690483e-06,
      "loss": 0.0077,
      "step": 10616
    },
    {
      "epoch": 0.6297900106774231,
      "grad_norm": 6.391995429992676,
      "learning_rate": 8.226997099920909e-06,
      "loss": 0.2899,
      "step": 10617
    },
    {
      "epoch": 0.6298493296951002,
      "grad_norm": 0.1118319034576416,
      "learning_rate": 8.225678882151333e-06,
      "loss": 0.0028,
      "step": 10618
    },
    {
      "epoch": 0.6299086487127773,
      "grad_norm": 7.716773509979248,
      "learning_rate": 8.224360664381757e-06,
      "loss": 0.2287,
      "step": 10619
    },
    {
      "epoch": 0.6299679677304544,
      "grad_norm": 1.1048699617385864,
      "learning_rate": 8.223042446612181e-06,
      "loss": 0.0092,
      "step": 10620
    },
    {
      "epoch": 0.6300272867481315,
      "grad_norm": 0.5022595524787903,
      "learning_rate": 8.221724228842605e-06,
      "loss": 0.0072,
      "step": 10621
    },
    {
      "epoch": 0.6300866057658085,
      "grad_norm": 9.374486923217773,
      "learning_rate": 8.22040601107303e-06,
      "loss": 0.2007,
      "step": 10622
    },
    {
      "epoch": 0.6301459247834856,
      "grad_norm": 4.513540267944336,
      "learning_rate": 8.219087793303454e-06,
      "loss": 0.0519,
      "step": 10623
    },
    {
      "epoch": 0.6302052438011626,
      "grad_norm": 7.593871593475342,
      "learning_rate": 8.21776957553388e-06,
      "loss": 0.2426,
      "step": 10624
    },
    {
      "epoch": 0.6302645628188397,
      "grad_norm": 0.2953432500362396,
      "learning_rate": 8.216451357764304e-06,
      "loss": 0.0036,
      "step": 10625
    },
    {
      "epoch": 0.6303238818365168,
      "grad_norm": 60.12454605102539,
      "learning_rate": 8.215133139994728e-06,
      "loss": 0.1521,
      "step": 10626
    },
    {
      "epoch": 0.6303832008541939,
      "grad_norm": 3.2377281188964844,
      "learning_rate": 8.213814922225152e-06,
      "loss": 0.0202,
      "step": 10627
    },
    {
      "epoch": 0.6304425198718709,
      "grad_norm": 0.09060370177030563,
      "learning_rate": 8.212496704455576e-06,
      "loss": 0.0015,
      "step": 10628
    },
    {
      "epoch": 0.630501838889548,
      "grad_norm": 0.3075210154056549,
      "learning_rate": 8.211178486686e-06,
      "loss": 0.0043,
      "step": 10629
    },
    {
      "epoch": 0.6305611579072251,
      "grad_norm": 0.18947413563728333,
      "learning_rate": 8.209860268916425e-06,
      "loss": 0.0018,
      "step": 10630
    },
    {
      "epoch": 0.6306204769249021,
      "grad_norm": 3.733431100845337,
      "learning_rate": 8.20854205114685e-06,
      "loss": 0.0997,
      "step": 10631
    },
    {
      "epoch": 0.6306797959425792,
      "grad_norm": 19.112552642822266,
      "learning_rate": 8.207223833377275e-06,
      "loss": 0.4695,
      "step": 10632
    },
    {
      "epoch": 0.6307391149602563,
      "grad_norm": 0.0626499131321907,
      "learning_rate": 8.205905615607699e-06,
      "loss": 0.001,
      "step": 10633
    },
    {
      "epoch": 0.6307984339779333,
      "grad_norm": 2.328132152557373,
      "learning_rate": 8.204587397838125e-06,
      "loss": 0.0195,
      "step": 10634
    },
    {
      "epoch": 0.6308577529956104,
      "grad_norm": 0.20089790225028992,
      "learning_rate": 8.203269180068549e-06,
      "loss": 0.0037,
      "step": 10635
    },
    {
      "epoch": 0.6309170720132875,
      "grad_norm": 8.035361289978027,
      "learning_rate": 8.201950962298973e-06,
      "loss": 0.1007,
      "step": 10636
    },
    {
      "epoch": 0.6309763910309645,
      "grad_norm": 0.013768673874437809,
      "learning_rate": 8.200632744529396e-06,
      "loss": 0.0004,
      "step": 10637
    },
    {
      "epoch": 0.6310357100486416,
      "grad_norm": 2.6627819538116455,
      "learning_rate": 8.199314526759822e-06,
      "loss": 0.0671,
      "step": 10638
    },
    {
      "epoch": 0.6310950290663186,
      "grad_norm": 1.3384288549423218,
      "learning_rate": 8.197996308990246e-06,
      "loss": 0.0183,
      "step": 10639
    },
    {
      "epoch": 0.6311543480839957,
      "grad_norm": 0.05784033238887787,
      "learning_rate": 8.19667809122067e-06,
      "loss": 0.0008,
      "step": 10640
    },
    {
      "epoch": 0.6312136671016728,
      "grad_norm": 6.217111110687256,
      "learning_rate": 8.195359873451096e-06,
      "loss": 0.0671,
      "step": 10641
    },
    {
      "epoch": 0.6312729861193499,
      "grad_norm": 0.08472179621458054,
      "learning_rate": 8.19404165568152e-06,
      "loss": 0.0015,
      "step": 10642
    },
    {
      "epoch": 0.631332305137027,
      "grad_norm": 0.02685123309493065,
      "learning_rate": 8.192723437911944e-06,
      "loss": 0.0009,
      "step": 10643
    },
    {
      "epoch": 0.631391624154704,
      "grad_norm": 8.235152244567871,
      "learning_rate": 8.191405220142368e-06,
      "loss": 0.29,
      "step": 10644
    },
    {
      "epoch": 0.631450943172381,
      "grad_norm": 8.0874605178833,
      "learning_rate": 8.190087002372793e-06,
      "loss": 0.3956,
      "step": 10645
    },
    {
      "epoch": 0.6315102621900581,
      "grad_norm": 18.782018661499023,
      "learning_rate": 8.188768784603217e-06,
      "loss": 0.2234,
      "step": 10646
    },
    {
      "epoch": 0.6315695812077352,
      "grad_norm": 22.690210342407227,
      "learning_rate": 8.187450566833641e-06,
      "loss": 0.1103,
      "step": 10647
    },
    {
      "epoch": 0.6316289002254123,
      "grad_norm": 18.192750930786133,
      "learning_rate": 8.186132349064067e-06,
      "loss": 0.8147,
      "step": 10648
    },
    {
      "epoch": 0.6316882192430894,
      "grad_norm": 2.372600793838501,
      "learning_rate": 8.184814131294491e-06,
      "loss": 0.031,
      "step": 10649
    },
    {
      "epoch": 0.6317475382607664,
      "grad_norm": 15.018882751464844,
      "learning_rate": 8.183495913524915e-06,
      "loss": 0.3588,
      "step": 10650
    },
    {
      "epoch": 0.6318068572784434,
      "grad_norm": 5.979756832122803,
      "learning_rate": 8.18217769575534e-06,
      "loss": 0.0782,
      "step": 10651
    },
    {
      "epoch": 0.6318661762961205,
      "grad_norm": 2.0453922748565674,
      "learning_rate": 8.180859477985764e-06,
      "loss": 0.0209,
      "step": 10652
    },
    {
      "epoch": 0.6319254953137976,
      "grad_norm": 0.016067832708358765,
      "learning_rate": 8.179541260216188e-06,
      "loss": 0.0005,
      "step": 10653
    },
    {
      "epoch": 0.6319848143314747,
      "grad_norm": 1.0336940288543701,
      "learning_rate": 8.178223042446612e-06,
      "loss": 0.0112,
      "step": 10654
    },
    {
      "epoch": 0.6320441333491518,
      "grad_norm": 7.447266578674316,
      "learning_rate": 8.176904824677038e-06,
      "loss": 0.1145,
      "step": 10655
    },
    {
      "epoch": 0.6321034523668289,
      "grad_norm": 0.39684247970581055,
      "learning_rate": 8.175586606907462e-06,
      "loss": 0.0073,
      "step": 10656
    },
    {
      "epoch": 0.6321627713845058,
      "grad_norm": 0.014848493039608002,
      "learning_rate": 8.174268389137886e-06,
      "loss": 0.0005,
      "step": 10657
    },
    {
      "epoch": 0.6322220904021829,
      "grad_norm": 0.2589842975139618,
      "learning_rate": 8.172950171368312e-06,
      "loss": 0.0069,
      "step": 10658
    },
    {
      "epoch": 0.63228140941986,
      "grad_norm": 2.315732717514038,
      "learning_rate": 8.171631953598735e-06,
      "loss": 0.0504,
      "step": 10659
    },
    {
      "epoch": 0.6323407284375371,
      "grad_norm": 0.14268161356449127,
      "learning_rate": 8.170313735829159e-06,
      "loss": 0.0034,
      "step": 10660
    },
    {
      "epoch": 0.6324000474552142,
      "grad_norm": 3.149017333984375,
      "learning_rate": 8.168995518059583e-06,
      "loss": 0.1033,
      "step": 10661
    },
    {
      "epoch": 0.6324593664728912,
      "grad_norm": 0.3119036853313446,
      "learning_rate": 8.167677300290009e-06,
      "loss": 0.0051,
      "step": 10662
    },
    {
      "epoch": 0.6325186854905682,
      "grad_norm": 0.03292645886540413,
      "learning_rate": 8.166359082520433e-06,
      "loss": 0.0007,
      "step": 10663
    },
    {
      "epoch": 0.6325780045082453,
      "grad_norm": 7.950721263885498,
      "learning_rate": 8.165040864750857e-06,
      "loss": 0.1835,
      "step": 10664
    },
    {
      "epoch": 0.6326373235259224,
      "grad_norm": 0.047162190079689026,
      "learning_rate": 8.163722646981283e-06,
      "loss": 0.001,
      "step": 10665
    },
    {
      "epoch": 0.6326966425435995,
      "grad_norm": 0.07873348891735077,
      "learning_rate": 8.162404429211707e-06,
      "loss": 0.0012,
      "step": 10666
    },
    {
      "epoch": 0.6327559615612766,
      "grad_norm": 15.370271682739258,
      "learning_rate": 8.161086211442131e-06,
      "loss": 0.0715,
      "step": 10667
    },
    {
      "epoch": 0.6328152805789536,
      "grad_norm": 7.474143981933594,
      "learning_rate": 8.159767993672556e-06,
      "loss": 0.0807,
      "step": 10668
    },
    {
      "epoch": 0.6328745995966307,
      "grad_norm": 36.80186080932617,
      "learning_rate": 8.15844977590298e-06,
      "loss": 0.7695,
      "step": 10669
    },
    {
      "epoch": 0.6329339186143077,
      "grad_norm": 11.864603042602539,
      "learning_rate": 8.157131558133404e-06,
      "loss": 0.0908,
      "step": 10670
    },
    {
      "epoch": 0.6329932376319848,
      "grad_norm": 0.026939285919070244,
      "learning_rate": 8.155813340363828e-06,
      "loss": 0.0008,
      "step": 10671
    },
    {
      "epoch": 0.6330525566496619,
      "grad_norm": 28.133180618286133,
      "learning_rate": 8.154495122594254e-06,
      "loss": 0.8843,
      "step": 10672
    },
    {
      "epoch": 0.633111875667339,
      "grad_norm": 0.0243800301104784,
      "learning_rate": 8.153176904824678e-06,
      "loss": 0.0006,
      "step": 10673
    },
    {
      "epoch": 0.633171194685016,
      "grad_norm": 0.1526915431022644,
      "learning_rate": 8.151858687055102e-06,
      "loss": 0.002,
      "step": 10674
    },
    {
      "epoch": 0.6332305137026931,
      "grad_norm": 0.022778237238526344,
      "learning_rate": 8.150540469285527e-06,
      "loss": 0.0004,
      "step": 10675
    },
    {
      "epoch": 0.6332898327203702,
      "grad_norm": 0.02498742751777172,
      "learning_rate": 8.14922225151595e-06,
      "loss": 0.0009,
      "step": 10676
    },
    {
      "epoch": 0.6333491517380472,
      "grad_norm": 1.0129998922348022,
      "learning_rate": 8.147904033746375e-06,
      "loss": 0.014,
      "step": 10677
    },
    {
      "epoch": 0.6334084707557243,
      "grad_norm": 2.7202401161193848,
      "learning_rate": 8.1465858159768e-06,
      "loss": 0.0369,
      "step": 10678
    },
    {
      "epoch": 0.6334677897734013,
      "grad_norm": 0.028568293899297714,
      "learning_rate": 8.145267598207225e-06,
      "loss": 0.0005,
      "step": 10679
    },
    {
      "epoch": 0.6335271087910784,
      "grad_norm": 0.04191150888800621,
      "learning_rate": 8.14394938043765e-06,
      "loss": 0.0008,
      "step": 10680
    },
    {
      "epoch": 0.6335864278087555,
      "grad_norm": 25.356464385986328,
      "learning_rate": 8.142631162668073e-06,
      "loss": 0.8673,
      "step": 10681
    },
    {
      "epoch": 0.6336457468264326,
      "grad_norm": 0.2938852906227112,
      "learning_rate": 8.141312944898498e-06,
      "loss": 0.003,
      "step": 10682
    },
    {
      "epoch": 0.6337050658441096,
      "grad_norm": 0.529931366443634,
      "learning_rate": 8.139994727128922e-06,
      "loss": 0.0044,
      "step": 10683
    },
    {
      "epoch": 0.6337643848617867,
      "grad_norm": 0.06963176280260086,
      "learning_rate": 8.138676509359346e-06,
      "loss": 0.0013,
      "step": 10684
    },
    {
      "epoch": 0.6338237038794637,
      "grad_norm": 0.5726884603500366,
      "learning_rate": 8.13735829158977e-06,
      "loss": 0.0106,
      "step": 10685
    },
    {
      "epoch": 0.6338830228971408,
      "grad_norm": 4.004983901977539,
      "learning_rate": 8.136040073820196e-06,
      "loss": 0.0661,
      "step": 10686
    },
    {
      "epoch": 0.6339423419148179,
      "grad_norm": 0.04387831315398216,
      "learning_rate": 8.13472185605062e-06,
      "loss": 0.0013,
      "step": 10687
    },
    {
      "epoch": 0.634001660932495,
      "grad_norm": 15.537086486816406,
      "learning_rate": 8.133403638281044e-06,
      "loss": 0.9592,
      "step": 10688
    },
    {
      "epoch": 0.6340609799501721,
      "grad_norm": 0.13075219094753265,
      "learning_rate": 8.13208542051147e-06,
      "loss": 0.0033,
      "step": 10689
    },
    {
      "epoch": 0.634120298967849,
      "grad_norm": 14.987120628356934,
      "learning_rate": 8.130767202741895e-06,
      "loss": 0.1583,
      "step": 10690
    },
    {
      "epoch": 0.6341796179855261,
      "grad_norm": 18.858884811401367,
      "learning_rate": 8.129448984972319e-06,
      "loss": 0.4281,
      "step": 10691
    },
    {
      "epoch": 0.6342389370032032,
      "grad_norm": 9.404377937316895,
      "learning_rate": 8.128130767202743e-06,
      "loss": 0.2323,
      "step": 10692
    },
    {
      "epoch": 0.6342982560208803,
      "grad_norm": 0.021822141483426094,
      "learning_rate": 8.126812549433167e-06,
      "loss": 0.0006,
      "step": 10693
    },
    {
      "epoch": 0.6343575750385574,
      "grad_norm": 1.019309639930725,
      "learning_rate": 8.125494331663591e-06,
      "loss": 0.0167,
      "step": 10694
    },
    {
      "epoch": 0.6344168940562345,
      "grad_norm": 1.8329145908355713,
      "learning_rate": 8.124176113894015e-06,
      "loss": 0.0204,
      "step": 10695
    },
    {
      "epoch": 0.6344762130739114,
      "grad_norm": 0.7907059788703918,
      "learning_rate": 8.122857896124441e-06,
      "loss": 0.0123,
      "step": 10696
    },
    {
      "epoch": 0.6345355320915885,
      "grad_norm": 0.8711636662483215,
      "learning_rate": 8.121539678354866e-06,
      "loss": 0.01,
      "step": 10697
    },
    {
      "epoch": 0.6345948511092656,
      "grad_norm": 1.187184453010559,
      "learning_rate": 8.12022146058529e-06,
      "loss": 0.0058,
      "step": 10698
    },
    {
      "epoch": 0.6346541701269427,
      "grad_norm": 0.21497021615505219,
      "learning_rate": 8.118903242815714e-06,
      "loss": 0.0019,
      "step": 10699
    },
    {
      "epoch": 0.6347134891446198,
      "grad_norm": 0.07724973559379578,
      "learning_rate": 8.117585025046138e-06,
      "loss": 0.0018,
      "step": 10700
    },
    {
      "epoch": 0.6347728081622969,
      "grad_norm": 0.03803560510277748,
      "learning_rate": 8.116266807276562e-06,
      "loss": 0.0008,
      "step": 10701
    },
    {
      "epoch": 0.634832127179974,
      "grad_norm": 0.011712044477462769,
      "learning_rate": 8.114948589506986e-06,
      "loss": 0.0003,
      "step": 10702
    },
    {
      "epoch": 0.6348914461976509,
      "grad_norm": 12.32985782623291,
      "learning_rate": 8.113630371737412e-06,
      "loss": 0.2803,
      "step": 10703
    },
    {
      "epoch": 0.634950765215328,
      "grad_norm": 0.2334948182106018,
      "learning_rate": 8.112312153967837e-06,
      "loss": 0.001,
      "step": 10704
    },
    {
      "epoch": 0.6350100842330051,
      "grad_norm": 0.013504994101822376,
      "learning_rate": 8.11099393619826e-06,
      "loss": 0.0004,
      "step": 10705
    },
    {
      "epoch": 0.6350694032506822,
      "grad_norm": 21.532337188720703,
      "learning_rate": 8.109675718428685e-06,
      "loss": 0.9938,
      "step": 10706
    },
    {
      "epoch": 0.6351287222683593,
      "grad_norm": 9.47894287109375,
      "learning_rate": 8.108357500659109e-06,
      "loss": 0.368,
      "step": 10707
    },
    {
      "epoch": 0.6351880412860363,
      "grad_norm": 2.3198978900909424,
      "learning_rate": 8.107039282889533e-06,
      "loss": 0.2749,
      "step": 10708
    },
    {
      "epoch": 0.6352473603037133,
      "grad_norm": 0.3668111264705658,
      "learning_rate": 8.105721065119957e-06,
      "loss": 0.0048,
      "step": 10709
    },
    {
      "epoch": 0.6353066793213904,
      "grad_norm": 0.3754862844944,
      "learning_rate": 8.104402847350383e-06,
      "loss": 0.0017,
      "step": 10710
    },
    {
      "epoch": 0.6353659983390675,
      "grad_norm": 0.3690764904022217,
      "learning_rate": 8.103084629580808e-06,
      "loss": 0.0064,
      "step": 10711
    },
    {
      "epoch": 0.6354253173567446,
      "grad_norm": 8.673320770263672,
      "learning_rate": 8.101766411811232e-06,
      "loss": 0.6648,
      "step": 10712
    },
    {
      "epoch": 0.6354846363744217,
      "grad_norm": 10.975675582885742,
      "learning_rate": 8.100448194041658e-06,
      "loss": 0.04,
      "step": 10713
    },
    {
      "epoch": 0.6355439553920987,
      "grad_norm": 0.786209225654602,
      "learning_rate": 8.099129976272082e-06,
      "loss": 0.0117,
      "step": 10714
    },
    {
      "epoch": 0.6356032744097758,
      "grad_norm": 0.15843382477760315,
      "learning_rate": 8.097811758502504e-06,
      "loss": 0.0008,
      "step": 10715
    },
    {
      "epoch": 0.6356625934274528,
      "grad_norm": 4.672029495239258,
      "learning_rate": 8.096493540732928e-06,
      "loss": 0.3342,
      "step": 10716
    },
    {
      "epoch": 0.6357219124451299,
      "grad_norm": 13.487178802490234,
      "learning_rate": 8.095175322963354e-06,
      "loss": 0.3674,
      "step": 10717
    },
    {
      "epoch": 0.635781231462807,
      "grad_norm": 0.0651499554514885,
      "learning_rate": 8.093857105193779e-06,
      "loss": 0.0009,
      "step": 10718
    },
    {
      "epoch": 0.635840550480484,
      "grad_norm": 0.21284794807434082,
      "learning_rate": 8.092538887424203e-06,
      "loss": 0.0026,
      "step": 10719
    },
    {
      "epoch": 0.6358998694981611,
      "grad_norm": 3.2227401733398438,
      "learning_rate": 8.091220669654629e-06,
      "loss": 0.0206,
      "step": 10720
    },
    {
      "epoch": 0.6359591885158382,
      "grad_norm": 12.128637313842773,
      "learning_rate": 8.089902451885053e-06,
      "loss": 0.9721,
      "step": 10721
    },
    {
      "epoch": 0.6360185075335153,
      "grad_norm": 15.824677467346191,
      "learning_rate": 8.088584234115477e-06,
      "loss": 0.4098,
      "step": 10722
    },
    {
      "epoch": 0.6360778265511923,
      "grad_norm": 0.25669944286346436,
      "learning_rate": 8.087266016345901e-06,
      "loss": 0.003,
      "step": 10723
    },
    {
      "epoch": 0.6361371455688694,
      "grad_norm": 9.178550720214844,
      "learning_rate": 8.085947798576325e-06,
      "loss": 1.0863,
      "step": 10724
    },
    {
      "epoch": 0.6361964645865464,
      "grad_norm": 16.54452133178711,
      "learning_rate": 8.08462958080675e-06,
      "loss": 0.5002,
      "step": 10725
    },
    {
      "epoch": 0.6362557836042235,
      "grad_norm": 7.432302474975586,
      "learning_rate": 8.083311363037174e-06,
      "loss": 0.3137,
      "step": 10726
    },
    {
      "epoch": 0.6363151026219006,
      "grad_norm": 0.02036219835281372,
      "learning_rate": 8.0819931452676e-06,
      "loss": 0.0007,
      "step": 10727
    },
    {
      "epoch": 0.6363744216395777,
      "grad_norm": 25.54315757751465,
      "learning_rate": 8.080674927498024e-06,
      "loss": 1.9556,
      "step": 10728
    },
    {
      "epoch": 0.6364337406572547,
      "grad_norm": 0.04998072609305382,
      "learning_rate": 8.079356709728448e-06,
      "loss": 0.0009,
      "step": 10729
    },
    {
      "epoch": 0.6364930596749317,
      "grad_norm": 0.08984655886888504,
      "learning_rate": 8.078038491958872e-06,
      "loss": 0.0016,
      "step": 10730
    },
    {
      "epoch": 0.6365523786926088,
      "grad_norm": 2.207648515701294,
      "learning_rate": 8.076720274189296e-06,
      "loss": 0.0256,
      "step": 10731
    },
    {
      "epoch": 0.6366116977102859,
      "grad_norm": 0.11588601022958755,
      "learning_rate": 8.07540205641972e-06,
      "loss": 0.0015,
      "step": 10732
    },
    {
      "epoch": 0.636671016727963,
      "grad_norm": 29.115009307861328,
      "learning_rate": 8.074083838650145e-06,
      "loss": 0.2346,
      "step": 10733
    },
    {
      "epoch": 0.6367303357456401,
      "grad_norm": 0.13584353029727936,
      "learning_rate": 8.07276562088057e-06,
      "loss": 0.0021,
      "step": 10734
    },
    {
      "epoch": 0.6367896547633172,
      "grad_norm": 0.007056564558297396,
      "learning_rate": 8.071447403110995e-06,
      "loss": 0.0003,
      "step": 10735
    },
    {
      "epoch": 0.6368489737809941,
      "grad_norm": 0.5546445846557617,
      "learning_rate": 8.070129185341419e-06,
      "loss": 0.0035,
      "step": 10736
    },
    {
      "epoch": 0.6369082927986712,
      "grad_norm": 0.02728239633142948,
      "learning_rate": 8.068810967571843e-06,
      "loss": 0.0005,
      "step": 10737
    },
    {
      "epoch": 0.6369676118163483,
      "grad_norm": 0.7054185271263123,
      "learning_rate": 8.067492749802267e-06,
      "loss": 0.0122,
      "step": 10738
    },
    {
      "epoch": 0.6370269308340254,
      "grad_norm": 0.01663178578019142,
      "learning_rate": 8.066174532032692e-06,
      "loss": 0.0004,
      "step": 10739
    },
    {
      "epoch": 0.6370862498517025,
      "grad_norm": 15.275041580200195,
      "learning_rate": 8.064856314263116e-06,
      "loss": 0.2705,
      "step": 10740
    },
    {
      "epoch": 0.6371455688693796,
      "grad_norm": 16.283885955810547,
      "learning_rate": 8.063538096493542e-06,
      "loss": 0.3438,
      "step": 10741
    },
    {
      "epoch": 0.6372048878870565,
      "grad_norm": 10.676673889160156,
      "learning_rate": 8.062219878723966e-06,
      "loss": 0.3166,
      "step": 10742
    },
    {
      "epoch": 0.6372642069047336,
      "grad_norm": 0.6416390538215637,
      "learning_rate": 8.06090166095439e-06,
      "loss": 0.0037,
      "step": 10743
    },
    {
      "epoch": 0.6373235259224107,
      "grad_norm": 24.287490844726562,
      "learning_rate": 8.059583443184816e-06,
      "loss": 0.6633,
      "step": 10744
    },
    {
      "epoch": 0.6373828449400878,
      "grad_norm": 21.23899269104004,
      "learning_rate": 8.05826522541524e-06,
      "loss": 1.0979,
      "step": 10745
    },
    {
      "epoch": 0.6374421639577649,
      "grad_norm": 3.6429555416107178,
      "learning_rate": 8.056947007645664e-06,
      "loss": 0.054,
      "step": 10746
    },
    {
      "epoch": 0.637501482975442,
      "grad_norm": 12.654651641845703,
      "learning_rate": 8.055628789876088e-06,
      "loss": 0.3189,
      "step": 10747
    },
    {
      "epoch": 0.637560801993119,
      "grad_norm": 14.428196907043457,
      "learning_rate": 8.054310572106513e-06,
      "loss": 0.3586,
      "step": 10748
    },
    {
      "epoch": 0.637620121010796,
      "grad_norm": 27.907184600830078,
      "learning_rate": 8.052992354336937e-06,
      "loss": 0.5137,
      "step": 10749
    },
    {
      "epoch": 0.6376794400284731,
      "grad_norm": 4.09536075592041,
      "learning_rate": 8.051674136567361e-06,
      "loss": 0.1143,
      "step": 10750
    },
    {
      "epoch": 0.6377387590461502,
      "grad_norm": 0.04572203382849693,
      "learning_rate": 8.050355918797787e-06,
      "loss": 0.001,
      "step": 10751
    },
    {
      "epoch": 0.6377980780638273,
      "grad_norm": 5.331676006317139,
      "learning_rate": 8.049037701028211e-06,
      "loss": 0.1169,
      "step": 10752
    },
    {
      "epoch": 0.6378573970815044,
      "grad_norm": 9.817177772521973,
      "learning_rate": 8.047719483258635e-06,
      "loss": 0.6,
      "step": 10753
    },
    {
      "epoch": 0.6379167160991814,
      "grad_norm": 0.2995093762874603,
      "learning_rate": 8.04640126548906e-06,
      "loss": 0.0038,
      "step": 10754
    },
    {
      "epoch": 0.6379760351168585,
      "grad_norm": 13.641030311584473,
      "learning_rate": 8.045083047719484e-06,
      "loss": 0.2233,
      "step": 10755
    },
    {
      "epoch": 0.6380353541345355,
      "grad_norm": 0.201842799782753,
      "learning_rate": 8.043764829949908e-06,
      "loss": 0.0016,
      "step": 10756
    },
    {
      "epoch": 0.6380946731522126,
      "grad_norm": 4.048409461975098,
      "learning_rate": 8.042446612180332e-06,
      "loss": 0.0774,
      "step": 10757
    },
    {
      "epoch": 0.6381539921698897,
      "grad_norm": 10.397254943847656,
      "learning_rate": 8.041128394410758e-06,
      "loss": 0.2709,
      "step": 10758
    },
    {
      "epoch": 0.6382133111875667,
      "grad_norm": 3.4425954818725586,
      "learning_rate": 8.039810176641182e-06,
      "loss": 0.0376,
      "step": 10759
    },
    {
      "epoch": 0.6382726302052438,
      "grad_norm": 0.1617998331785202,
      "learning_rate": 8.038491958871606e-06,
      "loss": 0.0043,
      "step": 10760
    },
    {
      "epoch": 0.6383319492229209,
      "grad_norm": 1.239149570465088,
      "learning_rate": 8.03717374110203e-06,
      "loss": 0.0227,
      "step": 10761
    },
    {
      "epoch": 0.6383912682405979,
      "grad_norm": 13.639692306518555,
      "learning_rate": 8.035855523332455e-06,
      "loss": 0.2423,
      "step": 10762
    },
    {
      "epoch": 0.638450587258275,
      "grad_norm": 3.3219687938690186,
      "learning_rate": 8.034537305562879e-06,
      "loss": 0.0349,
      "step": 10763
    },
    {
      "epoch": 0.638509906275952,
      "grad_norm": 0.06559266149997711,
      "learning_rate": 8.033219087793303e-06,
      "loss": 0.0008,
      "step": 10764
    },
    {
      "epoch": 0.6385692252936291,
      "grad_norm": 0.20982903242111206,
      "learning_rate": 8.031900870023729e-06,
      "loss": 0.0032,
      "step": 10765
    },
    {
      "epoch": 0.6386285443113062,
      "grad_norm": 0.07515228539705276,
      "learning_rate": 8.030582652254153e-06,
      "loss": 0.0013,
      "step": 10766
    },
    {
      "epoch": 0.6386878633289833,
      "grad_norm": 5.502238750457764,
      "learning_rate": 8.029264434484577e-06,
      "loss": 0.3145,
      "step": 10767
    },
    {
      "epoch": 0.6387471823466604,
      "grad_norm": 0.1195647120475769,
      "learning_rate": 8.027946216715003e-06,
      "loss": 0.0017,
      "step": 10768
    },
    {
      "epoch": 0.6388065013643374,
      "grad_norm": 32.06515121459961,
      "learning_rate": 8.026627998945427e-06,
      "loss": 1.2937,
      "step": 10769
    },
    {
      "epoch": 0.6388658203820144,
      "grad_norm": 49.46002197265625,
      "learning_rate": 8.025309781175852e-06,
      "loss": 0.491,
      "step": 10770
    },
    {
      "epoch": 0.6389251393996915,
      "grad_norm": 0.1016642153263092,
      "learning_rate": 8.023991563406274e-06,
      "loss": 0.0019,
      "step": 10771
    },
    {
      "epoch": 0.6389844584173686,
      "grad_norm": 24.906051635742188,
      "learning_rate": 8.0226733456367e-06,
      "loss": 0.6344,
      "step": 10772
    },
    {
      "epoch": 0.6390437774350457,
      "grad_norm": 2.451950788497925,
      "learning_rate": 8.021355127867124e-06,
      "loss": 0.0539,
      "step": 10773
    },
    {
      "epoch": 0.6391030964527228,
      "grad_norm": 1.1491029262542725,
      "learning_rate": 8.020036910097548e-06,
      "loss": 0.0145,
      "step": 10774
    },
    {
      "epoch": 0.6391624154703998,
      "grad_norm": 1.6587603092193604,
      "learning_rate": 8.018718692327974e-06,
      "loss": 0.0161,
      "step": 10775
    },
    {
      "epoch": 0.6392217344880768,
      "grad_norm": 0.41828978061676025,
      "learning_rate": 8.017400474558398e-06,
      "loss": 0.0037,
      "step": 10776
    },
    {
      "epoch": 0.6392810535057539,
      "grad_norm": 0.0429268404841423,
      "learning_rate": 8.016082256788823e-06,
      "loss": 0.0011,
      "step": 10777
    },
    {
      "epoch": 0.639340372523431,
      "grad_norm": 7.85090446472168,
      "learning_rate": 8.014764039019247e-06,
      "loss": 0.254,
      "step": 10778
    },
    {
      "epoch": 0.6393996915411081,
      "grad_norm": 7.256048679351807,
      "learning_rate": 8.013445821249671e-06,
      "loss": 0.1717,
      "step": 10779
    },
    {
      "epoch": 0.6394590105587852,
      "grad_norm": 8.947896957397461,
      "learning_rate": 8.012127603480095e-06,
      "loss": 0.1653,
      "step": 10780
    },
    {
      "epoch": 0.6395183295764623,
      "grad_norm": 0.011567013338208199,
      "learning_rate": 8.01080938571052e-06,
      "loss": 0.0004,
      "step": 10781
    },
    {
      "epoch": 0.6395776485941392,
      "grad_norm": 0.014489008113741875,
      "learning_rate": 8.009491167940945e-06,
      "loss": 0.0005,
      "step": 10782
    },
    {
      "epoch": 0.6396369676118163,
      "grad_norm": 12.031288146972656,
      "learning_rate": 8.00817295017137e-06,
      "loss": 0.5147,
      "step": 10783
    },
    {
      "epoch": 0.6396962866294934,
      "grad_norm": 12.407379150390625,
      "learning_rate": 8.006854732401794e-06,
      "loss": 0.0799,
      "step": 10784
    },
    {
      "epoch": 0.6397556056471705,
      "grad_norm": 0.2889104187488556,
      "learning_rate": 8.005536514632218e-06,
      "loss": 0.004,
      "step": 10785
    },
    {
      "epoch": 0.6398149246648476,
      "grad_norm": 13.615255355834961,
      "learning_rate": 8.004218296862642e-06,
      "loss": 0.1614,
      "step": 10786
    },
    {
      "epoch": 0.6398742436825247,
      "grad_norm": 9.7838134765625,
      "learning_rate": 8.002900079093066e-06,
      "loss": 0.1504,
      "step": 10787
    },
    {
      "epoch": 0.6399335627002016,
      "grad_norm": 0.8389051556587219,
      "learning_rate": 8.00158186132349e-06,
      "loss": 0.0123,
      "step": 10788
    },
    {
      "epoch": 0.6399928817178787,
      "grad_norm": 2.78977632522583,
      "learning_rate": 8.000263643553916e-06,
      "loss": 0.0318,
      "step": 10789
    },
    {
      "epoch": 0.6400522007355558,
      "grad_norm": 3.816683292388916,
      "learning_rate": 7.99894542578434e-06,
      "loss": 0.0675,
      "step": 10790
    },
    {
      "epoch": 0.6401115197532329,
      "grad_norm": 0.6675878167152405,
      "learning_rate": 7.997627208014765e-06,
      "loss": 0.007,
      "step": 10791
    },
    {
      "epoch": 0.64017083877091,
      "grad_norm": 0.058474063873291016,
      "learning_rate": 7.99630899024519e-06,
      "loss": 0.0013,
      "step": 10792
    },
    {
      "epoch": 0.640230157788587,
      "grad_norm": 3.5560028553009033,
      "learning_rate": 7.994990772475613e-06,
      "loss": 0.0456,
      "step": 10793
    },
    {
      "epoch": 0.6402894768062641,
      "grad_norm": 0.14006564021110535,
      "learning_rate": 7.993672554706037e-06,
      "loss": 0.0026,
      "step": 10794
    },
    {
      "epoch": 0.6403487958239411,
      "grad_norm": 0.17663414776325226,
      "learning_rate": 7.992354336936461e-06,
      "loss": 0.003,
      "step": 10795
    },
    {
      "epoch": 0.6404081148416182,
      "grad_norm": 0.028577644377946854,
      "learning_rate": 7.991036119166887e-06,
      "loss": 0.0006,
      "step": 10796
    },
    {
      "epoch": 0.6404674338592953,
      "grad_norm": 0.3161563277244568,
      "learning_rate": 7.989717901397311e-06,
      "loss": 0.0041,
      "step": 10797
    },
    {
      "epoch": 0.6405267528769724,
      "grad_norm": 3.9569427967071533,
      "learning_rate": 7.988399683627736e-06,
      "loss": 0.0685,
      "step": 10798
    },
    {
      "epoch": 0.6405860718946494,
      "grad_norm": 0.26749762892723083,
      "learning_rate": 7.987081465858161e-06,
      "loss": 0.0033,
      "step": 10799
    },
    {
      "epoch": 0.6406453909123265,
      "grad_norm": 20.758533477783203,
      "learning_rate": 7.985763248088586e-06,
      "loss": 0.3144,
      "step": 10800
    },
    {
      "epoch": 0.6407047099300036,
      "grad_norm": 13.310824394226074,
      "learning_rate": 7.98444503031901e-06,
      "loss": 0.2847,
      "step": 10801
    },
    {
      "epoch": 0.6407640289476806,
      "grad_norm": 32.04549026489258,
      "learning_rate": 7.983126812549434e-06,
      "loss": 0.6615,
      "step": 10802
    },
    {
      "epoch": 0.6408233479653577,
      "grad_norm": 0.06369362771511078,
      "learning_rate": 7.981808594779858e-06,
      "loss": 0.0019,
      "step": 10803
    },
    {
      "epoch": 0.6408826669830348,
      "grad_norm": 3.053635835647583,
      "learning_rate": 7.980490377010282e-06,
      "loss": 0.334,
      "step": 10804
    },
    {
      "epoch": 0.6409419860007118,
      "grad_norm": 61.477073669433594,
      "learning_rate": 7.979172159240707e-06,
      "loss": 0.2107,
      "step": 10805
    },
    {
      "epoch": 0.6410013050183889,
      "grad_norm": 13.337263107299805,
      "learning_rate": 7.977853941471132e-06,
      "loss": 1.0719,
      "step": 10806
    },
    {
      "epoch": 0.641060624036066,
      "grad_norm": 0.03463531285524368,
      "learning_rate": 7.976535723701557e-06,
      "loss": 0.0008,
      "step": 10807
    },
    {
      "epoch": 0.641119943053743,
      "grad_norm": 0.037366367876529694,
      "learning_rate": 7.97521750593198e-06,
      "loss": 0.0009,
      "step": 10808
    },
    {
      "epoch": 0.6411792620714201,
      "grad_norm": 1.278625726699829,
      "learning_rate": 7.973899288162405e-06,
      "loss": 0.0213,
      "step": 10809
    },
    {
      "epoch": 0.6412385810890971,
      "grad_norm": 0.06559988856315613,
      "learning_rate": 7.97258107039283e-06,
      "loss": 0.0011,
      "step": 10810
    },
    {
      "epoch": 0.6412979001067742,
      "grad_norm": 0.2673666179180145,
      "learning_rate": 7.971262852623253e-06,
      "loss": 0.0038,
      "step": 10811
    },
    {
      "epoch": 0.6413572191244513,
      "grad_norm": 2.9436583518981934,
      "learning_rate": 7.969944634853678e-06,
      "loss": 0.0902,
      "step": 10812
    },
    {
      "epoch": 0.6414165381421284,
      "grad_norm": 2.8396918773651123,
      "learning_rate": 7.968626417084103e-06,
      "loss": 0.0241,
      "step": 10813
    },
    {
      "epoch": 0.6414758571598055,
      "grad_norm": 10.11328125,
      "learning_rate": 7.967308199314528e-06,
      "loss": 0.2436,
      "step": 10814
    },
    {
      "epoch": 0.6415351761774825,
      "grad_norm": 1.4844636917114258,
      "learning_rate": 7.965989981544952e-06,
      "loss": 0.0132,
      "step": 10815
    },
    {
      "epoch": 0.6415944951951595,
      "grad_norm": 11.581305503845215,
      "learning_rate": 7.964671763775376e-06,
      "loss": 0.8245,
      "step": 10816
    },
    {
      "epoch": 0.6416538142128366,
      "grad_norm": 0.24414855241775513,
      "learning_rate": 7.9633535460058e-06,
      "loss": 0.0034,
      "step": 10817
    },
    {
      "epoch": 0.6417131332305137,
      "grad_norm": 0.21801409125328064,
      "learning_rate": 7.962035328236224e-06,
      "loss": 0.0036,
      "step": 10818
    },
    {
      "epoch": 0.6417724522481908,
      "grad_norm": 18.70391082763672,
      "learning_rate": 7.960717110466649e-06,
      "loss": 0.0769,
      "step": 10819
    },
    {
      "epoch": 0.6418317712658679,
      "grad_norm": 1.0909174680709839,
      "learning_rate": 7.959398892697074e-06,
      "loss": 0.0161,
      "step": 10820
    },
    {
      "epoch": 0.6418910902835449,
      "grad_norm": 0.32775527238845825,
      "learning_rate": 7.958080674927499e-06,
      "loss": 0.0049,
      "step": 10821
    },
    {
      "epoch": 0.6419504093012219,
      "grad_norm": 5.273103713989258,
      "learning_rate": 7.956762457157923e-06,
      "loss": 0.0945,
      "step": 10822
    },
    {
      "epoch": 0.642009728318899,
      "grad_norm": 0.4963858425617218,
      "learning_rate": 7.955444239388349e-06,
      "loss": 0.006,
      "step": 10823
    },
    {
      "epoch": 0.6420690473365761,
      "grad_norm": 0.04325156286358833,
      "learning_rate": 7.954126021618773e-06,
      "loss": 0.0011,
      "step": 10824
    },
    {
      "epoch": 0.6421283663542532,
      "grad_norm": 3.0340023040771484,
      "learning_rate": 7.952807803849197e-06,
      "loss": 0.0257,
      "step": 10825
    },
    {
      "epoch": 0.6421876853719303,
      "grad_norm": 3.45002818107605,
      "learning_rate": 7.951489586079621e-06,
      "loss": 0.029,
      "step": 10826
    },
    {
      "epoch": 0.6422470043896074,
      "grad_norm": 0.573611855506897,
      "learning_rate": 7.950171368310045e-06,
      "loss": 0.0108,
      "step": 10827
    },
    {
      "epoch": 0.6423063234072843,
      "grad_norm": 5.2240891456604,
      "learning_rate": 7.94885315054047e-06,
      "loss": 0.2128,
      "step": 10828
    },
    {
      "epoch": 0.6423656424249614,
      "grad_norm": 9.571433067321777,
      "learning_rate": 7.947534932770894e-06,
      "loss": 0.6097,
      "step": 10829
    },
    {
      "epoch": 0.6424249614426385,
      "grad_norm": 0.06044752150774002,
      "learning_rate": 7.94621671500132e-06,
      "loss": 0.0014,
      "step": 10830
    },
    {
      "epoch": 0.6424842804603156,
      "grad_norm": 2.7141947746276855,
      "learning_rate": 7.944898497231744e-06,
      "loss": 0.0508,
      "step": 10831
    },
    {
      "epoch": 0.6425435994779927,
      "grad_norm": 0.2013757973909378,
      "learning_rate": 7.943580279462168e-06,
      "loss": 0.0034,
      "step": 10832
    },
    {
      "epoch": 0.6426029184956698,
      "grad_norm": 0.403433620929718,
      "learning_rate": 7.942262061692592e-06,
      "loss": 0.0056,
      "step": 10833
    },
    {
      "epoch": 0.6426622375133467,
      "grad_norm": 0.10096379369497299,
      "learning_rate": 7.940943843923016e-06,
      "loss": 0.0016,
      "step": 10834
    },
    {
      "epoch": 0.6427215565310238,
      "grad_norm": 0.563842236995697,
      "learning_rate": 7.93962562615344e-06,
      "loss": 0.0054,
      "step": 10835
    },
    {
      "epoch": 0.6427808755487009,
      "grad_norm": 0.026303162798285484,
      "learning_rate": 7.938307408383865e-06,
      "loss": 0.0007,
      "step": 10836
    },
    {
      "epoch": 0.642840194566378,
      "grad_norm": 0.1476191133260727,
      "learning_rate": 7.93698919061429e-06,
      "loss": 0.0028,
      "step": 10837
    },
    {
      "epoch": 0.6428995135840551,
      "grad_norm": 40.186431884765625,
      "learning_rate": 7.935670972844715e-06,
      "loss": 0.233,
      "step": 10838
    },
    {
      "epoch": 0.6429588326017321,
      "grad_norm": 4.317119121551514,
      "learning_rate": 7.934352755075139e-06,
      "loss": 0.0459,
      "step": 10839
    },
    {
      "epoch": 0.6430181516194092,
      "grad_norm": 0.6920551061630249,
      "learning_rate": 7.933034537305563e-06,
      "loss": 0.0078,
      "step": 10840
    },
    {
      "epoch": 0.6430774706370862,
      "grad_norm": 14.69836139678955,
      "learning_rate": 7.931716319535987e-06,
      "loss": 0.4412,
      "step": 10841
    },
    {
      "epoch": 0.6431367896547633,
      "grad_norm": 12.001055717468262,
      "learning_rate": 7.930398101766412e-06,
      "loss": 0.2252,
      "step": 10842
    },
    {
      "epoch": 0.6431961086724404,
      "grad_norm": 0.11080870777368546,
      "learning_rate": 7.929079883996838e-06,
      "loss": 0.0023,
      "step": 10843
    },
    {
      "epoch": 0.6432554276901175,
      "grad_norm": 53.55843734741211,
      "learning_rate": 7.927761666227262e-06,
      "loss": 1.0374,
      "step": 10844
    },
    {
      "epoch": 0.6433147467077945,
      "grad_norm": 0.3536074757575989,
      "learning_rate": 7.926443448457686e-06,
      "loss": 0.0047,
      "step": 10845
    },
    {
      "epoch": 0.6433740657254716,
      "grad_norm": 8.400178909301758,
      "learning_rate": 7.92512523068811e-06,
      "loss": 0.3501,
      "step": 10846
    },
    {
      "epoch": 0.6434333847431487,
      "grad_norm": 2.129772663116455,
      "learning_rate": 7.923807012918536e-06,
      "loss": 0.0142,
      "step": 10847
    },
    {
      "epoch": 0.6434927037608257,
      "grad_norm": 0.016160810366272926,
      "learning_rate": 7.92248879514896e-06,
      "loss": 0.0006,
      "step": 10848
    },
    {
      "epoch": 0.6435520227785028,
      "grad_norm": 15.198556900024414,
      "learning_rate": 7.921170577379383e-06,
      "loss": 0.9417,
      "step": 10849
    },
    {
      "epoch": 0.6436113417961798,
      "grad_norm": 0.20006117224693298,
      "learning_rate": 7.919852359609809e-06,
      "loss": 0.0027,
      "step": 10850
    },
    {
      "epoch": 0.6436706608138569,
      "grad_norm": 9.205999374389648,
      "learning_rate": 7.918534141840233e-06,
      "loss": 0.2195,
      "step": 10851
    },
    {
      "epoch": 0.643729979831534,
      "grad_norm": 4.212617874145508,
      "learning_rate": 7.917215924070657e-06,
      "loss": 0.0242,
      "step": 10852
    },
    {
      "epoch": 0.6437892988492111,
      "grad_norm": 4.452790260314941,
      "learning_rate": 7.915897706301081e-06,
      "loss": 0.0593,
      "step": 10853
    },
    {
      "epoch": 0.6438486178668881,
      "grad_norm": 0.035279110074043274,
      "learning_rate": 7.914579488531507e-06,
      "loss": 0.0007,
      "step": 10854
    },
    {
      "epoch": 0.6439079368845652,
      "grad_norm": 0.0327552855014801,
      "learning_rate": 7.913261270761931e-06,
      "loss": 0.0008,
      "step": 10855
    },
    {
      "epoch": 0.6439672559022422,
      "grad_norm": 4.552349090576172,
      "learning_rate": 7.911943052992355e-06,
      "loss": 0.0623,
      "step": 10856
    },
    {
      "epoch": 0.6440265749199193,
      "grad_norm": 3.5607001781463623,
      "learning_rate": 7.91062483522278e-06,
      "loss": 0.072,
      "step": 10857
    },
    {
      "epoch": 0.6440858939375964,
      "grad_norm": 2.9737772941589355,
      "learning_rate": 7.909306617453204e-06,
      "loss": 0.0193,
      "step": 10858
    },
    {
      "epoch": 0.6441452129552735,
      "grad_norm": 9.004239082336426,
      "learning_rate": 7.907988399683628e-06,
      "loss": 0.3633,
      "step": 10859
    },
    {
      "epoch": 0.6442045319729506,
      "grad_norm": 16.505435943603516,
      "learning_rate": 7.906670181914052e-06,
      "loss": 0.7061,
      "step": 10860
    },
    {
      "epoch": 0.6442638509906276,
      "grad_norm": 29.660995483398438,
      "learning_rate": 7.905351964144478e-06,
      "loss": 0.726,
      "step": 10861
    },
    {
      "epoch": 0.6443231700083046,
      "grad_norm": 8.179733276367188,
      "learning_rate": 7.904033746374902e-06,
      "loss": 0.1134,
      "step": 10862
    },
    {
      "epoch": 0.6443824890259817,
      "grad_norm": 1.1824274063110352,
      "learning_rate": 7.902715528605326e-06,
      "loss": 0.0185,
      "step": 10863
    },
    {
      "epoch": 0.6444418080436588,
      "grad_norm": 3.9250786304473877,
      "learning_rate": 7.90139731083575e-06,
      "loss": 0.0261,
      "step": 10864
    },
    {
      "epoch": 0.6445011270613359,
      "grad_norm": 0.19323863089084625,
      "learning_rate": 7.900079093066175e-06,
      "loss": 0.0035,
      "step": 10865
    },
    {
      "epoch": 0.644560446079013,
      "grad_norm": 0.03199071064591408,
      "learning_rate": 7.898760875296599e-06,
      "loss": 0.0008,
      "step": 10866
    },
    {
      "epoch": 0.64461976509669,
      "grad_norm": 0.9050310850143433,
      "learning_rate": 7.897442657527025e-06,
      "loss": 0.0102,
      "step": 10867
    },
    {
      "epoch": 0.644679084114367,
      "grad_norm": 13.245012283325195,
      "learning_rate": 7.896124439757449e-06,
      "loss": 0.4247,
      "step": 10868
    },
    {
      "epoch": 0.6447384031320441,
      "grad_norm": 4.6687211990356445,
      "learning_rate": 7.894806221987873e-06,
      "loss": 0.0429,
      "step": 10869
    },
    {
      "epoch": 0.6447977221497212,
      "grad_norm": 2.5426599979400635,
      "learning_rate": 7.893488004218297e-06,
      "loss": 0.0312,
      "step": 10870
    },
    {
      "epoch": 0.6448570411673983,
      "grad_norm": 0.09766104817390442,
      "learning_rate": 7.892169786448722e-06,
      "loss": 0.0021,
      "step": 10871
    },
    {
      "epoch": 0.6449163601850754,
      "grad_norm": 8.630603790283203,
      "learning_rate": 7.890851568679146e-06,
      "loss": 0.3838,
      "step": 10872
    },
    {
      "epoch": 0.6449756792027524,
      "grad_norm": 0.056864116340875626,
      "learning_rate": 7.88953335090957e-06,
      "loss": 0.002,
      "step": 10873
    },
    {
      "epoch": 0.6450349982204294,
      "grad_norm": 0.03130834549665451,
      "learning_rate": 7.888215133139996e-06,
      "loss": 0.0009,
      "step": 10874
    },
    {
      "epoch": 0.6450943172381065,
      "grad_norm": 0.026842067018151283,
      "learning_rate": 7.88689691537042e-06,
      "loss": 0.001,
      "step": 10875
    },
    {
      "epoch": 0.6451536362557836,
      "grad_norm": 0.02727593295276165,
      "learning_rate": 7.885578697600844e-06,
      "loss": 0.0005,
      "step": 10876
    },
    {
      "epoch": 0.6452129552734607,
      "grad_norm": 0.13991829752922058,
      "learning_rate": 7.884260479831268e-06,
      "loss": 0.0031,
      "step": 10877
    },
    {
      "epoch": 0.6452722742911378,
      "grad_norm": 0.044043030589818954,
      "learning_rate": 7.882942262061694e-06,
      "loss": 0.0011,
      "step": 10878
    },
    {
      "epoch": 0.6453315933088148,
      "grad_norm": 3.424191474914551,
      "learning_rate": 7.881624044292118e-06,
      "loss": 0.033,
      "step": 10879
    },
    {
      "epoch": 0.6453909123264919,
      "grad_norm": 25.47393226623535,
      "learning_rate": 7.880305826522543e-06,
      "loss": 0.4182,
      "step": 10880
    },
    {
      "epoch": 0.6454502313441689,
      "grad_norm": 9.984600067138672,
      "learning_rate": 7.878987608752967e-06,
      "loss": 0.5645,
      "step": 10881
    },
    {
      "epoch": 0.645509550361846,
      "grad_norm": 27.54949378967285,
      "learning_rate": 7.877669390983391e-06,
      "loss": 0.5778,
      "step": 10882
    },
    {
      "epoch": 0.6455688693795231,
      "grad_norm": 23.141935348510742,
      "learning_rate": 7.876351173213815e-06,
      "loss": 0.3615,
      "step": 10883
    },
    {
      "epoch": 0.6456281883972002,
      "grad_norm": 4.747718334197998,
      "learning_rate": 7.87503295544424e-06,
      "loss": 0.0583,
      "step": 10884
    },
    {
      "epoch": 0.6456875074148772,
      "grad_norm": 0.08522789180278778,
      "learning_rate": 7.873714737674665e-06,
      "loss": 0.0014,
      "step": 10885
    },
    {
      "epoch": 0.6457468264325543,
      "grad_norm": 3.362212896347046,
      "learning_rate": 7.87239651990509e-06,
      "loss": 0.0239,
      "step": 10886
    },
    {
      "epoch": 0.6458061454502313,
      "grad_norm": 3.8302948474884033,
      "learning_rate": 7.871078302135514e-06,
      "loss": 0.027,
      "step": 10887
    },
    {
      "epoch": 0.6458654644679084,
      "grad_norm": 0.032015856355428696,
      "learning_rate": 7.869760084365938e-06,
      "loss": 0.0006,
      "step": 10888
    },
    {
      "epoch": 0.6459247834855855,
      "grad_norm": 0.026059703901410103,
      "learning_rate": 7.868441866596362e-06,
      "loss": 0.0004,
      "step": 10889
    },
    {
      "epoch": 0.6459841025032625,
      "grad_norm": 0.5235556364059448,
      "learning_rate": 7.867123648826786e-06,
      "loss": 0.0069,
      "step": 10890
    },
    {
      "epoch": 0.6460434215209396,
      "grad_norm": 9.54133129119873,
      "learning_rate": 7.865805431057212e-06,
      "loss": 0.2343,
      "step": 10891
    },
    {
      "epoch": 0.6461027405386167,
      "grad_norm": 0.04959113150835037,
      "learning_rate": 7.864487213287636e-06,
      "loss": 0.0008,
      "step": 10892
    },
    {
      "epoch": 0.6461620595562938,
      "grad_norm": 13.215628623962402,
      "learning_rate": 7.86316899551806e-06,
      "loss": 0.3336,
      "step": 10893
    },
    {
      "epoch": 0.6462213785739708,
      "grad_norm": 6.182965278625488,
      "learning_rate": 7.861850777748485e-06,
      "loss": 0.1068,
      "step": 10894
    },
    {
      "epoch": 0.6462806975916479,
      "grad_norm": 3.915762186050415,
      "learning_rate": 7.860532559978909e-06,
      "loss": 0.0831,
      "step": 10895
    },
    {
      "epoch": 0.6463400166093249,
      "grad_norm": 3.1907103061676025,
      "learning_rate": 7.859214342209333e-06,
      "loss": 0.2207,
      "step": 10896
    },
    {
      "epoch": 0.646399335627002,
      "grad_norm": 0.027942147105932236,
      "learning_rate": 7.857896124439757e-06,
      "loss": 0.0007,
      "step": 10897
    },
    {
      "epoch": 0.6464586546446791,
      "grad_norm": 71.28133392333984,
      "learning_rate": 7.856577906670183e-06,
      "loss": 1.0418,
      "step": 10898
    },
    {
      "epoch": 0.6465179736623562,
      "grad_norm": 0.5734723806381226,
      "learning_rate": 7.855259688900607e-06,
      "loss": 0.0049,
      "step": 10899
    },
    {
      "epoch": 0.6465772926800332,
      "grad_norm": 2.3427865505218506,
      "learning_rate": 7.853941471131031e-06,
      "loss": 0.0479,
      "step": 10900
    },
    {
      "epoch": 0.6466366116977103,
      "grad_norm": 0.25738242268562317,
      "learning_rate": 7.852623253361456e-06,
      "loss": 0.0053,
      "step": 10901
    },
    {
      "epoch": 0.6466959307153873,
      "grad_norm": 11.25995922088623,
      "learning_rate": 7.851305035591881e-06,
      "loss": 0.3761,
      "step": 10902
    },
    {
      "epoch": 0.6467552497330644,
      "grad_norm": 0.013692202046513557,
      "learning_rate": 7.849986817822306e-06,
      "loss": 0.0005,
      "step": 10903
    },
    {
      "epoch": 0.6468145687507415,
      "grad_norm": 9.735466957092285,
      "learning_rate": 7.84866860005273e-06,
      "loss": 0.2854,
      "step": 10904
    },
    {
      "epoch": 0.6468738877684186,
      "grad_norm": 1.2633649110794067,
      "learning_rate": 7.847350382283154e-06,
      "loss": 0.0225,
      "step": 10905
    },
    {
      "epoch": 0.6469332067860957,
      "grad_norm": 7.976334571838379,
      "learning_rate": 7.846032164513578e-06,
      "loss": 0.1297,
      "step": 10906
    },
    {
      "epoch": 0.6469925258037726,
      "grad_norm": 0.16931289434432983,
      "learning_rate": 7.844713946744002e-06,
      "loss": 0.0041,
      "step": 10907
    },
    {
      "epoch": 0.6470518448214497,
      "grad_norm": 0.5870432257652283,
      "learning_rate": 7.843395728974427e-06,
      "loss": 0.0052,
      "step": 10908
    },
    {
      "epoch": 0.6471111638391268,
      "grad_norm": 1.1465977430343628,
      "learning_rate": 7.842077511204852e-06,
      "loss": 0.0199,
      "step": 10909
    },
    {
      "epoch": 0.6471704828568039,
      "grad_norm": 0.15489917993545532,
      "learning_rate": 7.840759293435277e-06,
      "loss": 0.003,
      "step": 10910
    },
    {
      "epoch": 0.647229801874481,
      "grad_norm": 1.6402565240859985,
      "learning_rate": 7.839441075665701e-06,
      "loss": 0.0291,
      "step": 10911
    },
    {
      "epoch": 0.6472891208921581,
      "grad_norm": 0.05100622400641441,
      "learning_rate": 7.838122857896125e-06,
      "loss": 0.0014,
      "step": 10912
    },
    {
      "epoch": 0.647348439909835,
      "grad_norm": 26.22513198852539,
      "learning_rate": 7.83680464012655e-06,
      "loss": 0.1426,
      "step": 10913
    },
    {
      "epoch": 0.6474077589275121,
      "grad_norm": 8.537150382995605,
      "learning_rate": 7.835486422356973e-06,
      "loss": 0.0722,
      "step": 10914
    },
    {
      "epoch": 0.6474670779451892,
      "grad_norm": 2.467233419418335,
      "learning_rate": 7.8341682045874e-06,
      "loss": 0.0189,
      "step": 10915
    },
    {
      "epoch": 0.6475263969628663,
      "grad_norm": 0.33794981241226196,
      "learning_rate": 7.832849986817823e-06,
      "loss": 0.0033,
      "step": 10916
    },
    {
      "epoch": 0.6475857159805434,
      "grad_norm": 0.019636135548353195,
      "learning_rate": 7.831531769048248e-06,
      "loss": 0.0006,
      "step": 10917
    },
    {
      "epoch": 0.6476450349982205,
      "grad_norm": 0.08701464533805847,
      "learning_rate": 7.830213551278672e-06,
      "loss": 0.002,
      "step": 10918
    },
    {
      "epoch": 0.6477043540158975,
      "grad_norm": 0.15474741160869598,
      "learning_rate": 7.828895333509096e-06,
      "loss": 0.0029,
      "step": 10919
    },
    {
      "epoch": 0.6477636730335745,
      "grad_norm": 0.04038446024060249,
      "learning_rate": 7.82757711573952e-06,
      "loss": 0.0008,
      "step": 10920
    },
    {
      "epoch": 0.6478229920512516,
      "grad_norm": 10.108414649963379,
      "learning_rate": 7.826258897969944e-06,
      "loss": 0.2647,
      "step": 10921
    },
    {
      "epoch": 0.6478823110689287,
      "grad_norm": 4.892001152038574,
      "learning_rate": 7.82494068020037e-06,
      "loss": 0.0598,
      "step": 10922
    },
    {
      "epoch": 0.6479416300866058,
      "grad_norm": 1.0284452438354492,
      "learning_rate": 7.823622462430794e-06,
      "loss": 0.0148,
      "step": 10923
    },
    {
      "epoch": 0.6480009491042829,
      "grad_norm": 0.15038351714611053,
      "learning_rate": 7.822304244661219e-06,
      "loss": 0.002,
      "step": 10924
    },
    {
      "epoch": 0.6480602681219599,
      "grad_norm": 5.50399112701416,
      "learning_rate": 7.820986026891643e-06,
      "loss": 0.0174,
      "step": 10925
    },
    {
      "epoch": 0.648119587139637,
      "grad_norm": 1.0770115852355957,
      "learning_rate": 7.819667809122069e-06,
      "loss": 0.0099,
      "step": 10926
    },
    {
      "epoch": 0.648178906157314,
      "grad_norm": 0.1573820412158966,
      "learning_rate": 7.818349591352491e-06,
      "loss": 0.0021,
      "step": 10927
    },
    {
      "epoch": 0.6482382251749911,
      "grad_norm": 0.767686128616333,
      "learning_rate": 7.817031373582915e-06,
      "loss": 0.0115,
      "step": 10928
    },
    {
      "epoch": 0.6482975441926682,
      "grad_norm": 1.6608421802520752,
      "learning_rate": 7.815713155813341e-06,
      "loss": 0.0272,
      "step": 10929
    },
    {
      "epoch": 0.6483568632103452,
      "grad_norm": 0.3638860881328583,
      "learning_rate": 7.814394938043765e-06,
      "loss": 0.0025,
      "step": 10930
    },
    {
      "epoch": 0.6484161822280223,
      "grad_norm": 0.5103233456611633,
      "learning_rate": 7.81307672027419e-06,
      "loss": 0.0083,
      "step": 10931
    },
    {
      "epoch": 0.6484755012456994,
      "grad_norm": 2.6175074577331543,
      "learning_rate": 7.811758502504614e-06,
      "loss": 0.0062,
      "step": 10932
    },
    {
      "epoch": 0.6485348202633764,
      "grad_norm": 0.0871669352054596,
      "learning_rate": 7.81044028473504e-06,
      "loss": 0.0008,
      "step": 10933
    },
    {
      "epoch": 0.6485941392810535,
      "grad_norm": 37.31535339355469,
      "learning_rate": 7.809122066965464e-06,
      "loss": 0.2772,
      "step": 10934
    },
    {
      "epoch": 0.6486534582987306,
      "grad_norm": 0.04552450031042099,
      "learning_rate": 7.807803849195888e-06,
      "loss": 0.0014,
      "step": 10935
    },
    {
      "epoch": 0.6487127773164076,
      "grad_norm": 13.521658897399902,
      "learning_rate": 7.806485631426312e-06,
      "loss": 0.1762,
      "step": 10936
    },
    {
      "epoch": 0.6487720963340847,
      "grad_norm": 8.096589088439941,
      "learning_rate": 7.805167413656737e-06,
      "loss": 0.3993,
      "step": 10937
    },
    {
      "epoch": 0.6488314153517618,
      "grad_norm": 0.8108716607093811,
      "learning_rate": 7.80384919588716e-06,
      "loss": 0.0038,
      "step": 10938
    },
    {
      "epoch": 0.6488907343694389,
      "grad_norm": 5.020473003387451,
      "learning_rate": 7.802530978117587e-06,
      "loss": 0.0622,
      "step": 10939
    },
    {
      "epoch": 0.6489500533871159,
      "grad_norm": 5.502915859222412,
      "learning_rate": 7.80121276034801e-06,
      "loss": 0.0543,
      "step": 10940
    },
    {
      "epoch": 0.649009372404793,
      "grad_norm": 2.3204896450042725,
      "learning_rate": 7.799894542578435e-06,
      "loss": 0.0266,
      "step": 10941
    },
    {
      "epoch": 0.64906869142247,
      "grad_norm": 7.304271221160889,
      "learning_rate": 7.798576324808859e-06,
      "loss": 0.0711,
      "step": 10942
    },
    {
      "epoch": 0.6491280104401471,
      "grad_norm": 9.368165016174316,
      "learning_rate": 7.797258107039283e-06,
      "loss": 0.4017,
      "step": 10943
    },
    {
      "epoch": 0.6491873294578242,
      "grad_norm": 1.338923692703247,
      "learning_rate": 7.795939889269708e-06,
      "loss": 0.0168,
      "step": 10944
    },
    {
      "epoch": 0.6492466484755013,
      "grad_norm": 7.276761054992676,
      "learning_rate": 7.794621671500132e-06,
      "loss": 0.554,
      "step": 10945
    },
    {
      "epoch": 0.6493059674931783,
      "grad_norm": 7.3213090896606445,
      "learning_rate": 7.793303453730558e-06,
      "loss": 0.4145,
      "step": 10946
    },
    {
      "epoch": 0.6493652865108553,
      "grad_norm": 0.07026877999305725,
      "learning_rate": 7.791985235960982e-06,
      "loss": 0.0009,
      "step": 10947
    },
    {
      "epoch": 0.6494246055285324,
      "grad_norm": 40.89060974121094,
      "learning_rate": 7.790667018191406e-06,
      "loss": 1.0302,
      "step": 10948
    },
    {
      "epoch": 0.6494839245462095,
      "grad_norm": 34.9888801574707,
      "learning_rate": 7.78934880042183e-06,
      "loss": 0.7099,
      "step": 10949
    },
    {
      "epoch": 0.6495432435638866,
      "grad_norm": 5.469785213470459,
      "learning_rate": 7.788030582652254e-06,
      "loss": 0.0427,
      "step": 10950
    },
    {
      "epoch": 0.6496025625815637,
      "grad_norm": 0.0329679436981678,
      "learning_rate": 7.786712364882679e-06,
      "loss": 0.0013,
      "step": 10951
    },
    {
      "epoch": 0.6496618815992408,
      "grad_norm": 24.133251190185547,
      "learning_rate": 7.785394147113103e-06,
      "loss": 0.8747,
      "step": 10952
    },
    {
      "epoch": 0.6497212006169177,
      "grad_norm": 1.619313359260559,
      "learning_rate": 7.784075929343529e-06,
      "loss": 0.0097,
      "step": 10953
    },
    {
      "epoch": 0.6497805196345948,
      "grad_norm": 2.923856496810913,
      "learning_rate": 7.782757711573953e-06,
      "loss": 0.029,
      "step": 10954
    },
    {
      "epoch": 0.6498398386522719,
      "grad_norm": 0.05217166617512703,
      "learning_rate": 7.781439493804377e-06,
      "loss": 0.001,
      "step": 10955
    },
    {
      "epoch": 0.649899157669949,
      "grad_norm": 11.006440162658691,
      "learning_rate": 7.780121276034801e-06,
      "loss": 0.2899,
      "step": 10956
    },
    {
      "epoch": 0.6499584766876261,
      "grad_norm": 5.111295700073242,
      "learning_rate": 7.778803058265227e-06,
      "loss": 0.0161,
      "step": 10957
    },
    {
      "epoch": 0.6500177957053032,
      "grad_norm": 0.03543676435947418,
      "learning_rate": 7.777484840495651e-06,
      "loss": 0.0009,
      "step": 10958
    },
    {
      "epoch": 0.6500771147229802,
      "grad_norm": 18.2957820892334,
      "learning_rate": 7.776166622726075e-06,
      "loss": 0.5686,
      "step": 10959
    },
    {
      "epoch": 0.6501364337406572,
      "grad_norm": 0.013146237470209599,
      "learning_rate": 7.7748484049565e-06,
      "loss": 0.0005,
      "step": 10960
    },
    {
      "epoch": 0.6501957527583343,
      "grad_norm": 3.9611737728118896,
      "learning_rate": 7.773530187186924e-06,
      "loss": 0.1183,
      "step": 10961
    },
    {
      "epoch": 0.6502550717760114,
      "grad_norm": 4.518511772155762,
      "learning_rate": 7.772211969417348e-06,
      "loss": 0.1747,
      "step": 10962
    },
    {
      "epoch": 0.6503143907936885,
      "grad_norm": 6.893381595611572,
      "learning_rate": 7.770893751647774e-06,
      "loss": 0.4259,
      "step": 10963
    },
    {
      "epoch": 0.6503737098113656,
      "grad_norm": 7.873457431793213,
      "learning_rate": 7.769575533878198e-06,
      "loss": 0.0786,
      "step": 10964
    },
    {
      "epoch": 0.6504330288290426,
      "grad_norm": 6.994424343109131,
      "learning_rate": 7.768257316108622e-06,
      "loss": 0.1223,
      "step": 10965
    },
    {
      "epoch": 0.6504923478467196,
      "grad_norm": 15.526176452636719,
      "learning_rate": 7.766939098339046e-06,
      "loss": 0.5561,
      "step": 10966
    },
    {
      "epoch": 0.6505516668643967,
      "grad_norm": 0.46185851097106934,
      "learning_rate": 7.76562088056947e-06,
      "loss": 0.0053,
      "step": 10967
    },
    {
      "epoch": 0.6506109858820738,
      "grad_norm": 0.023040035739541054,
      "learning_rate": 7.764302662799895e-06,
      "loss": 0.0006,
      "step": 10968
    },
    {
      "epoch": 0.6506703048997509,
      "grad_norm": 2.2623960971832275,
      "learning_rate": 7.762984445030319e-06,
      "loss": 0.0408,
      "step": 10969
    },
    {
      "epoch": 0.650729623917428,
      "grad_norm": 4.516998767852783,
      "learning_rate": 7.761666227260745e-06,
      "loss": 0.0339,
      "step": 10970
    },
    {
      "epoch": 0.650788942935105,
      "grad_norm": 0.08207869529724121,
      "learning_rate": 7.760348009491169e-06,
      "loss": 0.0015,
      "step": 10971
    },
    {
      "epoch": 0.6508482619527821,
      "grad_norm": 4.156396389007568,
      "learning_rate": 7.759029791721593e-06,
      "loss": 0.0321,
      "step": 10972
    },
    {
      "epoch": 0.6509075809704591,
      "grad_norm": 17.73653221130371,
      "learning_rate": 7.757711573952017e-06,
      "loss": 0.081,
      "step": 10973
    },
    {
      "epoch": 0.6509668999881362,
      "grad_norm": 10.261343955993652,
      "learning_rate": 7.756393356182442e-06,
      "loss": 0.4255,
      "step": 10974
    },
    {
      "epoch": 0.6510262190058133,
      "grad_norm": 0.27193528413772583,
      "learning_rate": 7.755075138412866e-06,
      "loss": 0.0058,
      "step": 10975
    },
    {
      "epoch": 0.6510855380234903,
      "grad_norm": 4.017848968505859,
      "learning_rate": 7.75375692064329e-06,
      "loss": 0.0727,
      "step": 10976
    },
    {
      "epoch": 0.6511448570411674,
      "grad_norm": 9.068425178527832,
      "learning_rate": 7.752438702873716e-06,
      "loss": 0.1023,
      "step": 10977
    },
    {
      "epoch": 0.6512041760588445,
      "grad_norm": 14.08826732635498,
      "learning_rate": 7.75112048510414e-06,
      "loss": 0.5859,
      "step": 10978
    },
    {
      "epoch": 0.6512634950765215,
      "grad_norm": 0.5849697589874268,
      "learning_rate": 7.749802267334564e-06,
      "loss": 0.0087,
      "step": 10979
    },
    {
      "epoch": 0.6513228140941986,
      "grad_norm": 3.4062013626098633,
      "learning_rate": 7.748484049564988e-06,
      "loss": 0.2587,
      "step": 10980
    },
    {
      "epoch": 0.6513821331118756,
      "grad_norm": 0.0193330068141222,
      "learning_rate": 7.747165831795414e-06,
      "loss": 0.0004,
      "step": 10981
    },
    {
      "epoch": 0.6514414521295527,
      "grad_norm": 1.6403435468673706,
      "learning_rate": 7.745847614025837e-06,
      "loss": 0.0194,
      "step": 10982
    },
    {
      "epoch": 0.6515007711472298,
      "grad_norm": 1.7999987602233887,
      "learning_rate": 7.744529396256261e-06,
      "loss": 0.007,
      "step": 10983
    },
    {
      "epoch": 0.6515600901649069,
      "grad_norm": 16.767303466796875,
      "learning_rate": 7.743211178486687e-06,
      "loss": 0.3185,
      "step": 10984
    },
    {
      "epoch": 0.651619409182584,
      "grad_norm": 0.6272906064987183,
      "learning_rate": 7.741892960717111e-06,
      "loss": 0.009,
      "step": 10985
    },
    {
      "epoch": 0.651678728200261,
      "grad_norm": 5.500004768371582,
      "learning_rate": 7.740574742947535e-06,
      "loss": 0.0847,
      "step": 10986
    },
    {
      "epoch": 0.651738047217938,
      "grad_norm": 3.0518410205841064,
      "learning_rate": 7.739256525177961e-06,
      "loss": 0.2263,
      "step": 10987
    },
    {
      "epoch": 0.6517973662356151,
      "grad_norm": 0.04893870651721954,
      "learning_rate": 7.737938307408385e-06,
      "loss": 0.001,
      "step": 10988
    },
    {
      "epoch": 0.6518566852532922,
      "grad_norm": 11.136411666870117,
      "learning_rate": 7.73662008963881e-06,
      "loss": 0.0826,
      "step": 10989
    },
    {
      "epoch": 0.6519160042709693,
      "grad_norm": 0.9498340487480164,
      "learning_rate": 7.735301871869234e-06,
      "loss": 0.014,
      "step": 10990
    },
    {
      "epoch": 0.6519753232886464,
      "grad_norm": 0.8411779999732971,
      "learning_rate": 7.733983654099658e-06,
      "loss": 0.0073,
      "step": 10991
    },
    {
      "epoch": 0.6520346423063234,
      "grad_norm": 1.3078975677490234,
      "learning_rate": 7.732665436330082e-06,
      "loss": 0.0082,
      "step": 10992
    },
    {
      "epoch": 0.6520939613240004,
      "grad_norm": 12.011228561401367,
      "learning_rate": 7.731347218560506e-06,
      "loss": 0.2263,
      "step": 10993
    },
    {
      "epoch": 0.6521532803416775,
      "grad_norm": 16.599733352661133,
      "learning_rate": 7.730029000790932e-06,
      "loss": 0.6295,
      "step": 10994
    },
    {
      "epoch": 0.6522125993593546,
      "grad_norm": 7.876951217651367,
      "learning_rate": 7.728710783021356e-06,
      "loss": 0.0549,
      "step": 10995
    },
    {
      "epoch": 0.6522719183770317,
      "grad_norm": 13.761921882629395,
      "learning_rate": 7.72739256525178e-06,
      "loss": 0.7015,
      "step": 10996
    },
    {
      "epoch": 0.6523312373947088,
      "grad_norm": 0.008620329201221466,
      "learning_rate": 7.726074347482205e-06,
      "loss": 0.0003,
      "step": 10997
    },
    {
      "epoch": 0.6523905564123859,
      "grad_norm": 0.08453179895877838,
      "learning_rate": 7.724756129712629e-06,
      "loss": 0.0014,
      "step": 10998
    },
    {
      "epoch": 0.6524498754300628,
      "grad_norm": 14.840038299560547,
      "learning_rate": 7.723437911943053e-06,
      "loss": 0.5024,
      "step": 10999
    },
    {
      "epoch": 0.6525091944477399,
      "grad_norm": 8.794844627380371,
      "learning_rate": 7.722119694173477e-06,
      "loss": 0.0459,
      "step": 11000
    },
    {
      "epoch": 0.652568513465417,
      "grad_norm": 25.9016056060791,
      "learning_rate": 7.720801476403903e-06,
      "loss": 0.4618,
      "step": 11001
    },
    {
      "epoch": 0.6526278324830941,
      "grad_norm": 9.374367713928223,
      "learning_rate": 7.719483258634327e-06,
      "loss": 0.2477,
      "step": 11002
    },
    {
      "epoch": 0.6526871515007712,
      "grad_norm": 8.320714950561523,
      "learning_rate": 7.718165040864751e-06,
      "loss": 0.2649,
      "step": 11003
    },
    {
      "epoch": 0.6527464705184483,
      "grad_norm": 0.06035694107413292,
      "learning_rate": 7.716846823095176e-06,
      "loss": 0.0013,
      "step": 11004
    },
    {
      "epoch": 0.6528057895361253,
      "grad_norm": 4.2011027336120605,
      "learning_rate": 7.7155286053256e-06,
      "loss": 0.0997,
      "step": 11005
    },
    {
      "epoch": 0.6528651085538023,
      "grad_norm": 0.5262372493743896,
      "learning_rate": 7.714210387556024e-06,
      "loss": 0.008,
      "step": 11006
    },
    {
      "epoch": 0.6529244275714794,
      "grad_norm": 10.43602466583252,
      "learning_rate": 7.712892169786448e-06,
      "loss": 0.1196,
      "step": 11007
    },
    {
      "epoch": 0.6529837465891565,
      "grad_norm": 0.04003949463367462,
      "learning_rate": 7.711573952016874e-06,
      "loss": 0.0008,
      "step": 11008
    },
    {
      "epoch": 0.6530430656068336,
      "grad_norm": 0.5259194374084473,
      "learning_rate": 7.710255734247298e-06,
      "loss": 0.0101,
      "step": 11009
    },
    {
      "epoch": 0.6531023846245106,
      "grad_norm": 15.1098051071167,
      "learning_rate": 7.708937516477722e-06,
      "loss": 1.1596,
      "step": 11010
    },
    {
      "epoch": 0.6531617036421877,
      "grad_norm": 0.38178008794784546,
      "learning_rate": 7.707619298708148e-06,
      "loss": 0.0089,
      "step": 11011
    },
    {
      "epoch": 0.6532210226598647,
      "grad_norm": 7.242515563964844,
      "learning_rate": 7.706301080938573e-06,
      "loss": 0.0541,
      "step": 11012
    },
    {
      "epoch": 0.6532803416775418,
      "grad_norm": 1.0164978504180908,
      "learning_rate": 7.704982863168997e-06,
      "loss": 0.0203,
      "step": 11013
    },
    {
      "epoch": 0.6533396606952189,
      "grad_norm": 10.707514762878418,
      "learning_rate": 7.703664645399421e-06,
      "loss": 0.4525,
      "step": 11014
    },
    {
      "epoch": 0.653398979712896,
      "grad_norm": 0.03399340435862541,
      "learning_rate": 7.702346427629845e-06,
      "loss": 0.0005,
      "step": 11015
    },
    {
      "epoch": 0.653458298730573,
      "grad_norm": 5.030640602111816,
      "learning_rate": 7.70102820986027e-06,
      "loss": 0.0325,
      "step": 11016
    },
    {
      "epoch": 0.6535176177482501,
      "grad_norm": 0.04750821366906166,
      "learning_rate": 7.699709992090693e-06,
      "loss": 0.0014,
      "step": 11017
    },
    {
      "epoch": 0.6535769367659272,
      "grad_norm": 48.332359313964844,
      "learning_rate": 7.69839177432112e-06,
      "loss": 0.6673,
      "step": 11018
    },
    {
      "epoch": 0.6536362557836042,
      "grad_norm": 4.14363431930542,
      "learning_rate": 7.697073556551544e-06,
      "loss": 0.012,
      "step": 11019
    },
    {
      "epoch": 0.6536955748012813,
      "grad_norm": 9.455191612243652,
      "learning_rate": 7.695755338781968e-06,
      "loss": 0.184,
      "step": 11020
    },
    {
      "epoch": 0.6537548938189583,
      "grad_norm": 0.46086418628692627,
      "learning_rate": 7.694437121012392e-06,
      "loss": 0.0059,
      "step": 11021
    },
    {
      "epoch": 0.6538142128366354,
      "grad_norm": 2.6459133625030518,
      "learning_rate": 7.693118903242816e-06,
      "loss": 0.0181,
      "step": 11022
    },
    {
      "epoch": 0.6538735318543125,
      "grad_norm": 3.538755178451538,
      "learning_rate": 7.69180068547324e-06,
      "loss": 0.0565,
      "step": 11023
    },
    {
      "epoch": 0.6539328508719896,
      "grad_norm": 0.6384269595146179,
      "learning_rate": 7.690482467703664e-06,
      "loss": 0.0073,
      "step": 11024
    },
    {
      "epoch": 0.6539921698896666,
      "grad_norm": 16.693313598632812,
      "learning_rate": 7.68916424993409e-06,
      "loss": 0.0844,
      "step": 11025
    },
    {
      "epoch": 0.6540514889073437,
      "grad_norm": 5.544183254241943,
      "learning_rate": 7.687846032164515e-06,
      "loss": 0.1037,
      "step": 11026
    },
    {
      "epoch": 0.6541108079250207,
      "grad_norm": 0.6416872143745422,
      "learning_rate": 7.686527814394939e-06,
      "loss": 0.0074,
      "step": 11027
    },
    {
      "epoch": 0.6541701269426978,
      "grad_norm": 0.09972754120826721,
      "learning_rate": 7.685209596625363e-06,
      "loss": 0.0021,
      "step": 11028
    },
    {
      "epoch": 0.6542294459603749,
      "grad_norm": 1.6580621004104614,
      "learning_rate": 7.683891378855787e-06,
      "loss": 0.0074,
      "step": 11029
    },
    {
      "epoch": 0.654288764978052,
      "grad_norm": 0.45473355054855347,
      "learning_rate": 7.682573161086211e-06,
      "loss": 0.0079,
      "step": 11030
    },
    {
      "epoch": 0.6543480839957291,
      "grad_norm": 1.7578896284103394,
      "learning_rate": 7.681254943316636e-06,
      "loss": 0.0201,
      "step": 11031
    },
    {
      "epoch": 0.654407403013406,
      "grad_norm": 5.66441535949707,
      "learning_rate": 7.679936725547061e-06,
      "loss": 0.0392,
      "step": 11032
    },
    {
      "epoch": 0.6544667220310831,
      "grad_norm": 5.941745758056641,
      "learning_rate": 7.678618507777486e-06,
      "loss": 0.3854,
      "step": 11033
    },
    {
      "epoch": 0.6545260410487602,
      "grad_norm": 4.922673225402832,
      "learning_rate": 7.67730029000791e-06,
      "loss": 0.0716,
      "step": 11034
    },
    {
      "epoch": 0.6545853600664373,
      "grad_norm": 18.892745971679688,
      "learning_rate": 7.675982072238336e-06,
      "loss": 0.1495,
      "step": 11035
    },
    {
      "epoch": 0.6546446790841144,
      "grad_norm": 5.920840263366699,
      "learning_rate": 7.67466385446876e-06,
      "loss": 0.2049,
      "step": 11036
    },
    {
      "epoch": 0.6547039981017915,
      "grad_norm": 4.417825698852539,
      "learning_rate": 7.673345636699184e-06,
      "loss": 0.0322,
      "step": 11037
    },
    {
      "epoch": 0.6547633171194684,
      "grad_norm": 0.019865941256284714,
      "learning_rate": 7.672027418929607e-06,
      "loss": 0.0007,
      "step": 11038
    },
    {
      "epoch": 0.6548226361371455,
      "grad_norm": 0.0387750081717968,
      "learning_rate": 7.670709201160032e-06,
      "loss": 0.0009,
      "step": 11039
    },
    {
      "epoch": 0.6548819551548226,
      "grad_norm": 8.302377700805664,
      "learning_rate": 7.669390983390457e-06,
      "loss": 0.5181,
      "step": 11040
    },
    {
      "epoch": 0.6549412741724997,
      "grad_norm": 5.861486434936523,
      "learning_rate": 7.66807276562088e-06,
      "loss": 0.0249,
      "step": 11041
    },
    {
      "epoch": 0.6550005931901768,
      "grad_norm": 0.6476656794548035,
      "learning_rate": 7.666754547851307e-06,
      "loss": 0.0041,
      "step": 11042
    },
    {
      "epoch": 0.6550599122078539,
      "grad_norm": 6.629147529602051,
      "learning_rate": 7.66543633008173e-06,
      "loss": 0.2283,
      "step": 11043
    },
    {
      "epoch": 0.655119231225531,
      "grad_norm": 2.8179869651794434,
      "learning_rate": 7.664118112312155e-06,
      "loss": 0.0275,
      "step": 11044
    },
    {
      "epoch": 0.6551785502432079,
      "grad_norm": 1.0424222946166992,
      "learning_rate": 7.66279989454258e-06,
      "loss": 0.0064,
      "step": 11045
    },
    {
      "epoch": 0.655237869260885,
      "grad_norm": 2.331336498260498,
      "learning_rate": 7.661481676773003e-06,
      "loss": 0.0225,
      "step": 11046
    },
    {
      "epoch": 0.6552971882785621,
      "grad_norm": 4.16627311706543,
      "learning_rate": 7.660163459003428e-06,
      "loss": 0.0235,
      "step": 11047
    },
    {
      "epoch": 0.6553565072962392,
      "grad_norm": 0.006924792192876339,
      "learning_rate": 7.658845241233852e-06,
      "loss": 0.0002,
      "step": 11048
    },
    {
      "epoch": 0.6554158263139163,
      "grad_norm": 1.0166810750961304,
      "learning_rate": 7.657527023464278e-06,
      "loss": 0.0085,
      "step": 11049
    },
    {
      "epoch": 0.6554751453315933,
      "grad_norm": 9.332467079162598,
      "learning_rate": 7.656208805694702e-06,
      "loss": 0.1448,
      "step": 11050
    },
    {
      "epoch": 0.6555344643492704,
      "grad_norm": 13.979179382324219,
      "learning_rate": 7.654890587925126e-06,
      "loss": 0.1341,
      "step": 11051
    },
    {
      "epoch": 0.6555937833669474,
      "grad_norm": 23.21686553955078,
      "learning_rate": 7.65357237015555e-06,
      "loss": 0.7877,
      "step": 11052
    },
    {
      "epoch": 0.6556531023846245,
      "grad_norm": 0.283966988325119,
      "learning_rate": 7.652254152385974e-06,
      "loss": 0.0047,
      "step": 11053
    },
    {
      "epoch": 0.6557124214023016,
      "grad_norm": 0.019862115383148193,
      "learning_rate": 7.650935934616399e-06,
      "loss": 0.0007,
      "step": 11054
    },
    {
      "epoch": 0.6557717404199787,
      "grad_norm": 0.0501093864440918,
      "learning_rate": 7.649617716846823e-06,
      "loss": 0.0008,
      "step": 11055
    },
    {
      "epoch": 0.6558310594376557,
      "grad_norm": 8.597936630249023,
      "learning_rate": 7.648299499077249e-06,
      "loss": 0.2874,
      "step": 11056
    },
    {
      "epoch": 0.6558903784553328,
      "grad_norm": 0.20582272112369537,
      "learning_rate": 7.646981281307673e-06,
      "loss": 0.0038,
      "step": 11057
    },
    {
      "epoch": 0.6559496974730098,
      "grad_norm": 6.73611307144165,
      "learning_rate": 7.645663063538097e-06,
      "loss": 0.1481,
      "step": 11058
    },
    {
      "epoch": 0.6560090164906869,
      "grad_norm": 25.837583541870117,
      "learning_rate": 7.644344845768523e-06,
      "loss": 0.7774,
      "step": 11059
    },
    {
      "epoch": 0.656068335508364,
      "grad_norm": 0.044104233384132385,
      "learning_rate": 7.643026627998945e-06,
      "loss": 0.0014,
      "step": 11060
    },
    {
      "epoch": 0.656127654526041,
      "grad_norm": 0.5381370186805725,
      "learning_rate": 7.64170841022937e-06,
      "loss": 0.0065,
      "step": 11061
    },
    {
      "epoch": 0.6561869735437181,
      "grad_norm": 0.057052481919527054,
      "learning_rate": 7.640390192459794e-06,
      "loss": 0.0011,
      "step": 11062
    },
    {
      "epoch": 0.6562462925613952,
      "grad_norm": 25.632205963134766,
      "learning_rate": 7.63907197469022e-06,
      "loss": 0.2465,
      "step": 11063
    },
    {
      "epoch": 0.6563056115790723,
      "grad_norm": 7.337432384490967,
      "learning_rate": 7.637753756920644e-06,
      "loss": 0.1821,
      "step": 11064
    },
    {
      "epoch": 0.6563649305967493,
      "grad_norm": 0.09265211224555969,
      "learning_rate": 7.636435539151068e-06,
      "loss": 0.0014,
      "step": 11065
    },
    {
      "epoch": 0.6564242496144264,
      "grad_norm": 1.7396199703216553,
      "learning_rate": 7.635117321381494e-06,
      "loss": 0.033,
      "step": 11066
    },
    {
      "epoch": 0.6564835686321034,
      "grad_norm": 0.047332845628261566,
      "learning_rate": 7.633799103611918e-06,
      "loss": 0.0009,
      "step": 11067
    },
    {
      "epoch": 0.6565428876497805,
      "grad_norm": 7.058296203613281,
      "learning_rate": 7.632480885842342e-06,
      "loss": 0.0922,
      "step": 11068
    },
    {
      "epoch": 0.6566022066674576,
      "grad_norm": 0.11158348619937897,
      "learning_rate": 7.631162668072766e-06,
      "loss": 0.0015,
      "step": 11069
    },
    {
      "epoch": 0.6566615256851347,
      "grad_norm": 0.014735720120370388,
      "learning_rate": 7.62984445030319e-06,
      "loss": 0.0005,
      "step": 11070
    },
    {
      "epoch": 0.6567208447028117,
      "grad_norm": 0.3751213252544403,
      "learning_rate": 7.628526232533615e-06,
      "loss": 0.0061,
      "step": 11071
    },
    {
      "epoch": 0.6567801637204888,
      "grad_norm": 0.06315488368272781,
      "learning_rate": 7.627208014764039e-06,
      "loss": 0.0012,
      "step": 11072
    },
    {
      "epoch": 0.6568394827381658,
      "grad_norm": 0.2220289260149002,
      "learning_rate": 7.625889796994465e-06,
      "loss": 0.0048,
      "step": 11073
    },
    {
      "epoch": 0.6568988017558429,
      "grad_norm": 3.5665574073791504,
      "learning_rate": 7.624571579224888e-06,
      "loss": 0.0499,
      "step": 11074
    },
    {
      "epoch": 0.65695812077352,
      "grad_norm": 29.92276382446289,
      "learning_rate": 7.6232533614553124e-06,
      "loss": 0.7446,
      "step": 11075
    },
    {
      "epoch": 0.6570174397911971,
      "grad_norm": 2.2240653038024902,
      "learning_rate": 7.621935143685738e-06,
      "loss": 0.0357,
      "step": 11076
    },
    {
      "epoch": 0.6570767588088742,
      "grad_norm": 0.028181718662381172,
      "learning_rate": 7.6206169259161625e-06,
      "loss": 0.0008,
      "step": 11077
    },
    {
      "epoch": 0.6571360778265511,
      "grad_norm": 11.56810474395752,
      "learning_rate": 7.619298708146587e-06,
      "loss": 0.1651,
      "step": 11078
    },
    {
      "epoch": 0.6571953968442282,
      "grad_norm": 0.04300301522016525,
      "learning_rate": 7.617980490377011e-06,
      "loss": 0.0011,
      "step": 11079
    },
    {
      "epoch": 0.6572547158619053,
      "grad_norm": 0.05751281976699829,
      "learning_rate": 7.616662272607436e-06,
      "loss": 0.0009,
      "step": 11080
    },
    {
      "epoch": 0.6573140348795824,
      "grad_norm": 11.814224243164062,
      "learning_rate": 7.61534405483786e-06,
      "loss": 0.4883,
      "step": 11081
    },
    {
      "epoch": 0.6573733538972595,
      "grad_norm": 0.1450287252664566,
      "learning_rate": 7.614025837068284e-06,
      "loss": 0.0033,
      "step": 11082
    },
    {
      "epoch": 0.6574326729149366,
      "grad_norm": 0.014781908132135868,
      "learning_rate": 7.612707619298709e-06,
      "loss": 0.0005,
      "step": 11083
    },
    {
      "epoch": 0.6574919919326137,
      "grad_norm": 0.17571255564689636,
      "learning_rate": 7.6113894015291335e-06,
      "loss": 0.0024,
      "step": 11084
    },
    {
      "epoch": 0.6575513109502906,
      "grad_norm": 0.2105269730091095,
      "learning_rate": 7.610071183759558e-06,
      "loss": 0.0015,
      "step": 11085
    },
    {
      "epoch": 0.6576106299679677,
      "grad_norm": 0.2936011552810669,
      "learning_rate": 7.608752965989982e-06,
      "loss": 0.0067,
      "step": 11086
    },
    {
      "epoch": 0.6576699489856448,
      "grad_norm": 6.811309814453125,
      "learning_rate": 7.607434748220407e-06,
      "loss": 0.0681,
      "step": 11087
    },
    {
      "epoch": 0.6577292680033219,
      "grad_norm": 0.0253241416066885,
      "learning_rate": 7.606116530450831e-06,
      "loss": 0.0008,
      "step": 11088
    },
    {
      "epoch": 0.657788587020999,
      "grad_norm": 7.011557579040527,
      "learning_rate": 7.604798312681255e-06,
      "loss": 0.2787,
      "step": 11089
    },
    {
      "epoch": 0.657847906038676,
      "grad_norm": 2.168397903442383,
      "learning_rate": 7.60348009491168e-06,
      "loss": 0.0197,
      "step": 11090
    },
    {
      "epoch": 0.657907225056353,
      "grad_norm": 0.1733511984348297,
      "learning_rate": 7.6021618771421045e-06,
      "loss": 0.0016,
      "step": 11091
    },
    {
      "epoch": 0.6579665440740301,
      "grad_norm": 7.670015811920166,
      "learning_rate": 7.600843659372529e-06,
      "loss": 0.2933,
      "step": 11092
    },
    {
      "epoch": 0.6580258630917072,
      "grad_norm": 28.993581771850586,
      "learning_rate": 7.599525441602953e-06,
      "loss": 0.9951,
      "step": 11093
    },
    {
      "epoch": 0.6580851821093843,
      "grad_norm": 13.511775016784668,
      "learning_rate": 7.598207223833378e-06,
      "loss": 0.2686,
      "step": 11094
    },
    {
      "epoch": 0.6581445011270614,
      "grad_norm": 0.24948716163635254,
      "learning_rate": 7.596889006063802e-06,
      "loss": 0.0051,
      "step": 11095
    },
    {
      "epoch": 0.6582038201447384,
      "grad_norm": 19.50205421447754,
      "learning_rate": 7.595570788294226e-06,
      "loss": 0.3398,
      "step": 11096
    },
    {
      "epoch": 0.6582631391624155,
      "grad_norm": 0.26539039611816406,
      "learning_rate": 7.594252570524651e-06,
      "loss": 0.0034,
      "step": 11097
    },
    {
      "epoch": 0.6583224581800925,
      "grad_norm": 1.2533165216445923,
      "learning_rate": 7.5929343527550755e-06,
      "loss": 0.0143,
      "step": 11098
    },
    {
      "epoch": 0.6583817771977696,
      "grad_norm": 11.033854484558105,
      "learning_rate": 7.5916161349855e-06,
      "loss": 0.8303,
      "step": 11099
    },
    {
      "epoch": 0.6584410962154467,
      "grad_norm": 0.14482341706752777,
      "learning_rate": 7.590297917215926e-06,
      "loss": 0.002,
      "step": 11100
    },
    {
      "epoch": 0.6585004152331237,
      "grad_norm": 0.0363038033246994,
      "learning_rate": 7.58897969944635e-06,
      "loss": 0.0007,
      "step": 11101
    },
    {
      "epoch": 0.6585597342508008,
      "grad_norm": 1.1296857595443726,
      "learning_rate": 7.587661481676773e-06,
      "loss": 0.0112,
      "step": 11102
    },
    {
      "epoch": 0.6586190532684779,
      "grad_norm": 0.32914429903030396,
      "learning_rate": 7.586343263907197e-06,
      "loss": 0.0063,
      "step": 11103
    },
    {
      "epoch": 0.6586783722861549,
      "grad_norm": 0.02836710587143898,
      "learning_rate": 7.585025046137623e-06,
      "loss": 0.0007,
      "step": 11104
    },
    {
      "epoch": 0.658737691303832,
      "grad_norm": 13.921524047851562,
      "learning_rate": 7.583706828368047e-06,
      "loss": 0.3035,
      "step": 11105
    },
    {
      "epoch": 0.6587970103215091,
      "grad_norm": 21.49358367919922,
      "learning_rate": 7.5823886105984716e-06,
      "loss": 0.7464,
      "step": 11106
    },
    {
      "epoch": 0.6588563293391861,
      "grad_norm": 3.0614397525787354,
      "learning_rate": 7.581070392828897e-06,
      "loss": 0.0921,
      "step": 11107
    },
    {
      "epoch": 0.6589156483568632,
      "grad_norm": 9.77977180480957,
      "learning_rate": 7.579752175059321e-06,
      "loss": 0.1647,
      "step": 11108
    },
    {
      "epoch": 0.6589749673745403,
      "grad_norm": 22.600109100341797,
      "learning_rate": 7.578433957289745e-06,
      "loss": 1.7448,
      "step": 11109
    },
    {
      "epoch": 0.6590342863922174,
      "grad_norm": 2.175309896469116,
      "learning_rate": 7.577115739520169e-06,
      "loss": 0.0211,
      "step": 11110
    },
    {
      "epoch": 0.6590936054098944,
      "grad_norm": 3.1595232486724854,
      "learning_rate": 7.575797521750594e-06,
      "loss": 0.0234,
      "step": 11111
    },
    {
      "epoch": 0.6591529244275715,
      "grad_norm": 0.02062039077281952,
      "learning_rate": 7.574479303981018e-06,
      "loss": 0.0007,
      "step": 11112
    },
    {
      "epoch": 0.6592122434452485,
      "grad_norm": 3.716355562210083,
      "learning_rate": 7.5731610862114426e-06,
      "loss": 0.0255,
      "step": 11113
    },
    {
      "epoch": 0.6592715624629256,
      "grad_norm": 2.934540271759033,
      "learning_rate": 7.571842868441868e-06,
      "loss": 0.0407,
      "step": 11114
    },
    {
      "epoch": 0.6593308814806027,
      "grad_norm": 2.308138608932495,
      "learning_rate": 7.570524650672292e-06,
      "loss": 0.0208,
      "step": 11115
    },
    {
      "epoch": 0.6593902004982798,
      "grad_norm": 11.900775909423828,
      "learning_rate": 7.569206432902716e-06,
      "loss": 0.0604,
      "step": 11116
    },
    {
      "epoch": 0.6594495195159568,
      "grad_norm": 10.255565643310547,
      "learning_rate": 7.56788821513314e-06,
      "loss": 0.1487,
      "step": 11117
    },
    {
      "epoch": 0.6595088385336338,
      "grad_norm": 3.283391237258911,
      "learning_rate": 7.566569997363565e-06,
      "loss": 0.0355,
      "step": 11118
    },
    {
      "epoch": 0.6595681575513109,
      "grad_norm": 6.826563358306885,
      "learning_rate": 7.565251779593989e-06,
      "loss": 0.4727,
      "step": 11119
    },
    {
      "epoch": 0.659627476568988,
      "grad_norm": 0.5946211218833923,
      "learning_rate": 7.5639335618244136e-06,
      "loss": 0.0067,
      "step": 11120
    },
    {
      "epoch": 0.6596867955866651,
      "grad_norm": 1.3241251707077026,
      "learning_rate": 7.562615344054839e-06,
      "loss": 0.029,
      "step": 11121
    },
    {
      "epoch": 0.6597461146043422,
      "grad_norm": 10.302706718444824,
      "learning_rate": 7.561297126285263e-06,
      "loss": 0.162,
      "step": 11122
    },
    {
      "epoch": 0.6598054336220193,
      "grad_norm": 8.576717376708984,
      "learning_rate": 7.559978908515687e-06,
      "loss": 0.0999,
      "step": 11123
    },
    {
      "epoch": 0.6598647526396962,
      "grad_norm": 0.2395438253879547,
      "learning_rate": 7.558660690746112e-06,
      "loss": 0.0049,
      "step": 11124
    },
    {
      "epoch": 0.6599240716573733,
      "grad_norm": 12.14375114440918,
      "learning_rate": 7.557342472976536e-06,
      "loss": 0.7925,
      "step": 11125
    },
    {
      "epoch": 0.6599833906750504,
      "grad_norm": 4.906589984893799,
      "learning_rate": 7.55602425520696e-06,
      "loss": 0.0467,
      "step": 11126
    },
    {
      "epoch": 0.6600427096927275,
      "grad_norm": 1.4764363765716553,
      "learning_rate": 7.5547060374373846e-06,
      "loss": 0.0207,
      "step": 11127
    },
    {
      "epoch": 0.6601020287104046,
      "grad_norm": 0.07848361134529114,
      "learning_rate": 7.5533878196678104e-06,
      "loss": 0.0015,
      "step": 11128
    },
    {
      "epoch": 0.6601613477280817,
      "grad_norm": 15.945119857788086,
      "learning_rate": 7.552069601898235e-06,
      "loss": 1.5265,
      "step": 11129
    },
    {
      "epoch": 0.6602206667457587,
      "grad_norm": 0.007682480849325657,
      "learning_rate": 7.550751384128658e-06,
      "loss": 0.0003,
      "step": 11130
    },
    {
      "epoch": 0.6602799857634357,
      "grad_norm": 7.754885673522949,
      "learning_rate": 7.549433166359084e-06,
      "loss": 0.1526,
      "step": 11131
    },
    {
      "epoch": 0.6603393047811128,
      "grad_norm": 0.4286482334136963,
      "learning_rate": 7.548114948589508e-06,
      "loss": 0.0055,
      "step": 11132
    },
    {
      "epoch": 0.6603986237987899,
      "grad_norm": 6.584625720977783,
      "learning_rate": 7.546796730819932e-06,
      "loss": 0.0972,
      "step": 11133
    },
    {
      "epoch": 0.660457942816467,
      "grad_norm": 1.0537606477737427,
      "learning_rate": 7.545478513050356e-06,
      "loss": 0.0082,
      "step": 11134
    },
    {
      "epoch": 0.660517261834144,
      "grad_norm": 0.016396228224039078,
      "learning_rate": 7.5441602952807815e-06,
      "loss": 0.0005,
      "step": 11135
    },
    {
      "epoch": 0.6605765808518211,
      "grad_norm": 0.18266458809375763,
      "learning_rate": 7.542842077511206e-06,
      "loss": 0.0034,
      "step": 11136
    },
    {
      "epoch": 0.6606358998694981,
      "grad_norm": 0.014069451950490475,
      "learning_rate": 7.54152385974163e-06,
      "loss": 0.0005,
      "step": 11137
    },
    {
      "epoch": 0.6606952188871752,
      "grad_norm": 6.431935787200928,
      "learning_rate": 7.540205641972055e-06,
      "loss": 0.49,
      "step": 11138
    },
    {
      "epoch": 0.6607545379048523,
      "grad_norm": 5.243589401245117,
      "learning_rate": 7.538887424202479e-06,
      "loss": 0.1481,
      "step": 11139
    },
    {
      "epoch": 0.6608138569225294,
      "grad_norm": 0.14261360466480255,
      "learning_rate": 7.537569206432903e-06,
      "loss": 0.0021,
      "step": 11140
    },
    {
      "epoch": 0.6608731759402064,
      "grad_norm": 0.16005997359752655,
      "learning_rate": 7.536250988663327e-06,
      "loss": 0.0036,
      "step": 11141
    },
    {
      "epoch": 0.6609324949578835,
      "grad_norm": 1.7985228300094604,
      "learning_rate": 7.5349327708937525e-06,
      "loss": 0.019,
      "step": 11142
    },
    {
      "epoch": 0.6609918139755606,
      "grad_norm": 2.390634059906006,
      "learning_rate": 7.533614553124177e-06,
      "loss": 0.0096,
      "step": 11143
    },
    {
      "epoch": 0.6610511329932376,
      "grad_norm": 0.028533751145005226,
      "learning_rate": 7.532296335354601e-06,
      "loss": 0.0007,
      "step": 11144
    },
    {
      "epoch": 0.6611104520109147,
      "grad_norm": 0.2884342670440674,
      "learning_rate": 7.530978117585026e-06,
      "loss": 0.0034,
      "step": 11145
    },
    {
      "epoch": 0.6611697710285918,
      "grad_norm": 9.134942054748535,
      "learning_rate": 7.52965989981545e-06,
      "loss": 0.4274,
      "step": 11146
    },
    {
      "epoch": 0.6612290900462688,
      "grad_norm": 0.674294650554657,
      "learning_rate": 7.528341682045874e-06,
      "loss": 0.0043,
      "step": 11147
    },
    {
      "epoch": 0.6612884090639459,
      "grad_norm": 0.03291529789566994,
      "learning_rate": 7.527023464276299e-06,
      "loss": 0.0007,
      "step": 11148
    },
    {
      "epoch": 0.661347728081623,
      "grad_norm": 16.911602020263672,
      "learning_rate": 7.5257052465067235e-06,
      "loss": 0.8192,
      "step": 11149
    },
    {
      "epoch": 0.6614070470993,
      "grad_norm": 1.1722052097320557,
      "learning_rate": 7.524387028737148e-06,
      "loss": 0.0154,
      "step": 11150
    },
    {
      "epoch": 0.6614663661169771,
      "grad_norm": 34.4307975769043,
      "learning_rate": 7.523068810967572e-06,
      "loss": 1.1463,
      "step": 11151
    },
    {
      "epoch": 0.6615256851346542,
      "grad_norm": 9.163050651550293,
      "learning_rate": 7.521750593197997e-06,
      "loss": 0.5298,
      "step": 11152
    },
    {
      "epoch": 0.6615850041523312,
      "grad_norm": 0.13678066432476044,
      "learning_rate": 7.520432375428421e-06,
      "loss": 0.0011,
      "step": 11153
    },
    {
      "epoch": 0.6616443231700083,
      "grad_norm": 0.022450175136327744,
      "learning_rate": 7.519114157658845e-06,
      "loss": 0.0005,
      "step": 11154
    },
    {
      "epoch": 0.6617036421876854,
      "grad_norm": 10.821592330932617,
      "learning_rate": 7.517795939889271e-06,
      "loss": 0.1829,
      "step": 11155
    },
    {
      "epoch": 0.6617629612053625,
      "grad_norm": 9.509485244750977,
      "learning_rate": 7.516477722119695e-06,
      "loss": 0.1844,
      "step": 11156
    },
    {
      "epoch": 0.6618222802230395,
      "grad_norm": 6.388577461242676,
      "learning_rate": 7.5151595043501195e-06,
      "loss": 0.1808,
      "step": 11157
    },
    {
      "epoch": 0.6618815992407165,
      "grad_norm": 2.391990900039673,
      "learning_rate": 7.513841286580543e-06,
      "loss": 0.0535,
      "step": 11158
    },
    {
      "epoch": 0.6619409182583936,
      "grad_norm": 0.07088089734315872,
      "learning_rate": 7.512523068810969e-06,
      "loss": 0.0024,
      "step": 11159
    },
    {
      "epoch": 0.6620002372760707,
      "grad_norm": 0.7932596206665039,
      "learning_rate": 7.511204851041393e-06,
      "loss": 0.0131,
      "step": 11160
    },
    {
      "epoch": 0.6620595562937478,
      "grad_norm": 0.49674156308174133,
      "learning_rate": 7.509886633271817e-06,
      "loss": 0.0023,
      "step": 11161
    },
    {
      "epoch": 0.6621188753114249,
      "grad_norm": 0.11291830986738205,
      "learning_rate": 7.508568415502242e-06,
      "loss": 0.0008,
      "step": 11162
    },
    {
      "epoch": 0.6621781943291019,
      "grad_norm": 6.111080169677734,
      "learning_rate": 7.507250197732666e-06,
      "loss": 0.3514,
      "step": 11163
    },
    {
      "epoch": 0.6622375133467789,
      "grad_norm": 0.9659226536750793,
      "learning_rate": 7.5059319799630905e-06,
      "loss": 0.0108,
      "step": 11164
    },
    {
      "epoch": 0.662296832364456,
      "grad_norm": 0.015777111053466797,
      "learning_rate": 7.504613762193515e-06,
      "loss": 0.0005,
      "step": 11165
    },
    {
      "epoch": 0.6623561513821331,
      "grad_norm": 0.11308595538139343,
      "learning_rate": 7.50329554442394e-06,
      "loss": 0.0011,
      "step": 11166
    },
    {
      "epoch": 0.6624154703998102,
      "grad_norm": 12.33195686340332,
      "learning_rate": 7.501977326654364e-06,
      "loss": 0.368,
      "step": 11167
    },
    {
      "epoch": 0.6624747894174873,
      "grad_norm": 0.030009528622031212,
      "learning_rate": 7.500659108884788e-06,
      "loss": 0.0007,
      "step": 11168
    },
    {
      "epoch": 0.6625341084351644,
      "grad_norm": 0.022590380162000656,
      "learning_rate": 7.499340891115213e-06,
      "loss": 0.0006,
      "step": 11169
    },
    {
      "epoch": 0.6625934274528413,
      "grad_norm": 11.967666625976562,
      "learning_rate": 7.498022673345637e-06,
      "loss": 0.1112,
      "step": 11170
    },
    {
      "epoch": 0.6626527464705184,
      "grad_norm": 7.231077194213867,
      "learning_rate": 7.4967044555760615e-06,
      "loss": 0.1499,
      "step": 11171
    },
    {
      "epoch": 0.6627120654881955,
      "grad_norm": 5.393940448760986,
      "learning_rate": 7.4953862378064865e-06,
      "loss": 0.0763,
      "step": 11172
    },
    {
      "epoch": 0.6627713845058726,
      "grad_norm": 0.03978016972541809,
      "learning_rate": 7.494068020036911e-06,
      "loss": 0.0011,
      "step": 11173
    },
    {
      "epoch": 0.6628307035235497,
      "grad_norm": 0.14620661735534668,
      "learning_rate": 7.492749802267335e-06,
      "loss": 0.0025,
      "step": 11174
    },
    {
      "epoch": 0.6628900225412268,
      "grad_norm": 0.021578194573521614,
      "learning_rate": 7.491431584497759e-06,
      "loss": 0.0007,
      "step": 11175
    },
    {
      "epoch": 0.6629493415589038,
      "grad_norm": 0.03910006582736969,
      "learning_rate": 7.490113366728184e-06,
      "loss": 0.0011,
      "step": 11176
    },
    {
      "epoch": 0.6630086605765808,
      "grad_norm": 0.0761621817946434,
      "learning_rate": 7.488795148958608e-06,
      "loss": 0.0018,
      "step": 11177
    },
    {
      "epoch": 0.6630679795942579,
      "grad_norm": 4.242146015167236,
      "learning_rate": 7.4874769311890325e-06,
      "loss": 0.0508,
      "step": 11178
    },
    {
      "epoch": 0.663127298611935,
      "grad_norm": 18.533845901489258,
      "learning_rate": 7.486158713419458e-06,
      "loss": 0.3302,
      "step": 11179
    },
    {
      "epoch": 0.6631866176296121,
      "grad_norm": 0.4262494146823883,
      "learning_rate": 7.484840495649882e-06,
      "loss": 0.0045,
      "step": 11180
    },
    {
      "epoch": 0.6632459366472891,
      "grad_norm": 2.2471253871917725,
      "learning_rate": 7.483522277880306e-06,
      "loss": 0.0084,
      "step": 11181
    },
    {
      "epoch": 0.6633052556649662,
      "grad_norm": 2.6067943572998047,
      "learning_rate": 7.48220406011073e-06,
      "loss": 0.0259,
      "step": 11182
    },
    {
      "epoch": 0.6633645746826432,
      "grad_norm": 2.2760281562805176,
      "learning_rate": 7.480885842341156e-06,
      "loss": 0.1567,
      "step": 11183
    },
    {
      "epoch": 0.6634238937003203,
      "grad_norm": 0.16007544100284576,
      "learning_rate": 7.47956762457158e-06,
      "loss": 0.0021,
      "step": 11184
    },
    {
      "epoch": 0.6634832127179974,
      "grad_norm": 2.995950937271118,
      "learning_rate": 7.478249406802004e-06,
      "loss": 0.0394,
      "step": 11185
    },
    {
      "epoch": 0.6635425317356745,
      "grad_norm": 0.9917272925376892,
      "learning_rate": 7.476931189032429e-06,
      "loss": 0.0089,
      "step": 11186
    },
    {
      "epoch": 0.6636018507533515,
      "grad_norm": 0.32531675696372986,
      "learning_rate": 7.475612971262854e-06,
      "loss": 0.0029,
      "step": 11187
    },
    {
      "epoch": 0.6636611697710286,
      "grad_norm": 0.06454382091760635,
      "learning_rate": 7.474294753493278e-06,
      "loss": 0.0014,
      "step": 11188
    },
    {
      "epoch": 0.6637204887887057,
      "grad_norm": 0.11551310122013092,
      "learning_rate": 7.472976535723702e-06,
      "loss": 0.0009,
      "step": 11189
    },
    {
      "epoch": 0.6637798078063827,
      "grad_norm": 0.02450353279709816,
      "learning_rate": 7.471658317954127e-06,
      "loss": 0.0005,
      "step": 11190
    },
    {
      "epoch": 0.6638391268240598,
      "grad_norm": 0.06196418032050133,
      "learning_rate": 7.470340100184551e-06,
      "loss": 0.0004,
      "step": 11191
    },
    {
      "epoch": 0.6638984458417369,
      "grad_norm": 6.217944145202637,
      "learning_rate": 7.469021882414975e-06,
      "loss": 0.0454,
      "step": 11192
    },
    {
      "epoch": 0.6639577648594139,
      "grad_norm": 0.19482842087745667,
      "learning_rate": 7.4677036646454e-06,
      "loss": 0.005,
      "step": 11193
    },
    {
      "epoch": 0.664017083877091,
      "grad_norm": 0.022823674604296684,
      "learning_rate": 7.466385446875825e-06,
      "loss": 0.0006,
      "step": 11194
    },
    {
      "epoch": 0.6640764028947681,
      "grad_norm": 5.584628105163574,
      "learning_rate": 7.465067229106249e-06,
      "loss": 0.3547,
      "step": 11195
    },
    {
      "epoch": 0.6641357219124451,
      "grad_norm": 0.02737603709101677,
      "learning_rate": 7.463749011336674e-06,
      "loss": 0.0006,
      "step": 11196
    },
    {
      "epoch": 0.6641950409301222,
      "grad_norm": 0.02101839892566204,
      "learning_rate": 7.462430793567098e-06,
      "loss": 0.0006,
      "step": 11197
    },
    {
      "epoch": 0.6642543599477992,
      "grad_norm": 28.930299758911133,
      "learning_rate": 7.461112575797522e-06,
      "loss": 0.2061,
      "step": 11198
    },
    {
      "epoch": 0.6643136789654763,
      "grad_norm": 0.29426342248916626,
      "learning_rate": 7.459794358027946e-06,
      "loss": 0.0058,
      "step": 11199
    },
    {
      "epoch": 0.6643729979831534,
      "grad_norm": 20.211639404296875,
      "learning_rate": 7.458476140258371e-06,
      "loss": 0.5853,
      "step": 11200
    },
    {
      "epoch": 0.6644323170008305,
      "grad_norm": 14.8497953414917,
      "learning_rate": 7.457157922488796e-06,
      "loss": 0.5479,
      "step": 11201
    },
    {
      "epoch": 0.6644916360185076,
      "grad_norm": 3.011582851409912,
      "learning_rate": 7.45583970471922e-06,
      "loss": 0.1259,
      "step": 11202
    },
    {
      "epoch": 0.6645509550361846,
      "grad_norm": 5.688107967376709,
      "learning_rate": 7.454521486949645e-06,
      "loss": 0.1379,
      "step": 11203
    },
    {
      "epoch": 0.6646102740538616,
      "grad_norm": 1.0631616115570068,
      "learning_rate": 7.453203269180069e-06,
      "loss": 0.0115,
      "step": 11204
    },
    {
      "epoch": 0.6646695930715387,
      "grad_norm": 0.14391358196735382,
      "learning_rate": 7.451885051410493e-06,
      "loss": 0.0017,
      "step": 11205
    },
    {
      "epoch": 0.6647289120892158,
      "grad_norm": 49.9936408996582,
      "learning_rate": 7.450566833640917e-06,
      "loss": 1.0503,
      "step": 11206
    },
    {
      "epoch": 0.6647882311068929,
      "grad_norm": 0.16271580755710602,
      "learning_rate": 7.449248615871343e-06,
      "loss": 0.0032,
      "step": 11207
    },
    {
      "epoch": 0.66484755012457,
      "grad_norm": 0.08228182047605515,
      "learning_rate": 7.447930398101767e-06,
      "loss": 0.0015,
      "step": 11208
    },
    {
      "epoch": 0.6649068691422471,
      "grad_norm": 0.4475550055503845,
      "learning_rate": 7.446612180332191e-06,
      "loss": 0.007,
      "step": 11209
    },
    {
      "epoch": 0.664966188159924,
      "grad_norm": 8.94381046295166,
      "learning_rate": 7.445293962562617e-06,
      "loss": 0.2714,
      "step": 11210
    },
    {
      "epoch": 0.6650255071776011,
      "grad_norm": 0.0081484355032444,
      "learning_rate": 7.443975744793041e-06,
      "loss": 0.0002,
      "step": 11211
    },
    {
      "epoch": 0.6650848261952782,
      "grad_norm": 0.020015904679894447,
      "learning_rate": 7.442657527023465e-06,
      "loss": 0.0005,
      "step": 11212
    },
    {
      "epoch": 0.6651441452129553,
      "grad_norm": 0.09889428317546844,
      "learning_rate": 7.441339309253889e-06,
      "loss": 0.0021,
      "step": 11213
    },
    {
      "epoch": 0.6652034642306324,
      "grad_norm": 7.781192779541016,
      "learning_rate": 7.440021091484314e-06,
      "loss": 0.1262,
      "step": 11214
    },
    {
      "epoch": 0.6652627832483095,
      "grad_norm": 0.03476854786276817,
      "learning_rate": 7.4387028737147384e-06,
      "loss": 0.0008,
      "step": 11215
    },
    {
      "epoch": 0.6653221022659864,
      "grad_norm": 13.013359069824219,
      "learning_rate": 7.437384655945163e-06,
      "loss": 0.214,
      "step": 11216
    },
    {
      "epoch": 0.6653814212836635,
      "grad_norm": 0.0335087813436985,
      "learning_rate": 7.436066438175588e-06,
      "loss": 0.0012,
      "step": 11217
    },
    {
      "epoch": 0.6654407403013406,
      "grad_norm": 0.023137718439102173,
      "learning_rate": 7.434748220406012e-06,
      "loss": 0.0007,
      "step": 11218
    },
    {
      "epoch": 0.6655000593190177,
      "grad_norm": 3.5776925086975098,
      "learning_rate": 7.433430002636436e-06,
      "loss": 0.1214,
      "step": 11219
    },
    {
      "epoch": 0.6655593783366948,
      "grad_norm": 3.4764065742492676,
      "learning_rate": 7.432111784866861e-06,
      "loss": 0.0155,
      "step": 11220
    },
    {
      "epoch": 0.6656186973543718,
      "grad_norm": 0.14841912686824799,
      "learning_rate": 7.430793567097285e-06,
      "loss": 0.0024,
      "step": 11221
    },
    {
      "epoch": 0.6656780163720489,
      "grad_norm": 4.204548358917236,
      "learning_rate": 7.4294753493277094e-06,
      "loss": 0.127,
      "step": 11222
    },
    {
      "epoch": 0.6657373353897259,
      "grad_norm": 4.572081565856934,
      "learning_rate": 7.428157131558134e-06,
      "loss": 0.0595,
      "step": 11223
    },
    {
      "epoch": 0.665796654407403,
      "grad_norm": 4.023769855499268,
      "learning_rate": 7.426838913788559e-06,
      "loss": 0.0967,
      "step": 11224
    },
    {
      "epoch": 0.6658559734250801,
      "grad_norm": 0.19403180480003357,
      "learning_rate": 7.425520696018983e-06,
      "loss": 0.0031,
      "step": 11225
    },
    {
      "epoch": 0.6659152924427572,
      "grad_norm": 16.291950225830078,
      "learning_rate": 7.424202478249407e-06,
      "loss": 0.0453,
      "step": 11226
    },
    {
      "epoch": 0.6659746114604342,
      "grad_norm": 0.27712538838386536,
      "learning_rate": 7.422884260479832e-06,
      "loss": 0.0026,
      "step": 11227
    },
    {
      "epoch": 0.6660339304781113,
      "grad_norm": 68.93254089355469,
      "learning_rate": 7.421566042710256e-06,
      "loss": 0.4115,
      "step": 11228
    },
    {
      "epoch": 0.6660932494957883,
      "grad_norm": 9.607605934143066,
      "learning_rate": 7.4202478249406804e-06,
      "loss": 0.0419,
      "step": 11229
    },
    {
      "epoch": 0.6661525685134654,
      "grad_norm": 34.816776275634766,
      "learning_rate": 7.418929607171105e-06,
      "loss": 0.2144,
      "step": 11230
    },
    {
      "epoch": 0.6662118875311425,
      "grad_norm": 5.87982702255249,
      "learning_rate": 7.41761138940153e-06,
      "loss": 0.141,
      "step": 11231
    },
    {
      "epoch": 0.6662712065488196,
      "grad_norm": 0.03913688287138939,
      "learning_rate": 7.416293171631954e-06,
      "loss": 0.0009,
      "step": 11232
    },
    {
      "epoch": 0.6663305255664966,
      "grad_norm": 14.203658103942871,
      "learning_rate": 7.414974953862378e-06,
      "loss": 0.0253,
      "step": 11233
    },
    {
      "epoch": 0.6663898445841737,
      "grad_norm": 0.036378368735313416,
      "learning_rate": 7.413656736092804e-06,
      "loss": 0.0007,
      "step": 11234
    },
    {
      "epoch": 0.6664491636018508,
      "grad_norm": 0.7458989024162292,
      "learning_rate": 7.412338518323228e-06,
      "loss": 0.0052,
      "step": 11235
    },
    {
      "epoch": 0.6665084826195278,
      "grad_norm": 0.9358270764350891,
      "learning_rate": 7.4110203005536515e-06,
      "loss": 0.0085,
      "step": 11236
    },
    {
      "epoch": 0.6665678016372049,
      "grad_norm": 17.13469886779785,
      "learning_rate": 7.409702082784076e-06,
      "loss": 0.1237,
      "step": 11237
    },
    {
      "epoch": 0.6666271206548819,
      "grad_norm": 6.086117267608643,
      "learning_rate": 7.4083838650145015e-06,
      "loss": 0.3936,
      "step": 11238
    },
    {
      "epoch": 0.666686439672559,
      "grad_norm": 9.993144035339355,
      "learning_rate": 7.407065647244926e-06,
      "loss": 0.709,
      "step": 11239
    },
    {
      "epoch": 0.6667457586902361,
      "grad_norm": 10.431594848632812,
      "learning_rate": 7.40574742947535e-06,
      "loss": 0.3258,
      "step": 11240
    },
    {
      "epoch": 0.6668050777079132,
      "grad_norm": 0.35758015513420105,
      "learning_rate": 7.404429211705775e-06,
      "loss": 0.0053,
      "step": 11241
    },
    {
      "epoch": 0.6668643967255902,
      "grad_norm": 12.038558959960938,
      "learning_rate": 7.403110993936199e-06,
      "loss": 0.4295,
      "step": 11242
    },
    {
      "epoch": 0.6669237157432673,
      "grad_norm": 6.985165119171143,
      "learning_rate": 7.401792776166623e-06,
      "loss": 0.368,
      "step": 11243
    },
    {
      "epoch": 0.6669830347609443,
      "grad_norm": 12.061477661132812,
      "learning_rate": 7.400474558397048e-06,
      "loss": 0.2707,
      "step": 11244
    },
    {
      "epoch": 0.6670423537786214,
      "grad_norm": 11.615571022033691,
      "learning_rate": 7.3991563406274725e-06,
      "loss": 0.3985,
      "step": 11245
    },
    {
      "epoch": 0.6671016727962985,
      "grad_norm": 31.352935791015625,
      "learning_rate": 7.397838122857897e-06,
      "loss": 0.1516,
      "step": 11246
    },
    {
      "epoch": 0.6671609918139756,
      "grad_norm": 0.46587786078453064,
      "learning_rate": 7.396519905088321e-06,
      "loss": 0.0067,
      "step": 11247
    },
    {
      "epoch": 0.6672203108316527,
      "grad_norm": 10.820292472839355,
      "learning_rate": 7.395201687318746e-06,
      "loss": 0.4247,
      "step": 11248
    },
    {
      "epoch": 0.6672796298493296,
      "grad_norm": 0.528672993183136,
      "learning_rate": 7.39388346954917e-06,
      "loss": 0.0037,
      "step": 11249
    },
    {
      "epoch": 0.6673389488670067,
      "grad_norm": 0.11716154217720032,
      "learning_rate": 7.392565251779594e-06,
      "loss": 0.0022,
      "step": 11250
    },
    {
      "epoch": 0.6673982678846838,
      "grad_norm": 3.7864115238189697,
      "learning_rate": 7.391247034010019e-06,
      "loss": 0.0454,
      "step": 11251
    },
    {
      "epoch": 0.6674575869023609,
      "grad_norm": 0.09847096353769302,
      "learning_rate": 7.3899288162404435e-06,
      "loss": 0.0018,
      "step": 11252
    },
    {
      "epoch": 0.667516905920038,
      "grad_norm": 2.9012482166290283,
      "learning_rate": 7.388610598470868e-06,
      "loss": 0.0246,
      "step": 11253
    },
    {
      "epoch": 0.6675762249377151,
      "grad_norm": 10.95506477355957,
      "learning_rate": 7.387292380701292e-06,
      "loss": 0.3747,
      "step": 11254
    },
    {
      "epoch": 0.6676355439553922,
      "grad_norm": 1.3725906610488892,
      "learning_rate": 7.385974162931717e-06,
      "loss": 0.0159,
      "step": 11255
    },
    {
      "epoch": 0.6676948629730691,
      "grad_norm": 9.422747611999512,
      "learning_rate": 7.384655945162141e-06,
      "loss": 0.198,
      "step": 11256
    },
    {
      "epoch": 0.6677541819907462,
      "grad_norm": 20.434965133666992,
      "learning_rate": 7.383337727392565e-06,
      "loss": 0.4657,
      "step": 11257
    },
    {
      "epoch": 0.6678135010084233,
      "grad_norm": 0.08231264352798462,
      "learning_rate": 7.38201950962299e-06,
      "loss": 0.0018,
      "step": 11258
    },
    {
      "epoch": 0.6678728200261004,
      "grad_norm": 0.004470255691558123,
      "learning_rate": 7.3807012918534145e-06,
      "loss": 0.0002,
      "step": 11259
    },
    {
      "epoch": 0.6679321390437775,
      "grad_norm": 0.09339312463998795,
      "learning_rate": 7.379383074083839e-06,
      "loss": 0.0018,
      "step": 11260
    },
    {
      "epoch": 0.6679914580614545,
      "grad_norm": 44.788856506347656,
      "learning_rate": 7.378064856314263e-06,
      "loss": 0.1514,
      "step": 11261
    },
    {
      "epoch": 0.6680507770791315,
      "grad_norm": 0.2808726131916046,
      "learning_rate": 7.376746638544689e-06,
      "loss": 0.0034,
      "step": 11262
    },
    {
      "epoch": 0.6681100960968086,
      "grad_norm": 0.019174901768565178,
      "learning_rate": 7.375428420775113e-06,
      "loss": 0.0004,
      "step": 11263
    },
    {
      "epoch": 0.6681694151144857,
      "grad_norm": 0.009494353085756302,
      "learning_rate": 7.374110203005536e-06,
      "loss": 0.0003,
      "step": 11264
    },
    {
      "epoch": 0.6682287341321628,
      "grad_norm": 1.107628583908081,
      "learning_rate": 7.372791985235962e-06,
      "loss": 0.0081,
      "step": 11265
    },
    {
      "epoch": 0.6682880531498399,
      "grad_norm": 0.041163381189107895,
      "learning_rate": 7.371473767466386e-06,
      "loss": 0.001,
      "step": 11266
    },
    {
      "epoch": 0.6683473721675169,
      "grad_norm": 13.646581649780273,
      "learning_rate": 7.3701555496968106e-06,
      "loss": 0.2009,
      "step": 11267
    },
    {
      "epoch": 0.668406691185194,
      "grad_norm": 13.68140697479248,
      "learning_rate": 7.368837331927236e-06,
      "loss": 0.1983,
      "step": 11268
    },
    {
      "epoch": 0.668466010202871,
      "grad_norm": 3.788102626800537,
      "learning_rate": 7.36751911415766e-06,
      "loss": 0.2761,
      "step": 11269
    },
    {
      "epoch": 0.6685253292205481,
      "grad_norm": 0.02992655523121357,
      "learning_rate": 7.366200896388084e-06,
      "loss": 0.0006,
      "step": 11270
    },
    {
      "epoch": 0.6685846482382252,
      "grad_norm": 3.7764601707458496,
      "learning_rate": 7.364882678618508e-06,
      "loss": 0.042,
      "step": 11271
    },
    {
      "epoch": 0.6686439672559022,
      "grad_norm": 12.114645957946777,
      "learning_rate": 7.363564460848933e-06,
      "loss": 0.1747,
      "step": 11272
    },
    {
      "epoch": 0.6687032862735793,
      "grad_norm": 14.612366676330566,
      "learning_rate": 7.362246243079357e-06,
      "loss": 0.2879,
      "step": 11273
    },
    {
      "epoch": 0.6687626052912564,
      "grad_norm": 5.190423011779785,
      "learning_rate": 7.3609280253097816e-06,
      "loss": 0.106,
      "step": 11274
    },
    {
      "epoch": 0.6688219243089334,
      "grad_norm": 0.10306434333324432,
      "learning_rate": 7.359609807540207e-06,
      "loss": 0.002,
      "step": 11275
    },
    {
      "epoch": 0.6688812433266105,
      "grad_norm": 2.3145463466644287,
      "learning_rate": 7.358291589770631e-06,
      "loss": 0.0277,
      "step": 11276
    },
    {
      "epoch": 0.6689405623442876,
      "grad_norm": 1.309841275215149,
      "learning_rate": 7.356973372001055e-06,
      "loss": 0.0048,
      "step": 11277
    },
    {
      "epoch": 0.6689998813619646,
      "grad_norm": 0.5644726753234863,
      "learning_rate": 7.355655154231479e-06,
      "loss": 0.0047,
      "step": 11278
    },
    {
      "epoch": 0.6690592003796417,
      "grad_norm": 6.527153015136719,
      "learning_rate": 7.354336936461904e-06,
      "loss": 0.2226,
      "step": 11279
    },
    {
      "epoch": 0.6691185193973188,
      "grad_norm": 4.270255088806152,
      "learning_rate": 7.353018718692328e-06,
      "loss": 0.0503,
      "step": 11280
    },
    {
      "epoch": 0.6691778384149959,
      "grad_norm": 0.8505237698554993,
      "learning_rate": 7.351700500922753e-06,
      "loss": 0.0067,
      "step": 11281
    },
    {
      "epoch": 0.6692371574326729,
      "grad_norm": 0.22383370995521545,
      "learning_rate": 7.350382283153178e-06,
      "loss": 0.0038,
      "step": 11282
    },
    {
      "epoch": 0.66929647645035,
      "grad_norm": 0.07875217497348785,
      "learning_rate": 7.349064065383602e-06,
      "loss": 0.0021,
      "step": 11283
    },
    {
      "epoch": 0.669355795468027,
      "grad_norm": 4.004169940948486,
      "learning_rate": 7.347745847614026e-06,
      "loss": 0.0119,
      "step": 11284
    },
    {
      "epoch": 0.6694151144857041,
      "grad_norm": 11.779583930969238,
      "learning_rate": 7.346427629844452e-06,
      "loss": 0.1815,
      "step": 11285
    },
    {
      "epoch": 0.6694744335033812,
      "grad_norm": 4.471107006072998,
      "learning_rate": 7.345109412074875e-06,
      "loss": 0.0643,
      "step": 11286
    },
    {
      "epoch": 0.6695337525210583,
      "grad_norm": 0.009233648888766766,
      "learning_rate": 7.343791194305299e-06,
      "loss": 0.0003,
      "step": 11287
    },
    {
      "epoch": 0.6695930715387354,
      "grad_norm": 11.185140609741211,
      "learning_rate": 7.342472976535724e-06,
      "loss": 0.8779,
      "step": 11288
    },
    {
      "epoch": 0.6696523905564123,
      "grad_norm": 0.43373796343803406,
      "learning_rate": 7.3411547587661495e-06,
      "loss": 0.0031,
      "step": 11289
    },
    {
      "epoch": 0.6697117095740894,
      "grad_norm": 9.74016284942627,
      "learning_rate": 7.339836540996574e-06,
      "loss": 0.1642,
      "step": 11290
    },
    {
      "epoch": 0.6697710285917665,
      "grad_norm": 0.21611887216567993,
      "learning_rate": 7.338518323226998e-06,
      "loss": 0.0043,
      "step": 11291
    },
    {
      "epoch": 0.6698303476094436,
      "grad_norm": 2.6835598945617676,
      "learning_rate": 7.337200105457423e-06,
      "loss": 0.0201,
      "step": 11292
    },
    {
      "epoch": 0.6698896666271207,
      "grad_norm": 0.07537597417831421,
      "learning_rate": 7.335881887687847e-06,
      "loss": 0.0015,
      "step": 11293
    },
    {
      "epoch": 0.6699489856447978,
      "grad_norm": 0.537786066532135,
      "learning_rate": 7.334563669918271e-06,
      "loss": 0.0111,
      "step": 11294
    },
    {
      "epoch": 0.6700083046624747,
      "grad_norm": 2.9591541290283203,
      "learning_rate": 7.3332454521486954e-06,
      "loss": 0.0205,
      "step": 11295
    },
    {
      "epoch": 0.6700676236801518,
      "grad_norm": 38.52310562133789,
      "learning_rate": 7.3319272343791205e-06,
      "loss": 0.1699,
      "step": 11296
    },
    {
      "epoch": 0.6701269426978289,
      "grad_norm": 3.92622709274292,
      "learning_rate": 7.330609016609545e-06,
      "loss": 0.0287,
      "step": 11297
    },
    {
      "epoch": 0.670186261715506,
      "grad_norm": 6.155513286590576,
      "learning_rate": 7.329290798839969e-06,
      "loss": 0.1124,
      "step": 11298
    },
    {
      "epoch": 0.6702455807331831,
      "grad_norm": 1.1100517511367798,
      "learning_rate": 7.327972581070394e-06,
      "loss": 0.0113,
      "step": 11299
    },
    {
      "epoch": 0.6703048997508602,
      "grad_norm": 8.99377727508545,
      "learning_rate": 7.326654363300818e-06,
      "loss": 0.2281,
      "step": 11300
    },
    {
      "epoch": 0.6703642187685372,
      "grad_norm": 10.440779685974121,
      "learning_rate": 7.325336145531242e-06,
      "loss": 0.1028,
      "step": 11301
    },
    {
      "epoch": 0.6704235377862142,
      "grad_norm": 0.3969564735889435,
      "learning_rate": 7.3240179277616664e-06,
      "loss": 0.0029,
      "step": 11302
    },
    {
      "epoch": 0.6704828568038913,
      "grad_norm": 0.23069624602794647,
      "learning_rate": 7.3226997099920915e-06,
      "loss": 0.0045,
      "step": 11303
    },
    {
      "epoch": 0.6705421758215684,
      "grad_norm": 9.929311752319336,
      "learning_rate": 7.321381492222516e-06,
      "loss": 0.3436,
      "step": 11304
    },
    {
      "epoch": 0.6706014948392455,
      "grad_norm": 0.07675109058618546,
      "learning_rate": 7.32006327445294e-06,
      "loss": 0.0011,
      "step": 11305
    },
    {
      "epoch": 0.6706608138569226,
      "grad_norm": 2.1280343532562256,
      "learning_rate": 7.318745056683365e-06,
      "loss": 0.0401,
      "step": 11306
    },
    {
      "epoch": 0.6707201328745996,
      "grad_norm": 25.362953186035156,
      "learning_rate": 7.317426838913789e-06,
      "loss": 0.1193,
      "step": 11307
    },
    {
      "epoch": 0.6707794518922766,
      "grad_norm": 7.160839557647705,
      "learning_rate": 7.316108621144213e-06,
      "loss": 0.2541,
      "step": 11308
    },
    {
      "epoch": 0.6708387709099537,
      "grad_norm": 0.08702485263347626,
      "learning_rate": 7.314790403374638e-06,
      "loss": 0.0007,
      "step": 11309
    },
    {
      "epoch": 0.6708980899276308,
      "grad_norm": 3.354907751083374,
      "learning_rate": 7.3134721856050625e-06,
      "loss": 0.076,
      "step": 11310
    },
    {
      "epoch": 0.6709574089453079,
      "grad_norm": 0.029164694249629974,
      "learning_rate": 7.312153967835487e-06,
      "loss": 0.0009,
      "step": 11311
    },
    {
      "epoch": 0.671016727962985,
      "grad_norm": 0.08869051188230515,
      "learning_rate": 7.310835750065911e-06,
      "loss": 0.0016,
      "step": 11312
    },
    {
      "epoch": 0.671076046980662,
      "grad_norm": 6.27243709564209,
      "learning_rate": 7.309517532296337e-06,
      "loss": 0.0846,
      "step": 11313
    },
    {
      "epoch": 0.6711353659983391,
      "grad_norm": 2.5076370239257812,
      "learning_rate": 7.30819931452676e-06,
      "loss": 0.1049,
      "step": 11314
    },
    {
      "epoch": 0.6711946850160161,
      "grad_norm": 0.2858709692955017,
      "learning_rate": 7.306881096757184e-06,
      "loss": 0.0019,
      "step": 11315
    },
    {
      "epoch": 0.6712540040336932,
      "grad_norm": 0.012487425468862057,
      "learning_rate": 7.30556287898761e-06,
      "loss": 0.0005,
      "step": 11316
    },
    {
      "epoch": 0.6713133230513703,
      "grad_norm": 0.1573898047208786,
      "learning_rate": 7.304244661218034e-06,
      "loss": 0.002,
      "step": 11317
    },
    {
      "epoch": 0.6713726420690473,
      "grad_norm": 10.894359588623047,
      "learning_rate": 7.3029264434484585e-06,
      "loss": 0.1248,
      "step": 11318
    },
    {
      "epoch": 0.6714319610867244,
      "grad_norm": 0.06866107881069183,
      "learning_rate": 7.301608225678883e-06,
      "loss": 0.0015,
      "step": 11319
    },
    {
      "epoch": 0.6714912801044015,
      "grad_norm": 0.3571733236312866,
      "learning_rate": 7.300290007909308e-06,
      "loss": 0.005,
      "step": 11320
    },
    {
      "epoch": 0.6715505991220785,
      "grad_norm": 0.025872565805912018,
      "learning_rate": 7.298971790139732e-06,
      "loss": 0.0004,
      "step": 11321
    },
    {
      "epoch": 0.6716099181397556,
      "grad_norm": 9.385228157043457,
      "learning_rate": 7.297653572370156e-06,
      "loss": 0.3911,
      "step": 11322
    },
    {
      "epoch": 0.6716692371574327,
      "grad_norm": 0.13081245124340057,
      "learning_rate": 7.296335354600581e-06,
      "loss": 0.0025,
      "step": 11323
    },
    {
      "epoch": 0.6717285561751097,
      "grad_norm": 0.10155952721834183,
      "learning_rate": 7.295017136831005e-06,
      "loss": 0.0014,
      "step": 11324
    },
    {
      "epoch": 0.6717878751927868,
      "grad_norm": 0.06440450251102448,
      "learning_rate": 7.2936989190614295e-06,
      "loss": 0.0015,
      "step": 11325
    },
    {
      "epoch": 0.6718471942104639,
      "grad_norm": 27.397958755493164,
      "learning_rate": 7.292380701291854e-06,
      "loss": 0.327,
      "step": 11326
    },
    {
      "epoch": 0.671906513228141,
      "grad_norm": 0.015976358205080032,
      "learning_rate": 7.291062483522279e-06,
      "loss": 0.0006,
      "step": 11327
    },
    {
      "epoch": 0.671965832245818,
      "grad_norm": 0.057122621685266495,
      "learning_rate": 7.289744265752703e-06,
      "loss": 0.0012,
      "step": 11328
    },
    {
      "epoch": 0.672025151263495,
      "grad_norm": 0.04275452345609665,
      "learning_rate": 7.288426047983127e-06,
      "loss": 0.0008,
      "step": 11329
    },
    {
      "epoch": 0.6720844702811721,
      "grad_norm": 0.07769579440355301,
      "learning_rate": 7.287107830213552e-06,
      "loss": 0.0017,
      "step": 11330
    },
    {
      "epoch": 0.6721437892988492,
      "grad_norm": 0.005737936124205589,
      "learning_rate": 7.285789612443976e-06,
      "loss": 0.0002,
      "step": 11331
    },
    {
      "epoch": 0.6722031083165263,
      "grad_norm": 2.655050277709961,
      "learning_rate": 7.2844713946744005e-06,
      "loss": 0.0214,
      "step": 11332
    },
    {
      "epoch": 0.6722624273342034,
      "grad_norm": 15.972498893737793,
      "learning_rate": 7.2831531769048256e-06,
      "loss": 0.6193,
      "step": 11333
    },
    {
      "epoch": 0.6723217463518805,
      "grad_norm": 2.542409896850586,
      "learning_rate": 7.28183495913525e-06,
      "loss": 0.0407,
      "step": 11334
    },
    {
      "epoch": 0.6723810653695574,
      "grad_norm": 5.282856464385986,
      "learning_rate": 7.280516741365674e-06,
      "loss": 0.0794,
      "step": 11335
    },
    {
      "epoch": 0.6724403843872345,
      "grad_norm": 15.26876449584961,
      "learning_rate": 7.279198523596098e-06,
      "loss": 0.1017,
      "step": 11336
    },
    {
      "epoch": 0.6724997034049116,
      "grad_norm": 0.07974492758512497,
      "learning_rate": 7.277880305826523e-06,
      "loss": 0.0013,
      "step": 11337
    },
    {
      "epoch": 0.6725590224225887,
      "grad_norm": 0.0477396585047245,
      "learning_rate": 7.276562088056947e-06,
      "loss": 0.0014,
      "step": 11338
    },
    {
      "epoch": 0.6726183414402658,
      "grad_norm": 5.157890319824219,
      "learning_rate": 7.2752438702873715e-06,
      "loss": 0.2779,
      "step": 11339
    },
    {
      "epoch": 0.6726776604579429,
      "grad_norm": 8.703445434570312,
      "learning_rate": 7.273925652517797e-06,
      "loss": 0.0888,
      "step": 11340
    },
    {
      "epoch": 0.6727369794756198,
      "grad_norm": 19.08989715576172,
      "learning_rate": 7.272607434748222e-06,
      "loss": 0.0517,
      "step": 11341
    },
    {
      "epoch": 0.6727962984932969,
      "grad_norm": 1.7537132501602173,
      "learning_rate": 7.271289216978645e-06,
      "loss": 0.0145,
      "step": 11342
    },
    {
      "epoch": 0.672855617510974,
      "grad_norm": 2.339433431625366,
      "learning_rate": 7.269970999209069e-06,
      "loss": 0.0411,
      "step": 11343
    },
    {
      "epoch": 0.6729149365286511,
      "grad_norm": 0.9058540463447571,
      "learning_rate": 7.268652781439495e-06,
      "loss": 0.0072,
      "step": 11344
    },
    {
      "epoch": 0.6729742555463282,
      "grad_norm": 6.362259864807129,
      "learning_rate": 7.267334563669919e-06,
      "loss": 0.205,
      "step": 11345
    },
    {
      "epoch": 0.6730335745640053,
      "grad_norm": 6.708776950836182,
      "learning_rate": 7.266016345900343e-06,
      "loss": 0.3337,
      "step": 11346
    },
    {
      "epoch": 0.6730928935816823,
      "grad_norm": 0.020011255517601967,
      "learning_rate": 7.264698128130768e-06,
      "loss": 0.0006,
      "step": 11347
    },
    {
      "epoch": 0.6731522125993593,
      "grad_norm": 0.9323436617851257,
      "learning_rate": 7.263379910361193e-06,
      "loss": 0.0066,
      "step": 11348
    },
    {
      "epoch": 0.6732115316170364,
      "grad_norm": 0.7357065081596375,
      "learning_rate": 7.262061692591617e-06,
      "loss": 0.0041,
      "step": 11349
    },
    {
      "epoch": 0.6732708506347135,
      "grad_norm": 1.8928769826889038,
      "learning_rate": 7.260743474822041e-06,
      "loss": 0.02,
      "step": 11350
    },
    {
      "epoch": 0.6733301696523906,
      "grad_norm": 0.008587672375142574,
      "learning_rate": 7.259425257052466e-06,
      "loss": 0.0003,
      "step": 11351
    },
    {
      "epoch": 0.6733894886700676,
      "grad_norm": 19.067337036132812,
      "learning_rate": 7.25810703928289e-06,
      "loss": 0.237,
      "step": 11352
    },
    {
      "epoch": 0.6734488076877447,
      "grad_norm": 0.03011934645473957,
      "learning_rate": 7.256788821513314e-06,
      "loss": 0.0009,
      "step": 11353
    },
    {
      "epoch": 0.6735081267054217,
      "grad_norm": 0.0906299501657486,
      "learning_rate": 7.255470603743739e-06,
      "loss": 0.0013,
      "step": 11354
    },
    {
      "epoch": 0.6735674457230988,
      "grad_norm": 0.30987420678138733,
      "learning_rate": 7.254152385974164e-06,
      "loss": 0.0058,
      "step": 11355
    },
    {
      "epoch": 0.6736267647407759,
      "grad_norm": 0.013593087904155254,
      "learning_rate": 7.252834168204588e-06,
      "loss": 0.0004,
      "step": 11356
    },
    {
      "epoch": 0.673686083758453,
      "grad_norm": 0.015026451088488102,
      "learning_rate": 7.251515950435013e-06,
      "loss": 0.0006,
      "step": 11357
    },
    {
      "epoch": 0.67374540277613,
      "grad_norm": 10.22494888305664,
      "learning_rate": 7.250197732665437e-06,
      "loss": 0.8491,
      "step": 11358
    },
    {
      "epoch": 0.6738047217938071,
      "grad_norm": 29.18089485168457,
      "learning_rate": 7.248879514895861e-06,
      "loss": 0.742,
      "step": 11359
    },
    {
      "epoch": 0.6738640408114842,
      "grad_norm": 2.159294605255127,
      "learning_rate": 7.247561297126285e-06,
      "loss": 0.0301,
      "step": 11360
    },
    {
      "epoch": 0.6739233598291612,
      "grad_norm": 0.01270088367164135,
      "learning_rate": 7.24624307935671e-06,
      "loss": 0.0003,
      "step": 11361
    },
    {
      "epoch": 0.6739826788468383,
      "grad_norm": 2.151920795440674,
      "learning_rate": 7.244924861587135e-06,
      "loss": 0.0311,
      "step": 11362
    },
    {
      "epoch": 0.6740419978645154,
      "grad_norm": 2.935001850128174,
      "learning_rate": 7.243606643817559e-06,
      "loss": 0.027,
      "step": 11363
    },
    {
      "epoch": 0.6741013168821924,
      "grad_norm": 0.03341576084494591,
      "learning_rate": 7.242288426047984e-06,
      "loss": 0.0007,
      "step": 11364
    },
    {
      "epoch": 0.6741606358998695,
      "grad_norm": 0.2457474172115326,
      "learning_rate": 7.240970208278408e-06,
      "loss": 0.0024,
      "step": 11365
    },
    {
      "epoch": 0.6742199549175466,
      "grad_norm": 14.076397895812988,
      "learning_rate": 7.239651990508832e-06,
      "loss": 0.4771,
      "step": 11366
    },
    {
      "epoch": 0.6742792739352236,
      "grad_norm": 5.613474369049072,
      "learning_rate": 7.238333772739256e-06,
      "loss": 0.1163,
      "step": 11367
    },
    {
      "epoch": 0.6743385929529007,
      "grad_norm": 10.956052780151367,
      "learning_rate": 7.237015554969682e-06,
      "loss": 0.1612,
      "step": 11368
    },
    {
      "epoch": 0.6743979119705777,
      "grad_norm": 0.2106499969959259,
      "learning_rate": 7.2356973372001065e-06,
      "loss": 0.0036,
      "step": 11369
    },
    {
      "epoch": 0.6744572309882548,
      "grad_norm": 0.09878488630056381,
      "learning_rate": 7.23437911943053e-06,
      "loss": 0.0019,
      "step": 11370
    },
    {
      "epoch": 0.6745165500059319,
      "grad_norm": 1.107858419418335,
      "learning_rate": 7.233060901660956e-06,
      "loss": 0.0119,
      "step": 11371
    },
    {
      "epoch": 0.674575869023609,
      "grad_norm": 1.3120653629302979,
      "learning_rate": 7.23174268389138e-06,
      "loss": 0.0157,
      "step": 11372
    },
    {
      "epoch": 0.6746351880412861,
      "grad_norm": 5.786494255065918,
      "learning_rate": 7.230424466121804e-06,
      "loss": 0.0271,
      "step": 11373
    },
    {
      "epoch": 0.6746945070589631,
      "grad_norm": 1.0539722442626953,
      "learning_rate": 7.229106248352228e-06,
      "loss": 0.016,
      "step": 11374
    },
    {
      "epoch": 0.6747538260766401,
      "grad_norm": 0.12660850584506989,
      "learning_rate": 7.227788030582653e-06,
      "loss": 0.0026,
      "step": 11375
    },
    {
      "epoch": 0.6748131450943172,
      "grad_norm": 10.777007102966309,
      "learning_rate": 7.2264698128130775e-06,
      "loss": 0.0664,
      "step": 11376
    },
    {
      "epoch": 0.6748724641119943,
      "grad_norm": 2.2450637817382812,
      "learning_rate": 7.225151595043502e-06,
      "loss": 0.0519,
      "step": 11377
    },
    {
      "epoch": 0.6749317831296714,
      "grad_norm": 4.647528171539307,
      "learning_rate": 7.223833377273927e-06,
      "loss": 0.0348,
      "step": 11378
    },
    {
      "epoch": 0.6749911021473485,
      "grad_norm": 0.10471116751432419,
      "learning_rate": 7.222515159504351e-06,
      "loss": 0.0014,
      "step": 11379
    },
    {
      "epoch": 0.6750504211650256,
      "grad_norm": 0.007777325809001923,
      "learning_rate": 7.221196941734775e-06,
      "loss": 0.0002,
      "step": 11380
    },
    {
      "epoch": 0.6751097401827025,
      "grad_norm": 8.82878589630127,
      "learning_rate": 7.2198787239652e-06,
      "loss": 0.5145,
      "step": 11381
    },
    {
      "epoch": 0.6751690592003796,
      "grad_norm": 4.3049798011779785,
      "learning_rate": 7.218560506195624e-06,
      "loss": 0.0924,
      "step": 11382
    },
    {
      "epoch": 0.6752283782180567,
      "grad_norm": 3.019320249557495,
      "learning_rate": 7.2172422884260485e-06,
      "loss": 0.0251,
      "step": 11383
    },
    {
      "epoch": 0.6752876972357338,
      "grad_norm": 25.427350997924805,
      "learning_rate": 7.215924070656473e-06,
      "loss": 1.9717,
      "step": 11384
    },
    {
      "epoch": 0.6753470162534109,
      "grad_norm": 0.0465724803507328,
      "learning_rate": 7.214605852886898e-06,
      "loss": 0.0006,
      "step": 11385
    },
    {
      "epoch": 0.675406335271088,
      "grad_norm": 9.427857398986816,
      "learning_rate": 7.213287635117322e-06,
      "loss": 0.2982,
      "step": 11386
    },
    {
      "epoch": 0.6754656542887649,
      "grad_norm": 0.1792079657316208,
      "learning_rate": 7.211969417347746e-06,
      "loss": 0.0016,
      "step": 11387
    },
    {
      "epoch": 0.675524973306442,
      "grad_norm": 10.641194343566895,
      "learning_rate": 7.210651199578171e-06,
      "loss": 0.2727,
      "step": 11388
    },
    {
      "epoch": 0.6755842923241191,
      "grad_norm": 0.023967232555150986,
      "learning_rate": 7.209332981808595e-06,
      "loss": 0.0005,
      "step": 11389
    },
    {
      "epoch": 0.6756436113417962,
      "grad_norm": 0.10403121262788773,
      "learning_rate": 7.2080147640390195e-06,
      "loss": 0.0014,
      "step": 11390
    },
    {
      "epoch": 0.6757029303594733,
      "grad_norm": 5.577511310577393,
      "learning_rate": 7.206696546269444e-06,
      "loss": 0.2255,
      "step": 11391
    },
    {
      "epoch": 0.6757622493771503,
      "grad_norm": 0.04649212956428528,
      "learning_rate": 7.205378328499869e-06,
      "loss": 0.0014,
      "step": 11392
    },
    {
      "epoch": 0.6758215683948274,
      "grad_norm": 5.23394775390625,
      "learning_rate": 7.204060110730293e-06,
      "loss": 0.1844,
      "step": 11393
    },
    {
      "epoch": 0.6758808874125044,
      "grad_norm": 0.13084474205970764,
      "learning_rate": 7.202741892960717e-06,
      "loss": 0.0024,
      "step": 11394
    },
    {
      "epoch": 0.6759402064301815,
      "grad_norm": 24.649967193603516,
      "learning_rate": 7.201423675191143e-06,
      "loss": 1.2226,
      "step": 11395
    },
    {
      "epoch": 0.6759995254478586,
      "grad_norm": 0.7083620429039001,
      "learning_rate": 7.200105457421567e-06,
      "loss": 0.0061,
      "step": 11396
    },
    {
      "epoch": 0.6760588444655357,
      "grad_norm": 12.912027359008789,
      "learning_rate": 7.1987872396519905e-06,
      "loss": 0.6844,
      "step": 11397
    },
    {
      "epoch": 0.6761181634832127,
      "grad_norm": 16.811025619506836,
      "learning_rate": 7.197469021882415e-06,
      "loss": 0.4445,
      "step": 11398
    },
    {
      "epoch": 0.6761774825008898,
      "grad_norm": 0.02659127674996853,
      "learning_rate": 7.1961508041128405e-06,
      "loss": 0.0005,
      "step": 11399
    },
    {
      "epoch": 0.6762368015185668,
      "grad_norm": 0.015668271109461784,
      "learning_rate": 7.194832586343265e-06,
      "loss": 0.0004,
      "step": 11400
    },
    {
      "epoch": 0.6762961205362439,
      "grad_norm": 6.691771507263184,
      "learning_rate": 7.193514368573689e-06,
      "loss": 0.351,
      "step": 11401
    },
    {
      "epoch": 0.676355439553921,
      "grad_norm": 0.13544704020023346,
      "learning_rate": 7.192196150804114e-06,
      "loss": 0.003,
      "step": 11402
    },
    {
      "epoch": 0.676414758571598,
      "grad_norm": 0.04978843778371811,
      "learning_rate": 7.190877933034538e-06,
      "loss": 0.0008,
      "step": 11403
    },
    {
      "epoch": 0.6764740775892751,
      "grad_norm": 1.8964093923568726,
      "learning_rate": 7.189559715264962e-06,
      "loss": 0.0444,
      "step": 11404
    },
    {
      "epoch": 0.6765333966069522,
      "grad_norm": 0.21398897469043732,
      "learning_rate": 7.188241497495387e-06,
      "loss": 0.0048,
      "step": 11405
    },
    {
      "epoch": 0.6765927156246293,
      "grad_norm": 0.515175998210907,
      "learning_rate": 7.1869232797258115e-06,
      "loss": 0.0041,
      "step": 11406
    },
    {
      "epoch": 0.6766520346423063,
      "grad_norm": 23.093050003051758,
      "learning_rate": 7.185605061956236e-06,
      "loss": 1.0929,
      "step": 11407
    },
    {
      "epoch": 0.6767113536599834,
      "grad_norm": 0.05940091982483864,
      "learning_rate": 7.18428684418666e-06,
      "loss": 0.0012,
      "step": 11408
    },
    {
      "epoch": 0.6767706726776604,
      "grad_norm": 9.19328784942627,
      "learning_rate": 7.182968626417085e-06,
      "loss": 0.5838,
      "step": 11409
    },
    {
      "epoch": 0.6768299916953375,
      "grad_norm": 5.055206298828125,
      "learning_rate": 7.181650408647509e-06,
      "loss": 0.2122,
      "step": 11410
    },
    {
      "epoch": 0.6768893107130146,
      "grad_norm": 15.337160110473633,
      "learning_rate": 7.180332190877933e-06,
      "loss": 0.5335,
      "step": 11411
    },
    {
      "epoch": 0.6769486297306917,
      "grad_norm": 0.07689377665519714,
      "learning_rate": 7.179013973108358e-06,
      "loss": 0.0009,
      "step": 11412
    },
    {
      "epoch": 0.6770079487483688,
      "grad_norm": 0.11670675128698349,
      "learning_rate": 7.1776957553387825e-06,
      "loss": 0.0026,
      "step": 11413
    },
    {
      "epoch": 0.6770672677660458,
      "grad_norm": 9.781678199768066,
      "learning_rate": 7.176377537569207e-06,
      "loss": 0.7404,
      "step": 11414
    },
    {
      "epoch": 0.6771265867837228,
      "grad_norm": 5.283764362335205,
      "learning_rate": 7.175059319799631e-06,
      "loss": 0.0243,
      "step": 11415
    },
    {
      "epoch": 0.6771859058013999,
      "grad_norm": 5.663282871246338,
      "learning_rate": 7.173741102030056e-06,
      "loss": 0.105,
      "step": 11416
    },
    {
      "epoch": 0.677245224819077,
      "grad_norm": 0.12158782035112381,
      "learning_rate": 7.17242288426048e-06,
      "loss": 0.0022,
      "step": 11417
    },
    {
      "epoch": 0.6773045438367541,
      "grad_norm": 13.300990104675293,
      "learning_rate": 7.171104666490904e-06,
      "loss": 0.0983,
      "step": 11418
    },
    {
      "epoch": 0.6773638628544312,
      "grad_norm": 7.1185102462768555,
      "learning_rate": 7.169786448721329e-06,
      "loss": 0.3042,
      "step": 11419
    },
    {
      "epoch": 0.6774231818721081,
      "grad_norm": 7.500832557678223,
      "learning_rate": 7.1684682309517535e-06,
      "loss": 0.1746,
      "step": 11420
    },
    {
      "epoch": 0.6774825008897852,
      "grad_norm": 0.012493903748691082,
      "learning_rate": 7.167150013182178e-06,
      "loss": 0.0003,
      "step": 11421
    },
    {
      "epoch": 0.6775418199074623,
      "grad_norm": 0.07969971746206284,
      "learning_rate": 7.165831795412602e-06,
      "loss": 0.0019,
      "step": 11422
    },
    {
      "epoch": 0.6776011389251394,
      "grad_norm": 0.14547306299209595,
      "learning_rate": 7.164513577643028e-06,
      "loss": 0.0014,
      "step": 11423
    },
    {
      "epoch": 0.6776604579428165,
      "grad_norm": 0.03425076976418495,
      "learning_rate": 7.163195359873452e-06,
      "loss": 0.0009,
      "step": 11424
    },
    {
      "epoch": 0.6777197769604936,
      "grad_norm": 12.7124605178833,
      "learning_rate": 7.161877142103875e-06,
      "loss": 0.1365,
      "step": 11425
    },
    {
      "epoch": 0.6777790959781707,
      "grad_norm": 0.30011874437332153,
      "learning_rate": 7.160558924334301e-06,
      "loss": 0.0044,
      "step": 11426
    },
    {
      "epoch": 0.6778384149958476,
      "grad_norm": 0.33106765151023865,
      "learning_rate": 7.159240706564725e-06,
      "loss": 0.0031,
      "step": 11427
    },
    {
      "epoch": 0.6778977340135247,
      "grad_norm": 5.8704752922058105,
      "learning_rate": 7.15792248879515e-06,
      "loss": 0.0302,
      "step": 11428
    },
    {
      "epoch": 0.6779570530312018,
      "grad_norm": 0.01580151356756687,
      "learning_rate": 7.156604271025575e-06,
      "loss": 0.0005,
      "step": 11429
    },
    {
      "epoch": 0.6780163720488789,
      "grad_norm": 0.7316899299621582,
      "learning_rate": 7.155286053255999e-06,
      "loss": 0.0108,
      "step": 11430
    },
    {
      "epoch": 0.678075691066556,
      "grad_norm": 0.3190896809101105,
      "learning_rate": 7.153967835486423e-06,
      "loss": 0.0053,
      "step": 11431
    },
    {
      "epoch": 0.678135010084233,
      "grad_norm": 0.17969028651714325,
      "learning_rate": 7.152649617716847e-06,
      "loss": 0.0027,
      "step": 11432
    },
    {
      "epoch": 0.67819432910191,
      "grad_norm": 1.9898881912231445,
      "learning_rate": 7.151331399947272e-06,
      "loss": 0.0162,
      "step": 11433
    },
    {
      "epoch": 0.6782536481195871,
      "grad_norm": 6.54588508605957,
      "learning_rate": 7.150013182177696e-06,
      "loss": 0.039,
      "step": 11434
    },
    {
      "epoch": 0.6783129671372642,
      "grad_norm": 0.08626139909029007,
      "learning_rate": 7.148694964408121e-06,
      "loss": 0.0019,
      "step": 11435
    },
    {
      "epoch": 0.6783722861549413,
      "grad_norm": 0.4238266944885254,
      "learning_rate": 7.147376746638546e-06,
      "loss": 0.0037,
      "step": 11436
    },
    {
      "epoch": 0.6784316051726184,
      "grad_norm": 0.18226738274097443,
      "learning_rate": 7.14605852886897e-06,
      "loss": 0.0021,
      "step": 11437
    },
    {
      "epoch": 0.6784909241902954,
      "grad_norm": 0.055962979793548584,
      "learning_rate": 7.144740311099394e-06,
      "loss": 0.0015,
      "step": 11438
    },
    {
      "epoch": 0.6785502432079725,
      "grad_norm": 2.3121113777160645,
      "learning_rate": 7.143422093329818e-06,
      "loss": 0.0261,
      "step": 11439
    },
    {
      "epoch": 0.6786095622256495,
      "grad_norm": 8.067886352539062,
      "learning_rate": 7.142103875560243e-06,
      "loss": 0.5563,
      "step": 11440
    },
    {
      "epoch": 0.6786688812433266,
      "grad_norm": 18.81800651550293,
      "learning_rate": 7.140785657790667e-06,
      "loss": 0.2184,
      "step": 11441
    },
    {
      "epoch": 0.6787282002610037,
      "grad_norm": 4.777096748352051,
      "learning_rate": 7.139467440021092e-06,
      "loss": 0.2865,
      "step": 11442
    },
    {
      "epoch": 0.6787875192786808,
      "grad_norm": 6.952474117279053,
      "learning_rate": 7.138149222251517e-06,
      "loss": 0.2499,
      "step": 11443
    },
    {
      "epoch": 0.6788468382963578,
      "grad_norm": 5.392300128936768,
      "learning_rate": 7.136831004481941e-06,
      "loss": 0.0236,
      "step": 11444
    },
    {
      "epoch": 0.6789061573140349,
      "grad_norm": 5.368526935577393,
      "learning_rate": 7.135512786712365e-06,
      "loss": 0.1384,
      "step": 11445
    },
    {
      "epoch": 0.6789654763317119,
      "grad_norm": 0.16763824224472046,
      "learning_rate": 7.134194568942789e-06,
      "loss": 0.0032,
      "step": 11446
    },
    {
      "epoch": 0.679024795349389,
      "grad_norm": 15.282995223999023,
      "learning_rate": 7.132876351173214e-06,
      "loss": 0.3936,
      "step": 11447
    },
    {
      "epoch": 0.6790841143670661,
      "grad_norm": 6.4048848152160645,
      "learning_rate": 7.131558133403638e-06,
      "loss": 0.0722,
      "step": 11448
    },
    {
      "epoch": 0.6791434333847431,
      "grad_norm": 1.846267580986023,
      "learning_rate": 7.130239915634063e-06,
      "loss": 0.0211,
      "step": 11449
    },
    {
      "epoch": 0.6792027524024202,
      "grad_norm": 0.08333954215049744,
      "learning_rate": 7.1289216978644885e-06,
      "loss": 0.0018,
      "step": 11450
    },
    {
      "epoch": 0.6792620714200973,
      "grad_norm": 1.3120001554489136,
      "learning_rate": 7.127603480094913e-06,
      "loss": 0.0183,
      "step": 11451
    },
    {
      "epoch": 0.6793213904377744,
      "grad_norm": 0.025403019040822983,
      "learning_rate": 7.126285262325337e-06,
      "loss": 0.0007,
      "step": 11452
    },
    {
      "epoch": 0.6793807094554514,
      "grad_norm": 0.020300915464758873,
      "learning_rate": 7.124967044555762e-06,
      "loss": 0.0009,
      "step": 11453
    },
    {
      "epoch": 0.6794400284731285,
      "grad_norm": 0.06133141741156578,
      "learning_rate": 7.123648826786186e-06,
      "loss": 0.0015,
      "step": 11454
    },
    {
      "epoch": 0.6794993474908055,
      "grad_norm": 0.09845677018165588,
      "learning_rate": 7.12233060901661e-06,
      "loss": 0.0018,
      "step": 11455
    },
    {
      "epoch": 0.6795586665084826,
      "grad_norm": 0.18045462667942047,
      "learning_rate": 7.1210123912470344e-06,
      "loss": 0.0052,
      "step": 11456
    },
    {
      "epoch": 0.6796179855261597,
      "grad_norm": 0.977790892124176,
      "learning_rate": 7.1196941734774595e-06,
      "loss": 0.0132,
      "step": 11457
    },
    {
      "epoch": 0.6796773045438368,
      "grad_norm": 0.2549511790275574,
      "learning_rate": 7.118375955707884e-06,
      "loss": 0.0022,
      "step": 11458
    },
    {
      "epoch": 0.6797366235615139,
      "grad_norm": 0.032975807785987854,
      "learning_rate": 7.117057737938308e-06,
      "loss": 0.0008,
      "step": 11459
    },
    {
      "epoch": 0.6797959425791908,
      "grad_norm": 1.5891578197479248,
      "learning_rate": 7.115739520168733e-06,
      "loss": 0.0262,
      "step": 11460
    },
    {
      "epoch": 0.6798552615968679,
      "grad_norm": 0.017934860661625862,
      "learning_rate": 7.114421302399157e-06,
      "loss": 0.0005,
      "step": 11461
    },
    {
      "epoch": 0.679914580614545,
      "grad_norm": 6.802402973175049,
      "learning_rate": 7.113103084629581e-06,
      "loss": 0.2029,
      "step": 11462
    },
    {
      "epoch": 0.6799738996322221,
      "grad_norm": 24.141233444213867,
      "learning_rate": 7.1117848668600055e-06,
      "loss": 0.5642,
      "step": 11463
    },
    {
      "epoch": 0.6800332186498992,
      "grad_norm": 4.595661640167236,
      "learning_rate": 7.1104666490904305e-06,
      "loss": 0.0391,
      "step": 11464
    },
    {
      "epoch": 0.6800925376675763,
      "grad_norm": 0.3921104669570923,
      "learning_rate": 7.109148431320855e-06,
      "loss": 0.0032,
      "step": 11465
    },
    {
      "epoch": 0.6801518566852532,
      "grad_norm": 15.626818656921387,
      "learning_rate": 7.107830213551279e-06,
      "loss": 0.5478,
      "step": 11466
    },
    {
      "epoch": 0.6802111757029303,
      "grad_norm": 20.982831954956055,
      "learning_rate": 7.106511995781704e-06,
      "loss": 0.1751,
      "step": 11467
    },
    {
      "epoch": 0.6802704947206074,
      "grad_norm": 0.02006499283015728,
      "learning_rate": 7.105193778012128e-06,
      "loss": 0.0006,
      "step": 11468
    },
    {
      "epoch": 0.6803298137382845,
      "grad_norm": 5.612435817718506,
      "learning_rate": 7.103875560242552e-06,
      "loss": 0.0486,
      "step": 11469
    },
    {
      "epoch": 0.6803891327559616,
      "grad_norm": 0.15607427060604095,
      "learning_rate": 7.1025573424729765e-06,
      "loss": 0.0019,
      "step": 11470
    },
    {
      "epoch": 0.6804484517736387,
      "grad_norm": 0.024441706016659737,
      "learning_rate": 7.1012391247034015e-06,
      "loss": 0.0007,
      "step": 11471
    },
    {
      "epoch": 0.6805077707913157,
      "grad_norm": 2.8927295207977295,
      "learning_rate": 7.099920906933826e-06,
      "loss": 0.017,
      "step": 11472
    },
    {
      "epoch": 0.6805670898089927,
      "grad_norm": 0.02211415022611618,
      "learning_rate": 7.09860268916425e-06,
      "loss": 0.0008,
      "step": 11473
    },
    {
      "epoch": 0.6806264088266698,
      "grad_norm": 0.16958945989608765,
      "learning_rate": 7.097284471394676e-06,
      "loss": 0.0034,
      "step": 11474
    },
    {
      "epoch": 0.6806857278443469,
      "grad_norm": 0.8807523250579834,
      "learning_rate": 7.095966253625099e-06,
      "loss": 0.011,
      "step": 11475
    },
    {
      "epoch": 0.680745046862024,
      "grad_norm": 20.184642791748047,
      "learning_rate": 7.094648035855523e-06,
      "loss": 0.3388,
      "step": 11476
    },
    {
      "epoch": 0.6808043658797011,
      "grad_norm": 21.994035720825195,
      "learning_rate": 7.093329818085949e-06,
      "loss": 0.393,
      "step": 11477
    },
    {
      "epoch": 0.6808636848973781,
      "grad_norm": 0.047096651047468185,
      "learning_rate": 7.092011600316373e-06,
      "loss": 0.0012,
      "step": 11478
    },
    {
      "epoch": 0.6809230039150551,
      "grad_norm": 0.009293636307120323,
      "learning_rate": 7.0906933825467975e-06,
      "loss": 0.0004,
      "step": 11479
    },
    {
      "epoch": 0.6809823229327322,
      "grad_norm": 0.04212385043501854,
      "learning_rate": 7.089375164777222e-06,
      "loss": 0.0006,
      "step": 11480
    },
    {
      "epoch": 0.6810416419504093,
      "grad_norm": 0.11442792415618896,
      "learning_rate": 7.088056947007647e-06,
      "loss": 0.0016,
      "step": 11481
    },
    {
      "epoch": 0.6811009609680864,
      "grad_norm": 0.30751684308052063,
      "learning_rate": 7.086738729238071e-06,
      "loss": 0.0058,
      "step": 11482
    },
    {
      "epoch": 0.6811602799857635,
      "grad_norm": 0.027607999742031097,
      "learning_rate": 7.085420511468495e-06,
      "loss": 0.0006,
      "step": 11483
    },
    {
      "epoch": 0.6812195990034405,
      "grad_norm": 0.8957789540290833,
      "learning_rate": 7.08410229369892e-06,
      "loss": 0.0188,
      "step": 11484
    },
    {
      "epoch": 0.6812789180211176,
      "grad_norm": 6.886443614959717,
      "learning_rate": 7.082784075929344e-06,
      "loss": 0.0423,
      "step": 11485
    },
    {
      "epoch": 0.6813382370387946,
      "grad_norm": 2.698082447052002,
      "learning_rate": 7.0814658581597685e-06,
      "loss": 0.0341,
      "step": 11486
    },
    {
      "epoch": 0.6813975560564717,
      "grad_norm": 0.016627667471766472,
      "learning_rate": 7.080147640390193e-06,
      "loss": 0.0005,
      "step": 11487
    },
    {
      "epoch": 0.6814568750741488,
      "grad_norm": 0.7265235781669617,
      "learning_rate": 7.078829422620618e-06,
      "loss": 0.0105,
      "step": 11488
    },
    {
      "epoch": 0.6815161940918258,
      "grad_norm": 0.4149189591407776,
      "learning_rate": 7.077511204851042e-06,
      "loss": 0.0046,
      "step": 11489
    },
    {
      "epoch": 0.6815755131095029,
      "grad_norm": 0.02918963134288788,
      "learning_rate": 7.076192987081466e-06,
      "loss": 0.0009,
      "step": 11490
    },
    {
      "epoch": 0.68163483212718,
      "grad_norm": 0.05681845545768738,
      "learning_rate": 7.074874769311891e-06,
      "loss": 0.0007,
      "step": 11491
    },
    {
      "epoch": 0.681694151144857,
      "grad_norm": 0.10313203185796738,
      "learning_rate": 7.073556551542315e-06,
      "loss": 0.0026,
      "step": 11492
    },
    {
      "epoch": 0.6817534701625341,
      "grad_norm": 0.0038431240245699883,
      "learning_rate": 7.0722383337727395e-06,
      "loss": 0.0002,
      "step": 11493
    },
    {
      "epoch": 0.6818127891802112,
      "grad_norm": 0.01527466531842947,
      "learning_rate": 7.070920116003164e-06,
      "loss": 0.0006,
      "step": 11494
    },
    {
      "epoch": 0.6818721081978882,
      "grad_norm": 0.07319734990596771,
      "learning_rate": 7.069601898233589e-06,
      "loss": 0.0008,
      "step": 11495
    },
    {
      "epoch": 0.6819314272155653,
      "grad_norm": 26.65097999572754,
      "learning_rate": 7.068283680464013e-06,
      "loss": 0.1194,
      "step": 11496
    },
    {
      "epoch": 0.6819907462332424,
      "grad_norm": 0.021819457411766052,
      "learning_rate": 7.066965462694437e-06,
      "loss": 0.0007,
      "step": 11497
    },
    {
      "epoch": 0.6820500652509195,
      "grad_norm": 2.612004041671753,
      "learning_rate": 7.065647244924862e-06,
      "loss": 0.0222,
      "step": 11498
    },
    {
      "epoch": 0.6821093842685965,
      "grad_norm": 7.708568096160889,
      "learning_rate": 7.064329027155286e-06,
      "loss": 0.3205,
      "step": 11499
    },
    {
      "epoch": 0.6821687032862735,
      "grad_norm": 0.02201688475906849,
      "learning_rate": 7.0630108093857105e-06,
      "loss": 0.0005,
      "step": 11500
    },
    {
      "epoch": 0.6822280223039506,
      "grad_norm": 0.02894522063434124,
      "learning_rate": 7.061692591616136e-06,
      "loss": 0.0006,
      "step": 11501
    },
    {
      "epoch": 0.6822873413216277,
      "grad_norm": 0.12457893043756485,
      "learning_rate": 7.060374373846561e-06,
      "loss": 0.0015,
      "step": 11502
    },
    {
      "epoch": 0.6823466603393048,
      "grad_norm": 16.700239181518555,
      "learning_rate": 7.059056156076984e-06,
      "loss": 0.5632,
      "step": 11503
    },
    {
      "epoch": 0.6824059793569819,
      "grad_norm": 0.7962572574615479,
      "learning_rate": 7.057737938307408e-06,
      "loss": 0.0135,
      "step": 11504
    },
    {
      "epoch": 0.682465298374659,
      "grad_norm": 1.0362509489059448,
      "learning_rate": 7.056419720537834e-06,
      "loss": 0.0154,
      "step": 11505
    },
    {
      "epoch": 0.6825246173923359,
      "grad_norm": 0.005356659647077322,
      "learning_rate": 7.055101502768258e-06,
      "loss": 0.0002,
      "step": 11506
    },
    {
      "epoch": 0.682583936410013,
      "grad_norm": 29.59245491027832,
      "learning_rate": 7.053783284998682e-06,
      "loss": 0.9748,
      "step": 11507
    },
    {
      "epoch": 0.6826432554276901,
      "grad_norm": 0.14719673991203308,
      "learning_rate": 7.052465067229107e-06,
      "loss": 0.0028,
      "step": 11508
    },
    {
      "epoch": 0.6827025744453672,
      "grad_norm": 10.928567886352539,
      "learning_rate": 7.051146849459532e-06,
      "loss": 0.0778,
      "step": 11509
    },
    {
      "epoch": 0.6827618934630443,
      "grad_norm": 3.0669772624969482,
      "learning_rate": 7.049828631689956e-06,
      "loss": 0.0601,
      "step": 11510
    },
    {
      "epoch": 0.6828212124807214,
      "grad_norm": 0.04878966882824898,
      "learning_rate": 7.04851041392038e-06,
      "loss": 0.0006,
      "step": 11511
    },
    {
      "epoch": 0.6828805314983983,
      "grad_norm": 0.04408923164010048,
      "learning_rate": 7.047192196150805e-06,
      "loss": 0.0007,
      "step": 11512
    },
    {
      "epoch": 0.6829398505160754,
      "grad_norm": 0.03002297319471836,
      "learning_rate": 7.045873978381229e-06,
      "loss": 0.0009,
      "step": 11513
    },
    {
      "epoch": 0.6829991695337525,
      "grad_norm": 0.9468562602996826,
      "learning_rate": 7.044555760611653e-06,
      "loss": 0.0125,
      "step": 11514
    },
    {
      "epoch": 0.6830584885514296,
      "grad_norm": 0.19561760127544403,
      "learning_rate": 7.0432375428420784e-06,
      "loss": 0.0022,
      "step": 11515
    },
    {
      "epoch": 0.6831178075691067,
      "grad_norm": 5.098012924194336,
      "learning_rate": 7.041919325072503e-06,
      "loss": 0.0796,
      "step": 11516
    },
    {
      "epoch": 0.6831771265867838,
      "grad_norm": 15.091607093811035,
      "learning_rate": 7.040601107302927e-06,
      "loss": 0.0715,
      "step": 11517
    },
    {
      "epoch": 0.6832364456044608,
      "grad_norm": 0.15766000747680664,
      "learning_rate": 7.039282889533352e-06,
      "loss": 0.0018,
      "step": 11518
    },
    {
      "epoch": 0.6832957646221378,
      "grad_norm": 8.093952178955078,
      "learning_rate": 7.037964671763776e-06,
      "loss": 0.1829,
      "step": 11519
    },
    {
      "epoch": 0.6833550836398149,
      "grad_norm": 3.4128549098968506,
      "learning_rate": 7.0366464539942e-06,
      "loss": 0.029,
      "step": 11520
    },
    {
      "epoch": 0.683414402657492,
      "grad_norm": 14.206003189086914,
      "learning_rate": 7.035328236224624e-06,
      "loss": 0.7138,
      "step": 11521
    },
    {
      "epoch": 0.6834737216751691,
      "grad_norm": 27.07984161376953,
      "learning_rate": 7.0340100184550494e-06,
      "loss": 0.6388,
      "step": 11522
    },
    {
      "epoch": 0.6835330406928461,
      "grad_norm": 0.0297444649040699,
      "learning_rate": 7.032691800685474e-06,
      "loss": 0.0007,
      "step": 11523
    },
    {
      "epoch": 0.6835923597105232,
      "grad_norm": 0.10465133935213089,
      "learning_rate": 7.031373582915898e-06,
      "loss": 0.0012,
      "step": 11524
    },
    {
      "epoch": 0.6836516787282002,
      "grad_norm": 0.5266443490982056,
      "learning_rate": 7.030055365146323e-06,
      "loss": 0.0025,
      "step": 11525
    },
    {
      "epoch": 0.6837109977458773,
      "grad_norm": 0.007596966810524464,
      "learning_rate": 7.028737147376747e-06,
      "loss": 0.0002,
      "step": 11526
    },
    {
      "epoch": 0.6837703167635544,
      "grad_norm": 10.67187213897705,
      "learning_rate": 7.027418929607171e-06,
      "loss": 0.377,
      "step": 11527
    },
    {
      "epoch": 0.6838296357812315,
      "grad_norm": 8.700003623962402,
      "learning_rate": 7.026100711837595e-06,
      "loss": 0.4917,
      "step": 11528
    },
    {
      "epoch": 0.6838889547989085,
      "grad_norm": 3.0976500511169434,
      "learning_rate": 7.024782494068021e-06,
      "loss": 0.2375,
      "step": 11529
    },
    {
      "epoch": 0.6839482738165856,
      "grad_norm": 0.06705057621002197,
      "learning_rate": 7.0234642762984455e-06,
      "loss": 0.0023,
      "step": 11530
    },
    {
      "epoch": 0.6840075928342627,
      "grad_norm": 0.25467532873153687,
      "learning_rate": 7.022146058528869e-06,
      "loss": 0.0025,
      "step": 11531
    },
    {
      "epoch": 0.6840669118519397,
      "grad_norm": 0.06846960633993149,
      "learning_rate": 7.020827840759295e-06,
      "loss": 0.0011,
      "step": 11532
    },
    {
      "epoch": 0.6841262308696168,
      "grad_norm": 0.04720370098948479,
      "learning_rate": 7.019509622989719e-06,
      "loss": 0.0011,
      "step": 11533
    },
    {
      "epoch": 0.6841855498872939,
      "grad_norm": 0.3016311228275299,
      "learning_rate": 7.018191405220143e-06,
      "loss": 0.0039,
      "step": 11534
    },
    {
      "epoch": 0.6842448689049709,
      "grad_norm": 0.029142428189516068,
      "learning_rate": 7.016873187450567e-06,
      "loss": 0.0005,
      "step": 11535
    },
    {
      "epoch": 0.684304187922648,
      "grad_norm": 0.24333778023719788,
      "learning_rate": 7.015554969680992e-06,
      "loss": 0.0037,
      "step": 11536
    },
    {
      "epoch": 0.6843635069403251,
      "grad_norm": 0.36779558658599854,
      "learning_rate": 7.0142367519114165e-06,
      "loss": 0.0039,
      "step": 11537
    },
    {
      "epoch": 0.6844228259580022,
      "grad_norm": 22.461345672607422,
      "learning_rate": 7.012918534141841e-06,
      "loss": 0.4741,
      "step": 11538
    },
    {
      "epoch": 0.6844821449756792,
      "grad_norm": 2.504812002182007,
      "learning_rate": 7.011600316372266e-06,
      "loss": 0.0315,
      "step": 11539
    },
    {
      "epoch": 0.6845414639933562,
      "grad_norm": 0.05510774999856949,
      "learning_rate": 7.01028209860269e-06,
      "loss": 0.0009,
      "step": 11540
    },
    {
      "epoch": 0.6846007830110333,
      "grad_norm": 1.6391966342926025,
      "learning_rate": 7.008963880833114e-06,
      "loss": 0.0225,
      "step": 11541
    },
    {
      "epoch": 0.6846601020287104,
      "grad_norm": 0.13536310195922852,
      "learning_rate": 7.007645663063539e-06,
      "loss": 0.0012,
      "step": 11542
    },
    {
      "epoch": 0.6847194210463875,
      "grad_norm": 0.4324520528316498,
      "learning_rate": 7.006327445293963e-06,
      "loss": 0.0045,
      "step": 11543
    },
    {
      "epoch": 0.6847787400640646,
      "grad_norm": 7.890812397003174,
      "learning_rate": 7.0050092275243875e-06,
      "loss": 0.2048,
      "step": 11544
    },
    {
      "epoch": 0.6848380590817416,
      "grad_norm": 28.173688888549805,
      "learning_rate": 7.003691009754812e-06,
      "loss": 0.4704,
      "step": 11545
    },
    {
      "epoch": 0.6848973780994186,
      "grad_norm": 5.701803684234619,
      "learning_rate": 7.002372791985237e-06,
      "loss": 0.1299,
      "step": 11546
    },
    {
      "epoch": 0.6849566971170957,
      "grad_norm": 2.418032169342041,
      "learning_rate": 7.001054574215661e-06,
      "loss": 0.0229,
      "step": 11547
    },
    {
      "epoch": 0.6850160161347728,
      "grad_norm": 0.0650264099240303,
      "learning_rate": 6.999736356446085e-06,
      "loss": 0.001,
      "step": 11548
    },
    {
      "epoch": 0.6850753351524499,
      "grad_norm": 0.13625438511371613,
      "learning_rate": 6.99841813867651e-06,
      "loss": 0.001,
      "step": 11549
    },
    {
      "epoch": 0.685134654170127,
      "grad_norm": 8.46528434753418,
      "learning_rate": 6.997099920906934e-06,
      "loss": 0.3875,
      "step": 11550
    },
    {
      "epoch": 0.6851939731878041,
      "grad_norm": 12.635527610778809,
      "learning_rate": 6.9957817031373585e-06,
      "loss": 0.2123,
      "step": 11551
    },
    {
      "epoch": 0.685253292205481,
      "grad_norm": 11.332808494567871,
      "learning_rate": 6.994463485367783e-06,
      "loss": 0.2777,
      "step": 11552
    },
    {
      "epoch": 0.6853126112231581,
      "grad_norm": 0.11475163698196411,
      "learning_rate": 6.993145267598208e-06,
      "loss": 0.0012,
      "step": 11553
    },
    {
      "epoch": 0.6853719302408352,
      "grad_norm": 3.519671678543091,
      "learning_rate": 6.991827049828632e-06,
      "loss": 0.1182,
      "step": 11554
    },
    {
      "epoch": 0.6854312492585123,
      "grad_norm": 1.353188157081604,
      "learning_rate": 6.990508832059056e-06,
      "loss": 0.0272,
      "step": 11555
    },
    {
      "epoch": 0.6854905682761894,
      "grad_norm": 14.803345680236816,
      "learning_rate": 6.989190614289482e-06,
      "loss": 0.2569,
      "step": 11556
    },
    {
      "epoch": 0.6855498872938665,
      "grad_norm": 0.023316750302910805,
      "learning_rate": 6.987872396519906e-06,
      "loss": 0.0003,
      "step": 11557
    },
    {
      "epoch": 0.6856092063115434,
      "grad_norm": 0.05453142896294594,
      "learning_rate": 6.98655417875033e-06,
      "loss": 0.0011,
      "step": 11558
    },
    {
      "epoch": 0.6856685253292205,
      "grad_norm": 6.708571434020996,
      "learning_rate": 6.985235960980754e-06,
      "loss": 0.3128,
      "step": 11559
    },
    {
      "epoch": 0.6857278443468976,
      "grad_norm": 8.7506742477417,
      "learning_rate": 6.9839177432111796e-06,
      "loss": 0.2125,
      "step": 11560
    },
    {
      "epoch": 0.6857871633645747,
      "grad_norm": 0.006382324732840061,
      "learning_rate": 6.982599525441604e-06,
      "loss": 0.0002,
      "step": 11561
    },
    {
      "epoch": 0.6858464823822518,
      "grad_norm": 3.0527758598327637,
      "learning_rate": 6.981281307672028e-06,
      "loss": 0.0292,
      "step": 11562
    },
    {
      "epoch": 0.6859058013999288,
      "grad_norm": 0.010289770551025867,
      "learning_rate": 6.979963089902453e-06,
      "loss": 0.0003,
      "step": 11563
    },
    {
      "epoch": 0.6859651204176059,
      "grad_norm": 0.007383563555777073,
      "learning_rate": 6.978644872132877e-06,
      "loss": 0.0002,
      "step": 11564
    },
    {
      "epoch": 0.6860244394352829,
      "grad_norm": 2.7730185985565186,
      "learning_rate": 6.977326654363301e-06,
      "loss": 0.0417,
      "step": 11565
    },
    {
      "epoch": 0.68608375845296,
      "grad_norm": 0.1302989423274994,
      "learning_rate": 6.976008436593726e-06,
      "loss": 0.002,
      "step": 11566
    },
    {
      "epoch": 0.6861430774706371,
      "grad_norm": 0.008138629607856274,
      "learning_rate": 6.9746902188241506e-06,
      "loss": 0.0003,
      "step": 11567
    },
    {
      "epoch": 0.6862023964883142,
      "grad_norm": 27.605358123779297,
      "learning_rate": 6.973372001054575e-06,
      "loss": 0.3853,
      "step": 11568
    },
    {
      "epoch": 0.6862617155059912,
      "grad_norm": 3.30570650100708,
      "learning_rate": 6.972053783284999e-06,
      "loss": 0.4351,
      "step": 11569
    },
    {
      "epoch": 0.6863210345236683,
      "grad_norm": 46.04297637939453,
      "learning_rate": 6.970735565515424e-06,
      "loss": 1.8726,
      "step": 11570
    },
    {
      "epoch": 0.6863803535413453,
      "grad_norm": 0.17622268199920654,
      "learning_rate": 6.969417347745848e-06,
      "loss": 0.0043,
      "step": 11571
    },
    {
      "epoch": 0.6864396725590224,
      "grad_norm": 0.39295729994773865,
      "learning_rate": 6.968099129976272e-06,
      "loss": 0.0022,
      "step": 11572
    },
    {
      "epoch": 0.6864989915766995,
      "grad_norm": 0.010275861248373985,
      "learning_rate": 6.966780912206697e-06,
      "loss": 0.0004,
      "step": 11573
    },
    {
      "epoch": 0.6865583105943766,
      "grad_norm": 0.046804606914520264,
      "learning_rate": 6.9654626944371216e-06,
      "loss": 0.0006,
      "step": 11574
    },
    {
      "epoch": 0.6866176296120536,
      "grad_norm": 13.5359525680542,
      "learning_rate": 6.964144476667546e-06,
      "loss": 0.8518,
      "step": 11575
    },
    {
      "epoch": 0.6866769486297307,
      "grad_norm": 10.205944061279297,
      "learning_rate": 6.96282625889797e-06,
      "loss": 0.1373,
      "step": 11576
    },
    {
      "epoch": 0.6867362676474078,
      "grad_norm": 6.513397693634033,
      "learning_rate": 6.961508041128395e-06,
      "loss": 0.0676,
      "step": 11577
    },
    {
      "epoch": 0.6867955866650848,
      "grad_norm": 0.1131080836057663,
      "learning_rate": 6.960189823358819e-06,
      "loss": 0.0011,
      "step": 11578
    },
    {
      "epoch": 0.6868549056827619,
      "grad_norm": 0.5734642744064331,
      "learning_rate": 6.958871605589243e-06,
      "loss": 0.0089,
      "step": 11579
    },
    {
      "epoch": 0.686914224700439,
      "grad_norm": 0.10991790890693665,
      "learning_rate": 6.957553387819669e-06,
      "loss": 0.0017,
      "step": 11580
    },
    {
      "epoch": 0.686973543718116,
      "grad_norm": 10.471211433410645,
      "learning_rate": 6.9562351700500926e-06,
      "loss": 0.7171,
      "step": 11581
    },
    {
      "epoch": 0.6870328627357931,
      "grad_norm": 5.195116996765137,
      "learning_rate": 6.954916952280517e-06,
      "loss": 0.0963,
      "step": 11582
    },
    {
      "epoch": 0.6870921817534702,
      "grad_norm": 6.000093936920166,
      "learning_rate": 6.953598734510941e-06,
      "loss": 0.0581,
      "step": 11583
    },
    {
      "epoch": 0.6871515007711473,
      "grad_norm": 5.17953634262085,
      "learning_rate": 6.952280516741367e-06,
      "loss": 0.2543,
      "step": 11584
    },
    {
      "epoch": 0.6872108197888243,
      "grad_norm": 0.016951024532318115,
      "learning_rate": 6.950962298971791e-06,
      "loss": 0.0004,
      "step": 11585
    },
    {
      "epoch": 0.6872701388065013,
      "grad_norm": 7.180959701538086,
      "learning_rate": 6.949644081202215e-06,
      "loss": 0.0266,
      "step": 11586
    },
    {
      "epoch": 0.6873294578241784,
      "grad_norm": 0.9751049876213074,
      "learning_rate": 6.94832586343264e-06,
      "loss": 0.0075,
      "step": 11587
    },
    {
      "epoch": 0.6873887768418555,
      "grad_norm": 11.461490631103516,
      "learning_rate": 6.947007645663064e-06,
      "loss": 0.2135,
      "step": 11588
    },
    {
      "epoch": 0.6874480958595326,
      "grad_norm": 41.15055847167969,
      "learning_rate": 6.945689427893489e-06,
      "loss": 0.1082,
      "step": 11589
    },
    {
      "epoch": 0.6875074148772097,
      "grad_norm": 0.09045547246932983,
      "learning_rate": 6.944371210123914e-06,
      "loss": 0.0023,
      "step": 11590
    },
    {
      "epoch": 0.6875667338948867,
      "grad_norm": 12.887499809265137,
      "learning_rate": 6.943052992354338e-06,
      "loss": 0.7193,
      "step": 11591
    },
    {
      "epoch": 0.6876260529125637,
      "grad_norm": 0.1360492706298828,
      "learning_rate": 6.941734774584762e-06,
      "loss": 0.002,
      "step": 11592
    },
    {
      "epoch": 0.6876853719302408,
      "grad_norm": 0.35307592153549194,
      "learning_rate": 6.940416556815186e-06,
      "loss": 0.002,
      "step": 11593
    },
    {
      "epoch": 0.6877446909479179,
      "grad_norm": 0.010822072625160217,
      "learning_rate": 6.939098339045611e-06,
      "loss": 0.0002,
      "step": 11594
    },
    {
      "epoch": 0.687804009965595,
      "grad_norm": 13.527477264404297,
      "learning_rate": 6.937780121276035e-06,
      "loss": 0.282,
      "step": 11595
    },
    {
      "epoch": 0.6878633289832721,
      "grad_norm": 1.1853711605072021,
      "learning_rate": 6.93646190350646e-06,
      "loss": 0.0027,
      "step": 11596
    },
    {
      "epoch": 0.6879226480009492,
      "grad_norm": 0.28423449397087097,
      "learning_rate": 6.935143685736885e-06,
      "loss": 0.0039,
      "step": 11597
    },
    {
      "epoch": 0.6879819670186261,
      "grad_norm": 0.010445850901305676,
      "learning_rate": 6.933825467967309e-06,
      "loss": 0.0004,
      "step": 11598
    },
    {
      "epoch": 0.6880412860363032,
      "grad_norm": 2.617572546005249,
      "learning_rate": 6.932507250197733e-06,
      "loss": 0.0168,
      "step": 11599
    },
    {
      "epoch": 0.6881006050539803,
      "grad_norm": 5.978275299072266,
      "learning_rate": 6.931189032428157e-06,
      "loss": 0.0917,
      "step": 11600
    },
    {
      "epoch": 0.6881599240716574,
      "grad_norm": 16.426557540893555,
      "learning_rate": 6.929870814658582e-06,
      "loss": 0.2644,
      "step": 11601
    },
    {
      "epoch": 0.6882192430893345,
      "grad_norm": 7.133918762207031,
      "learning_rate": 6.928552596889006e-06,
      "loss": 0.267,
      "step": 11602
    },
    {
      "epoch": 0.6882785621070115,
      "grad_norm": 0.07282625138759613,
      "learning_rate": 6.927234379119431e-06,
      "loss": 0.0013,
      "step": 11603
    },
    {
      "epoch": 0.6883378811246885,
      "grad_norm": 0.08842957764863968,
      "learning_rate": 6.925916161349856e-06,
      "loss": 0.0021,
      "step": 11604
    },
    {
      "epoch": 0.6883972001423656,
      "grad_norm": 47.56643295288086,
      "learning_rate": 6.92459794358028e-06,
      "loss": 3.5534,
      "step": 11605
    },
    {
      "epoch": 0.6884565191600427,
      "grad_norm": 13.863777160644531,
      "learning_rate": 6.923279725810704e-06,
      "loss": 0.7243,
      "step": 11606
    },
    {
      "epoch": 0.6885158381777198,
      "grad_norm": 0.10625225305557251,
      "learning_rate": 6.921961508041128e-06,
      "loss": 0.0026,
      "step": 11607
    },
    {
      "epoch": 0.6885751571953969,
      "grad_norm": 11.061078071594238,
      "learning_rate": 6.920643290271554e-06,
      "loss": 0.3603,
      "step": 11608
    },
    {
      "epoch": 0.6886344762130739,
      "grad_norm": 1.2792904376983643,
      "learning_rate": 6.9193250725019774e-06,
      "loss": 0.0055,
      "step": 11609
    },
    {
      "epoch": 0.688693795230751,
      "grad_norm": 0.772707998752594,
      "learning_rate": 6.918006854732402e-06,
      "loss": 0.0094,
      "step": 11610
    },
    {
      "epoch": 0.688753114248428,
      "grad_norm": 7.330389499664307,
      "learning_rate": 6.9166886369628275e-06,
      "loss": 0.0944,
      "step": 11611
    },
    {
      "epoch": 0.6888124332661051,
      "grad_norm": 7.6362762451171875,
      "learning_rate": 6.915370419193252e-06,
      "loss": 0.1869,
      "step": 11612
    },
    {
      "epoch": 0.6888717522837822,
      "grad_norm": 0.03960496932268143,
      "learning_rate": 6.914052201423676e-06,
      "loss": 0.0007,
      "step": 11613
    },
    {
      "epoch": 0.6889310713014593,
      "grad_norm": 0.04476180672645569,
      "learning_rate": 6.912733983654101e-06,
      "loss": 0.0014,
      "step": 11614
    },
    {
      "epoch": 0.6889903903191363,
      "grad_norm": 18.168842315673828,
      "learning_rate": 6.911415765884525e-06,
      "loss": 0.1071,
      "step": 11615
    },
    {
      "epoch": 0.6890497093368134,
      "grad_norm": 6.137195110321045,
      "learning_rate": 6.910097548114949e-06,
      "loss": 0.1983,
      "step": 11616
    },
    {
      "epoch": 0.6891090283544905,
      "grad_norm": 35.204444885253906,
      "learning_rate": 6.9087793303453735e-06,
      "loss": 0.1325,
      "step": 11617
    },
    {
      "epoch": 0.6891683473721675,
      "grad_norm": 1.0284823179244995,
      "learning_rate": 6.9074611125757985e-06,
      "loss": 0.0189,
      "step": 11618
    },
    {
      "epoch": 0.6892276663898446,
      "grad_norm": 0.020033296197652817,
      "learning_rate": 6.906142894806223e-06,
      "loss": 0.0006,
      "step": 11619
    },
    {
      "epoch": 0.6892869854075216,
      "grad_norm": 20.861915588378906,
      "learning_rate": 6.904824677036647e-06,
      "loss": 0.1777,
      "step": 11620
    },
    {
      "epoch": 0.6893463044251987,
      "grad_norm": 0.2952407896518707,
      "learning_rate": 6.903506459267072e-06,
      "loss": 0.0043,
      "step": 11621
    },
    {
      "epoch": 0.6894056234428758,
      "grad_norm": 3.1105895042419434,
      "learning_rate": 6.902188241497496e-06,
      "loss": 0.0527,
      "step": 11622
    },
    {
      "epoch": 0.6894649424605529,
      "grad_norm": 0.1226530522108078,
      "learning_rate": 6.90087002372792e-06,
      "loss": 0.002,
      "step": 11623
    },
    {
      "epoch": 0.6895242614782299,
      "grad_norm": 0.011166051030158997,
      "learning_rate": 6.8995518059583445e-06,
      "loss": 0.0005,
      "step": 11624
    },
    {
      "epoch": 0.689583580495907,
      "grad_norm": 0.04936793074011803,
      "learning_rate": 6.8982335881887695e-06,
      "loss": 0.0009,
      "step": 11625
    },
    {
      "epoch": 0.689642899513584,
      "grad_norm": 27.893205642700195,
      "learning_rate": 6.896915370419194e-06,
      "loss": 0.0502,
      "step": 11626
    },
    {
      "epoch": 0.6897022185312611,
      "grad_norm": 2.3294694423675537,
      "learning_rate": 6.895597152649618e-06,
      "loss": 0.0174,
      "step": 11627
    },
    {
      "epoch": 0.6897615375489382,
      "grad_norm": 6.4379730224609375,
      "learning_rate": 6.894278934880043e-06,
      "loss": 0.0949,
      "step": 11628
    },
    {
      "epoch": 0.6898208565666153,
      "grad_norm": 10.07206916809082,
      "learning_rate": 6.892960717110467e-06,
      "loss": 0.1125,
      "step": 11629
    },
    {
      "epoch": 0.6898801755842924,
      "grad_norm": 12.196693420410156,
      "learning_rate": 6.891642499340891e-06,
      "loss": 0.1919,
      "step": 11630
    },
    {
      "epoch": 0.6899394946019693,
      "grad_norm": 27.74933433532715,
      "learning_rate": 6.8903242815713155e-06,
      "loss": 0.1519,
      "step": 11631
    },
    {
      "epoch": 0.6899988136196464,
      "grad_norm": 45.60205841064453,
      "learning_rate": 6.8890060638017405e-06,
      "loss": 0.919,
      "step": 11632
    },
    {
      "epoch": 0.6900581326373235,
      "grad_norm": 5.624457836151123,
      "learning_rate": 6.887687846032165e-06,
      "loss": 0.0676,
      "step": 11633
    },
    {
      "epoch": 0.6901174516550006,
      "grad_norm": 6.848677158355713,
      "learning_rate": 6.886369628262589e-06,
      "loss": 0.034,
      "step": 11634
    },
    {
      "epoch": 0.6901767706726777,
      "grad_norm": 12.3192777633667,
      "learning_rate": 6.885051410493015e-06,
      "loss": 0.0369,
      "step": 11635
    },
    {
      "epoch": 0.6902360896903548,
      "grad_norm": 1.9835472106933594,
      "learning_rate": 6.883733192723439e-06,
      "loss": 0.014,
      "step": 11636
    },
    {
      "epoch": 0.6902954087080317,
      "grad_norm": 0.05788026750087738,
      "learning_rate": 6.882414974953862e-06,
      "loss": 0.0013,
      "step": 11637
    },
    {
      "epoch": 0.6903547277257088,
      "grad_norm": 2.2145872116088867,
      "learning_rate": 6.881096757184288e-06,
      "loss": 0.0121,
      "step": 11638
    },
    {
      "epoch": 0.6904140467433859,
      "grad_norm": 12.808403968811035,
      "learning_rate": 6.879778539414712e-06,
      "loss": 0.2398,
      "step": 11639
    },
    {
      "epoch": 0.690473365761063,
      "grad_norm": 2.1171200275421143,
      "learning_rate": 6.8784603216451365e-06,
      "loss": 0.0102,
      "step": 11640
    },
    {
      "epoch": 0.6905326847787401,
      "grad_norm": 5.395117282867432,
      "learning_rate": 6.877142103875561e-06,
      "loss": 0.0761,
      "step": 11641
    },
    {
      "epoch": 0.6905920037964172,
      "grad_norm": 0.19248157739639282,
      "learning_rate": 6.875823886105986e-06,
      "loss": 0.003,
      "step": 11642
    },
    {
      "epoch": 0.6906513228140942,
      "grad_norm": 0.014275532215833664,
      "learning_rate": 6.87450566833641e-06,
      "loss": 0.0004,
      "step": 11643
    },
    {
      "epoch": 0.6907106418317712,
      "grad_norm": 0.05080776661634445,
      "learning_rate": 6.873187450566834e-06,
      "loss": 0.001,
      "step": 11644
    },
    {
      "epoch": 0.6907699608494483,
      "grad_norm": 0.07803969830274582,
      "learning_rate": 6.871869232797259e-06,
      "loss": 0.0017,
      "step": 11645
    },
    {
      "epoch": 0.6908292798671254,
      "grad_norm": 0.07312402129173279,
      "learning_rate": 6.870551015027683e-06,
      "loss": 0.0019,
      "step": 11646
    },
    {
      "epoch": 0.6908885988848025,
      "grad_norm": 2.373042583465576,
      "learning_rate": 6.8692327972581075e-06,
      "loss": 0.0118,
      "step": 11647
    },
    {
      "epoch": 0.6909479179024796,
      "grad_norm": 13.370705604553223,
      "learning_rate": 6.867914579488532e-06,
      "loss": 0.143,
      "step": 11648
    },
    {
      "epoch": 0.6910072369201566,
      "grad_norm": 0.016564900055527687,
      "learning_rate": 6.866596361718957e-06,
      "loss": 0.0005,
      "step": 11649
    },
    {
      "epoch": 0.6910665559378336,
      "grad_norm": 25.054885864257812,
      "learning_rate": 6.865278143949381e-06,
      "loss": 0.0595,
      "step": 11650
    },
    {
      "epoch": 0.6911258749555107,
      "grad_norm": 1.9914462566375732,
      "learning_rate": 6.863959926179805e-06,
      "loss": 0.0739,
      "step": 11651
    },
    {
      "epoch": 0.6911851939731878,
      "grad_norm": 0.05923241004347801,
      "learning_rate": 6.86264170841023e-06,
      "loss": 0.0014,
      "step": 11652
    },
    {
      "epoch": 0.6912445129908649,
      "grad_norm": 32.8140983581543,
      "learning_rate": 6.861323490640654e-06,
      "loss": 0.1767,
      "step": 11653
    },
    {
      "epoch": 0.691303832008542,
      "grad_norm": 0.023048629984259605,
      "learning_rate": 6.8600052728710785e-06,
      "loss": 0.0004,
      "step": 11654
    },
    {
      "epoch": 0.691363151026219,
      "grad_norm": 5.0294508934021,
      "learning_rate": 6.858687055101503e-06,
      "loss": 0.0489,
      "step": 11655
    },
    {
      "epoch": 0.6914224700438961,
      "grad_norm": 16.854642868041992,
      "learning_rate": 6.857368837331928e-06,
      "loss": 1.1404,
      "step": 11656
    },
    {
      "epoch": 0.6914817890615731,
      "grad_norm": 1.6302307844161987,
      "learning_rate": 6.856050619562352e-06,
      "loss": 0.0275,
      "step": 11657
    },
    {
      "epoch": 0.6915411080792502,
      "grad_norm": 0.0845443606376648,
      "learning_rate": 6.854732401792776e-06,
      "loss": 0.0017,
      "step": 11658
    },
    {
      "epoch": 0.6916004270969273,
      "grad_norm": 16.6015567779541,
      "learning_rate": 6.853414184023201e-06,
      "loss": 0.1543,
      "step": 11659
    },
    {
      "epoch": 0.6916597461146043,
      "grad_norm": 13.253046989440918,
      "learning_rate": 6.852095966253625e-06,
      "loss": 0.204,
      "step": 11660
    },
    {
      "epoch": 0.6917190651322814,
      "grad_norm": 0.038296058773994446,
      "learning_rate": 6.8507777484840496e-06,
      "loss": 0.0009,
      "step": 11661
    },
    {
      "epoch": 0.6917783841499585,
      "grad_norm": 0.04425647109746933,
      "learning_rate": 6.8494595307144754e-06,
      "loss": 0.001,
      "step": 11662
    },
    {
      "epoch": 0.6918377031676356,
      "grad_norm": 25.680068969726562,
      "learning_rate": 6.8481413129449e-06,
      "loss": 0.4145,
      "step": 11663
    },
    {
      "epoch": 0.6918970221853126,
      "grad_norm": 10.821192741394043,
      "learning_rate": 6.846823095175324e-06,
      "loss": 0.3053,
      "step": 11664
    },
    {
      "epoch": 0.6919563412029897,
      "grad_norm": 0.05195797234773636,
      "learning_rate": 6.845504877405747e-06,
      "loss": 0.0008,
      "step": 11665
    },
    {
      "epoch": 0.6920156602206667,
      "grad_norm": 13.68087100982666,
      "learning_rate": 6.844186659636173e-06,
      "loss": 0.4447,
      "step": 11666
    },
    {
      "epoch": 0.6920749792383438,
      "grad_norm": 0.022702068090438843,
      "learning_rate": 6.842868441866597e-06,
      "loss": 0.0006,
      "step": 11667
    },
    {
      "epoch": 0.6921342982560209,
      "grad_norm": 0.023664269596338272,
      "learning_rate": 6.841550224097021e-06,
      "loss": 0.0007,
      "step": 11668
    },
    {
      "epoch": 0.692193617273698,
      "grad_norm": 7.457452297210693,
      "learning_rate": 6.8402320063274464e-06,
      "loss": 0.6406,
      "step": 11669
    },
    {
      "epoch": 0.692252936291375,
      "grad_norm": 0.009447431191802025,
      "learning_rate": 6.838913788557871e-06,
      "loss": 0.0003,
      "step": 11670
    },
    {
      "epoch": 0.692312255309052,
      "grad_norm": 6.609504699707031,
      "learning_rate": 6.837595570788295e-06,
      "loss": 0.1044,
      "step": 11671
    },
    {
      "epoch": 0.6923715743267291,
      "grad_norm": 3.172565460205078,
      "learning_rate": 6.836277353018719e-06,
      "loss": 0.0402,
      "step": 11672
    },
    {
      "epoch": 0.6924308933444062,
      "grad_norm": 0.017789989709854126,
      "learning_rate": 6.834959135249144e-06,
      "loss": 0.0005,
      "step": 11673
    },
    {
      "epoch": 0.6924902123620833,
      "grad_norm": 19.419456481933594,
      "learning_rate": 6.833640917479568e-06,
      "loss": 0.5117,
      "step": 11674
    },
    {
      "epoch": 0.6925495313797604,
      "grad_norm": 0.736197292804718,
      "learning_rate": 6.832322699709992e-06,
      "loss": 0.0091,
      "step": 11675
    },
    {
      "epoch": 0.6926088503974375,
      "grad_norm": 0.03661855682730675,
      "learning_rate": 6.8310044819404174e-06,
      "loss": 0.0009,
      "step": 11676
    },
    {
      "epoch": 0.6926681694151144,
      "grad_norm": 0.023315224796533585,
      "learning_rate": 6.829686264170842e-06,
      "loss": 0.0006,
      "step": 11677
    },
    {
      "epoch": 0.6927274884327915,
      "grad_norm": 0.13222645223140717,
      "learning_rate": 6.828368046401266e-06,
      "loss": 0.0018,
      "step": 11678
    },
    {
      "epoch": 0.6927868074504686,
      "grad_norm": 1.13882577419281,
      "learning_rate": 6.82704982863169e-06,
      "loss": 0.0121,
      "step": 11679
    },
    {
      "epoch": 0.6928461264681457,
      "grad_norm": 6.757358551025391,
      "learning_rate": 6.825731610862115e-06,
      "loss": 0.4045,
      "step": 11680
    },
    {
      "epoch": 0.6929054454858228,
      "grad_norm": 0.014471931383013725,
      "learning_rate": 6.824413393092539e-06,
      "loss": 0.0004,
      "step": 11681
    },
    {
      "epoch": 0.6929647645034999,
      "grad_norm": 0.08096723258495331,
      "learning_rate": 6.823095175322963e-06,
      "loss": 0.0017,
      "step": 11682
    },
    {
      "epoch": 0.6930240835211768,
      "grad_norm": 0.8885176181793213,
      "learning_rate": 6.8217769575533884e-06,
      "loss": 0.0112,
      "step": 11683
    },
    {
      "epoch": 0.6930834025388539,
      "grad_norm": 0.2427193522453308,
      "learning_rate": 6.820458739783813e-06,
      "loss": 0.003,
      "step": 11684
    },
    {
      "epoch": 0.693142721556531,
      "grad_norm": 7.072739124298096,
      "learning_rate": 6.819140522014237e-06,
      "loss": 0.0393,
      "step": 11685
    },
    {
      "epoch": 0.6932020405742081,
      "grad_norm": 1.0574778318405151,
      "learning_rate": 6.817822304244663e-06,
      "loss": 0.0117,
      "step": 11686
    },
    {
      "epoch": 0.6932613595918852,
      "grad_norm": 10.004973411560059,
      "learning_rate": 6.816504086475086e-06,
      "loss": 0.3008,
      "step": 11687
    },
    {
      "epoch": 0.6933206786095623,
      "grad_norm": 0.4000207781791687,
      "learning_rate": 6.81518586870551e-06,
      "loss": 0.0019,
      "step": 11688
    },
    {
      "epoch": 0.6933799976272393,
      "grad_norm": 16.305335998535156,
      "learning_rate": 6.813867650935934e-06,
      "loss": 0.4918,
      "step": 11689
    },
    {
      "epoch": 0.6934393166449163,
      "grad_norm": 26.824527740478516,
      "learning_rate": 6.81254943316636e-06,
      "loss": 0.2876,
      "step": 11690
    },
    {
      "epoch": 0.6934986356625934,
      "grad_norm": 4.521078586578369,
      "learning_rate": 6.8112312153967845e-06,
      "loss": 0.0103,
      "step": 11691
    },
    {
      "epoch": 0.6935579546802705,
      "grad_norm": 0.03834297135472298,
      "learning_rate": 6.809912997627209e-06,
      "loss": 0.0007,
      "step": 11692
    },
    {
      "epoch": 0.6936172736979476,
      "grad_norm": 0.6072801351547241,
      "learning_rate": 6.808594779857634e-06,
      "loss": 0.0021,
      "step": 11693
    },
    {
      "epoch": 0.6936765927156247,
      "grad_norm": 11.171113014221191,
      "learning_rate": 6.807276562088058e-06,
      "loss": 0.9649,
      "step": 11694
    },
    {
      "epoch": 0.6937359117333017,
      "grad_norm": 0.013429805636405945,
      "learning_rate": 6.805958344318482e-06,
      "loss": 0.0004,
      "step": 11695
    },
    {
      "epoch": 0.6937952307509787,
      "grad_norm": 19.08323097229004,
      "learning_rate": 6.804640126548906e-06,
      "loss": 0.6318,
      "step": 11696
    },
    {
      "epoch": 0.6938545497686558,
      "grad_norm": 0.12076213955879211,
      "learning_rate": 6.803321908779331e-06,
      "loss": 0.0027,
      "step": 11697
    },
    {
      "epoch": 0.6939138687863329,
      "grad_norm": 0.10151813179254532,
      "learning_rate": 6.8020036910097555e-06,
      "loss": 0.0021,
      "step": 11698
    },
    {
      "epoch": 0.69397318780401,
      "grad_norm": 26.324140548706055,
      "learning_rate": 6.80068547324018e-06,
      "loss": 0.4639,
      "step": 11699
    },
    {
      "epoch": 0.694032506821687,
      "grad_norm": 0.5393229126930237,
      "learning_rate": 6.799367255470605e-06,
      "loss": 0.0037,
      "step": 11700
    },
    {
      "epoch": 0.6940918258393641,
      "grad_norm": 14.77892780303955,
      "learning_rate": 6.798049037701029e-06,
      "loss": 0.2096,
      "step": 11701
    },
    {
      "epoch": 0.6941511448570412,
      "grad_norm": 4.78959321975708,
      "learning_rate": 6.796730819931453e-06,
      "loss": 0.1432,
      "step": 11702
    },
    {
      "epoch": 0.6942104638747182,
      "grad_norm": 0.2607590854167938,
      "learning_rate": 6.795412602161877e-06,
      "loss": 0.0041,
      "step": 11703
    },
    {
      "epoch": 0.6942697828923953,
      "grad_norm": 0.09585367143154144,
      "learning_rate": 6.794094384392302e-06,
      "loss": 0.002,
      "step": 11704
    },
    {
      "epoch": 0.6943291019100724,
      "grad_norm": 0.24601423740386963,
      "learning_rate": 6.7927761666227265e-06,
      "loss": 0.0044,
      "step": 11705
    },
    {
      "epoch": 0.6943884209277494,
      "grad_norm": 0.4456896483898163,
      "learning_rate": 6.791457948853151e-06,
      "loss": 0.0035,
      "step": 11706
    },
    {
      "epoch": 0.6944477399454265,
      "grad_norm": 6.410813808441162,
      "learning_rate": 6.790139731083576e-06,
      "loss": 0.032,
      "step": 11707
    },
    {
      "epoch": 0.6945070589631036,
      "grad_norm": 5.940560340881348,
      "learning_rate": 6.788821513314e-06,
      "loss": 0.0873,
      "step": 11708
    },
    {
      "epoch": 0.6945663779807807,
      "grad_norm": 5.651397228240967,
      "learning_rate": 6.787503295544424e-06,
      "loss": 0.2439,
      "step": 11709
    },
    {
      "epoch": 0.6946256969984577,
      "grad_norm": 9.153524398803711,
      "learning_rate": 6.786185077774849e-06,
      "loss": 0.0495,
      "step": 11710
    },
    {
      "epoch": 0.6946850160161347,
      "grad_norm": 5.510184288024902,
      "learning_rate": 6.784866860005273e-06,
      "loss": 0.0305,
      "step": 11711
    },
    {
      "epoch": 0.6947443350338118,
      "grad_norm": 0.09616363048553467,
      "learning_rate": 6.7835486422356975e-06,
      "loss": 0.0013,
      "step": 11712
    },
    {
      "epoch": 0.6948036540514889,
      "grad_norm": 0.24991632997989655,
      "learning_rate": 6.782230424466122e-06,
      "loss": 0.0061,
      "step": 11713
    },
    {
      "epoch": 0.694862973069166,
      "grad_norm": 0.045130446553230286,
      "learning_rate": 6.7809122066965476e-06,
      "loss": 0.0009,
      "step": 11714
    },
    {
      "epoch": 0.6949222920868431,
      "grad_norm": 1.8041274547576904,
      "learning_rate": 6.779593988926971e-06,
      "loss": 0.0222,
      "step": 11715
    },
    {
      "epoch": 0.6949816111045201,
      "grad_norm": 0.011316376738250256,
      "learning_rate": 6.778275771157395e-06,
      "loss": 0.0005,
      "step": 11716
    },
    {
      "epoch": 0.6950409301221971,
      "grad_norm": 11.270099639892578,
      "learning_rate": 6.776957553387821e-06,
      "loss": 0.3817,
      "step": 11717
    },
    {
      "epoch": 0.6951002491398742,
      "grad_norm": 19.223228454589844,
      "learning_rate": 6.775639335618245e-06,
      "loss": 0.6126,
      "step": 11718
    },
    {
      "epoch": 0.6951595681575513,
      "grad_norm": 1.852962851524353,
      "learning_rate": 6.774321117848669e-06,
      "loss": 0.0192,
      "step": 11719
    },
    {
      "epoch": 0.6952188871752284,
      "grad_norm": 13.562294006347656,
      "learning_rate": 6.7730029000790935e-06,
      "loss": 0.2346,
      "step": 11720
    },
    {
      "epoch": 0.6952782061929055,
      "grad_norm": 0.031908463686704636,
      "learning_rate": 6.7716846823095186e-06,
      "loss": 0.0007,
      "step": 11721
    },
    {
      "epoch": 0.6953375252105826,
      "grad_norm": 0.03613552823662758,
      "learning_rate": 6.770366464539943e-06,
      "loss": 0.001,
      "step": 11722
    },
    {
      "epoch": 0.6953968442282595,
      "grad_norm": 4.585989952087402,
      "learning_rate": 6.769048246770367e-06,
      "loss": 0.1546,
      "step": 11723
    },
    {
      "epoch": 0.6954561632459366,
      "grad_norm": 2.6152031421661377,
      "learning_rate": 6.767730029000792e-06,
      "loss": 0.0529,
      "step": 11724
    },
    {
      "epoch": 0.6955154822636137,
      "grad_norm": 5.957912445068359,
      "learning_rate": 6.766411811231216e-06,
      "loss": 0.051,
      "step": 11725
    },
    {
      "epoch": 0.6955748012812908,
      "grad_norm": 0.4624265730381012,
      "learning_rate": 6.76509359346164e-06,
      "loss": 0.0088,
      "step": 11726
    },
    {
      "epoch": 0.6956341202989679,
      "grad_norm": 0.28360891342163086,
      "learning_rate": 6.763775375692065e-06,
      "loss": 0.0032,
      "step": 11727
    },
    {
      "epoch": 0.695693439316645,
      "grad_norm": 1.970991611480713,
      "learning_rate": 6.7624571579224896e-06,
      "loss": 0.0211,
      "step": 11728
    },
    {
      "epoch": 0.6957527583343219,
      "grad_norm": 0.014134835451841354,
      "learning_rate": 6.761138940152914e-06,
      "loss": 0.0004,
      "step": 11729
    },
    {
      "epoch": 0.695812077351999,
      "grad_norm": 0.41455981135368347,
      "learning_rate": 6.759820722383338e-06,
      "loss": 0.0052,
      "step": 11730
    },
    {
      "epoch": 0.6958713963696761,
      "grad_norm": 0.32499638199806213,
      "learning_rate": 6.758502504613763e-06,
      "loss": 0.0035,
      "step": 11731
    },
    {
      "epoch": 0.6959307153873532,
      "grad_norm": 3.0609898567199707,
      "learning_rate": 6.757184286844187e-06,
      "loss": 0.0669,
      "step": 11732
    },
    {
      "epoch": 0.6959900344050303,
      "grad_norm": 7.0593085289001465,
      "learning_rate": 6.755866069074611e-06,
      "loss": 0.1503,
      "step": 11733
    },
    {
      "epoch": 0.6960493534227074,
      "grad_norm": 1.5077223777770996,
      "learning_rate": 6.754547851305036e-06,
      "loss": 0.0158,
      "step": 11734
    },
    {
      "epoch": 0.6961086724403844,
      "grad_norm": 1.2905089855194092,
      "learning_rate": 6.7532296335354606e-06,
      "loss": 0.0057,
      "step": 11735
    },
    {
      "epoch": 0.6961679914580614,
      "grad_norm": 0.024741699919104576,
      "learning_rate": 6.751911415765885e-06,
      "loss": 0.0005,
      "step": 11736
    },
    {
      "epoch": 0.6962273104757385,
      "grad_norm": 0.06069924682378769,
      "learning_rate": 6.750593197996309e-06,
      "loss": 0.0009,
      "step": 11737
    },
    {
      "epoch": 0.6962866294934156,
      "grad_norm": 3.9762823581695557,
      "learning_rate": 6.749274980226734e-06,
      "loss": 0.5062,
      "step": 11738
    },
    {
      "epoch": 0.6963459485110927,
      "grad_norm": 0.39937660098075867,
      "learning_rate": 6.747956762457158e-06,
      "loss": 0.0028,
      "step": 11739
    },
    {
      "epoch": 0.6964052675287697,
      "grad_norm": 0.00872714538127184,
      "learning_rate": 6.746638544687582e-06,
      "loss": 0.0003,
      "step": 11740
    },
    {
      "epoch": 0.6964645865464468,
      "grad_norm": 0.028897959738969803,
      "learning_rate": 6.745320326918008e-06,
      "loss": 0.0004,
      "step": 11741
    },
    {
      "epoch": 0.6965239055641239,
      "grad_norm": 17.787870407104492,
      "learning_rate": 6.7440021091484324e-06,
      "loss": 0.154,
      "step": 11742
    },
    {
      "epoch": 0.6965832245818009,
      "grad_norm": 0.9077310562133789,
      "learning_rate": 6.742683891378856e-06,
      "loss": 0.0132,
      "step": 11743
    },
    {
      "epoch": 0.696642543599478,
      "grad_norm": 22.217023849487305,
      "learning_rate": 6.74136567360928e-06,
      "loss": 0.5226,
      "step": 11744
    },
    {
      "epoch": 0.696701862617155,
      "grad_norm": 2.7146477699279785,
      "learning_rate": 6.740047455839706e-06,
      "loss": 0.0261,
      "step": 11745
    },
    {
      "epoch": 0.6967611816348321,
      "grad_norm": 9.0213623046875,
      "learning_rate": 6.73872923807013e-06,
      "loss": 0.471,
      "step": 11746
    },
    {
      "epoch": 0.6968205006525092,
      "grad_norm": 17.791778564453125,
      "learning_rate": 6.737411020300554e-06,
      "loss": 0.0925,
      "step": 11747
    },
    {
      "epoch": 0.6968798196701863,
      "grad_norm": 1.338185429573059,
      "learning_rate": 6.736092802530979e-06,
      "loss": 0.006,
      "step": 11748
    },
    {
      "epoch": 0.6969391386878633,
      "grad_norm": 0.2539837658405304,
      "learning_rate": 6.7347745847614034e-06,
      "loss": 0.0034,
      "step": 11749
    },
    {
      "epoch": 0.6969984577055404,
      "grad_norm": 0.022294625639915466,
      "learning_rate": 6.733456366991828e-06,
      "loss": 0.0004,
      "step": 11750
    },
    {
      "epoch": 0.6970577767232174,
      "grad_norm": 0.8154141306877136,
      "learning_rate": 6.732138149222253e-06,
      "loss": 0.007,
      "step": 11751
    },
    {
      "epoch": 0.6971170957408945,
      "grad_norm": 26.81251335144043,
      "learning_rate": 6.730819931452677e-06,
      "loss": 1.1012,
      "step": 11752
    },
    {
      "epoch": 0.6971764147585716,
      "grad_norm": 39.96733474731445,
      "learning_rate": 6.729501713683101e-06,
      "loss": 0.8605,
      "step": 11753
    },
    {
      "epoch": 0.6972357337762487,
      "grad_norm": 0.2351953685283661,
      "learning_rate": 6.728183495913525e-06,
      "loss": 0.0037,
      "step": 11754
    },
    {
      "epoch": 0.6972950527939258,
      "grad_norm": 9.349024772644043,
      "learning_rate": 6.72686527814395e-06,
      "loss": 0.1685,
      "step": 11755
    },
    {
      "epoch": 0.6973543718116028,
      "grad_norm": 0.10094019025564194,
      "learning_rate": 6.7255470603743744e-06,
      "loss": 0.001,
      "step": 11756
    },
    {
      "epoch": 0.6974136908292798,
      "grad_norm": 5.113971710205078,
      "learning_rate": 6.724228842604799e-06,
      "loss": 0.0422,
      "step": 11757
    },
    {
      "epoch": 0.6974730098469569,
      "grad_norm": 49.31850051879883,
      "learning_rate": 6.722910624835224e-06,
      "loss": 0.5633,
      "step": 11758
    },
    {
      "epoch": 0.697532328864634,
      "grad_norm": 24.13117790222168,
      "learning_rate": 6.721592407065648e-06,
      "loss": 0.1498,
      "step": 11759
    },
    {
      "epoch": 0.6975916478823111,
      "grad_norm": 9.813101768493652,
      "learning_rate": 6.720274189296072e-06,
      "loss": 0.2653,
      "step": 11760
    },
    {
      "epoch": 0.6976509668999882,
      "grad_norm": 8.020051956176758,
      "learning_rate": 6.718955971526496e-06,
      "loss": 0.3896,
      "step": 11761
    },
    {
      "epoch": 0.6977102859176652,
      "grad_norm": 21.7954044342041,
      "learning_rate": 6.717637753756921e-06,
      "loss": 0.3353,
      "step": 11762
    },
    {
      "epoch": 0.6977696049353422,
      "grad_norm": 0.04703354090452194,
      "learning_rate": 6.7163195359873454e-06,
      "loss": 0.0007,
      "step": 11763
    },
    {
      "epoch": 0.6978289239530193,
      "grad_norm": 5.087887763977051,
      "learning_rate": 6.71500131821777e-06,
      "loss": 0.0698,
      "step": 11764
    },
    {
      "epoch": 0.6978882429706964,
      "grad_norm": 6.992162704467773,
      "learning_rate": 6.713683100448195e-06,
      "loss": 0.4155,
      "step": 11765
    },
    {
      "epoch": 0.6979475619883735,
      "grad_norm": 0.2762039005756378,
      "learning_rate": 6.712364882678619e-06,
      "loss": 0.0028,
      "step": 11766
    },
    {
      "epoch": 0.6980068810060506,
      "grad_norm": 0.20704296231269836,
      "learning_rate": 6.711046664909043e-06,
      "loss": 0.0013,
      "step": 11767
    },
    {
      "epoch": 0.6980662000237277,
      "grad_norm": 1.6415942907333374,
      "learning_rate": 6.709728447139467e-06,
      "loss": 0.0088,
      "step": 11768
    },
    {
      "epoch": 0.6981255190414046,
      "grad_norm": 0.05292266234755516,
      "learning_rate": 6.708410229369893e-06,
      "loss": 0.0005,
      "step": 11769
    },
    {
      "epoch": 0.6981848380590817,
      "grad_norm": 1.2070971727371216,
      "learning_rate": 6.707092011600317e-06,
      "loss": 0.0142,
      "step": 11770
    },
    {
      "epoch": 0.6982441570767588,
      "grad_norm": 0.6242830753326416,
      "learning_rate": 6.705773793830741e-06,
      "loss": 0.0091,
      "step": 11771
    },
    {
      "epoch": 0.6983034760944359,
      "grad_norm": 7.728924751281738,
      "learning_rate": 6.7044555760611665e-06,
      "loss": 0.3394,
      "step": 11772
    },
    {
      "epoch": 0.698362795112113,
      "grad_norm": 0.24144567549228668,
      "learning_rate": 6.703137358291591e-06,
      "loss": 0.0029,
      "step": 11773
    },
    {
      "epoch": 0.69842211412979,
      "grad_norm": 7.532583236694336,
      "learning_rate": 6.701819140522015e-06,
      "loss": 0.1077,
      "step": 11774
    },
    {
      "epoch": 0.698481433147467,
      "grad_norm": 0.38155534863471985,
      "learning_rate": 6.70050092275244e-06,
      "loss": 0.0043,
      "step": 11775
    },
    {
      "epoch": 0.6985407521651441,
      "grad_norm": 11.246416091918945,
      "learning_rate": 6.699182704982864e-06,
      "loss": 0.494,
      "step": 11776
    },
    {
      "epoch": 0.6986000711828212,
      "grad_norm": 5.449843883514404,
      "learning_rate": 6.697864487213288e-06,
      "loss": 0.4358,
      "step": 11777
    },
    {
      "epoch": 0.6986593902004983,
      "grad_norm": 1.0343425273895264,
      "learning_rate": 6.6965462694437125e-06,
      "loss": 0.0078,
      "step": 11778
    },
    {
      "epoch": 0.6987187092181754,
      "grad_norm": 0.20942799746990204,
      "learning_rate": 6.6952280516741375e-06,
      "loss": 0.0042,
      "step": 11779
    },
    {
      "epoch": 0.6987780282358524,
      "grad_norm": 0.1180713102221489,
      "learning_rate": 6.693909833904562e-06,
      "loss": 0.0027,
      "step": 11780
    },
    {
      "epoch": 0.6988373472535295,
      "grad_norm": 15.827384948730469,
      "learning_rate": 6.692591616134986e-06,
      "loss": 0.4823,
      "step": 11781
    },
    {
      "epoch": 0.6988966662712065,
      "grad_norm": 9.765390396118164,
      "learning_rate": 6.691273398365411e-06,
      "loss": 0.6794,
      "step": 11782
    },
    {
      "epoch": 0.6989559852888836,
      "grad_norm": 8.636578559875488,
      "learning_rate": 6.689955180595835e-06,
      "loss": 0.2072,
      "step": 11783
    },
    {
      "epoch": 0.6990153043065607,
      "grad_norm": 9.973440170288086,
      "learning_rate": 6.688636962826259e-06,
      "loss": 0.0808,
      "step": 11784
    },
    {
      "epoch": 0.6990746233242378,
      "grad_norm": 0.22747181355953217,
      "learning_rate": 6.6873187450566835e-06,
      "loss": 0.0019,
      "step": 11785
    },
    {
      "epoch": 0.6991339423419148,
      "grad_norm": 0.14815399050712585,
      "learning_rate": 6.6860005272871085e-06,
      "loss": 0.0027,
      "step": 11786
    },
    {
      "epoch": 0.6991932613595919,
      "grad_norm": 8.892777442932129,
      "learning_rate": 6.684682309517533e-06,
      "loss": 0.2446,
      "step": 11787
    },
    {
      "epoch": 0.699252580377269,
      "grad_norm": 0.011169391684234142,
      "learning_rate": 6.683364091747957e-06,
      "loss": 0.0003,
      "step": 11788
    },
    {
      "epoch": 0.699311899394946,
      "grad_norm": 1.634666919708252,
      "learning_rate": 6.682045873978382e-06,
      "loss": 0.016,
      "step": 11789
    },
    {
      "epoch": 0.6993712184126231,
      "grad_norm": 0.045006364583969116,
      "learning_rate": 6.680727656208806e-06,
      "loss": 0.0006,
      "step": 11790
    },
    {
      "epoch": 0.6994305374303001,
      "grad_norm": 0.6582124829292297,
      "learning_rate": 6.67940943843923e-06,
      "loss": 0.0082,
      "step": 11791
    },
    {
      "epoch": 0.6994898564479772,
      "grad_norm": 8.867206573486328,
      "learning_rate": 6.6780912206696545e-06,
      "loss": 0.0204,
      "step": 11792
    },
    {
      "epoch": 0.6995491754656543,
      "grad_norm": 0.011823737993836403,
      "learning_rate": 6.6767730029000795e-06,
      "loss": 0.0004,
      "step": 11793
    },
    {
      "epoch": 0.6996084944833314,
      "grad_norm": 0.1825273334980011,
      "learning_rate": 6.675454785130504e-06,
      "loss": 0.0009,
      "step": 11794
    },
    {
      "epoch": 0.6996678135010084,
      "grad_norm": 0.5011833310127258,
      "learning_rate": 6.674136567360928e-06,
      "loss": 0.005,
      "step": 11795
    },
    {
      "epoch": 0.6997271325186855,
      "grad_norm": 1.4221422672271729,
      "learning_rate": 6.672818349591354e-06,
      "loss": 0.0244,
      "step": 11796
    },
    {
      "epoch": 0.6997864515363625,
      "grad_norm": 14.414958000183105,
      "learning_rate": 6.671500131821778e-06,
      "loss": 0.4104,
      "step": 11797
    },
    {
      "epoch": 0.6998457705540396,
      "grad_norm": 4.771146297454834,
      "learning_rate": 6.670181914052201e-06,
      "loss": 0.1027,
      "step": 11798
    },
    {
      "epoch": 0.6999050895717167,
      "grad_norm": 25.395755767822266,
      "learning_rate": 6.668863696282627e-06,
      "loss": 0.6009,
      "step": 11799
    },
    {
      "epoch": 0.6999644085893938,
      "grad_norm": 0.35858047008514404,
      "learning_rate": 6.667545478513051e-06,
      "loss": 0.004,
      "step": 11800
    },
    {
      "epoch": 0.7000237276070709,
      "grad_norm": 0.02950853295624256,
      "learning_rate": 6.6662272607434756e-06,
      "loss": 0.0005,
      "step": 11801
    },
    {
      "epoch": 0.7000830466247479,
      "grad_norm": 0.19843058288097382,
      "learning_rate": 6.6649090429739e-06,
      "loss": 0.0036,
      "step": 11802
    },
    {
      "epoch": 0.7001423656424249,
      "grad_norm": 0.33485475182533264,
      "learning_rate": 6.663590825204325e-06,
      "loss": 0.0027,
      "step": 11803
    },
    {
      "epoch": 0.700201684660102,
      "grad_norm": 3.2251811027526855,
      "learning_rate": 6.662272607434749e-06,
      "loss": 0.0181,
      "step": 11804
    },
    {
      "epoch": 0.7002610036777791,
      "grad_norm": 19.25040626525879,
      "learning_rate": 6.660954389665173e-06,
      "loss": 0.4038,
      "step": 11805
    },
    {
      "epoch": 0.7003203226954562,
      "grad_norm": 12.245362281799316,
      "learning_rate": 6.659636171895598e-06,
      "loss": 0.1926,
      "step": 11806
    },
    {
      "epoch": 0.7003796417131333,
      "grad_norm": 1.1041455268859863,
      "learning_rate": 6.658317954126022e-06,
      "loss": 0.0153,
      "step": 11807
    },
    {
      "epoch": 0.7004389607308102,
      "grad_norm": 1.2094569206237793,
      "learning_rate": 6.6569997363564466e-06,
      "loss": 0.0132,
      "step": 11808
    },
    {
      "epoch": 0.7004982797484873,
      "grad_norm": 7.174095630645752,
      "learning_rate": 6.655681518586871e-06,
      "loss": 0.3761,
      "step": 11809
    },
    {
      "epoch": 0.7005575987661644,
      "grad_norm": 1.0911089181900024,
      "learning_rate": 6.654363300817296e-06,
      "loss": 0.0074,
      "step": 11810
    },
    {
      "epoch": 0.7006169177838415,
      "grad_norm": 0.1024368405342102,
      "learning_rate": 6.65304508304772e-06,
      "loss": 0.0025,
      "step": 11811
    },
    {
      "epoch": 0.7006762368015186,
      "grad_norm": 11.20312786102295,
      "learning_rate": 6.651726865278144e-06,
      "loss": 0.1964,
      "step": 11812
    },
    {
      "epoch": 0.7007355558191957,
      "grad_norm": 24.797168731689453,
      "learning_rate": 6.650408647508569e-06,
      "loss": 0.1363,
      "step": 11813
    },
    {
      "epoch": 0.7007948748368727,
      "grad_norm": 1.7735068798065186,
      "learning_rate": 6.649090429738993e-06,
      "loss": 0.0248,
      "step": 11814
    },
    {
      "epoch": 0.7008541938545497,
      "grad_norm": 55.02227783203125,
      "learning_rate": 6.6477722119694176e-06,
      "loss": 0.4447,
      "step": 11815
    },
    {
      "epoch": 0.7009135128722268,
      "grad_norm": 0.2702818214893341,
      "learning_rate": 6.646453994199842e-06,
      "loss": 0.0035,
      "step": 11816
    },
    {
      "epoch": 0.7009728318899039,
      "grad_norm": 16.79123306274414,
      "learning_rate": 6.645135776430267e-06,
      "loss": 0.1935,
      "step": 11817
    },
    {
      "epoch": 0.701032150907581,
      "grad_norm": 0.02166651375591755,
      "learning_rate": 6.643817558660691e-06,
      "loss": 0.0006,
      "step": 11818
    },
    {
      "epoch": 0.7010914699252581,
      "grad_norm": 0.012667457573115826,
      "learning_rate": 6.642499340891115e-06,
      "loss": 0.0004,
      "step": 11819
    },
    {
      "epoch": 0.7011507889429351,
      "grad_norm": 0.04127563536167145,
      "learning_rate": 6.641181123121541e-06,
      "loss": 0.0011,
      "step": 11820
    },
    {
      "epoch": 0.7012101079606121,
      "grad_norm": 0.16707828640937805,
      "learning_rate": 6.639862905351964e-06,
      "loss": 0.0028,
      "step": 11821
    },
    {
      "epoch": 0.7012694269782892,
      "grad_norm": 1.164503812789917,
      "learning_rate": 6.6385446875823886e-06,
      "loss": 0.008,
      "step": 11822
    },
    {
      "epoch": 0.7013287459959663,
      "grad_norm": 0.5627641677856445,
      "learning_rate": 6.6372264698128144e-06,
      "loss": 0.0089,
      "step": 11823
    },
    {
      "epoch": 0.7013880650136434,
      "grad_norm": 0.35667315125465393,
      "learning_rate": 6.635908252043239e-06,
      "loss": 0.0036,
      "step": 11824
    },
    {
      "epoch": 0.7014473840313205,
      "grad_norm": 6.039201736450195,
      "learning_rate": 6.634590034273663e-06,
      "loss": 0.0616,
      "step": 11825
    },
    {
      "epoch": 0.7015067030489975,
      "grad_norm": 16.95086669921875,
      "learning_rate": 6.633271816504086e-06,
      "loss": 1.5622,
      "step": 11826
    },
    {
      "epoch": 0.7015660220666746,
      "grad_norm": 8.625052452087402,
      "learning_rate": 6.631953598734512e-06,
      "loss": 0.1777,
      "step": 11827
    },
    {
      "epoch": 0.7016253410843516,
      "grad_norm": 0.005968132987618446,
      "learning_rate": 6.630635380964936e-06,
      "loss": 0.0001,
      "step": 11828
    },
    {
      "epoch": 0.7016846601020287,
      "grad_norm": 0.033519670367240906,
      "learning_rate": 6.62931716319536e-06,
      "loss": 0.0007,
      "step": 11829
    },
    {
      "epoch": 0.7017439791197058,
      "grad_norm": 0.07567591965198517,
      "learning_rate": 6.6279989454257855e-06,
      "loss": 0.0012,
      "step": 11830
    },
    {
      "epoch": 0.7018032981373828,
      "grad_norm": 1.1737979650497437,
      "learning_rate": 6.62668072765621e-06,
      "loss": 0.0111,
      "step": 11831
    },
    {
      "epoch": 0.7018626171550599,
      "grad_norm": 3.000312089920044,
      "learning_rate": 6.625362509886634e-06,
      "loss": 0.0381,
      "step": 11832
    },
    {
      "epoch": 0.701921936172737,
      "grad_norm": 1.3361918926239014,
      "learning_rate": 6.624044292117058e-06,
      "loss": 0.0092,
      "step": 11833
    },
    {
      "epoch": 0.7019812551904141,
      "grad_norm": 0.16471536457538605,
      "learning_rate": 6.622726074347483e-06,
      "loss": 0.002,
      "step": 11834
    },
    {
      "epoch": 0.7020405742080911,
      "grad_norm": 20.200870513916016,
      "learning_rate": 6.621407856577907e-06,
      "loss": 0.0687,
      "step": 11835
    },
    {
      "epoch": 0.7020998932257682,
      "grad_norm": 27.570390701293945,
      "learning_rate": 6.620089638808331e-06,
      "loss": 0.1227,
      "step": 11836
    },
    {
      "epoch": 0.7021592122434452,
      "grad_norm": 13.467097282409668,
      "learning_rate": 6.6187714210387565e-06,
      "loss": 0.4123,
      "step": 11837
    },
    {
      "epoch": 0.7022185312611223,
      "grad_norm": 0.09244099259376526,
      "learning_rate": 6.617453203269181e-06,
      "loss": 0.0017,
      "step": 11838
    },
    {
      "epoch": 0.7022778502787994,
      "grad_norm": 0.39638060331344604,
      "learning_rate": 6.616134985499605e-06,
      "loss": 0.0023,
      "step": 11839
    },
    {
      "epoch": 0.7023371692964765,
      "grad_norm": 0.3300183415412903,
      "learning_rate": 6.614816767730029e-06,
      "loss": 0.0031,
      "step": 11840
    },
    {
      "epoch": 0.7023964883141535,
      "grad_norm": 8.08125114440918,
      "learning_rate": 6.613498549960454e-06,
      "loss": 0.3519,
      "step": 11841
    },
    {
      "epoch": 0.7024558073318306,
      "grad_norm": 36.034996032714844,
      "learning_rate": 6.612180332190878e-06,
      "loss": 0.4054,
      "step": 11842
    },
    {
      "epoch": 0.7025151263495076,
      "grad_norm": 10.195054054260254,
      "learning_rate": 6.6108621144213024e-06,
      "loss": 0.1792,
      "step": 11843
    },
    {
      "epoch": 0.7025744453671847,
      "grad_norm": 0.08439557254314423,
      "learning_rate": 6.6095438966517275e-06,
      "loss": 0.0012,
      "step": 11844
    },
    {
      "epoch": 0.7026337643848618,
      "grad_norm": 28.87990951538086,
      "learning_rate": 6.608225678882152e-06,
      "loss": 0.1827,
      "step": 11845
    },
    {
      "epoch": 0.7026930834025389,
      "grad_norm": 0.4186488389968872,
      "learning_rate": 6.606907461112576e-06,
      "loss": 0.0058,
      "step": 11846
    },
    {
      "epoch": 0.702752402420216,
      "grad_norm": 2.580789089202881,
      "learning_rate": 6.605589243343002e-06,
      "loss": 0.03,
      "step": 11847
    },
    {
      "epoch": 0.7028117214378929,
      "grad_norm": 0.09539946168661118,
      "learning_rate": 6.604271025573425e-06,
      "loss": 0.0017,
      "step": 11848
    },
    {
      "epoch": 0.70287104045557,
      "grad_norm": 0.011373890563845634,
      "learning_rate": 6.602952807803849e-06,
      "loss": 0.0002,
      "step": 11849
    },
    {
      "epoch": 0.7029303594732471,
      "grad_norm": 12.654061317443848,
      "learning_rate": 6.6016345900342734e-06,
      "loss": 0.1641,
      "step": 11850
    },
    {
      "epoch": 0.7029896784909242,
      "grad_norm": 0.15375041961669922,
      "learning_rate": 6.600316372264699e-06,
      "loss": 0.0026,
      "step": 11851
    },
    {
      "epoch": 0.7030489975086013,
      "grad_norm": 0.024332955479621887,
      "learning_rate": 6.5989981544951235e-06,
      "loss": 0.0005,
      "step": 11852
    },
    {
      "epoch": 0.7031083165262784,
      "grad_norm": 6.9369378089904785,
      "learning_rate": 6.597679936725548e-06,
      "loss": 0.1388,
      "step": 11853
    },
    {
      "epoch": 0.7031676355439553,
      "grad_norm": 22.971040725708008,
      "learning_rate": 6.596361718955973e-06,
      "loss": 0.727,
      "step": 11854
    },
    {
      "epoch": 0.7032269545616324,
      "grad_norm": 7.912914752960205,
      "learning_rate": 6.595043501186397e-06,
      "loss": 0.1692,
      "step": 11855
    },
    {
      "epoch": 0.7032862735793095,
      "grad_norm": 0.38238537311553955,
      "learning_rate": 6.593725283416821e-06,
      "loss": 0.0031,
      "step": 11856
    },
    {
      "epoch": 0.7033455925969866,
      "grad_norm": 9.68766975402832,
      "learning_rate": 6.592407065647245e-06,
      "loss": 0.1957,
      "step": 11857
    },
    {
      "epoch": 0.7034049116146637,
      "grad_norm": 2.2477498054504395,
      "learning_rate": 6.59108884787767e-06,
      "loss": 0.0466,
      "step": 11858
    },
    {
      "epoch": 0.7034642306323408,
      "grad_norm": 0.6763467788696289,
      "learning_rate": 6.5897706301080945e-06,
      "loss": 0.0118,
      "step": 11859
    },
    {
      "epoch": 0.7035235496500178,
      "grad_norm": 15.395122528076172,
      "learning_rate": 6.588452412338519e-06,
      "loss": 0.2869,
      "step": 11860
    },
    {
      "epoch": 0.7035828686676948,
      "grad_norm": 9.508896827697754,
      "learning_rate": 6.587134194568944e-06,
      "loss": 0.0791,
      "step": 11861
    },
    {
      "epoch": 0.7036421876853719,
      "grad_norm": 6.816782474517822,
      "learning_rate": 6.585815976799368e-06,
      "loss": 0.2094,
      "step": 11862
    },
    {
      "epoch": 0.703701506703049,
      "grad_norm": 5.037994861602783,
      "learning_rate": 6.584497759029792e-06,
      "loss": 0.0617,
      "step": 11863
    },
    {
      "epoch": 0.7037608257207261,
      "grad_norm": 0.007092498242855072,
      "learning_rate": 6.583179541260216e-06,
      "loss": 0.0002,
      "step": 11864
    },
    {
      "epoch": 0.7038201447384032,
      "grad_norm": 5.540307521820068,
      "learning_rate": 6.581861323490641e-06,
      "loss": 0.1385,
      "step": 11865
    },
    {
      "epoch": 0.7038794637560802,
      "grad_norm": 4.24078893661499,
      "learning_rate": 6.5805431057210655e-06,
      "loss": 0.0535,
      "step": 11866
    },
    {
      "epoch": 0.7039387827737573,
      "grad_norm": 23.83715057373047,
      "learning_rate": 6.57922488795149e-06,
      "loss": 1.2357,
      "step": 11867
    },
    {
      "epoch": 0.7039981017914343,
      "grad_norm": 25.53591537475586,
      "learning_rate": 6.577906670181915e-06,
      "loss": 0.3472,
      "step": 11868
    },
    {
      "epoch": 0.7040574208091114,
      "grad_norm": 0.27759435772895813,
      "learning_rate": 6.576588452412339e-06,
      "loss": 0.005,
      "step": 11869
    },
    {
      "epoch": 0.7041167398267885,
      "grad_norm": 4.191420078277588,
      "learning_rate": 6.575270234642763e-06,
      "loss": 0.0979,
      "step": 11870
    },
    {
      "epoch": 0.7041760588444655,
      "grad_norm": 8.056585311889648,
      "learning_rate": 6.573952016873188e-06,
      "loss": 0.153,
      "step": 11871
    },
    {
      "epoch": 0.7042353778621426,
      "grad_norm": 10.857756614685059,
      "learning_rate": 6.572633799103612e-06,
      "loss": 0.1921,
      "step": 11872
    },
    {
      "epoch": 0.7042946968798197,
      "grad_norm": 0.01869780384004116,
      "learning_rate": 6.5713155813340365e-06,
      "loss": 0.0004,
      "step": 11873
    },
    {
      "epoch": 0.7043540158974967,
      "grad_norm": 40.029239654541016,
      "learning_rate": 6.569997363564461e-06,
      "loss": 0.5156,
      "step": 11874
    },
    {
      "epoch": 0.7044133349151738,
      "grad_norm": 0.2823305130004883,
      "learning_rate": 6.568679145794887e-06,
      "loss": 0.0041,
      "step": 11875
    },
    {
      "epoch": 0.7044726539328509,
      "grad_norm": 0.0513906292617321,
      "learning_rate": 6.56736092802531e-06,
      "loss": 0.001,
      "step": 11876
    },
    {
      "epoch": 0.7045319729505279,
      "grad_norm": 13.027997970581055,
      "learning_rate": 6.566042710255734e-06,
      "loss": 0.5258,
      "step": 11877
    },
    {
      "epoch": 0.704591291968205,
      "grad_norm": 0.9655118584632874,
      "learning_rate": 6.56472449248616e-06,
      "loss": 0.0099,
      "step": 11878
    },
    {
      "epoch": 0.7046506109858821,
      "grad_norm": 2.5449578762054443,
      "learning_rate": 6.563406274716584e-06,
      "loss": 0.1031,
      "step": 11879
    },
    {
      "epoch": 0.7047099300035592,
      "grad_norm": 0.024215057492256165,
      "learning_rate": 6.562088056947008e-06,
      "loss": 0.0007,
      "step": 11880
    },
    {
      "epoch": 0.7047692490212362,
      "grad_norm": 9.65731143951416,
      "learning_rate": 6.5607698391774325e-06,
      "loss": 0.1789,
      "step": 11881
    },
    {
      "epoch": 0.7048285680389133,
      "grad_norm": 0.08458103239536285,
      "learning_rate": 6.559451621407858e-06,
      "loss": 0.0013,
      "step": 11882
    },
    {
      "epoch": 0.7048878870565903,
      "grad_norm": 6.552274703979492,
      "learning_rate": 6.558133403638282e-06,
      "loss": 0.0622,
      "step": 11883
    },
    {
      "epoch": 0.7049472060742674,
      "grad_norm": 0.08450959622859955,
      "learning_rate": 6.556815185868706e-06,
      "loss": 0.0023,
      "step": 11884
    },
    {
      "epoch": 0.7050065250919445,
      "grad_norm": 9.660407066345215,
      "learning_rate": 6.555496968099131e-06,
      "loss": 0.2155,
      "step": 11885
    },
    {
      "epoch": 0.7050658441096216,
      "grad_norm": 2.9872021675109863,
      "learning_rate": 6.554178750329555e-06,
      "loss": 0.03,
      "step": 11886
    },
    {
      "epoch": 0.7051251631272986,
      "grad_norm": 0.07490440458059311,
      "learning_rate": 6.552860532559979e-06,
      "loss": 0.0008,
      "step": 11887
    },
    {
      "epoch": 0.7051844821449756,
      "grad_norm": 15.288307189941406,
      "learning_rate": 6.5515423147904036e-06,
      "loss": 0.2039,
      "step": 11888
    },
    {
      "epoch": 0.7052438011626527,
      "grad_norm": 1.741686224937439,
      "learning_rate": 6.550224097020829e-06,
      "loss": 0.0824,
      "step": 11889
    },
    {
      "epoch": 0.7053031201803298,
      "grad_norm": 0.02311902493238449,
      "learning_rate": 6.548905879251253e-06,
      "loss": 0.0006,
      "step": 11890
    },
    {
      "epoch": 0.7053624391980069,
      "grad_norm": 0.003439890220761299,
      "learning_rate": 6.547587661481677e-06,
      "loss": 0.0001,
      "step": 11891
    },
    {
      "epoch": 0.705421758215684,
      "grad_norm": 0.9124457836151123,
      "learning_rate": 6.546269443712102e-06,
      "loss": 0.0048,
      "step": 11892
    },
    {
      "epoch": 0.7054810772333611,
      "grad_norm": 0.8124815225601196,
      "learning_rate": 6.544951225942526e-06,
      "loss": 0.0059,
      "step": 11893
    },
    {
      "epoch": 0.705540396251038,
      "grad_norm": 7.888920307159424,
      "learning_rate": 6.54363300817295e-06,
      "loss": 0.0426,
      "step": 11894
    },
    {
      "epoch": 0.7055997152687151,
      "grad_norm": 0.016902698203921318,
      "learning_rate": 6.542314790403375e-06,
      "loss": 0.0004,
      "step": 11895
    },
    {
      "epoch": 0.7056590342863922,
      "grad_norm": 2.5621089935302734,
      "learning_rate": 6.5409965726338e-06,
      "loss": 0.0413,
      "step": 11896
    },
    {
      "epoch": 0.7057183533040693,
      "grad_norm": 6.364006042480469,
      "learning_rate": 6.539678354864224e-06,
      "loss": 0.3269,
      "step": 11897
    },
    {
      "epoch": 0.7057776723217464,
      "grad_norm": 0.016242604702711105,
      "learning_rate": 6.538360137094648e-06,
      "loss": 0.0004,
      "step": 11898
    },
    {
      "epoch": 0.7058369913394235,
      "grad_norm": 0.5740793943405151,
      "learning_rate": 6.537041919325073e-06,
      "loss": 0.0053,
      "step": 11899
    },
    {
      "epoch": 0.7058963103571004,
      "grad_norm": 13.109574317932129,
      "learning_rate": 6.535723701555497e-06,
      "loss": 0.2721,
      "step": 11900
    },
    {
      "epoch": 0.7059556293747775,
      "grad_norm": 0.09362102299928665,
      "learning_rate": 6.534405483785921e-06,
      "loss": 0.0015,
      "step": 11901
    },
    {
      "epoch": 0.7060149483924546,
      "grad_norm": 0.5088971853256226,
      "learning_rate": 6.533087266016347e-06,
      "loss": 0.0036,
      "step": 11902
    },
    {
      "epoch": 0.7060742674101317,
      "grad_norm": 15.285614013671875,
      "learning_rate": 6.5317690482467714e-06,
      "loss": 0.4279,
      "step": 11903
    },
    {
      "epoch": 0.7061335864278088,
      "grad_norm": 0.4406621754169464,
      "learning_rate": 6.530450830477195e-06,
      "loss": 0.0042,
      "step": 11904
    },
    {
      "epoch": 0.7061929054454859,
      "grad_norm": 17.368083953857422,
      "learning_rate": 6.529132612707619e-06,
      "loss": 0.3492,
      "step": 11905
    },
    {
      "epoch": 0.7062522244631629,
      "grad_norm": 2.92620587348938,
      "learning_rate": 6.527814394938045e-06,
      "loss": 0.0407,
      "step": 11906
    },
    {
      "epoch": 0.7063115434808399,
      "grad_norm": 2.799966335296631,
      "learning_rate": 6.526496177168469e-06,
      "loss": 0.0463,
      "step": 11907
    },
    {
      "epoch": 0.706370862498517,
      "grad_norm": 0.010393856093287468,
      "learning_rate": 6.525177959398893e-06,
      "loss": 0.0004,
      "step": 11908
    },
    {
      "epoch": 0.7064301815161941,
      "grad_norm": 0.1838301122188568,
      "learning_rate": 6.523859741629318e-06,
      "loss": 0.0036,
      "step": 11909
    },
    {
      "epoch": 0.7064895005338712,
      "grad_norm": 0.3468252420425415,
      "learning_rate": 6.5225415238597424e-06,
      "loss": 0.0042,
      "step": 11910
    },
    {
      "epoch": 0.7065488195515482,
      "grad_norm": 0.039522647857666016,
      "learning_rate": 6.521223306090167e-06,
      "loss": 0.0007,
      "step": 11911
    },
    {
      "epoch": 0.7066081385692253,
      "grad_norm": 2.5666604042053223,
      "learning_rate": 6.519905088320591e-06,
      "loss": 0.0315,
      "step": 11912
    },
    {
      "epoch": 0.7066674575869024,
      "grad_norm": 1.3372128009796143,
      "learning_rate": 6.518586870551016e-06,
      "loss": 0.0104,
      "step": 11913
    },
    {
      "epoch": 0.7067267766045794,
      "grad_norm": 0.18448427319526672,
      "learning_rate": 6.51726865278144e-06,
      "loss": 0.0035,
      "step": 11914
    },
    {
      "epoch": 0.7067860956222565,
      "grad_norm": 1.070396900177002,
      "learning_rate": 6.515950435011864e-06,
      "loss": 0.0108,
      "step": 11915
    },
    {
      "epoch": 0.7068454146399336,
      "grad_norm": 0.1670932173728943,
      "learning_rate": 6.514632217242289e-06,
      "loss": 0.0013,
      "step": 11916
    },
    {
      "epoch": 0.7069047336576106,
      "grad_norm": 0.5973531603813171,
      "learning_rate": 6.5133139994727134e-06,
      "loss": 0.0096,
      "step": 11917
    },
    {
      "epoch": 0.7069640526752877,
      "grad_norm": 19.755952835083008,
      "learning_rate": 6.511995781703138e-06,
      "loss": 0.7857,
      "step": 11918
    },
    {
      "epoch": 0.7070233716929648,
      "grad_norm": 10.213025093078613,
      "learning_rate": 6.510677563933563e-06,
      "loss": 0.1843,
      "step": 11919
    },
    {
      "epoch": 0.7070826907106418,
      "grad_norm": 0.9014365077018738,
      "learning_rate": 6.509359346163987e-06,
      "loss": 0.0096,
      "step": 11920
    },
    {
      "epoch": 0.7071420097283189,
      "grad_norm": 13.955517768859863,
      "learning_rate": 6.508041128394411e-06,
      "loss": 0.1644,
      "step": 11921
    },
    {
      "epoch": 0.707201328745996,
      "grad_norm": 2.322763442993164,
      "learning_rate": 6.506722910624835e-06,
      "loss": 0.0307,
      "step": 11922
    },
    {
      "epoch": 0.707260647763673,
      "grad_norm": 2.6120214462280273,
      "learning_rate": 6.50540469285526e-06,
      "loss": 0.0404,
      "step": 11923
    },
    {
      "epoch": 0.7073199667813501,
      "grad_norm": 65.64761352539062,
      "learning_rate": 6.5040864750856845e-06,
      "loss": 0.3435,
      "step": 11924
    },
    {
      "epoch": 0.7073792857990272,
      "grad_norm": 0.44797366857528687,
      "learning_rate": 6.502768257316109e-06,
      "loss": 0.0044,
      "step": 11925
    },
    {
      "epoch": 0.7074386048167043,
      "grad_norm": 0.06899773329496384,
      "learning_rate": 6.501450039546534e-06,
      "loss": 0.0009,
      "step": 11926
    },
    {
      "epoch": 0.7074979238343813,
      "grad_norm": 31.810400009155273,
      "learning_rate": 6.500131821776958e-06,
      "loss": 0.3488,
      "step": 11927
    },
    {
      "epoch": 0.7075572428520583,
      "grad_norm": 0.7145156264305115,
      "learning_rate": 6.498813604007382e-06,
      "loss": 0.0093,
      "step": 11928
    },
    {
      "epoch": 0.7076165618697354,
      "grad_norm": 30.312362670898438,
      "learning_rate": 6.497495386237806e-06,
      "loss": 0.2519,
      "step": 11929
    },
    {
      "epoch": 0.7076758808874125,
      "grad_norm": 0.2642654776573181,
      "learning_rate": 6.496177168468232e-06,
      "loss": 0.0027,
      "step": 11930
    },
    {
      "epoch": 0.7077351999050896,
      "grad_norm": 0.059602588415145874,
      "learning_rate": 6.494858950698656e-06,
      "loss": 0.0012,
      "step": 11931
    },
    {
      "epoch": 0.7077945189227667,
      "grad_norm": 13.544920921325684,
      "learning_rate": 6.49354073292908e-06,
      "loss": 1.7261,
      "step": 11932
    },
    {
      "epoch": 0.7078538379404437,
      "grad_norm": 0.035311635583639145,
      "learning_rate": 6.4922225151595055e-06,
      "loss": 0.0009,
      "step": 11933
    },
    {
      "epoch": 0.7079131569581207,
      "grad_norm": 0.2550823986530304,
      "learning_rate": 6.49090429738993e-06,
      "loss": 0.0036,
      "step": 11934
    },
    {
      "epoch": 0.7079724759757978,
      "grad_norm": 7.512000560760498,
      "learning_rate": 6.489586079620354e-06,
      "loss": 0.2634,
      "step": 11935
    },
    {
      "epoch": 0.7080317949934749,
      "grad_norm": 0.03266086429357529,
      "learning_rate": 6.488267861850778e-06,
      "loss": 0.0005,
      "step": 11936
    },
    {
      "epoch": 0.708091114011152,
      "grad_norm": 0.06419382989406586,
      "learning_rate": 6.486949644081203e-06,
      "loss": 0.0009,
      "step": 11937
    },
    {
      "epoch": 0.7081504330288291,
      "grad_norm": 0.18472246825695038,
      "learning_rate": 6.485631426311627e-06,
      "loss": 0.0018,
      "step": 11938
    },
    {
      "epoch": 0.7082097520465062,
      "grad_norm": 2.5487608909606934,
      "learning_rate": 6.4843132085420515e-06,
      "loss": 0.1257,
      "step": 11939
    },
    {
      "epoch": 0.7082690710641831,
      "grad_norm": 0.7591533660888672,
      "learning_rate": 6.4829949907724765e-06,
      "loss": 0.0119,
      "step": 11940
    },
    {
      "epoch": 0.7083283900818602,
      "grad_norm": 9.103668212890625,
      "learning_rate": 6.481676773002901e-06,
      "loss": 0.1528,
      "step": 11941
    },
    {
      "epoch": 0.7083877090995373,
      "grad_norm": 0.0314796045422554,
      "learning_rate": 6.480358555233325e-06,
      "loss": 0.0005,
      "step": 11942
    },
    {
      "epoch": 0.7084470281172144,
      "grad_norm": 6.657230854034424,
      "learning_rate": 6.47904033746375e-06,
      "loss": 0.1158,
      "step": 11943
    },
    {
      "epoch": 0.7085063471348915,
      "grad_norm": 9.340188980102539,
      "learning_rate": 6.477722119694174e-06,
      "loss": 0.3452,
      "step": 11944
    },
    {
      "epoch": 0.7085656661525686,
      "grad_norm": 10.242300033569336,
      "learning_rate": 6.476403901924598e-06,
      "loss": 0.9679,
      "step": 11945
    },
    {
      "epoch": 0.7086249851702456,
      "grad_norm": 0.25827085971832275,
      "learning_rate": 6.4750856841550225e-06,
      "loss": 0.002,
      "step": 11946
    },
    {
      "epoch": 0.7086843041879226,
      "grad_norm": 0.6108266115188599,
      "learning_rate": 6.4737674663854475e-06,
      "loss": 0.0074,
      "step": 11947
    },
    {
      "epoch": 0.7087436232055997,
      "grad_norm": 2.5211870670318604,
      "learning_rate": 6.472449248615872e-06,
      "loss": 0.0247,
      "step": 11948
    },
    {
      "epoch": 0.7088029422232768,
      "grad_norm": 7.470009803771973,
      "learning_rate": 6.471131030846296e-06,
      "loss": 0.0936,
      "step": 11949
    },
    {
      "epoch": 0.7088622612409539,
      "grad_norm": 0.06061973050236702,
      "learning_rate": 6.469812813076721e-06,
      "loss": 0.0015,
      "step": 11950
    },
    {
      "epoch": 0.708921580258631,
      "grad_norm": 8.456719398498535,
      "learning_rate": 6.468494595307145e-06,
      "loss": 0.152,
      "step": 11951
    },
    {
      "epoch": 0.708980899276308,
      "grad_norm": 1.8048417568206787,
      "learning_rate": 6.467176377537569e-06,
      "loss": 0.0179,
      "step": 11952
    },
    {
      "epoch": 0.709040218293985,
      "grad_norm": 6.774343967437744,
      "learning_rate": 6.4658581597679935e-06,
      "loss": 0.0942,
      "step": 11953
    },
    {
      "epoch": 0.7090995373116621,
      "grad_norm": 10.887063980102539,
      "learning_rate": 6.4645399419984185e-06,
      "loss": 0.9145,
      "step": 11954
    },
    {
      "epoch": 0.7091588563293392,
      "grad_norm": 9.314730644226074,
      "learning_rate": 6.463221724228843e-06,
      "loss": 0.2061,
      "step": 11955
    },
    {
      "epoch": 0.7092181753470163,
      "grad_norm": 16.612262725830078,
      "learning_rate": 6.461903506459267e-06,
      "loss": 0.4988,
      "step": 11956
    },
    {
      "epoch": 0.7092774943646933,
      "grad_norm": 13.15221118927002,
      "learning_rate": 6.460585288689693e-06,
      "loss": 0.1725,
      "step": 11957
    },
    {
      "epoch": 0.7093368133823704,
      "grad_norm": 0.30873623490333557,
      "learning_rate": 6.459267070920117e-06,
      "loss": 0.0038,
      "step": 11958
    },
    {
      "epoch": 0.7093961324000475,
      "grad_norm": 2.153333902359009,
      "learning_rate": 6.457948853150541e-06,
      "loss": 0.0174,
      "step": 11959
    },
    {
      "epoch": 0.7094554514177245,
      "grad_norm": 0.16686849296092987,
      "learning_rate": 6.456630635380966e-06,
      "loss": 0.0024,
      "step": 11960
    },
    {
      "epoch": 0.7095147704354016,
      "grad_norm": 14.640874862670898,
      "learning_rate": 6.45531241761139e-06,
      "loss": 0.1198,
      "step": 11961
    },
    {
      "epoch": 0.7095740894530786,
      "grad_norm": 8.57927131652832,
      "learning_rate": 6.4539941998418146e-06,
      "loss": 0.1389,
      "step": 11962
    },
    {
      "epoch": 0.7096334084707557,
      "grad_norm": 1.7881996631622314,
      "learning_rate": 6.452675982072239e-06,
      "loss": 0.0206,
      "step": 11963
    },
    {
      "epoch": 0.7096927274884328,
      "grad_norm": 38.89045333862305,
      "learning_rate": 6.451357764302664e-06,
      "loss": 0.5484,
      "step": 11964
    },
    {
      "epoch": 0.7097520465061099,
      "grad_norm": 0.2141166478395462,
      "learning_rate": 6.450039546533088e-06,
      "loss": 0.0014,
      "step": 11965
    },
    {
      "epoch": 0.7098113655237869,
      "grad_norm": 0.2634815275669098,
      "learning_rate": 6.448721328763512e-06,
      "loss": 0.0046,
      "step": 11966
    },
    {
      "epoch": 0.709870684541464,
      "grad_norm": 0.0238933227956295,
      "learning_rate": 6.447403110993937e-06,
      "loss": 0.0006,
      "step": 11967
    },
    {
      "epoch": 0.709930003559141,
      "grad_norm": 0.6582068204879761,
      "learning_rate": 6.446084893224361e-06,
      "loss": 0.0032,
      "step": 11968
    },
    {
      "epoch": 0.7099893225768181,
      "grad_norm": 4.122955322265625,
      "learning_rate": 6.4447666754547856e-06,
      "loss": 0.6089,
      "step": 11969
    },
    {
      "epoch": 0.7100486415944952,
      "grad_norm": 5.4532976150512695,
      "learning_rate": 6.44344845768521e-06,
      "loss": 0.0421,
      "step": 11970
    },
    {
      "epoch": 0.7101079606121723,
      "grad_norm": 0.11776198446750641,
      "learning_rate": 6.442130239915635e-06,
      "loss": 0.0028,
      "step": 11971
    },
    {
      "epoch": 0.7101672796298494,
      "grad_norm": 0.10481848567724228,
      "learning_rate": 6.440812022146059e-06,
      "loss": 0.001,
      "step": 11972
    },
    {
      "epoch": 0.7102265986475264,
      "grad_norm": 0.14855153858661652,
      "learning_rate": 6.439493804376483e-06,
      "loss": 0.0033,
      "step": 11973
    },
    {
      "epoch": 0.7102859176652034,
      "grad_norm": 0.006324366666376591,
      "learning_rate": 6.438175586606908e-06,
      "loss": 0.0002,
      "step": 11974
    },
    {
      "epoch": 0.7103452366828805,
      "grad_norm": 0.008974166586995125,
      "learning_rate": 6.436857368837332e-06,
      "loss": 0.0002,
      "step": 11975
    },
    {
      "epoch": 0.7104045557005576,
      "grad_norm": 1.2656328678131104,
      "learning_rate": 6.435539151067757e-06,
      "loss": 0.0249,
      "step": 11976
    },
    {
      "epoch": 0.7104638747182347,
      "grad_norm": 22.489500045776367,
      "learning_rate": 6.434220933298181e-06,
      "loss": 0.1906,
      "step": 11977
    },
    {
      "epoch": 0.7105231937359118,
      "grad_norm": 0.0984966978430748,
      "learning_rate": 6.432902715528606e-06,
      "loss": 0.0012,
      "step": 11978
    },
    {
      "epoch": 0.7105825127535887,
      "grad_norm": 0.02118232101202011,
      "learning_rate": 6.43158449775903e-06,
      "loss": 0.0005,
      "step": 11979
    },
    {
      "epoch": 0.7106418317712658,
      "grad_norm": 3.4700605869293213,
      "learning_rate": 6.430266279989454e-06,
      "loss": 0.0424,
      "step": 11980
    },
    {
      "epoch": 0.7107011507889429,
      "grad_norm": 0.44402551651000977,
      "learning_rate": 6.42894806221988e-06,
      "loss": 0.0073,
      "step": 11981
    },
    {
      "epoch": 0.71076046980662,
      "grad_norm": 24.992000579833984,
      "learning_rate": 6.427629844450303e-06,
      "loss": 0.2846,
      "step": 11982
    },
    {
      "epoch": 0.7108197888242971,
      "grad_norm": 0.03099256381392479,
      "learning_rate": 6.426311626680728e-06,
      "loss": 0.0009,
      "step": 11983
    },
    {
      "epoch": 0.7108791078419742,
      "grad_norm": 0.07231585681438446,
      "learning_rate": 6.4249934089111535e-06,
      "loss": 0.0017,
      "step": 11984
    },
    {
      "epoch": 0.7109384268596513,
      "grad_norm": 1.0670256614685059,
      "learning_rate": 6.423675191141578e-06,
      "loss": 0.0232,
      "step": 11985
    },
    {
      "epoch": 0.7109977458773282,
      "grad_norm": 0.12501612305641174,
      "learning_rate": 6.422356973372002e-06,
      "loss": 0.0027,
      "step": 11986
    },
    {
      "epoch": 0.7110570648950053,
      "grad_norm": 34.08909225463867,
      "learning_rate": 6.421038755602426e-06,
      "loss": 0.3675,
      "step": 11987
    },
    {
      "epoch": 0.7111163839126824,
      "grad_norm": 31.87097930908203,
      "learning_rate": 6.419720537832851e-06,
      "loss": 0.3696,
      "step": 11988
    },
    {
      "epoch": 0.7111757029303595,
      "grad_norm": 0.5581191182136536,
      "learning_rate": 6.418402320063275e-06,
      "loss": 0.0103,
      "step": 11989
    },
    {
      "epoch": 0.7112350219480366,
      "grad_norm": 21.690446853637695,
      "learning_rate": 6.4170841022936994e-06,
      "loss": 0.684,
      "step": 11990
    },
    {
      "epoch": 0.7112943409657136,
      "grad_norm": 13.647205352783203,
      "learning_rate": 6.4157658845241245e-06,
      "loss": 0.5235,
      "step": 11991
    },
    {
      "epoch": 0.7113536599833907,
      "grad_norm": 3.275362730026245,
      "learning_rate": 6.414447666754549e-06,
      "loss": 0.0541,
      "step": 11992
    },
    {
      "epoch": 0.7114129790010677,
      "grad_norm": 33.616943359375,
      "learning_rate": 6.413129448984973e-06,
      "loss": 0.2601,
      "step": 11993
    },
    {
      "epoch": 0.7114722980187448,
      "grad_norm": 16.650287628173828,
      "learning_rate": 6.411811231215397e-06,
      "loss": 0.4576,
      "step": 11994
    },
    {
      "epoch": 0.7115316170364219,
      "grad_norm": 3.9108588695526123,
      "learning_rate": 6.410493013445822e-06,
      "loss": 0.0148,
      "step": 11995
    },
    {
      "epoch": 0.711590936054099,
      "grad_norm": 0.1097438707947731,
      "learning_rate": 6.409174795676246e-06,
      "loss": 0.0022,
      "step": 11996
    },
    {
      "epoch": 0.711650255071776,
      "grad_norm": 1.626397728919983,
      "learning_rate": 6.4078565779066704e-06,
      "loss": 0.0124,
      "step": 11997
    },
    {
      "epoch": 0.7117095740894531,
      "grad_norm": 0.13348586857318878,
      "learning_rate": 6.4065383601370955e-06,
      "loss": 0.0013,
      "step": 11998
    },
    {
      "epoch": 0.7117688931071301,
      "grad_norm": 0.3877837657928467,
      "learning_rate": 6.40522014236752e-06,
      "loss": 0.0046,
      "step": 11999
    },
    {
      "epoch": 0.7118282121248072,
      "grad_norm": 4.405481338500977,
      "learning_rate": 6.403901924597944e-06,
      "loss": 0.0834,
      "step": 12000
    },
    {
      "epoch": 0.7118875311424843,
      "grad_norm": 11.773083686828613,
      "learning_rate": 6.402583706828368e-06,
      "loss": 0.3469,
      "step": 12001
    },
    {
      "epoch": 0.7119468501601613,
      "grad_norm": 0.5537936091423035,
      "learning_rate": 6.401265489058793e-06,
      "loss": 0.0065,
      "step": 12002
    },
    {
      "epoch": 0.7120061691778384,
      "grad_norm": 8.5032320022583,
      "learning_rate": 6.399947271289217e-06,
      "loss": 0.0546,
      "step": 12003
    },
    {
      "epoch": 0.7120654881955155,
      "grad_norm": 10.952306747436523,
      "learning_rate": 6.3986290535196414e-06,
      "loss": 0.0484,
      "step": 12004
    },
    {
      "epoch": 0.7121248072131926,
      "grad_norm": 0.02201630361378193,
      "learning_rate": 6.3973108357500665e-06,
      "loss": 0.0006,
      "step": 12005
    },
    {
      "epoch": 0.7121841262308696,
      "grad_norm": 0.12758012115955353,
      "learning_rate": 6.395992617980491e-06,
      "loss": 0.0023,
      "step": 12006
    },
    {
      "epoch": 0.7122434452485467,
      "grad_norm": 0.04456978291273117,
      "learning_rate": 6.394674400210915e-06,
      "loss": 0.0009,
      "step": 12007
    },
    {
      "epoch": 0.7123027642662237,
      "grad_norm": 0.02321973815560341,
      "learning_rate": 6.393356182441341e-06,
      "loss": 0.0005,
      "step": 12008
    },
    {
      "epoch": 0.7123620832839008,
      "grad_norm": 0.14072810113430023,
      "learning_rate": 6.392037964671765e-06,
      "loss": 0.0008,
      "step": 12009
    },
    {
      "epoch": 0.7124214023015779,
      "grad_norm": 0.007367517799139023,
      "learning_rate": 6.390719746902188e-06,
      "loss": 0.0002,
      "step": 12010
    },
    {
      "epoch": 0.712480721319255,
      "grad_norm": 8.866175651550293,
      "learning_rate": 6.3894015291326124e-06,
      "loss": 0.0886,
      "step": 12011
    },
    {
      "epoch": 0.712540040336932,
      "grad_norm": 0.16930824518203735,
      "learning_rate": 6.388083311363038e-06,
      "loss": 0.0024,
      "step": 12012
    },
    {
      "epoch": 0.712599359354609,
      "grad_norm": 0.010324490256607533,
      "learning_rate": 6.3867650935934625e-06,
      "loss": 0.0003,
      "step": 12013
    },
    {
      "epoch": 0.7126586783722861,
      "grad_norm": 0.1853708177804947,
      "learning_rate": 6.385446875823887e-06,
      "loss": 0.0033,
      "step": 12014
    },
    {
      "epoch": 0.7127179973899632,
      "grad_norm": 0.11481013894081116,
      "learning_rate": 6.384128658054312e-06,
      "loss": 0.002,
      "step": 12015
    },
    {
      "epoch": 0.7127773164076403,
      "grad_norm": 0.05661281198263168,
      "learning_rate": 6.382810440284736e-06,
      "loss": 0.0008,
      "step": 12016
    },
    {
      "epoch": 0.7128366354253174,
      "grad_norm": 13.017549514770508,
      "learning_rate": 6.38149222251516e-06,
      "loss": 0.1082,
      "step": 12017
    },
    {
      "epoch": 0.7128959544429945,
      "grad_norm": 6.108008861541748,
      "learning_rate": 6.380174004745584e-06,
      "loss": 0.3153,
      "step": 12018
    },
    {
      "epoch": 0.7129552734606714,
      "grad_norm": 15.031213760375977,
      "learning_rate": 6.378855786976009e-06,
      "loss": 0.7341,
      "step": 12019
    },
    {
      "epoch": 0.7130145924783485,
      "grad_norm": 41.22404861450195,
      "learning_rate": 6.3775375692064335e-06,
      "loss": 0.4621,
      "step": 12020
    },
    {
      "epoch": 0.7130739114960256,
      "grad_norm": 0.01620776578783989,
      "learning_rate": 6.376219351436858e-06,
      "loss": 0.0004,
      "step": 12021
    },
    {
      "epoch": 0.7131332305137027,
      "grad_norm": 0.07935401797294617,
      "learning_rate": 6.374901133667283e-06,
      "loss": 0.0009,
      "step": 12022
    },
    {
      "epoch": 0.7131925495313798,
      "grad_norm": 0.008352051489055157,
      "learning_rate": 6.373582915897707e-06,
      "loss": 0.0002,
      "step": 12023
    },
    {
      "epoch": 0.7132518685490569,
      "grad_norm": 0.4379803538322449,
      "learning_rate": 6.372264698128131e-06,
      "loss": 0.0036,
      "step": 12024
    },
    {
      "epoch": 0.7133111875667338,
      "grad_norm": 8.397893905639648,
      "learning_rate": 6.370946480358555e-06,
      "loss": 0.3708,
      "step": 12025
    },
    {
      "epoch": 0.7133705065844109,
      "grad_norm": 0.22845134139060974,
      "learning_rate": 6.36962826258898e-06,
      "loss": 0.0021,
      "step": 12026
    },
    {
      "epoch": 0.713429825602088,
      "grad_norm": 2.935436725616455,
      "learning_rate": 6.3683100448194045e-06,
      "loss": 0.0151,
      "step": 12027
    },
    {
      "epoch": 0.7134891446197651,
      "grad_norm": 0.7908744812011719,
      "learning_rate": 6.366991827049829e-06,
      "loss": 0.0097,
      "step": 12028
    },
    {
      "epoch": 0.7135484636374422,
      "grad_norm": 0.1121884286403656,
      "learning_rate": 6.365673609280254e-06,
      "loss": 0.0018,
      "step": 12029
    },
    {
      "epoch": 0.7136077826551193,
      "grad_norm": 0.06290731579065323,
      "learning_rate": 6.364355391510678e-06,
      "loss": 0.0011,
      "step": 12030
    },
    {
      "epoch": 0.7136671016727963,
      "grad_norm": 46.40229034423828,
      "learning_rate": 6.363037173741102e-06,
      "loss": 0.3663,
      "step": 12031
    },
    {
      "epoch": 0.7137264206904733,
      "grad_norm": 4.11865758895874,
      "learning_rate": 6.361718955971527e-06,
      "loss": 0.0493,
      "step": 12032
    },
    {
      "epoch": 0.7137857397081504,
      "grad_norm": 18.813133239746094,
      "learning_rate": 6.360400738201951e-06,
      "loss": 0.3918,
      "step": 12033
    },
    {
      "epoch": 0.7138450587258275,
      "grad_norm": 10.240772247314453,
      "learning_rate": 6.3590825204323755e-06,
      "loss": 0.0438,
      "step": 12034
    },
    {
      "epoch": 0.7139043777435046,
      "grad_norm": 0.0300804041326046,
      "learning_rate": 6.3577643026628e-06,
      "loss": 0.0009,
      "step": 12035
    },
    {
      "epoch": 0.7139636967611817,
      "grad_norm": 0.04346206411719322,
      "learning_rate": 6.356446084893226e-06,
      "loss": 0.0012,
      "step": 12036
    },
    {
      "epoch": 0.7140230157788587,
      "grad_norm": 2.8130784034729004,
      "learning_rate": 6.35512786712365e-06,
      "loss": 0.0212,
      "step": 12037
    },
    {
      "epoch": 0.7140823347965358,
      "grad_norm": 28.004789352416992,
      "learning_rate": 6.353809649354073e-06,
      "loss": 0.8517,
      "step": 12038
    },
    {
      "epoch": 0.7141416538142128,
      "grad_norm": 0.012082288973033428,
      "learning_rate": 6.352491431584499e-06,
      "loss": 0.0003,
      "step": 12039
    },
    {
      "epoch": 0.7142009728318899,
      "grad_norm": 1.8403946161270142,
      "learning_rate": 6.351173213814923e-06,
      "loss": 0.0045,
      "step": 12040
    },
    {
      "epoch": 0.714260291849567,
      "grad_norm": 0.01668318174779415,
      "learning_rate": 6.349854996045347e-06,
      "loss": 0.0005,
      "step": 12041
    },
    {
      "epoch": 0.714319610867244,
      "grad_norm": 0.02498289942741394,
      "learning_rate": 6.3485367782757716e-06,
      "loss": 0.0006,
      "step": 12042
    },
    {
      "epoch": 0.7143789298849211,
      "grad_norm": 0.4881303608417511,
      "learning_rate": 6.347218560506197e-06,
      "loss": 0.0054,
      "step": 12043
    },
    {
      "epoch": 0.7144382489025982,
      "grad_norm": 13.035284042358398,
      "learning_rate": 6.345900342736621e-06,
      "loss": 0.2165,
      "step": 12044
    },
    {
      "epoch": 0.7144975679202752,
      "grad_norm": 11.069695472717285,
      "learning_rate": 6.344582124967045e-06,
      "loss": 1.4601,
      "step": 12045
    },
    {
      "epoch": 0.7145568869379523,
      "grad_norm": 0.048479098826646805,
      "learning_rate": 6.34326390719747e-06,
      "loss": 0.0005,
      "step": 12046
    },
    {
      "epoch": 0.7146162059556294,
      "grad_norm": 8.461345672607422,
      "learning_rate": 6.341945689427894e-06,
      "loss": 0.2057,
      "step": 12047
    },
    {
      "epoch": 0.7146755249733064,
      "grad_norm": 0.371773362159729,
      "learning_rate": 6.340627471658318e-06,
      "loss": 0.0032,
      "step": 12048
    },
    {
      "epoch": 0.7147348439909835,
      "grad_norm": 3.518763542175293,
      "learning_rate": 6.3393092538887426e-06,
      "loss": 0.0652,
      "step": 12049
    },
    {
      "epoch": 0.7147941630086606,
      "grad_norm": 0.028820887207984924,
      "learning_rate": 6.337991036119168e-06,
      "loss": 0.0008,
      "step": 12050
    },
    {
      "epoch": 0.7148534820263377,
      "grad_norm": 12.811169624328613,
      "learning_rate": 6.336672818349592e-06,
      "loss": 0.1413,
      "step": 12051
    },
    {
      "epoch": 0.7149128010440147,
      "grad_norm": 0.04467269405722618,
      "learning_rate": 6.335354600580016e-06,
      "loss": 0.001,
      "step": 12052
    },
    {
      "epoch": 0.7149721200616918,
      "grad_norm": 0.10924796760082245,
      "learning_rate": 6.334036382810441e-06,
      "loss": 0.0023,
      "step": 12053
    },
    {
      "epoch": 0.7150314390793688,
      "grad_norm": 27.97442626953125,
      "learning_rate": 6.332718165040865e-06,
      "loss": 0.2516,
      "step": 12054
    },
    {
      "epoch": 0.7150907580970459,
      "grad_norm": 0.00850911345332861,
      "learning_rate": 6.331399947271289e-06,
      "loss": 0.0003,
      "step": 12055
    },
    {
      "epoch": 0.715150077114723,
      "grad_norm": 10.251203536987305,
      "learning_rate": 6.330081729501714e-06,
      "loss": 0.0828,
      "step": 12056
    },
    {
      "epoch": 0.7152093961324001,
      "grad_norm": 0.020573243498802185,
      "learning_rate": 6.328763511732139e-06,
      "loss": 0.0004,
      "step": 12057
    },
    {
      "epoch": 0.7152687151500771,
      "grad_norm": 0.8030105829238892,
      "learning_rate": 6.327445293962563e-06,
      "loss": 0.015,
      "step": 12058
    },
    {
      "epoch": 0.7153280341677541,
      "grad_norm": 0.8051074743270874,
      "learning_rate": 6.326127076192987e-06,
      "loss": 0.006,
      "step": 12059
    },
    {
      "epoch": 0.7153873531854312,
      "grad_norm": 0.22415070235729218,
      "learning_rate": 6.324808858423412e-06,
      "loss": 0.0016,
      "step": 12060
    },
    {
      "epoch": 0.7154466722031083,
      "grad_norm": 1.366788625717163,
      "learning_rate": 6.323490640653836e-06,
      "loss": 0.0033,
      "step": 12061
    },
    {
      "epoch": 0.7155059912207854,
      "grad_norm": 16.26974868774414,
      "learning_rate": 6.32217242288426e-06,
      "loss": 0.2228,
      "step": 12062
    },
    {
      "epoch": 0.7155653102384625,
      "grad_norm": 1.0543252229690552,
      "learning_rate": 6.320854205114686e-06,
      "loss": 0.0096,
      "step": 12063
    },
    {
      "epoch": 0.7156246292561396,
      "grad_norm": 2.222254753112793,
      "learning_rate": 6.3195359873451105e-06,
      "loss": 0.0202,
      "step": 12064
    },
    {
      "epoch": 0.7156839482738165,
      "grad_norm": 6.308795928955078,
      "learning_rate": 6.318217769575535e-06,
      "loss": 0.1176,
      "step": 12065
    },
    {
      "epoch": 0.7157432672914936,
      "grad_norm": 0.05196090415120125,
      "learning_rate": 6.316899551805958e-06,
      "loss": 0.0008,
      "step": 12066
    },
    {
      "epoch": 0.7158025863091707,
      "grad_norm": 0.05338381603360176,
      "learning_rate": 6.315581334036384e-06,
      "loss": 0.0007,
      "step": 12067
    },
    {
      "epoch": 0.7158619053268478,
      "grad_norm": 10.274495124816895,
      "learning_rate": 6.314263116266808e-06,
      "loss": 0.0464,
      "step": 12068
    },
    {
      "epoch": 0.7159212243445249,
      "grad_norm": 10.378466606140137,
      "learning_rate": 6.312944898497232e-06,
      "loss": 0.2159,
      "step": 12069
    },
    {
      "epoch": 0.715980543362202,
      "grad_norm": 4.931375980377197,
      "learning_rate": 6.311626680727657e-06,
      "loss": 0.0374,
      "step": 12070
    },
    {
      "epoch": 0.716039862379879,
      "grad_norm": 0.25533148646354675,
      "learning_rate": 6.3103084629580815e-06,
      "loss": 0.0016,
      "step": 12071
    },
    {
      "epoch": 0.716099181397556,
      "grad_norm": 10.024704933166504,
      "learning_rate": 6.308990245188506e-06,
      "loss": 0.1277,
      "step": 12072
    },
    {
      "epoch": 0.7161585004152331,
      "grad_norm": 2.532787322998047,
      "learning_rate": 6.30767202741893e-06,
      "loss": 0.0668,
      "step": 12073
    },
    {
      "epoch": 0.7162178194329102,
      "grad_norm": 21.695688247680664,
      "learning_rate": 6.306353809649355e-06,
      "loss": 1.048,
      "step": 12074
    },
    {
      "epoch": 0.7162771384505873,
      "grad_norm": 5.593442440032959,
      "learning_rate": 6.305035591879779e-06,
      "loss": 0.0255,
      "step": 12075
    },
    {
      "epoch": 0.7163364574682644,
      "grad_norm": 0.0077803609892725945,
      "learning_rate": 6.303717374110203e-06,
      "loss": 0.0002,
      "step": 12076
    },
    {
      "epoch": 0.7163957764859414,
      "grad_norm": 0.16505751013755798,
      "learning_rate": 6.302399156340628e-06,
      "loss": 0.002,
      "step": 12077
    },
    {
      "epoch": 0.7164550955036184,
      "grad_norm": 0.05977076292037964,
      "learning_rate": 6.3010809385710525e-06,
      "loss": 0.0007,
      "step": 12078
    },
    {
      "epoch": 0.7165144145212955,
      "grad_norm": 5.55943489074707,
      "learning_rate": 6.299762720801477e-06,
      "loss": 0.0288,
      "step": 12079
    },
    {
      "epoch": 0.7165737335389726,
      "grad_norm": 0.009518907405436039,
      "learning_rate": 6.298444503031902e-06,
      "loss": 0.0002,
      "step": 12080
    },
    {
      "epoch": 0.7166330525566497,
      "grad_norm": 0.00878513976931572,
      "learning_rate": 6.297126285262326e-06,
      "loss": 0.0003,
      "step": 12081
    },
    {
      "epoch": 0.7166923715743267,
      "grad_norm": 5.260044574737549,
      "learning_rate": 6.29580806749275e-06,
      "loss": 0.0906,
      "step": 12082
    },
    {
      "epoch": 0.7167516905920038,
      "grad_norm": 2.558727741241455,
      "learning_rate": 6.294489849723174e-06,
      "loss": 0.0072,
      "step": 12083
    },
    {
      "epoch": 0.7168110096096809,
      "grad_norm": 5.701132297515869,
      "learning_rate": 6.293171631953599e-06,
      "loss": 0.1432,
      "step": 12084
    },
    {
      "epoch": 0.7168703286273579,
      "grad_norm": 0.28938180208206177,
      "learning_rate": 6.2918534141840235e-06,
      "loss": 0.0025,
      "step": 12085
    },
    {
      "epoch": 0.716929647645035,
      "grad_norm": 0.02393694780766964,
      "learning_rate": 6.290535196414448e-06,
      "loss": 0.0004,
      "step": 12086
    },
    {
      "epoch": 0.7169889666627121,
      "grad_norm": 6.366391181945801,
      "learning_rate": 6.2892169786448735e-06,
      "loss": 0.1681,
      "step": 12087
    },
    {
      "epoch": 0.7170482856803891,
      "grad_norm": 0.007518680300563574,
      "learning_rate": 6.287898760875297e-06,
      "loss": 0.0002,
      "step": 12088
    },
    {
      "epoch": 0.7171076046980662,
      "grad_norm": 24.075952529907227,
      "learning_rate": 6.286580543105721e-06,
      "loss": 0.2109,
      "step": 12089
    },
    {
      "epoch": 0.7171669237157433,
      "grad_norm": 0.11265971511602402,
      "learning_rate": 6.285262325336145e-06,
      "loss": 0.0014,
      "step": 12090
    },
    {
      "epoch": 0.7172262427334203,
      "grad_norm": 0.3388559818267822,
      "learning_rate": 6.283944107566571e-06,
      "loss": 0.0041,
      "step": 12091
    },
    {
      "epoch": 0.7172855617510974,
      "grad_norm": 0.28992679715156555,
      "learning_rate": 6.282625889796995e-06,
      "loss": 0.0035,
      "step": 12092
    },
    {
      "epoch": 0.7173448807687745,
      "grad_norm": 0.18791133165359497,
      "learning_rate": 6.2813076720274195e-06,
      "loss": 0.0033,
      "step": 12093
    },
    {
      "epoch": 0.7174041997864515,
      "grad_norm": 0.3251740634441376,
      "learning_rate": 6.2799894542578445e-06,
      "loss": 0.0035,
      "step": 12094
    },
    {
      "epoch": 0.7174635188041286,
      "grad_norm": 0.0955289900302887,
      "learning_rate": 6.278671236488269e-06,
      "loss": 0.0012,
      "step": 12095
    },
    {
      "epoch": 0.7175228378218057,
      "grad_norm": 0.1745234578847885,
      "learning_rate": 6.277353018718693e-06,
      "loss": 0.0022,
      "step": 12096
    },
    {
      "epoch": 0.7175821568394828,
      "grad_norm": 0.029973406344652176,
      "learning_rate": 6.276034800949117e-06,
      "loss": 0.0006,
      "step": 12097
    },
    {
      "epoch": 0.7176414758571598,
      "grad_norm": 0.024135302752256393,
      "learning_rate": 6.274716583179542e-06,
      "loss": 0.0006,
      "step": 12098
    },
    {
      "epoch": 0.7177007948748368,
      "grad_norm": 2.8198940753936768,
      "learning_rate": 6.273398365409966e-06,
      "loss": 0.0347,
      "step": 12099
    },
    {
      "epoch": 0.7177601138925139,
      "grad_norm": 14.28780460357666,
      "learning_rate": 6.2720801476403905e-06,
      "loss": 0.6258,
      "step": 12100
    },
    {
      "epoch": 0.717819432910191,
      "grad_norm": 14.57934284210205,
      "learning_rate": 6.2707619298708155e-06,
      "loss": 0.4702,
      "step": 12101
    },
    {
      "epoch": 0.7178787519278681,
      "grad_norm": 21.160205841064453,
      "learning_rate": 6.26944371210124e-06,
      "loss": 0.4238,
      "step": 12102
    },
    {
      "epoch": 0.7179380709455452,
      "grad_norm": 0.2277241349220276,
      "learning_rate": 6.268125494331664e-06,
      "loss": 0.0041,
      "step": 12103
    },
    {
      "epoch": 0.7179973899632222,
      "grad_norm": 26.167911529541016,
      "learning_rate": 6.266807276562089e-06,
      "loss": 0.9905,
      "step": 12104
    },
    {
      "epoch": 0.7180567089808992,
      "grad_norm": 19.30552864074707,
      "learning_rate": 6.265489058792513e-06,
      "loss": 1.0596,
      "step": 12105
    },
    {
      "epoch": 0.7181160279985763,
      "grad_norm": 3.0561633110046387,
      "learning_rate": 6.264170841022937e-06,
      "loss": 0.0148,
      "step": 12106
    },
    {
      "epoch": 0.7181753470162534,
      "grad_norm": 4.788821697235107,
      "learning_rate": 6.2628526232533615e-06,
      "loss": 0.1278,
      "step": 12107
    },
    {
      "epoch": 0.7182346660339305,
      "grad_norm": 12.59239673614502,
      "learning_rate": 6.2615344054837865e-06,
      "loss": 0.0664,
      "step": 12108
    },
    {
      "epoch": 0.7182939850516076,
      "grad_norm": 1.7404065132141113,
      "learning_rate": 6.260216187714211e-06,
      "loss": 0.0226,
      "step": 12109
    },
    {
      "epoch": 0.7183533040692847,
      "grad_norm": 0.022258581593632698,
      "learning_rate": 6.258897969944635e-06,
      "loss": 0.0005,
      "step": 12110
    },
    {
      "epoch": 0.7184126230869616,
      "grad_norm": 0.03063850663602352,
      "learning_rate": 6.25757975217506e-06,
      "loss": 0.0008,
      "step": 12111
    },
    {
      "epoch": 0.7184719421046387,
      "grad_norm": 0.31827670335769653,
      "learning_rate": 6.256261534405484e-06,
      "loss": 0.0032,
      "step": 12112
    },
    {
      "epoch": 0.7185312611223158,
      "grad_norm": 7.838045120239258,
      "learning_rate": 6.254943316635908e-06,
      "loss": 0.034,
      "step": 12113
    },
    {
      "epoch": 0.7185905801399929,
      "grad_norm": 1.9343857765197754,
      "learning_rate": 6.2536250988663325e-06,
      "loss": 0.0238,
      "step": 12114
    },
    {
      "epoch": 0.71864989915767,
      "grad_norm": 0.08732990175485611,
      "learning_rate": 6.252306881096758e-06,
      "loss": 0.0013,
      "step": 12115
    },
    {
      "epoch": 0.718709218175347,
      "grad_norm": 0.02273089438676834,
      "learning_rate": 6.250988663327182e-06,
      "loss": 0.0006,
      "step": 12116
    },
    {
      "epoch": 0.7187685371930241,
      "grad_norm": 7.833085536956787,
      "learning_rate": 6.249670445557606e-06,
      "loss": 0.1018,
      "step": 12117
    },
    {
      "epoch": 0.7188278562107011,
      "grad_norm": 0.22435040771961212,
      "learning_rate": 6.248352227788032e-06,
      "loss": 0.0026,
      "step": 12118
    },
    {
      "epoch": 0.7188871752283782,
      "grad_norm": 0.08276178687810898,
      "learning_rate": 6.247034010018456e-06,
      "loss": 0.0012,
      "step": 12119
    },
    {
      "epoch": 0.7189464942460553,
      "grad_norm": 0.05665868893265724,
      "learning_rate": 6.24571579224888e-06,
      "loss": 0.0008,
      "step": 12120
    },
    {
      "epoch": 0.7190058132637324,
      "grad_norm": 0.015174788422882557,
      "learning_rate": 6.244397574479304e-06,
      "loss": 0.0004,
      "step": 12121
    },
    {
      "epoch": 0.7190651322814094,
      "grad_norm": 0.26275938749313354,
      "learning_rate": 6.243079356709729e-06,
      "loss": 0.0036,
      "step": 12122
    },
    {
      "epoch": 0.7191244512990865,
      "grad_norm": 0.012722213752567768,
      "learning_rate": 6.241761138940154e-06,
      "loss": 0.0003,
      "step": 12123
    },
    {
      "epoch": 0.7191837703167635,
      "grad_norm": 20.253068923950195,
      "learning_rate": 6.240442921170578e-06,
      "loss": 0.2774,
      "step": 12124
    },
    {
      "epoch": 0.7192430893344406,
      "grad_norm": 5.274514675140381,
      "learning_rate": 6.239124703401003e-06,
      "loss": 0.0914,
      "step": 12125
    },
    {
      "epoch": 0.7193024083521177,
      "grad_norm": 12.90932846069336,
      "learning_rate": 6.237806485631427e-06,
      "loss": 0.0286,
      "step": 12126
    },
    {
      "epoch": 0.7193617273697948,
      "grad_norm": 0.8298979997634888,
      "learning_rate": 6.236488267861851e-06,
      "loss": 0.009,
      "step": 12127
    },
    {
      "epoch": 0.7194210463874718,
      "grad_norm": 0.33081507682800293,
      "learning_rate": 6.235170050092276e-06,
      "loss": 0.0017,
      "step": 12128
    },
    {
      "epoch": 0.7194803654051489,
      "grad_norm": 0.08558014035224915,
      "learning_rate": 6.2338518323227e-06,
      "loss": 0.0012,
      "step": 12129
    },
    {
      "epoch": 0.719539684422826,
      "grad_norm": 0.13626253604888916,
      "learning_rate": 6.232533614553125e-06,
      "loss": 0.0012,
      "step": 12130
    },
    {
      "epoch": 0.719599003440503,
      "grad_norm": 7.185100555419922,
      "learning_rate": 6.231215396783549e-06,
      "loss": 0.121,
      "step": 12131
    },
    {
      "epoch": 0.7196583224581801,
      "grad_norm": 0.1335100531578064,
      "learning_rate": 6.229897179013974e-06,
      "loss": 0.0017,
      "step": 12132
    },
    {
      "epoch": 0.7197176414758572,
      "grad_norm": 0.0490441657602787,
      "learning_rate": 6.228578961244398e-06,
      "loss": 0.0011,
      "step": 12133
    },
    {
      "epoch": 0.7197769604935342,
      "grad_norm": 0.5210866928100586,
      "learning_rate": 6.227260743474822e-06,
      "loss": 0.0082,
      "step": 12134
    },
    {
      "epoch": 0.7198362795112113,
      "grad_norm": 0.008569600060582161,
      "learning_rate": 6.225942525705247e-06,
      "loss": 0.0002,
      "step": 12135
    },
    {
      "epoch": 0.7198955985288884,
      "grad_norm": 7.554599285125732,
      "learning_rate": 6.224624307935671e-06,
      "loss": 0.0848,
      "step": 12136
    },
    {
      "epoch": 0.7199549175465654,
      "grad_norm": 0.5608360767364502,
      "learning_rate": 6.223306090166096e-06,
      "loss": 0.0027,
      "step": 12137
    },
    {
      "epoch": 0.7200142365642425,
      "grad_norm": 0.517744243144989,
      "learning_rate": 6.22198787239652e-06,
      "loss": 0.0054,
      "step": 12138
    },
    {
      "epoch": 0.7200735555819195,
      "grad_norm": 0.03563592955470085,
      "learning_rate": 6.220669654626945e-06,
      "loss": 0.0006,
      "step": 12139
    },
    {
      "epoch": 0.7201328745995966,
      "grad_norm": 0.00436123413965106,
      "learning_rate": 6.219351436857369e-06,
      "loss": 0.0001,
      "step": 12140
    },
    {
      "epoch": 0.7201921936172737,
      "grad_norm": 0.019607799127697945,
      "learning_rate": 6.218033219087793e-06,
      "loss": 0.0005,
      "step": 12141
    },
    {
      "epoch": 0.7202515126349508,
      "grad_norm": 2.3987174034118652,
      "learning_rate": 6.216715001318219e-06,
      "loss": 0.011,
      "step": 12142
    },
    {
      "epoch": 0.7203108316526279,
      "grad_norm": 10.644916534423828,
      "learning_rate": 6.215396783548643e-06,
      "loss": 0.102,
      "step": 12143
    },
    {
      "epoch": 0.7203701506703049,
      "grad_norm": 6.734808444976807,
      "learning_rate": 6.214078565779067e-06,
      "loss": 0.0334,
      "step": 12144
    },
    {
      "epoch": 0.7204294696879819,
      "grad_norm": 10.190899848937988,
      "learning_rate": 6.212760348009491e-06,
      "loss": 0.0965,
      "step": 12145
    },
    {
      "epoch": 0.720488788705659,
      "grad_norm": 6.555980682373047,
      "learning_rate": 6.211442130239917e-06,
      "loss": 0.6237,
      "step": 12146
    },
    {
      "epoch": 0.7205481077233361,
      "grad_norm": 0.09034478664398193,
      "learning_rate": 6.210123912470341e-06,
      "loss": 0.0016,
      "step": 12147
    },
    {
      "epoch": 0.7206074267410132,
      "grad_norm": 0.10036839544773102,
      "learning_rate": 6.208805694700765e-06,
      "loss": 0.0016,
      "step": 12148
    },
    {
      "epoch": 0.7206667457586903,
      "grad_norm": 3.3273699283599854,
      "learning_rate": 6.20748747693119e-06,
      "loss": 0.0367,
      "step": 12149
    },
    {
      "epoch": 0.7207260647763672,
      "grad_norm": 1.7191497087478638,
      "learning_rate": 6.206169259161614e-06,
      "loss": 0.015,
      "step": 12150
    },
    {
      "epoch": 0.7207853837940443,
      "grad_norm": 0.09864114969968796,
      "learning_rate": 6.2048510413920384e-06,
      "loss": 0.0013,
      "step": 12151
    },
    {
      "epoch": 0.7208447028117214,
      "grad_norm": 0.2502198815345764,
      "learning_rate": 6.2035328236224635e-06,
      "loss": 0.0018,
      "step": 12152
    },
    {
      "epoch": 0.7209040218293985,
      "grad_norm": 0.22421513497829437,
      "learning_rate": 6.202214605852888e-06,
      "loss": 0.003,
      "step": 12153
    },
    {
      "epoch": 0.7209633408470756,
      "grad_norm": 0.2534598708152771,
      "learning_rate": 6.200896388083312e-06,
      "loss": 0.0029,
      "step": 12154
    },
    {
      "epoch": 0.7210226598647527,
      "grad_norm": 22.25530242919922,
      "learning_rate": 6.199578170313736e-06,
      "loss": 0.9694,
      "step": 12155
    },
    {
      "epoch": 0.7210819788824298,
      "grad_norm": 4.640318393707275,
      "learning_rate": 6.198259952544161e-06,
      "loss": 0.0208,
      "step": 12156
    },
    {
      "epoch": 0.7211412979001067,
      "grad_norm": 0.9079769849777222,
      "learning_rate": 6.196941734774585e-06,
      "loss": 0.0057,
      "step": 12157
    },
    {
      "epoch": 0.7212006169177838,
      "grad_norm": 0.23336829245090485,
      "learning_rate": 6.1956235170050095e-06,
      "loss": 0.0032,
      "step": 12158
    },
    {
      "epoch": 0.7212599359354609,
      "grad_norm": 0.026727523654699326,
      "learning_rate": 6.1943052992354345e-06,
      "loss": 0.0004,
      "step": 12159
    },
    {
      "epoch": 0.721319254953138,
      "grad_norm": 1.8850431442260742,
      "learning_rate": 6.192987081465859e-06,
      "loss": 0.0035,
      "step": 12160
    },
    {
      "epoch": 0.7213785739708151,
      "grad_norm": 3.577240228652954,
      "learning_rate": 6.191668863696283e-06,
      "loss": 0.036,
      "step": 12161
    },
    {
      "epoch": 0.7214378929884921,
      "grad_norm": 8.647988319396973,
      "learning_rate": 6.190350645926707e-06,
      "loss": 0.2381,
      "step": 12162
    },
    {
      "epoch": 0.7214972120061692,
      "grad_norm": 2.226249933242798,
      "learning_rate": 6.189032428157132e-06,
      "loss": 0.0188,
      "step": 12163
    },
    {
      "epoch": 0.7215565310238462,
      "grad_norm": 2.33113431930542,
      "learning_rate": 6.187714210387556e-06,
      "loss": 0.0435,
      "step": 12164
    },
    {
      "epoch": 0.7216158500415233,
      "grad_norm": 0.013067236170172691,
      "learning_rate": 6.1863959926179805e-06,
      "loss": 0.0004,
      "step": 12165
    },
    {
      "epoch": 0.7216751690592004,
      "grad_norm": 0.13718707859516144,
      "learning_rate": 6.1850777748484055e-06,
      "loss": 0.001,
      "step": 12166
    },
    {
      "epoch": 0.7217344880768775,
      "grad_norm": 0.1460365206003189,
      "learning_rate": 6.18375955707883e-06,
      "loss": 0.0037,
      "step": 12167
    },
    {
      "epoch": 0.7217938070945545,
      "grad_norm": 5.06788969039917,
      "learning_rate": 6.182441339309254e-06,
      "loss": 0.3423,
      "step": 12168
    },
    {
      "epoch": 0.7218531261122316,
      "grad_norm": 0.07532225549221039,
      "learning_rate": 6.181123121539678e-06,
      "loss": 0.0019,
      "step": 12169
    },
    {
      "epoch": 0.7219124451299086,
      "grad_norm": 1.2894906997680664,
      "learning_rate": 6.179804903770104e-06,
      "loss": 0.0095,
      "step": 12170
    },
    {
      "epoch": 0.7219717641475857,
      "grad_norm": 10.617439270019531,
      "learning_rate": 6.178486686000528e-06,
      "loss": 0.2056,
      "step": 12171
    },
    {
      "epoch": 0.7220310831652628,
      "grad_norm": 0.28451821208000183,
      "learning_rate": 6.1771684682309515e-06,
      "loss": 0.0026,
      "step": 12172
    },
    {
      "epoch": 0.7220904021829399,
      "grad_norm": 3.270066261291504,
      "learning_rate": 6.175850250461377e-06,
      "loss": 0.0126,
      "step": 12173
    },
    {
      "epoch": 0.7221497212006169,
      "grad_norm": 0.046230971813201904,
      "learning_rate": 6.1745320326918015e-06,
      "loss": 0.0006,
      "step": 12174
    },
    {
      "epoch": 0.722209040218294,
      "grad_norm": 11.393190383911133,
      "learning_rate": 6.173213814922226e-06,
      "loss": 0.4698,
      "step": 12175
    },
    {
      "epoch": 0.7222683592359711,
      "grad_norm": 0.41765013337135315,
      "learning_rate": 6.171895597152651e-06,
      "loss": 0.005,
      "step": 12176
    },
    {
      "epoch": 0.7223276782536481,
      "grad_norm": 0.052077312022447586,
      "learning_rate": 6.170577379383075e-06,
      "loss": 0.0007,
      "step": 12177
    },
    {
      "epoch": 0.7223869972713252,
      "grad_norm": 0.049728650599718094,
      "learning_rate": 6.169259161613499e-06,
      "loss": 0.0009,
      "step": 12178
    },
    {
      "epoch": 0.7224463162890022,
      "grad_norm": 0.04863373935222626,
      "learning_rate": 6.167940943843923e-06,
      "loss": 0.0006,
      "step": 12179
    },
    {
      "epoch": 0.7225056353066793,
      "grad_norm": 0.013036469928920269,
      "learning_rate": 6.166622726074348e-06,
      "loss": 0.0004,
      "step": 12180
    },
    {
      "epoch": 0.7225649543243564,
      "grad_norm": 1.4439570903778076,
      "learning_rate": 6.1653045083047725e-06,
      "loss": 0.0209,
      "step": 12181
    },
    {
      "epoch": 0.7226242733420335,
      "grad_norm": 23.99692153930664,
      "learning_rate": 6.163986290535197e-06,
      "loss": 0.6232,
      "step": 12182
    },
    {
      "epoch": 0.7226835923597105,
      "grad_norm": 0.14698752760887146,
      "learning_rate": 6.162668072765622e-06,
      "loss": 0.0039,
      "step": 12183
    },
    {
      "epoch": 0.7227429113773876,
      "grad_norm": 1.0717700719833374,
      "learning_rate": 6.161349854996046e-06,
      "loss": 0.0101,
      "step": 12184
    },
    {
      "epoch": 0.7228022303950646,
      "grad_norm": 0.19106271862983704,
      "learning_rate": 6.16003163722647e-06,
      "loss": 0.0023,
      "step": 12185
    },
    {
      "epoch": 0.7228615494127417,
      "grad_norm": 0.007534864358603954,
      "learning_rate": 6.158713419456894e-06,
      "loss": 0.0002,
      "step": 12186
    },
    {
      "epoch": 0.7229208684304188,
      "grad_norm": 1.6106561422348022,
      "learning_rate": 6.157395201687319e-06,
      "loss": 0.1169,
      "step": 12187
    },
    {
      "epoch": 0.7229801874480959,
      "grad_norm": 10.006091117858887,
      "learning_rate": 6.1560769839177435e-06,
      "loss": 0.098,
      "step": 12188
    },
    {
      "epoch": 0.723039506465773,
      "grad_norm": 15.913918495178223,
      "learning_rate": 6.154758766148168e-06,
      "loss": 0.2627,
      "step": 12189
    },
    {
      "epoch": 0.72309882548345,
      "grad_norm": 0.07346852123737335,
      "learning_rate": 6.153440548378593e-06,
      "loss": 0.0012,
      "step": 12190
    },
    {
      "epoch": 0.723158144501127,
      "grad_norm": 0.018582185730338097,
      "learning_rate": 6.152122330609017e-06,
      "loss": 0.0004,
      "step": 12191
    },
    {
      "epoch": 0.7232174635188041,
      "grad_norm": 0.1903068572282791,
      "learning_rate": 6.150804112839441e-06,
      "loss": 0.0032,
      "step": 12192
    },
    {
      "epoch": 0.7232767825364812,
      "grad_norm": 2.549672842025757,
      "learning_rate": 6.149485895069867e-06,
      "loss": 0.3022,
      "step": 12193
    },
    {
      "epoch": 0.7233361015541583,
      "grad_norm": 3.444554328918457,
      "learning_rate": 6.14816767730029e-06,
      "loss": 0.0175,
      "step": 12194
    },
    {
      "epoch": 0.7233954205718354,
      "grad_norm": 1.7116807699203491,
      "learning_rate": 6.1468494595307145e-06,
      "loss": 0.0161,
      "step": 12195
    },
    {
      "epoch": 0.7234547395895125,
      "grad_norm": 0.06739616394042969,
      "learning_rate": 6.145531241761139e-06,
      "loss": 0.0006,
      "step": 12196
    },
    {
      "epoch": 0.7235140586071894,
      "grad_norm": 0.12180586159229279,
      "learning_rate": 6.144213023991565e-06,
      "loss": 0.0024,
      "step": 12197
    },
    {
      "epoch": 0.7235733776248665,
      "grad_norm": 0.1067769005894661,
      "learning_rate": 6.142894806221989e-06,
      "loss": 0.0023,
      "step": 12198
    },
    {
      "epoch": 0.7236326966425436,
      "grad_norm": 0.013377208262681961,
      "learning_rate": 6.141576588452413e-06,
      "loss": 0.0002,
      "step": 12199
    },
    {
      "epoch": 0.7236920156602207,
      "grad_norm": 0.415391743183136,
      "learning_rate": 6.140258370682838e-06,
      "loss": 0.0067,
      "step": 12200
    },
    {
      "epoch": 0.7237513346778978,
      "grad_norm": 0.11991017311811447,
      "learning_rate": 6.138940152913262e-06,
      "loss": 0.0015,
      "step": 12201
    },
    {
      "epoch": 0.7238106536955748,
      "grad_norm": 36.573646545410156,
      "learning_rate": 6.137621935143686e-06,
      "loss": 0.4507,
      "step": 12202
    },
    {
      "epoch": 0.7238699727132518,
      "grad_norm": 0.03546608239412308,
      "learning_rate": 6.136303717374111e-06,
      "loss": 0.0005,
      "step": 12203
    },
    {
      "epoch": 0.7239292917309289,
      "grad_norm": 13.971955299377441,
      "learning_rate": 6.134985499604536e-06,
      "loss": 0.7006,
      "step": 12204
    },
    {
      "epoch": 0.723988610748606,
      "grad_norm": 0.012107377871870995,
      "learning_rate": 6.13366728183496e-06,
      "loss": 0.0003,
      "step": 12205
    },
    {
      "epoch": 0.7240479297662831,
      "grad_norm": 1.2970472574234009,
      "learning_rate": 6.132349064065384e-06,
      "loss": 0.0083,
      "step": 12206
    },
    {
      "epoch": 0.7241072487839602,
      "grad_norm": 0.34249672293663025,
      "learning_rate": 6.131030846295809e-06,
      "loss": 0.0038,
      "step": 12207
    },
    {
      "epoch": 0.7241665678016372,
      "grad_norm": 0.41399911046028137,
      "learning_rate": 6.129712628526233e-06,
      "loss": 0.0042,
      "step": 12208
    },
    {
      "epoch": 0.7242258868193143,
      "grad_norm": 0.25055447220802307,
      "learning_rate": 6.128394410756657e-06,
      "loss": 0.0015,
      "step": 12209
    },
    {
      "epoch": 0.7242852058369913,
      "grad_norm": 4.798664093017578,
      "learning_rate": 6.127076192987082e-06,
      "loss": 0.1506,
      "step": 12210
    },
    {
      "epoch": 0.7243445248546684,
      "grad_norm": 4.438588619232178,
      "learning_rate": 6.125757975217507e-06,
      "loss": 0.0907,
      "step": 12211
    },
    {
      "epoch": 0.7244038438723455,
      "grad_norm": 0.1775047332048416,
      "learning_rate": 6.124439757447931e-06,
      "loss": 0.0021,
      "step": 12212
    },
    {
      "epoch": 0.7244631628900225,
      "grad_norm": 0.018999043852090836,
      "learning_rate": 6.123121539678355e-06,
      "loss": 0.0002,
      "step": 12213
    },
    {
      "epoch": 0.7245224819076996,
      "grad_norm": 0.9815628528594971,
      "learning_rate": 6.12180332190878e-06,
      "loss": 0.0061,
      "step": 12214
    },
    {
      "epoch": 0.7245818009253767,
      "grad_norm": 0.0783149003982544,
      "learning_rate": 6.120485104139204e-06,
      "loss": 0.0008,
      "step": 12215
    },
    {
      "epoch": 0.7246411199430537,
      "grad_norm": 1.0707632303237915,
      "learning_rate": 6.119166886369628e-06,
      "loss": 0.0097,
      "step": 12216
    },
    {
      "epoch": 0.7247004389607308,
      "grad_norm": 0.008495221845805645,
      "learning_rate": 6.1178486686000534e-06,
      "loss": 0.0003,
      "step": 12217
    },
    {
      "epoch": 0.7247597579784079,
      "grad_norm": 0.0058067492209374905,
      "learning_rate": 6.116530450830478e-06,
      "loss": 0.0002,
      "step": 12218
    },
    {
      "epoch": 0.7248190769960849,
      "grad_norm": 0.020058834925293922,
      "learning_rate": 6.115212233060902e-06,
      "loss": 0.0005,
      "step": 12219
    },
    {
      "epoch": 0.724878396013762,
      "grad_norm": 0.013200125657022,
      "learning_rate": 6.113894015291326e-06,
      "loss": 0.0004,
      "step": 12220
    },
    {
      "epoch": 0.7249377150314391,
      "grad_norm": 0.04900329187512398,
      "learning_rate": 6.112575797521752e-06,
      "loss": 0.0004,
      "step": 12221
    },
    {
      "epoch": 0.7249970340491162,
      "grad_norm": 0.10403510183095932,
      "learning_rate": 6.111257579752175e-06,
      "loss": 0.0015,
      "step": 12222
    },
    {
      "epoch": 0.7250563530667932,
      "grad_norm": 8.68175220489502,
      "learning_rate": 6.109939361982599e-06,
      "loss": 0.1204,
      "step": 12223
    },
    {
      "epoch": 0.7251156720844703,
      "grad_norm": 6.965881824493408,
      "learning_rate": 6.108621144213025e-06,
      "loss": 0.4382,
      "step": 12224
    },
    {
      "epoch": 0.7251749911021473,
      "grad_norm": 17.427946090698242,
      "learning_rate": 6.1073029264434495e-06,
      "loss": 1.087,
      "step": 12225
    },
    {
      "epoch": 0.7252343101198244,
      "grad_norm": 0.00880990270525217,
      "learning_rate": 6.105984708673874e-06,
      "loss": 0.0002,
      "step": 12226
    },
    {
      "epoch": 0.7252936291375015,
      "grad_norm": 0.10330136865377426,
      "learning_rate": 6.104666490904297e-06,
      "loss": 0.0014,
      "step": 12227
    },
    {
      "epoch": 0.7253529481551786,
      "grad_norm": 0.5909578204154968,
      "learning_rate": 6.103348273134723e-06,
      "loss": 0.0042,
      "step": 12228
    },
    {
      "epoch": 0.7254122671728556,
      "grad_norm": 11.570509910583496,
      "learning_rate": 6.102030055365147e-06,
      "loss": 0.1511,
      "step": 12229
    },
    {
      "epoch": 0.7254715861905326,
      "grad_norm": 1.5100126266479492,
      "learning_rate": 6.100711837595571e-06,
      "loss": 0.0079,
      "step": 12230
    },
    {
      "epoch": 0.7255309052082097,
      "grad_norm": 0.20913825929164886,
      "learning_rate": 6.099393619825996e-06,
      "loss": 0.0024,
      "step": 12231
    },
    {
      "epoch": 0.7255902242258868,
      "grad_norm": 0.052195001393556595,
      "learning_rate": 6.0980754020564205e-06,
      "loss": 0.001,
      "step": 12232
    },
    {
      "epoch": 0.7256495432435639,
      "grad_norm": 0.030525794252753258,
      "learning_rate": 6.096757184286845e-06,
      "loss": 0.0006,
      "step": 12233
    },
    {
      "epoch": 0.725708862261241,
      "grad_norm": 5.314696788787842,
      "learning_rate": 6.095438966517269e-06,
      "loss": 0.1218,
      "step": 12234
    },
    {
      "epoch": 0.7257681812789181,
      "grad_norm": 1.1866521835327148,
      "learning_rate": 6.094120748747694e-06,
      "loss": 0.0114,
      "step": 12235
    },
    {
      "epoch": 0.725827500296595,
      "grad_norm": 37.371761322021484,
      "learning_rate": 6.092802530978118e-06,
      "loss": 1.181,
      "step": 12236
    },
    {
      "epoch": 0.7258868193142721,
      "grad_norm": 3.5207278728485107,
      "learning_rate": 6.091484313208542e-06,
      "loss": 0.0283,
      "step": 12237
    },
    {
      "epoch": 0.7259461383319492,
      "grad_norm": 0.18656228482723236,
      "learning_rate": 6.090166095438967e-06,
      "loss": 0.0014,
      "step": 12238
    },
    {
      "epoch": 0.7260054573496263,
      "grad_norm": 17.208629608154297,
      "learning_rate": 6.0888478776693915e-06,
      "loss": 1.014,
      "step": 12239
    },
    {
      "epoch": 0.7260647763673034,
      "grad_norm": 0.0017208927311003208,
      "learning_rate": 6.087529659899816e-06,
      "loss": 0.0001,
      "step": 12240
    },
    {
      "epoch": 0.7261240953849805,
      "grad_norm": 0.03996080905199051,
      "learning_rate": 6.086211442130241e-06,
      "loss": 0.0005,
      "step": 12241
    },
    {
      "epoch": 0.7261834144026575,
      "grad_norm": 8.489089012145996,
      "learning_rate": 6.084893224360665e-06,
      "loss": 0.3147,
      "step": 12242
    },
    {
      "epoch": 0.7262427334203345,
      "grad_norm": 1.1853477954864502,
      "learning_rate": 6.083575006591089e-06,
      "loss": 0.0067,
      "step": 12243
    },
    {
      "epoch": 0.7263020524380116,
      "grad_norm": 0.045872606337070465,
      "learning_rate": 6.082256788821513e-06,
      "loss": 0.001,
      "step": 12244
    },
    {
      "epoch": 0.7263613714556887,
      "grad_norm": 19.81697654724121,
      "learning_rate": 6.080938571051938e-06,
      "loss": 0.1707,
      "step": 12245
    },
    {
      "epoch": 0.7264206904733658,
      "grad_norm": 18.464847564697266,
      "learning_rate": 6.0796203532823625e-06,
      "loss": 0.3588,
      "step": 12246
    },
    {
      "epoch": 0.7264800094910429,
      "grad_norm": 14.637903213500977,
      "learning_rate": 6.078302135512787e-06,
      "loss": 0.9323,
      "step": 12247
    },
    {
      "epoch": 0.7265393285087199,
      "grad_norm": 80.42922973632812,
      "learning_rate": 6.0769839177432125e-06,
      "loss": 0.9222,
      "step": 12248
    },
    {
      "epoch": 0.7265986475263969,
      "grad_norm": 7.343698978424072,
      "learning_rate": 6.075665699973636e-06,
      "loss": 0.0635,
      "step": 12249
    },
    {
      "epoch": 0.726657966544074,
      "grad_norm": 3.334650754928589,
      "learning_rate": 6.07434748220406e-06,
      "loss": 0.0394,
      "step": 12250
    },
    {
      "epoch": 0.7267172855617511,
      "grad_norm": 0.20436552166938782,
      "learning_rate": 6.073029264434484e-06,
      "loss": 0.0021,
      "step": 12251
    },
    {
      "epoch": 0.7267766045794282,
      "grad_norm": 3.7575485706329346,
      "learning_rate": 6.07171104666491e-06,
      "loss": 0.0217,
      "step": 12252
    },
    {
      "epoch": 0.7268359235971052,
      "grad_norm": 0.035011690109968185,
      "learning_rate": 6.070392828895334e-06,
      "loss": 0.0006,
      "step": 12253
    },
    {
      "epoch": 0.7268952426147823,
      "grad_norm": 0.5287109613418579,
      "learning_rate": 6.0690746111257585e-06,
      "loss": 0.0073,
      "step": 12254
    },
    {
      "epoch": 0.7269545616324594,
      "grad_norm": 16.530057907104492,
      "learning_rate": 6.0677563933561836e-06,
      "loss": 0.1412,
      "step": 12255
    },
    {
      "epoch": 0.7270138806501364,
      "grad_norm": 0.08830378204584122,
      "learning_rate": 6.066438175586608e-06,
      "loss": 0.0012,
      "step": 12256
    },
    {
      "epoch": 0.7270731996678135,
      "grad_norm": 7.681225299835205,
      "learning_rate": 6.065119957817032e-06,
      "loss": 0.1527,
      "step": 12257
    },
    {
      "epoch": 0.7271325186854906,
      "grad_norm": 0.48882582783699036,
      "learning_rate": 6.063801740047456e-06,
      "loss": 0.0045,
      "step": 12258
    },
    {
      "epoch": 0.7271918377031676,
      "grad_norm": 0.014055863954126835,
      "learning_rate": 6.062483522277881e-06,
      "loss": 0.0004,
      "step": 12259
    },
    {
      "epoch": 0.7272511567208447,
      "grad_norm": 0.21660232543945312,
      "learning_rate": 6.061165304508305e-06,
      "loss": 0.0027,
      "step": 12260
    },
    {
      "epoch": 0.7273104757385218,
      "grad_norm": 7.988609790802002,
      "learning_rate": 6.0598470867387295e-06,
      "loss": 0.475,
      "step": 12261
    },
    {
      "epoch": 0.7273697947561988,
      "grad_norm": 2.164198398590088,
      "learning_rate": 6.0585288689691546e-06,
      "loss": 0.0198,
      "step": 12262
    },
    {
      "epoch": 0.7274291137738759,
      "grad_norm": 19.217052459716797,
      "learning_rate": 6.057210651199579e-06,
      "loss": 0.2125,
      "step": 12263
    },
    {
      "epoch": 0.727488432791553,
      "grad_norm": 0.14021681249141693,
      "learning_rate": 6.055892433430003e-06,
      "loss": 0.0016,
      "step": 12264
    },
    {
      "epoch": 0.72754775180923,
      "grad_norm": 8.648362159729004,
      "learning_rate": 6.054574215660428e-06,
      "loss": 0.2453,
      "step": 12265
    },
    {
      "epoch": 0.7276070708269071,
      "grad_norm": 7.261526107788086,
      "learning_rate": 6.053255997890852e-06,
      "loss": 0.1288,
      "step": 12266
    },
    {
      "epoch": 0.7276663898445842,
      "grad_norm": 0.061932481825351715,
      "learning_rate": 6.051937780121276e-06,
      "loss": 0.0014,
      "step": 12267
    },
    {
      "epoch": 0.7277257088622613,
      "grad_norm": 0.013356734067201614,
      "learning_rate": 6.0506195623517005e-06,
      "loss": 0.0004,
      "step": 12268
    },
    {
      "epoch": 0.7277850278799383,
      "grad_norm": 3.410414218902588,
      "learning_rate": 6.0493013445821256e-06,
      "loss": 0.1987,
      "step": 12269
    },
    {
      "epoch": 0.7278443468976153,
      "grad_norm": 0.03430042415857315,
      "learning_rate": 6.04798312681255e-06,
      "loss": 0.0009,
      "step": 12270
    },
    {
      "epoch": 0.7279036659152924,
      "grad_norm": 0.0326140895485878,
      "learning_rate": 6.046664909042974e-06,
      "loss": 0.0008,
      "step": 12271
    },
    {
      "epoch": 0.7279629849329695,
      "grad_norm": 0.016321348026394844,
      "learning_rate": 6.045346691273399e-06,
      "loss": 0.0004,
      "step": 12272
    },
    {
      "epoch": 0.7280223039506466,
      "grad_norm": 1.2602641582489014,
      "learning_rate": 6.044028473503823e-06,
      "loss": 0.0102,
      "step": 12273
    },
    {
      "epoch": 0.7280816229683237,
      "grad_norm": 0.022615626454353333,
      "learning_rate": 6.042710255734247e-06,
      "loss": 0.0007,
      "step": 12274
    },
    {
      "epoch": 0.7281409419860008,
      "grad_norm": 0.019504571333527565,
      "learning_rate": 6.0413920379646715e-06,
      "loss": 0.0004,
      "step": 12275
    },
    {
      "epoch": 0.7282002610036777,
      "grad_norm": 0.06744919717311859,
      "learning_rate": 6.040073820195097e-06,
      "loss": 0.0008,
      "step": 12276
    },
    {
      "epoch": 0.7282595800213548,
      "grad_norm": 2.368398427963257,
      "learning_rate": 6.038755602425521e-06,
      "loss": 0.0081,
      "step": 12277
    },
    {
      "epoch": 0.7283188990390319,
      "grad_norm": 14.547419548034668,
      "learning_rate": 6.037437384655945e-06,
      "loss": 0.4906,
      "step": 12278
    },
    {
      "epoch": 0.728378218056709,
      "grad_norm": 20.518924713134766,
      "learning_rate": 6.036119166886371e-06,
      "loss": 0.9549,
      "step": 12279
    },
    {
      "epoch": 0.7284375370743861,
      "grad_norm": 11.52385139465332,
      "learning_rate": 6.034800949116795e-06,
      "loss": 0.4995,
      "step": 12280
    },
    {
      "epoch": 0.7284968560920632,
      "grad_norm": 13.115547180175781,
      "learning_rate": 6.033482731347219e-06,
      "loss": 0.0805,
      "step": 12281
    },
    {
      "epoch": 0.7285561751097401,
      "grad_norm": 47.65707778930664,
      "learning_rate": 6.032164513577643e-06,
      "loss": 0.5912,
      "step": 12282
    },
    {
      "epoch": 0.7286154941274172,
      "grad_norm": 4.361565113067627,
      "learning_rate": 6.030846295808068e-06,
      "loss": 0.073,
      "step": 12283
    },
    {
      "epoch": 0.7286748131450943,
      "grad_norm": 0.14296121895313263,
      "learning_rate": 6.029528078038493e-06,
      "loss": 0.0027,
      "step": 12284
    },
    {
      "epoch": 0.7287341321627714,
      "grad_norm": 0.3511885702610016,
      "learning_rate": 6.028209860268917e-06,
      "loss": 0.0053,
      "step": 12285
    },
    {
      "epoch": 0.7287934511804485,
      "grad_norm": 0.10153229534626007,
      "learning_rate": 6.026891642499342e-06,
      "loss": 0.0016,
      "step": 12286
    },
    {
      "epoch": 0.7288527701981256,
      "grad_norm": 10.882766723632812,
      "learning_rate": 6.025573424729766e-06,
      "loss": 0.4361,
      "step": 12287
    },
    {
      "epoch": 0.7289120892158026,
      "grad_norm": 0.06650370359420776,
      "learning_rate": 6.02425520696019e-06,
      "loss": 0.0008,
      "step": 12288
    },
    {
      "epoch": 0.7289714082334796,
      "grad_norm": 0.011882978491485119,
      "learning_rate": 6.022936989190615e-06,
      "loss": 0.0002,
      "step": 12289
    },
    {
      "epoch": 0.7290307272511567,
      "grad_norm": 13.479827880859375,
      "learning_rate": 6.021618771421039e-06,
      "loss": 0.476,
      "step": 12290
    },
    {
      "epoch": 0.7290900462688338,
      "grad_norm": 1.0244194269180298,
      "learning_rate": 6.020300553651464e-06,
      "loss": 0.0089,
      "step": 12291
    },
    {
      "epoch": 0.7291493652865109,
      "grad_norm": 6.4429779052734375,
      "learning_rate": 6.018982335881888e-06,
      "loss": 0.2335,
      "step": 12292
    },
    {
      "epoch": 0.729208684304188,
      "grad_norm": 1.8845854997634888,
      "learning_rate": 6.017664118112313e-06,
      "loss": 0.0236,
      "step": 12293
    },
    {
      "epoch": 0.729268003321865,
      "grad_norm": 29.099773406982422,
      "learning_rate": 6.016345900342737e-06,
      "loss": 0.6174,
      "step": 12294
    },
    {
      "epoch": 0.729327322339542,
      "grad_norm": 16.164609909057617,
      "learning_rate": 6.015027682573161e-06,
      "loss": 0.1521,
      "step": 12295
    },
    {
      "epoch": 0.7293866413572191,
      "grad_norm": 0.09483082592487335,
      "learning_rate": 6.013709464803586e-06,
      "loss": 0.0017,
      "step": 12296
    },
    {
      "epoch": 0.7294459603748962,
      "grad_norm": 1.5851773023605347,
      "learning_rate": 6.01239124703401e-06,
      "loss": 0.0162,
      "step": 12297
    },
    {
      "epoch": 0.7295052793925733,
      "grad_norm": 0.3438640832901001,
      "learning_rate": 6.011073029264435e-06,
      "loss": 0.0042,
      "step": 12298
    },
    {
      "epoch": 0.7295645984102503,
      "grad_norm": 3.0828394889831543,
      "learning_rate": 6.009754811494859e-06,
      "loss": 0.0331,
      "step": 12299
    },
    {
      "epoch": 0.7296239174279274,
      "grad_norm": 2.279442548751831,
      "learning_rate": 6.008436593725284e-06,
      "loss": 0.0321,
      "step": 12300
    },
    {
      "epoch": 0.7296832364456045,
      "grad_norm": 2.816936492919922,
      "learning_rate": 6.007118375955708e-06,
      "loss": 0.1382,
      "step": 12301
    },
    {
      "epoch": 0.7297425554632815,
      "grad_norm": 4.354132652282715,
      "learning_rate": 6.005800158186132e-06,
      "loss": 0.1382,
      "step": 12302
    },
    {
      "epoch": 0.7298018744809586,
      "grad_norm": 1.0070503950119019,
      "learning_rate": 6.004481940416558e-06,
      "loss": 0.0093,
      "step": 12303
    },
    {
      "epoch": 0.7298611934986357,
      "grad_norm": 0.07467575371265411,
      "learning_rate": 6.003163722646982e-06,
      "loss": 0.0004,
      "step": 12304
    },
    {
      "epoch": 0.7299205125163127,
      "grad_norm": 0.5247772932052612,
      "learning_rate": 6.001845504877406e-06,
      "loss": 0.0062,
      "step": 12305
    },
    {
      "epoch": 0.7299798315339898,
      "grad_norm": 0.10299434512853622,
      "learning_rate": 6.00052728710783e-06,
      "loss": 0.0017,
      "step": 12306
    },
    {
      "epoch": 0.7300391505516669,
      "grad_norm": 0.07109341025352478,
      "learning_rate": 5.999209069338256e-06,
      "loss": 0.0005,
      "step": 12307
    },
    {
      "epoch": 0.7300984695693439,
      "grad_norm": 0.03153560310602188,
      "learning_rate": 5.99789085156868e-06,
      "loss": 0.0004,
      "step": 12308
    },
    {
      "epoch": 0.730157788587021,
      "grad_norm": 9.461400985717773,
      "learning_rate": 5.996572633799104e-06,
      "loss": 0.2867,
      "step": 12309
    },
    {
      "epoch": 0.730217107604698,
      "grad_norm": 0.31683796644210815,
      "learning_rate": 5.995254416029529e-06,
      "loss": 0.0029,
      "step": 12310
    },
    {
      "epoch": 0.7302764266223751,
      "grad_norm": 26.251806259155273,
      "learning_rate": 5.993936198259953e-06,
      "loss": 0.0947,
      "step": 12311
    },
    {
      "epoch": 0.7303357456400522,
      "grad_norm": 0.40362808108329773,
      "learning_rate": 5.9926179804903775e-06,
      "loss": 0.0034,
      "step": 12312
    },
    {
      "epoch": 0.7303950646577293,
      "grad_norm": 21.208507537841797,
      "learning_rate": 5.9912997627208025e-06,
      "loss": 0.3325,
      "step": 12313
    },
    {
      "epoch": 0.7304543836754064,
      "grad_norm": 8.069141387939453,
      "learning_rate": 5.989981544951227e-06,
      "loss": 0.444,
      "step": 12314
    },
    {
      "epoch": 0.7305137026930834,
      "grad_norm": 11.321301460266113,
      "learning_rate": 5.988663327181651e-06,
      "loss": 0.6961,
      "step": 12315
    },
    {
      "epoch": 0.7305730217107604,
      "grad_norm": 27.746646881103516,
      "learning_rate": 5.987345109412075e-06,
      "loss": 0.4958,
      "step": 12316
    },
    {
      "epoch": 0.7306323407284375,
      "grad_norm": 0.028450483456254005,
      "learning_rate": 5.9860268916425e-06,
      "loss": 0.0006,
      "step": 12317
    },
    {
      "epoch": 0.7306916597461146,
      "grad_norm": 0.6410789489746094,
      "learning_rate": 5.984708673872924e-06,
      "loss": 0.006,
      "step": 12318
    },
    {
      "epoch": 0.7307509787637917,
      "grad_norm": 3.213984489440918,
      "learning_rate": 5.9833904561033485e-06,
      "loss": 0.0359,
      "step": 12319
    },
    {
      "epoch": 0.7308102977814688,
      "grad_norm": 1.059307336807251,
      "learning_rate": 5.9820722383337735e-06,
      "loss": 0.0066,
      "step": 12320
    },
    {
      "epoch": 0.7308696167991459,
      "grad_norm": 1.493414044380188,
      "learning_rate": 5.980754020564198e-06,
      "loss": 0.0148,
      "step": 12321
    },
    {
      "epoch": 0.7309289358168228,
      "grad_norm": 22.697017669677734,
      "learning_rate": 5.979435802794622e-06,
      "loss": 1.0037,
      "step": 12322
    },
    {
      "epoch": 0.7309882548344999,
      "grad_norm": 0.009006181731820107,
      "learning_rate": 5.978117585025046e-06,
      "loss": 0.0002,
      "step": 12323
    },
    {
      "epoch": 0.731047573852177,
      "grad_norm": 16.0037841796875,
      "learning_rate": 5.976799367255471e-06,
      "loss": 0.5931,
      "step": 12324
    },
    {
      "epoch": 0.7311068928698541,
      "grad_norm": 0.16622616350650787,
      "learning_rate": 5.975481149485895e-06,
      "loss": 0.0024,
      "step": 12325
    },
    {
      "epoch": 0.7311662118875312,
      "grad_norm": 0.49995261430740356,
      "learning_rate": 5.9741629317163195e-06,
      "loss": 0.0069,
      "step": 12326
    },
    {
      "epoch": 0.7312255309052083,
      "grad_norm": 2.6141245365142822,
      "learning_rate": 5.9728447139467445e-06,
      "loss": 0.0346,
      "step": 12327
    },
    {
      "epoch": 0.7312848499228852,
      "grad_norm": 0.04649481922388077,
      "learning_rate": 5.971526496177169e-06,
      "loss": 0.0008,
      "step": 12328
    },
    {
      "epoch": 0.7313441689405623,
      "grad_norm": 0.03769727051258087,
      "learning_rate": 5.970208278407593e-06,
      "loss": 0.0012,
      "step": 12329
    },
    {
      "epoch": 0.7314034879582394,
      "grad_norm": 6.585395812988281,
      "learning_rate": 5.968890060638017e-06,
      "loss": 0.0406,
      "step": 12330
    },
    {
      "epoch": 0.7314628069759165,
      "grad_norm": 0.02155405469238758,
      "learning_rate": 5.967571842868443e-06,
      "loss": 0.0005,
      "step": 12331
    },
    {
      "epoch": 0.7315221259935936,
      "grad_norm": 7.998568058013916,
      "learning_rate": 5.966253625098867e-06,
      "loss": 0.1022,
      "step": 12332
    },
    {
      "epoch": 0.7315814450112706,
      "grad_norm": 2.6924893856048584,
      "learning_rate": 5.9649354073292905e-06,
      "loss": 0.0614,
      "step": 12333
    },
    {
      "epoch": 0.7316407640289477,
      "grad_norm": 0.48014694452285767,
      "learning_rate": 5.963617189559716e-06,
      "loss": 0.0059,
      "step": 12334
    },
    {
      "epoch": 0.7317000830466247,
      "grad_norm": 8.564496994018555,
      "learning_rate": 5.9622989717901405e-06,
      "loss": 0.081,
      "step": 12335
    },
    {
      "epoch": 0.7317594020643018,
      "grad_norm": 0.4450939893722534,
      "learning_rate": 5.960980754020565e-06,
      "loss": 0.0064,
      "step": 12336
    },
    {
      "epoch": 0.7318187210819789,
      "grad_norm": 0.83127760887146,
      "learning_rate": 5.95966253625099e-06,
      "loss": 0.0111,
      "step": 12337
    },
    {
      "epoch": 0.731878040099656,
      "grad_norm": 0.49106565117836,
      "learning_rate": 5.958344318481414e-06,
      "loss": 0.0073,
      "step": 12338
    },
    {
      "epoch": 0.731937359117333,
      "grad_norm": 3.633282423019409,
      "learning_rate": 5.957026100711838e-06,
      "loss": 0.0159,
      "step": 12339
    },
    {
      "epoch": 0.7319966781350101,
      "grad_norm": 0.010572812519967556,
      "learning_rate": 5.955707882942262e-06,
      "loss": 0.0003,
      "step": 12340
    },
    {
      "epoch": 0.7320559971526871,
      "grad_norm": 15.438199996948242,
      "learning_rate": 5.954389665172687e-06,
      "loss": 0.333,
      "step": 12341
    },
    {
      "epoch": 0.7321153161703642,
      "grad_norm": 8.576459884643555,
      "learning_rate": 5.9530714474031115e-06,
      "loss": 0.1241,
      "step": 12342
    },
    {
      "epoch": 0.7321746351880413,
      "grad_norm": 6.91343355178833,
      "learning_rate": 5.951753229633536e-06,
      "loss": 0.0407,
      "step": 12343
    },
    {
      "epoch": 0.7322339542057184,
      "grad_norm": 4.411448001861572,
      "learning_rate": 5.950435011863961e-06,
      "loss": 0.0491,
      "step": 12344
    },
    {
      "epoch": 0.7322932732233954,
      "grad_norm": 32.52500915527344,
      "learning_rate": 5.949116794094385e-06,
      "loss": 0.5387,
      "step": 12345
    },
    {
      "epoch": 0.7323525922410725,
      "grad_norm": 4.921709060668945,
      "learning_rate": 5.947798576324809e-06,
      "loss": 0.2526,
      "step": 12346
    },
    {
      "epoch": 0.7324119112587496,
      "grad_norm": 0.1479836404323578,
      "learning_rate": 5.946480358555233e-06,
      "loss": 0.0033,
      "step": 12347
    },
    {
      "epoch": 0.7324712302764266,
      "grad_norm": 0.04748315364122391,
      "learning_rate": 5.945162140785658e-06,
      "loss": 0.0006,
      "step": 12348
    },
    {
      "epoch": 0.7325305492941037,
      "grad_norm": 16.128215789794922,
      "learning_rate": 5.9438439230160826e-06,
      "loss": 0.1034,
      "step": 12349
    },
    {
      "epoch": 0.7325898683117807,
      "grad_norm": 1.611911416053772,
      "learning_rate": 5.942525705246507e-06,
      "loss": 0.0057,
      "step": 12350
    },
    {
      "epoch": 0.7326491873294578,
      "grad_norm": 0.07669375091791153,
      "learning_rate": 5.941207487476932e-06,
      "loss": 0.0016,
      "step": 12351
    },
    {
      "epoch": 0.7327085063471349,
      "grad_norm": 9.129327774047852,
      "learning_rate": 5.939889269707356e-06,
      "loss": 0.2599,
      "step": 12352
    },
    {
      "epoch": 0.732767825364812,
      "grad_norm": 3.587224006652832,
      "learning_rate": 5.93857105193778e-06,
      "loss": 0.0783,
      "step": 12353
    },
    {
      "epoch": 0.732827144382489,
      "grad_norm": 20.234283447265625,
      "learning_rate": 5.937252834168204e-06,
      "loss": 0.1065,
      "step": 12354
    },
    {
      "epoch": 0.732886463400166,
      "grad_norm": 6.0459184646606445,
      "learning_rate": 5.935934616398629e-06,
      "loss": 0.2082,
      "step": 12355
    },
    {
      "epoch": 0.7329457824178431,
      "grad_norm": 21.096721649169922,
      "learning_rate": 5.9346163986290536e-06,
      "loss": 0.6007,
      "step": 12356
    },
    {
      "epoch": 0.7330051014355202,
      "grad_norm": 0.23310500383377075,
      "learning_rate": 5.933298180859478e-06,
      "loss": 0.0028,
      "step": 12357
    },
    {
      "epoch": 0.7330644204531973,
      "grad_norm": 0.886237621307373,
      "learning_rate": 5.931979963089904e-06,
      "loss": 0.0093,
      "step": 12358
    },
    {
      "epoch": 0.7331237394708744,
      "grad_norm": 5.736021995544434,
      "learning_rate": 5.930661745320328e-06,
      "loss": 0.0823,
      "step": 12359
    },
    {
      "epoch": 0.7331830584885515,
      "grad_norm": 6.7104082107543945,
      "learning_rate": 5.929343527550752e-06,
      "loss": 0.0566,
      "step": 12360
    },
    {
      "epoch": 0.7332423775062284,
      "grad_norm": 2.8359646797180176,
      "learning_rate": 5.928025309781177e-06,
      "loss": 0.071,
      "step": 12361
    },
    {
      "epoch": 0.7333016965239055,
      "grad_norm": 1.8222439289093018,
      "learning_rate": 5.926707092011601e-06,
      "loss": 0.0296,
      "step": 12362
    },
    {
      "epoch": 0.7333610155415826,
      "grad_norm": 4.835309982299805,
      "learning_rate": 5.925388874242025e-06,
      "loss": 0.2709,
      "step": 12363
    },
    {
      "epoch": 0.7334203345592597,
      "grad_norm": 0.20636947453022003,
      "learning_rate": 5.92407065647245e-06,
      "loss": 0.0021,
      "step": 12364
    },
    {
      "epoch": 0.7334796535769368,
      "grad_norm": 7.041660785675049,
      "learning_rate": 5.922752438702875e-06,
      "loss": 0.0584,
      "step": 12365
    },
    {
      "epoch": 0.7335389725946139,
      "grad_norm": 1.2511253356933594,
      "learning_rate": 5.921434220933299e-06,
      "loss": 0.01,
      "step": 12366
    },
    {
      "epoch": 0.733598291612291,
      "grad_norm": 4.69434928894043,
      "learning_rate": 5.920116003163723e-06,
      "loss": 0.0136,
      "step": 12367
    },
    {
      "epoch": 0.7336576106299679,
      "grad_norm": 0.02260447107255459,
      "learning_rate": 5.918797785394148e-06,
      "loss": 0.0007,
      "step": 12368
    },
    {
      "epoch": 0.733716929647645,
      "grad_norm": 4.9705586433410645,
      "learning_rate": 5.917479567624572e-06,
      "loss": 0.0342,
      "step": 12369
    },
    {
      "epoch": 0.7337762486653221,
      "grad_norm": 23.908422470092773,
      "learning_rate": 5.916161349854996e-06,
      "loss": 0.152,
      "step": 12370
    },
    {
      "epoch": 0.7338355676829992,
      "grad_norm": 0.0818132609128952,
      "learning_rate": 5.914843132085421e-06,
      "loss": 0.0012,
      "step": 12371
    },
    {
      "epoch": 0.7338948867006763,
      "grad_norm": 14.891698837280273,
      "learning_rate": 5.913524914315846e-06,
      "loss": 0.2138,
      "step": 12372
    },
    {
      "epoch": 0.7339542057183533,
      "grad_norm": 0.03126326575875282,
      "learning_rate": 5.91220669654627e-06,
      "loss": 0.0006,
      "step": 12373
    },
    {
      "epoch": 0.7340135247360303,
      "grad_norm": 20.993013381958008,
      "learning_rate": 5.910888478776694e-06,
      "loss": 0.1679,
      "step": 12374
    },
    {
      "epoch": 0.7340728437537074,
      "grad_norm": 17.547426223754883,
      "learning_rate": 5.909570261007119e-06,
      "loss": 0.1521,
      "step": 12375
    },
    {
      "epoch": 0.7341321627713845,
      "grad_norm": 14.68221378326416,
      "learning_rate": 5.908252043237543e-06,
      "loss": 0.4114,
      "step": 12376
    },
    {
      "epoch": 0.7341914817890616,
      "grad_norm": 3.668555736541748,
      "learning_rate": 5.906933825467967e-06,
      "loss": 0.0147,
      "step": 12377
    },
    {
      "epoch": 0.7342508008067387,
      "grad_norm": 0.21962933242321014,
      "learning_rate": 5.905615607698392e-06,
      "loss": 0.0047,
      "step": 12378
    },
    {
      "epoch": 0.7343101198244157,
      "grad_norm": 0.0825711116194725,
      "learning_rate": 5.904297389928817e-06,
      "loss": 0.0015,
      "step": 12379
    },
    {
      "epoch": 0.7343694388420928,
      "grad_norm": 0.08864504843950272,
      "learning_rate": 5.902979172159241e-06,
      "loss": 0.0013,
      "step": 12380
    },
    {
      "epoch": 0.7344287578597698,
      "grad_norm": 27.464550018310547,
      "learning_rate": 5.901660954389665e-06,
      "loss": 0.369,
      "step": 12381
    },
    {
      "epoch": 0.7344880768774469,
      "grad_norm": 0.45625805854797363,
      "learning_rate": 5.900342736620091e-06,
      "loss": 0.0035,
      "step": 12382
    },
    {
      "epoch": 0.734547395895124,
      "grad_norm": 16.482149124145508,
      "learning_rate": 5.899024518850514e-06,
      "loss": 0.1628,
      "step": 12383
    },
    {
      "epoch": 0.734606714912801,
      "grad_norm": 0.04171689972281456,
      "learning_rate": 5.897706301080938e-06,
      "loss": 0.0006,
      "step": 12384
    },
    {
      "epoch": 0.7346660339304781,
      "grad_norm": 0.8951906561851501,
      "learning_rate": 5.896388083311364e-06,
      "loss": 0.0079,
      "step": 12385
    },
    {
      "epoch": 0.7347253529481552,
      "grad_norm": 0.9704031348228455,
      "learning_rate": 5.8950698655417885e-06,
      "loss": 0.0059,
      "step": 12386
    },
    {
      "epoch": 0.7347846719658322,
      "grad_norm": 7.30794095993042,
      "learning_rate": 5.893751647772213e-06,
      "loss": 0.3087,
      "step": 12387
    },
    {
      "epoch": 0.7348439909835093,
      "grad_norm": 7.722341537475586,
      "learning_rate": 5.892433430002637e-06,
      "loss": 0.0299,
      "step": 12388
    },
    {
      "epoch": 0.7349033100011864,
      "grad_norm": 0.04600423574447632,
      "learning_rate": 5.891115212233062e-06,
      "loss": 0.0009,
      "step": 12389
    },
    {
      "epoch": 0.7349626290188634,
      "grad_norm": 3.8759496212005615,
      "learning_rate": 5.889796994463486e-06,
      "loss": 0.1603,
      "step": 12390
    },
    {
      "epoch": 0.7350219480365405,
      "grad_norm": 2.0173394680023193,
      "learning_rate": 5.88847877669391e-06,
      "loss": 0.0191,
      "step": 12391
    },
    {
      "epoch": 0.7350812670542176,
      "grad_norm": 0.04354161024093628,
      "learning_rate": 5.887160558924335e-06,
      "loss": 0.0006,
      "step": 12392
    },
    {
      "epoch": 0.7351405860718947,
      "grad_norm": 0.00873059406876564,
      "learning_rate": 5.8858423411547595e-06,
      "loss": 0.0002,
      "step": 12393
    },
    {
      "epoch": 0.7351999050895717,
      "grad_norm": 0.04802578687667847,
      "learning_rate": 5.884524123385184e-06,
      "loss": 0.0008,
      "step": 12394
    },
    {
      "epoch": 0.7352592241072488,
      "grad_norm": 3.279003381729126,
      "learning_rate": 5.883205905615608e-06,
      "loss": 0.032,
      "step": 12395
    },
    {
      "epoch": 0.7353185431249258,
      "grad_norm": 1.6616415977478027,
      "learning_rate": 5.881887687846033e-06,
      "loss": 0.0143,
      "step": 12396
    },
    {
      "epoch": 0.7353778621426029,
      "grad_norm": 0.19377054274082184,
      "learning_rate": 5.880569470076457e-06,
      "loss": 0.002,
      "step": 12397
    },
    {
      "epoch": 0.73543718116028,
      "grad_norm": 0.11689149588346481,
      "learning_rate": 5.879251252306881e-06,
      "loss": 0.0015,
      "step": 12398
    },
    {
      "epoch": 0.7354965001779571,
      "grad_norm": 0.05666240304708481,
      "learning_rate": 5.877933034537306e-06,
      "loss": 0.0007,
      "step": 12399
    },
    {
      "epoch": 0.7355558191956342,
      "grad_norm": 18.331167221069336,
      "learning_rate": 5.8766148167677305e-06,
      "loss": 0.2154,
      "step": 12400
    },
    {
      "epoch": 0.7356151382133111,
      "grad_norm": 0.0429903008043766,
      "learning_rate": 5.875296598998155e-06,
      "loss": 0.0007,
      "step": 12401
    },
    {
      "epoch": 0.7356744572309882,
      "grad_norm": 21.817346572875977,
      "learning_rate": 5.87397838122858e-06,
      "loss": 0.4264,
      "step": 12402
    },
    {
      "epoch": 0.7357337762486653,
      "grad_norm": 0.005639658309519291,
      "learning_rate": 5.872660163459004e-06,
      "loss": 0.0002,
      "step": 12403
    },
    {
      "epoch": 0.7357930952663424,
      "grad_norm": 0.12295547872781754,
      "learning_rate": 5.871341945689428e-06,
      "loss": 0.002,
      "step": 12404
    },
    {
      "epoch": 0.7358524142840195,
      "grad_norm": 1.9093003273010254,
      "learning_rate": 5.870023727919852e-06,
      "loss": 0.0226,
      "step": 12405
    },
    {
      "epoch": 0.7359117333016966,
      "grad_norm": 0.2670958638191223,
      "learning_rate": 5.868705510150277e-06,
      "loss": 0.0066,
      "step": 12406
    },
    {
      "epoch": 0.7359710523193735,
      "grad_norm": 16.523990631103516,
      "learning_rate": 5.8673872923807015e-06,
      "loss": 0.0857,
      "step": 12407
    },
    {
      "epoch": 0.7360303713370506,
      "grad_norm": 0.6475088596343994,
      "learning_rate": 5.866069074611126e-06,
      "loss": 0.0102,
      "step": 12408
    },
    {
      "epoch": 0.7360896903547277,
      "grad_norm": 13.748787879943848,
      "learning_rate": 5.8647508568415516e-06,
      "loss": 0.9395,
      "step": 12409
    },
    {
      "epoch": 0.7361490093724048,
      "grad_norm": 0.24424220621585846,
      "learning_rate": 5.863432639071976e-06,
      "loss": 0.0039,
      "step": 12410
    },
    {
      "epoch": 0.7362083283900819,
      "grad_norm": 0.0030362578108906746,
      "learning_rate": 5.862114421302399e-06,
      "loss": 0.0001,
      "step": 12411
    },
    {
      "epoch": 0.736267647407759,
      "grad_norm": 0.0025559323839843273,
      "learning_rate": 5.860796203532823e-06,
      "loss": 0.0001,
      "step": 12412
    },
    {
      "epoch": 0.736326966425436,
      "grad_norm": 12.189597129821777,
      "learning_rate": 5.859477985763249e-06,
      "loss": 0.1237,
      "step": 12413
    },
    {
      "epoch": 0.736386285443113,
      "grad_norm": 2.4095394611358643,
      "learning_rate": 5.858159767993673e-06,
      "loss": 0.0264,
      "step": 12414
    },
    {
      "epoch": 0.7364456044607901,
      "grad_norm": 0.047377750277519226,
      "learning_rate": 5.8568415502240975e-06,
      "loss": 0.0006,
      "step": 12415
    },
    {
      "epoch": 0.7365049234784672,
      "grad_norm": 0.009713053703308105,
      "learning_rate": 5.8555233324545226e-06,
      "loss": 0.0003,
      "step": 12416
    },
    {
      "epoch": 0.7365642424961443,
      "grad_norm": 12.547334671020508,
      "learning_rate": 5.854205114684947e-06,
      "loss": 0.7411,
      "step": 12417
    },
    {
      "epoch": 0.7366235615138214,
      "grad_norm": 0.1620722860097885,
      "learning_rate": 5.852886896915371e-06,
      "loss": 0.0028,
      "step": 12418
    },
    {
      "epoch": 0.7366828805314984,
      "grad_norm": 0.01287996955215931,
      "learning_rate": 5.851568679145795e-06,
      "loss": 0.0002,
      "step": 12419
    },
    {
      "epoch": 0.7367421995491754,
      "grad_norm": 0.01742071658372879,
      "learning_rate": 5.85025046137622e-06,
      "loss": 0.0004,
      "step": 12420
    },
    {
      "epoch": 0.7368015185668525,
      "grad_norm": 16.9754638671875,
      "learning_rate": 5.848932243606644e-06,
      "loss": 0.0898,
      "step": 12421
    },
    {
      "epoch": 0.7368608375845296,
      "grad_norm": 6.4125800132751465,
      "learning_rate": 5.8476140258370685e-06,
      "loss": 0.2293,
      "step": 12422
    },
    {
      "epoch": 0.7369201566022067,
      "grad_norm": 12.024271011352539,
      "learning_rate": 5.8462958080674936e-06,
      "loss": 0.2693,
      "step": 12423
    },
    {
      "epoch": 0.7369794756198838,
      "grad_norm": 0.5067287683486938,
      "learning_rate": 5.844977590297918e-06,
      "loss": 0.0029,
      "step": 12424
    },
    {
      "epoch": 0.7370387946375608,
      "grad_norm": 50.36929702758789,
      "learning_rate": 5.843659372528342e-06,
      "loss": 1.7113,
      "step": 12425
    },
    {
      "epoch": 0.7370981136552379,
      "grad_norm": 11.73336124420166,
      "learning_rate": 5.842341154758767e-06,
      "loss": 0.1691,
      "step": 12426
    },
    {
      "epoch": 0.7371574326729149,
      "grad_norm": 11.069488525390625,
      "learning_rate": 5.841022936989191e-06,
      "loss": 0.3288,
      "step": 12427
    },
    {
      "epoch": 0.737216751690592,
      "grad_norm": 13.250741004943848,
      "learning_rate": 5.839704719219615e-06,
      "loss": 0.3466,
      "step": 12428
    },
    {
      "epoch": 0.7372760707082691,
      "grad_norm": 16.150022506713867,
      "learning_rate": 5.8383865014500395e-06,
      "loss": 0.0864,
      "step": 12429
    },
    {
      "epoch": 0.7373353897259461,
      "grad_norm": 0.1268632411956787,
      "learning_rate": 5.8370682836804646e-06,
      "loss": 0.0014,
      "step": 12430
    },
    {
      "epoch": 0.7373947087436232,
      "grad_norm": 0.007553610019385815,
      "learning_rate": 5.835750065910889e-06,
      "loss": 0.0002,
      "step": 12431
    },
    {
      "epoch": 0.7374540277613003,
      "grad_norm": 0.02185240387916565,
      "learning_rate": 5.834431848141313e-06,
      "loss": 0.0004,
      "step": 12432
    },
    {
      "epoch": 0.7375133467789773,
      "grad_norm": 0.7502632737159729,
      "learning_rate": 5.833113630371738e-06,
      "loss": 0.0116,
      "step": 12433
    },
    {
      "epoch": 0.7375726657966544,
      "grad_norm": 11.333850860595703,
      "learning_rate": 5.831795412602162e-06,
      "loss": 0.6116,
      "step": 12434
    },
    {
      "epoch": 0.7376319848143315,
      "grad_norm": 0.01946915313601494,
      "learning_rate": 5.830477194832586e-06,
      "loss": 0.0003,
      "step": 12435
    },
    {
      "epoch": 0.7376913038320085,
      "grad_norm": 2.0892109870910645,
      "learning_rate": 5.8291589770630105e-06,
      "loss": 0.0264,
      "step": 12436
    },
    {
      "epoch": 0.7377506228496856,
      "grad_norm": 6.937208652496338,
      "learning_rate": 5.8278407592934364e-06,
      "loss": 0.2469,
      "step": 12437
    },
    {
      "epoch": 0.7378099418673627,
      "grad_norm": 2.425023317337036,
      "learning_rate": 5.826522541523861e-06,
      "loss": 0.0261,
      "step": 12438
    },
    {
      "epoch": 0.7378692608850398,
      "grad_norm": 1.065484881401062,
      "learning_rate": 5.825204323754284e-06,
      "loss": 0.0093,
      "step": 12439
    },
    {
      "epoch": 0.7379285799027168,
      "grad_norm": 0.5961015224456787,
      "learning_rate": 5.82388610598471e-06,
      "loss": 0.0046,
      "step": 12440
    },
    {
      "epoch": 0.7379878989203938,
      "grad_norm": 10.25863265991211,
      "learning_rate": 5.822567888215134e-06,
      "loss": 0.0864,
      "step": 12441
    },
    {
      "epoch": 0.7380472179380709,
      "grad_norm": 5.735065937042236,
      "learning_rate": 5.821249670445558e-06,
      "loss": 0.1041,
      "step": 12442
    },
    {
      "epoch": 0.738106536955748,
      "grad_norm": 20.366127014160156,
      "learning_rate": 5.819931452675982e-06,
      "loss": 0.1137,
      "step": 12443
    },
    {
      "epoch": 0.7381658559734251,
      "grad_norm": 2.1715593338012695,
      "learning_rate": 5.8186132349064074e-06,
      "loss": 0.0542,
      "step": 12444
    },
    {
      "epoch": 0.7382251749911022,
      "grad_norm": 13.298068046569824,
      "learning_rate": 5.817295017136832e-06,
      "loss": 0.9393,
      "step": 12445
    },
    {
      "epoch": 0.7382844940087793,
      "grad_norm": 3.081172466278076,
      "learning_rate": 5.815976799367256e-06,
      "loss": 0.028,
      "step": 12446
    },
    {
      "epoch": 0.7383438130264562,
      "grad_norm": 12.32526969909668,
      "learning_rate": 5.814658581597681e-06,
      "loss": 0.3066,
      "step": 12447
    },
    {
      "epoch": 0.7384031320441333,
      "grad_norm": 27.57472801208496,
      "learning_rate": 5.813340363828105e-06,
      "loss": 0.5084,
      "step": 12448
    },
    {
      "epoch": 0.7384624510618104,
      "grad_norm": 0.004543395712971687,
      "learning_rate": 5.812022146058529e-06,
      "loss": 0.0002,
      "step": 12449
    },
    {
      "epoch": 0.7385217700794875,
      "grad_norm": 0.09901171177625656,
      "learning_rate": 5.810703928288954e-06,
      "loss": 0.0014,
      "step": 12450
    },
    {
      "epoch": 0.7385810890971646,
      "grad_norm": 17.13252830505371,
      "learning_rate": 5.8093857105193784e-06,
      "loss": 0.2192,
      "step": 12451
    },
    {
      "epoch": 0.7386404081148417,
      "grad_norm": 5.28741455078125,
      "learning_rate": 5.808067492749803e-06,
      "loss": 0.1518,
      "step": 12452
    },
    {
      "epoch": 0.7386997271325186,
      "grad_norm": 16.81365203857422,
      "learning_rate": 5.806749274980227e-06,
      "loss": 0.1127,
      "step": 12453
    },
    {
      "epoch": 0.7387590461501957,
      "grad_norm": 22.91638946533203,
      "learning_rate": 5.805431057210652e-06,
      "loss": 1.8202,
      "step": 12454
    },
    {
      "epoch": 0.7388183651678728,
      "grad_norm": 14.055625915527344,
      "learning_rate": 5.804112839441076e-06,
      "loss": 0.145,
      "step": 12455
    },
    {
      "epoch": 0.7388776841855499,
      "grad_norm": 0.019064100459218025,
      "learning_rate": 5.8027946216715e-06,
      "loss": 0.0006,
      "step": 12456
    },
    {
      "epoch": 0.738937003203227,
      "grad_norm": 0.012138892896473408,
      "learning_rate": 5.801476403901925e-06,
      "loss": 0.0004,
      "step": 12457
    },
    {
      "epoch": 0.7389963222209041,
      "grad_norm": 0.06778255105018616,
      "learning_rate": 5.8001581861323494e-06,
      "loss": 0.0015,
      "step": 12458
    },
    {
      "epoch": 0.7390556412385811,
      "grad_norm": 3.395083427429199,
      "learning_rate": 5.798839968362774e-06,
      "loss": 0.0355,
      "step": 12459
    },
    {
      "epoch": 0.7391149602562581,
      "grad_norm": 0.014345486648380756,
      "learning_rate": 5.797521750593198e-06,
      "loss": 0.0005,
      "step": 12460
    },
    {
      "epoch": 0.7391742792739352,
      "grad_norm": 3.8809614181518555,
      "learning_rate": 5.796203532823623e-06,
      "loss": 0.1048,
      "step": 12461
    },
    {
      "epoch": 0.7392335982916123,
      "grad_norm": 1.6058024168014526,
      "learning_rate": 5.794885315054047e-06,
      "loss": 0.0081,
      "step": 12462
    },
    {
      "epoch": 0.7392929173092894,
      "grad_norm": 0.07368078082799911,
      "learning_rate": 5.793567097284471e-06,
      "loss": 0.0016,
      "step": 12463
    },
    {
      "epoch": 0.7393522363269664,
      "grad_norm": 0.1427462249994278,
      "learning_rate": 5.792248879514897e-06,
      "loss": 0.0014,
      "step": 12464
    },
    {
      "epoch": 0.7394115553446435,
      "grad_norm": 0.024347318336367607,
      "learning_rate": 5.790930661745321e-06,
      "loss": 0.0004,
      "step": 12465
    },
    {
      "epoch": 0.7394708743623205,
      "grad_norm": 0.023628244176506996,
      "learning_rate": 5.7896124439757455e-06,
      "loss": 0.0007,
      "step": 12466
    },
    {
      "epoch": 0.7395301933799976,
      "grad_norm": 12.05590534210205,
      "learning_rate": 5.788294226206169e-06,
      "loss": 0.2333,
      "step": 12467
    },
    {
      "epoch": 0.7395895123976747,
      "grad_norm": 0.057284608483314514,
      "learning_rate": 5.786976008436595e-06,
      "loss": 0.0007,
      "step": 12468
    },
    {
      "epoch": 0.7396488314153518,
      "grad_norm": 1.18474543094635,
      "learning_rate": 5.785657790667019e-06,
      "loss": 0.0108,
      "step": 12469
    },
    {
      "epoch": 0.7397081504330288,
      "grad_norm": 2.573089361190796,
      "learning_rate": 5.784339572897443e-06,
      "loss": 0.0179,
      "step": 12470
    },
    {
      "epoch": 0.7397674694507059,
      "grad_norm": 0.03574807941913605,
      "learning_rate": 5.783021355127868e-06,
      "loss": 0.0008,
      "step": 12471
    },
    {
      "epoch": 0.739826788468383,
      "grad_norm": 0.4495793282985687,
      "learning_rate": 5.781703137358292e-06,
      "loss": 0.0016,
      "step": 12472
    },
    {
      "epoch": 0.73988610748606,
      "grad_norm": 0.2189265638589859,
      "learning_rate": 5.7803849195887165e-06,
      "loss": 0.003,
      "step": 12473
    },
    {
      "epoch": 0.7399454265037371,
      "grad_norm": 0.627431333065033,
      "learning_rate": 5.7790667018191415e-06,
      "loss": 0.0044,
      "step": 12474
    },
    {
      "epoch": 0.7400047455214142,
      "grad_norm": 0.0357213169336319,
      "learning_rate": 5.777748484049566e-06,
      "loss": 0.0011,
      "step": 12475
    },
    {
      "epoch": 0.7400640645390912,
      "grad_norm": 0.011929200030863285,
      "learning_rate": 5.77643026627999e-06,
      "loss": 0.0003,
      "step": 12476
    },
    {
      "epoch": 0.7401233835567683,
      "grad_norm": 21.104814529418945,
      "learning_rate": 5.775112048510414e-06,
      "loss": 0.2404,
      "step": 12477
    },
    {
      "epoch": 0.7401827025744454,
      "grad_norm": 0.3704527020454407,
      "learning_rate": 5.773793830740839e-06,
      "loss": 0.0063,
      "step": 12478
    },
    {
      "epoch": 0.7402420215921224,
      "grad_norm": 11.017095565795898,
      "learning_rate": 5.772475612971263e-06,
      "loss": 0.1095,
      "step": 12479
    },
    {
      "epoch": 0.7403013406097995,
      "grad_norm": 0.10596345365047455,
      "learning_rate": 5.7711573952016875e-06,
      "loss": 0.001,
      "step": 12480
    },
    {
      "epoch": 0.7403606596274765,
      "grad_norm": 2.0148394107818604,
      "learning_rate": 5.7698391774321125e-06,
      "loss": 0.0251,
      "step": 12481
    },
    {
      "epoch": 0.7404199786451536,
      "grad_norm": 13.47689437866211,
      "learning_rate": 5.768520959662537e-06,
      "loss": 0.1609,
      "step": 12482
    },
    {
      "epoch": 0.7404792976628307,
      "grad_norm": 0.09833740442991257,
      "learning_rate": 5.767202741892961e-06,
      "loss": 0.0011,
      "step": 12483
    },
    {
      "epoch": 0.7405386166805078,
      "grad_norm": 0.035053737461566925,
      "learning_rate": 5.765884524123385e-06,
      "loss": 0.0005,
      "step": 12484
    },
    {
      "epoch": 0.7405979356981849,
      "grad_norm": 0.07119403034448624,
      "learning_rate": 5.76456630635381e-06,
      "loss": 0.0013,
      "step": 12485
    },
    {
      "epoch": 0.7406572547158619,
      "grad_norm": 0.40793779492378235,
      "learning_rate": 5.763248088584234e-06,
      "loss": 0.0021,
      "step": 12486
    },
    {
      "epoch": 0.7407165737335389,
      "grad_norm": 11.457433700561523,
      "learning_rate": 5.7619298708146585e-06,
      "loss": 0.8102,
      "step": 12487
    },
    {
      "epoch": 0.740775892751216,
      "grad_norm": 3.680509328842163,
      "learning_rate": 5.760611653045084e-06,
      "loss": 0.0505,
      "step": 12488
    },
    {
      "epoch": 0.7408352117688931,
      "grad_norm": 0.08152168244123459,
      "learning_rate": 5.759293435275508e-06,
      "loss": 0.0017,
      "step": 12489
    },
    {
      "epoch": 0.7408945307865702,
      "grad_norm": 0.12476412951946259,
      "learning_rate": 5.757975217505932e-06,
      "loss": 0.001,
      "step": 12490
    },
    {
      "epoch": 0.7409538498042473,
      "grad_norm": 8.814366340637207,
      "learning_rate": 5.756656999736356e-06,
      "loss": 0.8407,
      "step": 12491
    },
    {
      "epoch": 0.7410131688219244,
      "grad_norm": 2.05315899848938,
      "learning_rate": 5.755338781966782e-06,
      "loss": 0.0121,
      "step": 12492
    },
    {
      "epoch": 0.7410724878396013,
      "grad_norm": 0.4195643663406372,
      "learning_rate": 5.754020564197206e-06,
      "loss": 0.0053,
      "step": 12493
    },
    {
      "epoch": 0.7411318068572784,
      "grad_norm": 3.591269016265869,
      "learning_rate": 5.75270234642763e-06,
      "loss": 0.0162,
      "step": 12494
    },
    {
      "epoch": 0.7411911258749555,
      "grad_norm": 3.98770809173584,
      "learning_rate": 5.751384128658055e-06,
      "loss": 0.0222,
      "step": 12495
    },
    {
      "epoch": 0.7412504448926326,
      "grad_norm": 0.014371199533343315,
      "learning_rate": 5.7500659108884796e-06,
      "loss": 0.0005,
      "step": 12496
    },
    {
      "epoch": 0.7413097639103097,
      "grad_norm": 9.394277572631836,
      "learning_rate": 5.748747693118904e-06,
      "loss": 0.0569,
      "step": 12497
    },
    {
      "epoch": 0.7413690829279868,
      "grad_norm": 0.8327460289001465,
      "learning_rate": 5.747429475349329e-06,
      "loss": 0.0079,
      "step": 12498
    },
    {
      "epoch": 0.7414284019456637,
      "grad_norm": 0.17302632331848145,
      "learning_rate": 5.746111257579753e-06,
      "loss": 0.0022,
      "step": 12499
    },
    {
      "epoch": 0.7414877209633408,
      "grad_norm": 2.2561519145965576,
      "learning_rate": 5.744793039810177e-06,
      "loss": 0.02,
      "step": 12500
    },
    {
      "epoch": 0.7415470399810179,
      "grad_norm": 0.8371970057487488,
      "learning_rate": 5.743474822040601e-06,
      "loss": 0.0146,
      "step": 12501
    },
    {
      "epoch": 0.741606358998695,
      "grad_norm": 2.2246387004852295,
      "learning_rate": 5.742156604271026e-06,
      "loss": 0.0176,
      "step": 12502
    },
    {
      "epoch": 0.7416656780163721,
      "grad_norm": 0.07006263732910156,
      "learning_rate": 5.7408383865014506e-06,
      "loss": 0.0006,
      "step": 12503
    },
    {
      "epoch": 0.7417249970340491,
      "grad_norm": 0.8938077688217163,
      "learning_rate": 5.739520168731875e-06,
      "loss": 0.0097,
      "step": 12504
    },
    {
      "epoch": 0.7417843160517262,
      "grad_norm": 0.08988798409700394,
      "learning_rate": 5.7382019509623e-06,
      "loss": 0.0016,
      "step": 12505
    },
    {
      "epoch": 0.7418436350694032,
      "grad_norm": 0.021462682634592056,
      "learning_rate": 5.736883733192724e-06,
      "loss": 0.0005,
      "step": 12506
    },
    {
      "epoch": 0.7419029540870803,
      "grad_norm": 0.1814316362142563,
      "learning_rate": 5.735565515423148e-06,
      "loss": 0.0035,
      "step": 12507
    },
    {
      "epoch": 0.7419622731047574,
      "grad_norm": 0.16994144022464752,
      "learning_rate": 5.734247297653572e-06,
      "loss": 0.002,
      "step": 12508
    },
    {
      "epoch": 0.7420215921224345,
      "grad_norm": 10.787010192871094,
      "learning_rate": 5.732929079883997e-06,
      "loss": 0.0703,
      "step": 12509
    },
    {
      "epoch": 0.7420809111401115,
      "grad_norm": 1.2835211753845215,
      "learning_rate": 5.7316108621144216e-06,
      "loss": 0.01,
      "step": 12510
    },
    {
      "epoch": 0.7421402301577886,
      "grad_norm": 10.465238571166992,
      "learning_rate": 5.730292644344846e-06,
      "loss": 0.1672,
      "step": 12511
    },
    {
      "epoch": 0.7421995491754656,
      "grad_norm": 0.07039318978786469,
      "learning_rate": 5.728974426575271e-06,
      "loss": 0.0011,
      "step": 12512
    },
    {
      "epoch": 0.7422588681931427,
      "grad_norm": 2.1551010608673096,
      "learning_rate": 5.727656208805695e-06,
      "loss": 0.0115,
      "step": 12513
    },
    {
      "epoch": 0.7423181872108198,
      "grad_norm": 24.316802978515625,
      "learning_rate": 5.726337991036119e-06,
      "loss": 1.5942,
      "step": 12514
    },
    {
      "epoch": 0.7423775062284969,
      "grad_norm": 32.55219650268555,
      "learning_rate": 5.725019773266543e-06,
      "loss": 0.6724,
      "step": 12515
    },
    {
      "epoch": 0.7424368252461739,
      "grad_norm": 0.10514573752880096,
      "learning_rate": 5.723701555496969e-06,
      "loss": 0.0021,
      "step": 12516
    },
    {
      "epoch": 0.742496144263851,
      "grad_norm": 0.09500330686569214,
      "learning_rate": 5.7223833377273926e-06,
      "loss": 0.0023,
      "step": 12517
    },
    {
      "epoch": 0.7425554632815281,
      "grad_norm": 7.482262134552002,
      "learning_rate": 5.721065119957817e-06,
      "loss": 0.5634,
      "step": 12518
    },
    {
      "epoch": 0.7426147822992051,
      "grad_norm": 0.08702831715345383,
      "learning_rate": 5.719746902188243e-06,
      "loss": 0.0015,
      "step": 12519
    },
    {
      "epoch": 0.7426741013168822,
      "grad_norm": 0.3545621335506439,
      "learning_rate": 5.718428684418667e-06,
      "loss": 0.004,
      "step": 12520
    },
    {
      "epoch": 0.7427334203345592,
      "grad_norm": 0.1366887241601944,
      "learning_rate": 5.717110466649091e-06,
      "loss": 0.0017,
      "step": 12521
    },
    {
      "epoch": 0.7427927393522363,
      "grad_norm": 12.040722846984863,
      "learning_rate": 5.715792248879516e-06,
      "loss": 0.7664,
      "step": 12522
    },
    {
      "epoch": 0.7428520583699134,
      "grad_norm": 9.30781078338623,
      "learning_rate": 5.71447403110994e-06,
      "loss": 0.1831,
      "step": 12523
    },
    {
      "epoch": 0.7429113773875905,
      "grad_norm": 3.1575639247894287,
      "learning_rate": 5.713155813340364e-06,
      "loss": 0.126,
      "step": 12524
    },
    {
      "epoch": 0.7429706964052676,
      "grad_norm": 9.971025466918945,
      "learning_rate": 5.711837595570789e-06,
      "loss": 0.432,
      "step": 12525
    },
    {
      "epoch": 0.7430300154229446,
      "grad_norm": 15.3247652053833,
      "learning_rate": 5.710519377801214e-06,
      "loss": 0.6011,
      "step": 12526
    },
    {
      "epoch": 0.7430893344406216,
      "grad_norm": 0.028606195002794266,
      "learning_rate": 5.709201160031638e-06,
      "loss": 0.0007,
      "step": 12527
    },
    {
      "epoch": 0.7431486534582987,
      "grad_norm": 0.05899195000529289,
      "learning_rate": 5.707882942262062e-06,
      "loss": 0.0008,
      "step": 12528
    },
    {
      "epoch": 0.7432079724759758,
      "grad_norm": 0.014558120630681515,
      "learning_rate": 5.706564724492487e-06,
      "loss": 0.0003,
      "step": 12529
    },
    {
      "epoch": 0.7432672914936529,
      "grad_norm": 3.688995361328125,
      "learning_rate": 5.705246506722911e-06,
      "loss": 0.0889,
      "step": 12530
    },
    {
      "epoch": 0.74332661051133,
      "grad_norm": 8.9523286819458,
      "learning_rate": 5.703928288953335e-06,
      "loss": 0.3622,
      "step": 12531
    },
    {
      "epoch": 0.743385929529007,
      "grad_norm": 0.012417169287800789,
      "learning_rate": 5.70261007118376e-06,
      "loss": 0.0003,
      "step": 12532
    },
    {
      "epoch": 0.743445248546684,
      "grad_norm": 0.0468561053276062,
      "learning_rate": 5.701291853414185e-06,
      "loss": 0.0007,
      "step": 12533
    },
    {
      "epoch": 0.7435045675643611,
      "grad_norm": 0.04369664564728737,
      "learning_rate": 5.699973635644609e-06,
      "loss": 0.0005,
      "step": 12534
    },
    {
      "epoch": 0.7435638865820382,
      "grad_norm": 0.01762929931282997,
      "learning_rate": 5.698655417875033e-06,
      "loss": 0.0006,
      "step": 12535
    },
    {
      "epoch": 0.7436232055997153,
      "grad_norm": 0.8263028860092163,
      "learning_rate": 5.697337200105458e-06,
      "loss": 0.0111,
      "step": 12536
    },
    {
      "epoch": 0.7436825246173924,
      "grad_norm": 0.039417579770088196,
      "learning_rate": 5.696018982335882e-06,
      "loss": 0.0008,
      "step": 12537
    },
    {
      "epoch": 0.7437418436350695,
      "grad_norm": 1.28426992893219,
      "learning_rate": 5.6947007645663064e-06,
      "loss": 0.0072,
      "step": 12538
    },
    {
      "epoch": 0.7438011626527464,
      "grad_norm": 3.7806625366210938,
      "learning_rate": 5.693382546796731e-06,
      "loss": 0.1112,
      "step": 12539
    },
    {
      "epoch": 0.7438604816704235,
      "grad_norm": 1.7734291553497314,
      "learning_rate": 5.692064329027156e-06,
      "loss": 0.0144,
      "step": 12540
    },
    {
      "epoch": 0.7439198006881006,
      "grad_norm": 0.5830335021018982,
      "learning_rate": 5.69074611125758e-06,
      "loss": 0.0101,
      "step": 12541
    },
    {
      "epoch": 0.7439791197057777,
      "grad_norm": 5.8147125244140625,
      "learning_rate": 5.689427893488004e-06,
      "loss": 0.072,
      "step": 12542
    },
    {
      "epoch": 0.7440384387234548,
      "grad_norm": 0.9423561692237854,
      "learning_rate": 5.68810967571843e-06,
      "loss": 0.0088,
      "step": 12543
    },
    {
      "epoch": 0.7440977577411318,
      "grad_norm": 0.0046939910389482975,
      "learning_rate": 5.686791457948854e-06,
      "loss": 0.0001,
      "step": 12544
    },
    {
      "epoch": 0.7441570767588088,
      "grad_norm": 14.347095489501953,
      "learning_rate": 5.6854732401792774e-06,
      "loss": 0.8829,
      "step": 12545
    },
    {
      "epoch": 0.7442163957764859,
      "grad_norm": 14.80833625793457,
      "learning_rate": 5.684155022409703e-06,
      "loss": 0.5163,
      "step": 12546
    },
    {
      "epoch": 0.744275714794163,
      "grad_norm": 0.0592014379799366,
      "learning_rate": 5.6828368046401275e-06,
      "loss": 0.0009,
      "step": 12547
    },
    {
      "epoch": 0.7443350338118401,
      "grad_norm": 0.014864618889987469,
      "learning_rate": 5.681518586870552e-06,
      "loss": 0.0004,
      "step": 12548
    },
    {
      "epoch": 0.7443943528295172,
      "grad_norm": 0.38072091341018677,
      "learning_rate": 5.680200369100976e-06,
      "loss": 0.0033,
      "step": 12549
    },
    {
      "epoch": 0.7444536718471942,
      "grad_norm": 0.03403014317154884,
      "learning_rate": 5.678882151331401e-06,
      "loss": 0.0009,
      "step": 12550
    },
    {
      "epoch": 0.7445129908648713,
      "grad_norm": 10.731822967529297,
      "learning_rate": 5.677563933561825e-06,
      "loss": 0.7087,
      "step": 12551
    },
    {
      "epoch": 0.7445723098825483,
      "grad_norm": 2.7294695377349854,
      "learning_rate": 5.676245715792249e-06,
      "loss": 0.0059,
      "step": 12552
    },
    {
      "epoch": 0.7446316289002254,
      "grad_norm": 6.094298839569092,
      "learning_rate": 5.674927498022674e-06,
      "loss": 0.0353,
      "step": 12553
    },
    {
      "epoch": 0.7446909479179025,
      "grad_norm": 26.76818084716797,
      "learning_rate": 5.6736092802530985e-06,
      "loss": 0.7174,
      "step": 12554
    },
    {
      "epoch": 0.7447502669355796,
      "grad_norm": 0.021604884415864944,
      "learning_rate": 5.672291062483523e-06,
      "loss": 0.0004,
      "step": 12555
    },
    {
      "epoch": 0.7448095859532566,
      "grad_norm": 0.029817378148436546,
      "learning_rate": 5.670972844713947e-06,
      "loss": 0.0005,
      "step": 12556
    },
    {
      "epoch": 0.7448689049709337,
      "grad_norm": 0.013339795172214508,
      "learning_rate": 5.669654626944372e-06,
      "loss": 0.0003,
      "step": 12557
    },
    {
      "epoch": 0.7449282239886107,
      "grad_norm": 0.11955264210700989,
      "learning_rate": 5.668336409174796e-06,
      "loss": 0.0027,
      "step": 12558
    },
    {
      "epoch": 0.7449875430062878,
      "grad_norm": 9.012582778930664,
      "learning_rate": 5.66701819140522e-06,
      "loss": 0.353,
      "step": 12559
    },
    {
      "epoch": 0.7450468620239649,
      "grad_norm": 0.013434694148600101,
      "learning_rate": 5.665699973635645e-06,
      "loss": 0.0003,
      "step": 12560
    },
    {
      "epoch": 0.745106181041642,
      "grad_norm": 0.035410840064287186,
      "learning_rate": 5.6643817558660695e-06,
      "loss": 0.0009,
      "step": 12561
    },
    {
      "epoch": 0.745165500059319,
      "grad_norm": 9.775802612304688,
      "learning_rate": 5.663063538096494e-06,
      "loss": 0.1058,
      "step": 12562
    },
    {
      "epoch": 0.7452248190769961,
      "grad_norm": 2.7787928581237793,
      "learning_rate": 5.661745320326918e-06,
      "loss": 0.0346,
      "step": 12563
    },
    {
      "epoch": 0.7452841380946732,
      "grad_norm": 0.15270617604255676,
      "learning_rate": 5.660427102557343e-06,
      "loss": 0.0015,
      "step": 12564
    },
    {
      "epoch": 0.7453434571123502,
      "grad_norm": 0.005642032250761986,
      "learning_rate": 5.659108884787767e-06,
      "loss": 0.0002,
      "step": 12565
    },
    {
      "epoch": 0.7454027761300273,
      "grad_norm": 21.59177017211914,
      "learning_rate": 5.657790667018191e-06,
      "loss": 1.0714,
      "step": 12566
    },
    {
      "epoch": 0.7454620951477043,
      "grad_norm": 0.03158525750041008,
      "learning_rate": 5.656472449248616e-06,
      "loss": 0.0007,
      "step": 12567
    },
    {
      "epoch": 0.7455214141653814,
      "grad_norm": 0.49275827407836914,
      "learning_rate": 5.6551542314790405e-06,
      "loss": 0.0035,
      "step": 12568
    },
    {
      "epoch": 0.7455807331830585,
      "grad_norm": 0.22180315852165222,
      "learning_rate": 5.653836013709465e-06,
      "loss": 0.0029,
      "step": 12569
    },
    {
      "epoch": 0.7456400522007356,
      "grad_norm": 11.305012702941895,
      "learning_rate": 5.652517795939891e-06,
      "loss": 0.0507,
      "step": 12570
    },
    {
      "epoch": 0.7456993712184127,
      "grad_norm": 1.6930111646652222,
      "learning_rate": 5.651199578170315e-06,
      "loss": 0.01,
      "step": 12571
    },
    {
      "epoch": 0.7457586902360896,
      "grad_norm": 15.35685920715332,
      "learning_rate": 5.649881360400739e-06,
      "loss": 0.1282,
      "step": 12572
    },
    {
      "epoch": 0.7458180092537667,
      "grad_norm": 6.197648048400879,
      "learning_rate": 5.648563142631162e-06,
      "loss": 0.0188,
      "step": 12573
    },
    {
      "epoch": 0.7458773282714438,
      "grad_norm": 0.983546257019043,
      "learning_rate": 5.647244924861588e-06,
      "loss": 0.0221,
      "step": 12574
    },
    {
      "epoch": 0.7459366472891209,
      "grad_norm": 0.016997551545500755,
      "learning_rate": 5.645926707092012e-06,
      "loss": 0.0005,
      "step": 12575
    },
    {
      "epoch": 0.745995966306798,
      "grad_norm": 0.14910224080085754,
      "learning_rate": 5.6446084893224365e-06,
      "loss": 0.0009,
      "step": 12576
    },
    {
      "epoch": 0.7460552853244751,
      "grad_norm": 0.013140592724084854,
      "learning_rate": 5.643290271552862e-06,
      "loss": 0.0004,
      "step": 12577
    },
    {
      "epoch": 0.746114604342152,
      "grad_norm": 0.32764166593551636,
      "learning_rate": 5.641972053783286e-06,
      "loss": 0.0011,
      "step": 12578
    },
    {
      "epoch": 0.7461739233598291,
      "grad_norm": 0.03222956135869026,
      "learning_rate": 5.64065383601371e-06,
      "loss": 0.0007,
      "step": 12579
    },
    {
      "epoch": 0.7462332423775062,
      "grad_norm": 0.043135546147823334,
      "learning_rate": 5.639335618244134e-06,
      "loss": 0.0011,
      "step": 12580
    },
    {
      "epoch": 0.7462925613951833,
      "grad_norm": 0.06726406514644623,
      "learning_rate": 5.638017400474559e-06,
      "loss": 0.0015,
      "step": 12581
    },
    {
      "epoch": 0.7463518804128604,
      "grad_norm": 2.2028961181640625,
      "learning_rate": 5.636699182704983e-06,
      "loss": 0.0182,
      "step": 12582
    },
    {
      "epoch": 0.7464111994305375,
      "grad_norm": 21.959423065185547,
      "learning_rate": 5.6353809649354076e-06,
      "loss": 0.6663,
      "step": 12583
    },
    {
      "epoch": 0.7464705184482145,
      "grad_norm": 4.26088809967041,
      "learning_rate": 5.634062747165833e-06,
      "loss": 0.0377,
      "step": 12584
    },
    {
      "epoch": 0.7465298374658915,
      "grad_norm": 38.783905029296875,
      "learning_rate": 5.632744529396257e-06,
      "loss": 1.636,
      "step": 12585
    },
    {
      "epoch": 0.7465891564835686,
      "grad_norm": 1.7354559898376465,
      "learning_rate": 5.631426311626681e-06,
      "loss": 0.0311,
      "step": 12586
    },
    {
      "epoch": 0.7466484755012457,
      "grad_norm": 0.008638633415102959,
      "learning_rate": 5.630108093857105e-06,
      "loss": 0.0002,
      "step": 12587
    },
    {
      "epoch": 0.7467077945189228,
      "grad_norm": 1.277246117591858,
      "learning_rate": 5.62878987608753e-06,
      "loss": 0.0207,
      "step": 12588
    },
    {
      "epoch": 0.7467671135365999,
      "grad_norm": 7.772277355194092,
      "learning_rate": 5.627471658317954e-06,
      "loss": 0.2828,
      "step": 12589
    },
    {
      "epoch": 0.7468264325542769,
      "grad_norm": 1.1625728607177734,
      "learning_rate": 5.6261534405483786e-06,
      "loss": 0.0037,
      "step": 12590
    },
    {
      "epoch": 0.7468857515719539,
      "grad_norm": 7.698896408081055,
      "learning_rate": 5.624835222778804e-06,
      "loss": 0.7472,
      "step": 12591
    },
    {
      "epoch": 0.746945070589631,
      "grad_norm": 0.0027765631675720215,
      "learning_rate": 5.623517005009228e-06,
      "loss": 0.0001,
      "step": 12592
    },
    {
      "epoch": 0.7470043896073081,
      "grad_norm": 7.17526388168335,
      "learning_rate": 5.622198787239652e-06,
      "loss": 0.1196,
      "step": 12593
    },
    {
      "epoch": 0.7470637086249852,
      "grad_norm": 15.731094360351562,
      "learning_rate": 5.620880569470078e-06,
      "loss": 0.0694,
      "step": 12594
    },
    {
      "epoch": 0.7471230276426623,
      "grad_norm": 3.9126813411712646,
      "learning_rate": 5.619562351700501e-06,
      "loss": 0.0884,
      "step": 12595
    },
    {
      "epoch": 0.7471823466603393,
      "grad_norm": 2.3706517219543457,
      "learning_rate": 5.618244133930925e-06,
      "loss": 0.0137,
      "step": 12596
    },
    {
      "epoch": 0.7472416656780164,
      "grad_norm": 0.14127610623836517,
      "learning_rate": 5.6169259161613496e-06,
      "loss": 0.003,
      "step": 12597
    },
    {
      "epoch": 0.7473009846956934,
      "grad_norm": 1.3080002069473267,
      "learning_rate": 5.6156076983917754e-06,
      "loss": 0.0053,
      "step": 12598
    },
    {
      "epoch": 0.7473603037133705,
      "grad_norm": 0.014694168232381344,
      "learning_rate": 5.6142894806222e-06,
      "loss": 0.0005,
      "step": 12599
    },
    {
      "epoch": 0.7474196227310476,
      "grad_norm": 1.6372052431106567,
      "learning_rate": 5.612971262852624e-06,
      "loss": 0.0198,
      "step": 12600
    },
    {
      "epoch": 0.7474789417487246,
      "grad_norm": 0.48050418496131897,
      "learning_rate": 5.611653045083049e-06,
      "loss": 0.0047,
      "step": 12601
    },
    {
      "epoch": 0.7475382607664017,
      "grad_norm": 0.04741402342915535,
      "learning_rate": 5.610334827313473e-06,
      "loss": 0.0016,
      "step": 12602
    },
    {
      "epoch": 0.7475975797840788,
      "grad_norm": 0.12194058299064636,
      "learning_rate": 5.609016609543897e-06,
      "loss": 0.0025,
      "step": 12603
    },
    {
      "epoch": 0.7476568988017559,
      "grad_norm": 1.6965683698654175,
      "learning_rate": 5.607698391774321e-06,
      "loss": 0.1405,
      "step": 12604
    },
    {
      "epoch": 0.7477162178194329,
      "grad_norm": 1.0970523357391357,
      "learning_rate": 5.6063801740047464e-06,
      "loss": 0.006,
      "step": 12605
    },
    {
      "epoch": 0.74777553683711,
      "grad_norm": 0.018031684681773186,
      "learning_rate": 5.605061956235171e-06,
      "loss": 0.0002,
      "step": 12606
    },
    {
      "epoch": 0.747834855854787,
      "grad_norm": 21.931455612182617,
      "learning_rate": 5.603743738465595e-06,
      "loss": 0.5913,
      "step": 12607
    },
    {
      "epoch": 0.7478941748724641,
      "grad_norm": 0.2200571745634079,
      "learning_rate": 5.60242552069602e-06,
      "loss": 0.0048,
      "step": 12608
    },
    {
      "epoch": 0.7479534938901412,
      "grad_norm": 0.08503393083810806,
      "learning_rate": 5.601107302926444e-06,
      "loss": 0.0014,
      "step": 12609
    },
    {
      "epoch": 0.7480128129078183,
      "grad_norm": 5.683774471282959,
      "learning_rate": 5.599789085156868e-06,
      "loss": 0.1017,
      "step": 12610
    },
    {
      "epoch": 0.7480721319254953,
      "grad_norm": 0.13733737170696259,
      "learning_rate": 5.598470867387292e-06,
      "loss": 0.0026,
      "step": 12611
    },
    {
      "epoch": 0.7481314509431723,
      "grad_norm": 2.3792924880981445,
      "learning_rate": 5.5971526496177174e-06,
      "loss": 0.0207,
      "step": 12612
    },
    {
      "epoch": 0.7481907699608494,
      "grad_norm": 0.02253965474665165,
      "learning_rate": 5.595834431848142e-06,
      "loss": 0.0007,
      "step": 12613
    },
    {
      "epoch": 0.7482500889785265,
      "grad_norm": 0.02194170281291008,
      "learning_rate": 5.594516214078566e-06,
      "loss": 0.0004,
      "step": 12614
    },
    {
      "epoch": 0.7483094079962036,
      "grad_norm": 1.3482718467712402,
      "learning_rate": 5.593197996308991e-06,
      "loss": 0.0132,
      "step": 12615
    },
    {
      "epoch": 0.7483687270138807,
      "grad_norm": 0.04167540371417999,
      "learning_rate": 5.591879778539415e-06,
      "loss": 0.0007,
      "step": 12616
    },
    {
      "epoch": 0.7484280460315578,
      "grad_norm": 16.320037841796875,
      "learning_rate": 5.590561560769839e-06,
      "loss": 0.1547,
      "step": 12617
    },
    {
      "epoch": 0.7484873650492347,
      "grad_norm": 0.013613030314445496,
      "learning_rate": 5.589243343000264e-06,
      "loss": 0.0005,
      "step": 12618
    },
    {
      "epoch": 0.7485466840669118,
      "grad_norm": 6.031407356262207,
      "learning_rate": 5.5879251252306885e-06,
      "loss": 0.0441,
      "step": 12619
    },
    {
      "epoch": 0.7486060030845889,
      "grad_norm": 0.27819493412971497,
      "learning_rate": 5.586606907461113e-06,
      "loss": 0.0036,
      "step": 12620
    },
    {
      "epoch": 0.748665322102266,
      "grad_norm": 6.612257480621338,
      "learning_rate": 5.585288689691537e-06,
      "loss": 0.1048,
      "step": 12621
    },
    {
      "epoch": 0.7487246411199431,
      "grad_norm": 14.456230163574219,
      "learning_rate": 5.583970471921963e-06,
      "loss": 0.0854,
      "step": 12622
    },
    {
      "epoch": 0.7487839601376202,
      "grad_norm": 10.550241470336914,
      "learning_rate": 5.582652254152386e-06,
      "loss": 0.1371,
      "step": 12623
    },
    {
      "epoch": 0.7488432791552971,
      "grad_norm": 7.815474033355713,
      "learning_rate": 5.58133403638281e-06,
      "loss": 0.0561,
      "step": 12624
    },
    {
      "epoch": 0.7489025981729742,
      "grad_norm": 8.274683952331543,
      "learning_rate": 5.580015818613236e-06,
      "loss": 0.307,
      "step": 12625
    },
    {
      "epoch": 0.7489619171906513,
      "grad_norm": 0.022737575694918633,
      "learning_rate": 5.57869760084366e-06,
      "loss": 0.0005,
      "step": 12626
    },
    {
      "epoch": 0.7490212362083284,
      "grad_norm": 5.576146125793457,
      "learning_rate": 5.5773793830740845e-06,
      "loss": 0.0309,
      "step": 12627
    },
    {
      "epoch": 0.7490805552260055,
      "grad_norm": 1.67327082157135,
      "learning_rate": 5.576061165304508e-06,
      "loss": 0.0054,
      "step": 12628
    },
    {
      "epoch": 0.7491398742436826,
      "grad_norm": 14.312764167785645,
      "learning_rate": 5.574742947534934e-06,
      "loss": 0.7062,
      "step": 12629
    },
    {
      "epoch": 0.7491991932613596,
      "grad_norm": 25.73307991027832,
      "learning_rate": 5.573424729765358e-06,
      "loss": 0.6097,
      "step": 12630
    },
    {
      "epoch": 0.7492585122790366,
      "grad_norm": 0.14539334177970886,
      "learning_rate": 5.572106511995782e-06,
      "loss": 0.0028,
      "step": 12631
    },
    {
      "epoch": 0.7493178312967137,
      "grad_norm": 0.018879616633057594,
      "learning_rate": 5.570788294226207e-06,
      "loss": 0.0003,
      "step": 12632
    },
    {
      "epoch": 0.7493771503143908,
      "grad_norm": 21.47708511352539,
      "learning_rate": 5.569470076456631e-06,
      "loss": 0.7521,
      "step": 12633
    },
    {
      "epoch": 0.7494364693320679,
      "grad_norm": 9.36059284210205,
      "learning_rate": 5.5681518586870555e-06,
      "loss": 0.1237,
      "step": 12634
    },
    {
      "epoch": 0.749495788349745,
      "grad_norm": 15.536500930786133,
      "learning_rate": 5.5668336409174805e-06,
      "loss": 0.2668,
      "step": 12635
    },
    {
      "epoch": 0.749555107367422,
      "grad_norm": 15.12767505645752,
      "learning_rate": 5.565515423147905e-06,
      "loss": 0.3784,
      "step": 12636
    },
    {
      "epoch": 0.749614426385099,
      "grad_norm": 0.05691119283437729,
      "learning_rate": 5.564197205378329e-06,
      "loss": 0.0011,
      "step": 12637
    },
    {
      "epoch": 0.7496737454027761,
      "grad_norm": 12.65884780883789,
      "learning_rate": 5.562878987608753e-06,
      "loss": 0.5948,
      "step": 12638
    },
    {
      "epoch": 0.7497330644204532,
      "grad_norm": 2.3931217193603516,
      "learning_rate": 5.561560769839178e-06,
      "loss": 0.016,
      "step": 12639
    },
    {
      "epoch": 0.7497923834381303,
      "grad_norm": 9.330036163330078,
      "learning_rate": 5.560242552069602e-06,
      "loss": 0.1404,
      "step": 12640
    },
    {
      "epoch": 0.7498517024558073,
      "grad_norm": 0.07688266783952713,
      "learning_rate": 5.5589243343000265e-06,
      "loss": 0.0013,
      "step": 12641
    },
    {
      "epoch": 0.7499110214734844,
      "grad_norm": 0.023826908320188522,
      "learning_rate": 5.5576061165304515e-06,
      "loss": 0.0008,
      "step": 12642
    },
    {
      "epoch": 0.7499703404911615,
      "grad_norm": 4.235445022583008,
      "learning_rate": 5.556287898760876e-06,
      "loss": 0.0454,
      "step": 12643
    },
    {
      "epoch": 0.7500296595088385,
      "grad_norm": 0.007658080197870731,
      "learning_rate": 5.5549696809913e-06,
      "loss": 0.0002,
      "step": 12644
    },
    {
      "epoch": 0.7500889785265156,
      "grad_norm": 6.963256359100342,
      "learning_rate": 5.553651463221724e-06,
      "loss": 0.2064,
      "step": 12645
    },
    {
      "epoch": 0.7501482975441927,
      "grad_norm": 52.29763412475586,
      "learning_rate": 5.552333245452149e-06,
      "loss": 0.1,
      "step": 12646
    },
    {
      "epoch": 0.7502076165618697,
      "grad_norm": 73.41902160644531,
      "learning_rate": 5.551015027682573e-06,
      "loss": 0.4142,
      "step": 12647
    },
    {
      "epoch": 0.7502669355795468,
      "grad_norm": 0.009693131782114506,
      "learning_rate": 5.5496968099129975e-06,
      "loss": 0.0003,
      "step": 12648
    },
    {
      "epoch": 0.7503262545972239,
      "grad_norm": 0.006389274261891842,
      "learning_rate": 5.548378592143423e-06,
      "loss": 0.0002,
      "step": 12649
    },
    {
      "epoch": 0.750385573614901,
      "grad_norm": 0.9639643430709839,
      "learning_rate": 5.5470603743738476e-06,
      "loss": 0.0118,
      "step": 12650
    },
    {
      "epoch": 0.750444892632578,
      "grad_norm": 0.1025426834821701,
      "learning_rate": 5.545742156604271e-06,
      "loss": 0.0017,
      "step": 12651
    },
    {
      "epoch": 0.750504211650255,
      "grad_norm": 2.3893609046936035,
      "learning_rate": 5.544423938834695e-06,
      "loss": 0.0224,
      "step": 12652
    },
    {
      "epoch": 0.7505635306679321,
      "grad_norm": 18.71805763244629,
      "learning_rate": 5.543105721065121e-06,
      "loss": 0.2604,
      "step": 12653
    },
    {
      "epoch": 0.7506228496856092,
      "grad_norm": 2.1781651973724365,
      "learning_rate": 5.541787503295545e-06,
      "loss": 0.0226,
      "step": 12654
    },
    {
      "epoch": 0.7506821687032863,
      "grad_norm": 1.8280205726623535,
      "learning_rate": 5.540469285525969e-06,
      "loss": 0.1214,
      "step": 12655
    },
    {
      "epoch": 0.7507414877209634,
      "grad_norm": 40.083282470703125,
      "learning_rate": 5.539151067756394e-06,
      "loss": 0.9545,
      "step": 12656
    },
    {
      "epoch": 0.7508008067386404,
      "grad_norm": 2.0664901733398438,
      "learning_rate": 5.5378328499868186e-06,
      "loss": 0.032,
      "step": 12657
    },
    {
      "epoch": 0.7508601257563174,
      "grad_norm": 0.6820205450057983,
      "learning_rate": 5.536514632217243e-06,
      "loss": 0.0071,
      "step": 12658
    },
    {
      "epoch": 0.7509194447739945,
      "grad_norm": 0.08206567168235779,
      "learning_rate": 5.535196414447668e-06,
      "loss": 0.0015,
      "step": 12659
    },
    {
      "epoch": 0.7509787637916716,
      "grad_norm": 0.056390032172203064,
      "learning_rate": 5.533878196678092e-06,
      "loss": 0.0013,
      "step": 12660
    },
    {
      "epoch": 0.7510380828093487,
      "grad_norm": 0.039671942591667175,
      "learning_rate": 5.532559978908516e-06,
      "loss": 0.0005,
      "step": 12661
    },
    {
      "epoch": 0.7510974018270258,
      "grad_norm": 1.3498859405517578,
      "learning_rate": 5.53124176113894e-06,
      "loss": 0.0133,
      "step": 12662
    },
    {
      "epoch": 0.7511567208447029,
      "grad_norm": 0.007981005124747753,
      "learning_rate": 5.529923543369365e-06,
      "loss": 0.0003,
      "step": 12663
    },
    {
      "epoch": 0.7512160398623798,
      "grad_norm": 5.35305118560791,
      "learning_rate": 5.5286053255997896e-06,
      "loss": 0.011,
      "step": 12664
    },
    {
      "epoch": 0.7512753588800569,
      "grad_norm": 13.911945343017578,
      "learning_rate": 5.527287107830214e-06,
      "loss": 0.5719,
      "step": 12665
    },
    {
      "epoch": 0.751334677897734,
      "grad_norm": 6.970943450927734,
      "learning_rate": 5.525968890060639e-06,
      "loss": 0.0692,
      "step": 12666
    },
    {
      "epoch": 0.7513939969154111,
      "grad_norm": 0.005747092887759209,
      "learning_rate": 5.524650672291063e-06,
      "loss": 0.0002,
      "step": 12667
    },
    {
      "epoch": 0.7514533159330882,
      "grad_norm": 8.10349178314209,
      "learning_rate": 5.523332454521487e-06,
      "loss": 0.0983,
      "step": 12668
    },
    {
      "epoch": 0.7515126349507653,
      "grad_norm": 3.5381267070770264,
      "learning_rate": 5.522014236751911e-06,
      "loss": 0.07,
      "step": 12669
    },
    {
      "epoch": 0.7515719539684422,
      "grad_norm": 13.717488288879395,
      "learning_rate": 5.520696018982336e-06,
      "loss": 0.4064,
      "step": 12670
    },
    {
      "epoch": 0.7516312729861193,
      "grad_norm": 16.94241714477539,
      "learning_rate": 5.519377801212761e-06,
      "loss": 0.3699,
      "step": 12671
    },
    {
      "epoch": 0.7516905920037964,
      "grad_norm": 0.9806122183799744,
      "learning_rate": 5.518059583443185e-06,
      "loss": 0.0083,
      "step": 12672
    },
    {
      "epoch": 0.7517499110214735,
      "grad_norm": 0.23067812621593475,
      "learning_rate": 5.51674136567361e-06,
      "loss": 0.0018,
      "step": 12673
    },
    {
      "epoch": 0.7518092300391506,
      "grad_norm": 18.32133674621582,
      "learning_rate": 5.515423147904034e-06,
      "loss": 0.237,
      "step": 12674
    },
    {
      "epoch": 0.7518685490568277,
      "grad_norm": 9.347312927246094,
      "learning_rate": 5.514104930134458e-06,
      "loss": 0.0842,
      "step": 12675
    },
    {
      "epoch": 0.7519278680745047,
      "grad_norm": 1.9138413667678833,
      "learning_rate": 5.512786712364882e-06,
      "loss": 0.018,
      "step": 12676
    },
    {
      "epoch": 0.7519871870921817,
      "grad_norm": 0.007584633771330118,
      "learning_rate": 5.511468494595308e-06,
      "loss": 0.0002,
      "step": 12677
    },
    {
      "epoch": 0.7520465061098588,
      "grad_norm": 13.431283950805664,
      "learning_rate": 5.510150276825732e-06,
      "loss": 0.2172,
      "step": 12678
    },
    {
      "epoch": 0.7521058251275359,
      "grad_norm": 9.258974075317383,
      "learning_rate": 5.508832059056156e-06,
      "loss": 0.4257,
      "step": 12679
    },
    {
      "epoch": 0.752165144145213,
      "grad_norm": 3.3472371101379395,
      "learning_rate": 5.507513841286582e-06,
      "loss": 0.2763,
      "step": 12680
    },
    {
      "epoch": 0.75222446316289,
      "grad_norm": 3.0001485347747803,
      "learning_rate": 5.506195623517006e-06,
      "loss": 0.0243,
      "step": 12681
    },
    {
      "epoch": 0.7522837821805671,
      "grad_norm": 5.7395758628845215,
      "learning_rate": 5.50487740574743e-06,
      "loss": 0.0606,
      "step": 12682
    },
    {
      "epoch": 0.7523431011982441,
      "grad_norm": 1.4510540962219238,
      "learning_rate": 5.503559187977855e-06,
      "loss": 0.0189,
      "step": 12683
    },
    {
      "epoch": 0.7524024202159212,
      "grad_norm": 8.296000480651855,
      "learning_rate": 5.502240970208279e-06,
      "loss": 0.1327,
      "step": 12684
    },
    {
      "epoch": 0.7524617392335983,
      "grad_norm": 3.3946218490600586,
      "learning_rate": 5.5009227524387034e-06,
      "loss": 0.1026,
      "step": 12685
    },
    {
      "epoch": 0.7525210582512754,
      "grad_norm": 0.01114205364137888,
      "learning_rate": 5.499604534669128e-06,
      "loss": 0.0003,
      "step": 12686
    },
    {
      "epoch": 0.7525803772689524,
      "grad_norm": 8.558935165405273,
      "learning_rate": 5.498286316899553e-06,
      "loss": 0.2584,
      "step": 12687
    },
    {
      "epoch": 0.7526396962866295,
      "grad_norm": 0.016266565769910812,
      "learning_rate": 5.496968099129977e-06,
      "loss": 0.0003,
      "step": 12688
    },
    {
      "epoch": 0.7526990153043066,
      "grad_norm": 19.35051155090332,
      "learning_rate": 5.495649881360401e-06,
      "loss": 0.0885,
      "step": 12689
    },
    {
      "epoch": 0.7527583343219836,
      "grad_norm": 0.09702024608850479,
      "learning_rate": 5.494331663590826e-06,
      "loss": 0.0018,
      "step": 12690
    },
    {
      "epoch": 0.7528176533396607,
      "grad_norm": 9.291109085083008,
      "learning_rate": 5.49301344582125e-06,
      "loss": 0.1981,
      "step": 12691
    },
    {
      "epoch": 0.7528769723573377,
      "grad_norm": 16.328880310058594,
      "learning_rate": 5.4916952280516744e-06,
      "loss": 0.5155,
      "step": 12692
    },
    {
      "epoch": 0.7529362913750148,
      "grad_norm": 0.10898730158805847,
      "learning_rate": 5.490377010282099e-06,
      "loss": 0.0014,
      "step": 12693
    },
    {
      "epoch": 0.7529956103926919,
      "grad_norm": 0.3528878688812256,
      "learning_rate": 5.489058792512524e-06,
      "loss": 0.0018,
      "step": 12694
    },
    {
      "epoch": 0.753054929410369,
      "grad_norm": 0.6190212368965149,
      "learning_rate": 5.487740574742948e-06,
      "loss": 0.0043,
      "step": 12695
    },
    {
      "epoch": 0.7531142484280461,
      "grad_norm": 10.698968887329102,
      "learning_rate": 5.486422356973372e-06,
      "loss": 0.9102,
      "step": 12696
    },
    {
      "epoch": 0.7531735674457231,
      "grad_norm": 0.0393097959458828,
      "learning_rate": 5.485104139203797e-06,
      "loss": 0.001,
      "step": 12697
    },
    {
      "epoch": 0.7532328864634001,
      "grad_norm": 0.011789991520345211,
      "learning_rate": 5.483785921434221e-06,
      "loss": 0.0003,
      "step": 12698
    },
    {
      "epoch": 0.7532922054810772,
      "grad_norm": 0.6220108270645142,
      "learning_rate": 5.4824677036646454e-06,
      "loss": 0.0024,
      "step": 12699
    },
    {
      "epoch": 0.7533515244987543,
      "grad_norm": 14.653484344482422,
      "learning_rate": 5.48114948589507e-06,
      "loss": 0.0968,
      "step": 12700
    },
    {
      "epoch": 0.7534108435164314,
      "grad_norm": 0.009214024990797043,
      "learning_rate": 5.479831268125495e-06,
      "loss": 0.0003,
      "step": 12701
    },
    {
      "epoch": 0.7534701625341085,
      "grad_norm": 0.6952502131462097,
      "learning_rate": 5.478513050355919e-06,
      "loss": 0.0115,
      "step": 12702
    },
    {
      "epoch": 0.7535294815517855,
      "grad_norm": 2.3630011081695557,
      "learning_rate": 5.477194832586343e-06,
      "loss": 0.1634,
      "step": 12703
    },
    {
      "epoch": 0.7535888005694625,
      "grad_norm": 0.9161188006401062,
      "learning_rate": 5.475876614816769e-06,
      "loss": 0.0048,
      "step": 12704
    },
    {
      "epoch": 0.7536481195871396,
      "grad_norm": 0.2538757622241974,
      "learning_rate": 5.474558397047193e-06,
      "loss": 0.0027,
      "step": 12705
    },
    {
      "epoch": 0.7537074386048167,
      "grad_norm": 57.433685302734375,
      "learning_rate": 5.4732401792776164e-06,
      "loss": 0.2292,
      "step": 12706
    },
    {
      "epoch": 0.7537667576224938,
      "grad_norm": 0.18313834071159363,
      "learning_rate": 5.471921961508042e-06,
      "loss": 0.003,
      "step": 12707
    },
    {
      "epoch": 0.7538260766401709,
      "grad_norm": 1.7415084838867188,
      "learning_rate": 5.4706037437384665e-06,
      "loss": 0.0247,
      "step": 12708
    },
    {
      "epoch": 0.753885395657848,
      "grad_norm": 0.012382281944155693,
      "learning_rate": 5.469285525968891e-06,
      "loss": 0.0003,
      "step": 12709
    },
    {
      "epoch": 0.7539447146755249,
      "grad_norm": 6.745205402374268,
      "learning_rate": 5.467967308199315e-06,
      "loss": 0.3065,
      "step": 12710
    },
    {
      "epoch": 0.754004033693202,
      "grad_norm": 2.289885997772217,
      "learning_rate": 5.46664909042974e-06,
      "loss": 0.0133,
      "step": 12711
    },
    {
      "epoch": 0.7540633527108791,
      "grad_norm": 0.035302720963954926,
      "learning_rate": 5.465330872660164e-06,
      "loss": 0.0008,
      "step": 12712
    },
    {
      "epoch": 0.7541226717285562,
      "grad_norm": 0.4536101222038269,
      "learning_rate": 5.464012654890588e-06,
      "loss": 0.0046,
      "step": 12713
    },
    {
      "epoch": 0.7541819907462333,
      "grad_norm": 0.019704928621649742,
      "learning_rate": 5.462694437121013e-06,
      "loss": 0.0004,
      "step": 12714
    },
    {
      "epoch": 0.7542413097639104,
      "grad_norm": 8.324795722961426,
      "learning_rate": 5.4613762193514375e-06,
      "loss": 0.1313,
      "step": 12715
    },
    {
      "epoch": 0.7543006287815873,
      "grad_norm": 0.316993772983551,
      "learning_rate": 5.460058001581862e-06,
      "loss": 0.0033,
      "step": 12716
    },
    {
      "epoch": 0.7543599477992644,
      "grad_norm": 0.2348894327878952,
      "learning_rate": 5.458739783812286e-06,
      "loss": 0.004,
      "step": 12717
    },
    {
      "epoch": 0.7544192668169415,
      "grad_norm": 0.4520972669124603,
      "learning_rate": 5.457421566042711e-06,
      "loss": 0.0049,
      "step": 12718
    },
    {
      "epoch": 0.7544785858346186,
      "grad_norm": 0.0838354080915451,
      "learning_rate": 5.456103348273135e-06,
      "loss": 0.0012,
      "step": 12719
    },
    {
      "epoch": 0.7545379048522957,
      "grad_norm": 7.716442584991455,
      "learning_rate": 5.454785130503559e-06,
      "loss": 0.0434,
      "step": 12720
    },
    {
      "epoch": 0.7545972238699727,
      "grad_norm": 49.63427734375,
      "learning_rate": 5.453466912733984e-06,
      "loss": 0.4617,
      "step": 12721
    },
    {
      "epoch": 0.7546565428876498,
      "grad_norm": 16.047788619995117,
      "learning_rate": 5.4521486949644085e-06,
      "loss": 0.4773,
      "step": 12722
    },
    {
      "epoch": 0.7547158619053268,
      "grad_norm": 0.4532662332057953,
      "learning_rate": 5.450830477194833e-06,
      "loss": 0.0071,
      "step": 12723
    },
    {
      "epoch": 0.7547751809230039,
      "grad_norm": 0.006363824475556612,
      "learning_rate": 5.449512259425257e-06,
      "loss": 0.0002,
      "step": 12724
    },
    {
      "epoch": 0.754834499940681,
      "grad_norm": 0.09533358365297318,
      "learning_rate": 5.448194041655682e-06,
      "loss": 0.0012,
      "step": 12725
    },
    {
      "epoch": 0.754893818958358,
      "grad_norm": 6.568685054779053,
      "learning_rate": 5.446875823886106e-06,
      "loss": 0.1086,
      "step": 12726
    },
    {
      "epoch": 0.7549531379760351,
      "grad_norm": 8.396007537841797,
      "learning_rate": 5.44555760611653e-06,
      "loss": 0.1233,
      "step": 12727
    },
    {
      "epoch": 0.7550124569937122,
      "grad_norm": 0.236240416765213,
      "learning_rate": 5.444239388346955e-06,
      "loss": 0.005,
      "step": 12728
    },
    {
      "epoch": 0.7550717760113893,
      "grad_norm": 0.020413929596543312,
      "learning_rate": 5.4429211705773795e-06,
      "loss": 0.0005,
      "step": 12729
    },
    {
      "epoch": 0.7551310950290663,
      "grad_norm": 14.036887168884277,
      "learning_rate": 5.441602952807804e-06,
      "loss": 1.5499,
      "step": 12730
    },
    {
      "epoch": 0.7551904140467434,
      "grad_norm": 4.646646499633789,
      "learning_rate": 5.44028473503823e-06,
      "loss": 0.0433,
      "step": 12731
    },
    {
      "epoch": 0.7552497330644204,
      "grad_norm": 3.628948211669922,
      "learning_rate": 5.438966517268654e-06,
      "loss": 0.0141,
      "step": 12732
    },
    {
      "epoch": 0.7553090520820975,
      "grad_norm": 0.07068436592817307,
      "learning_rate": 5.437648299499078e-06,
      "loss": 0.0007,
      "step": 12733
    },
    {
      "epoch": 0.7553683710997746,
      "grad_norm": 0.25260648131370544,
      "learning_rate": 5.436330081729501e-06,
      "loss": 0.0015,
      "step": 12734
    },
    {
      "epoch": 0.7554276901174517,
      "grad_norm": 7.824814319610596,
      "learning_rate": 5.435011863959927e-06,
      "loss": 0.11,
      "step": 12735
    },
    {
      "epoch": 0.7554870091351287,
      "grad_norm": 1.351035714149475,
      "learning_rate": 5.433693646190351e-06,
      "loss": 0.0179,
      "step": 12736
    },
    {
      "epoch": 0.7555463281528058,
      "grad_norm": 0.13096633553504944,
      "learning_rate": 5.4323754284207756e-06,
      "loss": 0.0024,
      "step": 12737
    },
    {
      "epoch": 0.7556056471704828,
      "grad_norm": 0.24617734551429749,
      "learning_rate": 5.431057210651201e-06,
      "loss": 0.0028,
      "step": 12738
    },
    {
      "epoch": 0.7556649661881599,
      "grad_norm": 1.5141074657440186,
      "learning_rate": 5.429738992881625e-06,
      "loss": 0.0167,
      "step": 12739
    },
    {
      "epoch": 0.755724285205837,
      "grad_norm": 5.594208240509033,
      "learning_rate": 5.428420775112049e-06,
      "loss": 0.0359,
      "step": 12740
    },
    {
      "epoch": 0.7557836042235141,
      "grad_norm": 0.03726065903902054,
      "learning_rate": 5.427102557342473e-06,
      "loss": 0.0005,
      "step": 12741
    },
    {
      "epoch": 0.7558429232411912,
      "grad_norm": 0.616427481174469,
      "learning_rate": 5.425784339572898e-06,
      "loss": 0.0091,
      "step": 12742
    },
    {
      "epoch": 0.7559022422588682,
      "grad_norm": 0.4404262602329254,
      "learning_rate": 5.424466121803322e-06,
      "loss": 0.008,
      "step": 12743
    },
    {
      "epoch": 0.7559615612765452,
      "grad_norm": 0.07631037384271622,
      "learning_rate": 5.4231479040337466e-06,
      "loss": 0.0015,
      "step": 12744
    },
    {
      "epoch": 0.7560208802942223,
      "grad_norm": 0.01978234015405178,
      "learning_rate": 5.421829686264172e-06,
      "loss": 0.0006,
      "step": 12745
    },
    {
      "epoch": 0.7560801993118994,
      "grad_norm": 0.01339562889188528,
      "learning_rate": 5.420511468494596e-06,
      "loss": 0.0005,
      "step": 12746
    },
    {
      "epoch": 0.7561395183295765,
      "grad_norm": 4.941967010498047,
      "learning_rate": 5.41919325072502e-06,
      "loss": 0.0652,
      "step": 12747
    },
    {
      "epoch": 0.7561988373472536,
      "grad_norm": 0.037349049001932144,
      "learning_rate": 5.417875032955444e-06,
      "loss": 0.0009,
      "step": 12748
    },
    {
      "epoch": 0.7562581563649305,
      "grad_norm": 0.032740890979766846,
      "learning_rate": 5.416556815185869e-06,
      "loss": 0.0006,
      "step": 12749
    },
    {
      "epoch": 0.7563174753826076,
      "grad_norm": 12.523063659667969,
      "learning_rate": 5.415238597416293e-06,
      "loss": 0.783,
      "step": 12750
    },
    {
      "epoch": 0.7563767944002847,
      "grad_norm": 20.07882308959961,
      "learning_rate": 5.4139203796467176e-06,
      "loss": 0.8691,
      "step": 12751
    },
    {
      "epoch": 0.7564361134179618,
      "grad_norm": 3.5483381748199463,
      "learning_rate": 5.412602161877143e-06,
      "loss": 0.0517,
      "step": 12752
    },
    {
      "epoch": 0.7564954324356389,
      "grad_norm": 5.124715328216553,
      "learning_rate": 5.411283944107567e-06,
      "loss": 0.0568,
      "step": 12753
    },
    {
      "epoch": 0.756554751453316,
      "grad_norm": 0.02842881716787815,
      "learning_rate": 5.409965726337991e-06,
      "loss": 0.0004,
      "step": 12754
    },
    {
      "epoch": 0.756614070470993,
      "grad_norm": 31.01348304748535,
      "learning_rate": 5.408647508568417e-06,
      "loss": 0.9528,
      "step": 12755
    },
    {
      "epoch": 0.75667338948867,
      "grad_norm": 13.851466178894043,
      "learning_rate": 5.40732929079884e-06,
      "loss": 0.5868,
      "step": 12756
    },
    {
      "epoch": 0.7567327085063471,
      "grad_norm": 0.014980457723140717,
      "learning_rate": 5.406011073029264e-06,
      "loss": 0.0005,
      "step": 12757
    },
    {
      "epoch": 0.7567920275240242,
      "grad_norm": 5.39990234375,
      "learning_rate": 5.4046928552596886e-06,
      "loss": 0.1479,
      "step": 12758
    },
    {
      "epoch": 0.7568513465417013,
      "grad_norm": 25.033056259155273,
      "learning_rate": 5.4033746374901145e-06,
      "loss": 0.6307,
      "step": 12759
    },
    {
      "epoch": 0.7569106655593784,
      "grad_norm": 0.009629390202462673,
      "learning_rate": 5.402056419720539e-06,
      "loss": 0.0002,
      "step": 12760
    },
    {
      "epoch": 0.7569699845770554,
      "grad_norm": 0.13050691783428192,
      "learning_rate": 5.400738201950963e-06,
      "loss": 0.0021,
      "step": 12761
    },
    {
      "epoch": 0.7570293035947324,
      "grad_norm": 2.424246311187744,
      "learning_rate": 5.399419984181388e-06,
      "loss": 0.2188,
      "step": 12762
    },
    {
      "epoch": 0.7570886226124095,
      "grad_norm": 0.00541152385994792,
      "learning_rate": 5.398101766411812e-06,
      "loss": 0.0002,
      "step": 12763
    },
    {
      "epoch": 0.7571479416300866,
      "grad_norm": 21.80268096923828,
      "learning_rate": 5.396783548642236e-06,
      "loss": 0.1296,
      "step": 12764
    },
    {
      "epoch": 0.7572072606477637,
      "grad_norm": 0.6993269324302673,
      "learning_rate": 5.3954653308726604e-06,
      "loss": 0.0079,
      "step": 12765
    },
    {
      "epoch": 0.7572665796654408,
      "grad_norm": 0.026107899844646454,
      "learning_rate": 5.3941471131030855e-06,
      "loss": 0.0002,
      "step": 12766
    },
    {
      "epoch": 0.7573258986831178,
      "grad_norm": 0.010641696862876415,
      "learning_rate": 5.39282889533351e-06,
      "loss": 0.0003,
      "step": 12767
    },
    {
      "epoch": 0.7573852177007949,
      "grad_norm": 3.0418291091918945,
      "learning_rate": 5.391510677563934e-06,
      "loss": 0.0338,
      "step": 12768
    },
    {
      "epoch": 0.7574445367184719,
      "grad_norm": 24.52616310119629,
      "learning_rate": 5.390192459794359e-06,
      "loss": 0.2319,
      "step": 12769
    },
    {
      "epoch": 0.757503855736149,
      "grad_norm": 2.2932143211364746,
      "learning_rate": 5.388874242024783e-06,
      "loss": 0.0239,
      "step": 12770
    },
    {
      "epoch": 0.7575631747538261,
      "grad_norm": 0.368592768907547,
      "learning_rate": 5.387556024255207e-06,
      "loss": 0.0038,
      "step": 12771
    },
    {
      "epoch": 0.7576224937715031,
      "grad_norm": 6.5599446296691895,
      "learning_rate": 5.3862378064856314e-06,
      "loss": 0.2452,
      "step": 12772
    },
    {
      "epoch": 0.7576818127891802,
      "grad_norm": 0.18068629503250122,
      "learning_rate": 5.3849195887160565e-06,
      "loss": 0.003,
      "step": 12773
    },
    {
      "epoch": 0.7577411318068573,
      "grad_norm": 0.01169088389724493,
      "learning_rate": 5.383601370946481e-06,
      "loss": 0.0004,
      "step": 12774
    },
    {
      "epoch": 0.7578004508245344,
      "grad_norm": 15.286849975585938,
      "learning_rate": 5.382283153176905e-06,
      "loss": 0.1785,
      "step": 12775
    },
    {
      "epoch": 0.7578597698422114,
      "grad_norm": 0.0646086111664772,
      "learning_rate": 5.38096493540733e-06,
      "loss": 0.001,
      "step": 12776
    },
    {
      "epoch": 0.7579190888598885,
      "grad_norm": 0.019754428416490555,
      "learning_rate": 5.379646717637754e-06,
      "loss": 0.0004,
      "step": 12777
    },
    {
      "epoch": 0.7579784078775655,
      "grad_norm": 0.04518262296915054,
      "learning_rate": 5.378328499868178e-06,
      "loss": 0.0009,
      "step": 12778
    },
    {
      "epoch": 0.7580377268952426,
      "grad_norm": 0.11949905753135681,
      "learning_rate": 5.377010282098603e-06,
      "loss": 0.0014,
      "step": 12779
    },
    {
      "epoch": 0.7580970459129197,
      "grad_norm": 0.2004747986793518,
      "learning_rate": 5.3756920643290275e-06,
      "loss": 0.0016,
      "step": 12780
    },
    {
      "epoch": 0.7581563649305968,
      "grad_norm": 53.49870300292969,
      "learning_rate": 5.374373846559452e-06,
      "loss": 0.3379,
      "step": 12781
    },
    {
      "epoch": 0.7582156839482738,
      "grad_norm": 26.406078338623047,
      "learning_rate": 5.373055628789876e-06,
      "loss": 1.3216,
      "step": 12782
    },
    {
      "epoch": 0.7582750029659509,
      "grad_norm": 22.788631439208984,
      "learning_rate": 5.371737411020302e-06,
      "loss": 0.766,
      "step": 12783
    },
    {
      "epoch": 0.7583343219836279,
      "grad_norm": 0.0928531140089035,
      "learning_rate": 5.370419193250725e-06,
      "loss": 0.0017,
      "step": 12784
    },
    {
      "epoch": 0.758393641001305,
      "grad_norm": 1.5411632061004639,
      "learning_rate": 5.369100975481149e-06,
      "loss": 0.0204,
      "step": 12785
    },
    {
      "epoch": 0.7584529600189821,
      "grad_norm": 4.241979122161865,
      "learning_rate": 5.367782757711575e-06,
      "loss": 0.0168,
      "step": 12786
    },
    {
      "epoch": 0.7585122790366592,
      "grad_norm": 0.3458837568759918,
      "learning_rate": 5.366464539941999e-06,
      "loss": 0.007,
      "step": 12787
    },
    {
      "epoch": 0.7585715980543363,
      "grad_norm": 0.00974823348224163,
      "learning_rate": 5.3651463221724235e-06,
      "loss": 0.0003,
      "step": 12788
    },
    {
      "epoch": 0.7586309170720132,
      "grad_norm": 2.3346304893493652,
      "learning_rate": 5.363828104402848e-06,
      "loss": 0.0477,
      "step": 12789
    },
    {
      "epoch": 0.7586902360896903,
      "grad_norm": 1.4766219854354858,
      "learning_rate": 5.362509886633273e-06,
      "loss": 0.0168,
      "step": 12790
    },
    {
      "epoch": 0.7587495551073674,
      "grad_norm": 6.144317150115967,
      "learning_rate": 5.361191668863697e-06,
      "loss": 0.0921,
      "step": 12791
    },
    {
      "epoch": 0.7588088741250445,
      "grad_norm": 72.87867736816406,
      "learning_rate": 5.359873451094121e-06,
      "loss": 0.8126,
      "step": 12792
    },
    {
      "epoch": 0.7588681931427216,
      "grad_norm": 0.04289751127362251,
      "learning_rate": 5.358555233324546e-06,
      "loss": 0.0011,
      "step": 12793
    },
    {
      "epoch": 0.7589275121603987,
      "grad_norm": 0.010975275188684464,
      "learning_rate": 5.35723701555497e-06,
      "loss": 0.0004,
      "step": 12794
    },
    {
      "epoch": 0.7589868311780756,
      "grad_norm": 2.8436622619628906,
      "learning_rate": 5.3559187977853945e-06,
      "loss": 0.0398,
      "step": 12795
    },
    {
      "epoch": 0.7590461501957527,
      "grad_norm": 11.051416397094727,
      "learning_rate": 5.354600580015819e-06,
      "loss": 0.112,
      "step": 12796
    },
    {
      "epoch": 0.7591054692134298,
      "grad_norm": 7.819587707519531,
      "learning_rate": 5.353282362246244e-06,
      "loss": 0.2085,
      "step": 12797
    },
    {
      "epoch": 0.7591647882311069,
      "grad_norm": 12.743061065673828,
      "learning_rate": 5.351964144476668e-06,
      "loss": 0.2621,
      "step": 12798
    },
    {
      "epoch": 0.759224107248784,
      "grad_norm": 12.32060718536377,
      "learning_rate": 5.350645926707092e-06,
      "loss": 0.4354,
      "step": 12799
    },
    {
      "epoch": 0.7592834262664611,
      "grad_norm": 31.20884895324707,
      "learning_rate": 5.349327708937517e-06,
      "loss": 0.0899,
      "step": 12800
    },
    {
      "epoch": 0.7593427452841381,
      "grad_norm": 1.5847688913345337,
      "learning_rate": 5.348009491167941e-06,
      "loss": 0.0148,
      "step": 12801
    },
    {
      "epoch": 0.7594020643018151,
      "grad_norm": 7.638308525085449,
      "learning_rate": 5.3466912733983655e-06,
      "loss": 0.2967,
      "step": 12802
    },
    {
      "epoch": 0.7594613833194922,
      "grad_norm": 0.06527187675237656,
      "learning_rate": 5.3453730556287905e-06,
      "loss": 0.0011,
      "step": 12803
    },
    {
      "epoch": 0.7595207023371693,
      "grad_norm": 0.09793960303068161,
      "learning_rate": 5.344054837859215e-06,
      "loss": 0.0011,
      "step": 12804
    },
    {
      "epoch": 0.7595800213548464,
      "grad_norm": 0.020125549286603928,
      "learning_rate": 5.342736620089639e-06,
      "loss": 0.0005,
      "step": 12805
    },
    {
      "epoch": 0.7596393403725235,
      "grad_norm": 0.0052125109359622,
      "learning_rate": 5.341418402320063e-06,
      "loss": 0.0002,
      "step": 12806
    },
    {
      "epoch": 0.7596986593902005,
      "grad_norm": 5.796720504760742,
      "learning_rate": 5.340100184550488e-06,
      "loss": 0.0576,
      "step": 12807
    },
    {
      "epoch": 0.7597579784078776,
      "grad_norm": 0.01011525746434927,
      "learning_rate": 5.338781966780912e-06,
      "loss": 0.0003,
      "step": 12808
    },
    {
      "epoch": 0.7598172974255546,
      "grad_norm": 0.11104503273963928,
      "learning_rate": 5.3374637490113365e-06,
      "loss": 0.0022,
      "step": 12809
    },
    {
      "epoch": 0.7598766164432317,
      "grad_norm": 0.272988498210907,
      "learning_rate": 5.336145531241762e-06,
      "loss": 0.0045,
      "step": 12810
    },
    {
      "epoch": 0.7599359354609088,
      "grad_norm": 7.888209342956543,
      "learning_rate": 5.334827313472187e-06,
      "loss": 0.0675,
      "step": 12811
    },
    {
      "epoch": 0.7599952544785858,
      "grad_norm": 0.06351827830076218,
      "learning_rate": 5.33350909570261e-06,
      "loss": 0.0011,
      "step": 12812
    },
    {
      "epoch": 0.7600545734962629,
      "grad_norm": 0.06464046984910965,
      "learning_rate": 5.332190877933034e-06,
      "loss": 0.0015,
      "step": 12813
    },
    {
      "epoch": 0.76011389251394,
      "grad_norm": 1.073309063911438,
      "learning_rate": 5.33087266016346e-06,
      "loss": 0.0082,
      "step": 12814
    },
    {
      "epoch": 0.760173211531617,
      "grad_norm": 0.02299307845532894,
      "learning_rate": 5.329554442393884e-06,
      "loss": 0.0006,
      "step": 12815
    },
    {
      "epoch": 0.7602325305492941,
      "grad_norm": 17.886871337890625,
      "learning_rate": 5.328236224624308e-06,
      "loss": 0.4539,
      "step": 12816
    },
    {
      "epoch": 0.7602918495669712,
      "grad_norm": 3.737630605697632,
      "learning_rate": 5.326918006854733e-06,
      "loss": 0.0777,
      "step": 12817
    },
    {
      "epoch": 0.7603511685846482,
      "grad_norm": 6.909292697906494,
      "learning_rate": 5.325599789085158e-06,
      "loss": 0.1489,
      "step": 12818
    },
    {
      "epoch": 0.7604104876023253,
      "grad_norm": 0.04559451714158058,
      "learning_rate": 5.324281571315582e-06,
      "loss": 0.0009,
      "step": 12819
    },
    {
      "epoch": 0.7604698066200024,
      "grad_norm": 0.07039246708154678,
      "learning_rate": 5.322963353546006e-06,
      "loss": 0.0013,
      "step": 12820
    },
    {
      "epoch": 0.7605291256376795,
      "grad_norm": 14.4523344039917,
      "learning_rate": 5.321645135776431e-06,
      "loss": 0.4974,
      "step": 12821
    },
    {
      "epoch": 0.7605884446553565,
      "grad_norm": 2.9396049976348877,
      "learning_rate": 5.320326918006855e-06,
      "loss": 0.0241,
      "step": 12822
    },
    {
      "epoch": 0.7606477636730336,
      "grad_norm": 21.015167236328125,
      "learning_rate": 5.319008700237279e-06,
      "loss": 0.6533,
      "step": 12823
    },
    {
      "epoch": 0.7607070826907106,
      "grad_norm": 1.8592536449432373,
      "learning_rate": 5.317690482467704e-06,
      "loss": 0.0255,
      "step": 12824
    },
    {
      "epoch": 0.7607664017083877,
      "grad_norm": 0.018922818824648857,
      "learning_rate": 5.316372264698129e-06,
      "loss": 0.0004,
      "step": 12825
    },
    {
      "epoch": 0.7608257207260648,
      "grad_norm": 16.57662010192871,
      "learning_rate": 5.315054046928553e-06,
      "loss": 0.3343,
      "step": 12826
    },
    {
      "epoch": 0.7608850397437419,
      "grad_norm": 0.07869801670312881,
      "learning_rate": 5.313735829158978e-06,
      "loss": 0.0014,
      "step": 12827
    },
    {
      "epoch": 0.7609443587614189,
      "grad_norm": 9.16748332977295,
      "learning_rate": 5.312417611389402e-06,
      "loss": 0.0527,
      "step": 12828
    },
    {
      "epoch": 0.7610036777790959,
      "grad_norm": 12.944809913635254,
      "learning_rate": 5.311099393619826e-06,
      "loss": 0.5588,
      "step": 12829
    },
    {
      "epoch": 0.761062996796773,
      "grad_norm": 10.679588317871094,
      "learning_rate": 5.30978117585025e-06,
      "loss": 0.145,
      "step": 12830
    },
    {
      "epoch": 0.7611223158144501,
      "grad_norm": 9.532470703125,
      "learning_rate": 5.308462958080675e-06,
      "loss": 0.5459,
      "step": 12831
    },
    {
      "epoch": 0.7611816348321272,
      "grad_norm": 0.04736385494470596,
      "learning_rate": 5.3071447403111e-06,
      "loss": 0.0007,
      "step": 12832
    },
    {
      "epoch": 0.7612409538498043,
      "grad_norm": 0.045458536595106125,
      "learning_rate": 5.305826522541524e-06,
      "loss": 0.0009,
      "step": 12833
    },
    {
      "epoch": 0.7613002728674814,
      "grad_norm": 0.946779727935791,
      "learning_rate": 5.304508304771949e-06,
      "loss": 0.0145,
      "step": 12834
    },
    {
      "epoch": 0.7613595918851583,
      "grad_norm": 0.03674503415822983,
      "learning_rate": 5.303190087002373e-06,
      "loss": 0.0005,
      "step": 12835
    },
    {
      "epoch": 0.7614189109028354,
      "grad_norm": 0.057600971311330795,
      "learning_rate": 5.301871869232797e-06,
      "loss": 0.001,
      "step": 12836
    },
    {
      "epoch": 0.7614782299205125,
      "grad_norm": 0.6703743934631348,
      "learning_rate": 5.300553651463221e-06,
      "loss": 0.0081,
      "step": 12837
    },
    {
      "epoch": 0.7615375489381896,
      "grad_norm": 10.685978889465332,
      "learning_rate": 5.299235433693647e-06,
      "loss": 0.3627,
      "step": 12838
    },
    {
      "epoch": 0.7615968679558667,
      "grad_norm": 5.0278801918029785,
      "learning_rate": 5.2979172159240714e-06,
      "loss": 0.0889,
      "step": 12839
    },
    {
      "epoch": 0.7616561869735438,
      "grad_norm": 0.019710825756192207,
      "learning_rate": 5.296598998154495e-06,
      "loss": 0.0005,
      "step": 12840
    },
    {
      "epoch": 0.7617155059912207,
      "grad_norm": 0.016798822209239006,
      "learning_rate": 5.295280780384921e-06,
      "loss": 0.0004,
      "step": 12841
    },
    {
      "epoch": 0.7617748250088978,
      "grad_norm": 32.4333610534668,
      "learning_rate": 5.293962562615345e-06,
      "loss": 0.2683,
      "step": 12842
    },
    {
      "epoch": 0.7618341440265749,
      "grad_norm": 0.19419901072978973,
      "learning_rate": 5.292644344845769e-06,
      "loss": 0.0021,
      "step": 12843
    },
    {
      "epoch": 0.761893463044252,
      "grad_norm": 7.241885185241699,
      "learning_rate": 5.291326127076194e-06,
      "loss": 0.079,
      "step": 12844
    },
    {
      "epoch": 0.7619527820619291,
      "grad_norm": 6.3742756843566895,
      "learning_rate": 5.290007909306618e-06,
      "loss": 0.0143,
      "step": 12845
    },
    {
      "epoch": 0.7620121010796062,
      "grad_norm": 26.58039093017578,
      "learning_rate": 5.2886896915370424e-06,
      "loss": 2.6901,
      "step": 12846
    },
    {
      "epoch": 0.7620714200972832,
      "grad_norm": 3.3162829875946045,
      "learning_rate": 5.287371473767467e-06,
      "loss": 0.1388,
      "step": 12847
    },
    {
      "epoch": 0.7621307391149602,
      "grad_norm": 6.621877670288086,
      "learning_rate": 5.286053255997892e-06,
      "loss": 0.1115,
      "step": 12848
    },
    {
      "epoch": 0.7621900581326373,
      "grad_norm": 0.23119811713695526,
      "learning_rate": 5.284735038228316e-06,
      "loss": 0.0031,
      "step": 12849
    },
    {
      "epoch": 0.7622493771503144,
      "grad_norm": 8.103498458862305,
      "learning_rate": 5.28341682045874e-06,
      "loss": 0.0528,
      "step": 12850
    },
    {
      "epoch": 0.7623086961679915,
      "grad_norm": 0.02946937084197998,
      "learning_rate": 5.282098602689165e-06,
      "loss": 0.0004,
      "step": 12851
    },
    {
      "epoch": 0.7623680151856685,
      "grad_norm": 0.017525168135762215,
      "learning_rate": 5.280780384919589e-06,
      "loss": 0.0004,
      "step": 12852
    },
    {
      "epoch": 0.7624273342033456,
      "grad_norm": 0.05946311727166176,
      "learning_rate": 5.2794621671500135e-06,
      "loss": 0.0005,
      "step": 12853
    },
    {
      "epoch": 0.7624866532210227,
      "grad_norm": 4.359665393829346,
      "learning_rate": 5.278143949380438e-06,
      "loss": 0.0738,
      "step": 12854
    },
    {
      "epoch": 0.7625459722386997,
      "grad_norm": 0.3662025034427643,
      "learning_rate": 5.276825731610863e-06,
      "loss": 0.0047,
      "step": 12855
    },
    {
      "epoch": 0.7626052912563768,
      "grad_norm": 3.3574585914611816,
      "learning_rate": 5.275507513841287e-06,
      "loss": 0.0872,
      "step": 12856
    },
    {
      "epoch": 0.7626646102740539,
      "grad_norm": 0.007914379239082336,
      "learning_rate": 5.274189296071711e-06,
      "loss": 0.0002,
      "step": 12857
    },
    {
      "epoch": 0.7627239292917309,
      "grad_norm": 0.4670514464378357,
      "learning_rate": 5.272871078302136e-06,
      "loss": 0.0028,
      "step": 12858
    },
    {
      "epoch": 0.762783248309408,
      "grad_norm": 7.62380838394165,
      "learning_rate": 5.27155286053256e-06,
      "loss": 0.3341,
      "step": 12859
    },
    {
      "epoch": 0.7628425673270851,
      "grad_norm": 8.23377799987793,
      "learning_rate": 5.2702346427629845e-06,
      "loss": 0.0569,
      "step": 12860
    },
    {
      "epoch": 0.7629018863447621,
      "grad_norm": 0.11023223400115967,
      "learning_rate": 5.268916424993409e-06,
      "loss": 0.0017,
      "step": 12861
    },
    {
      "epoch": 0.7629612053624392,
      "grad_norm": 3.7351653575897217,
      "learning_rate": 5.267598207223834e-06,
      "loss": 0.048,
      "step": 12862
    },
    {
      "epoch": 0.7630205243801162,
      "grad_norm": 0.00893901102244854,
      "learning_rate": 5.266279989454258e-06,
      "loss": 0.0003,
      "step": 12863
    },
    {
      "epoch": 0.7630798433977933,
      "grad_norm": 3.8913376331329346,
      "learning_rate": 5.264961771684682e-06,
      "loss": 0.0849,
      "step": 12864
    },
    {
      "epoch": 0.7631391624154704,
      "grad_norm": 13.809905052185059,
      "learning_rate": 5.263643553915108e-06,
      "loss": 0.8165,
      "step": 12865
    },
    {
      "epoch": 0.7631984814331475,
      "grad_norm": 0.05674894154071808,
      "learning_rate": 5.262325336145532e-06,
      "loss": 0.0004,
      "step": 12866
    },
    {
      "epoch": 0.7632578004508246,
      "grad_norm": 0.3212360143661499,
      "learning_rate": 5.261007118375956e-06,
      "loss": 0.0052,
      "step": 12867
    },
    {
      "epoch": 0.7633171194685016,
      "grad_norm": 19.902040481567383,
      "learning_rate": 5.259688900606381e-06,
      "loss": 0.6048,
      "step": 12868
    },
    {
      "epoch": 0.7633764384861786,
      "grad_norm": 5.849594593048096,
      "learning_rate": 5.2583706828368055e-06,
      "loss": 0.2693,
      "step": 12869
    },
    {
      "epoch": 0.7634357575038557,
      "grad_norm": 6.076835632324219,
      "learning_rate": 5.25705246506723e-06,
      "loss": 0.0648,
      "step": 12870
    },
    {
      "epoch": 0.7634950765215328,
      "grad_norm": 0.021942155435681343,
      "learning_rate": 5.255734247297654e-06,
      "loss": 0.0004,
      "step": 12871
    },
    {
      "epoch": 0.7635543955392099,
      "grad_norm": 0.15706652402877808,
      "learning_rate": 5.254416029528079e-06,
      "loss": 0.0014,
      "step": 12872
    },
    {
      "epoch": 0.763613714556887,
      "grad_norm": 0.1445634812116623,
      "learning_rate": 5.253097811758503e-06,
      "loss": 0.0021,
      "step": 12873
    },
    {
      "epoch": 0.763673033574564,
      "grad_norm": 9.503401756286621,
      "learning_rate": 5.251779593988927e-06,
      "loss": 0.2038,
      "step": 12874
    },
    {
      "epoch": 0.763732352592241,
      "grad_norm": 21.030345916748047,
      "learning_rate": 5.250461376219352e-06,
      "loss": 0.1611,
      "step": 12875
    },
    {
      "epoch": 0.7637916716099181,
      "grad_norm": 0.6553897261619568,
      "learning_rate": 5.2491431584497765e-06,
      "loss": 0.0066,
      "step": 12876
    },
    {
      "epoch": 0.7638509906275952,
      "grad_norm": 0.2216147482395172,
      "learning_rate": 5.247824940680201e-06,
      "loss": 0.0022,
      "step": 12877
    },
    {
      "epoch": 0.7639103096452723,
      "grad_norm": 8.587386131286621,
      "learning_rate": 5.246506722910625e-06,
      "loss": 0.0486,
      "step": 12878
    },
    {
      "epoch": 0.7639696286629494,
      "grad_norm": 4.715346336364746,
      "learning_rate": 5.24518850514105e-06,
      "loss": 0.0741,
      "step": 12879
    },
    {
      "epoch": 0.7640289476806265,
      "grad_norm": 0.07830904424190521,
      "learning_rate": 5.243870287371474e-06,
      "loss": 0.0009,
      "step": 12880
    },
    {
      "epoch": 0.7640882666983034,
      "grad_norm": 13.012216567993164,
      "learning_rate": 5.242552069601898e-06,
      "loss": 0.6268,
      "step": 12881
    },
    {
      "epoch": 0.7641475857159805,
      "grad_norm": 5.097031593322754,
      "learning_rate": 5.241233851832323e-06,
      "loss": 0.3156,
      "step": 12882
    },
    {
      "epoch": 0.7642069047336576,
      "grad_norm": 0.027720242738723755,
      "learning_rate": 5.2399156340627475e-06,
      "loss": 0.0005,
      "step": 12883
    },
    {
      "epoch": 0.7642662237513347,
      "grad_norm": 5.9983062744140625,
      "learning_rate": 5.238597416293172e-06,
      "loss": 0.0918,
      "step": 12884
    },
    {
      "epoch": 0.7643255427690118,
      "grad_norm": 0.25339820981025696,
      "learning_rate": 5.237279198523596e-06,
      "loss": 0.004,
      "step": 12885
    },
    {
      "epoch": 0.7643848617866889,
      "grad_norm": 0.5639787316322327,
      "learning_rate": 5.235960980754021e-06,
      "loss": 0.0045,
      "step": 12886
    },
    {
      "epoch": 0.7644441808043658,
      "grad_norm": 3.4441025257110596,
      "learning_rate": 5.234642762984445e-06,
      "loss": 0.0546,
      "step": 12887
    },
    {
      "epoch": 0.7645034998220429,
      "grad_norm": 2.2159876823425293,
      "learning_rate": 5.233324545214869e-06,
      "loss": 0.033,
      "step": 12888
    },
    {
      "epoch": 0.76456281883972,
      "grad_norm": 1.0206657648086548,
      "learning_rate": 5.232006327445295e-06,
      "loss": 0.0053,
      "step": 12889
    },
    {
      "epoch": 0.7646221378573971,
      "grad_norm": 27.587263107299805,
      "learning_rate": 5.2306881096757185e-06,
      "loss": 0.3294,
      "step": 12890
    },
    {
      "epoch": 0.7646814568750742,
      "grad_norm": 5.728178977966309,
      "learning_rate": 5.229369891906143e-06,
      "loss": 0.1538,
      "step": 12891
    },
    {
      "epoch": 0.7647407758927512,
      "grad_norm": 0.013887662440538406,
      "learning_rate": 5.228051674136569e-06,
      "loss": 0.0003,
      "step": 12892
    },
    {
      "epoch": 0.7648000949104283,
      "grad_norm": 1.2130374908447266,
      "learning_rate": 5.226733456366993e-06,
      "loss": 0.0121,
      "step": 12893
    },
    {
      "epoch": 0.7648594139281053,
      "grad_norm": 12.934806823730469,
      "learning_rate": 5.225415238597417e-06,
      "loss": 0.6902,
      "step": 12894
    },
    {
      "epoch": 0.7649187329457824,
      "grad_norm": 0.12108362466096878,
      "learning_rate": 5.224097020827841e-06,
      "loss": 0.0016,
      "step": 12895
    },
    {
      "epoch": 0.7649780519634595,
      "grad_norm": 0.14062952995300293,
      "learning_rate": 5.222778803058266e-06,
      "loss": 0.0024,
      "step": 12896
    },
    {
      "epoch": 0.7650373709811366,
      "grad_norm": 46.63469314575195,
      "learning_rate": 5.22146058528869e-06,
      "loss": 1.2422,
      "step": 12897
    },
    {
      "epoch": 0.7650966899988136,
      "grad_norm": 11.650818824768066,
      "learning_rate": 5.220142367519115e-06,
      "loss": 0.3795,
      "step": 12898
    },
    {
      "epoch": 0.7651560090164907,
      "grad_norm": 0.4818316400051117,
      "learning_rate": 5.21882414974954e-06,
      "loss": 0.0063,
      "step": 12899
    },
    {
      "epoch": 0.7652153280341678,
      "grad_norm": 9.518237113952637,
      "learning_rate": 5.217505931979964e-06,
      "loss": 0.4773,
      "step": 12900
    },
    {
      "epoch": 0.7652746470518448,
      "grad_norm": 2.6946747303009033,
      "learning_rate": 5.216187714210388e-06,
      "loss": 0.2632,
      "step": 12901
    },
    {
      "epoch": 0.7653339660695219,
      "grad_norm": 12.738235473632812,
      "learning_rate": 5.214869496440812e-06,
      "loss": 0.0569,
      "step": 12902
    },
    {
      "epoch": 0.765393285087199,
      "grad_norm": 5.789722442626953,
      "learning_rate": 5.213551278671237e-06,
      "loss": 0.0629,
      "step": 12903
    },
    {
      "epoch": 0.765452604104876,
      "grad_norm": 0.021046232432127,
      "learning_rate": 5.212233060901661e-06,
      "loss": 0.0006,
      "step": 12904
    },
    {
      "epoch": 0.7655119231225531,
      "grad_norm": 3.122295379638672,
      "learning_rate": 5.210914843132086e-06,
      "loss": 0.0692,
      "step": 12905
    },
    {
      "epoch": 0.7655712421402302,
      "grad_norm": 0.09935135394334793,
      "learning_rate": 5.209596625362511e-06,
      "loss": 0.0017,
      "step": 12906
    },
    {
      "epoch": 0.7656305611579072,
      "grad_norm": 0.0682920441031456,
      "learning_rate": 5.208278407592935e-06,
      "loss": 0.0018,
      "step": 12907
    },
    {
      "epoch": 0.7656898801755843,
      "grad_norm": 0.06115897372364998,
      "learning_rate": 5.206960189823359e-06,
      "loss": 0.0003,
      "step": 12908
    },
    {
      "epoch": 0.7657491991932613,
      "grad_norm": 1.220079779624939,
      "learning_rate": 5.205641972053783e-06,
      "loss": 0.0125,
      "step": 12909
    },
    {
      "epoch": 0.7658085182109384,
      "grad_norm": 0.013227283954620361,
      "learning_rate": 5.204323754284208e-06,
      "loss": 0.0003,
      "step": 12910
    },
    {
      "epoch": 0.7658678372286155,
      "grad_norm": 8.580060958862305,
      "learning_rate": 5.203005536514632e-06,
      "loss": 0.3161,
      "step": 12911
    },
    {
      "epoch": 0.7659271562462926,
      "grad_norm": 0.555624783039093,
      "learning_rate": 5.201687318745057e-06,
      "loss": 0.0048,
      "step": 12912
    },
    {
      "epoch": 0.7659864752639697,
      "grad_norm": 0.008102476596832275,
      "learning_rate": 5.200369100975482e-06,
      "loss": 0.0003,
      "step": 12913
    },
    {
      "epoch": 0.7660457942816467,
      "grad_norm": 16.497159957885742,
      "learning_rate": 5.199050883205906e-06,
      "loss": 0.1421,
      "step": 12914
    },
    {
      "epoch": 0.7661051132993237,
      "grad_norm": 0.008883154019713402,
      "learning_rate": 5.19773266543633e-06,
      "loss": 0.0002,
      "step": 12915
    },
    {
      "epoch": 0.7661644323170008,
      "grad_norm": 24.182153701782227,
      "learning_rate": 5.196414447666756e-06,
      "loss": 0.258,
      "step": 12916
    },
    {
      "epoch": 0.7662237513346779,
      "grad_norm": 0.172153040766716,
      "learning_rate": 5.19509622989718e-06,
      "loss": 0.0026,
      "step": 12917
    },
    {
      "epoch": 0.766283070352355,
      "grad_norm": 2.272252321243286,
      "learning_rate": 5.193778012127603e-06,
      "loss": 0.0468,
      "step": 12918
    },
    {
      "epoch": 0.7663423893700321,
      "grad_norm": 0.0660589337348938,
      "learning_rate": 5.192459794358028e-06,
      "loss": 0.0013,
      "step": 12919
    },
    {
      "epoch": 0.766401708387709,
      "grad_norm": 19.832483291625977,
      "learning_rate": 5.1911415765884535e-06,
      "loss": 0.5527,
      "step": 12920
    },
    {
      "epoch": 0.7664610274053861,
      "grad_norm": 0.12427323311567307,
      "learning_rate": 5.189823358818878e-06,
      "loss": 0.0024,
      "step": 12921
    },
    {
      "epoch": 0.7665203464230632,
      "grad_norm": 0.1401781439781189,
      "learning_rate": 5.188505141049302e-06,
      "loss": 0.0023,
      "step": 12922
    },
    {
      "epoch": 0.7665796654407403,
      "grad_norm": 0.04828255996108055,
      "learning_rate": 5.187186923279727e-06,
      "loss": 0.0012,
      "step": 12923
    },
    {
      "epoch": 0.7666389844584174,
      "grad_norm": 1.5336090326309204,
      "learning_rate": 5.185868705510151e-06,
      "loss": 0.0184,
      "step": 12924
    },
    {
      "epoch": 0.7666983034760945,
      "grad_norm": 0.22302109003067017,
      "learning_rate": 5.184550487740575e-06,
      "loss": 0.0027,
      "step": 12925
    },
    {
      "epoch": 0.7667576224937716,
      "grad_norm": 0.04607361927628517,
      "learning_rate": 5.1832322699709994e-06,
      "loss": 0.0006,
      "step": 12926
    },
    {
      "epoch": 0.7668169415114485,
      "grad_norm": 4.670910835266113,
      "learning_rate": 5.1819140522014245e-06,
      "loss": 0.3087,
      "step": 12927
    },
    {
      "epoch": 0.7668762605291256,
      "grad_norm": 18.464601516723633,
      "learning_rate": 5.180595834431849e-06,
      "loss": 0.7694,
      "step": 12928
    },
    {
      "epoch": 0.7669355795468027,
      "grad_norm": 19.374046325683594,
      "learning_rate": 5.179277616662273e-06,
      "loss": 0.8196,
      "step": 12929
    },
    {
      "epoch": 0.7669948985644798,
      "grad_norm": 0.07243847846984863,
      "learning_rate": 5.177959398892698e-06,
      "loss": 0.0011,
      "step": 12930
    },
    {
      "epoch": 0.7670542175821569,
      "grad_norm": 0.9486166834831238,
      "learning_rate": 5.176641181123122e-06,
      "loss": 0.0059,
      "step": 12931
    },
    {
      "epoch": 0.767113536599834,
      "grad_norm": 2.801180124282837,
      "learning_rate": 5.175322963353546e-06,
      "loss": 0.0357,
      "step": 12932
    },
    {
      "epoch": 0.767172855617511,
      "grad_norm": 20.20378875732422,
      "learning_rate": 5.1740047455839704e-06,
      "loss": 0.9949,
      "step": 12933
    },
    {
      "epoch": 0.767232174635188,
      "grad_norm": 0.008821356110274792,
      "learning_rate": 5.1726865278143955e-06,
      "loss": 0.0002,
      "step": 12934
    },
    {
      "epoch": 0.7672914936528651,
      "grad_norm": 3.8090875148773193,
      "learning_rate": 5.17136831004482e-06,
      "loss": 0.0562,
      "step": 12935
    },
    {
      "epoch": 0.7673508126705422,
      "grad_norm": 33.98876953125,
      "learning_rate": 5.170050092275244e-06,
      "loss": 0.0672,
      "step": 12936
    },
    {
      "epoch": 0.7674101316882193,
      "grad_norm": 0.48648950457572937,
      "learning_rate": 5.168731874505669e-06,
      "loss": 0.0055,
      "step": 12937
    },
    {
      "epoch": 0.7674694507058963,
      "grad_norm": 1.1786292791366577,
      "learning_rate": 5.167413656736093e-06,
      "loss": 0.0112,
      "step": 12938
    },
    {
      "epoch": 0.7675287697235734,
      "grad_norm": 0.012034304440021515,
      "learning_rate": 5.166095438966517e-06,
      "loss": 0.0004,
      "step": 12939
    },
    {
      "epoch": 0.7675880887412504,
      "grad_norm": 0.23545768857002258,
      "learning_rate": 5.164777221196942e-06,
      "loss": 0.0021,
      "step": 12940
    },
    {
      "epoch": 0.7676474077589275,
      "grad_norm": 12.369226455688477,
      "learning_rate": 5.1634590034273665e-06,
      "loss": 0.223,
      "step": 12941
    },
    {
      "epoch": 0.7677067267766046,
      "grad_norm": 0.732230007648468,
      "learning_rate": 5.162140785657791e-06,
      "loss": 0.0071,
      "step": 12942
    },
    {
      "epoch": 0.7677660457942816,
      "grad_norm": 0.06879907846450806,
      "learning_rate": 5.160822567888215e-06,
      "loss": 0.0017,
      "step": 12943
    },
    {
      "epoch": 0.7678253648119587,
      "grad_norm": 0.03669046610593796,
      "learning_rate": 5.159504350118641e-06,
      "loss": 0.0006,
      "step": 12944
    },
    {
      "epoch": 0.7678846838296358,
      "grad_norm": 12.780489921569824,
      "learning_rate": 5.158186132349065e-06,
      "loss": 0.8513,
      "step": 12945
    },
    {
      "epoch": 0.7679440028473129,
      "grad_norm": 0.044758860021829605,
      "learning_rate": 5.156867914579488e-06,
      "loss": 0.0012,
      "step": 12946
    },
    {
      "epoch": 0.7680033218649899,
      "grad_norm": 3.6981263160705566,
      "learning_rate": 5.155549696809914e-06,
      "loss": 0.0487,
      "step": 12947
    },
    {
      "epoch": 0.768062640882667,
      "grad_norm": 0.32180002331733704,
      "learning_rate": 5.154231479040338e-06,
      "loss": 0.0054,
      "step": 12948
    },
    {
      "epoch": 0.768121959900344,
      "grad_norm": 0.08632677793502808,
      "learning_rate": 5.1529132612707625e-06,
      "loss": 0.0018,
      "step": 12949
    },
    {
      "epoch": 0.7681812789180211,
      "grad_norm": 1.0841313600540161,
      "learning_rate": 5.151595043501187e-06,
      "loss": 0.0212,
      "step": 12950
    },
    {
      "epoch": 0.7682405979356982,
      "grad_norm": 0.39314189553260803,
      "learning_rate": 5.150276825731612e-06,
      "loss": 0.0076,
      "step": 12951
    },
    {
      "epoch": 0.7682999169533753,
      "grad_norm": 0.06987537443637848,
      "learning_rate": 5.148958607962036e-06,
      "loss": 0.0007,
      "step": 12952
    },
    {
      "epoch": 0.7683592359710523,
      "grad_norm": 25.4766845703125,
      "learning_rate": 5.14764039019246e-06,
      "loss": 1.468,
      "step": 12953
    },
    {
      "epoch": 0.7684185549887294,
      "grad_norm": 8.401093482971191,
      "learning_rate": 5.146322172422885e-06,
      "loss": 0.4218,
      "step": 12954
    },
    {
      "epoch": 0.7684778740064064,
      "grad_norm": 0.0374903604388237,
      "learning_rate": 5.145003954653309e-06,
      "loss": 0.0006,
      "step": 12955
    },
    {
      "epoch": 0.7685371930240835,
      "grad_norm": 0.0701904222369194,
      "learning_rate": 5.1436857368837335e-06,
      "loss": 0.001,
      "step": 12956
    },
    {
      "epoch": 0.7685965120417606,
      "grad_norm": 10.589112281799316,
      "learning_rate": 5.142367519114158e-06,
      "loss": 0.4277,
      "step": 12957
    },
    {
      "epoch": 0.7686558310594377,
      "grad_norm": 2.9567787647247314,
      "learning_rate": 5.141049301344583e-06,
      "loss": 0.0285,
      "step": 12958
    },
    {
      "epoch": 0.7687151500771148,
      "grad_norm": 0.6519902944564819,
      "learning_rate": 5.139731083575007e-06,
      "loss": 0.0067,
      "step": 12959
    },
    {
      "epoch": 0.7687744690947917,
      "grad_norm": 0.35159406065940857,
      "learning_rate": 5.138412865805431e-06,
      "loss": 0.0032,
      "step": 12960
    },
    {
      "epoch": 0.7688337881124688,
      "grad_norm": 9.9509859085083,
      "learning_rate": 5.137094648035856e-06,
      "loss": 0.2425,
      "step": 12961
    },
    {
      "epoch": 0.7688931071301459,
      "grad_norm": 0.06820029020309448,
      "learning_rate": 5.13577643026628e-06,
      "loss": 0.0013,
      "step": 12962
    },
    {
      "epoch": 0.768952426147823,
      "grad_norm": 0.02794533595442772,
      "learning_rate": 5.1344582124967045e-06,
      "loss": 0.0006,
      "step": 12963
    },
    {
      "epoch": 0.7690117451655001,
      "grad_norm": 5.547816276550293,
      "learning_rate": 5.1331399947271296e-06,
      "loss": 0.1933,
      "step": 12964
    },
    {
      "epoch": 0.7690710641831772,
      "grad_norm": 0.26871228218078613,
      "learning_rate": 5.131821776957554e-06,
      "loss": 0.0032,
      "step": 12965
    },
    {
      "epoch": 0.7691303832008541,
      "grad_norm": 1.2909486293792725,
      "learning_rate": 5.130503559187978e-06,
      "loss": 0.0243,
      "step": 12966
    },
    {
      "epoch": 0.7691897022185312,
      "grad_norm": 0.25057896971702576,
      "learning_rate": 5.129185341418402e-06,
      "loss": 0.0042,
      "step": 12967
    },
    {
      "epoch": 0.7692490212362083,
      "grad_norm": 3.430903196334839,
      "learning_rate": 5.127867123648827e-06,
      "loss": 0.0275,
      "step": 12968
    },
    {
      "epoch": 0.7693083402538854,
      "grad_norm": 32.56707000732422,
      "learning_rate": 5.126548905879251e-06,
      "loss": 0.0864,
      "step": 12969
    },
    {
      "epoch": 0.7693676592715625,
      "grad_norm": 7.03399133682251,
      "learning_rate": 5.1252306881096755e-06,
      "loss": 0.392,
      "step": 12970
    },
    {
      "epoch": 0.7694269782892396,
      "grad_norm": 12.517508506774902,
      "learning_rate": 5.123912470340101e-06,
      "loss": 0.5596,
      "step": 12971
    },
    {
      "epoch": 0.7694862973069166,
      "grad_norm": 0.01713237538933754,
      "learning_rate": 5.122594252570526e-06,
      "loss": 0.0004,
      "step": 12972
    },
    {
      "epoch": 0.7695456163245936,
      "grad_norm": 0.16917914152145386,
      "learning_rate": 5.12127603480095e-06,
      "loss": 0.0017,
      "step": 12973
    },
    {
      "epoch": 0.7696049353422707,
      "grad_norm": 0.031061148270964622,
      "learning_rate": 5.119957817031373e-06,
      "loss": 0.0007,
      "step": 12974
    },
    {
      "epoch": 0.7696642543599478,
      "grad_norm": 10.14528751373291,
      "learning_rate": 5.118639599261799e-06,
      "loss": 0.1379,
      "step": 12975
    },
    {
      "epoch": 0.7697235733776249,
      "grad_norm": 1.5608904361724854,
      "learning_rate": 5.117321381492223e-06,
      "loss": 0.0082,
      "step": 12976
    },
    {
      "epoch": 0.769782892395302,
      "grad_norm": 2.2756874561309814,
      "learning_rate": 5.116003163722647e-06,
      "loss": 0.0271,
      "step": 12977
    },
    {
      "epoch": 0.769842211412979,
      "grad_norm": 10.122819900512695,
      "learning_rate": 5.114684945953072e-06,
      "loss": 0.2886,
      "step": 12978
    },
    {
      "epoch": 0.7699015304306561,
      "grad_norm": 15.625456809997559,
      "learning_rate": 5.113366728183497e-06,
      "loss": 0.0703,
      "step": 12979
    },
    {
      "epoch": 0.7699608494483331,
      "grad_norm": 0.043431371450424194,
      "learning_rate": 5.112048510413921e-06,
      "loss": 0.0011,
      "step": 12980
    },
    {
      "epoch": 0.7700201684660102,
      "grad_norm": 8.651494026184082,
      "learning_rate": 5.110730292644345e-06,
      "loss": 0.1165,
      "step": 12981
    },
    {
      "epoch": 0.7700794874836873,
      "grad_norm": 2.5373823642730713,
      "learning_rate": 5.10941207487477e-06,
      "loss": 0.0406,
      "step": 12982
    },
    {
      "epoch": 0.7701388065013643,
      "grad_norm": 0.6860912442207336,
      "learning_rate": 5.108093857105194e-06,
      "loss": 0.0086,
      "step": 12983
    },
    {
      "epoch": 0.7701981255190414,
      "grad_norm": 27.695159912109375,
      "learning_rate": 5.106775639335618e-06,
      "loss": 0.1927,
      "step": 12984
    },
    {
      "epoch": 0.7702574445367185,
      "grad_norm": 0.1806197315454483,
      "learning_rate": 5.105457421566043e-06,
      "loss": 0.0018,
      "step": 12985
    },
    {
      "epoch": 0.7703167635543955,
      "grad_norm": 0.0965607613325119,
      "learning_rate": 5.104139203796468e-06,
      "loss": 0.0009,
      "step": 12986
    },
    {
      "epoch": 0.7703760825720726,
      "grad_norm": 16.21123695373535,
      "learning_rate": 5.102820986026892e-06,
      "loss": 0.3493,
      "step": 12987
    },
    {
      "epoch": 0.7704354015897497,
      "grad_norm": 0.2406621128320694,
      "learning_rate": 5.101502768257317e-06,
      "loss": 0.0045,
      "step": 12988
    },
    {
      "epoch": 0.7704947206074267,
      "grad_norm": 0.019780948758125305,
      "learning_rate": 5.100184550487741e-06,
      "loss": 0.0005,
      "step": 12989
    },
    {
      "epoch": 0.7705540396251038,
      "grad_norm": 1.0228687524795532,
      "learning_rate": 5.098866332718165e-06,
      "loss": 0.0088,
      "step": 12990
    },
    {
      "epoch": 0.7706133586427809,
      "grad_norm": 14.07895278930664,
      "learning_rate": 5.097548114948589e-06,
      "loss": 0.0929,
      "step": 12991
    },
    {
      "epoch": 0.770672677660458,
      "grad_norm": 15.83481216430664,
      "learning_rate": 5.096229897179014e-06,
      "loss": 1.1686,
      "step": 12992
    },
    {
      "epoch": 0.770731996678135,
      "grad_norm": 1.5351927280426025,
      "learning_rate": 5.094911679409439e-06,
      "loss": 0.0136,
      "step": 12993
    },
    {
      "epoch": 0.770791315695812,
      "grad_norm": 6.456180572509766,
      "learning_rate": 5.093593461639863e-06,
      "loss": 0.0857,
      "step": 12994
    },
    {
      "epoch": 0.7708506347134891,
      "grad_norm": 11.302681922912598,
      "learning_rate": 5.092275243870289e-06,
      "loss": 0.379,
      "step": 12995
    },
    {
      "epoch": 0.7709099537311662,
      "grad_norm": 0.23305846750736237,
      "learning_rate": 5.090957026100712e-06,
      "loss": 0.0033,
      "step": 12996
    },
    {
      "epoch": 0.7709692727488433,
      "grad_norm": 4.958564758300781,
      "learning_rate": 5.089638808331136e-06,
      "loss": 0.0664,
      "step": 12997
    },
    {
      "epoch": 0.7710285917665204,
      "grad_norm": 0.028646087273955345,
      "learning_rate": 5.08832059056156e-06,
      "loss": 0.0003,
      "step": 12998
    },
    {
      "epoch": 0.7710879107841974,
      "grad_norm": 0.017140423879027367,
      "learning_rate": 5.087002372791986e-06,
      "loss": 0.0005,
      "step": 12999
    },
    {
      "epoch": 0.7711472298018744,
      "grad_norm": 0.008159070275723934,
      "learning_rate": 5.0856841550224105e-06,
      "loss": 0.0003,
      "step": 13000
    },
    {
      "epoch": 0.7712065488195515,
      "grad_norm": 1.0437250137329102,
      "learning_rate": 5.084365937252835e-06,
      "loss": 0.0072,
      "step": 13001
    },
    {
      "epoch": 0.7712658678372286,
      "grad_norm": 0.023714106529951096,
      "learning_rate": 5.08304771948326e-06,
      "loss": 0.0006,
      "step": 13002
    },
    {
      "epoch": 0.7713251868549057,
      "grad_norm": 2.283872365951538,
      "learning_rate": 5.081729501713684e-06,
      "loss": 0.0447,
      "step": 13003
    },
    {
      "epoch": 0.7713845058725828,
      "grad_norm": 3.0634965896606445,
      "learning_rate": 5.080411283944108e-06,
      "loss": 0.0362,
      "step": 13004
    },
    {
      "epoch": 0.7714438248902599,
      "grad_norm": 0.09247104078531265,
      "learning_rate": 5.079093066174532e-06,
      "loss": 0.001,
      "step": 13005
    },
    {
      "epoch": 0.7715031439079368,
      "grad_norm": 0.4429163932800293,
      "learning_rate": 5.077774848404957e-06,
      "loss": 0.0038,
      "step": 13006
    },
    {
      "epoch": 0.7715624629256139,
      "grad_norm": 0.1796337515115738,
      "learning_rate": 5.0764566306353815e-06,
      "loss": 0.0027,
      "step": 13007
    },
    {
      "epoch": 0.771621781943291,
      "grad_norm": 0.018440017476677895,
      "learning_rate": 5.075138412865806e-06,
      "loss": 0.0004,
      "step": 13008
    },
    {
      "epoch": 0.7716811009609681,
      "grad_norm": 0.2151186168193817,
      "learning_rate": 5.073820195096231e-06,
      "loss": 0.0048,
      "step": 13009
    },
    {
      "epoch": 0.7717404199786452,
      "grad_norm": 32.15526580810547,
      "learning_rate": 5.072501977326655e-06,
      "loss": 1.1135,
      "step": 13010
    },
    {
      "epoch": 0.7717997389963223,
      "grad_norm": 17.088973999023438,
      "learning_rate": 5.071183759557079e-06,
      "loss": 1.5759,
      "step": 13011
    },
    {
      "epoch": 0.7718590580139992,
      "grad_norm": 1.1219645738601685,
      "learning_rate": 5.069865541787504e-06,
      "loss": 0.0134,
      "step": 13012
    },
    {
      "epoch": 0.7719183770316763,
      "grad_norm": 1.91448175907135,
      "learning_rate": 5.068547324017928e-06,
      "loss": 0.0477,
      "step": 13013
    },
    {
      "epoch": 0.7719776960493534,
      "grad_norm": 0.0468389131128788,
      "learning_rate": 5.0672291062483525e-06,
      "loss": 0.0013,
      "step": 13014
    },
    {
      "epoch": 0.7720370150670305,
      "grad_norm": 4.807156085968018,
      "learning_rate": 5.065910888478777e-06,
      "loss": 0.1061,
      "step": 13015
    },
    {
      "epoch": 0.7720963340847076,
      "grad_norm": 1.1673085689544678,
      "learning_rate": 5.064592670709202e-06,
      "loss": 0.0107,
      "step": 13016
    },
    {
      "epoch": 0.7721556531023847,
      "grad_norm": 0.4628939926624298,
      "learning_rate": 5.063274452939626e-06,
      "loss": 0.0047,
      "step": 13017
    },
    {
      "epoch": 0.7722149721200617,
      "grad_norm": 0.06433767080307007,
      "learning_rate": 5.06195623517005e-06,
      "loss": 0.0011,
      "step": 13018
    },
    {
      "epoch": 0.7722742911377387,
      "grad_norm": 4.473644733428955,
      "learning_rate": 5.060638017400475e-06,
      "loss": 0.0994,
      "step": 13019
    },
    {
      "epoch": 0.7723336101554158,
      "grad_norm": 0.39447474479675293,
      "learning_rate": 5.059319799630899e-06,
      "loss": 0.0037,
      "step": 13020
    },
    {
      "epoch": 0.7723929291730929,
      "grad_norm": 29.948453903198242,
      "learning_rate": 5.0580015818613235e-06,
      "loss": 2.0097,
      "step": 13021
    },
    {
      "epoch": 0.77245224819077,
      "grad_norm": 8.383605003356934,
      "learning_rate": 5.056683364091748e-06,
      "loss": 0.0573,
      "step": 13022
    },
    {
      "epoch": 0.772511567208447,
      "grad_norm": 9.779083251953125,
      "learning_rate": 5.0553651463221735e-06,
      "loss": 0.4698,
      "step": 13023
    },
    {
      "epoch": 0.7725708862261241,
      "grad_norm": 6.5337371826171875,
      "learning_rate": 5.054046928552597e-06,
      "loss": 0.1505,
      "step": 13024
    },
    {
      "epoch": 0.7726302052438012,
      "grad_norm": 9.671618461608887,
      "learning_rate": 5.052728710783021e-06,
      "loss": 0.1015,
      "step": 13025
    },
    {
      "epoch": 0.7726895242614782,
      "grad_norm": 0.11332354694604874,
      "learning_rate": 5.051410493013447e-06,
      "loss": 0.0013,
      "step": 13026
    },
    {
      "epoch": 0.7727488432791553,
      "grad_norm": 0.8378285765647888,
      "learning_rate": 5.050092275243871e-06,
      "loss": 0.0098,
      "step": 13027
    },
    {
      "epoch": 0.7728081622968324,
      "grad_norm": 3.6774792671203613,
      "learning_rate": 5.048774057474295e-06,
      "loss": 0.146,
      "step": 13028
    },
    {
      "epoch": 0.7728674813145094,
      "grad_norm": 0.05765190348029137,
      "learning_rate": 5.047455839704719e-06,
      "loss": 0.0013,
      "step": 13029
    },
    {
      "epoch": 0.7729268003321865,
      "grad_norm": 6.908895969390869,
      "learning_rate": 5.0461376219351445e-06,
      "loss": 0.5328,
      "step": 13030
    },
    {
      "epoch": 0.7729861193498636,
      "grad_norm": 0.017687369138002396,
      "learning_rate": 5.044819404165569e-06,
      "loss": 0.0005,
      "step": 13031
    },
    {
      "epoch": 0.7730454383675406,
      "grad_norm": 1.1900333166122437,
      "learning_rate": 5.043501186395993e-06,
      "loss": 0.0085,
      "step": 13032
    },
    {
      "epoch": 0.7731047573852177,
      "grad_norm": 1.529231309890747,
      "learning_rate": 5.042182968626418e-06,
      "loss": 0.0135,
      "step": 13033
    },
    {
      "epoch": 0.7731640764028948,
      "grad_norm": 19.02785301208496,
      "learning_rate": 5.040864750856842e-06,
      "loss": 0.9813,
      "step": 13034
    },
    {
      "epoch": 0.7732233954205718,
      "grad_norm": 13.38381576538086,
      "learning_rate": 5.039546533087266e-06,
      "loss": 0.3203,
      "step": 13035
    },
    {
      "epoch": 0.7732827144382489,
      "grad_norm": 4.922340393066406,
      "learning_rate": 5.038228315317691e-06,
      "loss": 0.023,
      "step": 13036
    },
    {
      "epoch": 0.773342033455926,
      "grad_norm": 1.882986307144165,
      "learning_rate": 5.0369100975481155e-06,
      "loss": 0.0187,
      "step": 13037
    },
    {
      "epoch": 0.7734013524736031,
      "grad_norm": 3.012425422668457,
      "learning_rate": 5.03559187977854e-06,
      "loss": 0.1376,
      "step": 13038
    },
    {
      "epoch": 0.7734606714912801,
      "grad_norm": 5.084597587585449,
      "learning_rate": 5.034273662008964e-06,
      "loss": 0.2009,
      "step": 13039
    },
    {
      "epoch": 0.7735199905089571,
      "grad_norm": 0.14730185270309448,
      "learning_rate": 5.032955444239389e-06,
      "loss": 0.0013,
      "step": 13040
    },
    {
      "epoch": 0.7735793095266342,
      "grad_norm": 0.25742852687835693,
      "learning_rate": 5.031637226469813e-06,
      "loss": 0.0057,
      "step": 13041
    },
    {
      "epoch": 0.7736386285443113,
      "grad_norm": 2.0059826374053955,
      "learning_rate": 5.030319008700237e-06,
      "loss": 0.0364,
      "step": 13042
    },
    {
      "epoch": 0.7736979475619884,
      "grad_norm": 1.4412226676940918,
      "learning_rate": 5.029000790930662e-06,
      "loss": 0.0121,
      "step": 13043
    },
    {
      "epoch": 0.7737572665796655,
      "grad_norm": 0.7771615982055664,
      "learning_rate": 5.0276825731610866e-06,
      "loss": 0.0062,
      "step": 13044
    },
    {
      "epoch": 0.7738165855973425,
      "grad_norm": 0.041506536304950714,
      "learning_rate": 5.026364355391511e-06,
      "loss": 0.0009,
      "step": 13045
    },
    {
      "epoch": 0.7738759046150195,
      "grad_norm": 0.3359375298023224,
      "learning_rate": 5.025046137621935e-06,
      "loss": 0.0033,
      "step": 13046
    },
    {
      "epoch": 0.7739352236326966,
      "grad_norm": 0.034021876752376556,
      "learning_rate": 5.02372791985236e-06,
      "loss": 0.0007,
      "step": 13047
    },
    {
      "epoch": 0.7739945426503737,
      "grad_norm": 34.019859313964844,
      "learning_rate": 5.022409702082784e-06,
      "loss": 0.4895,
      "step": 13048
    },
    {
      "epoch": 0.7740538616680508,
      "grad_norm": 4.678628921508789,
      "learning_rate": 5.021091484313208e-06,
      "loss": 0.0276,
      "step": 13049
    },
    {
      "epoch": 0.7741131806857279,
      "grad_norm": 33.34371566772461,
      "learning_rate": 5.019773266543634e-06,
      "loss": 0.2932,
      "step": 13050
    },
    {
      "epoch": 0.774172499703405,
      "grad_norm": 0.010282645002007484,
      "learning_rate": 5.018455048774058e-06,
      "loss": 0.0003,
      "step": 13051
    },
    {
      "epoch": 0.7742318187210819,
      "grad_norm": 6.025137901306152,
      "learning_rate": 5.017136831004482e-06,
      "loss": 0.1021,
      "step": 13052
    },
    {
      "epoch": 0.774291137738759,
      "grad_norm": 0.025625580921769142,
      "learning_rate": 5.015818613234906e-06,
      "loss": 0.0006,
      "step": 13053
    },
    {
      "epoch": 0.7743504567564361,
      "grad_norm": 0.19809623062610626,
      "learning_rate": 5.014500395465332e-06,
      "loss": 0.0038,
      "step": 13054
    },
    {
      "epoch": 0.7744097757741132,
      "grad_norm": 0.11074089258909225,
      "learning_rate": 5.013182177695756e-06,
      "loss": 0.0015,
      "step": 13055
    },
    {
      "epoch": 0.7744690947917903,
      "grad_norm": 8.928624153137207,
      "learning_rate": 5.01186395992618e-06,
      "loss": 0.6546,
      "step": 13056
    },
    {
      "epoch": 0.7745284138094674,
      "grad_norm": 0.00974755734205246,
      "learning_rate": 5.010545742156605e-06,
      "loss": 0.0002,
      "step": 13057
    },
    {
      "epoch": 0.7745877328271444,
      "grad_norm": 0.1567137986421585,
      "learning_rate": 5.009227524387029e-06,
      "loss": 0.0038,
      "step": 13058
    },
    {
      "epoch": 0.7746470518448214,
      "grad_norm": 0.02045293338596821,
      "learning_rate": 5.007909306617454e-06,
      "loss": 0.0005,
      "step": 13059
    },
    {
      "epoch": 0.7747063708624985,
      "grad_norm": 6.16198205947876,
      "learning_rate": 5.006591088847879e-06,
      "loss": 0.2078,
      "step": 13060
    },
    {
      "epoch": 0.7747656898801756,
      "grad_norm": 0.005941064562648535,
      "learning_rate": 5.005272871078303e-06,
      "loss": 0.0001,
      "step": 13061
    },
    {
      "epoch": 0.7748250088978527,
      "grad_norm": 1.1289358139038086,
      "learning_rate": 5.003954653308727e-06,
      "loss": 0.0178,
      "step": 13062
    },
    {
      "epoch": 0.7748843279155297,
      "grad_norm": 0.07450170069932938,
      "learning_rate": 5.002636435539151e-06,
      "loss": 0.0012,
      "step": 13063
    },
    {
      "epoch": 0.7749436469332068,
      "grad_norm": 3.2204532623291016,
      "learning_rate": 5.001318217769576e-06,
      "loss": 0.0216,
      "step": 13064
    },
    {
      "epoch": 0.7750029659508838,
      "grad_norm": 4.209928035736084,
      "learning_rate": 5e-06,
      "loss": 0.0375,
      "step": 13065
    },
    {
      "epoch": 0.7750622849685609,
      "grad_norm": 0.12912429869174957,
      "learning_rate": 4.9986817822304254e-06,
      "loss": 0.002,
      "step": 13066
    },
    {
      "epoch": 0.775121603986238,
      "grad_norm": 7.062504768371582,
      "learning_rate": 4.99736356446085e-06,
      "loss": 0.4027,
      "step": 13067
    },
    {
      "epoch": 0.7751809230039151,
      "grad_norm": 8.554559707641602,
      "learning_rate": 4.996045346691274e-06,
      "loss": 0.0659,
      "step": 13068
    },
    {
      "epoch": 0.7752402420215921,
      "grad_norm": 7.773989677429199,
      "learning_rate": 4.994727128921698e-06,
      "loss": 0.0982,
      "step": 13069
    },
    {
      "epoch": 0.7752995610392692,
      "grad_norm": 69.05352020263672,
      "learning_rate": 4.993408911152123e-06,
      "loss": 1.4556,
      "step": 13070
    },
    {
      "epoch": 0.7753588800569463,
      "grad_norm": 10.357060432434082,
      "learning_rate": 4.992090693382547e-06,
      "loss": 0.0757,
      "step": 13071
    },
    {
      "epoch": 0.7754181990746233,
      "grad_norm": 22.058958053588867,
      "learning_rate": 4.990772475612971e-06,
      "loss": 0.0882,
      "step": 13072
    },
    {
      "epoch": 0.7754775180923004,
      "grad_norm": 0.029041750356554985,
      "learning_rate": 4.9894542578433964e-06,
      "loss": 0.0007,
      "step": 13073
    },
    {
      "epoch": 0.7755368371099775,
      "grad_norm": 10.903655052185059,
      "learning_rate": 4.988136040073821e-06,
      "loss": 0.0517,
      "step": 13074
    },
    {
      "epoch": 0.7755961561276545,
      "grad_norm": 11.32972240447998,
      "learning_rate": 4.986817822304245e-06,
      "loss": 0.0422,
      "step": 13075
    },
    {
      "epoch": 0.7756554751453316,
      "grad_norm": 0.03513866290450096,
      "learning_rate": 4.985499604534669e-06,
      "loss": 0.0009,
      "step": 13076
    },
    {
      "epoch": 0.7757147941630087,
      "grad_norm": 0.008742301724851131,
      "learning_rate": 4.984181386765094e-06,
      "loss": 0.0002,
      "step": 13077
    },
    {
      "epoch": 0.7757741131806857,
      "grad_norm": 0.38489487767219543,
      "learning_rate": 4.982863168995519e-06,
      "loss": 0.0036,
      "step": 13078
    },
    {
      "epoch": 0.7758334321983628,
      "grad_norm": 6.408919334411621,
      "learning_rate": 4.981544951225942e-06,
      "loss": 0.2483,
      "step": 13079
    },
    {
      "epoch": 0.7758927512160398,
      "grad_norm": 0.04596468433737755,
      "learning_rate": 4.9802267334563675e-06,
      "loss": 0.0009,
      "step": 13080
    },
    {
      "epoch": 0.7759520702337169,
      "grad_norm": 4.148501873016357,
      "learning_rate": 4.978908515686792e-06,
      "loss": 0.1159,
      "step": 13081
    },
    {
      "epoch": 0.776011389251394,
      "grad_norm": 17.451196670532227,
      "learning_rate": 4.977590297917217e-06,
      "loss": 0.1078,
      "step": 13082
    },
    {
      "epoch": 0.7760707082690711,
      "grad_norm": 0.3368545472621918,
      "learning_rate": 4.976272080147641e-06,
      "loss": 0.0042,
      "step": 13083
    },
    {
      "epoch": 0.7761300272867482,
      "grad_norm": 0.04722467437386513,
      "learning_rate": 4.974953862378065e-06,
      "loss": 0.0006,
      "step": 13084
    },
    {
      "epoch": 0.7761893463044252,
      "grad_norm": 3.643697738647461,
      "learning_rate": 4.97363564460849e-06,
      "loss": 0.0303,
      "step": 13085
    },
    {
      "epoch": 0.7762486653221022,
      "grad_norm": 30.657676696777344,
      "learning_rate": 4.972317426838914e-06,
      "loss": 0.3078,
      "step": 13086
    },
    {
      "epoch": 0.7763079843397793,
      "grad_norm": 16.296661376953125,
      "learning_rate": 4.9709992090693385e-06,
      "loss": 0.3846,
      "step": 13087
    },
    {
      "epoch": 0.7763673033574564,
      "grad_norm": 0.3214772641658783,
      "learning_rate": 4.969680991299763e-06,
      "loss": 0.0058,
      "step": 13088
    },
    {
      "epoch": 0.7764266223751335,
      "grad_norm": 1.610073447227478,
      "learning_rate": 4.968362773530188e-06,
      "loss": 0.0159,
      "step": 13089
    },
    {
      "epoch": 0.7764859413928106,
      "grad_norm": 0.05758604407310486,
      "learning_rate": 4.967044555760612e-06,
      "loss": 0.0013,
      "step": 13090
    },
    {
      "epoch": 0.7765452604104875,
      "grad_norm": 8.18862533569336,
      "learning_rate": 4.965726337991036e-06,
      "loss": 0.3419,
      "step": 13091
    },
    {
      "epoch": 0.7766045794281646,
      "grad_norm": 12.216897010803223,
      "learning_rate": 4.964408120221461e-06,
      "loss": 0.4727,
      "step": 13092
    },
    {
      "epoch": 0.7766638984458417,
      "grad_norm": 0.40152519941329956,
      "learning_rate": 4.963089902451885e-06,
      "loss": 0.0068,
      "step": 13093
    },
    {
      "epoch": 0.7767232174635188,
      "grad_norm": 13.286304473876953,
      "learning_rate": 4.96177168468231e-06,
      "loss": 0.2224,
      "step": 13094
    },
    {
      "epoch": 0.7767825364811959,
      "grad_norm": 0.06508617848157883,
      "learning_rate": 4.9604534669127345e-06,
      "loss": 0.0008,
      "step": 13095
    },
    {
      "epoch": 0.776841855498873,
      "grad_norm": 0.023090383037924767,
      "learning_rate": 4.959135249143159e-06,
      "loss": 0.0004,
      "step": 13096
    },
    {
      "epoch": 0.77690117451655,
      "grad_norm": 0.035896435379981995,
      "learning_rate": 4.957817031373584e-06,
      "loss": 0.0008,
      "step": 13097
    },
    {
      "epoch": 0.776960493534227,
      "grad_norm": 0.9670712947845459,
      "learning_rate": 4.956498813604008e-06,
      "loss": 0.0115,
      "step": 13098
    },
    {
      "epoch": 0.7770198125519041,
      "grad_norm": 1.2881534099578857,
      "learning_rate": 4.955180595834432e-06,
      "loss": 0.0111,
      "step": 13099
    },
    {
      "epoch": 0.7770791315695812,
      "grad_norm": 0.15487363934516907,
      "learning_rate": 4.953862378064856e-06,
      "loss": 0.0028,
      "step": 13100
    },
    {
      "epoch": 0.7771384505872583,
      "grad_norm": 1.0487278699874878,
      "learning_rate": 4.952544160295281e-06,
      "loss": 0.0115,
      "step": 13101
    },
    {
      "epoch": 0.7771977696049354,
      "grad_norm": 0.16164177656173706,
      "learning_rate": 4.9512259425257055e-06,
      "loss": 0.0021,
      "step": 13102
    },
    {
      "epoch": 0.7772570886226124,
      "grad_norm": 11.158232688903809,
      "learning_rate": 4.94990772475613e-06,
      "loss": 0.498,
      "step": 13103
    },
    {
      "epoch": 0.7773164076402895,
      "grad_norm": 0.045319635421037674,
      "learning_rate": 4.948589506986555e-06,
      "loss": 0.0003,
      "step": 13104
    },
    {
      "epoch": 0.7773757266579665,
      "grad_norm": 0.31764858961105347,
      "learning_rate": 4.947271289216979e-06,
      "loss": 0.0044,
      "step": 13105
    },
    {
      "epoch": 0.7774350456756436,
      "grad_norm": 0.048526402562856674,
      "learning_rate": 4.945953071447404e-06,
      "loss": 0.0009,
      "step": 13106
    },
    {
      "epoch": 0.7774943646933207,
      "grad_norm": 23.60944366455078,
      "learning_rate": 4.944634853677828e-06,
      "loss": 0.1652,
      "step": 13107
    },
    {
      "epoch": 0.7775536837109978,
      "grad_norm": 0.29513004422187805,
      "learning_rate": 4.943316635908252e-06,
      "loss": 0.0041,
      "step": 13108
    },
    {
      "epoch": 0.7776130027286748,
      "grad_norm": 1.532920479774475,
      "learning_rate": 4.941998418138677e-06,
      "loss": 0.0193,
      "step": 13109
    },
    {
      "epoch": 0.7776723217463519,
      "grad_norm": 1.5918853282928467,
      "learning_rate": 4.9406802003691015e-06,
      "loss": 0.0153,
      "step": 13110
    },
    {
      "epoch": 0.7777316407640289,
      "grad_norm": 29.856151580810547,
      "learning_rate": 4.939361982599526e-06,
      "loss": 1.1537,
      "step": 13111
    },
    {
      "epoch": 0.777790959781706,
      "grad_norm": 0.6391897201538086,
      "learning_rate": 4.93804376482995e-06,
      "loss": 0.0072,
      "step": 13112
    },
    {
      "epoch": 0.7778502787993831,
      "grad_norm": 16.856985092163086,
      "learning_rate": 4.936725547060375e-06,
      "loss": 0.5446,
      "step": 13113
    },
    {
      "epoch": 0.7779095978170601,
      "grad_norm": 1.1928731203079224,
      "learning_rate": 4.935407329290799e-06,
      "loss": 0.0116,
      "step": 13114
    },
    {
      "epoch": 0.7779689168347372,
      "grad_norm": 3.1398918628692627,
      "learning_rate": 4.934089111521223e-06,
      "loss": 0.0462,
      "step": 13115
    },
    {
      "epoch": 0.7780282358524143,
      "grad_norm": 0.009925882332026958,
      "learning_rate": 4.932770893751648e-06,
      "loss": 0.0003,
      "step": 13116
    },
    {
      "epoch": 0.7780875548700914,
      "grad_norm": 3.557520866394043,
      "learning_rate": 4.9314526759820725e-06,
      "loss": 0.0405,
      "step": 13117
    },
    {
      "epoch": 0.7781468738877684,
      "grad_norm": 8.436430931091309,
      "learning_rate": 4.930134458212497e-06,
      "loss": 0.1487,
      "step": 13118
    },
    {
      "epoch": 0.7782061929054455,
      "grad_norm": 0.013857519254088402,
      "learning_rate": 4.928816240442922e-06,
      "loss": 0.0002,
      "step": 13119
    },
    {
      "epoch": 0.7782655119231225,
      "grad_norm": 4.451280117034912,
      "learning_rate": 4.927498022673346e-06,
      "loss": 0.0453,
      "step": 13120
    },
    {
      "epoch": 0.7783248309407996,
      "grad_norm": 0.6131927967071533,
      "learning_rate": 4.926179804903771e-06,
      "loss": 0.0126,
      "step": 13121
    },
    {
      "epoch": 0.7783841499584767,
      "grad_norm": 3.6870524883270264,
      "learning_rate": 4.924861587134195e-06,
      "loss": 0.028,
      "step": 13122
    },
    {
      "epoch": 0.7784434689761538,
      "grad_norm": 0.16422432661056519,
      "learning_rate": 4.923543369364619e-06,
      "loss": 0.0015,
      "step": 13123
    },
    {
      "epoch": 0.7785027879938308,
      "grad_norm": 0.020559703931212425,
      "learning_rate": 4.9222251515950435e-06,
      "loss": 0.0003,
      "step": 13124
    },
    {
      "epoch": 0.7785621070115079,
      "grad_norm": 14.068778038024902,
      "learning_rate": 4.9209069338254686e-06,
      "loss": 0.4477,
      "step": 13125
    },
    {
      "epoch": 0.7786214260291849,
      "grad_norm": 0.1460266411304474,
      "learning_rate": 4.919588716055893e-06,
      "loss": 0.0026,
      "step": 13126
    },
    {
      "epoch": 0.778680745046862,
      "grad_norm": 7.941161632537842,
      "learning_rate": 4.918270498286317e-06,
      "loss": 0.0943,
      "step": 13127
    },
    {
      "epoch": 0.7787400640645391,
      "grad_norm": 4.523963928222656,
      "learning_rate": 4.916952280516742e-06,
      "loss": 0.193,
      "step": 13128
    },
    {
      "epoch": 0.7787993830822162,
      "grad_norm": 3.461031675338745,
      "learning_rate": 4.915634062747166e-06,
      "loss": 0.0371,
      "step": 13129
    },
    {
      "epoch": 0.7788587020998933,
      "grad_norm": 11.85023021697998,
      "learning_rate": 4.91431584497759e-06,
      "loss": 1.7799,
      "step": 13130
    },
    {
      "epoch": 0.7789180211175702,
      "grad_norm": 0.11055214703083038,
      "learning_rate": 4.912997627208015e-06,
      "loss": 0.0015,
      "step": 13131
    },
    {
      "epoch": 0.7789773401352473,
      "grad_norm": 5.190873622894287,
      "learning_rate": 4.91167940943844e-06,
      "loss": 0.1059,
      "step": 13132
    },
    {
      "epoch": 0.7790366591529244,
      "grad_norm": 0.3251567482948303,
      "learning_rate": 4.910361191668865e-06,
      "loss": 0.0039,
      "step": 13133
    },
    {
      "epoch": 0.7790959781706015,
      "grad_norm": 2.725048780441284,
      "learning_rate": 4.909042973899289e-06,
      "loss": 0.038,
      "step": 13134
    },
    {
      "epoch": 0.7791552971882786,
      "grad_norm": 12.76662540435791,
      "learning_rate": 4.907724756129713e-06,
      "loss": 0.2272,
      "step": 13135
    },
    {
      "epoch": 0.7792146162059557,
      "grad_norm": 0.02516915462911129,
      "learning_rate": 4.906406538360137e-06,
      "loss": 0.0004,
      "step": 13136
    },
    {
      "epoch": 0.7792739352236328,
      "grad_norm": 7.73076057434082,
      "learning_rate": 4.905088320590562e-06,
      "loss": 0.1077,
      "step": 13137
    },
    {
      "epoch": 0.7793332542413097,
      "grad_norm": 4.390993118286133,
      "learning_rate": 4.903770102820986e-06,
      "loss": 0.053,
      "step": 13138
    },
    {
      "epoch": 0.7793925732589868,
      "grad_norm": 1.743643879890442,
      "learning_rate": 4.902451885051411e-06,
      "loss": 0.0237,
      "step": 13139
    },
    {
      "epoch": 0.7794518922766639,
      "grad_norm": 0.7039226293563843,
      "learning_rate": 4.901133667281836e-06,
      "loss": 0.0071,
      "step": 13140
    },
    {
      "epoch": 0.779511211294341,
      "grad_norm": 0.006708514876663685,
      "learning_rate": 4.89981544951226e-06,
      "loss": 0.0002,
      "step": 13141
    },
    {
      "epoch": 0.7795705303120181,
      "grad_norm": 2.206777811050415,
      "learning_rate": 4.898497231742684e-06,
      "loss": 0.0159,
      "step": 13142
    },
    {
      "epoch": 0.7796298493296951,
      "grad_norm": 0.01183719839900732,
      "learning_rate": 4.897179013973109e-06,
      "loss": 0.0003,
      "step": 13143
    },
    {
      "epoch": 0.7796891683473721,
      "grad_norm": 0.03662192076444626,
      "learning_rate": 4.895860796203533e-06,
      "loss": 0.0012,
      "step": 13144
    },
    {
      "epoch": 0.7797484873650492,
      "grad_norm": 0.00817286316305399,
      "learning_rate": 4.894542578433958e-06,
      "loss": 0.0003,
      "step": 13145
    },
    {
      "epoch": 0.7798078063827263,
      "grad_norm": 0.3491760194301605,
      "learning_rate": 4.893224360664382e-06,
      "loss": 0.0058,
      "step": 13146
    },
    {
      "epoch": 0.7798671254004034,
      "grad_norm": 0.6312188506126404,
      "learning_rate": 4.891906142894807e-06,
      "loss": 0.0026,
      "step": 13147
    },
    {
      "epoch": 0.7799264444180805,
      "grad_norm": 0.02052394114434719,
      "learning_rate": 4.890587925125231e-06,
      "loss": 0.0005,
      "step": 13148
    },
    {
      "epoch": 0.7799857634357575,
      "grad_norm": 2.1172280311584473,
      "learning_rate": 4.889269707355656e-06,
      "loss": 0.2144,
      "step": 13149
    },
    {
      "epoch": 0.7800450824534346,
      "grad_norm": 0.31815245747566223,
      "learning_rate": 4.88795148958608e-06,
      "loss": 0.0039,
      "step": 13150
    },
    {
      "epoch": 0.7801044014711116,
      "grad_norm": 28.456472396850586,
      "learning_rate": 4.886633271816504e-06,
      "loss": 0.1809,
      "step": 13151
    },
    {
      "epoch": 0.7801637204887887,
      "grad_norm": 37.797977447509766,
      "learning_rate": 4.885315054046929e-06,
      "loss": 0.1531,
      "step": 13152
    },
    {
      "epoch": 0.7802230395064658,
      "grad_norm": 0.2979449927806854,
      "learning_rate": 4.8839968362773534e-06,
      "loss": 0.0021,
      "step": 13153
    },
    {
      "epoch": 0.7802823585241428,
      "grad_norm": 11.591761589050293,
      "learning_rate": 4.882678618507778e-06,
      "loss": 0.4537,
      "step": 13154
    },
    {
      "epoch": 0.7803416775418199,
      "grad_norm": 13.799820899963379,
      "learning_rate": 4.881360400738203e-06,
      "loss": 0.1666,
      "step": 13155
    },
    {
      "epoch": 0.780400996559497,
      "grad_norm": 0.025740090757608414,
      "learning_rate": 4.880042182968627e-06,
      "loss": 0.0005,
      "step": 13156
    },
    {
      "epoch": 0.780460315577174,
      "grad_norm": 0.03672504797577858,
      "learning_rate": 4.878723965199051e-06,
      "loss": 0.0008,
      "step": 13157
    },
    {
      "epoch": 0.7805196345948511,
      "grad_norm": 13.723063468933105,
      "learning_rate": 4.877405747429475e-06,
      "loss": 0.6709,
      "step": 13158
    },
    {
      "epoch": 0.7805789536125282,
      "grad_norm": 0.12143465131521225,
      "learning_rate": 4.8760875296599e-06,
      "loss": 0.0016,
      "step": 13159
    },
    {
      "epoch": 0.7806382726302052,
      "grad_norm": 0.01773509569466114,
      "learning_rate": 4.8747693118903244e-06,
      "loss": 0.0006,
      "step": 13160
    },
    {
      "epoch": 0.7806975916478823,
      "grad_norm": 1.7359195947647095,
      "learning_rate": 4.8734510941207495e-06,
      "loss": 0.0394,
      "step": 13161
    },
    {
      "epoch": 0.7807569106655594,
      "grad_norm": 2.1706748008728027,
      "learning_rate": 4.872132876351174e-06,
      "loss": 0.0325,
      "step": 13162
    },
    {
      "epoch": 0.7808162296832365,
      "grad_norm": 4.317630767822266,
      "learning_rate": 4.870814658581598e-06,
      "loss": 0.0443,
      "step": 13163
    },
    {
      "epoch": 0.7808755487009135,
      "grad_norm": 1.0292906761169434,
      "learning_rate": 4.869496440812023e-06,
      "loss": 0.0162,
      "step": 13164
    },
    {
      "epoch": 0.7809348677185906,
      "grad_norm": 4.14439582824707,
      "learning_rate": 4.868178223042447e-06,
      "loss": 0.0249,
      "step": 13165
    },
    {
      "epoch": 0.7809941867362676,
      "grad_norm": 18.090150833129883,
      "learning_rate": 4.866860005272871e-06,
      "loss": 0.8278,
      "step": 13166
    },
    {
      "epoch": 0.7810535057539447,
      "grad_norm": 0.026006821542978287,
      "learning_rate": 4.865541787503296e-06,
      "loss": 0.0006,
      "step": 13167
    },
    {
      "epoch": 0.7811128247716218,
      "grad_norm": 0.03459597006440163,
      "learning_rate": 4.8642235697337205e-06,
      "loss": 0.0008,
      "step": 13168
    },
    {
      "epoch": 0.7811721437892989,
      "grad_norm": 0.09973251819610596,
      "learning_rate": 4.862905351964145e-06,
      "loss": 0.0014,
      "step": 13169
    },
    {
      "epoch": 0.7812314628069759,
      "grad_norm": 0.09832349419593811,
      "learning_rate": 4.861587134194569e-06,
      "loss": 0.0014,
      "step": 13170
    },
    {
      "epoch": 0.781290781824653,
      "grad_norm": 0.11012033373117447,
      "learning_rate": 4.860268916424994e-06,
      "loss": 0.002,
      "step": 13171
    },
    {
      "epoch": 0.78135010084233,
      "grad_norm": 9.842754364013672,
      "learning_rate": 4.858950698655418e-06,
      "loss": 0.2884,
      "step": 13172
    },
    {
      "epoch": 0.7814094198600071,
      "grad_norm": 0.011391589418053627,
      "learning_rate": 4.857632480885843e-06,
      "loss": 0.0004,
      "step": 13173
    },
    {
      "epoch": 0.7814687388776842,
      "grad_norm": 1.4183443784713745,
      "learning_rate": 4.856314263116267e-06,
      "loss": 0.0144,
      "step": 13174
    },
    {
      "epoch": 0.7815280578953613,
      "grad_norm": 0.27280187606811523,
      "learning_rate": 4.8549960453466915e-06,
      "loss": 0.0047,
      "step": 13175
    },
    {
      "epoch": 0.7815873769130384,
      "grad_norm": 15.082601547241211,
      "learning_rate": 4.8536778275771165e-06,
      "loss": 1.0062,
      "step": 13176
    },
    {
      "epoch": 0.7816466959307153,
      "grad_norm": 64.10184478759766,
      "learning_rate": 4.852359609807541e-06,
      "loss": 1.4802,
      "step": 13177
    },
    {
      "epoch": 0.7817060149483924,
      "grad_norm": 3.4274067878723145,
      "learning_rate": 4.851041392037965e-06,
      "loss": 0.0684,
      "step": 13178
    },
    {
      "epoch": 0.7817653339660695,
      "grad_norm": 0.07334056496620178,
      "learning_rate": 4.84972317426839e-06,
      "loss": 0.0017,
      "step": 13179
    },
    {
      "epoch": 0.7818246529837466,
      "grad_norm": 2.723574161529541,
      "learning_rate": 4.848404956498814e-06,
      "loss": 0.0589,
      "step": 13180
    },
    {
      "epoch": 0.7818839720014237,
      "grad_norm": 0.7499995827674866,
      "learning_rate": 4.847086738729238e-06,
      "loss": 0.008,
      "step": 13181
    },
    {
      "epoch": 0.7819432910191008,
      "grad_norm": 28.333044052124023,
      "learning_rate": 4.8457685209596625e-06,
      "loss": 0.5567,
      "step": 13182
    },
    {
      "epoch": 0.7820026100367778,
      "grad_norm": 11.146961212158203,
      "learning_rate": 4.8444503031900875e-06,
      "loss": 0.237,
      "step": 13183
    },
    {
      "epoch": 0.7820619290544548,
      "grad_norm": 0.013491236604750156,
      "learning_rate": 4.843132085420512e-06,
      "loss": 0.0004,
      "step": 13184
    },
    {
      "epoch": 0.7821212480721319,
      "grad_norm": 0.026984183117747307,
      "learning_rate": 4.841813867650936e-06,
      "loss": 0.0002,
      "step": 13185
    },
    {
      "epoch": 0.782180567089809,
      "grad_norm": 20.394847869873047,
      "learning_rate": 4.840495649881361e-06,
      "loss": 0.1813,
      "step": 13186
    },
    {
      "epoch": 0.7822398861074861,
      "grad_norm": 0.174595445394516,
      "learning_rate": 4.839177432111785e-06,
      "loss": 0.0038,
      "step": 13187
    },
    {
      "epoch": 0.7822992051251632,
      "grad_norm": 3.536257266998291,
      "learning_rate": 4.83785921434221e-06,
      "loss": 0.04,
      "step": 13188
    },
    {
      "epoch": 0.7823585241428402,
      "grad_norm": 61.00079345703125,
      "learning_rate": 4.836540996572634e-06,
      "loss": 0.612,
      "step": 13189
    },
    {
      "epoch": 0.7824178431605172,
      "grad_norm": 0.012501835823059082,
      "learning_rate": 4.8352227788030585e-06,
      "loss": 0.0004,
      "step": 13190
    },
    {
      "epoch": 0.7824771621781943,
      "grad_norm": 0.034701742231845856,
      "learning_rate": 4.8339045610334836e-06,
      "loss": 0.0008,
      "step": 13191
    },
    {
      "epoch": 0.7825364811958714,
      "grad_norm": 0.1562674641609192,
      "learning_rate": 4.832586343263908e-06,
      "loss": 0.0017,
      "step": 13192
    },
    {
      "epoch": 0.7825958002135485,
      "grad_norm": 8.510444641113281,
      "learning_rate": 4.831268125494332e-06,
      "loss": 0.0582,
      "step": 13193
    },
    {
      "epoch": 0.7826551192312255,
      "grad_norm": 6.487009048461914,
      "learning_rate": 4.829949907724756e-06,
      "loss": 0.0562,
      "step": 13194
    },
    {
      "epoch": 0.7827144382489026,
      "grad_norm": 0.5544316172599792,
      "learning_rate": 4.828631689955181e-06,
      "loss": 0.0057,
      "step": 13195
    },
    {
      "epoch": 0.7827737572665797,
      "grad_norm": 0.4105650782585144,
      "learning_rate": 4.827313472185605e-06,
      "loss": 0.0044,
      "step": 13196
    },
    {
      "epoch": 0.7828330762842567,
      "grad_norm": 1.5901257991790771,
      "learning_rate": 4.8259952544160295e-06,
      "loss": 0.0168,
      "step": 13197
    },
    {
      "epoch": 0.7828923953019338,
      "grad_norm": 0.16467556357383728,
      "learning_rate": 4.8246770366464546e-06,
      "loss": 0.0026,
      "step": 13198
    },
    {
      "epoch": 0.7829517143196109,
      "grad_norm": 1.317507266998291,
      "learning_rate": 4.823358818876879e-06,
      "loss": 0.0123,
      "step": 13199
    },
    {
      "epoch": 0.7830110333372879,
      "grad_norm": 0.02088259905576706,
      "learning_rate": 4.822040601107304e-06,
      "loss": 0.0005,
      "step": 13200
    },
    {
      "epoch": 0.783070352354965,
      "grad_norm": 20.2304630279541,
      "learning_rate": 4.820722383337728e-06,
      "loss": 0.5989,
      "step": 13201
    },
    {
      "epoch": 0.7831296713726421,
      "grad_norm": 11.04466438293457,
      "learning_rate": 4.819404165568152e-06,
      "loss": 0.4514,
      "step": 13202
    },
    {
      "epoch": 0.7831889903903191,
      "grad_norm": 22.83915901184082,
      "learning_rate": 4.818085947798577e-06,
      "loss": 0.4156,
      "step": 13203
    },
    {
      "epoch": 0.7832483094079962,
      "grad_norm": 0.07057075202465057,
      "learning_rate": 4.816767730029001e-06,
      "loss": 0.0011,
      "step": 13204
    },
    {
      "epoch": 0.7833076284256733,
      "grad_norm": 0.010549299418926239,
      "learning_rate": 4.8154495122594256e-06,
      "loss": 0.0003,
      "step": 13205
    },
    {
      "epoch": 0.7833669474433503,
      "grad_norm": 0.02031669020652771,
      "learning_rate": 4.81413129448985e-06,
      "loss": 0.0004,
      "step": 13206
    },
    {
      "epoch": 0.7834262664610274,
      "grad_norm": 1.9132593870162964,
      "learning_rate": 4.812813076720275e-06,
      "loss": 0.0149,
      "step": 13207
    },
    {
      "epoch": 0.7834855854787045,
      "grad_norm": 0.6195669174194336,
      "learning_rate": 4.811494858950699e-06,
      "loss": 0.0052,
      "step": 13208
    },
    {
      "epoch": 0.7835449044963816,
      "grad_norm": 0.01849406026303768,
      "learning_rate": 4.810176641181123e-06,
      "loss": 0.0005,
      "step": 13209
    },
    {
      "epoch": 0.7836042235140586,
      "grad_norm": 0.11799901723861694,
      "learning_rate": 4.808858423411548e-06,
      "loss": 0.0015,
      "step": 13210
    },
    {
      "epoch": 0.7836635425317356,
      "grad_norm": 2.144144058227539,
      "learning_rate": 4.807540205641972e-06,
      "loss": 0.0171,
      "step": 13211
    },
    {
      "epoch": 0.7837228615494127,
      "grad_norm": 0.02145240642130375,
      "learning_rate": 4.806221987872397e-06,
      "loss": 0.0004,
      "step": 13212
    },
    {
      "epoch": 0.7837821805670898,
      "grad_norm": 7.993264675140381,
      "learning_rate": 4.804903770102821e-06,
      "loss": 0.0505,
      "step": 13213
    },
    {
      "epoch": 0.7838414995847669,
      "grad_norm": 0.45252761244773865,
      "learning_rate": 4.803585552333246e-06,
      "loss": 0.0073,
      "step": 13214
    },
    {
      "epoch": 0.783900818602444,
      "grad_norm": 0.018497535958886147,
      "learning_rate": 4.802267334563671e-06,
      "loss": 0.0008,
      "step": 13215
    },
    {
      "epoch": 0.783960137620121,
      "grad_norm": 0.019762501120567322,
      "learning_rate": 4.800949116794095e-06,
      "loss": 0.0003,
      "step": 13216
    },
    {
      "epoch": 0.784019456637798,
      "grad_norm": 0.01589895971119404,
      "learning_rate": 4.799630899024519e-06,
      "loss": 0.0004,
      "step": 13217
    },
    {
      "epoch": 0.7840787756554751,
      "grad_norm": 12.699983596801758,
      "learning_rate": 4.798312681254943e-06,
      "loss": 0.4047,
      "step": 13218
    },
    {
      "epoch": 0.7841380946731522,
      "grad_norm": 0.1778152585029602,
      "learning_rate": 4.796994463485368e-06,
      "loss": 0.0019,
      "step": 13219
    },
    {
      "epoch": 0.7841974136908293,
      "grad_norm": 11.530153274536133,
      "learning_rate": 4.795676245715793e-06,
      "loss": 0.138,
      "step": 13220
    },
    {
      "epoch": 0.7842567327085064,
      "grad_norm": 4.958341598510742,
      "learning_rate": 4.794358027946217e-06,
      "loss": 0.0446,
      "step": 13221
    },
    {
      "epoch": 0.7843160517261835,
      "grad_norm": 0.007463791873306036,
      "learning_rate": 4.793039810176642e-06,
      "loss": 0.0002,
      "step": 13222
    },
    {
      "epoch": 0.7843753707438604,
      "grad_norm": 39.089683532714844,
      "learning_rate": 4.791721592407066e-06,
      "loss": 0.7221,
      "step": 13223
    },
    {
      "epoch": 0.7844346897615375,
      "grad_norm": 0.04233529046177864,
      "learning_rate": 4.79040337463749e-06,
      "loss": 0.0012,
      "step": 13224
    },
    {
      "epoch": 0.7844940087792146,
      "grad_norm": 18.647058486938477,
      "learning_rate": 4.789085156867914e-06,
      "loss": 0.5489,
      "step": 13225
    },
    {
      "epoch": 0.7845533277968917,
      "grad_norm": 12.374218940734863,
      "learning_rate": 4.7877669390983394e-06,
      "loss": 0.1109,
      "step": 13226
    },
    {
      "epoch": 0.7846126468145688,
      "grad_norm": 0.14956800639629364,
      "learning_rate": 4.7864487213287645e-06,
      "loss": 0.0028,
      "step": 13227
    },
    {
      "epoch": 0.7846719658322459,
      "grad_norm": 0.17843370139598846,
      "learning_rate": 4.785130503559189e-06,
      "loss": 0.0033,
      "step": 13228
    },
    {
      "epoch": 0.7847312848499229,
      "grad_norm": 7.058927059173584,
      "learning_rate": 4.783812285789613e-06,
      "loss": 0.1716,
      "step": 13229
    },
    {
      "epoch": 0.7847906038675999,
      "grad_norm": 0.3010152280330658,
      "learning_rate": 4.782494068020037e-06,
      "loss": 0.0054,
      "step": 13230
    },
    {
      "epoch": 0.784849922885277,
      "grad_norm": 13.21369743347168,
      "learning_rate": 4.781175850250462e-06,
      "loss": 0.2162,
      "step": 13231
    },
    {
      "epoch": 0.7849092419029541,
      "grad_norm": 7.069003105163574,
      "learning_rate": 4.779857632480886e-06,
      "loss": 0.1967,
      "step": 13232
    },
    {
      "epoch": 0.7849685609206312,
      "grad_norm": 0.7859975099563599,
      "learning_rate": 4.7785394147113104e-06,
      "loss": 0.0055,
      "step": 13233
    },
    {
      "epoch": 0.7850278799383082,
      "grad_norm": 1.9429925680160522,
      "learning_rate": 4.7772211969417355e-06,
      "loss": 0.0611,
      "step": 13234
    },
    {
      "epoch": 0.7850871989559853,
      "grad_norm": 0.030021246522665024,
      "learning_rate": 4.77590297917216e-06,
      "loss": 0.0006,
      "step": 13235
    },
    {
      "epoch": 0.7851465179736623,
      "grad_norm": 17.850061416625977,
      "learning_rate": 4.774584761402584e-06,
      "loss": 0.0464,
      "step": 13236
    },
    {
      "epoch": 0.7852058369913394,
      "grad_norm": 0.08678389340639114,
      "learning_rate": 4.773266543633008e-06,
      "loss": 0.0009,
      "step": 13237
    },
    {
      "epoch": 0.7852651560090165,
      "grad_norm": 0.110504649579525,
      "learning_rate": 4.771948325863433e-06,
      "loss": 0.0033,
      "step": 13238
    },
    {
      "epoch": 0.7853244750266936,
      "grad_norm": 1.0547517538070679,
      "learning_rate": 4.770630108093858e-06,
      "loss": 0.0094,
      "step": 13239
    },
    {
      "epoch": 0.7853837940443706,
      "grad_norm": 68.60322570800781,
      "learning_rate": 4.769311890324282e-06,
      "loss": 0.9436,
      "step": 13240
    },
    {
      "epoch": 0.7854431130620477,
      "grad_norm": 0.060607243329286575,
      "learning_rate": 4.7679936725547065e-06,
      "loss": 0.0006,
      "step": 13241
    },
    {
      "epoch": 0.7855024320797248,
      "grad_norm": 0.10127348452806473,
      "learning_rate": 4.766675454785131e-06,
      "loss": 0.0014,
      "step": 13242
    },
    {
      "epoch": 0.7855617510974018,
      "grad_norm": 1.18661630153656,
      "learning_rate": 4.765357237015556e-06,
      "loss": 0.0095,
      "step": 13243
    },
    {
      "epoch": 0.7856210701150789,
      "grad_norm": 0.029555562883615494,
      "learning_rate": 4.76403901924598e-06,
      "loss": 0.0005,
      "step": 13244
    },
    {
      "epoch": 0.785680389132756,
      "grad_norm": 0.09627287834882736,
      "learning_rate": 4.762720801476404e-06,
      "loss": 0.0015,
      "step": 13245
    },
    {
      "epoch": 0.785739708150433,
      "grad_norm": 0.07197663933038712,
      "learning_rate": 4.761402583706829e-06,
      "loss": 0.0012,
      "step": 13246
    },
    {
      "epoch": 0.7857990271681101,
      "grad_norm": 0.04164648428559303,
      "learning_rate": 4.760084365937253e-06,
      "loss": 0.0009,
      "step": 13247
    },
    {
      "epoch": 0.7858583461857872,
      "grad_norm": 0.0879233255982399,
      "learning_rate": 4.7587661481676775e-06,
      "loss": 0.0023,
      "step": 13248
    },
    {
      "epoch": 0.7859176652034642,
      "grad_norm": 0.13410039246082306,
      "learning_rate": 4.757447930398102e-06,
      "loss": 0.0019,
      "step": 13249
    },
    {
      "epoch": 0.7859769842211413,
      "grad_norm": 1.0971256494522095,
      "learning_rate": 4.756129712628527e-06,
      "loss": 0.0101,
      "step": 13250
    },
    {
      "epoch": 0.7860363032388183,
      "grad_norm": 0.3901914358139038,
      "learning_rate": 4.754811494858952e-06,
      "loss": 0.0057,
      "step": 13251
    },
    {
      "epoch": 0.7860956222564954,
      "grad_norm": 15.728169441223145,
      "learning_rate": 4.753493277089375e-06,
      "loss": 0.2558,
      "step": 13252
    },
    {
      "epoch": 0.7861549412741725,
      "grad_norm": 0.005423502530902624,
      "learning_rate": 4.7521750593198e-06,
      "loss": 0.0002,
      "step": 13253
    },
    {
      "epoch": 0.7862142602918496,
      "grad_norm": 0.6077567934989929,
      "learning_rate": 4.750856841550224e-06,
      "loss": 0.0054,
      "step": 13254
    },
    {
      "epoch": 0.7862735793095267,
      "grad_norm": 10.251317977905273,
      "learning_rate": 4.749538623780649e-06,
      "loss": 0.6164,
      "step": 13255
    },
    {
      "epoch": 0.7863328983272037,
      "grad_norm": 68.84339141845703,
      "learning_rate": 4.7482204060110735e-06,
      "loss": 0.3798,
      "step": 13256
    },
    {
      "epoch": 0.7863922173448807,
      "grad_norm": 1.404449224472046,
      "learning_rate": 4.746902188241498e-06,
      "loss": 0.0209,
      "step": 13257
    },
    {
      "epoch": 0.7864515363625578,
      "grad_norm": 15.247507095336914,
      "learning_rate": 4.745583970471923e-06,
      "loss": 0.4039,
      "step": 13258
    },
    {
      "epoch": 0.7865108553802349,
      "grad_norm": 7.526970863342285,
      "learning_rate": 4.744265752702347e-06,
      "loss": 0.0241,
      "step": 13259
    },
    {
      "epoch": 0.786570174397912,
      "grad_norm": 12.768494606018066,
      "learning_rate": 4.742947534932771e-06,
      "loss": 0.5331,
      "step": 13260
    },
    {
      "epoch": 0.7866294934155891,
      "grad_norm": 2.4763457775115967,
      "learning_rate": 4.741629317163195e-06,
      "loss": 0.023,
      "step": 13261
    },
    {
      "epoch": 0.7866888124332662,
      "grad_norm": 1.02884840965271,
      "learning_rate": 4.74031109939362e-06,
      "loss": 0.0158,
      "step": 13262
    },
    {
      "epoch": 0.7867481314509431,
      "grad_norm": 11.841049194335938,
      "learning_rate": 4.7389928816240445e-06,
      "loss": 0.253,
      "step": 13263
    },
    {
      "epoch": 0.7868074504686202,
      "grad_norm": 1.6825497150421143,
      "learning_rate": 4.737674663854469e-06,
      "loss": 0.0113,
      "step": 13264
    },
    {
      "epoch": 0.7868667694862973,
      "grad_norm": 0.04680563509464264,
      "learning_rate": 4.736356446084894e-06,
      "loss": 0.0008,
      "step": 13265
    },
    {
      "epoch": 0.7869260885039744,
      "grad_norm": 3.241575002670288,
      "learning_rate": 4.735038228315318e-06,
      "loss": 0.0483,
      "step": 13266
    },
    {
      "epoch": 0.7869854075216515,
      "grad_norm": 2.883512258529663,
      "learning_rate": 4.733720010545743e-06,
      "loss": 0.0406,
      "step": 13267
    },
    {
      "epoch": 0.7870447265393286,
      "grad_norm": 10.303629875183105,
      "learning_rate": 4.732401792776167e-06,
      "loss": 0.3965,
      "step": 13268
    },
    {
      "epoch": 0.7871040455570055,
      "grad_norm": 0.057544343173503876,
      "learning_rate": 4.731083575006591e-06,
      "loss": 0.0008,
      "step": 13269
    },
    {
      "epoch": 0.7871633645746826,
      "grad_norm": 11.434215545654297,
      "learning_rate": 4.729765357237016e-06,
      "loss": 0.1911,
      "step": 13270
    },
    {
      "epoch": 0.7872226835923597,
      "grad_norm": 9.080121040344238,
      "learning_rate": 4.7284471394674405e-06,
      "loss": 0.154,
      "step": 13271
    },
    {
      "epoch": 0.7872820026100368,
      "grad_norm": 8.776164054870605,
      "learning_rate": 4.727128921697865e-06,
      "loss": 0.2336,
      "step": 13272
    },
    {
      "epoch": 0.7873413216277139,
      "grad_norm": 0.571292519569397,
      "learning_rate": 4.725810703928289e-06,
      "loss": 0.0044,
      "step": 13273
    },
    {
      "epoch": 0.787400640645391,
      "grad_norm": 0.036693498492240906,
      "learning_rate": 4.724492486158714e-06,
      "loss": 0.0008,
      "step": 13274
    },
    {
      "epoch": 0.787459959663068,
      "grad_norm": 14.163796424865723,
      "learning_rate": 4.723174268389138e-06,
      "loss": 0.3305,
      "step": 13275
    },
    {
      "epoch": 0.787519278680745,
      "grad_norm": 0.012443487532436848,
      "learning_rate": 4.721856050619562e-06,
      "loss": 0.0004,
      "step": 13276
    },
    {
      "epoch": 0.7875785976984221,
      "grad_norm": 0.1795421540737152,
      "learning_rate": 4.720537832849987e-06,
      "loss": 0.0021,
      "step": 13277
    },
    {
      "epoch": 0.7876379167160992,
      "grad_norm": 0.3859827518463135,
      "learning_rate": 4.7192196150804116e-06,
      "loss": 0.0052,
      "step": 13278
    },
    {
      "epoch": 0.7876972357337763,
      "grad_norm": 0.0758742019534111,
      "learning_rate": 4.717901397310837e-06,
      "loss": 0.0019,
      "step": 13279
    },
    {
      "epoch": 0.7877565547514533,
      "grad_norm": 11.45055103302002,
      "learning_rate": 4.71658317954126e-06,
      "loss": 0.2049,
      "step": 13280
    },
    {
      "epoch": 0.7878158737691304,
      "grad_norm": 3.951834201812744,
      "learning_rate": 4.715264961771685e-06,
      "loss": 0.1967,
      "step": 13281
    },
    {
      "epoch": 0.7878751927868074,
      "grad_norm": 6.545129299163818,
      "learning_rate": 4.71394674400211e-06,
      "loss": 0.0771,
      "step": 13282
    },
    {
      "epoch": 0.7879345118044845,
      "grad_norm": 23.073591232299805,
      "learning_rate": 4.712628526232534e-06,
      "loss": 0.1826,
      "step": 13283
    },
    {
      "epoch": 0.7879938308221616,
      "grad_norm": 3.9956390857696533,
      "learning_rate": 4.711310308462958e-06,
      "loss": 0.1095,
      "step": 13284
    },
    {
      "epoch": 0.7880531498398387,
      "grad_norm": 0.19888818264007568,
      "learning_rate": 4.7099920906933826e-06,
      "loss": 0.0022,
      "step": 13285
    },
    {
      "epoch": 0.7881124688575157,
      "grad_norm": 0.11807659268379211,
      "learning_rate": 4.708673872923808e-06,
      "loss": 0.0033,
      "step": 13286
    },
    {
      "epoch": 0.7881717878751928,
      "grad_norm": 5.570311546325684,
      "learning_rate": 4.707355655154232e-06,
      "loss": 0.2095,
      "step": 13287
    },
    {
      "epoch": 0.7882311068928699,
      "grad_norm": 0.7404035925865173,
      "learning_rate": 4.706037437384656e-06,
      "loss": 0.0069,
      "step": 13288
    },
    {
      "epoch": 0.7882904259105469,
      "grad_norm": 3.1285271644592285,
      "learning_rate": 4.704719219615081e-06,
      "loss": 0.0862,
      "step": 13289
    },
    {
      "epoch": 0.788349744928224,
      "grad_norm": 11.303540229797363,
      "learning_rate": 4.703401001845505e-06,
      "loss": 0.8955,
      "step": 13290
    },
    {
      "epoch": 0.788409063945901,
      "grad_norm": 7.633083820343018,
      "learning_rate": 4.702082784075929e-06,
      "loss": 0.3379,
      "step": 13291
    },
    {
      "epoch": 0.7884683829635781,
      "grad_norm": 0.1945025771856308,
      "learning_rate": 4.700764566306354e-06,
      "loss": 0.0019,
      "step": 13292
    },
    {
      "epoch": 0.7885277019812552,
      "grad_norm": 5.834860801696777,
      "learning_rate": 4.699446348536779e-06,
      "loss": 0.1009,
      "step": 13293
    },
    {
      "epoch": 0.7885870209989323,
      "grad_norm": 2.7333321571350098,
      "learning_rate": 4.698128130767204e-06,
      "loss": 0.0136,
      "step": 13294
    },
    {
      "epoch": 0.7886463400166093,
      "grad_norm": 7.235783100128174,
      "learning_rate": 4.696809912997628e-06,
      "loss": 0.3935,
      "step": 13295
    },
    {
      "epoch": 0.7887056590342864,
      "grad_norm": 0.01226135902106762,
      "learning_rate": 4.695491695228052e-06,
      "loss": 0.0003,
      "step": 13296
    },
    {
      "epoch": 0.7887649780519634,
      "grad_norm": 4.568893909454346,
      "learning_rate": 4.694173477458476e-06,
      "loss": 0.0114,
      "step": 13297
    },
    {
      "epoch": 0.7888242970696405,
      "grad_norm": 23.918197631835938,
      "learning_rate": 4.692855259688901e-06,
      "loss": 0.0639,
      "step": 13298
    },
    {
      "epoch": 0.7888836160873176,
      "grad_norm": 9.921680450439453,
      "learning_rate": 4.691537041919325e-06,
      "loss": 0.215,
      "step": 13299
    },
    {
      "epoch": 0.7889429351049947,
      "grad_norm": 1.5467596054077148,
      "learning_rate": 4.69021882414975e-06,
      "loss": 0.0319,
      "step": 13300
    },
    {
      "epoch": 0.7890022541226718,
      "grad_norm": 0.048998501151800156,
      "learning_rate": 4.688900606380175e-06,
      "loss": 0.0011,
      "step": 13301
    },
    {
      "epoch": 0.7890615731403487,
      "grad_norm": 4.095199108123779,
      "learning_rate": 4.687582388610599e-06,
      "loss": 0.0648,
      "step": 13302
    },
    {
      "epoch": 0.7891208921580258,
      "grad_norm": 0.005650642793625593,
      "learning_rate": 4.686264170841023e-06,
      "loss": 0.0002,
      "step": 13303
    },
    {
      "epoch": 0.7891802111757029,
      "grad_norm": 2.3481221199035645,
      "learning_rate": 4.684945953071448e-06,
      "loss": 0.0871,
      "step": 13304
    },
    {
      "epoch": 0.78923953019338,
      "grad_norm": 0.07556043565273285,
      "learning_rate": 4.683627735301872e-06,
      "loss": 0.0016,
      "step": 13305
    },
    {
      "epoch": 0.7892988492110571,
      "grad_norm": 1.8033008575439453,
      "learning_rate": 4.682309517532297e-06,
      "loss": 0.0156,
      "step": 13306
    },
    {
      "epoch": 0.7893581682287342,
      "grad_norm": 20.40886116027832,
      "learning_rate": 4.6809912997627214e-06,
      "loss": 0.2752,
      "step": 13307
    },
    {
      "epoch": 0.7894174872464113,
      "grad_norm": 0.03351496532559395,
      "learning_rate": 4.679673081993146e-06,
      "loss": 0.0006,
      "step": 13308
    },
    {
      "epoch": 0.7894768062640882,
      "grad_norm": 10.352716445922852,
      "learning_rate": 4.67835486422357e-06,
      "loss": 0.5334,
      "step": 13309
    },
    {
      "epoch": 0.7895361252817653,
      "grad_norm": 0.3979246914386749,
      "learning_rate": 4.677036646453995e-06,
      "loss": 0.0041,
      "step": 13310
    },
    {
      "epoch": 0.7895954442994424,
      "grad_norm": 2.9975197315216064,
      "learning_rate": 4.675718428684419e-06,
      "loss": 0.0884,
      "step": 13311
    },
    {
      "epoch": 0.7896547633171195,
      "grad_norm": 0.08646538108587265,
      "learning_rate": 4.674400210914843e-06,
      "loss": 0.0016,
      "step": 13312
    },
    {
      "epoch": 0.7897140823347966,
      "grad_norm": 5.964049339294434,
      "learning_rate": 4.673081993145268e-06,
      "loss": 0.0758,
      "step": 13313
    },
    {
      "epoch": 0.7897734013524736,
      "grad_norm": 0.8922886252403259,
      "learning_rate": 4.6717637753756925e-06,
      "loss": 0.0097,
      "step": 13314
    },
    {
      "epoch": 0.7898327203701506,
      "grad_norm": 0.20498168468475342,
      "learning_rate": 4.670445557606117e-06,
      "loss": 0.002,
      "step": 13315
    },
    {
      "epoch": 0.7898920393878277,
      "grad_norm": 0.1470382958650589,
      "learning_rate": 4.669127339836542e-06,
      "loss": 0.0018,
      "step": 13316
    },
    {
      "epoch": 0.7899513584055048,
      "grad_norm": 1.2630635499954224,
      "learning_rate": 4.667809122066966e-06,
      "loss": 0.0086,
      "step": 13317
    },
    {
      "epoch": 0.7900106774231819,
      "grad_norm": 14.95577621459961,
      "learning_rate": 4.666490904297391e-06,
      "loss": 0.7033,
      "step": 13318
    },
    {
      "epoch": 0.790069996440859,
      "grad_norm": 12.884708404541016,
      "learning_rate": 4.665172686527814e-06,
      "loss": 0.7454,
      "step": 13319
    },
    {
      "epoch": 0.790129315458536,
      "grad_norm": 3.525071620941162,
      "learning_rate": 4.663854468758239e-06,
      "loss": 0.0776,
      "step": 13320
    },
    {
      "epoch": 0.7901886344762131,
      "grad_norm": 1.349605917930603,
      "learning_rate": 4.6625362509886635e-06,
      "loss": 0.0165,
      "step": 13321
    },
    {
      "epoch": 0.7902479534938901,
      "grad_norm": 1.187885046005249,
      "learning_rate": 4.6612180332190885e-06,
      "loss": 0.0136,
      "step": 13322
    },
    {
      "epoch": 0.7903072725115672,
      "grad_norm": 8.40023422241211,
      "learning_rate": 4.659899815449513e-06,
      "loss": 0.2488,
      "step": 13323
    },
    {
      "epoch": 0.7903665915292443,
      "grad_norm": 1.7954583168029785,
      "learning_rate": 4.658581597679937e-06,
      "loss": 0.0115,
      "step": 13324
    },
    {
      "epoch": 0.7904259105469214,
      "grad_norm": 0.057285062968730927,
      "learning_rate": 4.657263379910362e-06,
      "loss": 0.001,
      "step": 13325
    },
    {
      "epoch": 0.7904852295645984,
      "grad_norm": 14.275354385375977,
      "learning_rate": 4.655945162140786e-06,
      "loss": 0.3328,
      "step": 13326
    },
    {
      "epoch": 0.7905445485822755,
      "grad_norm": 20.473173141479492,
      "learning_rate": 4.65462694437121e-06,
      "loss": 0.8084,
      "step": 13327
    },
    {
      "epoch": 0.7906038675999525,
      "grad_norm": 0.068482406437397,
      "learning_rate": 4.653308726601635e-06,
      "loss": 0.0005,
      "step": 13328
    },
    {
      "epoch": 0.7906631866176296,
      "grad_norm": 0.7345622777938843,
      "learning_rate": 4.6519905088320595e-06,
      "loss": 0.0075,
      "step": 13329
    },
    {
      "epoch": 0.7907225056353067,
      "grad_norm": 0.05466296896338463,
      "learning_rate": 4.650672291062484e-06,
      "loss": 0.0007,
      "step": 13330
    },
    {
      "epoch": 0.7907818246529837,
      "grad_norm": 222.0410614013672,
      "learning_rate": 4.649354073292908e-06,
      "loss": 0.6111,
      "step": 13331
    },
    {
      "epoch": 0.7908411436706608,
      "grad_norm": 0.24235841631889343,
      "learning_rate": 4.648035855523333e-06,
      "loss": 0.0042,
      "step": 13332
    },
    {
      "epoch": 0.7909004626883379,
      "grad_norm": 6.086169242858887,
      "learning_rate": 4.646717637753757e-06,
      "loss": 0.0952,
      "step": 13333
    },
    {
      "epoch": 0.790959781706015,
      "grad_norm": 2.663206100463867,
      "learning_rate": 4.645399419984182e-06,
      "loss": 0.0337,
      "step": 13334
    },
    {
      "epoch": 0.791019100723692,
      "grad_norm": 8.638455390930176,
      "learning_rate": 4.644081202214606e-06,
      "loss": 0.0814,
      "step": 13335
    },
    {
      "epoch": 0.791078419741369,
      "grad_norm": 10.584749221801758,
      "learning_rate": 4.6427629844450305e-06,
      "loss": 0.1594,
      "step": 13336
    },
    {
      "epoch": 0.7911377387590461,
      "grad_norm": 17.092586517333984,
      "learning_rate": 4.6414447666754555e-06,
      "loss": 0.5467,
      "step": 13337
    },
    {
      "epoch": 0.7911970577767232,
      "grad_norm": 7.996772289276123,
      "learning_rate": 4.64012654890588e-06,
      "loss": 0.1327,
      "step": 13338
    },
    {
      "epoch": 0.7912563767944003,
      "grad_norm": 14.343162536621094,
      "learning_rate": 4.638808331136304e-06,
      "loss": 0.6029,
      "step": 13339
    },
    {
      "epoch": 0.7913156958120774,
      "grad_norm": 9.753511428833008,
      "learning_rate": 4.637490113366729e-06,
      "loss": 0.091,
      "step": 13340
    },
    {
      "epoch": 0.7913750148297544,
      "grad_norm": 4.555389404296875,
      "learning_rate": 4.636171895597153e-06,
      "loss": 0.0519,
      "step": 13341
    },
    {
      "epoch": 0.7914343338474314,
      "grad_norm": 0.11816708743572235,
      "learning_rate": 4.634853677827577e-06,
      "loss": 0.0012,
      "step": 13342
    },
    {
      "epoch": 0.7914936528651085,
      "grad_norm": 2.3658719062805176,
      "learning_rate": 4.6335354600580015e-06,
      "loss": 0.0308,
      "step": 13343
    },
    {
      "epoch": 0.7915529718827856,
      "grad_norm": 0.08013264834880829,
      "learning_rate": 4.6322172422884265e-06,
      "loss": 0.0019,
      "step": 13344
    },
    {
      "epoch": 0.7916122909004627,
      "grad_norm": 0.05414612963795662,
      "learning_rate": 4.630899024518851e-06,
      "loss": 0.0013,
      "step": 13345
    },
    {
      "epoch": 0.7916716099181398,
      "grad_norm": 0.08828490972518921,
      "learning_rate": 4.629580806749276e-06,
      "loss": 0.0012,
      "step": 13346
    },
    {
      "epoch": 0.7917309289358169,
      "grad_norm": 0.010251149535179138,
      "learning_rate": 4.6282625889797e-06,
      "loss": 0.0003,
      "step": 13347
    },
    {
      "epoch": 0.7917902479534938,
      "grad_norm": 4.666157245635986,
      "learning_rate": 4.626944371210124e-06,
      "loss": 0.0983,
      "step": 13348
    },
    {
      "epoch": 0.7918495669711709,
      "grad_norm": 5.121536731719971,
      "learning_rate": 4.625626153440549e-06,
      "loss": 0.0423,
      "step": 13349
    },
    {
      "epoch": 0.791908885988848,
      "grad_norm": 23.221704483032227,
      "learning_rate": 4.624307935670973e-06,
      "loss": 0.2147,
      "step": 13350
    },
    {
      "epoch": 0.7919682050065251,
      "grad_norm": 0.09340203553438187,
      "learning_rate": 4.6229897179013975e-06,
      "loss": 0.0017,
      "step": 13351
    },
    {
      "epoch": 0.7920275240242022,
      "grad_norm": 0.1801113784313202,
      "learning_rate": 4.6216715001318226e-06,
      "loss": 0.0011,
      "step": 13352
    },
    {
      "epoch": 0.7920868430418793,
      "grad_norm": 11.254576683044434,
      "learning_rate": 4.620353282362247e-06,
      "loss": 0.4876,
      "step": 13353
    },
    {
      "epoch": 0.7921461620595563,
      "grad_norm": 0.9837743043899536,
      "learning_rate": 4.619035064592671e-06,
      "loss": 0.014,
      "step": 13354
    },
    {
      "epoch": 0.7922054810772333,
      "grad_norm": 0.35533684492111206,
      "learning_rate": 4.617716846823095e-06,
      "loss": 0.0053,
      "step": 13355
    },
    {
      "epoch": 0.7922648000949104,
      "grad_norm": 4.78621244430542,
      "learning_rate": 4.61639862905352e-06,
      "loss": 0.0408,
      "step": 13356
    },
    {
      "epoch": 0.7923241191125875,
      "grad_norm": 66.71692657470703,
      "learning_rate": 4.615080411283944e-06,
      "loss": 0.3783,
      "step": 13357
    },
    {
      "epoch": 0.7923834381302646,
      "grad_norm": 4.564377307891846,
      "learning_rate": 4.6137621935143685e-06,
      "loss": 0.2727,
      "step": 13358
    },
    {
      "epoch": 0.7924427571479417,
      "grad_norm": 0.005685742944478989,
      "learning_rate": 4.612443975744794e-06,
      "loss": 0.0002,
      "step": 13359
    },
    {
      "epoch": 0.7925020761656187,
      "grad_norm": 1.435999870300293,
      "learning_rate": 4.611125757975218e-06,
      "loss": 0.0043,
      "step": 13360
    },
    {
      "epoch": 0.7925613951832957,
      "grad_norm": 0.008500334806740284,
      "learning_rate": 4.609807540205643e-06,
      "loss": 0.0003,
      "step": 13361
    },
    {
      "epoch": 0.7926207142009728,
      "grad_norm": 5.853292465209961,
      "learning_rate": 4.608489322436067e-06,
      "loss": 0.076,
      "step": 13362
    },
    {
      "epoch": 0.7926800332186499,
      "grad_norm": 0.01677873730659485,
      "learning_rate": 4.607171104666491e-06,
      "loss": 0.0004,
      "step": 13363
    },
    {
      "epoch": 0.792739352236327,
      "grad_norm": 10.643937110900879,
      "learning_rate": 4.605852886896916e-06,
      "loss": 0.526,
      "step": 13364
    },
    {
      "epoch": 0.792798671254004,
      "grad_norm": 9.954612731933594,
      "learning_rate": 4.60453466912734e-06,
      "loss": 0.4102,
      "step": 13365
    },
    {
      "epoch": 0.7928579902716811,
      "grad_norm": 0.04089118912816048,
      "learning_rate": 4.603216451357765e-06,
      "loss": 0.0007,
      "step": 13366
    },
    {
      "epoch": 0.7929173092893582,
      "grad_norm": 0.05327083170413971,
      "learning_rate": 4.601898233588189e-06,
      "loss": 0.0007,
      "step": 13367
    },
    {
      "epoch": 0.7929766283070352,
      "grad_norm": 0.004069475922733545,
      "learning_rate": 4.600580015818614e-06,
      "loss": 0.0001,
      "step": 13368
    },
    {
      "epoch": 0.7930359473247123,
      "grad_norm": 0.01959773525595665,
      "learning_rate": 4.599261798049038e-06,
      "loss": 0.0007,
      "step": 13369
    },
    {
      "epoch": 0.7930952663423894,
      "grad_norm": 6.263937473297119,
      "learning_rate": 4.597943580279462e-06,
      "loss": 0.127,
      "step": 13370
    },
    {
      "epoch": 0.7931545853600664,
      "grad_norm": 11.431840896606445,
      "learning_rate": 4.596625362509887e-06,
      "loss": 0.3201,
      "step": 13371
    },
    {
      "epoch": 0.7932139043777435,
      "grad_norm": 0.004517755471169949,
      "learning_rate": 4.595307144740311e-06,
      "loss": 0.0001,
      "step": 13372
    },
    {
      "epoch": 0.7932732233954206,
      "grad_norm": 0.08319173008203506,
      "learning_rate": 4.5939889269707364e-06,
      "loss": 0.0013,
      "step": 13373
    },
    {
      "epoch": 0.7933325424130976,
      "grad_norm": 70.09194946289062,
      "learning_rate": 4.592670709201161e-06,
      "loss": 1.7435,
      "step": 13374
    },
    {
      "epoch": 0.7933918614307747,
      "grad_norm": 0.05024921894073486,
      "learning_rate": 4.591352491431585e-06,
      "loss": 0.001,
      "step": 13375
    },
    {
      "epoch": 0.7934511804484518,
      "grad_norm": 0.2382628470659256,
      "learning_rate": 4.59003427366201e-06,
      "loss": 0.0028,
      "step": 13376
    },
    {
      "epoch": 0.7935104994661288,
      "grad_norm": 11.550976753234863,
      "learning_rate": 4.588716055892434e-06,
      "loss": 0.1521,
      "step": 13377
    },
    {
      "epoch": 0.7935698184838059,
      "grad_norm": 0.2519885003566742,
      "learning_rate": 4.587397838122858e-06,
      "loss": 0.0028,
      "step": 13378
    },
    {
      "epoch": 0.793629137501483,
      "grad_norm": 5.440768241882324,
      "learning_rate": 4.586079620353282e-06,
      "loss": 0.1362,
      "step": 13379
    },
    {
      "epoch": 0.7936884565191601,
      "grad_norm": 0.1831347644329071,
      "learning_rate": 4.5847614025837074e-06,
      "loss": 0.002,
      "step": 13380
    },
    {
      "epoch": 0.7937477755368371,
      "grad_norm": 7.313656330108643,
      "learning_rate": 4.583443184814132e-06,
      "loss": 0.3137,
      "step": 13381
    },
    {
      "epoch": 0.7938070945545141,
      "grad_norm": 0.02011263370513916,
      "learning_rate": 4.582124967044556e-06,
      "loss": 0.0007,
      "step": 13382
    },
    {
      "epoch": 0.7938664135721912,
      "grad_norm": 10.733962059020996,
      "learning_rate": 4.580806749274981e-06,
      "loss": 0.27,
      "step": 13383
    },
    {
      "epoch": 0.7939257325898683,
      "grad_norm": 2.550438165664673,
      "learning_rate": 4.579488531505405e-06,
      "loss": 0.0307,
      "step": 13384
    },
    {
      "epoch": 0.7939850516075454,
      "grad_norm": 12.645087242126465,
      "learning_rate": 4.57817031373583e-06,
      "loss": 0.2389,
      "step": 13385
    },
    {
      "epoch": 0.7940443706252225,
      "grad_norm": 1.5900920629501343,
      "learning_rate": 4.576852095966253e-06,
      "loss": 0.0357,
      "step": 13386
    },
    {
      "epoch": 0.7941036896428996,
      "grad_norm": 12.624195098876953,
      "learning_rate": 4.5755338781966784e-06,
      "loss": 0.2734,
      "step": 13387
    },
    {
      "epoch": 0.7941630086605765,
      "grad_norm": 7.511338233947754,
      "learning_rate": 4.5742156604271035e-06,
      "loss": 0.2629,
      "step": 13388
    },
    {
      "epoch": 0.7942223276782536,
      "grad_norm": 0.006366481073200703,
      "learning_rate": 4.572897442657528e-06,
      "loss": 0.0002,
      "step": 13389
    },
    {
      "epoch": 0.7942816466959307,
      "grad_norm": 11.265839576721191,
      "learning_rate": 4.571579224887952e-06,
      "loss": 0.3872,
      "step": 13390
    },
    {
      "epoch": 0.7943409657136078,
      "grad_norm": 0.038923200219869614,
      "learning_rate": 4.570261007118376e-06,
      "loss": 0.0004,
      "step": 13391
    },
    {
      "epoch": 0.7944002847312849,
      "grad_norm": 14.027606010437012,
      "learning_rate": 4.568942789348801e-06,
      "loss": 0.1151,
      "step": 13392
    },
    {
      "epoch": 0.794459603748962,
      "grad_norm": 0.017815828323364258,
      "learning_rate": 4.567624571579225e-06,
      "loss": 0.0004,
      "step": 13393
    },
    {
      "epoch": 0.7945189227666389,
      "grad_norm": 0.03331214562058449,
      "learning_rate": 4.5663063538096494e-06,
      "loss": 0.0006,
      "step": 13394
    },
    {
      "epoch": 0.794578241784316,
      "grad_norm": 1.1690247058868408,
      "learning_rate": 4.5649881360400745e-06,
      "loss": 0.0118,
      "step": 13395
    },
    {
      "epoch": 0.7946375608019931,
      "grad_norm": 1.1288456916809082,
      "learning_rate": 4.563669918270499e-06,
      "loss": 0.0139,
      "step": 13396
    },
    {
      "epoch": 0.7946968798196702,
      "grad_norm": 2.930924892425537,
      "learning_rate": 4.562351700500923e-06,
      "loss": 0.0348,
      "step": 13397
    },
    {
      "epoch": 0.7947561988373473,
      "grad_norm": 6.8115034103393555,
      "learning_rate": 4.561033482731347e-06,
      "loss": 0.0703,
      "step": 13398
    },
    {
      "epoch": 0.7948155178550244,
      "grad_norm": 0.23301321268081665,
      "learning_rate": 4.559715264961772e-06,
      "loss": 0.0012,
      "step": 13399
    },
    {
      "epoch": 0.7948748368727014,
      "grad_norm": 15.361764907836914,
      "learning_rate": 4.558397047192197e-06,
      "loss": 0.1537,
      "step": 13400
    },
    {
      "epoch": 0.7949341558903784,
      "grad_norm": 0.25340479612350464,
      "learning_rate": 4.557078829422621e-06,
      "loss": 0.0039,
      "step": 13401
    },
    {
      "epoch": 0.7949934749080555,
      "grad_norm": 11.104266166687012,
      "learning_rate": 4.5557606116530455e-06,
      "loss": 0.0849,
      "step": 13402
    },
    {
      "epoch": 0.7950527939257326,
      "grad_norm": 10.925339698791504,
      "learning_rate": 4.55444239388347e-06,
      "loss": 0.2941,
      "step": 13403
    },
    {
      "epoch": 0.7951121129434097,
      "grad_norm": 0.027740946039557457,
      "learning_rate": 4.553124176113895e-06,
      "loss": 0.0007,
      "step": 13404
    },
    {
      "epoch": 0.7951714319610867,
      "grad_norm": 0.2237657755613327,
      "learning_rate": 4.551805958344319e-06,
      "loss": 0.0019,
      "step": 13405
    },
    {
      "epoch": 0.7952307509787638,
      "grad_norm": 3.6905570030212402,
      "learning_rate": 4.550487740574743e-06,
      "loss": 0.028,
      "step": 13406
    },
    {
      "epoch": 0.7952900699964408,
      "grad_norm": 0.2757105827331543,
      "learning_rate": 4.549169522805168e-06,
      "loss": 0.0022,
      "step": 13407
    },
    {
      "epoch": 0.7953493890141179,
      "grad_norm": 0.05671302601695061,
      "learning_rate": 4.547851305035592e-06,
      "loss": 0.0007,
      "step": 13408
    },
    {
      "epoch": 0.795408708031795,
      "grad_norm": 10.582244873046875,
      "learning_rate": 4.5465330872660165e-06,
      "loss": 0.1455,
      "step": 13409
    },
    {
      "epoch": 0.7954680270494721,
      "grad_norm": 6.76084041595459,
      "learning_rate": 4.545214869496441e-06,
      "loss": 0.1777,
      "step": 13410
    },
    {
      "epoch": 0.7955273460671491,
      "grad_norm": 0.006954510230571032,
      "learning_rate": 4.543896651726866e-06,
      "loss": 0.0002,
      "step": 13411
    },
    {
      "epoch": 0.7955866650848262,
      "grad_norm": 9.182907104492188,
      "learning_rate": 4.542578433957291e-06,
      "loss": 0.073,
      "step": 13412
    },
    {
      "epoch": 0.7956459841025033,
      "grad_norm": 26.16975212097168,
      "learning_rate": 4.541260216187715e-06,
      "loss": 0.8572,
      "step": 13413
    },
    {
      "epoch": 0.7957053031201803,
      "grad_norm": 1.000234842300415,
      "learning_rate": 4.539941998418139e-06,
      "loss": 0.0086,
      "step": 13414
    },
    {
      "epoch": 0.7957646221378574,
      "grad_norm": 0.014725659042596817,
      "learning_rate": 4.538623780648563e-06,
      "loss": 0.0004,
      "step": 13415
    },
    {
      "epoch": 0.7958239411555345,
      "grad_norm": 3.860191583633423,
      "learning_rate": 4.537305562878988e-06,
      "loss": 0.0546,
      "step": 13416
    },
    {
      "epoch": 0.7958832601732115,
      "grad_norm": 0.058547623455524445,
      "learning_rate": 4.5359873451094125e-06,
      "loss": 0.0013,
      "step": 13417
    },
    {
      "epoch": 0.7959425791908886,
      "grad_norm": 2.518683433532715,
      "learning_rate": 4.534669127339837e-06,
      "loss": 0.0482,
      "step": 13418
    },
    {
      "epoch": 0.7960018982085657,
      "grad_norm": 6.610963344573975,
      "learning_rate": 4.533350909570262e-06,
      "loss": 0.0808,
      "step": 13419
    },
    {
      "epoch": 0.7960612172262427,
      "grad_norm": 0.3553108274936676,
      "learning_rate": 4.532032691800686e-06,
      "loss": 0.0037,
      "step": 13420
    },
    {
      "epoch": 0.7961205362439198,
      "grad_norm": 0.05130963400006294,
      "learning_rate": 4.53071447403111e-06,
      "loss": 0.0006,
      "step": 13421
    },
    {
      "epoch": 0.7961798552615968,
      "grad_norm": 22.09010124206543,
      "learning_rate": 4.529396256261534e-06,
      "loss": 0.3107,
      "step": 13422
    },
    {
      "epoch": 0.7962391742792739,
      "grad_norm": 14.789765357971191,
      "learning_rate": 4.528078038491959e-06,
      "loss": 0.1293,
      "step": 13423
    },
    {
      "epoch": 0.796298493296951,
      "grad_norm": 0.5053836107254028,
      "learning_rate": 4.526759820722384e-06,
      "loss": 0.0085,
      "step": 13424
    },
    {
      "epoch": 0.7963578123146281,
      "grad_norm": 0.01817072369158268,
      "learning_rate": 4.525441602952808e-06,
      "loss": 0.0005,
      "step": 13425
    },
    {
      "epoch": 0.7964171313323052,
      "grad_norm": 24.33299446105957,
      "learning_rate": 4.524123385183233e-06,
      "loss": 0.7826,
      "step": 13426
    },
    {
      "epoch": 0.7964764503499822,
      "grad_norm": 0.5328299403190613,
      "learning_rate": 4.522805167413657e-06,
      "loss": 0.006,
      "step": 13427
    },
    {
      "epoch": 0.7965357693676592,
      "grad_norm": 4.528552055358887,
      "learning_rate": 4.521486949644082e-06,
      "loss": 0.0199,
      "step": 13428
    },
    {
      "epoch": 0.7965950883853363,
      "grad_norm": 1.1324844360351562,
      "learning_rate": 4.520168731874506e-06,
      "loss": 0.0125,
      "step": 13429
    },
    {
      "epoch": 0.7966544074030134,
      "grad_norm": 4.68921422958374,
      "learning_rate": 4.51885051410493e-06,
      "loss": 0.0187,
      "step": 13430
    },
    {
      "epoch": 0.7967137264206905,
      "grad_norm": 0.007004281971603632,
      "learning_rate": 4.517532296335355e-06,
      "loss": 0.0003,
      "step": 13431
    },
    {
      "epoch": 0.7967730454383676,
      "grad_norm": 93.6126708984375,
      "learning_rate": 4.5162140785657796e-06,
      "loss": 0.8998,
      "step": 13432
    },
    {
      "epoch": 0.7968323644560447,
      "grad_norm": 0.017288275063037872,
      "learning_rate": 4.514895860796204e-06,
      "loss": 0.0004,
      "step": 13433
    },
    {
      "epoch": 0.7968916834737216,
      "grad_norm": 32.22215270996094,
      "learning_rate": 4.513577643026628e-06,
      "loss": 0.3791,
      "step": 13434
    },
    {
      "epoch": 0.7969510024913987,
      "grad_norm": 21.426660537719727,
      "learning_rate": 4.512259425257053e-06,
      "loss": 0.2007,
      "step": 13435
    },
    {
      "epoch": 0.7970103215090758,
      "grad_norm": 0.054129380732774734,
      "learning_rate": 4.510941207487477e-06,
      "loss": 0.001,
      "step": 13436
    },
    {
      "epoch": 0.7970696405267529,
      "grad_norm": 10.099472045898438,
      "learning_rate": 4.509622989717901e-06,
      "loss": 0.1248,
      "step": 13437
    },
    {
      "epoch": 0.79712895954443,
      "grad_norm": 29.528060913085938,
      "learning_rate": 4.508304771948326e-06,
      "loss": 2.0526,
      "step": 13438
    },
    {
      "epoch": 0.7971882785621071,
      "grad_norm": 4.9052581787109375,
      "learning_rate": 4.5069865541787506e-06,
      "loss": 0.0349,
      "step": 13439
    },
    {
      "epoch": 0.797247597579784,
      "grad_norm": 0.17519189417362213,
      "learning_rate": 4.505668336409176e-06,
      "loss": 0.0017,
      "step": 13440
    },
    {
      "epoch": 0.7973069165974611,
      "grad_norm": 7.990437030792236,
      "learning_rate": 4.5043501186396e-06,
      "loss": 0.3238,
      "step": 13441
    },
    {
      "epoch": 0.7973662356151382,
      "grad_norm": 7.119030475616455,
      "learning_rate": 4.503031900870024e-06,
      "loss": 0.6176,
      "step": 13442
    },
    {
      "epoch": 0.7974255546328153,
      "grad_norm": 0.1283807009458542,
      "learning_rate": 4.501713683100449e-06,
      "loss": 0.0019,
      "step": 13443
    },
    {
      "epoch": 0.7974848736504924,
      "grad_norm": 10.606036186218262,
      "learning_rate": 4.500395465330873e-06,
      "loss": 0.3479,
      "step": 13444
    },
    {
      "epoch": 0.7975441926681694,
      "grad_norm": 0.10314404964447021,
      "learning_rate": 4.499077247561297e-06,
      "loss": 0.0018,
      "step": 13445
    },
    {
      "epoch": 0.7976035116858465,
      "grad_norm": 0.19807761907577515,
      "learning_rate": 4.4977590297917216e-06,
      "loss": 0.0035,
      "step": 13446
    },
    {
      "epoch": 0.7976628307035235,
      "grad_norm": 3.061927556991577,
      "learning_rate": 4.496440812022147e-06,
      "loss": 0.0282,
      "step": 13447
    },
    {
      "epoch": 0.7977221497212006,
      "grad_norm": 4.21147346496582,
      "learning_rate": 4.495122594252571e-06,
      "loss": 0.0504,
      "step": 13448
    },
    {
      "epoch": 0.7977814687388777,
      "grad_norm": 3.7338039875030518,
      "learning_rate": 4.493804376482995e-06,
      "loss": 0.0644,
      "step": 13449
    },
    {
      "epoch": 0.7978407877565548,
      "grad_norm": 4.933078765869141,
      "learning_rate": 4.49248615871342e-06,
      "loss": 0.122,
      "step": 13450
    },
    {
      "epoch": 0.7979001067742318,
      "grad_norm": 3.4345531463623047,
      "learning_rate": 4.491167940943844e-06,
      "loss": 0.2399,
      "step": 13451
    },
    {
      "epoch": 0.7979594257919089,
      "grad_norm": 0.020017264410853386,
      "learning_rate": 4.489849723174269e-06,
      "loss": 0.0005,
      "step": 13452
    },
    {
      "epoch": 0.7980187448095859,
      "grad_norm": 5.610452175140381,
      "learning_rate": 4.4885315054046926e-06,
      "loss": 0.4614,
      "step": 13453
    },
    {
      "epoch": 0.798078063827263,
      "grad_norm": 0.023851795122027397,
      "learning_rate": 4.487213287635118e-06,
      "loss": 0.0005,
      "step": 13454
    },
    {
      "epoch": 0.7981373828449401,
      "grad_norm": 4.731962203979492,
      "learning_rate": 4.485895069865543e-06,
      "loss": 0.0386,
      "step": 13455
    },
    {
      "epoch": 0.7981967018626172,
      "grad_norm": 0.01225120760500431,
      "learning_rate": 4.484576852095967e-06,
      "loss": 0.0003,
      "step": 13456
    },
    {
      "epoch": 0.7982560208802942,
      "grad_norm": 4.594817161560059,
      "learning_rate": 4.483258634326391e-06,
      "loss": 0.175,
      "step": 13457
    },
    {
      "epoch": 0.7983153398979713,
      "grad_norm": 1.734031081199646,
      "learning_rate": 4.481940416556815e-06,
      "loss": 0.0171,
      "step": 13458
    },
    {
      "epoch": 0.7983746589156484,
      "grad_norm": 4.796187400817871,
      "learning_rate": 4.48062219878724e-06,
      "loss": 0.0292,
      "step": 13459
    },
    {
      "epoch": 0.7984339779333254,
      "grad_norm": 5.631191253662109,
      "learning_rate": 4.4793039810176644e-06,
      "loss": 0.0381,
      "step": 13460
    },
    {
      "epoch": 0.7984932969510025,
      "grad_norm": 4.467848300933838,
      "learning_rate": 4.477985763248089e-06,
      "loss": 0.0165,
      "step": 13461
    },
    {
      "epoch": 0.7985526159686795,
      "grad_norm": 0.9869508743286133,
      "learning_rate": 4.476667545478514e-06,
      "loss": 0.019,
      "step": 13462
    },
    {
      "epoch": 0.7986119349863566,
      "grad_norm": 12.769759178161621,
      "learning_rate": 4.475349327708938e-06,
      "loss": 0.4382,
      "step": 13463
    },
    {
      "epoch": 0.7986712540040337,
      "grad_norm": 0.025442814454436302,
      "learning_rate": 4.474031109939362e-06,
      "loss": 0.001,
      "step": 13464
    },
    {
      "epoch": 0.7987305730217108,
      "grad_norm": 0.5346310138702393,
      "learning_rate": 4.472712892169786e-06,
      "loss": 0.0042,
      "step": 13465
    },
    {
      "epoch": 0.7987898920393879,
      "grad_norm": 5.38534688949585,
      "learning_rate": 4.471394674400211e-06,
      "loss": 0.0729,
      "step": 13466
    },
    {
      "epoch": 0.7988492110570649,
      "grad_norm": 1.8943815231323242,
      "learning_rate": 4.470076456630636e-06,
      "loss": 0.0254,
      "step": 13467
    },
    {
      "epoch": 0.7989085300747419,
      "grad_norm": 1.0257999897003174,
      "learning_rate": 4.4687582388610605e-06,
      "loss": 0.0095,
      "step": 13468
    },
    {
      "epoch": 0.798967849092419,
      "grad_norm": 1.5376522541046143,
      "learning_rate": 4.467440021091485e-06,
      "loss": 0.0131,
      "step": 13469
    },
    {
      "epoch": 0.7990271681100961,
      "grad_norm": 0.05179552361369133,
      "learning_rate": 4.466121803321909e-06,
      "loss": 0.0011,
      "step": 13470
    },
    {
      "epoch": 0.7990864871277732,
      "grad_norm": 0.0707351490855217,
      "learning_rate": 4.464803585552334e-06,
      "loss": 0.0014,
      "step": 13471
    },
    {
      "epoch": 0.7991458061454503,
      "grad_norm": 12.007548332214355,
      "learning_rate": 4.463485367782758e-06,
      "loss": 0.4102,
      "step": 13472
    },
    {
      "epoch": 0.7992051251631273,
      "grad_norm": 0.25342458486557007,
      "learning_rate": 4.462167150013182e-06,
      "loss": 0.0032,
      "step": 13473
    },
    {
      "epoch": 0.7992644441808043,
      "grad_norm": 0.010863319039344788,
      "learning_rate": 4.460848932243607e-06,
      "loss": 0.0003,
      "step": 13474
    },
    {
      "epoch": 0.7993237631984814,
      "grad_norm": 0.4544790983200073,
      "learning_rate": 4.4595307144740315e-06,
      "loss": 0.006,
      "step": 13475
    },
    {
      "epoch": 0.7993830822161585,
      "grad_norm": 53.07091522216797,
      "learning_rate": 4.458212496704456e-06,
      "loss": 0.1283,
      "step": 13476
    },
    {
      "epoch": 0.7994424012338356,
      "grad_norm": 0.11652575433254242,
      "learning_rate": 4.45689427893488e-06,
      "loss": 0.0013,
      "step": 13477
    },
    {
      "epoch": 0.7995017202515127,
      "grad_norm": 3.7980852127075195,
      "learning_rate": 4.455576061165305e-06,
      "loss": 0.2128,
      "step": 13478
    },
    {
      "epoch": 0.7995610392691898,
      "grad_norm": 0.6855970621109009,
      "learning_rate": 4.45425784339573e-06,
      "loss": 0.0042,
      "step": 13479
    },
    {
      "epoch": 0.7996203582868667,
      "grad_norm": 9.192630767822266,
      "learning_rate": 4.452939625626153e-06,
      "loss": 0.372,
      "step": 13480
    },
    {
      "epoch": 0.7996796773045438,
      "grad_norm": 2.0604090690612793,
      "learning_rate": 4.451621407856578e-06,
      "loss": 0.0313,
      "step": 13481
    },
    {
      "epoch": 0.7997389963222209,
      "grad_norm": 0.017481358721852303,
      "learning_rate": 4.4503031900870025e-06,
      "loss": 0.0005,
      "step": 13482
    },
    {
      "epoch": 0.799798315339898,
      "grad_norm": 0.20133180916309357,
      "learning_rate": 4.4489849723174275e-06,
      "loss": 0.0027,
      "step": 13483
    },
    {
      "epoch": 0.7998576343575751,
      "grad_norm": 0.0037228104192763567,
      "learning_rate": 4.447666754547852e-06,
      "loss": 0.0001,
      "step": 13484
    },
    {
      "epoch": 0.7999169533752521,
      "grad_norm": 0.08992276340723038,
      "learning_rate": 4.446348536778276e-06,
      "loss": 0.0019,
      "step": 13485
    },
    {
      "epoch": 0.7999762723929291,
      "grad_norm": 3.601562261581421,
      "learning_rate": 4.445030319008701e-06,
      "loss": 0.0323,
      "step": 13486
    },
    {
      "epoch": 0.8000355914106062,
      "grad_norm": 0.42857125401496887,
      "learning_rate": 4.443712101239125e-06,
      "loss": 0.0066,
      "step": 13487
    },
    {
      "epoch": 0.8000949104282833,
      "grad_norm": 7.0733442306518555,
      "learning_rate": 4.442393883469549e-06,
      "loss": 0.2344,
      "step": 13488
    },
    {
      "epoch": 0.8001542294459604,
      "grad_norm": 6.125574111938477,
      "learning_rate": 4.4410756656999735e-06,
      "loss": 0.1232,
      "step": 13489
    },
    {
      "epoch": 0.8002135484636375,
      "grad_norm": 3.5933988094329834,
      "learning_rate": 4.4397574479303985e-06,
      "loss": 0.0743,
      "step": 13490
    },
    {
      "epoch": 0.8002728674813145,
      "grad_norm": 4.1228437423706055,
      "learning_rate": 4.4384392301608235e-06,
      "loss": 0.1655,
      "step": 13491
    },
    {
      "epoch": 0.8003321864989916,
      "grad_norm": 0.0022919937036931515,
      "learning_rate": 4.437121012391247e-06,
      "loss": 0.0001,
      "step": 13492
    },
    {
      "epoch": 0.8003915055166686,
      "grad_norm": 34.99720764160156,
      "learning_rate": 4.435802794621672e-06,
      "loss": 0.3739,
      "step": 13493
    },
    {
      "epoch": 0.8004508245343457,
      "grad_norm": 0.4361346662044525,
      "learning_rate": 4.434484576852096e-06,
      "loss": 0.0032,
      "step": 13494
    },
    {
      "epoch": 0.8005101435520228,
      "grad_norm": 20.536479949951172,
      "learning_rate": 4.433166359082521e-06,
      "loss": 0.9907,
      "step": 13495
    },
    {
      "epoch": 0.8005694625696999,
      "grad_norm": 31.4489688873291,
      "learning_rate": 4.431848141312945e-06,
      "loss": 0.8436,
      "step": 13496
    },
    {
      "epoch": 0.8006287815873769,
      "grad_norm": 0.02568242698907852,
      "learning_rate": 4.4305299235433695e-06,
      "loss": 0.0005,
      "step": 13497
    },
    {
      "epoch": 0.800688100605054,
      "grad_norm": 13.372027397155762,
      "learning_rate": 4.4292117057737945e-06,
      "loss": 0.2181,
      "step": 13498
    },
    {
      "epoch": 0.800747419622731,
      "grad_norm": 3.267876148223877,
      "learning_rate": 4.427893488004219e-06,
      "loss": 0.0553,
      "step": 13499
    },
    {
      "epoch": 0.8008067386404081,
      "grad_norm": 0.11382152885198593,
      "learning_rate": 4.426575270234643e-06,
      "loss": 0.0021,
      "step": 13500
    },
    {
      "epoch": 0.8008660576580852,
      "grad_norm": 0.5501272678375244,
      "learning_rate": 4.425257052465067e-06,
      "loss": 0.0038,
      "step": 13501
    },
    {
      "epoch": 0.8009253766757622,
      "grad_norm": 3.1166484355926514,
      "learning_rate": 4.423938834695492e-06,
      "loss": 0.0902,
      "step": 13502
    },
    {
      "epoch": 0.8009846956934393,
      "grad_norm": 43.12051010131836,
      "learning_rate": 4.422620616925916e-06,
      "loss": 0.9306,
      "step": 13503
    },
    {
      "epoch": 0.8010440147111164,
      "grad_norm": 0.08874271810054779,
      "learning_rate": 4.4213023991563405e-06,
      "loss": 0.001,
      "step": 13504
    },
    {
      "epoch": 0.8011033337287935,
      "grad_norm": 13.196586608886719,
      "learning_rate": 4.4199841813867656e-06,
      "loss": 0.6347,
      "step": 13505
    },
    {
      "epoch": 0.8011626527464705,
      "grad_norm": 2.4428489208221436,
      "learning_rate": 4.41866596361719e-06,
      "loss": 0.0181,
      "step": 13506
    },
    {
      "epoch": 0.8012219717641476,
      "grad_norm": 0.6451575756072998,
      "learning_rate": 4.417347745847615e-06,
      "loss": 0.0102,
      "step": 13507
    },
    {
      "epoch": 0.8012812907818246,
      "grad_norm": 0.45567670464515686,
      "learning_rate": 4.416029528078039e-06,
      "loss": 0.0063,
      "step": 13508
    },
    {
      "epoch": 0.8013406097995017,
      "grad_norm": 8.858412742614746,
      "learning_rate": 4.414711310308463e-06,
      "loss": 0.0862,
      "step": 13509
    },
    {
      "epoch": 0.8013999288171788,
      "grad_norm": 0.026012767106294632,
      "learning_rate": 4.413393092538888e-06,
      "loss": 0.0007,
      "step": 13510
    },
    {
      "epoch": 0.8014592478348559,
      "grad_norm": 8.829066276550293,
      "learning_rate": 4.412074874769312e-06,
      "loss": 0.1889,
      "step": 13511
    },
    {
      "epoch": 0.801518566852533,
      "grad_norm": 19.288467407226562,
      "learning_rate": 4.4107566569997366e-06,
      "loss": 0.4037,
      "step": 13512
    },
    {
      "epoch": 0.80157788587021,
      "grad_norm": 0.18041376769542694,
      "learning_rate": 4.409438439230162e-06,
      "loss": 0.0035,
      "step": 13513
    },
    {
      "epoch": 0.801637204887887,
      "grad_norm": 1.1730637550354004,
      "learning_rate": 4.408120221460586e-06,
      "loss": 0.0046,
      "step": 13514
    },
    {
      "epoch": 0.8016965239055641,
      "grad_norm": 8.07865047454834,
      "learning_rate": 4.40680200369101e-06,
      "loss": 0.0571,
      "step": 13515
    },
    {
      "epoch": 0.8017558429232412,
      "grad_norm": 44.92860794067383,
      "learning_rate": 4.405483785921434e-06,
      "loss": 0.6344,
      "step": 13516
    },
    {
      "epoch": 0.8018151619409183,
      "grad_norm": 0.25060051679611206,
      "learning_rate": 4.404165568151859e-06,
      "loss": 0.0029,
      "step": 13517
    },
    {
      "epoch": 0.8018744809585954,
      "grad_norm": 5.334517955780029,
      "learning_rate": 4.402847350382283e-06,
      "loss": 0.0881,
      "step": 13518
    },
    {
      "epoch": 0.8019337999762723,
      "grad_norm": 6.081244945526123,
      "learning_rate": 4.4015291326127076e-06,
      "loss": 0.364,
      "step": 13519
    },
    {
      "epoch": 0.8019931189939494,
      "grad_norm": 8.667153358459473,
      "learning_rate": 4.400210914843133e-06,
      "loss": 0.591,
      "step": 13520
    },
    {
      "epoch": 0.8020524380116265,
      "grad_norm": 14.024911880493164,
      "learning_rate": 4.398892697073557e-06,
      "loss": 0.2234,
      "step": 13521
    },
    {
      "epoch": 0.8021117570293036,
      "grad_norm": 0.09528538584709167,
      "learning_rate": 4.397574479303982e-06,
      "loss": 0.0011,
      "step": 13522
    },
    {
      "epoch": 0.8021710760469807,
      "grad_norm": 0.19152617454528809,
      "learning_rate": 4.396256261534406e-06,
      "loss": 0.0015,
      "step": 13523
    },
    {
      "epoch": 0.8022303950646578,
      "grad_norm": 12.3695650100708,
      "learning_rate": 4.39493804376483e-06,
      "loss": 0.2666,
      "step": 13524
    },
    {
      "epoch": 0.8022897140823348,
      "grad_norm": 6.77180814743042,
      "learning_rate": 4.393619825995255e-06,
      "loss": 0.1968,
      "step": 13525
    },
    {
      "epoch": 0.8023490331000118,
      "grad_norm": 5.836320400238037,
      "learning_rate": 4.392301608225679e-06,
      "loss": 0.2112,
      "step": 13526
    },
    {
      "epoch": 0.8024083521176889,
      "grad_norm": 0.388926237821579,
      "learning_rate": 4.390983390456104e-06,
      "loss": 0.0041,
      "step": 13527
    },
    {
      "epoch": 0.802467671135366,
      "grad_norm": 0.04109089449048042,
      "learning_rate": 4.389665172686528e-06,
      "loss": 0.0007,
      "step": 13528
    },
    {
      "epoch": 0.8025269901530431,
      "grad_norm": 1.7612048387527466,
      "learning_rate": 4.388346954916953e-06,
      "loss": 0.0119,
      "step": 13529
    },
    {
      "epoch": 0.8025863091707202,
      "grad_norm": 0.07280416786670685,
      "learning_rate": 4.387028737147377e-06,
      "loss": 0.0013,
      "step": 13530
    },
    {
      "epoch": 0.8026456281883972,
      "grad_norm": 0.020885871723294258,
      "learning_rate": 4.385710519377801e-06,
      "loss": 0.0003,
      "step": 13531
    },
    {
      "epoch": 0.8027049472060742,
      "grad_norm": 5.94315767288208,
      "learning_rate": 4.384392301608226e-06,
      "loss": 0.4655,
      "step": 13532
    },
    {
      "epoch": 0.8027642662237513,
      "grad_norm": 7.358355522155762,
      "learning_rate": 4.38307408383865e-06,
      "loss": 0.8926,
      "step": 13533
    },
    {
      "epoch": 0.8028235852414284,
      "grad_norm": 2.9446351528167725,
      "learning_rate": 4.3817558660690754e-06,
      "loss": 0.0208,
      "step": 13534
    },
    {
      "epoch": 0.8028829042591055,
      "grad_norm": 2.6398253440856934,
      "learning_rate": 4.3804376482995e-06,
      "loss": 0.0191,
      "step": 13535
    },
    {
      "epoch": 0.8029422232767826,
      "grad_norm": 5.065769672393799,
      "learning_rate": 4.379119430529924e-06,
      "loss": 0.2912,
      "step": 13536
    },
    {
      "epoch": 0.8030015422944596,
      "grad_norm": 0.010098550468683243,
      "learning_rate": 4.377801212760349e-06,
      "loss": 0.0003,
      "step": 13537
    },
    {
      "epoch": 0.8030608613121367,
      "grad_norm": 0.3461742103099823,
      "learning_rate": 4.376482994990773e-06,
      "loss": 0.0031,
      "step": 13538
    },
    {
      "epoch": 0.8031201803298137,
      "grad_norm": 36.779964447021484,
      "learning_rate": 4.375164777221197e-06,
      "loss": 0.3686,
      "step": 13539
    },
    {
      "epoch": 0.8031794993474908,
      "grad_norm": 4.943841457366943,
      "learning_rate": 4.373846559451621e-06,
      "loss": 0.0239,
      "step": 13540
    },
    {
      "epoch": 0.8032388183651679,
      "grad_norm": 0.08959348499774933,
      "learning_rate": 4.3725283416820464e-06,
      "loss": 0.0011,
      "step": 13541
    },
    {
      "epoch": 0.803298137382845,
      "grad_norm": 0.6081450581550598,
      "learning_rate": 4.371210123912471e-06,
      "loss": 0.0099,
      "step": 13542
    },
    {
      "epoch": 0.803357456400522,
      "grad_norm": 0.05142650008201599,
      "learning_rate": 4.369891906142895e-06,
      "loss": 0.0008,
      "step": 13543
    },
    {
      "epoch": 0.8034167754181991,
      "grad_norm": 0.12492580711841583,
      "learning_rate": 4.36857368837332e-06,
      "loss": 0.0011,
      "step": 13544
    },
    {
      "epoch": 0.8034760944358761,
      "grad_norm": 0.06391817331314087,
      "learning_rate": 4.367255470603744e-06,
      "loss": 0.0009,
      "step": 13545
    },
    {
      "epoch": 0.8035354134535532,
      "grad_norm": 0.09280764311552048,
      "learning_rate": 4.365937252834169e-06,
      "loss": 0.0009,
      "step": 13546
    },
    {
      "epoch": 0.8035947324712303,
      "grad_norm": 4.560743808746338,
      "learning_rate": 4.364619035064592e-06,
      "loss": 0.0284,
      "step": 13547
    },
    {
      "epoch": 0.8036540514889073,
      "grad_norm": 1.05919349193573,
      "learning_rate": 4.3633008172950175e-06,
      "loss": 0.0138,
      "step": 13548
    },
    {
      "epoch": 0.8037133705065844,
      "grad_norm": 0.09372136741876602,
      "learning_rate": 4.3619825995254425e-06,
      "loss": 0.0011,
      "step": 13549
    },
    {
      "epoch": 0.8037726895242615,
      "grad_norm": 0.2668202519416809,
      "learning_rate": 4.360664381755867e-06,
      "loss": 0.0042,
      "step": 13550
    },
    {
      "epoch": 0.8038320085419386,
      "grad_norm": 0.14965637028217316,
      "learning_rate": 4.359346163986291e-06,
      "loss": 0.0026,
      "step": 13551
    },
    {
      "epoch": 0.8038913275596156,
      "grad_norm": 0.23985004425048828,
      "learning_rate": 4.358027946216715e-06,
      "loss": 0.0032,
      "step": 13552
    },
    {
      "epoch": 0.8039506465772926,
      "grad_norm": 0.012825938872992992,
      "learning_rate": 4.35670972844714e-06,
      "loss": 0.0004,
      "step": 13553
    },
    {
      "epoch": 0.8040099655949697,
      "grad_norm": 4.235353946685791,
      "learning_rate": 4.355391510677564e-06,
      "loss": 0.0125,
      "step": 13554
    },
    {
      "epoch": 0.8040692846126468,
      "grad_norm": 0.006592517253011465,
      "learning_rate": 4.3540732929079885e-06,
      "loss": 0.0002,
      "step": 13555
    },
    {
      "epoch": 0.8041286036303239,
      "grad_norm": 0.0665692687034607,
      "learning_rate": 4.3527550751384135e-06,
      "loss": 0.0013,
      "step": 13556
    },
    {
      "epoch": 0.804187922648001,
      "grad_norm": 12.2164306640625,
      "learning_rate": 4.351436857368838e-06,
      "loss": 0.1972,
      "step": 13557
    },
    {
      "epoch": 0.8042472416656781,
      "grad_norm": 0.032898373901844025,
      "learning_rate": 4.350118639599262e-06,
      "loss": 0.0005,
      "step": 13558
    },
    {
      "epoch": 0.804306560683355,
      "grad_norm": 15.955070495605469,
      "learning_rate": 4.348800421829686e-06,
      "loss": 0.1134,
      "step": 13559
    },
    {
      "epoch": 0.8043658797010321,
      "grad_norm": 0.04405354708433151,
      "learning_rate": 4.347482204060111e-06,
      "loss": 0.0007,
      "step": 13560
    },
    {
      "epoch": 0.8044251987187092,
      "grad_norm": 2.223067045211792,
      "learning_rate": 4.346163986290536e-06,
      "loss": 0.0105,
      "step": 13561
    },
    {
      "epoch": 0.8044845177363863,
      "grad_norm": 0.009522170759737492,
      "learning_rate": 4.34484576852096e-06,
      "loss": 0.0002,
      "step": 13562
    },
    {
      "epoch": 0.8045438367540634,
      "grad_norm": 5.177483081817627,
      "learning_rate": 4.3435275507513845e-06,
      "loss": 0.0476,
      "step": 13563
    },
    {
      "epoch": 0.8046031557717405,
      "grad_norm": 0.023318566381931305,
      "learning_rate": 4.342209332981809e-06,
      "loss": 0.0005,
      "step": 13564
    },
    {
      "epoch": 0.8046624747894174,
      "grad_norm": 0.7994014024734497,
      "learning_rate": 4.340891115212234e-06,
      "loss": 0.011,
      "step": 13565
    },
    {
      "epoch": 0.8047217938070945,
      "grad_norm": 0.08356714993715286,
      "learning_rate": 4.339572897442658e-06,
      "loss": 0.0012,
      "step": 13566
    },
    {
      "epoch": 0.8047811128247716,
      "grad_norm": 0.6748165488243103,
      "learning_rate": 4.338254679673082e-06,
      "loss": 0.0071,
      "step": 13567
    },
    {
      "epoch": 0.8048404318424487,
      "grad_norm": 0.30863744020462036,
      "learning_rate": 4.336936461903507e-06,
      "loss": 0.0021,
      "step": 13568
    },
    {
      "epoch": 0.8048997508601258,
      "grad_norm": 9.041362762451172,
      "learning_rate": 4.335618244133931e-06,
      "loss": 0.7085,
      "step": 13569
    },
    {
      "epoch": 0.8049590698778029,
      "grad_norm": 6.264712333679199,
      "learning_rate": 4.3343000263643555e-06,
      "loss": 0.0491,
      "step": 13570
    },
    {
      "epoch": 0.8050183888954799,
      "grad_norm": 2.7447619438171387,
      "learning_rate": 4.33298180859478e-06,
      "loss": 0.0292,
      "step": 13571
    },
    {
      "epoch": 0.8050777079131569,
      "grad_norm": 2.9303579330444336,
      "learning_rate": 4.331663590825205e-06,
      "loss": 0.0277,
      "step": 13572
    },
    {
      "epoch": 0.805137026930834,
      "grad_norm": 5.377836227416992,
      "learning_rate": 4.33034537305563e-06,
      "loss": 0.0309,
      "step": 13573
    },
    {
      "epoch": 0.8051963459485111,
      "grad_norm": 0.009179455228149891,
      "learning_rate": 4.329027155286054e-06,
      "loss": 0.0003,
      "step": 13574
    },
    {
      "epoch": 0.8052556649661882,
      "grad_norm": 0.4682086408138275,
      "learning_rate": 4.327708937516478e-06,
      "loss": 0.005,
      "step": 13575
    },
    {
      "epoch": 0.8053149839838653,
      "grad_norm": 6.589929580688477,
      "learning_rate": 4.326390719746902e-06,
      "loss": 0.0709,
      "step": 13576
    },
    {
      "epoch": 0.8053743030015423,
      "grad_norm": 11.627364158630371,
      "learning_rate": 4.325072501977327e-06,
      "loss": 0.504,
      "step": 13577
    },
    {
      "epoch": 0.8054336220192193,
      "grad_norm": 1.2382667064666748,
      "learning_rate": 4.3237542842077515e-06,
      "loss": 0.0138,
      "step": 13578
    },
    {
      "epoch": 0.8054929410368964,
      "grad_norm": 12.615960121154785,
      "learning_rate": 4.322436066438176e-06,
      "loss": 0.283,
      "step": 13579
    },
    {
      "epoch": 0.8055522600545735,
      "grad_norm": 3.641195774078369,
      "learning_rate": 4.321117848668601e-06,
      "loss": 0.188,
      "step": 13580
    },
    {
      "epoch": 0.8056115790722506,
      "grad_norm": 0.044662948697805405,
      "learning_rate": 4.319799630899025e-06,
      "loss": 0.0006,
      "step": 13581
    },
    {
      "epoch": 0.8056708980899276,
      "grad_norm": 0.08082681894302368,
      "learning_rate": 4.318481413129449e-06,
      "loss": 0.0011,
      "step": 13582
    },
    {
      "epoch": 0.8057302171076047,
      "grad_norm": 3.1491122245788574,
      "learning_rate": 4.317163195359873e-06,
      "loss": 0.074,
      "step": 13583
    },
    {
      "epoch": 0.8057895361252818,
      "grad_norm": 1.0789284706115723,
      "learning_rate": 4.315844977590298e-06,
      "loss": 0.0124,
      "step": 13584
    },
    {
      "epoch": 0.8058488551429588,
      "grad_norm": 3.8074395656585693,
      "learning_rate": 4.314526759820723e-06,
      "loss": 0.1283,
      "step": 13585
    },
    {
      "epoch": 0.8059081741606359,
      "grad_norm": 25.412649154663086,
      "learning_rate": 4.313208542051147e-06,
      "loss": 1.3155,
      "step": 13586
    },
    {
      "epoch": 0.805967493178313,
      "grad_norm": 0.18727093935012817,
      "learning_rate": 4.311890324281572e-06,
      "loss": 0.0009,
      "step": 13587
    },
    {
      "epoch": 0.80602681219599,
      "grad_norm": 20.969362258911133,
      "learning_rate": 4.310572106511996e-06,
      "loss": 0.1361,
      "step": 13588
    },
    {
      "epoch": 0.8060861312136671,
      "grad_norm": 3.8172287940979004,
      "learning_rate": 4.309253888742421e-06,
      "loss": 0.0198,
      "step": 13589
    },
    {
      "epoch": 0.8061454502313442,
      "grad_norm": 10.69470500946045,
      "learning_rate": 4.307935670972845e-06,
      "loss": 0.3301,
      "step": 13590
    },
    {
      "epoch": 0.8062047692490213,
      "grad_norm": 14.187833786010742,
      "learning_rate": 4.306617453203269e-06,
      "loss": 0.433,
      "step": 13591
    },
    {
      "epoch": 0.8062640882666983,
      "grad_norm": 2.2029082775115967,
      "learning_rate": 4.305299235433694e-06,
      "loss": 0.0099,
      "step": 13592
    },
    {
      "epoch": 0.8063234072843753,
      "grad_norm": 0.009789533913135529,
      "learning_rate": 4.303981017664119e-06,
      "loss": 0.0002,
      "step": 13593
    },
    {
      "epoch": 0.8063827263020524,
      "grad_norm": 4.753535747528076,
      "learning_rate": 4.302662799894543e-06,
      "loss": 0.1692,
      "step": 13594
    },
    {
      "epoch": 0.8064420453197295,
      "grad_norm": 0.6408176422119141,
      "learning_rate": 4.301344582124967e-06,
      "loss": 0.0033,
      "step": 13595
    },
    {
      "epoch": 0.8065013643374066,
      "grad_norm": 8.728535652160645,
      "learning_rate": 4.300026364355392e-06,
      "loss": 0.1926,
      "step": 13596
    },
    {
      "epoch": 0.8065606833550837,
      "grad_norm": 26.165355682373047,
      "learning_rate": 4.298708146585816e-06,
      "loss": 0.8203,
      "step": 13597
    },
    {
      "epoch": 0.8066200023727607,
      "grad_norm": 0.10542309284210205,
      "learning_rate": 4.29738992881624e-06,
      "loss": 0.0014,
      "step": 13598
    },
    {
      "epoch": 0.8066793213904377,
      "grad_norm": 4.329257965087891,
      "learning_rate": 4.296071711046665e-06,
      "loss": 0.0697,
      "step": 13599
    },
    {
      "epoch": 0.8067386404081148,
      "grad_norm": 0.01168014481663704,
      "learning_rate": 4.29475349327709e-06,
      "loss": 0.0004,
      "step": 13600
    },
    {
      "epoch": 0.8067979594257919,
      "grad_norm": 0.05562012642621994,
      "learning_rate": 4.293435275507515e-06,
      "loss": 0.0008,
      "step": 13601
    },
    {
      "epoch": 0.806857278443469,
      "grad_norm": 1.4488139152526855,
      "learning_rate": 4.292117057737939e-06,
      "loss": 0.0157,
      "step": 13602
    },
    {
      "epoch": 0.8069165974611461,
      "grad_norm": 3.8152246475219727,
      "learning_rate": 4.290798839968363e-06,
      "loss": 0.0247,
      "step": 13603
    },
    {
      "epoch": 0.8069759164788232,
      "grad_norm": 0.2798043191432953,
      "learning_rate": 4.289480622198788e-06,
      "loss": 0.0036,
      "step": 13604
    },
    {
      "epoch": 0.8070352354965001,
      "grad_norm": 0.20815987884998322,
      "learning_rate": 4.288162404429212e-06,
      "loss": 0.003,
      "step": 13605
    },
    {
      "epoch": 0.8070945545141772,
      "grad_norm": 0.020300431177020073,
      "learning_rate": 4.286844186659636e-06,
      "loss": 0.0005,
      "step": 13606
    },
    {
      "epoch": 0.8071538735318543,
      "grad_norm": 0.013164938427507877,
      "learning_rate": 4.285525968890061e-06,
      "loss": 0.0003,
      "step": 13607
    },
    {
      "epoch": 0.8072131925495314,
      "grad_norm": 0.3336709439754486,
      "learning_rate": 4.284207751120486e-06,
      "loss": 0.0016,
      "step": 13608
    },
    {
      "epoch": 0.8072725115672085,
      "grad_norm": 0.01342358160763979,
      "learning_rate": 4.28288953335091e-06,
      "loss": 0.0004,
      "step": 13609
    },
    {
      "epoch": 0.8073318305848856,
      "grad_norm": 2.3069639205932617,
      "learning_rate": 4.281571315581334e-06,
      "loss": 0.0796,
      "step": 13610
    },
    {
      "epoch": 0.8073911496025625,
      "grad_norm": 18.659637451171875,
      "learning_rate": 4.280253097811759e-06,
      "loss": 0.528,
      "step": 13611
    },
    {
      "epoch": 0.8074504686202396,
      "grad_norm": 0.046603549271821976,
      "learning_rate": 4.278934880042183e-06,
      "loss": 0.001,
      "step": 13612
    },
    {
      "epoch": 0.8075097876379167,
      "grad_norm": 0.17259785532951355,
      "learning_rate": 4.277616662272608e-06,
      "loss": 0.0025,
      "step": 13613
    },
    {
      "epoch": 0.8075691066555938,
      "grad_norm": 13.850115776062012,
      "learning_rate": 4.276298444503032e-06,
      "loss": 0.2467,
      "step": 13614
    },
    {
      "epoch": 0.8076284256732709,
      "grad_norm": 6.5793843269348145,
      "learning_rate": 4.274980226733457e-06,
      "loss": 0.1931,
      "step": 13615
    },
    {
      "epoch": 0.807687744690948,
      "grad_norm": 0.5953592658042908,
      "learning_rate": 4.273662008963882e-06,
      "loss": 0.0058,
      "step": 13616
    },
    {
      "epoch": 0.807747063708625,
      "grad_norm": 11.808969497680664,
      "learning_rate": 4.272343791194306e-06,
      "loss": 0.6197,
      "step": 13617
    },
    {
      "epoch": 0.807806382726302,
      "grad_norm": 1.384498953819275,
      "learning_rate": 4.27102557342473e-06,
      "loss": 0.0078,
      "step": 13618
    },
    {
      "epoch": 0.8078657017439791,
      "grad_norm": 0.024274678900837898,
      "learning_rate": 4.269707355655154e-06,
      "loss": 0.0006,
      "step": 13619
    },
    {
      "epoch": 0.8079250207616562,
      "grad_norm": 0.020491713657975197,
      "learning_rate": 4.268389137885579e-06,
      "loss": 0.0008,
      "step": 13620
    },
    {
      "epoch": 0.8079843397793333,
      "grad_norm": 0.8036624193191528,
      "learning_rate": 4.2670709201160034e-06,
      "loss": 0.0138,
      "step": 13621
    },
    {
      "epoch": 0.8080436587970103,
      "grad_norm": 1.2542717456817627,
      "learning_rate": 4.265752702346428e-06,
      "loss": 0.0179,
      "step": 13622
    },
    {
      "epoch": 0.8081029778146874,
      "grad_norm": 48.08469772338867,
      "learning_rate": 4.264434484576853e-06,
      "loss": 2.4449,
      "step": 13623
    },
    {
      "epoch": 0.8081622968323644,
      "grad_norm": 0.055833298712968826,
      "learning_rate": 4.263116266807277e-06,
      "loss": 0.0009,
      "step": 13624
    },
    {
      "epoch": 0.8082216158500415,
      "grad_norm": 6.337496757507324,
      "learning_rate": 4.261798049037701e-06,
      "loss": 0.0449,
      "step": 13625
    },
    {
      "epoch": 0.8082809348677186,
      "grad_norm": 3.4931559562683105,
      "learning_rate": 4.260479831268125e-06,
      "loss": 0.0147,
      "step": 13626
    },
    {
      "epoch": 0.8083402538853957,
      "grad_norm": 0.011688738130033016,
      "learning_rate": 4.25916161349855e-06,
      "loss": 0.0003,
      "step": 13627
    },
    {
      "epoch": 0.8083995729030727,
      "grad_norm": 3.865417242050171,
      "learning_rate": 4.257843395728975e-06,
      "loss": 0.0594,
      "step": 13628
    },
    {
      "epoch": 0.8084588919207498,
      "grad_norm": 0.027997057884931564,
      "learning_rate": 4.2565251779593995e-06,
      "loss": 0.0005,
      "step": 13629
    },
    {
      "epoch": 0.8085182109384269,
      "grad_norm": 10.057060241699219,
      "learning_rate": 4.255206960189824e-06,
      "loss": 0.1028,
      "step": 13630
    },
    {
      "epoch": 0.8085775299561039,
      "grad_norm": 10.309825897216797,
      "learning_rate": 4.253888742420248e-06,
      "loss": 0.9414,
      "step": 13631
    },
    {
      "epoch": 0.808636848973781,
      "grad_norm": 19.79388427734375,
      "learning_rate": 4.252570524650673e-06,
      "loss": 0.6498,
      "step": 13632
    },
    {
      "epoch": 0.808696167991458,
      "grad_norm": 41.56901931762695,
      "learning_rate": 4.251252306881097e-06,
      "loss": 0.7069,
      "step": 13633
    },
    {
      "epoch": 0.8087554870091351,
      "grad_norm": 5.871687412261963,
      "learning_rate": 4.249934089111521e-06,
      "loss": 0.045,
      "step": 13634
    },
    {
      "epoch": 0.8088148060268122,
      "grad_norm": 10.318851470947266,
      "learning_rate": 4.248615871341946e-06,
      "loss": 0.1672,
      "step": 13635
    },
    {
      "epoch": 0.8088741250444893,
      "grad_norm": 0.21552009880542755,
      "learning_rate": 4.2472976535723705e-06,
      "loss": 0.0018,
      "step": 13636
    },
    {
      "epoch": 0.8089334440621664,
      "grad_norm": 3.4336936473846436,
      "learning_rate": 4.245979435802795e-06,
      "loss": 0.0564,
      "step": 13637
    },
    {
      "epoch": 0.8089927630798434,
      "grad_norm": 0.05905231088399887,
      "learning_rate": 4.244661218033219e-06,
      "loss": 0.0012,
      "step": 13638
    },
    {
      "epoch": 0.8090520820975204,
      "grad_norm": 0.026557929813861847,
      "learning_rate": 4.243343000263644e-06,
      "loss": 0.0005,
      "step": 13639
    },
    {
      "epoch": 0.8091114011151975,
      "grad_norm": 4.6905341148376465,
      "learning_rate": 4.242024782494069e-06,
      "loss": 0.0702,
      "step": 13640
    },
    {
      "epoch": 0.8091707201328746,
      "grad_norm": 4.297919273376465,
      "learning_rate": 4.240706564724493e-06,
      "loss": 0.0472,
      "step": 13641
    },
    {
      "epoch": 0.8092300391505517,
      "grad_norm": 14.239387512207031,
      "learning_rate": 4.239388346954917e-06,
      "loss": 0.7587,
      "step": 13642
    },
    {
      "epoch": 0.8092893581682288,
      "grad_norm": 0.201671302318573,
      "learning_rate": 4.2380701291853415e-06,
      "loss": 0.0011,
      "step": 13643
    },
    {
      "epoch": 0.8093486771859058,
      "grad_norm": 18.31993865966797,
      "learning_rate": 4.2367519114157665e-06,
      "loss": 0.4386,
      "step": 13644
    },
    {
      "epoch": 0.8094079962035828,
      "grad_norm": 20.446828842163086,
      "learning_rate": 4.235433693646191e-06,
      "loss": 0.4495,
      "step": 13645
    },
    {
      "epoch": 0.8094673152212599,
      "grad_norm": 7.123793601989746,
      "learning_rate": 4.234115475876615e-06,
      "loss": 0.5332,
      "step": 13646
    },
    {
      "epoch": 0.809526634238937,
      "grad_norm": 5.199843406677246,
      "learning_rate": 4.23279725810704e-06,
      "loss": 0.4248,
      "step": 13647
    },
    {
      "epoch": 0.8095859532566141,
      "grad_norm": 0.9336678981781006,
      "learning_rate": 4.231479040337464e-06,
      "loss": 0.0178,
      "step": 13648
    },
    {
      "epoch": 0.8096452722742912,
      "grad_norm": 0.044055260717868805,
      "learning_rate": 4.230160822567888e-06,
      "loss": 0.0011,
      "step": 13649
    },
    {
      "epoch": 0.8097045912919683,
      "grad_norm": 0.022083956748247147,
      "learning_rate": 4.2288426047983125e-06,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.8097639103096452,
      "grad_norm": 9.8239107131958,
      "learning_rate": 4.2275243870287375e-06,
      "loss": 0.2481,
      "step": 13651
    },
    {
      "epoch": 0.8098232293273223,
      "grad_norm": 10.303256034851074,
      "learning_rate": 4.2262061692591626e-06,
      "loss": 0.0986,
      "step": 13652
    },
    {
      "epoch": 0.8098825483449994,
      "grad_norm": 10.649147033691406,
      "learning_rate": 4.224887951489586e-06,
      "loss": 0.2887,
      "step": 13653
    },
    {
      "epoch": 0.8099418673626765,
      "grad_norm": 2.5285751819610596,
      "learning_rate": 4.223569733720011e-06,
      "loss": 0.0359,
      "step": 13654
    },
    {
      "epoch": 0.8100011863803536,
      "grad_norm": 0.46946102380752563,
      "learning_rate": 4.222251515950435e-06,
      "loss": 0.005,
      "step": 13655
    },
    {
      "epoch": 0.8100605053980307,
      "grad_norm": 0.2998596429824829,
      "learning_rate": 4.22093329818086e-06,
      "loss": 0.0038,
      "step": 13656
    },
    {
      "epoch": 0.8101198244157076,
      "grad_norm": 2.834639310836792,
      "learning_rate": 4.219615080411284e-06,
      "loss": 0.0383,
      "step": 13657
    },
    {
      "epoch": 0.8101791434333847,
      "grad_norm": 0.015159395523369312,
      "learning_rate": 4.2182968626417085e-06,
      "loss": 0.0003,
      "step": 13658
    },
    {
      "epoch": 0.8102384624510618,
      "grad_norm": 9.242439270019531,
      "learning_rate": 4.2169786448721336e-06,
      "loss": 0.2086,
      "step": 13659
    },
    {
      "epoch": 0.8102977814687389,
      "grad_norm": 0.2678091526031494,
      "learning_rate": 4.215660427102558e-06,
      "loss": 0.0063,
      "step": 13660
    },
    {
      "epoch": 0.810357100486416,
      "grad_norm": 10.953706741333008,
      "learning_rate": 4.214342209332982e-06,
      "loss": 0.35,
      "step": 13661
    },
    {
      "epoch": 0.810416419504093,
      "grad_norm": 8.881150245666504,
      "learning_rate": 4.213023991563406e-06,
      "loss": 0.3522,
      "step": 13662
    },
    {
      "epoch": 0.8104757385217701,
      "grad_norm": 2.375835657119751,
      "learning_rate": 4.211705773793831e-06,
      "loss": 0.1023,
      "step": 13663
    },
    {
      "epoch": 0.8105350575394471,
      "grad_norm": 3.1210269927978516,
      "learning_rate": 4.210387556024255e-06,
      "loss": 0.0152,
      "step": 13664
    },
    {
      "epoch": 0.8105943765571242,
      "grad_norm": 0.021902894601225853,
      "learning_rate": 4.2090693382546795e-06,
      "loss": 0.0005,
      "step": 13665
    },
    {
      "epoch": 0.8106536955748013,
      "grad_norm": 16.360698699951172,
      "learning_rate": 4.2077511204851046e-06,
      "loss": 0.1842,
      "step": 13666
    },
    {
      "epoch": 0.8107130145924784,
      "grad_norm": 0.08243794739246368,
      "learning_rate": 4.206432902715529e-06,
      "loss": 0.001,
      "step": 13667
    },
    {
      "epoch": 0.8107723336101554,
      "grad_norm": 0.016338085755705833,
      "learning_rate": 4.205114684945954e-06,
      "loss": 0.0005,
      "step": 13668
    },
    {
      "epoch": 0.8108316526278325,
      "grad_norm": 3.6666500568389893,
      "learning_rate": 4.203796467176378e-06,
      "loss": 0.0444,
      "step": 13669
    },
    {
      "epoch": 0.8108909716455095,
      "grad_norm": 8.764700889587402,
      "learning_rate": 4.202478249406802e-06,
      "loss": 0.3462,
      "step": 13670
    },
    {
      "epoch": 0.8109502906631866,
      "grad_norm": 50.71514892578125,
      "learning_rate": 4.201160031637227e-06,
      "loss": 0.2707,
      "step": 13671
    },
    {
      "epoch": 0.8110096096808637,
      "grad_norm": 7.378398895263672,
      "learning_rate": 4.199841813867651e-06,
      "loss": 0.074,
      "step": 13672
    },
    {
      "epoch": 0.8110689286985407,
      "grad_norm": 0.02039918303489685,
      "learning_rate": 4.1985235960980756e-06,
      "loss": 0.0005,
      "step": 13673
    },
    {
      "epoch": 0.8111282477162178,
      "grad_norm": 1.2672290802001953,
      "learning_rate": 4.1972053783285e-06,
      "loss": 0.0085,
      "step": 13674
    },
    {
      "epoch": 0.8111875667338949,
      "grad_norm": 0.8375338315963745,
      "learning_rate": 4.195887160558925e-06,
      "loss": 0.0075,
      "step": 13675
    },
    {
      "epoch": 0.811246885751572,
      "grad_norm": 0.029487328603863716,
      "learning_rate": 4.194568942789349e-06,
      "loss": 0.0005,
      "step": 13676
    },
    {
      "epoch": 0.811306204769249,
      "grad_norm": 5.414958477020264,
      "learning_rate": 4.193250725019773e-06,
      "loss": 0.0474,
      "step": 13677
    },
    {
      "epoch": 0.8113655237869261,
      "grad_norm": 15.241983413696289,
      "learning_rate": 4.191932507250198e-06,
      "loss": 0.4806,
      "step": 13678
    },
    {
      "epoch": 0.8114248428046031,
      "grad_norm": 9.35444450378418,
      "learning_rate": 4.190614289480622e-06,
      "loss": 0.3267,
      "step": 13679
    },
    {
      "epoch": 0.8114841618222802,
      "grad_norm": 3.4252898693084717,
      "learning_rate": 4.189296071711047e-06,
      "loss": 0.1104,
      "step": 13680
    },
    {
      "epoch": 0.8115434808399573,
      "grad_norm": 8.290699005126953,
      "learning_rate": 4.187977853941472e-06,
      "loss": 0.0944,
      "step": 13681
    },
    {
      "epoch": 0.8116027998576344,
      "grad_norm": 0.02341703325510025,
      "learning_rate": 4.186659636171896e-06,
      "loss": 0.0005,
      "step": 13682
    },
    {
      "epoch": 0.8116621188753115,
      "grad_norm": 0.14567714929580688,
      "learning_rate": 4.185341418402321e-06,
      "loss": 0.0017,
      "step": 13683
    },
    {
      "epoch": 0.8117214378929885,
      "grad_norm": 0.37647637724876404,
      "learning_rate": 4.184023200632745e-06,
      "loss": 0.0081,
      "step": 13684
    },
    {
      "epoch": 0.8117807569106655,
      "grad_norm": 3.029040813446045,
      "learning_rate": 4.182704982863169e-06,
      "loss": 0.0355,
      "step": 13685
    },
    {
      "epoch": 0.8118400759283426,
      "grad_norm": 0.1784343421459198,
      "learning_rate": 4.181386765093593e-06,
      "loss": 0.0025,
      "step": 13686
    },
    {
      "epoch": 0.8118993949460197,
      "grad_norm": 0.03642631694674492,
      "learning_rate": 4.180068547324018e-06,
      "loss": 0.0009,
      "step": 13687
    },
    {
      "epoch": 0.8119587139636968,
      "grad_norm": 4.517969131469727,
      "learning_rate": 4.178750329554443e-06,
      "loss": 0.235,
      "step": 13688
    },
    {
      "epoch": 0.8120180329813739,
      "grad_norm": 0.04962173104286194,
      "learning_rate": 4.177432111784867e-06,
      "loss": 0.0008,
      "step": 13689
    },
    {
      "epoch": 0.8120773519990508,
      "grad_norm": 20.11406898498535,
      "learning_rate": 4.176113894015292e-06,
      "loss": 0.3302,
      "step": 13690
    },
    {
      "epoch": 0.8121366710167279,
      "grad_norm": 0.024546947330236435,
      "learning_rate": 4.174795676245716e-06,
      "loss": 0.0007,
      "step": 13691
    },
    {
      "epoch": 0.812195990034405,
      "grad_norm": 0.05947369337081909,
      "learning_rate": 4.17347745847614e-06,
      "loss": 0.0008,
      "step": 13692
    },
    {
      "epoch": 0.8122553090520821,
      "grad_norm": 0.46971309185028076,
      "learning_rate": 4.172159240706565e-06,
      "loss": 0.0025,
      "step": 13693
    },
    {
      "epoch": 0.8123146280697592,
      "grad_norm": 0.02092786692082882,
      "learning_rate": 4.1708410229369894e-06,
      "loss": 0.0005,
      "step": 13694
    },
    {
      "epoch": 0.8123739470874363,
      "grad_norm": 0.03445661440491676,
      "learning_rate": 4.1695228051674145e-06,
      "loss": 0.0006,
      "step": 13695
    },
    {
      "epoch": 0.8124332661051133,
      "grad_norm": 0.0066180103458464146,
      "learning_rate": 4.168204587397839e-06,
      "loss": 0.0002,
      "step": 13696
    },
    {
      "epoch": 0.8124925851227903,
      "grad_norm": 0.08223696798086166,
      "learning_rate": 4.166886369628263e-06,
      "loss": 0.0009,
      "step": 13697
    },
    {
      "epoch": 0.8125519041404674,
      "grad_norm": 5.335840225219727,
      "learning_rate": 4.165568151858687e-06,
      "loss": 0.0562,
      "step": 13698
    },
    {
      "epoch": 0.8126112231581445,
      "grad_norm": 0.06599210947751999,
      "learning_rate": 4.164249934089112e-06,
      "loss": 0.0013,
      "step": 13699
    },
    {
      "epoch": 0.8126705421758216,
      "grad_norm": 0.02319636382162571,
      "learning_rate": 4.162931716319536e-06,
      "loss": 0.0007,
      "step": 13700
    },
    {
      "epoch": 0.8127298611934987,
      "grad_norm": 3.430614471435547,
      "learning_rate": 4.1616134985499604e-06,
      "loss": 0.0382,
      "step": 13701
    },
    {
      "epoch": 0.8127891802111757,
      "grad_norm": 0.03047705814242363,
      "learning_rate": 4.1602952807803855e-06,
      "loss": 0.0005,
      "step": 13702
    },
    {
      "epoch": 0.8128484992288527,
      "grad_norm": 11.263211250305176,
      "learning_rate": 4.15897706301081e-06,
      "loss": 0.1585,
      "step": 13703
    },
    {
      "epoch": 0.8129078182465298,
      "grad_norm": 11.707762718200684,
      "learning_rate": 4.157658845241234e-06,
      "loss": 0.2432,
      "step": 13704
    },
    {
      "epoch": 0.8129671372642069,
      "grad_norm": 0.2830226421356201,
      "learning_rate": 4.156340627471659e-06,
      "loss": 0.0031,
      "step": 13705
    },
    {
      "epoch": 0.813026456281884,
      "grad_norm": 0.6423089504241943,
      "learning_rate": 4.155022409702083e-06,
      "loss": 0.0081,
      "step": 13706
    },
    {
      "epoch": 0.813085775299561,
      "grad_norm": 11.650346755981445,
      "learning_rate": 4.153704191932508e-06,
      "loss": 0.7543,
      "step": 13707
    },
    {
      "epoch": 0.8131450943172381,
      "grad_norm": 9.153529167175293,
      "learning_rate": 4.152385974162932e-06,
      "loss": 0.2136,
      "step": 13708
    },
    {
      "epoch": 0.8132044133349152,
      "grad_norm": 0.29910027980804443,
      "learning_rate": 4.1510677563933565e-06,
      "loss": 0.003,
      "step": 13709
    },
    {
      "epoch": 0.8132637323525922,
      "grad_norm": 0.017562612891197205,
      "learning_rate": 4.149749538623781e-06,
      "loss": 0.0005,
      "step": 13710
    },
    {
      "epoch": 0.8133230513702693,
      "grad_norm": 11.254007339477539,
      "learning_rate": 4.148431320854206e-06,
      "loss": 0.1802,
      "step": 13711
    },
    {
      "epoch": 0.8133823703879464,
      "grad_norm": 4.523020267486572,
      "learning_rate": 4.14711310308463e-06,
      "loss": 0.0367,
      "step": 13712
    },
    {
      "epoch": 0.8134416894056234,
      "grad_norm": 0.5709581971168518,
      "learning_rate": 4.145794885315054e-06,
      "loss": 0.007,
      "step": 13713
    },
    {
      "epoch": 0.8135010084233005,
      "grad_norm": 3.7668392658233643,
      "learning_rate": 4.144476667545479e-06,
      "loss": 0.0643,
      "step": 13714
    },
    {
      "epoch": 0.8135603274409776,
      "grad_norm": 12.774031639099121,
      "learning_rate": 4.143158449775903e-06,
      "loss": 0.2466,
      "step": 13715
    },
    {
      "epoch": 0.8136196464586547,
      "grad_norm": 0.03183043748140335,
      "learning_rate": 4.1418402320063275e-06,
      "loss": 0.0006,
      "step": 13716
    },
    {
      "epoch": 0.8136789654763317,
      "grad_norm": 7.670137405395508,
      "learning_rate": 4.1405220142367525e-06,
      "loss": 0.1117,
      "step": 13717
    },
    {
      "epoch": 0.8137382844940088,
      "grad_norm": 0.11359919607639313,
      "learning_rate": 4.139203796467177e-06,
      "loss": 0.0013,
      "step": 13718
    },
    {
      "epoch": 0.8137976035116858,
      "grad_norm": 16.302846908569336,
      "learning_rate": 4.137885578697602e-06,
      "loss": 0.3256,
      "step": 13719
    },
    {
      "epoch": 0.8138569225293629,
      "grad_norm": 1.8798022270202637,
      "learning_rate": 4.136567360928025e-06,
      "loss": 0.0201,
      "step": 13720
    },
    {
      "epoch": 0.81391624154704,
      "grad_norm": 0.38461655378341675,
      "learning_rate": 4.13524914315845e-06,
      "loss": 0.003,
      "step": 13721
    },
    {
      "epoch": 0.8139755605647171,
      "grad_norm": 0.0873183086514473,
      "learning_rate": 4.133930925388874e-06,
      "loss": 0.0009,
      "step": 13722
    },
    {
      "epoch": 0.8140348795823941,
      "grad_norm": 0.013484001159667969,
      "learning_rate": 4.132612707619299e-06,
      "loss": 0.0004,
      "step": 13723
    },
    {
      "epoch": 0.8140941986000712,
      "grad_norm": 3.121786594390869,
      "learning_rate": 4.1312944898497235e-06,
      "loss": 0.0271,
      "step": 13724
    },
    {
      "epoch": 0.8141535176177482,
      "grad_norm": 20.282703399658203,
      "learning_rate": 4.129976272080148e-06,
      "loss": 0.04,
      "step": 13725
    },
    {
      "epoch": 0.8142128366354253,
      "grad_norm": 0.015418506227433681,
      "learning_rate": 4.128658054310573e-06,
      "loss": 0.0004,
      "step": 13726
    },
    {
      "epoch": 0.8142721556531024,
      "grad_norm": 6.540633201599121,
      "learning_rate": 4.127339836540997e-06,
      "loss": 0.2361,
      "step": 13727
    },
    {
      "epoch": 0.8143314746707795,
      "grad_norm": 1.3964473009109497,
      "learning_rate": 4.126021618771421e-06,
      "loss": 0.0182,
      "step": 13728
    },
    {
      "epoch": 0.8143907936884566,
      "grad_norm": 0.493266224861145,
      "learning_rate": 4.124703401001846e-06,
      "loss": 0.0048,
      "step": 13729
    },
    {
      "epoch": 0.8144501127061335,
      "grad_norm": 0.04156177490949631,
      "learning_rate": 4.12338518323227e-06,
      "loss": 0.0008,
      "step": 13730
    },
    {
      "epoch": 0.8145094317238106,
      "grad_norm": 0.008080713450908661,
      "learning_rate": 4.1220669654626945e-06,
      "loss": 0.0003,
      "step": 13731
    },
    {
      "epoch": 0.8145687507414877,
      "grad_norm": 5.550451278686523,
      "learning_rate": 4.120748747693119e-06,
      "loss": 0.1352,
      "step": 13732
    },
    {
      "epoch": 0.8146280697591648,
      "grad_norm": 0.05099354684352875,
      "learning_rate": 4.119430529923544e-06,
      "loss": 0.0008,
      "step": 13733
    },
    {
      "epoch": 0.8146873887768419,
      "grad_norm": 0.040514856576919556,
      "learning_rate": 4.118112312153968e-06,
      "loss": 0.0007,
      "step": 13734
    },
    {
      "epoch": 0.814746707794519,
      "grad_norm": 0.1306951344013214,
      "learning_rate": 4.116794094384393e-06,
      "loss": 0.0026,
      "step": 13735
    },
    {
      "epoch": 0.8148060268121959,
      "grad_norm": 6.5808210372924805,
      "learning_rate": 4.115475876614817e-06,
      "loss": 0.2736,
      "step": 13736
    },
    {
      "epoch": 0.814865345829873,
      "grad_norm": 16.766422271728516,
      "learning_rate": 4.114157658845241e-06,
      "loss": 1.3767,
      "step": 13737
    },
    {
      "epoch": 0.8149246648475501,
      "grad_norm": 0.12486107647418976,
      "learning_rate": 4.112839441075666e-06,
      "loss": 0.0025,
      "step": 13738
    },
    {
      "epoch": 0.8149839838652272,
      "grad_norm": 6.904570579528809,
      "learning_rate": 4.1115212233060906e-06,
      "loss": 0.1139,
      "step": 13739
    },
    {
      "epoch": 0.8150433028829043,
      "grad_norm": 2.6504862308502197,
      "learning_rate": 4.110203005536515e-06,
      "loss": 0.0235,
      "step": 13740
    },
    {
      "epoch": 0.8151026219005814,
      "grad_norm": 0.16512353718280792,
      "learning_rate": 4.10888478776694e-06,
      "loss": 0.0029,
      "step": 13741
    },
    {
      "epoch": 0.8151619409182584,
      "grad_norm": 0.02760166861116886,
      "learning_rate": 4.107566569997364e-06,
      "loss": 0.0007,
      "step": 13742
    },
    {
      "epoch": 0.8152212599359354,
      "grad_norm": 4.221001148223877,
      "learning_rate": 4.106248352227788e-06,
      "loss": 0.2092,
      "step": 13743
    },
    {
      "epoch": 0.8152805789536125,
      "grad_norm": 0.13842079043388367,
      "learning_rate": 4.104930134458212e-06,
      "loss": 0.0027,
      "step": 13744
    },
    {
      "epoch": 0.8153398979712896,
      "grad_norm": 18.94040298461914,
      "learning_rate": 4.103611916688637e-06,
      "loss": 0.9791,
      "step": 13745
    },
    {
      "epoch": 0.8153992169889667,
      "grad_norm": 0.14353404939174652,
      "learning_rate": 4.102293698919062e-06,
      "loss": 0.0018,
      "step": 13746
    },
    {
      "epoch": 0.8154585360066438,
      "grad_norm": 1.5460251569747925,
      "learning_rate": 4.100975481149487e-06,
      "loss": 0.0174,
      "step": 13747
    },
    {
      "epoch": 0.8155178550243208,
      "grad_norm": 6.5421881675720215,
      "learning_rate": 4.099657263379911e-06,
      "loss": 0.4879,
      "step": 13748
    },
    {
      "epoch": 0.8155771740419978,
      "grad_norm": 0.4079253375530243,
      "learning_rate": 4.098339045610335e-06,
      "loss": 0.0072,
      "step": 13749
    },
    {
      "epoch": 0.8156364930596749,
      "grad_norm": 0.27625390887260437,
      "learning_rate": 4.09702082784076e-06,
      "loss": 0.0022,
      "step": 13750
    },
    {
      "epoch": 0.815695812077352,
      "grad_norm": 0.10264258086681366,
      "learning_rate": 4.095702610071184e-06,
      "loss": 0.0017,
      "step": 13751
    },
    {
      "epoch": 0.8157551310950291,
      "grad_norm": 2.098827600479126,
      "learning_rate": 4.094384392301608e-06,
      "loss": 0.0284,
      "step": 13752
    },
    {
      "epoch": 0.8158144501127061,
      "grad_norm": 0.12233085185289383,
      "learning_rate": 4.093066174532033e-06,
      "loss": 0.0021,
      "step": 13753
    },
    {
      "epoch": 0.8158737691303832,
      "grad_norm": 20.612070083618164,
      "learning_rate": 4.091747956762458e-06,
      "loss": 0.3633,
      "step": 13754
    },
    {
      "epoch": 0.8159330881480603,
      "grad_norm": 11.671920776367188,
      "learning_rate": 4.090429738992882e-06,
      "loss": 0.2973,
      "step": 13755
    },
    {
      "epoch": 0.8159924071657373,
      "grad_norm": 0.03226276859641075,
      "learning_rate": 4.089111521223306e-06,
      "loss": 0.001,
      "step": 13756
    },
    {
      "epoch": 0.8160517261834144,
      "grad_norm": 0.032175157219171524,
      "learning_rate": 4.087793303453731e-06,
      "loss": 0.001,
      "step": 13757
    },
    {
      "epoch": 0.8161110452010915,
      "grad_norm": 0.5759017467498779,
      "learning_rate": 4.086475085684156e-06,
      "loss": 0.0063,
      "step": 13758
    },
    {
      "epoch": 0.8161703642187685,
      "grad_norm": 8.28898811340332,
      "learning_rate": 4.085156867914579e-06,
      "loss": 0.2901,
      "step": 13759
    },
    {
      "epoch": 0.8162296832364456,
      "grad_norm": 0.03729788959026337,
      "learning_rate": 4.083838650145004e-06,
      "loss": 0.0006,
      "step": 13760
    },
    {
      "epoch": 0.8162890022541227,
      "grad_norm": 9.957316398620605,
      "learning_rate": 4.082520432375429e-06,
      "loss": 0.1106,
      "step": 13761
    },
    {
      "epoch": 0.8163483212717998,
      "grad_norm": 1.7616775035858154,
      "learning_rate": 4.081202214605854e-06,
      "loss": 0.0164,
      "step": 13762
    },
    {
      "epoch": 0.8164076402894768,
      "grad_norm": 0.017768772318959236,
      "learning_rate": 4.079883996836278e-06,
      "loss": 0.0004,
      "step": 13763
    },
    {
      "epoch": 0.8164669593071539,
      "grad_norm": 0.14995816349983215,
      "learning_rate": 4.078565779066702e-06,
      "loss": 0.0009,
      "step": 13764
    },
    {
      "epoch": 0.8165262783248309,
      "grad_norm": 3.5874810218811035,
      "learning_rate": 4.077247561297127e-06,
      "loss": 0.0867,
      "step": 13765
    },
    {
      "epoch": 0.816585597342508,
      "grad_norm": 0.8483562469482422,
      "learning_rate": 4.075929343527551e-06,
      "loss": 0.0114,
      "step": 13766
    },
    {
      "epoch": 0.8166449163601851,
      "grad_norm": 2.7168304920196533,
      "learning_rate": 4.074611125757975e-06,
      "loss": 0.0631,
      "step": 13767
    },
    {
      "epoch": 0.8167042353778622,
      "grad_norm": 1.6735893487930298,
      "learning_rate": 4.0732929079884e-06,
      "loss": 0.038,
      "step": 13768
    },
    {
      "epoch": 0.8167635543955392,
      "grad_norm": 23.01145362854004,
      "learning_rate": 4.071974690218825e-06,
      "loss": 0.5497,
      "step": 13769
    },
    {
      "epoch": 0.8168228734132162,
      "grad_norm": 0.4652484357357025,
      "learning_rate": 4.070656472449249e-06,
      "loss": 0.0041,
      "step": 13770
    },
    {
      "epoch": 0.8168821924308933,
      "grad_norm": 0.04167656973004341,
      "learning_rate": 4.069338254679673e-06,
      "loss": 0.0006,
      "step": 13771
    },
    {
      "epoch": 0.8169415114485704,
      "grad_norm": 0.03590215742588043,
      "learning_rate": 4.068020036910098e-06,
      "loss": 0.0004,
      "step": 13772
    },
    {
      "epoch": 0.8170008304662475,
      "grad_norm": 0.013840587809681892,
      "learning_rate": 4.066701819140522e-06,
      "loss": 0.0005,
      "step": 13773
    },
    {
      "epoch": 0.8170601494839246,
      "grad_norm": 15.298843383789062,
      "learning_rate": 4.065383601370947e-06,
      "loss": 1.1309,
      "step": 13774
    },
    {
      "epoch": 0.8171194685016017,
      "grad_norm": 0.5870317220687866,
      "learning_rate": 4.0640653836013715e-06,
      "loss": 0.0107,
      "step": 13775
    },
    {
      "epoch": 0.8171787875192786,
      "grad_norm": 13.29406452178955,
      "learning_rate": 4.062747165831796e-06,
      "loss": 0.4952,
      "step": 13776
    },
    {
      "epoch": 0.8172381065369557,
      "grad_norm": 0.08284458518028259,
      "learning_rate": 4.061428948062221e-06,
      "loss": 0.0013,
      "step": 13777
    },
    {
      "epoch": 0.8172974255546328,
      "grad_norm": 6.0184102058410645,
      "learning_rate": 4.060110730292645e-06,
      "loss": 0.0563,
      "step": 13778
    },
    {
      "epoch": 0.8173567445723099,
      "grad_norm": 0.04296102002263069,
      "learning_rate": 4.058792512523069e-06,
      "loss": 0.0007,
      "step": 13779
    },
    {
      "epoch": 0.817416063589987,
      "grad_norm": 0.20746932923793793,
      "learning_rate": 4.057474294753493e-06,
      "loss": 0.0028,
      "step": 13780
    },
    {
      "epoch": 0.8174753826076641,
      "grad_norm": 11.2459077835083,
      "learning_rate": 4.056156076983918e-06,
      "loss": 0.6617,
      "step": 13781
    },
    {
      "epoch": 0.817534701625341,
      "grad_norm": 0.13604921102523804,
      "learning_rate": 4.0548378592143425e-06,
      "loss": 0.0014,
      "step": 13782
    },
    {
      "epoch": 0.8175940206430181,
      "grad_norm": 0.4100571870803833,
      "learning_rate": 4.053519641444767e-06,
      "loss": 0.0069,
      "step": 13783
    },
    {
      "epoch": 0.8176533396606952,
      "grad_norm": 0.01226840354502201,
      "learning_rate": 4.052201423675192e-06,
      "loss": 0.0002,
      "step": 13784
    },
    {
      "epoch": 0.8177126586783723,
      "grad_norm": 12.731298446655273,
      "learning_rate": 4.050883205905616e-06,
      "loss": 0.0238,
      "step": 13785
    },
    {
      "epoch": 0.8177719776960494,
      "grad_norm": 0.2074848860502243,
      "learning_rate": 4.049564988136041e-06,
      "loss": 0.0024,
      "step": 13786
    },
    {
      "epoch": 0.8178312967137265,
      "grad_norm": 0.0055873580276966095,
      "learning_rate": 4.048246770366464e-06,
      "loss": 0.0002,
      "step": 13787
    },
    {
      "epoch": 0.8178906157314035,
      "grad_norm": 0.0634796991944313,
      "learning_rate": 4.046928552596889e-06,
      "loss": 0.0015,
      "step": 13788
    },
    {
      "epoch": 0.8179499347490805,
      "grad_norm": 0.013345880433917046,
      "learning_rate": 4.045610334827314e-06,
      "loss": 0.0004,
      "step": 13789
    },
    {
      "epoch": 0.8180092537667576,
      "grad_norm": 0.015865666791796684,
      "learning_rate": 4.0442921170577385e-06,
      "loss": 0.0003,
      "step": 13790
    },
    {
      "epoch": 0.8180685727844347,
      "grad_norm": 51.713260650634766,
      "learning_rate": 4.042973899288163e-06,
      "loss": 0.1471,
      "step": 13791
    },
    {
      "epoch": 0.8181278918021118,
      "grad_norm": 2.745156764984131,
      "learning_rate": 4.041655681518587e-06,
      "loss": 0.0316,
      "step": 13792
    },
    {
      "epoch": 0.8181872108197888,
      "grad_norm": 9.723950386047363,
      "learning_rate": 4.040337463749012e-06,
      "loss": 0.2791,
      "step": 13793
    },
    {
      "epoch": 0.8182465298374659,
      "grad_norm": 0.07197044044733047,
      "learning_rate": 4.039019245979436e-06,
      "loss": 0.0008,
      "step": 13794
    },
    {
      "epoch": 0.818305848855143,
      "grad_norm": 4.631924152374268,
      "learning_rate": 4.03770102820986e-06,
      "loss": 0.0235,
      "step": 13795
    },
    {
      "epoch": 0.81836516787282,
      "grad_norm": 0.06250107288360596,
      "learning_rate": 4.036382810440285e-06,
      "loss": 0.0008,
      "step": 13796
    },
    {
      "epoch": 0.8184244868904971,
      "grad_norm": 0.0329495370388031,
      "learning_rate": 4.0350645926707095e-06,
      "loss": 0.0003,
      "step": 13797
    },
    {
      "epoch": 0.8184838059081742,
      "grad_norm": 0.049216128885746,
      "learning_rate": 4.033746374901134e-06,
      "loss": 0.0014,
      "step": 13798
    },
    {
      "epoch": 0.8185431249258512,
      "grad_norm": 5.608240604400635,
      "learning_rate": 4.032428157131558e-06,
      "loss": 0.0578,
      "step": 13799
    },
    {
      "epoch": 0.8186024439435283,
      "grad_norm": 7.356782913208008,
      "learning_rate": 4.031109939361983e-06,
      "loss": 0.4796,
      "step": 13800
    },
    {
      "epoch": 0.8186617629612054,
      "grad_norm": 13.323224067687988,
      "learning_rate": 4.029791721592408e-06,
      "loss": 0.1056,
      "step": 13801
    },
    {
      "epoch": 0.8187210819788824,
      "grad_norm": 12.096076011657715,
      "learning_rate": 4.028473503822832e-06,
      "loss": 0.4797,
      "step": 13802
    },
    {
      "epoch": 0.8187804009965595,
      "grad_norm": 2.3137521743774414,
      "learning_rate": 4.027155286053256e-06,
      "loss": 0.0479,
      "step": 13803
    },
    {
      "epoch": 0.8188397200142365,
      "grad_norm": 0.5280919671058655,
      "learning_rate": 4.0258370682836805e-06,
      "loss": 0.0032,
      "step": 13804
    },
    {
      "epoch": 0.8188990390319136,
      "grad_norm": 6.102036952972412,
      "learning_rate": 4.0245188505141055e-06,
      "loss": 0.0586,
      "step": 13805
    },
    {
      "epoch": 0.8189583580495907,
      "grad_norm": 3.59627103805542,
      "learning_rate": 4.02320063274453e-06,
      "loss": 0.1112,
      "step": 13806
    },
    {
      "epoch": 0.8190176770672678,
      "grad_norm": 0.05203717201948166,
      "learning_rate": 4.021882414974954e-06,
      "loss": 0.0011,
      "step": 13807
    },
    {
      "epoch": 0.8190769960849449,
      "grad_norm": 0.6562369465827942,
      "learning_rate": 4.020564197205379e-06,
      "loss": 0.0078,
      "step": 13808
    },
    {
      "epoch": 0.8191363151026219,
      "grad_norm": 31.060312271118164,
      "learning_rate": 4.019245979435803e-06,
      "loss": 0.3931,
      "step": 13809
    },
    {
      "epoch": 0.8191956341202989,
      "grad_norm": 15.24386978149414,
      "learning_rate": 4.017927761666227e-06,
      "loss": 0.611,
      "step": 13810
    },
    {
      "epoch": 0.819254953137976,
      "grad_norm": 5.011163711547852,
      "learning_rate": 4.0166095438966515e-06,
      "loss": 0.0438,
      "step": 13811
    },
    {
      "epoch": 0.8193142721556531,
      "grad_norm": 16.204744338989258,
      "learning_rate": 4.0152913261270765e-06,
      "loss": 0.1364,
      "step": 13812
    },
    {
      "epoch": 0.8193735911733302,
      "grad_norm": 8.911717414855957,
      "learning_rate": 4.0139731083575016e-06,
      "loss": 0.6681,
      "step": 13813
    },
    {
      "epoch": 0.8194329101910073,
      "grad_norm": 4.750881195068359,
      "learning_rate": 4.012654890587926e-06,
      "loss": 0.0522,
      "step": 13814
    },
    {
      "epoch": 0.8194922292086843,
      "grad_norm": 12.552845001220703,
      "learning_rate": 4.01133667281835e-06,
      "loss": 0.5348,
      "step": 13815
    },
    {
      "epoch": 0.8195515482263613,
      "grad_norm": 1.124294400215149,
      "learning_rate": 4.010018455048774e-06,
      "loss": 0.0069,
      "step": 13816
    },
    {
      "epoch": 0.8196108672440384,
      "grad_norm": 2.5944619178771973,
      "learning_rate": 4.008700237279199e-06,
      "loss": 0.0319,
      "step": 13817
    },
    {
      "epoch": 0.8196701862617155,
      "grad_norm": 4.501797676086426,
      "learning_rate": 4.007382019509623e-06,
      "loss": 0.0301,
      "step": 13818
    },
    {
      "epoch": 0.8197295052793926,
      "grad_norm": 2.3119359016418457,
      "learning_rate": 4.0060638017400475e-06,
      "loss": 0.0312,
      "step": 13819
    },
    {
      "epoch": 0.8197888242970697,
      "grad_norm": 36.316776275634766,
      "learning_rate": 4.0047455839704726e-06,
      "loss": 0.154,
      "step": 13820
    },
    {
      "epoch": 0.8198481433147468,
      "grad_norm": 0.18120622634887695,
      "learning_rate": 4.003427366200897e-06,
      "loss": 0.0009,
      "step": 13821
    },
    {
      "epoch": 0.8199074623324237,
      "grad_norm": 0.3956013321876526,
      "learning_rate": 4.002109148431321e-06,
      "loss": 0.0035,
      "step": 13822
    },
    {
      "epoch": 0.8199667813501008,
      "grad_norm": 11.952169418334961,
      "learning_rate": 4.000790930661745e-06,
      "loss": 0.2326,
      "step": 13823
    },
    {
      "epoch": 0.8200261003677779,
      "grad_norm": 0.13823331892490387,
      "learning_rate": 3.99947271289217e-06,
      "loss": 0.0018,
      "step": 13824
    },
    {
      "epoch": 0.820085419385455,
      "grad_norm": 1.4463094472885132,
      "learning_rate": 3.998154495122595e-06,
      "loss": 0.0223,
      "step": 13825
    },
    {
      "epoch": 0.8201447384031321,
      "grad_norm": 0.07749682664871216,
      "learning_rate": 3.9968362773530185e-06,
      "loss": 0.0016,
      "step": 13826
    },
    {
      "epoch": 0.8202040574208092,
      "grad_norm": 1.9325816631317139,
      "learning_rate": 3.995518059583444e-06,
      "loss": 0.02,
      "step": 13827
    },
    {
      "epoch": 0.8202633764384861,
      "grad_norm": 0.31039607524871826,
      "learning_rate": 3.994199841813868e-06,
      "loss": 0.0027,
      "step": 13828
    },
    {
      "epoch": 0.8203226954561632,
      "grad_norm": 11.2432279586792,
      "learning_rate": 3.992881624044293e-06,
      "loss": 0.151,
      "step": 13829
    },
    {
      "epoch": 0.8203820144738403,
      "grad_norm": 0.011181063950061798,
      "learning_rate": 3.991563406274717e-06,
      "loss": 0.0003,
      "step": 13830
    },
    {
      "epoch": 0.8204413334915174,
      "grad_norm": 11.174589157104492,
      "learning_rate": 3.990245188505141e-06,
      "loss": 1.087,
      "step": 13831
    },
    {
      "epoch": 0.8205006525091945,
      "grad_norm": 11.002948760986328,
      "learning_rate": 3.988926970735566e-06,
      "loss": 0.2926,
      "step": 13832
    },
    {
      "epoch": 0.8205599715268715,
      "grad_norm": 14.146280288696289,
      "learning_rate": 3.98760875296599e-06,
      "loss": 0.308,
      "step": 13833
    },
    {
      "epoch": 0.8206192905445486,
      "grad_norm": 0.15904124081134796,
      "learning_rate": 3.986290535196415e-06,
      "loss": 0.0021,
      "step": 13834
    },
    {
      "epoch": 0.8206786095622256,
      "grad_norm": 0.16965486109256744,
      "learning_rate": 3.984972317426839e-06,
      "loss": 0.0028,
      "step": 13835
    },
    {
      "epoch": 0.8207379285799027,
      "grad_norm": 24.948856353759766,
      "learning_rate": 3.983654099657264e-06,
      "loss": 0.6079,
      "step": 13836
    },
    {
      "epoch": 0.8207972475975798,
      "grad_norm": 2.0269784927368164,
      "learning_rate": 3.982335881887688e-06,
      "loss": 0.0251,
      "step": 13837
    },
    {
      "epoch": 0.8208565666152569,
      "grad_norm": 0.03585835546255112,
      "learning_rate": 3.981017664118112e-06,
      "loss": 0.0008,
      "step": 13838
    },
    {
      "epoch": 0.8209158856329339,
      "grad_norm": 5.255804061889648,
      "learning_rate": 3.979699446348537e-06,
      "loss": 0.1411,
      "step": 13839
    },
    {
      "epoch": 0.820975204650611,
      "grad_norm": 0.03567860275506973,
      "learning_rate": 3.978381228578961e-06,
      "loss": 0.0007,
      "step": 13840
    },
    {
      "epoch": 0.8210345236682881,
      "grad_norm": 0.14384041726589203,
      "learning_rate": 3.9770630108093864e-06,
      "loss": 0.0027,
      "step": 13841
    },
    {
      "epoch": 0.8210938426859651,
      "grad_norm": 10.388105392456055,
      "learning_rate": 3.975744793039811e-06,
      "loss": 0.1256,
      "step": 13842
    },
    {
      "epoch": 0.8211531617036422,
      "grad_norm": 0.23216287791728973,
      "learning_rate": 3.974426575270235e-06,
      "loss": 0.002,
      "step": 13843
    },
    {
      "epoch": 0.8212124807213192,
      "grad_norm": 0.0625537857413292,
      "learning_rate": 3.97310835750066e-06,
      "loss": 0.0006,
      "step": 13844
    },
    {
      "epoch": 0.8212717997389963,
      "grad_norm": 0.21548143029212952,
      "learning_rate": 3.971790139731084e-06,
      "loss": 0.0011,
      "step": 13845
    },
    {
      "epoch": 0.8213311187566734,
      "grad_norm": 10.769905090332031,
      "learning_rate": 3.970471921961508e-06,
      "loss": 0.2339,
      "step": 13846
    },
    {
      "epoch": 0.8213904377743505,
      "grad_norm": 0.593389093875885,
      "learning_rate": 3.969153704191932e-06,
      "loss": 0.0064,
      "step": 13847
    },
    {
      "epoch": 0.8214497567920275,
      "grad_norm": 0.9995490908622742,
      "learning_rate": 3.9678354864223574e-06,
      "loss": 0.0176,
      "step": 13848
    },
    {
      "epoch": 0.8215090758097046,
      "grad_norm": 14.562801361083984,
      "learning_rate": 3.966517268652782e-06,
      "loss": 0.9059,
      "step": 13849
    },
    {
      "epoch": 0.8215683948273816,
      "grad_norm": 0.02728840336203575,
      "learning_rate": 3.965199050883206e-06,
      "loss": 0.0005,
      "step": 13850
    },
    {
      "epoch": 0.8216277138450587,
      "grad_norm": 7.5599870681762695,
      "learning_rate": 3.963880833113631e-06,
      "loss": 0.08,
      "step": 13851
    },
    {
      "epoch": 0.8216870328627358,
      "grad_norm": 4.1232452392578125,
      "learning_rate": 3.962562615344055e-06,
      "loss": 0.0334,
      "step": 13852
    },
    {
      "epoch": 0.8217463518804129,
      "grad_norm": 8.251481056213379,
      "learning_rate": 3.96124439757448e-06,
      "loss": 0.1859,
      "step": 13853
    },
    {
      "epoch": 0.82180567089809,
      "grad_norm": 0.09815936535596848,
      "learning_rate": 3.959926179804904e-06,
      "loss": 0.0012,
      "step": 13854
    },
    {
      "epoch": 0.821864989915767,
      "grad_norm": 13.895173072814941,
      "learning_rate": 3.9586079620353284e-06,
      "loss": 0.0937,
      "step": 13855
    },
    {
      "epoch": 0.821924308933444,
      "grad_norm": 1.500593900680542,
      "learning_rate": 3.9572897442657535e-06,
      "loss": 0.0097,
      "step": 13856
    },
    {
      "epoch": 0.8219836279511211,
      "grad_norm": 14.367759704589844,
      "learning_rate": 3.955971526496178e-06,
      "loss": 0.451,
      "step": 13857
    },
    {
      "epoch": 0.8220429469687982,
      "grad_norm": 0.29309558868408203,
      "learning_rate": 3.954653308726602e-06,
      "loss": 0.0029,
      "step": 13858
    },
    {
      "epoch": 0.8221022659864753,
      "grad_norm": 9.09466552734375,
      "learning_rate": 3.953335090957026e-06,
      "loss": 0.1337,
      "step": 13859
    },
    {
      "epoch": 0.8221615850041524,
      "grad_norm": 4.552847385406494,
      "learning_rate": 3.952016873187451e-06,
      "loss": 0.1891,
      "step": 13860
    },
    {
      "epoch": 0.8222209040218293,
      "grad_norm": 0.019584335386753082,
      "learning_rate": 3.950698655417875e-06,
      "loss": 0.0005,
      "step": 13861
    },
    {
      "epoch": 0.8222802230395064,
      "grad_norm": 0.6964766979217529,
      "learning_rate": 3.9493804376482994e-06,
      "loss": 0.0122,
      "step": 13862
    },
    {
      "epoch": 0.8223395420571835,
      "grad_norm": 0.23557943105697632,
      "learning_rate": 3.9480622198787245e-06,
      "loss": 0.0025,
      "step": 13863
    },
    {
      "epoch": 0.8223988610748606,
      "grad_norm": 2.6565628051757812,
      "learning_rate": 3.946744002109149e-06,
      "loss": 0.0472,
      "step": 13864
    },
    {
      "epoch": 0.8224581800925377,
      "grad_norm": 0.01086536142975092,
      "learning_rate": 3.945425784339573e-06,
      "loss": 0.0002,
      "step": 13865
    },
    {
      "epoch": 0.8225174991102148,
      "grad_norm": 0.04026011750102043,
      "learning_rate": 3.944107566569998e-06,
      "loss": 0.0003,
      "step": 13866
    },
    {
      "epoch": 0.8225768181278919,
      "grad_norm": 6.270813465118408,
      "learning_rate": 3.942789348800422e-06,
      "loss": 0.6314,
      "step": 13867
    },
    {
      "epoch": 0.8226361371455688,
      "grad_norm": 0.02556067891418934,
      "learning_rate": 3.941471131030847e-06,
      "loss": 0.0005,
      "step": 13868
    },
    {
      "epoch": 0.8226954561632459,
      "grad_norm": 0.07339832186698914,
      "learning_rate": 3.940152913261271e-06,
      "loss": 0.0019,
      "step": 13869
    },
    {
      "epoch": 0.822754775180923,
      "grad_norm": 0.027462836354970932,
      "learning_rate": 3.9388346954916955e-06,
      "loss": 0.0006,
      "step": 13870
    },
    {
      "epoch": 0.8228140941986001,
      "grad_norm": 3.5448288917541504,
      "learning_rate": 3.93751647772212e-06,
      "loss": 0.0227,
      "step": 13871
    },
    {
      "epoch": 0.8228734132162772,
      "grad_norm": 27.584218978881836,
      "learning_rate": 3.936198259952545e-06,
      "loss": 1.056,
      "step": 13872
    },
    {
      "epoch": 0.8229327322339542,
      "grad_norm": 0.024896109476685524,
      "learning_rate": 3.934880042182969e-06,
      "loss": 0.0006,
      "step": 13873
    },
    {
      "epoch": 0.8229920512516312,
      "grad_norm": 0.25718846917152405,
      "learning_rate": 3.933561824413393e-06,
      "loss": 0.0033,
      "step": 13874
    },
    {
      "epoch": 0.8230513702693083,
      "grad_norm": 0.3642357587814331,
      "learning_rate": 3.932243606643818e-06,
      "loss": 0.0038,
      "step": 13875
    },
    {
      "epoch": 0.8231106892869854,
      "grad_norm": 11.351813316345215,
      "learning_rate": 3.930925388874242e-06,
      "loss": 0.1761,
      "step": 13876
    },
    {
      "epoch": 0.8231700083046625,
      "grad_norm": 0.27998659014701843,
      "learning_rate": 3.9296071711046665e-06,
      "loss": 0.0044,
      "step": 13877
    },
    {
      "epoch": 0.8232293273223396,
      "grad_norm": 2.1103460788726807,
      "learning_rate": 3.9282889533350915e-06,
      "loss": 0.017,
      "step": 13878
    },
    {
      "epoch": 0.8232886463400166,
      "grad_norm": 0.1119331568479538,
      "learning_rate": 3.926970735565516e-06,
      "loss": 0.0014,
      "step": 13879
    },
    {
      "epoch": 0.8233479653576937,
      "grad_norm": 0.026426665484905243,
      "learning_rate": 3.925652517795941e-06,
      "loss": 0.0008,
      "step": 13880
    },
    {
      "epoch": 0.8234072843753707,
      "grad_norm": 0.0760817900300026,
      "learning_rate": 3.924334300026365e-06,
      "loss": 0.0009,
      "step": 13881
    },
    {
      "epoch": 0.8234666033930478,
      "grad_norm": 0.1301102489233017,
      "learning_rate": 3.923016082256789e-06,
      "loss": 0.0033,
      "step": 13882
    },
    {
      "epoch": 0.8235259224107249,
      "grad_norm": 0.5171617865562439,
      "learning_rate": 3.921697864487213e-06,
      "loss": 0.0066,
      "step": 13883
    },
    {
      "epoch": 0.823585241428402,
      "grad_norm": 0.40687820315361023,
      "learning_rate": 3.920379646717638e-06,
      "loss": 0.0044,
      "step": 13884
    },
    {
      "epoch": 0.823644560446079,
      "grad_norm": 0.05880243703722954,
      "learning_rate": 3.9190614289480625e-06,
      "loss": 0.0008,
      "step": 13885
    },
    {
      "epoch": 0.8237038794637561,
      "grad_norm": 3.691915988922119,
      "learning_rate": 3.917743211178487e-06,
      "loss": 0.0831,
      "step": 13886
    },
    {
      "epoch": 0.8237631984814332,
      "grad_norm": 0.15653063356876373,
      "learning_rate": 3.916424993408912e-06,
      "loss": 0.0011,
      "step": 13887
    },
    {
      "epoch": 0.8238225174991102,
      "grad_norm": 25.204954147338867,
      "learning_rate": 3.915106775639336e-06,
      "loss": 0.5012,
      "step": 13888
    },
    {
      "epoch": 0.8238818365167873,
      "grad_norm": 6.427465915679932,
      "learning_rate": 3.91378855786976e-06,
      "loss": 0.2265,
      "step": 13889
    },
    {
      "epoch": 0.8239411555344643,
      "grad_norm": 0.03432263061404228,
      "learning_rate": 3.912470340100185e-06,
      "loss": 0.0006,
      "step": 13890
    },
    {
      "epoch": 0.8240004745521414,
      "grad_norm": 0.4055822789669037,
      "learning_rate": 3.911152122330609e-06,
      "loss": 0.0025,
      "step": 13891
    },
    {
      "epoch": 0.8240597935698185,
      "grad_norm": 11.03729248046875,
      "learning_rate": 3.909833904561034e-06,
      "loss": 0.7179,
      "step": 13892
    },
    {
      "epoch": 0.8241191125874956,
      "grad_norm": 0.10393325984477997,
      "learning_rate": 3.908515686791458e-06,
      "loss": 0.0015,
      "step": 13893
    },
    {
      "epoch": 0.8241784316051726,
      "grad_norm": 0.42223620414733887,
      "learning_rate": 3.907197469021883e-06,
      "loss": 0.007,
      "step": 13894
    },
    {
      "epoch": 0.8242377506228497,
      "grad_norm": 3.362183094024658,
      "learning_rate": 3.905879251252307e-06,
      "loss": 0.0356,
      "step": 13895
    },
    {
      "epoch": 0.8242970696405267,
      "grad_norm": 3.094803810119629,
      "learning_rate": 3.904561033482732e-06,
      "loss": 0.1026,
      "step": 13896
    },
    {
      "epoch": 0.8243563886582038,
      "grad_norm": 0.11607741564512253,
      "learning_rate": 3.903242815713156e-06,
      "loss": 0.0015,
      "step": 13897
    },
    {
      "epoch": 0.8244157076758809,
      "grad_norm": 10.238981246948242,
      "learning_rate": 3.90192459794358e-06,
      "loss": 0.2926,
      "step": 13898
    },
    {
      "epoch": 0.824475026693558,
      "grad_norm": 0.1325596123933792,
      "learning_rate": 3.900606380174005e-06,
      "loss": 0.0022,
      "step": 13899
    },
    {
      "epoch": 0.8245343457112351,
      "grad_norm": 0.060496821999549866,
      "learning_rate": 3.8992881624044296e-06,
      "loss": 0.0018,
      "step": 13900
    },
    {
      "epoch": 0.824593664728912,
      "grad_norm": 10.120241165161133,
      "learning_rate": 3.897969944634854e-06,
      "loss": 0.0418,
      "step": 13901
    },
    {
      "epoch": 0.8246529837465891,
      "grad_norm": 0.14682258665561676,
      "learning_rate": 3.896651726865279e-06,
      "loss": 0.0009,
      "step": 13902
    },
    {
      "epoch": 0.8247123027642662,
      "grad_norm": 4.0345659255981445,
      "learning_rate": 3.895333509095703e-06,
      "loss": 0.0318,
      "step": 13903
    },
    {
      "epoch": 0.8247716217819433,
      "grad_norm": 0.44971761107444763,
      "learning_rate": 3.894015291326127e-06,
      "loss": 0.0041,
      "step": 13904
    },
    {
      "epoch": 0.8248309407996204,
      "grad_norm": 7.032068252563477,
      "learning_rate": 3.892697073556551e-06,
      "loss": 0.149,
      "step": 13905
    },
    {
      "epoch": 0.8248902598172975,
      "grad_norm": 0.010498697869479656,
      "learning_rate": 3.891378855786976e-06,
      "loss": 0.0004,
      "step": 13906
    },
    {
      "epoch": 0.8249495788349744,
      "grad_norm": 0.18668463826179504,
      "learning_rate": 3.8900606380174006e-06,
      "loss": 0.0012,
      "step": 13907
    },
    {
      "epoch": 0.8250088978526515,
      "grad_norm": 13.038013458251953,
      "learning_rate": 3.888742420247826e-06,
      "loss": 0.1217,
      "step": 13908
    },
    {
      "epoch": 0.8250682168703286,
      "grad_norm": 0.33605584502220154,
      "learning_rate": 3.88742420247825e-06,
      "loss": 0.0031,
      "step": 13909
    },
    {
      "epoch": 0.8251275358880057,
      "grad_norm": 0.019368179142475128,
      "learning_rate": 3.886105984708674e-06,
      "loss": 0.0006,
      "step": 13910
    },
    {
      "epoch": 0.8251868549056828,
      "grad_norm": 0.06505081802606583,
      "learning_rate": 3.884787766939099e-06,
      "loss": 0.0014,
      "step": 13911
    },
    {
      "epoch": 0.8252461739233599,
      "grad_norm": 0.3489455282688141,
      "learning_rate": 3.883469549169523e-06,
      "loss": 0.0054,
      "step": 13912
    },
    {
      "epoch": 0.8253054929410369,
      "grad_norm": 1.1588573455810547,
      "learning_rate": 3.882151331399947e-06,
      "loss": 0.0179,
      "step": 13913
    },
    {
      "epoch": 0.8253648119587139,
      "grad_norm": 4.648379325866699,
      "learning_rate": 3.880833113630372e-06,
      "loss": 0.2899,
      "step": 13914
    },
    {
      "epoch": 0.825424130976391,
      "grad_norm": 2.0964791774749756,
      "learning_rate": 3.879514895860797e-06,
      "loss": 0.0467,
      "step": 13915
    },
    {
      "epoch": 0.8254834499940681,
      "grad_norm": 1.0234730243682861,
      "learning_rate": 3.878196678091221e-06,
      "loss": 0.0085,
      "step": 13916
    },
    {
      "epoch": 0.8255427690117452,
      "grad_norm": 0.24449826776981354,
      "learning_rate": 3.876878460321645e-06,
      "loss": 0.0033,
      "step": 13917
    },
    {
      "epoch": 0.8256020880294223,
      "grad_norm": 10.489991188049316,
      "learning_rate": 3.87556024255207e-06,
      "loss": 1.0629,
      "step": 13918
    },
    {
      "epoch": 0.8256614070470993,
      "grad_norm": 0.014021489769220352,
      "learning_rate": 3.874242024782494e-06,
      "loss": 0.0005,
      "step": 13919
    },
    {
      "epoch": 0.8257207260647764,
      "grad_norm": 10.105582237243652,
      "learning_rate": 3.872923807012918e-06,
      "loss": 0.1674,
      "step": 13920
    },
    {
      "epoch": 0.8257800450824534,
      "grad_norm": 2.299262285232544,
      "learning_rate": 3.8716055892433434e-06,
      "loss": 0.0118,
      "step": 13921
    },
    {
      "epoch": 0.8258393641001305,
      "grad_norm": 1.270559310913086,
      "learning_rate": 3.870287371473768e-06,
      "loss": 0.0072,
      "step": 13922
    },
    {
      "epoch": 0.8258986831178076,
      "grad_norm": 0.13745437562465668,
      "learning_rate": 3.868969153704193e-06,
      "loss": 0.0019,
      "step": 13923
    },
    {
      "epoch": 0.8259580021354846,
      "grad_norm": 0.7098205089569092,
      "learning_rate": 3.867650935934617e-06,
      "loss": 0.0098,
      "step": 13924
    },
    {
      "epoch": 0.8260173211531617,
      "grad_norm": 0.6829119324684143,
      "learning_rate": 3.866332718165041e-06,
      "loss": 0.0114,
      "step": 13925
    },
    {
      "epoch": 0.8260766401708388,
      "grad_norm": 0.4503156244754791,
      "learning_rate": 3.865014500395466e-06,
      "loss": 0.0044,
      "step": 13926
    },
    {
      "epoch": 0.8261359591885158,
      "grad_norm": 4.060160160064697,
      "learning_rate": 3.86369628262589e-06,
      "loss": 0.0992,
      "step": 13927
    },
    {
      "epoch": 0.8261952782061929,
      "grad_norm": 0.028278710320591927,
      "learning_rate": 3.8623780648563144e-06,
      "loss": 0.0007,
      "step": 13928
    },
    {
      "epoch": 0.82625459722387,
      "grad_norm": 25.72005844116211,
      "learning_rate": 3.861059847086739e-06,
      "loss": 0.2988,
      "step": 13929
    },
    {
      "epoch": 0.826313916241547,
      "grad_norm": 3.9719934463500977,
      "learning_rate": 3.859741629317164e-06,
      "loss": 0.0521,
      "step": 13930
    },
    {
      "epoch": 0.8263732352592241,
      "grad_norm": 0.006445821840316057,
      "learning_rate": 3.858423411547588e-06,
      "loss": 0.0001,
      "step": 13931
    },
    {
      "epoch": 0.8264325542769012,
      "grad_norm": 0.0057801115326583385,
      "learning_rate": 3.857105193778012e-06,
      "loss": 0.0002,
      "step": 13932
    },
    {
      "epoch": 0.8264918732945783,
      "grad_norm": 0.1290569305419922,
      "learning_rate": 3.855786976008437e-06,
      "loss": 0.0012,
      "step": 13933
    },
    {
      "epoch": 0.8265511923122553,
      "grad_norm": 0.009162986651062965,
      "learning_rate": 3.854468758238861e-06,
      "loss": 0.0002,
      "step": 13934
    },
    {
      "epoch": 0.8266105113299324,
      "grad_norm": 0.13134661316871643,
      "learning_rate": 3.853150540469286e-06,
      "loss": 0.001,
      "step": 13935
    },
    {
      "epoch": 0.8266698303476094,
      "grad_norm": 3.330561637878418,
      "learning_rate": 3.8518323226997105e-06,
      "loss": 0.0517,
      "step": 13936
    },
    {
      "epoch": 0.8267291493652865,
      "grad_norm": 0.0784531906247139,
      "learning_rate": 3.850514104930135e-06,
      "loss": 0.0012,
      "step": 13937
    },
    {
      "epoch": 0.8267884683829636,
      "grad_norm": 8.92604923248291,
      "learning_rate": 3.84919588716056e-06,
      "loss": 0.1276,
      "step": 13938
    },
    {
      "epoch": 0.8268477874006407,
      "grad_norm": 0.033978745341300964,
      "learning_rate": 3.847877669390984e-06,
      "loss": 0.0006,
      "step": 13939
    },
    {
      "epoch": 0.8269071064183177,
      "grad_norm": 4.451368808746338,
      "learning_rate": 3.846559451621408e-06,
      "loss": 0.1102,
      "step": 13940
    },
    {
      "epoch": 0.8269664254359947,
      "grad_norm": 0.18585778772830963,
      "learning_rate": 3.845241233851832e-06,
      "loss": 0.0022,
      "step": 13941
    },
    {
      "epoch": 0.8270257444536718,
      "grad_norm": 6.463402271270752,
      "learning_rate": 3.843923016082257e-06,
      "loss": 0.0581,
      "step": 13942
    },
    {
      "epoch": 0.8270850634713489,
      "grad_norm": 0.13981425762176514,
      "learning_rate": 3.8426047983126815e-06,
      "loss": 0.0032,
      "step": 13943
    },
    {
      "epoch": 0.827144382489026,
      "grad_norm": 13.074554443359375,
      "learning_rate": 3.841286580543106e-06,
      "loss": 0.2733,
      "step": 13944
    },
    {
      "epoch": 0.8272037015067031,
      "grad_norm": 0.4392428994178772,
      "learning_rate": 3.839968362773531e-06,
      "loss": 0.003,
      "step": 13945
    },
    {
      "epoch": 0.8272630205243802,
      "grad_norm": 0.04527272284030914,
      "learning_rate": 3.838650145003955e-06,
      "loss": 0.0009,
      "step": 13946
    },
    {
      "epoch": 0.8273223395420571,
      "grad_norm": 12.604446411132812,
      "learning_rate": 3.83733192723438e-06,
      "loss": 0.195,
      "step": 13947
    },
    {
      "epoch": 0.8273816585597342,
      "grad_norm": 3.4982097148895264,
      "learning_rate": 3.836013709464803e-06,
      "loss": 0.0509,
      "step": 13948
    },
    {
      "epoch": 0.8274409775774113,
      "grad_norm": 2.8074402809143066,
      "learning_rate": 3.834695491695228e-06,
      "loss": 0.0634,
      "step": 13949
    },
    {
      "epoch": 0.8275002965950884,
      "grad_norm": 2.1317484378814697,
      "learning_rate": 3.833377273925653e-06,
      "loss": 0.0282,
      "step": 13950
    },
    {
      "epoch": 0.8275596156127655,
      "grad_norm": 7.9812445640563965,
      "learning_rate": 3.8320590561560775e-06,
      "loss": 0.1635,
      "step": 13951
    },
    {
      "epoch": 0.8276189346304426,
      "grad_norm": 11.832817077636719,
      "learning_rate": 3.830740838386502e-06,
      "loss": 0.1208,
      "step": 13952
    },
    {
      "epoch": 0.8276782536481195,
      "grad_norm": 0.023798853158950806,
      "learning_rate": 3.829422620616926e-06,
      "loss": 0.0008,
      "step": 13953
    },
    {
      "epoch": 0.8277375726657966,
      "grad_norm": 14.452658653259277,
      "learning_rate": 3.828104402847351e-06,
      "loss": 0.4757,
      "step": 13954
    },
    {
      "epoch": 0.8277968916834737,
      "grad_norm": 16.106197357177734,
      "learning_rate": 3.826786185077775e-06,
      "loss": 0.7283,
      "step": 13955
    },
    {
      "epoch": 0.8278562107011508,
      "grad_norm": 1.6688982248306274,
      "learning_rate": 3.825467967308199e-06,
      "loss": 0.0374,
      "step": 13956
    },
    {
      "epoch": 0.8279155297188279,
      "grad_norm": 1.3498225212097168,
      "learning_rate": 3.824149749538624e-06,
      "loss": 0.0133,
      "step": 13957
    },
    {
      "epoch": 0.827974848736505,
      "grad_norm": 0.349247008562088,
      "learning_rate": 3.8228315317690485e-06,
      "loss": 0.0026,
      "step": 13958
    },
    {
      "epoch": 0.828034167754182,
      "grad_norm": 1.8876436948776245,
      "learning_rate": 3.821513313999473e-06,
      "loss": 0.0234,
      "step": 13959
    },
    {
      "epoch": 0.828093486771859,
      "grad_norm": 1.9776499271392822,
      "learning_rate": 3.820195096229897e-06,
      "loss": 0.012,
      "step": 13960
    },
    {
      "epoch": 0.8281528057895361,
      "grad_norm": 0.07219844311475754,
      "learning_rate": 3.818876878460322e-06,
      "loss": 0.0015,
      "step": 13961
    },
    {
      "epoch": 0.8282121248072132,
      "grad_norm": 0.014963477849960327,
      "learning_rate": 3.817558660690747e-06,
      "loss": 0.0003,
      "step": 13962
    },
    {
      "epoch": 0.8282714438248903,
      "grad_norm": 0.10834793746471405,
      "learning_rate": 3.816240442921171e-06,
      "loss": 0.0015,
      "step": 13963
    },
    {
      "epoch": 0.8283307628425673,
      "grad_norm": 0.016400057822465897,
      "learning_rate": 3.814922225151595e-06,
      "loss": 0.0005,
      "step": 13964
    },
    {
      "epoch": 0.8283900818602444,
      "grad_norm": 3.8472347259521484,
      "learning_rate": 3.8136040073820195e-06,
      "loss": 0.1191,
      "step": 13965
    },
    {
      "epoch": 0.8284494008779215,
      "grad_norm": 3.387333393096924,
      "learning_rate": 3.812285789612444e-06,
      "loss": 0.0137,
      "step": 13966
    },
    {
      "epoch": 0.8285087198955985,
      "grad_norm": 1.1667096614837646,
      "learning_rate": 3.810967571842869e-06,
      "loss": 0.0106,
      "step": 13967
    },
    {
      "epoch": 0.8285680389132756,
      "grad_norm": 5.791468620300293,
      "learning_rate": 3.8096493540732933e-06,
      "loss": 0.2036,
      "step": 13968
    },
    {
      "epoch": 0.8286273579309527,
      "grad_norm": 6.336817264556885,
      "learning_rate": 3.808331136303718e-06,
      "loss": 0.07,
      "step": 13969
    },
    {
      "epoch": 0.8286866769486297,
      "grad_norm": 12.34017562866211,
      "learning_rate": 3.807012918534142e-06,
      "loss": 0.7517,
      "step": 13970
    },
    {
      "epoch": 0.8287459959663068,
      "grad_norm": 0.04478132352232933,
      "learning_rate": 3.8056947007645668e-06,
      "loss": 0.0006,
      "step": 13971
    },
    {
      "epoch": 0.8288053149839839,
      "grad_norm": 0.08118218928575516,
      "learning_rate": 3.804376482994991e-06,
      "loss": 0.0011,
      "step": 13972
    },
    {
      "epoch": 0.8288646340016609,
      "grad_norm": 0.006573522463440895,
      "learning_rate": 3.8030582652254156e-06,
      "loss": 0.0002,
      "step": 13973
    },
    {
      "epoch": 0.828923953019338,
      "grad_norm": 3.2757742404937744,
      "learning_rate": 3.80174004745584e-06,
      "loss": 0.173,
      "step": 13974
    },
    {
      "epoch": 0.828983272037015,
      "grad_norm": 0.8502612113952637,
      "learning_rate": 3.8004218296862644e-06,
      "loss": 0.0095,
      "step": 13975
    },
    {
      "epoch": 0.8290425910546921,
      "grad_norm": 0.4798949360847473,
      "learning_rate": 3.799103611916689e-06,
      "loss": 0.0041,
      "step": 13976
    },
    {
      "epoch": 0.8291019100723692,
      "grad_norm": 0.003981270827353001,
      "learning_rate": 3.797785394147113e-06,
      "loss": 0.0002,
      "step": 13977
    },
    {
      "epoch": 0.8291612290900463,
      "grad_norm": 0.023868627846240997,
      "learning_rate": 3.7964671763775378e-06,
      "loss": 0.0005,
      "step": 13978
    },
    {
      "epoch": 0.8292205481077234,
      "grad_norm": 0.0395231693983078,
      "learning_rate": 3.795148958607963e-06,
      "loss": 0.0008,
      "step": 13979
    },
    {
      "epoch": 0.8292798671254004,
      "grad_norm": 0.0656374841928482,
      "learning_rate": 3.7938307408383866e-06,
      "loss": 0.0011,
      "step": 13980
    },
    {
      "epoch": 0.8293391861430774,
      "grad_norm": 0.11626848578453064,
      "learning_rate": 3.7925125230688116e-06,
      "loss": 0.0016,
      "step": 13981
    },
    {
      "epoch": 0.8293985051607545,
      "grad_norm": 65.4182357788086,
      "learning_rate": 3.7911943052992358e-06,
      "loss": 1.871,
      "step": 13982
    },
    {
      "epoch": 0.8294578241784316,
      "grad_norm": 0.9131192564964294,
      "learning_rate": 3.7898760875296604e-06,
      "loss": 0.0068,
      "step": 13983
    },
    {
      "epoch": 0.8295171431961087,
      "grad_norm": 0.020399637520313263,
      "learning_rate": 3.7885578697600846e-06,
      "loss": 0.0006,
      "step": 13984
    },
    {
      "epoch": 0.8295764622137858,
      "grad_norm": 0.019327133893966675,
      "learning_rate": 3.787239651990509e-06,
      "loss": 0.0004,
      "step": 13985
    },
    {
      "epoch": 0.8296357812314628,
      "grad_norm": 0.7896128296852112,
      "learning_rate": 3.785921434220934e-06,
      "loss": 0.0106,
      "step": 13986
    },
    {
      "epoch": 0.8296951002491398,
      "grad_norm": 21.635391235351562,
      "learning_rate": 3.784603216451358e-06,
      "loss": 0.2108,
      "step": 13987
    },
    {
      "epoch": 0.8297544192668169,
      "grad_norm": 0.706793487071991,
      "learning_rate": 3.7832849986817826e-06,
      "loss": 0.0043,
      "step": 13988
    },
    {
      "epoch": 0.829813738284494,
      "grad_norm": 3.2563719749450684,
      "learning_rate": 3.7819667809122068e-06,
      "loss": 0.0273,
      "step": 13989
    },
    {
      "epoch": 0.8298730573021711,
      "grad_norm": 0.9587501287460327,
      "learning_rate": 3.7806485631426314e-06,
      "loss": 0.0078,
      "step": 13990
    },
    {
      "epoch": 0.8299323763198482,
      "grad_norm": 0.192886084318161,
      "learning_rate": 3.779330345373056e-06,
      "loss": 0.0025,
      "step": 13991
    },
    {
      "epoch": 0.8299916953375253,
      "grad_norm": 8.219586372375488,
      "learning_rate": 3.77801212760348e-06,
      "loss": 0.2274,
      "step": 13992
    },
    {
      "epoch": 0.8300510143552022,
      "grad_norm": 0.01045947801321745,
      "learning_rate": 3.7766939098339052e-06,
      "loss": 0.0003,
      "step": 13993
    },
    {
      "epoch": 0.8301103333728793,
      "grad_norm": 6.35818338394165,
      "learning_rate": 3.775375692064329e-06,
      "loss": 0.1188,
      "step": 13994
    },
    {
      "epoch": 0.8301696523905564,
      "grad_norm": 43.73292541503906,
      "learning_rate": 3.774057474294754e-06,
      "loss": 0.5581,
      "step": 13995
    },
    {
      "epoch": 0.8302289714082335,
      "grad_norm": 8.793720245361328,
      "learning_rate": 3.772739256525178e-06,
      "loss": 0.2461,
      "step": 13996
    },
    {
      "epoch": 0.8302882904259106,
      "grad_norm": 6.661519527435303,
      "learning_rate": 3.771421038755603e-06,
      "loss": 0.4529,
      "step": 13997
    },
    {
      "epoch": 0.8303476094435877,
      "grad_norm": 8.235666275024414,
      "learning_rate": 3.7701028209860274e-06,
      "loss": 0.5115,
      "step": 13998
    },
    {
      "epoch": 0.8304069284612646,
      "grad_norm": 0.02237623743712902,
      "learning_rate": 3.7687846032164516e-06,
      "loss": 0.0003,
      "step": 13999
    },
    {
      "epoch": 0.8304662474789417,
      "grad_norm": 2.2006289958953857,
      "learning_rate": 3.7674663854468762e-06,
      "loss": 0.0202,
      "step": 14000
    },
    {
      "epoch": 0.8305255664966188,
      "grad_norm": 1.5754598379135132,
      "learning_rate": 3.7661481676773004e-06,
      "loss": 0.0193,
      "step": 14001
    },
    {
      "epoch": 0.8305848855142959,
      "grad_norm": 0.20798872411251068,
      "learning_rate": 3.764829949907725e-06,
      "loss": 0.0016,
      "step": 14002
    },
    {
      "epoch": 0.830644204531973,
      "grad_norm": 1.0014034509658813,
      "learning_rate": 3.7635117321381496e-06,
      "loss": 0.0162,
      "step": 14003
    },
    {
      "epoch": 0.83070352354965,
      "grad_norm": 34.654483795166016,
      "learning_rate": 3.762193514368574e-06,
      "loss": 0.4221,
      "step": 14004
    },
    {
      "epoch": 0.8307628425673271,
      "grad_norm": 0.08216913789510727,
      "learning_rate": 3.7608752965989984e-06,
      "loss": 0.0016,
      "step": 14005
    },
    {
      "epoch": 0.8308221615850041,
      "grad_norm": 0.04510721191763878,
      "learning_rate": 3.7595570788294226e-06,
      "loss": 0.0013,
      "step": 14006
    },
    {
      "epoch": 0.8308814806026812,
      "grad_norm": 7.307096004486084,
      "learning_rate": 3.7582388610598477e-06,
      "loss": 0.6087,
      "step": 14007
    },
    {
      "epoch": 0.8309407996203583,
      "grad_norm": 13.376948356628418,
      "learning_rate": 3.7569206432902714e-06,
      "loss": 0.9124,
      "step": 14008
    },
    {
      "epoch": 0.8310001186380354,
      "grad_norm": 0.0933431014418602,
      "learning_rate": 3.7556024255206965e-06,
      "loss": 0.0012,
      "step": 14009
    },
    {
      "epoch": 0.8310594376557124,
      "grad_norm": 0.42969200015068054,
      "learning_rate": 3.754284207751121e-06,
      "loss": 0.005,
      "step": 14010
    },
    {
      "epoch": 0.8311187566733895,
      "grad_norm": 0.054705437272787094,
      "learning_rate": 3.7529659899815453e-06,
      "loss": 0.0008,
      "step": 14011
    },
    {
      "epoch": 0.8311780756910666,
      "grad_norm": 8.97701644897461,
      "learning_rate": 3.75164777221197e-06,
      "loss": 0.3799,
      "step": 14012
    },
    {
      "epoch": 0.8312373947087436,
      "grad_norm": 21.835214614868164,
      "learning_rate": 3.750329554442394e-06,
      "loss": 0.341,
      "step": 14013
    },
    {
      "epoch": 0.8312967137264207,
      "grad_norm": 21.578645706176758,
      "learning_rate": 3.7490113366728187e-06,
      "loss": 0.1046,
      "step": 14014
    },
    {
      "epoch": 0.8313560327440978,
      "grad_norm": 4.904603481292725,
      "learning_rate": 3.7476931189032433e-06,
      "loss": 0.2269,
      "step": 14015
    },
    {
      "epoch": 0.8314153517617748,
      "grad_norm": 11.074953079223633,
      "learning_rate": 3.7463749011336675e-06,
      "loss": 0.2315,
      "step": 14016
    },
    {
      "epoch": 0.8314746707794519,
      "grad_norm": 0.08837952464818954,
      "learning_rate": 3.745056683364092e-06,
      "loss": 0.0012,
      "step": 14017
    },
    {
      "epoch": 0.831533989797129,
      "grad_norm": 0.5030773282051086,
      "learning_rate": 3.7437384655945163e-06,
      "loss": 0.0098,
      "step": 14018
    },
    {
      "epoch": 0.831593308814806,
      "grad_norm": 0.2290669083595276,
      "learning_rate": 3.742420247824941e-06,
      "loss": 0.0038,
      "step": 14019
    },
    {
      "epoch": 0.8316526278324831,
      "grad_norm": 1.8455041646957397,
      "learning_rate": 3.741102030055365e-06,
      "loss": 0.0045,
      "step": 14020
    },
    {
      "epoch": 0.8317119468501601,
      "grad_norm": 0.05655866116285324,
      "learning_rate": 3.73978381228579e-06,
      "loss": 0.0012,
      "step": 14021
    },
    {
      "epoch": 0.8317712658678372,
      "grad_norm": 1.6181018352508545,
      "learning_rate": 3.7384655945162147e-06,
      "loss": 0.0109,
      "step": 14022
    },
    {
      "epoch": 0.8318305848855143,
      "grad_norm": 6.808888912200928,
      "learning_rate": 3.737147376746639e-06,
      "loss": 0.1655,
      "step": 14023
    },
    {
      "epoch": 0.8318899039031914,
      "grad_norm": 12.547525405883789,
      "learning_rate": 3.7358291589770635e-06,
      "loss": 0.559,
      "step": 14024
    },
    {
      "epoch": 0.8319492229208685,
      "grad_norm": 0.008562926203012466,
      "learning_rate": 3.7345109412074877e-06,
      "loss": 0.0003,
      "step": 14025
    },
    {
      "epoch": 0.8320085419385455,
      "grad_norm": 12.567641258239746,
      "learning_rate": 3.7331927234379123e-06,
      "loss": 0.4358,
      "step": 14026
    },
    {
      "epoch": 0.8320678609562225,
      "grad_norm": 13.83676815032959,
      "learning_rate": 3.731874505668337e-06,
      "loss": 0.6203,
      "step": 14027
    },
    {
      "epoch": 0.8321271799738996,
      "grad_norm": 4.345681190490723,
      "learning_rate": 3.730556287898761e-06,
      "loss": 0.1629,
      "step": 14028
    },
    {
      "epoch": 0.8321864989915767,
      "grad_norm": 1.6966975927352905,
      "learning_rate": 3.7292380701291857e-06,
      "loss": 0.0215,
      "step": 14029
    },
    {
      "epoch": 0.8322458180092538,
      "grad_norm": 0.018267150968313217,
      "learning_rate": 3.72791985235961e-06,
      "loss": 0.0005,
      "step": 14030
    },
    {
      "epoch": 0.8323051370269309,
      "grad_norm": 5.7444353103637695,
      "learning_rate": 3.7266016345900345e-06,
      "loss": 0.0872,
      "step": 14031
    },
    {
      "epoch": 0.8323644560446078,
      "grad_norm": 0.21527962386608124,
      "learning_rate": 3.7252834168204587e-06,
      "loss": 0.0019,
      "step": 14032
    },
    {
      "epoch": 0.8324237750622849,
      "grad_norm": 1.029788613319397,
      "learning_rate": 3.7239651990508833e-06,
      "loss": 0.014,
      "step": 14033
    },
    {
      "epoch": 0.832483094079962,
      "grad_norm": 8.985648155212402,
      "learning_rate": 3.7226469812813083e-06,
      "loss": 0.0696,
      "step": 14034
    },
    {
      "epoch": 0.8325424130976391,
      "grad_norm": 4.210469722747803,
      "learning_rate": 3.7213287635117325e-06,
      "loss": 0.0407,
      "step": 14035
    },
    {
      "epoch": 0.8326017321153162,
      "grad_norm": 10.192325592041016,
      "learning_rate": 3.720010545742157e-06,
      "loss": 0.1114,
      "step": 14036
    },
    {
      "epoch": 0.8326610511329933,
      "grad_norm": 0.49213907122612,
      "learning_rate": 3.7186923279725813e-06,
      "loss": 0.002,
      "step": 14037
    },
    {
      "epoch": 0.8327203701506704,
      "grad_norm": 0.007417149841785431,
      "learning_rate": 3.717374110203006e-06,
      "loss": 0.0002,
      "step": 14038
    },
    {
      "epoch": 0.8327796891683473,
      "grad_norm": 34.72197723388672,
      "learning_rate": 3.7160558924334305e-06,
      "loss": 0.3783,
      "step": 14039
    },
    {
      "epoch": 0.8328390081860244,
      "grad_norm": 0.2864777147769928,
      "learning_rate": 3.7147376746638547e-06,
      "loss": 0.0037,
      "step": 14040
    },
    {
      "epoch": 0.8328983272037015,
      "grad_norm": 13.438215255737305,
      "learning_rate": 3.7134194568942793e-06,
      "loss": 0.3484,
      "step": 14041
    },
    {
      "epoch": 0.8329576462213786,
      "grad_norm": 0.42430564761161804,
      "learning_rate": 3.7121012391247035e-06,
      "loss": 0.0051,
      "step": 14042
    },
    {
      "epoch": 0.8330169652390557,
      "grad_norm": 28.169178009033203,
      "learning_rate": 3.710783021355128e-06,
      "loss": 0.6722,
      "step": 14043
    },
    {
      "epoch": 0.8330762842567327,
      "grad_norm": 11.04005241394043,
      "learning_rate": 3.7094648035855523e-06,
      "loss": 0.2285,
      "step": 14044
    },
    {
      "epoch": 0.8331356032744098,
      "grad_norm": 4.108578681945801,
      "learning_rate": 3.708146585815977e-06,
      "loss": 0.0412,
      "step": 14045
    },
    {
      "epoch": 0.8331949222920868,
      "grad_norm": 7.702632427215576,
      "learning_rate": 3.706828368046402e-06,
      "loss": 0.0481,
      "step": 14046
    },
    {
      "epoch": 0.8332542413097639,
      "grad_norm": 1.8524278402328491,
      "learning_rate": 3.7055101502768257e-06,
      "loss": 0.028,
      "step": 14047
    },
    {
      "epoch": 0.833313560327441,
      "grad_norm": 4.78578519821167,
      "learning_rate": 3.7041919325072508e-06,
      "loss": 0.337,
      "step": 14048
    },
    {
      "epoch": 0.8333728793451181,
      "grad_norm": 1.4939512014389038,
      "learning_rate": 3.702873714737675e-06,
      "loss": 0.0274,
      "step": 14049
    },
    {
      "epoch": 0.8334321983627951,
      "grad_norm": 7.595273017883301,
      "learning_rate": 3.7015554969680996e-06,
      "loss": 0.0616,
      "step": 14050
    },
    {
      "epoch": 0.8334915173804722,
      "grad_norm": 4.377120018005371,
      "learning_rate": 3.700237279198524e-06,
      "loss": 0.0875,
      "step": 14051
    },
    {
      "epoch": 0.8335508363981492,
      "grad_norm": 0.05408770963549614,
      "learning_rate": 3.6989190614289484e-06,
      "loss": 0.0011,
      "step": 14052
    },
    {
      "epoch": 0.8336101554158263,
      "grad_norm": 11.562554359436035,
      "learning_rate": 3.697600843659373e-06,
      "loss": 0.1804,
      "step": 14053
    },
    {
      "epoch": 0.8336694744335034,
      "grad_norm": 0.047562338411808014,
      "learning_rate": 3.696282625889797e-06,
      "loss": 0.0008,
      "step": 14054
    },
    {
      "epoch": 0.8337287934511804,
      "grad_norm": 7.511312007904053,
      "learning_rate": 3.6949644081202218e-06,
      "loss": 0.7107,
      "step": 14055
    },
    {
      "epoch": 0.8337881124688575,
      "grad_norm": 0.03301406651735306,
      "learning_rate": 3.693646190350646e-06,
      "loss": 0.0007,
      "step": 14056
    },
    {
      "epoch": 0.8338474314865346,
      "grad_norm": 0.7508440017700195,
      "learning_rate": 3.6923279725810706e-06,
      "loss": 0.0084,
      "step": 14057
    },
    {
      "epoch": 0.8339067505042117,
      "grad_norm": 5.871338844299316,
      "learning_rate": 3.691009754811495e-06,
      "loss": 0.0712,
      "step": 14058
    },
    {
      "epoch": 0.8339660695218887,
      "grad_norm": 0.40417376160621643,
      "learning_rate": 3.6896915370419194e-06,
      "loss": 0.0059,
      "step": 14059
    },
    {
      "epoch": 0.8340253885395658,
      "grad_norm": 0.01075669564306736,
      "learning_rate": 3.6883733192723444e-06,
      "loss": 0.0004,
      "step": 14060
    },
    {
      "epoch": 0.8340847075572428,
      "grad_norm": 19.949678421020508,
      "learning_rate": 3.687055101502768e-06,
      "loss": 0.1971,
      "step": 14061
    },
    {
      "epoch": 0.8341440265749199,
      "grad_norm": 0.14520056545734406,
      "learning_rate": 3.685736883733193e-06,
      "loss": 0.002,
      "step": 14062
    },
    {
      "epoch": 0.834203345592597,
      "grad_norm": 0.03132404759526253,
      "learning_rate": 3.684418665963618e-06,
      "loss": 0.0006,
      "step": 14063
    },
    {
      "epoch": 0.8342626646102741,
      "grad_norm": 1.370139241218567,
      "learning_rate": 3.683100448194042e-06,
      "loss": 0.0076,
      "step": 14064
    },
    {
      "epoch": 0.8343219836279511,
      "grad_norm": 0.18761956691741943,
      "learning_rate": 3.6817822304244666e-06,
      "loss": 0.0026,
      "step": 14065
    },
    {
      "epoch": 0.8343813026456282,
      "grad_norm": 1.2048150300979614,
      "learning_rate": 3.6804640126548908e-06,
      "loss": 0.0228,
      "step": 14066
    },
    {
      "epoch": 0.8344406216633052,
      "grad_norm": 16.79834747314453,
      "learning_rate": 3.6791457948853154e-06,
      "loss": 0.2499,
      "step": 14067
    },
    {
      "epoch": 0.8344999406809823,
      "grad_norm": 5.919147491455078,
      "learning_rate": 3.6778275771157396e-06,
      "loss": 0.1521,
      "step": 14068
    },
    {
      "epoch": 0.8345592596986594,
      "grad_norm": 1.6724649667739868,
      "learning_rate": 3.676509359346164e-06,
      "loss": 0.0213,
      "step": 14069
    },
    {
      "epoch": 0.8346185787163365,
      "grad_norm": 17.198904037475586,
      "learning_rate": 3.675191141576589e-06,
      "loss": 0.2552,
      "step": 14070
    },
    {
      "epoch": 0.8346778977340136,
      "grad_norm": 0.031367912888526917,
      "learning_rate": 3.673872923807013e-06,
      "loss": 0.0005,
      "step": 14071
    },
    {
      "epoch": 0.8347372167516905,
      "grad_norm": 0.01769341714680195,
      "learning_rate": 3.6725547060374376e-06,
      "loss": 0.0005,
      "step": 14072
    },
    {
      "epoch": 0.8347965357693676,
      "grad_norm": 2.60587477684021,
      "learning_rate": 3.671236488267862e-06,
      "loss": 0.05,
      "step": 14073
    },
    {
      "epoch": 0.8348558547870447,
      "grad_norm": 0.14479008316993713,
      "learning_rate": 3.669918270498287e-06,
      "loss": 0.0017,
      "step": 14074
    },
    {
      "epoch": 0.8349151738047218,
      "grad_norm": 0.03312221169471741,
      "learning_rate": 3.6686000527287114e-06,
      "loss": 0.001,
      "step": 14075
    },
    {
      "epoch": 0.8349744928223989,
      "grad_norm": 0.015577489510178566,
      "learning_rate": 3.6672818349591356e-06,
      "loss": 0.0003,
      "step": 14076
    },
    {
      "epoch": 0.835033811840076,
      "grad_norm": 0.034572768956422806,
      "learning_rate": 3.6659636171895602e-06,
      "loss": 0.0006,
      "step": 14077
    },
    {
      "epoch": 0.8350931308577529,
      "grad_norm": 19.34267807006836,
      "learning_rate": 3.6646453994199844e-06,
      "loss": 0.505,
      "step": 14078
    },
    {
      "epoch": 0.83515244987543,
      "grad_norm": 0.6110544800758362,
      "learning_rate": 3.663327181650409e-06,
      "loss": 0.0118,
      "step": 14079
    },
    {
      "epoch": 0.8352117688931071,
      "grad_norm": 1.8151413202285767,
      "learning_rate": 3.6620089638808332e-06,
      "loss": 0.0255,
      "step": 14080
    },
    {
      "epoch": 0.8352710879107842,
      "grad_norm": 15.874591827392578,
      "learning_rate": 3.660690746111258e-06,
      "loss": 0.6807,
      "step": 14081
    },
    {
      "epoch": 0.8353304069284613,
      "grad_norm": 0.029408996924757957,
      "learning_rate": 3.6593725283416824e-06,
      "loss": 0.0006,
      "step": 14082
    },
    {
      "epoch": 0.8353897259461384,
      "grad_norm": 2.079712390899658,
      "learning_rate": 3.6580543105721066e-06,
      "loss": 0.0343,
      "step": 14083
    },
    {
      "epoch": 0.8354490449638154,
      "grad_norm": 14.696333885192871,
      "learning_rate": 3.6567360928025312e-06,
      "loss": 0.3903,
      "step": 14084
    },
    {
      "epoch": 0.8355083639814924,
      "grad_norm": 21.113483428955078,
      "learning_rate": 3.6554178750329554e-06,
      "loss": 0.3393,
      "step": 14085
    },
    {
      "epoch": 0.8355676829991695,
      "grad_norm": 1.4911147356033325,
      "learning_rate": 3.65409965726338e-06,
      "loss": 0.0093,
      "step": 14086
    },
    {
      "epoch": 0.8356270020168466,
      "grad_norm": 5.406590461730957,
      "learning_rate": 3.652781439493805e-06,
      "loss": 0.1982,
      "step": 14087
    },
    {
      "epoch": 0.8356863210345237,
      "grad_norm": 0.1574576199054718,
      "learning_rate": 3.6514632217242293e-06,
      "loss": 0.0025,
      "step": 14088
    },
    {
      "epoch": 0.8357456400522008,
      "grad_norm": 31.12705421447754,
      "learning_rate": 3.650145003954654e-06,
      "loss": 1.8561,
      "step": 14089
    },
    {
      "epoch": 0.8358049590698778,
      "grad_norm": 0.018566975370049477,
      "learning_rate": 3.648826786185078e-06,
      "loss": 0.0005,
      "step": 14090
    },
    {
      "epoch": 0.8358642780875549,
      "grad_norm": 7.124171257019043,
      "learning_rate": 3.6475085684155027e-06,
      "loss": 0.1085,
      "step": 14091
    },
    {
      "epoch": 0.8359235971052319,
      "grad_norm": 0.048057351261377335,
      "learning_rate": 3.646190350645927e-06,
      "loss": 0.0008,
      "step": 14092
    },
    {
      "epoch": 0.835982916122909,
      "grad_norm": 0.035212304443120956,
      "learning_rate": 3.6448721328763515e-06,
      "loss": 0.0009,
      "step": 14093
    },
    {
      "epoch": 0.8360422351405861,
      "grad_norm": 0.3624460697174072,
      "learning_rate": 3.643553915106776e-06,
      "loss": 0.0032,
      "step": 14094
    },
    {
      "epoch": 0.8361015541582631,
      "grad_norm": 1.9796319007873535,
      "learning_rate": 3.6422356973372003e-06,
      "loss": 0.0177,
      "step": 14095
    },
    {
      "epoch": 0.8361608731759402,
      "grad_norm": 20.960508346557617,
      "learning_rate": 3.640917479567625e-06,
      "loss": 1.4482,
      "step": 14096
    },
    {
      "epoch": 0.8362201921936173,
      "grad_norm": 0.7085520029067993,
      "learning_rate": 3.639599261798049e-06,
      "loss": 0.0052,
      "step": 14097
    },
    {
      "epoch": 0.8362795112112943,
      "grad_norm": 0.05441833287477493,
      "learning_rate": 3.6382810440284737e-06,
      "loss": 0.0013,
      "step": 14098
    },
    {
      "epoch": 0.8363388302289714,
      "grad_norm": 0.013867799192667007,
      "learning_rate": 3.6369628262588987e-06,
      "loss": 0.0003,
      "step": 14099
    },
    {
      "epoch": 0.8363981492466485,
      "grad_norm": 0.015245635062456131,
      "learning_rate": 3.6356446084893225e-06,
      "loss": 0.0004,
      "step": 14100
    },
    {
      "epoch": 0.8364574682643255,
      "grad_norm": 18.627792358398438,
      "learning_rate": 3.6343263907197475e-06,
      "loss": 0.6857,
      "step": 14101
    },
    {
      "epoch": 0.8365167872820026,
      "grad_norm": 0.04086145758628845,
      "learning_rate": 3.6330081729501717e-06,
      "loss": 0.0008,
      "step": 14102
    },
    {
      "epoch": 0.8365761062996797,
      "grad_norm": 13.333832740783691,
      "learning_rate": 3.6316899551805963e-06,
      "loss": 0.4275,
      "step": 14103
    },
    {
      "epoch": 0.8366354253173568,
      "grad_norm": 25.99203872680664,
      "learning_rate": 3.6303717374110205e-06,
      "loss": 0.5075,
      "step": 14104
    },
    {
      "epoch": 0.8366947443350338,
      "grad_norm": 8.92617416381836,
      "learning_rate": 3.629053519641445e-06,
      "loss": 0.1383,
      "step": 14105
    },
    {
      "epoch": 0.8367540633527109,
      "grad_norm": 0.31862735748291016,
      "learning_rate": 3.6277353018718697e-06,
      "loss": 0.0026,
      "step": 14106
    },
    {
      "epoch": 0.8368133823703879,
      "grad_norm": 0.6330101490020752,
      "learning_rate": 3.626417084102294e-06,
      "loss": 0.0122,
      "step": 14107
    },
    {
      "epoch": 0.836872701388065,
      "grad_norm": 0.01155869010835886,
      "learning_rate": 3.6250988663327185e-06,
      "loss": 0.0003,
      "step": 14108
    },
    {
      "epoch": 0.8369320204057421,
      "grad_norm": 0.31956908106803894,
      "learning_rate": 3.6237806485631427e-06,
      "loss": 0.0057,
      "step": 14109
    },
    {
      "epoch": 0.8369913394234192,
      "grad_norm": 0.06604770570993423,
      "learning_rate": 3.6224624307935673e-06,
      "loss": 0.0013,
      "step": 14110
    },
    {
      "epoch": 0.8370506584410962,
      "grad_norm": 0.11514901369810104,
      "learning_rate": 3.621144213023992e-06,
      "loss": 0.0029,
      "step": 14111
    },
    {
      "epoch": 0.8371099774587732,
      "grad_norm": 0.7953546643257141,
      "learning_rate": 3.619825995254416e-06,
      "loss": 0.0071,
      "step": 14112
    },
    {
      "epoch": 0.8371692964764503,
      "grad_norm": 2.1467397212982178,
      "learning_rate": 3.618507777484841e-06,
      "loss": 0.011,
      "step": 14113
    },
    {
      "epoch": 0.8372286154941274,
      "grad_norm": 3.116819381713867,
      "learning_rate": 3.617189559715265e-06,
      "loss": 0.046,
      "step": 14114
    },
    {
      "epoch": 0.8372879345118045,
      "grad_norm": 0.21008534729480743,
      "learning_rate": 3.61587134194569e-06,
      "loss": 0.0027,
      "step": 14115
    },
    {
      "epoch": 0.8373472535294816,
      "grad_norm": 1.5400850772857666,
      "learning_rate": 3.614553124176114e-06,
      "loss": 0.0219,
      "step": 14116
    },
    {
      "epoch": 0.8374065725471587,
      "grad_norm": 0.48853829503059387,
      "learning_rate": 3.6132349064065387e-06,
      "loss": 0.0105,
      "step": 14117
    },
    {
      "epoch": 0.8374658915648356,
      "grad_norm": 6.76456356048584,
      "learning_rate": 3.6119166886369633e-06,
      "loss": 0.1037,
      "step": 14118
    },
    {
      "epoch": 0.8375252105825127,
      "grad_norm": 5.329463958740234,
      "learning_rate": 3.6105984708673875e-06,
      "loss": 0.143,
      "step": 14119
    },
    {
      "epoch": 0.8375845296001898,
      "grad_norm": 11.307626724243164,
      "learning_rate": 3.609280253097812e-06,
      "loss": 0.1995,
      "step": 14120
    },
    {
      "epoch": 0.8376438486178669,
      "grad_norm": 0.07935306429862976,
      "learning_rate": 3.6079620353282363e-06,
      "loss": 0.0009,
      "step": 14121
    },
    {
      "epoch": 0.837703167635544,
      "grad_norm": 4.93430233001709,
      "learning_rate": 3.606643817558661e-06,
      "loss": 0.0331,
      "step": 14122
    },
    {
      "epoch": 0.8377624866532211,
      "grad_norm": 2.6905269622802734,
      "learning_rate": 3.6053255997890855e-06,
      "loss": 0.0373,
      "step": 14123
    },
    {
      "epoch": 0.8378218056708981,
      "grad_norm": 0.651944637298584,
      "learning_rate": 3.6040073820195097e-06,
      "loss": 0.0102,
      "step": 14124
    },
    {
      "epoch": 0.8378811246885751,
      "grad_norm": 9.069808006286621,
      "learning_rate": 3.6026891642499343e-06,
      "loss": 0.2646,
      "step": 14125
    },
    {
      "epoch": 0.8379404437062522,
      "grad_norm": 37.307594299316406,
      "learning_rate": 3.6013709464803585e-06,
      "loss": 0.5953,
      "step": 14126
    },
    {
      "epoch": 0.8379997627239293,
      "grad_norm": 0.3458903133869171,
      "learning_rate": 3.6000527287107836e-06,
      "loss": 0.0046,
      "step": 14127
    },
    {
      "epoch": 0.8380590817416064,
      "grad_norm": 0.18178784847259521,
      "learning_rate": 3.5987345109412073e-06,
      "loss": 0.0011,
      "step": 14128
    },
    {
      "epoch": 0.8381184007592835,
      "grad_norm": 4.830526351928711,
      "learning_rate": 3.5974162931716324e-06,
      "loss": 0.0602,
      "step": 14129
    },
    {
      "epoch": 0.8381777197769605,
      "grad_norm": 0.08395799249410629,
      "learning_rate": 3.596098075402057e-06,
      "loss": 0.0016,
      "step": 14130
    },
    {
      "epoch": 0.8382370387946375,
      "grad_norm": 13.042595863342285,
      "learning_rate": 3.594779857632481e-06,
      "loss": 0.5205,
      "step": 14131
    },
    {
      "epoch": 0.8382963578123146,
      "grad_norm": 0.43285050988197327,
      "learning_rate": 3.5934616398629058e-06,
      "loss": 0.0069,
      "step": 14132
    },
    {
      "epoch": 0.8383556768299917,
      "grad_norm": 5.881247043609619,
      "learning_rate": 3.59214342209333e-06,
      "loss": 0.0615,
      "step": 14133
    },
    {
      "epoch": 0.8384149958476688,
      "grad_norm": 0.03431083634495735,
      "learning_rate": 3.5908252043237546e-06,
      "loss": 0.0005,
      "step": 14134
    },
    {
      "epoch": 0.8384743148653458,
      "grad_norm": 0.12675327062606812,
      "learning_rate": 3.589506986554179e-06,
      "loss": 0.0014,
      "step": 14135
    },
    {
      "epoch": 0.8385336338830229,
      "grad_norm": 2.0367348194122314,
      "learning_rate": 3.5881887687846034e-06,
      "loss": 0.0379,
      "step": 14136
    },
    {
      "epoch": 0.8385929529007,
      "grad_norm": 2.119372844696045,
      "learning_rate": 3.586870551015028e-06,
      "loss": 0.0053,
      "step": 14137
    },
    {
      "epoch": 0.838652271918377,
      "grad_norm": 2.647108793258667,
      "learning_rate": 3.585552333245452e-06,
      "loss": 0.0357,
      "step": 14138
    },
    {
      "epoch": 0.8387115909360541,
      "grad_norm": 2.5448083877563477,
      "learning_rate": 3.5842341154758768e-06,
      "loss": 0.03,
      "step": 14139
    },
    {
      "epoch": 0.8387709099537312,
      "grad_norm": 0.6031339764595032,
      "learning_rate": 3.582915897706301e-06,
      "loss": 0.0042,
      "step": 14140
    },
    {
      "epoch": 0.8388302289714082,
      "grad_norm": 0.03138820081949234,
      "learning_rate": 3.581597679936726e-06,
      "loss": 0.0008,
      "step": 14141
    },
    {
      "epoch": 0.8388895479890853,
      "grad_norm": 0.039696794003248215,
      "learning_rate": 3.5802794621671506e-06,
      "loss": 0.0005,
      "step": 14142
    },
    {
      "epoch": 0.8389488670067624,
      "grad_norm": 0.19554878771305084,
      "learning_rate": 3.578961244397575e-06,
      "loss": 0.0014,
      "step": 14143
    },
    {
      "epoch": 0.8390081860244394,
      "grad_norm": 5.853902816772461,
      "learning_rate": 3.5776430266279994e-06,
      "loss": 0.1266,
      "step": 14144
    },
    {
      "epoch": 0.8390675050421165,
      "grad_norm": 0.0353286936879158,
      "learning_rate": 3.5763248088584236e-06,
      "loss": 0.001,
      "step": 14145
    },
    {
      "epoch": 0.8391268240597936,
      "grad_norm": 0.1656612753868103,
      "learning_rate": 3.575006591088848e-06,
      "loss": 0.0019,
      "step": 14146
    },
    {
      "epoch": 0.8391861430774706,
      "grad_norm": 3.833883047103882,
      "learning_rate": 3.573688373319273e-06,
      "loss": 0.0544,
      "step": 14147
    },
    {
      "epoch": 0.8392454620951477,
      "grad_norm": 0.005178188439458609,
      "learning_rate": 3.572370155549697e-06,
      "loss": 0.0002,
      "step": 14148
    },
    {
      "epoch": 0.8393047811128248,
      "grad_norm": 0.005576806142926216,
      "learning_rate": 3.5710519377801216e-06,
      "loss": 0.0002,
      "step": 14149
    },
    {
      "epoch": 0.8393641001305019,
      "grad_norm": 9.40937614440918,
      "learning_rate": 3.569733720010546e-06,
      "loss": 0.2852,
      "step": 14150
    },
    {
      "epoch": 0.8394234191481789,
      "grad_norm": 11.685208320617676,
      "learning_rate": 3.5684155022409704e-06,
      "loss": 0.4031,
      "step": 14151
    },
    {
      "epoch": 0.839482738165856,
      "grad_norm": 0.08052276819944382,
      "learning_rate": 3.5670972844713946e-06,
      "loss": 0.0016,
      "step": 14152
    },
    {
      "epoch": 0.839542057183533,
      "grad_norm": 38.44205856323242,
      "learning_rate": 3.565779066701819e-06,
      "loss": 0.9374,
      "step": 14153
    },
    {
      "epoch": 0.8396013762012101,
      "grad_norm": 0.030765080824494362,
      "learning_rate": 3.5644608489322442e-06,
      "loss": 0.0008,
      "step": 14154
    },
    {
      "epoch": 0.8396606952188872,
      "grad_norm": 0.12087851762771606,
      "learning_rate": 3.5631426311626684e-06,
      "loss": 0.0021,
      "step": 14155
    },
    {
      "epoch": 0.8397200142365643,
      "grad_norm": 21.73584747314453,
      "learning_rate": 3.561824413393093e-06,
      "loss": 0.9427,
      "step": 14156
    },
    {
      "epoch": 0.8397793332542413,
      "grad_norm": 0.01294714491814375,
      "learning_rate": 3.5605061956235172e-06,
      "loss": 0.0004,
      "step": 14157
    },
    {
      "epoch": 0.8398386522719183,
      "grad_norm": 0.9779831171035767,
      "learning_rate": 3.559187977853942e-06,
      "loss": 0.0186,
      "step": 14158
    },
    {
      "epoch": 0.8398979712895954,
      "grad_norm": 0.12787564098834991,
      "learning_rate": 3.5578697600843664e-06,
      "loss": 0.0025,
      "step": 14159
    },
    {
      "epoch": 0.8399572903072725,
      "grad_norm": 0.15502549707889557,
      "learning_rate": 3.5565515423147906e-06,
      "loss": 0.0024,
      "step": 14160
    },
    {
      "epoch": 0.8400166093249496,
      "grad_norm": 0.01049916073679924,
      "learning_rate": 3.5552333245452152e-06,
      "loss": 0.0003,
      "step": 14161
    },
    {
      "epoch": 0.8400759283426267,
      "grad_norm": 3.507883071899414,
      "learning_rate": 3.5539151067756394e-06,
      "loss": 0.0936,
      "step": 14162
    },
    {
      "epoch": 0.8401352473603038,
      "grad_norm": 1.240217924118042,
      "learning_rate": 3.552596889006064e-06,
      "loss": 0.0137,
      "step": 14163
    },
    {
      "epoch": 0.8401945663779807,
      "grad_norm": 0.8478336334228516,
      "learning_rate": 3.5512786712364882e-06,
      "loss": 0.009,
      "step": 14164
    },
    {
      "epoch": 0.8402538853956578,
      "grad_norm": 13.66795825958252,
      "learning_rate": 3.549960453466913e-06,
      "loss": 0.236,
      "step": 14165
    },
    {
      "epoch": 0.8403132044133349,
      "grad_norm": 7.614997863769531,
      "learning_rate": 3.548642235697338e-06,
      "loss": 0.0872,
      "step": 14166
    },
    {
      "epoch": 0.840372523431012,
      "grad_norm": 13.534796714782715,
      "learning_rate": 3.5473240179277616e-06,
      "loss": 0.0433,
      "step": 14167
    },
    {
      "epoch": 0.8404318424486891,
      "grad_norm": 12.901901245117188,
      "learning_rate": 3.5460058001581867e-06,
      "loss": 0.4965,
      "step": 14168
    },
    {
      "epoch": 0.8404911614663662,
      "grad_norm": 0.16227811574935913,
      "learning_rate": 3.544687582388611e-06,
      "loss": 0.0024,
      "step": 14169
    },
    {
      "epoch": 0.8405504804840432,
      "grad_norm": 0.3416188359260559,
      "learning_rate": 3.5433693646190355e-06,
      "loss": 0.0046,
      "step": 14170
    },
    {
      "epoch": 0.8406097995017202,
      "grad_norm": 7.458450794219971,
      "learning_rate": 3.54205114684946e-06,
      "loss": 0.273,
      "step": 14171
    },
    {
      "epoch": 0.8406691185193973,
      "grad_norm": 0.4995586574077606,
      "learning_rate": 3.5407329290798843e-06,
      "loss": 0.0074,
      "step": 14172
    },
    {
      "epoch": 0.8407284375370744,
      "grad_norm": 17.508193969726562,
      "learning_rate": 3.539414711310309e-06,
      "loss": 0.3668,
      "step": 14173
    },
    {
      "epoch": 0.8407877565547515,
      "grad_norm": 6.440041542053223,
      "learning_rate": 3.538096493540733e-06,
      "loss": 0.1938,
      "step": 14174
    },
    {
      "epoch": 0.8408470755724285,
      "grad_norm": 19.180883407592773,
      "learning_rate": 3.5367782757711577e-06,
      "loss": 0.542,
      "step": 14175
    },
    {
      "epoch": 0.8409063945901056,
      "grad_norm": 0.1900220513343811,
      "learning_rate": 3.535460058001582e-06,
      "loss": 0.0027,
      "step": 14176
    },
    {
      "epoch": 0.8409657136077826,
      "grad_norm": 6.337923526763916,
      "learning_rate": 3.5341418402320065e-06,
      "loss": 0.1049,
      "step": 14177
    },
    {
      "epoch": 0.8410250326254597,
      "grad_norm": 29.284563064575195,
      "learning_rate": 3.532823622462431e-06,
      "loss": 0.0663,
      "step": 14178
    },
    {
      "epoch": 0.8410843516431368,
      "grad_norm": 0.16754905879497528,
      "learning_rate": 3.5315054046928553e-06,
      "loss": 0.0023,
      "step": 14179
    },
    {
      "epoch": 0.8411436706608139,
      "grad_norm": 0.34402912855148315,
      "learning_rate": 3.5301871869232803e-06,
      "loss": 0.003,
      "step": 14180
    },
    {
      "epoch": 0.8412029896784909,
      "grad_norm": 0.0018824277212843299,
      "learning_rate": 3.528868969153704e-06,
      "loss": 0.0001,
      "step": 14181
    },
    {
      "epoch": 0.841262308696168,
      "grad_norm": 11.305416107177734,
      "learning_rate": 3.527550751384129e-06,
      "loss": 0.5891,
      "step": 14182
    },
    {
      "epoch": 0.8413216277138451,
      "grad_norm": 1.4830242395401,
      "learning_rate": 3.5262325336145537e-06,
      "loss": 0.0045,
      "step": 14183
    },
    {
      "epoch": 0.8413809467315221,
      "grad_norm": 0.015452753752470016,
      "learning_rate": 3.524914315844978e-06,
      "loss": 0.0004,
      "step": 14184
    },
    {
      "epoch": 0.8414402657491992,
      "grad_norm": 0.8197407722473145,
      "learning_rate": 3.5235960980754025e-06,
      "loss": 0.0079,
      "step": 14185
    },
    {
      "epoch": 0.8414995847668763,
      "grad_norm": 8.590372085571289,
      "learning_rate": 3.5222778803058267e-06,
      "loss": 0.8667,
      "step": 14186
    },
    {
      "epoch": 0.8415589037845533,
      "grad_norm": 0.0197567418217659,
      "learning_rate": 3.5209596625362513e-06,
      "loss": 0.0003,
      "step": 14187
    },
    {
      "epoch": 0.8416182228022304,
      "grad_norm": 9.13428783416748,
      "learning_rate": 3.519641444766676e-06,
      "loss": 0.5758,
      "step": 14188
    },
    {
      "epoch": 0.8416775418199075,
      "grad_norm": 11.675477027893066,
      "learning_rate": 3.5183232269971e-06,
      "loss": 0.1571,
      "step": 14189
    },
    {
      "epoch": 0.8417368608375845,
      "grad_norm": 1.517530083656311,
      "learning_rate": 3.5170050092275247e-06,
      "loss": 0.026,
      "step": 14190
    },
    {
      "epoch": 0.8417961798552616,
      "grad_norm": 23.674283981323242,
      "learning_rate": 3.515686791457949e-06,
      "loss": 0.2591,
      "step": 14191
    },
    {
      "epoch": 0.8418554988729386,
      "grad_norm": 0.4236392080783844,
      "learning_rate": 3.5143685736883735e-06,
      "loss": 0.0041,
      "step": 14192
    },
    {
      "epoch": 0.8419148178906157,
      "grad_norm": 4.7874860763549805,
      "learning_rate": 3.5130503559187977e-06,
      "loss": 0.0641,
      "step": 14193
    },
    {
      "epoch": 0.8419741369082928,
      "grad_norm": 1.925752878189087,
      "learning_rate": 3.5117321381492227e-06,
      "loss": 0.0331,
      "step": 14194
    },
    {
      "epoch": 0.8420334559259699,
      "grad_norm": 1.6578208208084106,
      "learning_rate": 3.5104139203796473e-06,
      "loss": 0.0247,
      "step": 14195
    },
    {
      "epoch": 0.842092774943647,
      "grad_norm": 4.630001544952393,
      "learning_rate": 3.5090957026100715e-06,
      "loss": 0.1245,
      "step": 14196
    },
    {
      "epoch": 0.842152093961324,
      "grad_norm": 11.038619041442871,
      "learning_rate": 3.507777484840496e-06,
      "loss": 0.7032,
      "step": 14197
    },
    {
      "epoch": 0.842211412979001,
      "grad_norm": 9.327375411987305,
      "learning_rate": 3.5064592670709203e-06,
      "loss": 0.5772,
      "step": 14198
    },
    {
      "epoch": 0.8422707319966781,
      "grad_norm": 0.03789632394909859,
      "learning_rate": 3.505141049301345e-06,
      "loss": 0.001,
      "step": 14199
    },
    {
      "epoch": 0.8423300510143552,
      "grad_norm": 0.008379597216844559,
      "learning_rate": 3.5038228315317696e-06,
      "loss": 0.0002,
      "step": 14200
    },
    {
      "epoch": 0.8423893700320323,
      "grad_norm": 0.811791718006134,
      "learning_rate": 3.5025046137621937e-06,
      "loss": 0.014,
      "step": 14201
    },
    {
      "epoch": 0.8424486890497094,
      "grad_norm": 6.43278694152832,
      "learning_rate": 3.5011863959926183e-06,
      "loss": 0.1365,
      "step": 14202
    },
    {
      "epoch": 0.8425080080673863,
      "grad_norm": 0.6409287452697754,
      "learning_rate": 3.4998681782230425e-06,
      "loss": 0.0087,
      "step": 14203
    },
    {
      "epoch": 0.8425673270850634,
      "grad_norm": 13.803221702575684,
      "learning_rate": 3.498549960453467e-06,
      "loss": 0.2811,
      "step": 14204
    },
    {
      "epoch": 0.8426266461027405,
      "grad_norm": 24.218538284301758,
      "learning_rate": 3.4972317426838913e-06,
      "loss": 0.878,
      "step": 14205
    },
    {
      "epoch": 0.8426859651204176,
      "grad_norm": 0.005866807885468006,
      "learning_rate": 3.495913524914316e-06,
      "loss": 0.0002,
      "step": 14206
    },
    {
      "epoch": 0.8427452841380947,
      "grad_norm": 1.4114129543304443,
      "learning_rate": 3.494595307144741e-06,
      "loss": 0.0129,
      "step": 14207
    },
    {
      "epoch": 0.8428046031557718,
      "grad_norm": 9.621227264404297,
      "learning_rate": 3.493277089375165e-06,
      "loss": 0.0606,
      "step": 14208
    },
    {
      "epoch": 0.8428639221734489,
      "grad_norm": 7.763022422790527,
      "learning_rate": 3.4919588716055898e-06,
      "loss": 0.2452,
      "step": 14209
    },
    {
      "epoch": 0.8429232411911258,
      "grad_norm": 0.37132030725479126,
      "learning_rate": 3.490640653836014e-06,
      "loss": 0.0053,
      "step": 14210
    },
    {
      "epoch": 0.8429825602088029,
      "grad_norm": 0.015309605747461319,
      "learning_rate": 3.4893224360664386e-06,
      "loss": 0.0003,
      "step": 14211
    },
    {
      "epoch": 0.84304187922648,
      "grad_norm": 0.021095069125294685,
      "learning_rate": 3.488004218296863e-06,
      "loss": 0.0006,
      "step": 14212
    },
    {
      "epoch": 0.8431011982441571,
      "grad_norm": 7.358588218688965,
      "learning_rate": 3.4866860005272874e-06,
      "loss": 0.3323,
      "step": 14213
    },
    {
      "epoch": 0.8431605172618342,
      "grad_norm": 11.980957984924316,
      "learning_rate": 3.485367782757712e-06,
      "loss": 0.6566,
      "step": 14214
    },
    {
      "epoch": 0.8432198362795112,
      "grad_norm": 0.3481934666633606,
      "learning_rate": 3.484049564988136e-06,
      "loss": 0.0033,
      "step": 14215
    },
    {
      "epoch": 0.8432791552971883,
      "grad_norm": 0.049109380692243576,
      "learning_rate": 3.4827313472185608e-06,
      "loss": 0.0006,
      "step": 14216
    },
    {
      "epoch": 0.8433384743148653,
      "grad_norm": 6.796210765838623,
      "learning_rate": 3.481413129448985e-06,
      "loss": 0.0673,
      "step": 14217
    },
    {
      "epoch": 0.8433977933325424,
      "grad_norm": 0.3188239634037018,
      "learning_rate": 3.4800949116794096e-06,
      "loss": 0.0023,
      "step": 14218
    },
    {
      "epoch": 0.8434571123502195,
      "grad_norm": 0.32278063893318176,
      "learning_rate": 3.4787766939098346e-06,
      "loss": 0.0038,
      "step": 14219
    },
    {
      "epoch": 0.8435164313678966,
      "grad_norm": 14.719673156738281,
      "learning_rate": 3.4774584761402584e-06,
      "loss": 0.1761,
      "step": 14220
    },
    {
      "epoch": 0.8435757503855736,
      "grad_norm": 21.437776565551758,
      "learning_rate": 3.4761402583706834e-06,
      "loss": 0.2619,
      "step": 14221
    },
    {
      "epoch": 0.8436350694032507,
      "grad_norm": 1.439029335975647,
      "learning_rate": 3.4748220406011076e-06,
      "loss": 0.0136,
      "step": 14222
    },
    {
      "epoch": 0.8436943884209277,
      "grad_norm": 0.0224214568734169,
      "learning_rate": 3.473503822831532e-06,
      "loss": 0.0007,
      "step": 14223
    },
    {
      "epoch": 0.8437537074386048,
      "grad_norm": 12.662429809570312,
      "learning_rate": 3.472185605061957e-06,
      "loss": 0.5275,
      "step": 14224
    },
    {
      "epoch": 0.8438130264562819,
      "grad_norm": 0.026143597438931465,
      "learning_rate": 3.470867387292381e-06,
      "loss": 0.0007,
      "step": 14225
    },
    {
      "epoch": 0.843872345473959,
      "grad_norm": 0.01822238601744175,
      "learning_rate": 3.4695491695228056e-06,
      "loss": 0.0005,
      "step": 14226
    },
    {
      "epoch": 0.843931664491636,
      "grad_norm": 0.04856026545166969,
      "learning_rate": 3.46823095175323e-06,
      "loss": 0.0008,
      "step": 14227
    },
    {
      "epoch": 0.8439909835093131,
      "grad_norm": 14.43580150604248,
      "learning_rate": 3.4669127339836544e-06,
      "loss": 0.1558,
      "step": 14228
    },
    {
      "epoch": 0.8440503025269902,
      "grad_norm": 0.06328215450048447,
      "learning_rate": 3.4655945162140786e-06,
      "loss": 0.0008,
      "step": 14229
    },
    {
      "epoch": 0.8441096215446672,
      "grad_norm": 0.03013737127184868,
      "learning_rate": 3.464276298444503e-06,
      "loss": 0.0006,
      "step": 14230
    },
    {
      "epoch": 0.8441689405623443,
      "grad_norm": 5.379077434539795,
      "learning_rate": 3.462958080674928e-06,
      "loss": 0.0757,
      "step": 14231
    },
    {
      "epoch": 0.8442282595800213,
      "grad_norm": 2.9048266410827637,
      "learning_rate": 3.461639862905352e-06,
      "loss": 0.0503,
      "step": 14232
    },
    {
      "epoch": 0.8442875785976984,
      "grad_norm": 0.14732131361961365,
      "learning_rate": 3.460321645135777e-06,
      "loss": 0.003,
      "step": 14233
    },
    {
      "epoch": 0.8443468976153755,
      "grad_norm": 0.3164632320404053,
      "learning_rate": 3.459003427366201e-06,
      "loss": 0.0023,
      "step": 14234
    },
    {
      "epoch": 0.8444062166330526,
      "grad_norm": 3.4262235164642334,
      "learning_rate": 3.457685209596626e-06,
      "loss": 0.0217,
      "step": 14235
    },
    {
      "epoch": 0.8444655356507296,
      "grad_norm": 2.107602596282959,
      "learning_rate": 3.4563669918270505e-06,
      "loss": 0.0201,
      "step": 14236
    },
    {
      "epoch": 0.8445248546684067,
      "grad_norm": 3.1088311672210693,
      "learning_rate": 3.4550487740574746e-06,
      "loss": 0.034,
      "step": 14237
    },
    {
      "epoch": 0.8445841736860837,
      "grad_norm": 3.6448299884796143,
      "learning_rate": 3.4537305562878992e-06,
      "loss": 0.044,
      "step": 14238
    },
    {
      "epoch": 0.8446434927037608,
      "grad_norm": 0.64310222864151,
      "learning_rate": 3.4524123385183234e-06,
      "loss": 0.0093,
      "step": 14239
    },
    {
      "epoch": 0.8447028117214379,
      "grad_norm": 7.365203380584717,
      "learning_rate": 3.451094120748748e-06,
      "loss": 0.1924,
      "step": 14240
    },
    {
      "epoch": 0.844762130739115,
      "grad_norm": 10.934148788452148,
      "learning_rate": 3.4497759029791722e-06,
      "loss": 0.4374,
      "step": 14241
    },
    {
      "epoch": 0.8448214497567921,
      "grad_norm": 0.43234968185424805,
      "learning_rate": 3.448457685209597e-06,
      "loss": 0.0058,
      "step": 14242
    },
    {
      "epoch": 0.844880768774469,
      "grad_norm": 0.28494998812675476,
      "learning_rate": 3.4471394674400215e-06,
      "loss": 0.0031,
      "step": 14243
    },
    {
      "epoch": 0.8449400877921461,
      "grad_norm": 18.372486114501953,
      "learning_rate": 3.4458212496704456e-06,
      "loss": 0.4449,
      "step": 14244
    },
    {
      "epoch": 0.8449994068098232,
      "grad_norm": 13.25248908996582,
      "learning_rate": 3.4445030319008703e-06,
      "loss": 0.1211,
      "step": 14245
    },
    {
      "epoch": 0.8450587258275003,
      "grad_norm": 0.03628974035382271,
      "learning_rate": 3.4431848141312944e-06,
      "loss": 0.0007,
      "step": 14246
    },
    {
      "epoch": 0.8451180448451774,
      "grad_norm": 0.05163763090968132,
      "learning_rate": 3.4418665963617195e-06,
      "loss": 0.0013,
      "step": 14247
    },
    {
      "epoch": 0.8451773638628545,
      "grad_norm": 0.11438276618719101,
      "learning_rate": 3.440548378592144e-06,
      "loss": 0.002,
      "step": 14248
    },
    {
      "epoch": 0.8452366828805316,
      "grad_norm": 0.16678500175476074,
      "learning_rate": 3.4392301608225683e-06,
      "loss": 0.0014,
      "step": 14249
    },
    {
      "epoch": 0.8452960018982085,
      "grad_norm": 0.43642106652259827,
      "learning_rate": 3.437911943052993e-06,
      "loss": 0.0077,
      "step": 14250
    },
    {
      "epoch": 0.8453553209158856,
      "grad_norm": 6.155897617340088,
      "learning_rate": 3.436593725283417e-06,
      "loss": 0.064,
      "step": 14251
    },
    {
      "epoch": 0.8454146399335627,
      "grad_norm": 2.685051441192627,
      "learning_rate": 3.4352755075138417e-06,
      "loss": 0.0572,
      "step": 14252
    },
    {
      "epoch": 0.8454739589512398,
      "grad_norm": 45.628265380859375,
      "learning_rate": 3.433957289744266e-06,
      "loss": 0.339,
      "step": 14253
    },
    {
      "epoch": 0.8455332779689169,
      "grad_norm": 0.12782427668571472,
      "learning_rate": 3.4326390719746905e-06,
      "loss": 0.0014,
      "step": 14254
    },
    {
      "epoch": 0.845592596986594,
      "grad_norm": 0.16885679960250854,
      "learning_rate": 3.431320854205115e-06,
      "loss": 0.0015,
      "step": 14255
    },
    {
      "epoch": 0.8456519160042709,
      "grad_norm": 0.637698769569397,
      "learning_rate": 3.4300026364355393e-06,
      "loss": 0.0076,
      "step": 14256
    },
    {
      "epoch": 0.845711235021948,
      "grad_norm": 10.99201488494873,
      "learning_rate": 3.428684418665964e-06,
      "loss": 0.0699,
      "step": 14257
    },
    {
      "epoch": 0.8457705540396251,
      "grad_norm": 0.277118980884552,
      "learning_rate": 3.427366200896388e-06,
      "loss": 0.0046,
      "step": 14258
    },
    {
      "epoch": 0.8458298730573022,
      "grad_norm": 0.3325394093990326,
      "learning_rate": 3.4260479831268127e-06,
      "loss": 0.0063,
      "step": 14259
    },
    {
      "epoch": 0.8458891920749793,
      "grad_norm": 0.2136799544095993,
      "learning_rate": 3.4247297653572377e-06,
      "loss": 0.0034,
      "step": 14260
    },
    {
      "epoch": 0.8459485110926563,
      "grad_norm": 2.9836857318878174,
      "learning_rate": 3.423411547587662e-06,
      "loss": 0.0441,
      "step": 14261
    },
    {
      "epoch": 0.8460078301103334,
      "grad_norm": 9.420060157775879,
      "learning_rate": 3.4220933298180865e-06,
      "loss": 0.1648,
      "step": 14262
    },
    {
      "epoch": 0.8460671491280104,
      "grad_norm": 10.62784194946289,
      "learning_rate": 3.4207751120485107e-06,
      "loss": 0.1025,
      "step": 14263
    },
    {
      "epoch": 0.8461264681456875,
      "grad_norm": 7.117870807647705,
      "learning_rate": 3.4194568942789353e-06,
      "loss": 0.2517,
      "step": 14264
    },
    {
      "epoch": 0.8461857871633646,
      "grad_norm": 3.753046751022339,
      "learning_rate": 3.4181386765093595e-06,
      "loss": 0.0515,
      "step": 14265
    },
    {
      "epoch": 0.8462451061810417,
      "grad_norm": 0.010924984700977802,
      "learning_rate": 3.416820458739784e-06,
      "loss": 0.0003,
      "step": 14266
    },
    {
      "epoch": 0.8463044251987187,
      "grad_norm": 24.704809188842773,
      "learning_rate": 3.4155022409702087e-06,
      "loss": 0.2687,
      "step": 14267
    },
    {
      "epoch": 0.8463637442163958,
      "grad_norm": 1.3377496004104614,
      "learning_rate": 3.414184023200633e-06,
      "loss": 0.0234,
      "step": 14268
    },
    {
      "epoch": 0.8464230632340728,
      "grad_norm": 6.739783763885498,
      "learning_rate": 3.4128658054310575e-06,
      "loss": 0.2595,
      "step": 14269
    },
    {
      "epoch": 0.8464823822517499,
      "grad_norm": 3.8524985313415527,
      "learning_rate": 3.4115475876614817e-06,
      "loss": 0.0202,
      "step": 14270
    },
    {
      "epoch": 0.846541701269427,
      "grad_norm": 0.004429641645401716,
      "learning_rate": 3.4102293698919063e-06,
      "loss": 0.0002,
      "step": 14271
    },
    {
      "epoch": 0.846601020287104,
      "grad_norm": 0.037873148918151855,
      "learning_rate": 3.4089111521223314e-06,
      "loss": 0.0008,
      "step": 14272
    },
    {
      "epoch": 0.8466603393047811,
      "grad_norm": 0.03255246579647064,
      "learning_rate": 3.407592934352755e-06,
      "loss": 0.0007,
      "step": 14273
    },
    {
      "epoch": 0.8467196583224582,
      "grad_norm": 0.019875161349773407,
      "learning_rate": 3.40627471658318e-06,
      "loss": 0.0006,
      "step": 14274
    },
    {
      "epoch": 0.8467789773401353,
      "grad_norm": 8.640982627868652,
      "learning_rate": 3.4049564988136043e-06,
      "loss": 0.0289,
      "step": 14275
    },
    {
      "epoch": 0.8468382963578123,
      "grad_norm": 7.499806880950928,
      "learning_rate": 3.403638281044029e-06,
      "loss": 0.236,
      "step": 14276
    },
    {
      "epoch": 0.8468976153754894,
      "grad_norm": 1.633683204650879,
      "learning_rate": 3.402320063274453e-06,
      "loss": 0.011,
      "step": 14277
    },
    {
      "epoch": 0.8469569343931664,
      "grad_norm": 0.05500076711177826,
      "learning_rate": 3.4010018455048777e-06,
      "loss": 0.0007,
      "step": 14278
    },
    {
      "epoch": 0.8470162534108435,
      "grad_norm": 0.023668544366955757,
      "learning_rate": 3.3996836277353024e-06,
      "loss": 0.0004,
      "step": 14279
    },
    {
      "epoch": 0.8470755724285206,
      "grad_norm": 15.007716178894043,
      "learning_rate": 3.3983654099657265e-06,
      "loss": 0.0739,
      "step": 14280
    },
    {
      "epoch": 0.8471348914461977,
      "grad_norm": 40.43869400024414,
      "learning_rate": 3.397047192196151e-06,
      "loss": 0.9141,
      "step": 14281
    },
    {
      "epoch": 0.8471942104638747,
      "grad_norm": 37.80596160888672,
      "learning_rate": 3.3957289744265753e-06,
      "loss": 0.472,
      "step": 14282
    },
    {
      "epoch": 0.8472535294815517,
      "grad_norm": 8.067939758300781,
      "learning_rate": 3.394410756657e-06,
      "loss": 0.0324,
      "step": 14283
    },
    {
      "epoch": 0.8473128484992288,
      "grad_norm": 2.564216375350952,
      "learning_rate": 3.3930925388874246e-06,
      "loss": 0.0199,
      "step": 14284
    },
    {
      "epoch": 0.8473721675169059,
      "grad_norm": 27.236820220947266,
      "learning_rate": 3.3917743211178487e-06,
      "loss": 0.1448,
      "step": 14285
    },
    {
      "epoch": 0.847431486534583,
      "grad_norm": 0.21333098411560059,
      "learning_rate": 3.3904561033482738e-06,
      "loss": 0.0044,
      "step": 14286
    },
    {
      "epoch": 0.8474908055522601,
      "grad_norm": 3.2705514430999756,
      "learning_rate": 3.3891378855786975e-06,
      "loss": 0.0327,
      "step": 14287
    },
    {
      "epoch": 0.8475501245699372,
      "grad_norm": 0.16099238395690918,
      "learning_rate": 3.3878196678091226e-06,
      "loss": 0.0019,
      "step": 14288
    },
    {
      "epoch": 0.8476094435876141,
      "grad_norm": 0.02321402169764042,
      "learning_rate": 3.3865014500395468e-06,
      "loss": 0.0003,
      "step": 14289
    },
    {
      "epoch": 0.8476687626052912,
      "grad_norm": 0.46741607785224915,
      "learning_rate": 3.3851832322699714e-06,
      "loss": 0.0039,
      "step": 14290
    },
    {
      "epoch": 0.8477280816229683,
      "grad_norm": 4.08051061630249,
      "learning_rate": 3.383865014500396e-06,
      "loss": 0.0199,
      "step": 14291
    },
    {
      "epoch": 0.8477874006406454,
      "grad_norm": 0.1389440894126892,
      "learning_rate": 3.38254679673082e-06,
      "loss": 0.0025,
      "step": 14292
    },
    {
      "epoch": 0.8478467196583225,
      "grad_norm": 1.3980721235275269,
      "learning_rate": 3.3812285789612448e-06,
      "loss": 0.0097,
      "step": 14293
    },
    {
      "epoch": 0.8479060386759996,
      "grad_norm": 0.02992354705929756,
      "learning_rate": 3.379910361191669e-06,
      "loss": 0.0009,
      "step": 14294
    },
    {
      "epoch": 0.8479653576936766,
      "grad_norm": 0.7766921520233154,
      "learning_rate": 3.3785921434220936e-06,
      "loss": 0.0075,
      "step": 14295
    },
    {
      "epoch": 0.8480246767113536,
      "grad_norm": 0.02449856698513031,
      "learning_rate": 3.377273925652518e-06,
      "loss": 0.0005,
      "step": 14296
    },
    {
      "epoch": 0.8480839957290307,
      "grad_norm": 35.349159240722656,
      "learning_rate": 3.3759557078829424e-06,
      "loss": 0.2707,
      "step": 14297
    },
    {
      "epoch": 0.8481433147467078,
      "grad_norm": 3.5546634197235107,
      "learning_rate": 3.374637490113367e-06,
      "loss": 0.0238,
      "step": 14298
    },
    {
      "epoch": 0.8482026337643849,
      "grad_norm": 16.76447296142578,
      "learning_rate": 3.373319272343791e-06,
      "loss": 0.9526,
      "step": 14299
    },
    {
      "epoch": 0.848261952782062,
      "grad_norm": 0.8617632389068604,
      "learning_rate": 3.3720010545742162e-06,
      "loss": 0.0088,
      "step": 14300
    },
    {
      "epoch": 0.848321271799739,
      "grad_norm": 1.4693470001220703,
      "learning_rate": 3.37068283680464e-06,
      "loss": 0.0183,
      "step": 14301
    },
    {
      "epoch": 0.848380590817416,
      "grad_norm": 3.9150869846343994,
      "learning_rate": 3.369364619035065e-06,
      "loss": 0.0517,
      "step": 14302
    },
    {
      "epoch": 0.8484399098350931,
      "grad_norm": 11.059171676635742,
      "learning_rate": 3.3680464012654896e-06,
      "loss": 0.0767,
      "step": 14303
    },
    {
      "epoch": 0.8484992288527702,
      "grad_norm": 28.99686622619629,
      "learning_rate": 3.366728183495914e-06,
      "loss": 0.2281,
      "step": 14304
    },
    {
      "epoch": 0.8485585478704473,
      "grad_norm": 0.019011517986655235,
      "learning_rate": 3.3654099657263384e-06,
      "loss": 0.0005,
      "step": 14305
    },
    {
      "epoch": 0.8486178668881244,
      "grad_norm": 0.8491003513336182,
      "learning_rate": 3.3640917479567626e-06,
      "loss": 0.0192,
      "step": 14306
    },
    {
      "epoch": 0.8486771859058014,
      "grad_norm": 0.11594302952289581,
      "learning_rate": 3.3627735301871872e-06,
      "loss": 0.0013,
      "step": 14307
    },
    {
      "epoch": 0.8487365049234785,
      "grad_norm": 2.284367322921753,
      "learning_rate": 3.361455312417612e-06,
      "loss": 0.0229,
      "step": 14308
    },
    {
      "epoch": 0.8487958239411555,
      "grad_norm": 0.050929538905620575,
      "learning_rate": 3.360137094648036e-06,
      "loss": 0.0009,
      "step": 14309
    },
    {
      "epoch": 0.8488551429588326,
      "grad_norm": 4.975837707519531,
      "learning_rate": 3.3588188768784606e-06,
      "loss": 0.1828,
      "step": 14310
    },
    {
      "epoch": 0.8489144619765097,
      "grad_norm": 1.2802387475967407,
      "learning_rate": 3.357500659108885e-06,
      "loss": 0.0192,
      "step": 14311
    },
    {
      "epoch": 0.8489737809941867,
      "grad_norm": 5.5337138175964355,
      "learning_rate": 3.3561824413393094e-06,
      "loss": 0.0941,
      "step": 14312
    },
    {
      "epoch": 0.8490331000118638,
      "grad_norm": 0.5602502226829529,
      "learning_rate": 3.3548642235697336e-06,
      "loss": 0.0087,
      "step": 14313
    },
    {
      "epoch": 0.8490924190295409,
      "grad_norm": 0.06778635829687119,
      "learning_rate": 3.3535460058001586e-06,
      "loss": 0.0013,
      "step": 14314
    },
    {
      "epoch": 0.8491517380472179,
      "grad_norm": 27.732162475585938,
      "learning_rate": 3.3522277880305833e-06,
      "loss": 0.1449,
      "step": 14315
    },
    {
      "epoch": 0.849211057064895,
      "grad_norm": 10.4786958694458,
      "learning_rate": 3.3509095702610074e-06,
      "loss": 0.1752,
      "step": 14316
    },
    {
      "epoch": 0.849270376082572,
      "grad_norm": 3.671902894973755,
      "learning_rate": 3.349591352491432e-06,
      "loss": 0.1469,
      "step": 14317
    },
    {
      "epoch": 0.8493296951002491,
      "grad_norm": 0.7901146411895752,
      "learning_rate": 3.3482731347218562e-06,
      "loss": 0.0095,
      "step": 14318
    },
    {
      "epoch": 0.8493890141179262,
      "grad_norm": 0.027237478643655777,
      "learning_rate": 3.346954916952281e-06,
      "loss": 0.0007,
      "step": 14319
    },
    {
      "epoch": 0.8494483331356033,
      "grad_norm": 0.3375214636325836,
      "learning_rate": 3.3456366991827055e-06,
      "loss": 0.0049,
      "step": 14320
    },
    {
      "epoch": 0.8495076521532804,
      "grad_norm": 11.052855491638184,
      "learning_rate": 3.3443184814131296e-06,
      "loss": 0.9604,
      "step": 14321
    },
    {
      "epoch": 0.8495669711709574,
      "grad_norm": 0.06624317914247513,
      "learning_rate": 3.3430002636435543e-06,
      "loss": 0.0009,
      "step": 14322
    },
    {
      "epoch": 0.8496262901886344,
      "grad_norm": 0.8689485192298889,
      "learning_rate": 3.3416820458739784e-06,
      "loss": 0.0095,
      "step": 14323
    },
    {
      "epoch": 0.8496856092063115,
      "grad_norm": 0.0730099081993103,
      "learning_rate": 3.340363828104403e-06,
      "loss": 0.0011,
      "step": 14324
    },
    {
      "epoch": 0.8497449282239886,
      "grad_norm": 19.1868953704834,
      "learning_rate": 3.3390456103348272e-06,
      "loss": 0.7321,
      "step": 14325
    },
    {
      "epoch": 0.8498042472416657,
      "grad_norm": 5.53788948059082,
      "learning_rate": 3.337727392565252e-06,
      "loss": 0.0241,
      "step": 14326
    },
    {
      "epoch": 0.8498635662593428,
      "grad_norm": 0.5563011765480042,
      "learning_rate": 3.336409174795677e-06,
      "loss": 0.0069,
      "step": 14327
    },
    {
      "epoch": 0.8499228852770198,
      "grad_norm": 0.05435450002551079,
      "learning_rate": 3.3350909570261007e-06,
      "loss": 0.0011,
      "step": 14328
    },
    {
      "epoch": 0.8499822042946968,
      "grad_norm": 0.020517665892839432,
      "learning_rate": 3.3337727392565257e-06,
      "loss": 0.0004,
      "step": 14329
    },
    {
      "epoch": 0.8500415233123739,
      "grad_norm": 5.787346363067627,
      "learning_rate": 3.33245452148695e-06,
      "loss": 0.0727,
      "step": 14330
    },
    {
      "epoch": 0.850100842330051,
      "grad_norm": 1.5615044832229614,
      "learning_rate": 3.3311363037173745e-06,
      "loss": 0.0182,
      "step": 14331
    },
    {
      "epoch": 0.8501601613477281,
      "grad_norm": 23.16911506652832,
      "learning_rate": 3.329818085947799e-06,
      "loss": 1.153,
      "step": 14332
    },
    {
      "epoch": 0.8502194803654052,
      "grad_norm": 0.18011419475078583,
      "learning_rate": 3.3284998681782233e-06,
      "loss": 0.002,
      "step": 14333
    },
    {
      "epoch": 0.8502787993830823,
      "grad_norm": 2.3689892292022705,
      "learning_rate": 3.327181650408648e-06,
      "loss": 0.1433,
      "step": 14334
    },
    {
      "epoch": 0.8503381184007592,
      "grad_norm": 0.04110250249505043,
      "learning_rate": 3.325863432639072e-06,
      "loss": 0.0008,
      "step": 14335
    },
    {
      "epoch": 0.8503974374184363,
      "grad_norm": 4.673984527587891,
      "learning_rate": 3.3245452148694967e-06,
      "loss": 0.1615,
      "step": 14336
    },
    {
      "epoch": 0.8504567564361134,
      "grad_norm": 1.215179681777954,
      "learning_rate": 3.323226997099921e-06,
      "loss": 0.0136,
      "step": 14337
    },
    {
      "epoch": 0.8505160754537905,
      "grad_norm": 4.083569049835205,
      "learning_rate": 3.3219087793303455e-06,
      "loss": 0.0678,
      "step": 14338
    },
    {
      "epoch": 0.8505753944714676,
      "grad_norm": 0.39790821075439453,
      "learning_rate": 3.3205905615607705e-06,
      "loss": 0.0052,
      "step": 14339
    },
    {
      "epoch": 0.8506347134891447,
      "grad_norm": 0.005540038924664259,
      "learning_rate": 3.3192723437911943e-06,
      "loss": 0.0002,
      "step": 14340
    },
    {
      "epoch": 0.8506940325068217,
      "grad_norm": 25.478511810302734,
      "learning_rate": 3.3179541260216193e-06,
      "loss": 1.0284,
      "step": 14341
    },
    {
      "epoch": 0.8507533515244987,
      "grad_norm": 0.14570122957229614,
      "learning_rate": 3.316635908252043e-06,
      "loss": 0.0016,
      "step": 14342
    },
    {
      "epoch": 0.8508126705421758,
      "grad_norm": 0.44577720761299133,
      "learning_rate": 3.315317690482468e-06,
      "loss": 0.0048,
      "step": 14343
    },
    {
      "epoch": 0.8508719895598529,
      "grad_norm": 0.8796427249908447,
      "learning_rate": 3.3139994727128927e-06,
      "loss": 0.0108,
      "step": 14344
    },
    {
      "epoch": 0.85093130857753,
      "grad_norm": 0.08158571273088455,
      "learning_rate": 3.312681254943317e-06,
      "loss": 0.0012,
      "step": 14345
    },
    {
      "epoch": 0.850990627595207,
      "grad_norm": 3.989091157913208,
      "learning_rate": 3.3113630371737415e-06,
      "loss": 0.043,
      "step": 14346
    },
    {
      "epoch": 0.8510499466128841,
      "grad_norm": 19.806793212890625,
      "learning_rate": 3.3100448194041657e-06,
      "loss": 0.2413,
      "step": 14347
    },
    {
      "epoch": 0.8511092656305611,
      "grad_norm": 0.12110406905412674,
      "learning_rate": 3.3087266016345903e-06,
      "loss": 0.0016,
      "step": 14348
    },
    {
      "epoch": 0.8511685846482382,
      "grad_norm": 1.9503576755523682,
      "learning_rate": 3.3074083838650145e-06,
      "loss": 0.0269,
      "step": 14349
    },
    {
      "epoch": 0.8512279036659153,
      "grad_norm": 6.355948448181152,
      "learning_rate": 3.306090166095439e-06,
      "loss": 0.1312,
      "step": 14350
    },
    {
      "epoch": 0.8512872226835924,
      "grad_norm": 1.931411623954773,
      "learning_rate": 3.3047719483258637e-06,
      "loss": 0.0139,
      "step": 14351
    },
    {
      "epoch": 0.8513465417012694,
      "grad_norm": 0.004142872057855129,
      "learning_rate": 3.303453730556288e-06,
      "loss": 0.0002,
      "step": 14352
    },
    {
      "epoch": 0.8514058607189465,
      "grad_norm": 0.4100884199142456,
      "learning_rate": 3.3021355127867125e-06,
      "loss": 0.0026,
      "step": 14353
    },
    {
      "epoch": 0.8514651797366236,
      "grad_norm": 6.380255699157715,
      "learning_rate": 3.3008172950171367e-06,
      "loss": 0.0867,
      "step": 14354
    },
    {
      "epoch": 0.8515244987543006,
      "grad_norm": 0.2132694274187088,
      "learning_rate": 3.2994990772475617e-06,
      "loss": 0.0037,
      "step": 14355
    },
    {
      "epoch": 0.8515838177719777,
      "grad_norm": 7.302882671356201,
      "learning_rate": 3.2981808594779864e-06,
      "loss": 0.4253,
      "step": 14356
    },
    {
      "epoch": 0.8516431367896548,
      "grad_norm": 7.617633819580078,
      "learning_rate": 3.2968626417084105e-06,
      "loss": 0.0468,
      "step": 14357
    },
    {
      "epoch": 0.8517024558073318,
      "grad_norm": 16.085758209228516,
      "learning_rate": 3.295544423938835e-06,
      "loss": 0.3981,
      "step": 14358
    },
    {
      "epoch": 0.8517617748250089,
      "grad_norm": 11.30716323852539,
      "learning_rate": 3.2942262061692593e-06,
      "loss": 0.5721,
      "step": 14359
    },
    {
      "epoch": 0.851821093842686,
      "grad_norm": 0.01150242518633604,
      "learning_rate": 3.292907988399684e-06,
      "loss": 0.0003,
      "step": 14360
    },
    {
      "epoch": 0.851880412860363,
      "grad_norm": 2.6397812366485596,
      "learning_rate": 3.291589770630108e-06,
      "loss": 0.0077,
      "step": 14361
    },
    {
      "epoch": 0.8519397318780401,
      "grad_norm": 0.017455045133829117,
      "learning_rate": 3.2902715528605328e-06,
      "loss": 0.0003,
      "step": 14362
    },
    {
      "epoch": 0.8519990508957171,
      "grad_norm": 6.502827167510986,
      "learning_rate": 3.2889533350909574e-06,
      "loss": 0.0723,
      "step": 14363
    },
    {
      "epoch": 0.8520583699133942,
      "grad_norm": 0.17806033790111542,
      "learning_rate": 3.2876351173213816e-06,
      "loss": 0.0018,
      "step": 14364
    },
    {
      "epoch": 0.8521176889310713,
      "grad_norm": 64.50608825683594,
      "learning_rate": 3.286316899551806e-06,
      "loss": 0.3422,
      "step": 14365
    },
    {
      "epoch": 0.8521770079487484,
      "grad_norm": 0.027659790590405464,
      "learning_rate": 3.2849986817822303e-06,
      "loss": 0.0006,
      "step": 14366
    },
    {
      "epoch": 0.8522363269664255,
      "grad_norm": 32.574729919433594,
      "learning_rate": 3.283680464012655e-06,
      "loss": 0.8268,
      "step": 14367
    },
    {
      "epoch": 0.8522956459841025,
      "grad_norm": 0.7999895215034485,
      "learning_rate": 3.28236224624308e-06,
      "loss": 0.0046,
      "step": 14368
    },
    {
      "epoch": 0.8523549650017795,
      "grad_norm": 0.8266226053237915,
      "learning_rate": 3.281044028473504e-06,
      "loss": 0.0072,
      "step": 14369
    },
    {
      "epoch": 0.8524142840194566,
      "grad_norm": 9.34388542175293,
      "learning_rate": 3.279725810703929e-06,
      "loss": 0.0388,
      "step": 14370
    },
    {
      "epoch": 0.8524736030371337,
      "grad_norm": 0.05873195827007294,
      "learning_rate": 3.278407592934353e-06,
      "loss": 0.0012,
      "step": 14371
    },
    {
      "epoch": 0.8525329220548108,
      "grad_norm": 1.7901816368103027,
      "learning_rate": 3.2770893751647776e-06,
      "loss": 0.0237,
      "step": 14372
    },
    {
      "epoch": 0.8525922410724879,
      "grad_norm": 3.986311912536621,
      "learning_rate": 3.2757711573952018e-06,
      "loss": 0.0349,
      "step": 14373
    },
    {
      "epoch": 0.852651560090165,
      "grad_norm": 4.011343955993652,
      "learning_rate": 3.2744529396256264e-06,
      "loss": 0.0176,
      "step": 14374
    },
    {
      "epoch": 0.8527108791078419,
      "grad_norm": 0.2885354459285736,
      "learning_rate": 3.273134721856051e-06,
      "loss": 0.0039,
      "step": 14375
    },
    {
      "epoch": 0.852770198125519,
      "grad_norm": 0.8820585012435913,
      "learning_rate": 3.271816504086475e-06,
      "loss": 0.0092,
      "step": 14376
    },
    {
      "epoch": 0.8528295171431961,
      "grad_norm": 0.10436062514781952,
      "learning_rate": 3.2704982863169e-06,
      "loss": 0.0011,
      "step": 14377
    },
    {
      "epoch": 0.8528888361608732,
      "grad_norm": 0.012153439223766327,
      "learning_rate": 3.269180068547324e-06,
      "loss": 0.0003,
      "step": 14378
    },
    {
      "epoch": 0.8529481551785503,
      "grad_norm": 19.643535614013672,
      "learning_rate": 3.2678618507777486e-06,
      "loss": 0.2006,
      "step": 14379
    },
    {
      "epoch": 0.8530074741962274,
      "grad_norm": 8.102413177490234,
      "learning_rate": 3.2665436330081736e-06,
      "loss": 0.0711,
      "step": 14380
    },
    {
      "epoch": 0.8530667932139043,
      "grad_norm": 0.6923276782035828,
      "learning_rate": 3.2652254152385974e-06,
      "loss": 0.003,
      "step": 14381
    },
    {
      "epoch": 0.8531261122315814,
      "grad_norm": 10.260136604309082,
      "learning_rate": 3.2639071974690224e-06,
      "loss": 0.3209,
      "step": 14382
    },
    {
      "epoch": 0.8531854312492585,
      "grad_norm": 22.586959838867188,
      "learning_rate": 3.2625889796994466e-06,
      "loss": 0.5415,
      "step": 14383
    },
    {
      "epoch": 0.8532447502669356,
      "grad_norm": 1.2840996980667114,
      "learning_rate": 3.2612707619298712e-06,
      "loss": 0.0136,
      "step": 14384
    },
    {
      "epoch": 0.8533040692846127,
      "grad_norm": 4.592519760131836,
      "learning_rate": 3.2599525441602954e-06,
      "loss": 0.0252,
      "step": 14385
    },
    {
      "epoch": 0.8533633883022897,
      "grad_norm": 0.017478862777352333,
      "learning_rate": 3.25863432639072e-06,
      "loss": 0.0004,
      "step": 14386
    },
    {
      "epoch": 0.8534227073199668,
      "grad_norm": 13.583747863769531,
      "learning_rate": 3.2573161086211446e-06,
      "loss": 0.6986,
      "step": 14387
    },
    {
      "epoch": 0.8534820263376438,
      "grad_norm": 0.45676305890083313,
      "learning_rate": 3.255997890851569e-06,
      "loss": 0.0046,
      "step": 14388
    },
    {
      "epoch": 0.8535413453553209,
      "grad_norm": 4.020635604858398,
      "learning_rate": 3.2546796730819934e-06,
      "loss": 0.0557,
      "step": 14389
    },
    {
      "epoch": 0.853600664372998,
      "grad_norm": 1.6476290225982666,
      "learning_rate": 3.2533614553124176e-06,
      "loss": 0.0617,
      "step": 14390
    },
    {
      "epoch": 0.8536599833906751,
      "grad_norm": 0.022310175001621246,
      "learning_rate": 3.2520432375428422e-06,
      "loss": 0.0005,
      "step": 14391
    },
    {
      "epoch": 0.8537193024083521,
      "grad_norm": 0.09652270376682281,
      "learning_rate": 3.250725019773267e-06,
      "loss": 0.0012,
      "step": 14392
    },
    {
      "epoch": 0.8537786214260292,
      "grad_norm": 8.560340881347656,
      "learning_rate": 3.249406802003691e-06,
      "loss": 0.2862,
      "step": 14393
    },
    {
      "epoch": 0.8538379404437062,
      "grad_norm": 0.14174683392047882,
      "learning_rate": 3.248088584234116e-06,
      "loss": 0.0011,
      "step": 14394
    },
    {
      "epoch": 0.8538972594613833,
      "grad_norm": 20.425920486450195,
      "learning_rate": 3.24677036646454e-06,
      "loss": 0.7956,
      "step": 14395
    },
    {
      "epoch": 0.8539565784790604,
      "grad_norm": 0.03713536635041237,
      "learning_rate": 3.245452148694965e-06,
      "loss": 0.0006,
      "step": 14396
    },
    {
      "epoch": 0.8540158974967375,
      "grad_norm": 8.098549842834473,
      "learning_rate": 3.244133930925389e-06,
      "loss": 0.0365,
      "step": 14397
    },
    {
      "epoch": 0.8540752165144145,
      "grad_norm": 0.13921897113323212,
      "learning_rate": 3.2428157131558137e-06,
      "loss": 0.0015,
      "step": 14398
    },
    {
      "epoch": 0.8541345355320916,
      "grad_norm": 0.05163589119911194,
      "learning_rate": 3.2414974953862383e-06,
      "loss": 0.0011,
      "step": 14399
    },
    {
      "epoch": 0.8541938545497687,
      "grad_norm": 0.33925938606262207,
      "learning_rate": 3.2401792776166625e-06,
      "loss": 0.0028,
      "step": 14400
    },
    {
      "epoch": 0.8542531735674457,
      "grad_norm": 0.012371806427836418,
      "learning_rate": 3.238861059847087e-06,
      "loss": 0.0002,
      "step": 14401
    },
    {
      "epoch": 0.8543124925851228,
      "grad_norm": 1.0060980319976807,
      "learning_rate": 3.2375428420775112e-06,
      "loss": 0.0156,
      "step": 14402
    },
    {
      "epoch": 0.8543718116027998,
      "grad_norm": 1.5953389406204224,
      "learning_rate": 3.236224624307936e-06,
      "loss": 0.0307,
      "step": 14403
    },
    {
      "epoch": 0.8544311306204769,
      "grad_norm": 5.485569000244141,
      "learning_rate": 3.2349064065383605e-06,
      "loss": 0.2712,
      "step": 14404
    },
    {
      "epoch": 0.854490449638154,
      "grad_norm": 0.0015078274300321937,
      "learning_rate": 3.2335881887687847e-06,
      "loss": 0.0001,
      "step": 14405
    },
    {
      "epoch": 0.8545497686558311,
      "grad_norm": 0.103409044444561,
      "learning_rate": 3.2322699709992093e-06,
      "loss": 0.0011,
      "step": 14406
    },
    {
      "epoch": 0.8546090876735081,
      "grad_norm": 0.01568027026951313,
      "learning_rate": 3.2309517532296335e-06,
      "loss": 0.0004,
      "step": 14407
    },
    {
      "epoch": 0.8546684066911852,
      "grad_norm": 0.6131553053855896,
      "learning_rate": 3.2296335354600585e-06,
      "loss": 0.0099,
      "step": 14408
    },
    {
      "epoch": 0.8547277257088622,
      "grad_norm": 7.843026638031006,
      "learning_rate": 3.228315317690483e-06,
      "loss": 0.124,
      "step": 14409
    },
    {
      "epoch": 0.8547870447265393,
      "grad_norm": 0.7842404842376709,
      "learning_rate": 3.2269970999209073e-06,
      "loss": 0.0032,
      "step": 14410
    },
    {
      "epoch": 0.8548463637442164,
      "grad_norm": 15.930829048156738,
      "learning_rate": 3.225678882151332e-06,
      "loss": 0.1243,
      "step": 14411
    },
    {
      "epoch": 0.8549056827618935,
      "grad_norm": 0.1233678087592125,
      "learning_rate": 3.224360664381756e-06,
      "loss": 0.001,
      "step": 14412
    },
    {
      "epoch": 0.8549650017795706,
      "grad_norm": 5.09110689163208,
      "learning_rate": 3.2230424466121807e-06,
      "loss": 0.1329,
      "step": 14413
    },
    {
      "epoch": 0.8550243207972476,
      "grad_norm": 24.74594497680664,
      "learning_rate": 3.221724228842605e-06,
      "loss": 1.2067,
      "step": 14414
    },
    {
      "epoch": 0.8550836398149246,
      "grad_norm": 40.177974700927734,
      "learning_rate": 3.2204060110730295e-06,
      "loss": 0.3097,
      "step": 14415
    },
    {
      "epoch": 0.8551429588326017,
      "grad_norm": 3.141829490661621,
      "learning_rate": 3.219087793303454e-06,
      "loss": 0.0662,
      "step": 14416
    },
    {
      "epoch": 0.8552022778502788,
      "grad_norm": 24.040843963623047,
      "learning_rate": 3.2177695755338783e-06,
      "loss": 0.212,
      "step": 14417
    },
    {
      "epoch": 0.8552615968679559,
      "grad_norm": 0.7195907831192017,
      "learning_rate": 3.216451357764303e-06,
      "loss": 0.0106,
      "step": 14418
    },
    {
      "epoch": 0.855320915885633,
      "grad_norm": 14.992803573608398,
      "learning_rate": 3.215133139994727e-06,
      "loss": 0.1506,
      "step": 14419
    },
    {
      "epoch": 0.85538023490331,
      "grad_norm": 0.2184576392173767,
      "learning_rate": 3.2138149222251517e-06,
      "loss": 0.0034,
      "step": 14420
    },
    {
      "epoch": 0.855439553920987,
      "grad_norm": 0.38586121797561646,
      "learning_rate": 3.2124967044555767e-06,
      "loss": 0.0049,
      "step": 14421
    },
    {
      "epoch": 0.8554988729386641,
      "grad_norm": 3.122929573059082,
      "learning_rate": 3.211178486686001e-06,
      "loss": 0.0111,
      "step": 14422
    },
    {
      "epoch": 0.8555581919563412,
      "grad_norm": 0.06598362326622009,
      "learning_rate": 3.2098602689164255e-06,
      "loss": 0.0008,
      "step": 14423
    },
    {
      "epoch": 0.8556175109740183,
      "grad_norm": 0.41449931263923645,
      "learning_rate": 3.2085420511468497e-06,
      "loss": 0.0051,
      "step": 14424
    },
    {
      "epoch": 0.8556768299916954,
      "grad_norm": 10.040593147277832,
      "learning_rate": 3.2072238333772743e-06,
      "loss": 0.9231,
      "step": 14425
    },
    {
      "epoch": 0.8557361490093724,
      "grad_norm": 0.2077888697385788,
      "learning_rate": 3.2059056156076985e-06,
      "loss": 0.0027,
      "step": 14426
    },
    {
      "epoch": 0.8557954680270494,
      "grad_norm": 6.120983600616455,
      "learning_rate": 3.204587397838123e-06,
      "loss": 0.3712,
      "step": 14427
    },
    {
      "epoch": 0.8558547870447265,
      "grad_norm": 0.9868871569633484,
      "learning_rate": 3.2032691800685477e-06,
      "loss": 0.0135,
      "step": 14428
    },
    {
      "epoch": 0.8559141060624036,
      "grad_norm": 3.8304450511932373,
      "learning_rate": 3.201950962298972e-06,
      "loss": 0.0371,
      "step": 14429
    },
    {
      "epoch": 0.8559734250800807,
      "grad_norm": 3.513472557067871,
      "learning_rate": 3.2006327445293965e-06,
      "loss": 0.1969,
      "step": 14430
    },
    {
      "epoch": 0.8560327440977578,
      "grad_norm": 1.5460968017578125,
      "learning_rate": 3.1993145267598207e-06,
      "loss": 0.0179,
      "step": 14431
    },
    {
      "epoch": 0.8560920631154348,
      "grad_norm": 1.2456145286560059,
      "learning_rate": 3.1979963089902453e-06,
      "loss": 0.0043,
      "step": 14432
    },
    {
      "epoch": 0.8561513821331119,
      "grad_norm": 1.8376942873001099,
      "learning_rate": 3.1966780912206704e-06,
      "loss": 0.0147,
      "step": 14433
    },
    {
      "epoch": 0.8562107011507889,
      "grad_norm": 0.17726244032382965,
      "learning_rate": 3.195359873451094e-06,
      "loss": 0.002,
      "step": 14434
    },
    {
      "epoch": 0.856270020168466,
      "grad_norm": 18.056608200073242,
      "learning_rate": 3.194041655681519e-06,
      "loss": 0.2153,
      "step": 14435
    },
    {
      "epoch": 0.8563293391861431,
      "grad_norm": 9.851987838745117,
      "learning_rate": 3.1927234379119434e-06,
      "loss": 0.5581,
      "step": 14436
    },
    {
      "epoch": 0.8563886582038202,
      "grad_norm": 14.233369827270508,
      "learning_rate": 3.191405220142368e-06,
      "loss": 1.1294,
      "step": 14437
    },
    {
      "epoch": 0.8564479772214972,
      "grad_norm": 0.18668729066848755,
      "learning_rate": 3.190087002372792e-06,
      "loss": 0.0011,
      "step": 14438
    },
    {
      "epoch": 0.8565072962391743,
      "grad_norm": 6.13067626953125,
      "learning_rate": 3.1887687846032168e-06,
      "loss": 0.0281,
      "step": 14439
    },
    {
      "epoch": 0.8565666152568513,
      "grad_norm": 3.207594633102417,
      "learning_rate": 3.1874505668336414e-06,
      "loss": 0.1341,
      "step": 14440
    },
    {
      "epoch": 0.8566259342745284,
      "grad_norm": 1.954103946685791,
      "learning_rate": 3.1861323490640656e-06,
      "loss": 0.0133,
      "step": 14441
    },
    {
      "epoch": 0.8566852532922055,
      "grad_norm": 0.028066016733646393,
      "learning_rate": 3.18481413129449e-06,
      "loss": 0.0005,
      "step": 14442
    },
    {
      "epoch": 0.8567445723098825,
      "grad_norm": 0.039801064878702164,
      "learning_rate": 3.1834959135249144e-06,
      "loss": 0.0007,
      "step": 14443
    },
    {
      "epoch": 0.8568038913275596,
      "grad_norm": 0.052780911326408386,
      "learning_rate": 3.182177695755339e-06,
      "loss": 0.0008,
      "step": 14444
    },
    {
      "epoch": 0.8568632103452367,
      "grad_norm": 0.9950230121612549,
      "learning_rate": 3.1808594779857636e-06,
      "loss": 0.0102,
      "step": 14445
    },
    {
      "epoch": 0.8569225293629138,
      "grad_norm": 5.385002613067627,
      "learning_rate": 3.1795412602161878e-06,
      "loss": 0.0236,
      "step": 14446
    },
    {
      "epoch": 0.8569818483805908,
      "grad_norm": 7.716256618499756,
      "learning_rate": 3.178223042446613e-06,
      "loss": 0.1116,
      "step": 14447
    },
    {
      "epoch": 0.8570411673982679,
      "grad_norm": 0.20697665214538574,
      "learning_rate": 3.1769048246770366e-06,
      "loss": 0.0023,
      "step": 14448
    },
    {
      "epoch": 0.8571004864159449,
      "grad_norm": 0.22316624224185944,
      "learning_rate": 3.1755866069074616e-06,
      "loss": 0.0033,
      "step": 14449
    },
    {
      "epoch": 0.857159805433622,
      "grad_norm": 4.956856727600098,
      "learning_rate": 3.1742683891378858e-06,
      "loss": 0.1967,
      "step": 14450
    },
    {
      "epoch": 0.8572191244512991,
      "grad_norm": 0.5918257236480713,
      "learning_rate": 3.1729501713683104e-06,
      "loss": 0.007,
      "step": 14451
    },
    {
      "epoch": 0.8572784434689762,
      "grad_norm": 0.008444112725555897,
      "learning_rate": 3.171631953598735e-06,
      "loss": 0.0002,
      "step": 14452
    },
    {
      "epoch": 0.8573377624866533,
      "grad_norm": 41.165977478027344,
      "learning_rate": 3.170313735829159e-06,
      "loss": 0.2398,
      "step": 14453
    },
    {
      "epoch": 0.8573970815043302,
      "grad_norm": 5.052577495574951,
      "learning_rate": 3.168995518059584e-06,
      "loss": 0.1769,
      "step": 14454
    },
    {
      "epoch": 0.8574564005220073,
      "grad_norm": 0.1102675125002861,
      "learning_rate": 3.167677300290008e-06,
      "loss": 0.0018,
      "step": 14455
    },
    {
      "epoch": 0.8575157195396844,
      "grad_norm": 0.8053746223449707,
      "learning_rate": 3.1663590825204326e-06,
      "loss": 0.0074,
      "step": 14456
    },
    {
      "epoch": 0.8575750385573615,
      "grad_norm": 2.139906406402588,
      "learning_rate": 3.165040864750857e-06,
      "loss": 0.0059,
      "step": 14457
    },
    {
      "epoch": 0.8576343575750386,
      "grad_norm": 0.10227473825216293,
      "learning_rate": 3.1637226469812814e-06,
      "loss": 0.0019,
      "step": 14458
    },
    {
      "epoch": 0.8576936765927157,
      "grad_norm": 13.857222557067871,
      "learning_rate": 3.162404429211706e-06,
      "loss": 0.6868,
      "step": 14459
    },
    {
      "epoch": 0.8577529956103926,
      "grad_norm": 40.30680847167969,
      "learning_rate": 3.16108621144213e-06,
      "loss": 0.4811,
      "step": 14460
    },
    {
      "epoch": 0.8578123146280697,
      "grad_norm": 0.018695132806897163,
      "learning_rate": 3.1597679936725552e-06,
      "loss": 0.0004,
      "step": 14461
    },
    {
      "epoch": 0.8578716336457468,
      "grad_norm": 13.139625549316406,
      "learning_rate": 3.158449775902979e-06,
      "loss": 0.6577,
      "step": 14462
    },
    {
      "epoch": 0.8579309526634239,
      "grad_norm": 0.11583967506885529,
      "learning_rate": 3.157131558133404e-06,
      "loss": 0.0015,
      "step": 14463
    },
    {
      "epoch": 0.857990271681101,
      "grad_norm": 3.735569953918457,
      "learning_rate": 3.1558133403638286e-06,
      "loss": 0.0356,
      "step": 14464
    },
    {
      "epoch": 0.8580495906987781,
      "grad_norm": 4.080489635467529,
      "learning_rate": 3.154495122594253e-06,
      "loss": 0.0695,
      "step": 14465
    },
    {
      "epoch": 0.8581089097164551,
      "grad_norm": 0.07223338633775711,
      "learning_rate": 3.1531769048246774e-06,
      "loss": 0.0008,
      "step": 14466
    },
    {
      "epoch": 0.8581682287341321,
      "grad_norm": 9.157388687133789,
      "learning_rate": 3.1518586870551016e-06,
      "loss": 0.2348,
      "step": 14467
    },
    {
      "epoch": 0.8582275477518092,
      "grad_norm": 4.756988525390625,
      "learning_rate": 3.1505404692855262e-06,
      "loss": 0.1586,
      "step": 14468
    },
    {
      "epoch": 0.8582868667694863,
      "grad_norm": 0.013320439495146275,
      "learning_rate": 3.149222251515951e-06,
      "loss": 0.0005,
      "step": 14469
    },
    {
      "epoch": 0.8583461857871634,
      "grad_norm": 13.003307342529297,
      "learning_rate": 3.147904033746375e-06,
      "loss": 0.0454,
      "step": 14470
    },
    {
      "epoch": 0.8584055048048405,
      "grad_norm": 51.56447219848633,
      "learning_rate": 3.1465858159767996e-06,
      "loss": 0.462,
      "step": 14471
    },
    {
      "epoch": 0.8584648238225175,
      "grad_norm": 0.20137153565883636,
      "learning_rate": 3.145267598207224e-06,
      "loss": 0.0027,
      "step": 14472
    },
    {
      "epoch": 0.8585241428401945,
      "grad_norm": 0.23143699765205383,
      "learning_rate": 3.1439493804376484e-06,
      "loss": 0.0027,
      "step": 14473
    },
    {
      "epoch": 0.8585834618578716,
      "grad_norm": 0.020778080448508263,
      "learning_rate": 3.1426311626680726e-06,
      "loss": 0.0006,
      "step": 14474
    },
    {
      "epoch": 0.8586427808755487,
      "grad_norm": 0.03238910064101219,
      "learning_rate": 3.1413129448984977e-06,
      "loss": 0.0005,
      "step": 14475
    },
    {
      "epoch": 0.8587020998932258,
      "grad_norm": 3.561781406402588,
      "learning_rate": 3.1399947271289223e-06,
      "loss": 0.0206,
      "step": 14476
    },
    {
      "epoch": 0.8587614189109029,
      "grad_norm": 0.6063280701637268,
      "learning_rate": 3.1386765093593465e-06,
      "loss": 0.0068,
      "step": 14477
    },
    {
      "epoch": 0.8588207379285799,
      "grad_norm": 0.01392065454274416,
      "learning_rate": 3.137358291589771e-06,
      "loss": 0.0002,
      "step": 14478
    },
    {
      "epoch": 0.858880056946257,
      "grad_norm": 0.003907732665538788,
      "learning_rate": 3.1360400738201953e-06,
      "loss": 0.0001,
      "step": 14479
    },
    {
      "epoch": 0.858939375963934,
      "grad_norm": 7.233703136444092,
      "learning_rate": 3.13472185605062e-06,
      "loss": 0.286,
      "step": 14480
    },
    {
      "epoch": 0.8589986949816111,
      "grad_norm": 0.09048065543174744,
      "learning_rate": 3.1334036382810445e-06,
      "loss": 0.0015,
      "step": 14481
    },
    {
      "epoch": 0.8590580139992882,
      "grad_norm": 0.054776884615421295,
      "learning_rate": 3.1320854205114687e-06,
      "loss": 0.001,
      "step": 14482
    },
    {
      "epoch": 0.8591173330169652,
      "grad_norm": 13.663345336914062,
      "learning_rate": 3.1307672027418933e-06,
      "loss": 0.1215,
      "step": 14483
    },
    {
      "epoch": 0.8591766520346423,
      "grad_norm": 50.5064811706543,
      "learning_rate": 3.1294489849723175e-06,
      "loss": 0.9662,
      "step": 14484
    },
    {
      "epoch": 0.8592359710523194,
      "grad_norm": 4.668673992156982,
      "learning_rate": 3.128130767202742e-06,
      "loss": 0.1216,
      "step": 14485
    },
    {
      "epoch": 0.8592952900699964,
      "grad_norm": 0.04250166192650795,
      "learning_rate": 3.1268125494331663e-06,
      "loss": 0.001,
      "step": 14486
    },
    {
      "epoch": 0.8593546090876735,
      "grad_norm": 0.3429744839668274,
      "learning_rate": 3.125494331663591e-06,
      "loss": 0.0052,
      "step": 14487
    },
    {
      "epoch": 0.8594139281053506,
      "grad_norm": 8.47547721862793,
      "learning_rate": 3.124176113894016e-06,
      "loss": 0.038,
      "step": 14488
    },
    {
      "epoch": 0.8594732471230276,
      "grad_norm": 0.017518799751996994,
      "learning_rate": 3.12285789612444e-06,
      "loss": 0.0005,
      "step": 14489
    },
    {
      "epoch": 0.8595325661407047,
      "grad_norm": 5.004058361053467,
      "learning_rate": 3.1215396783548647e-06,
      "loss": 0.0513,
      "step": 14490
    },
    {
      "epoch": 0.8595918851583818,
      "grad_norm": 3.763378381729126,
      "learning_rate": 3.120221460585289e-06,
      "loss": 0.0513,
      "step": 14491
    },
    {
      "epoch": 0.8596512041760589,
      "grad_norm": 0.012585224583745003,
      "learning_rate": 3.1189032428157135e-06,
      "loss": 0.0003,
      "step": 14492
    },
    {
      "epoch": 0.8597105231937359,
      "grad_norm": 0.007306922227144241,
      "learning_rate": 3.117585025046138e-06,
      "loss": 0.0003,
      "step": 14493
    },
    {
      "epoch": 0.859769842211413,
      "grad_norm": 2.5756022930145264,
      "learning_rate": 3.1162668072765623e-06,
      "loss": 0.0257,
      "step": 14494
    },
    {
      "epoch": 0.85982916122909,
      "grad_norm": 0.6058613657951355,
      "learning_rate": 3.114948589506987e-06,
      "loss": 0.0054,
      "step": 14495
    },
    {
      "epoch": 0.8598884802467671,
      "grad_norm": 2.9560024738311768,
      "learning_rate": 3.113630371737411e-06,
      "loss": 0.0405,
      "step": 14496
    },
    {
      "epoch": 0.8599477992644442,
      "grad_norm": 3.5743649005889893,
      "learning_rate": 3.1123121539678357e-06,
      "loss": 0.025,
      "step": 14497
    },
    {
      "epoch": 0.8600071182821213,
      "grad_norm": 9.773076057434082,
      "learning_rate": 3.11099393619826e-06,
      "loss": 0.4643,
      "step": 14498
    },
    {
      "epoch": 0.8600664372997984,
      "grad_norm": 15.475176811218262,
      "learning_rate": 3.1096757184286845e-06,
      "loss": 0.8768,
      "step": 14499
    },
    {
      "epoch": 0.8601257563174753,
      "grad_norm": 8.858296394348145,
      "learning_rate": 3.1083575006591095e-06,
      "loss": 0.2111,
      "step": 14500
    },
    {
      "epoch": 0.8601850753351524,
      "grad_norm": 3.011788845062256,
      "learning_rate": 3.1070392828895333e-06,
      "loss": 0.0349,
      "step": 14501
    },
    {
      "epoch": 0.8602443943528295,
      "grad_norm": 2.1978111267089844,
      "learning_rate": 3.1057210651199583e-06,
      "loss": 0.0201,
      "step": 14502
    },
    {
      "epoch": 0.8603037133705066,
      "grad_norm": 0.15244750678539276,
      "learning_rate": 3.1044028473503825e-06,
      "loss": 0.0032,
      "step": 14503
    },
    {
      "epoch": 0.8603630323881837,
      "grad_norm": 0.07494986057281494,
      "learning_rate": 3.103084629580807e-06,
      "loss": 0.0011,
      "step": 14504
    },
    {
      "epoch": 0.8604223514058608,
      "grad_norm": 10.458244323730469,
      "learning_rate": 3.1017664118112317e-06,
      "loss": 0.2727,
      "step": 14505
    },
    {
      "epoch": 0.8604816704235377,
      "grad_norm": 4.33577299118042,
      "learning_rate": 3.100448194041656e-06,
      "loss": 0.1112,
      "step": 14506
    },
    {
      "epoch": 0.8605409894412148,
      "grad_norm": 18.605369567871094,
      "learning_rate": 3.0991299762720805e-06,
      "loss": 0.5859,
      "step": 14507
    },
    {
      "epoch": 0.8606003084588919,
      "grad_norm": 0.04219512268900871,
      "learning_rate": 3.0978117585025047e-06,
      "loss": 0.0008,
      "step": 14508
    },
    {
      "epoch": 0.860659627476569,
      "grad_norm": 1.1307111978530884,
      "learning_rate": 3.0964935407329293e-06,
      "loss": 0.0111,
      "step": 14509
    },
    {
      "epoch": 0.8607189464942461,
      "grad_norm": 0.11982858926057816,
      "learning_rate": 3.0951753229633535e-06,
      "loss": 0.0016,
      "step": 14510
    },
    {
      "epoch": 0.8607782655119232,
      "grad_norm": 0.07709326595067978,
      "learning_rate": 3.093857105193778e-06,
      "loss": 0.0012,
      "step": 14511
    },
    {
      "epoch": 0.8608375845296002,
      "grad_norm": 0.20386438071727753,
      "learning_rate": 3.0925388874242027e-06,
      "loss": 0.0031,
      "step": 14512
    },
    {
      "epoch": 0.8608969035472772,
      "grad_norm": 7.323721408843994,
      "learning_rate": 3.091220669654627e-06,
      "loss": 0.1294,
      "step": 14513
    },
    {
      "epoch": 0.8609562225649543,
      "grad_norm": 7.975712299346924,
      "learning_rate": 3.089902451885052e-06,
      "loss": 0.1209,
      "step": 14514
    },
    {
      "epoch": 0.8610155415826314,
      "grad_norm": 2.2340786457061768,
      "learning_rate": 3.0885842341154757e-06,
      "loss": 0.0183,
      "step": 14515
    },
    {
      "epoch": 0.8610748606003085,
      "grad_norm": 0.22880077362060547,
      "learning_rate": 3.0872660163459008e-06,
      "loss": 0.0029,
      "step": 14516
    },
    {
      "epoch": 0.8611341796179856,
      "grad_norm": 0.006022653076797724,
      "learning_rate": 3.0859477985763254e-06,
      "loss": 0.0002,
      "step": 14517
    },
    {
      "epoch": 0.8611934986356626,
      "grad_norm": 0.503441572189331,
      "learning_rate": 3.0846295808067496e-06,
      "loss": 0.0036,
      "step": 14518
    },
    {
      "epoch": 0.8612528176533396,
      "grad_norm": 1.1464509963989258,
      "learning_rate": 3.083311363037174e-06,
      "loss": 0.0137,
      "step": 14519
    },
    {
      "epoch": 0.8613121366710167,
      "grad_norm": 0.10925692319869995,
      "learning_rate": 3.0819931452675984e-06,
      "loss": 0.0017,
      "step": 14520
    },
    {
      "epoch": 0.8613714556886938,
      "grad_norm": 0.18187567591667175,
      "learning_rate": 3.080674927498023e-06,
      "loss": 0.001,
      "step": 14521
    },
    {
      "epoch": 0.8614307747063709,
      "grad_norm": 16.82048225402832,
      "learning_rate": 3.079356709728447e-06,
      "loss": 0.4266,
      "step": 14522
    },
    {
      "epoch": 0.861490093724048,
      "grad_norm": 0.673840343952179,
      "learning_rate": 3.0780384919588718e-06,
      "loss": 0.0091,
      "step": 14523
    },
    {
      "epoch": 0.861549412741725,
      "grad_norm": 0.490471750497818,
      "learning_rate": 3.0767202741892964e-06,
      "loss": 0.0025,
      "step": 14524
    },
    {
      "epoch": 0.8616087317594021,
      "grad_norm": 0.13381053507328033,
      "learning_rate": 3.0754020564197206e-06,
      "loss": 0.0027,
      "step": 14525
    },
    {
      "epoch": 0.8616680507770791,
      "grad_norm": 3.235548496246338,
      "learning_rate": 3.074083838650145e-06,
      "loss": 0.0325,
      "step": 14526
    },
    {
      "epoch": 0.8617273697947562,
      "grad_norm": 4.460057258605957,
      "learning_rate": 3.0727656208805694e-06,
      "loss": 0.0643,
      "step": 14527
    },
    {
      "epoch": 0.8617866888124333,
      "grad_norm": 2.970216989517212,
      "learning_rate": 3.0714474031109944e-06,
      "loss": 0.0296,
      "step": 14528
    },
    {
      "epoch": 0.8618460078301103,
      "grad_norm": 0.028838707134127617,
      "learning_rate": 3.070129185341419e-06,
      "loss": 0.0009,
      "step": 14529
    },
    {
      "epoch": 0.8619053268477874,
      "grad_norm": 0.008042875677347183,
      "learning_rate": 3.068810967571843e-06,
      "loss": 0.0003,
      "step": 14530
    },
    {
      "epoch": 0.8619646458654645,
      "grad_norm": 4.960671424865723,
      "learning_rate": 3.067492749802268e-06,
      "loss": 0.0199,
      "step": 14531
    },
    {
      "epoch": 0.8620239648831415,
      "grad_norm": 5.699484348297119,
      "learning_rate": 3.066174532032692e-06,
      "loss": 0.0459,
      "step": 14532
    },
    {
      "epoch": 0.8620832839008186,
      "grad_norm": 0.33993884921073914,
      "learning_rate": 3.0648563142631166e-06,
      "loss": 0.0028,
      "step": 14533
    },
    {
      "epoch": 0.8621426029184956,
      "grad_norm": 60.6530876159668,
      "learning_rate": 3.063538096493541e-06,
      "loss": 0.3824,
      "step": 14534
    },
    {
      "epoch": 0.8622019219361727,
      "grad_norm": 33.2896728515625,
      "learning_rate": 3.0622198787239654e-06,
      "loss": 0.8793,
      "step": 14535
    },
    {
      "epoch": 0.8622612409538498,
      "grad_norm": 10.646733283996582,
      "learning_rate": 3.06090166095439e-06,
      "loss": 0.4138,
      "step": 14536
    },
    {
      "epoch": 0.8623205599715269,
      "grad_norm": 2.7543647289276123,
      "learning_rate": 3.059583443184814e-06,
      "loss": 0.0207,
      "step": 14537
    },
    {
      "epoch": 0.862379878989204,
      "grad_norm": 27.078433990478516,
      "learning_rate": 3.058265225415239e-06,
      "loss": 0.2816,
      "step": 14538
    },
    {
      "epoch": 0.862439198006881,
      "grad_norm": 23.935575485229492,
      "learning_rate": 3.056947007645663e-06,
      "loss": 0.304,
      "step": 14539
    },
    {
      "epoch": 0.862498517024558,
      "grad_norm": 4.442950248718262,
      "learning_rate": 3.0556287898760876e-06,
      "loss": 0.0272,
      "step": 14540
    },
    {
      "epoch": 0.8625578360422351,
      "grad_norm": 0.06585641205310822,
      "learning_rate": 3.0543105721065126e-06,
      "loss": 0.0013,
      "step": 14541
    },
    {
      "epoch": 0.8626171550599122,
      "grad_norm": 0.02603246085345745,
      "learning_rate": 3.052992354336937e-06,
      "loss": 0.0005,
      "step": 14542
    },
    {
      "epoch": 0.8626764740775893,
      "grad_norm": 10.333842277526855,
      "learning_rate": 3.0516741365673614e-06,
      "loss": 0.1937,
      "step": 14543
    },
    {
      "epoch": 0.8627357930952664,
      "grad_norm": 3.716679573059082,
      "learning_rate": 3.0503559187977856e-06,
      "loss": 0.0869,
      "step": 14544
    },
    {
      "epoch": 0.8627951121129435,
      "grad_norm": 1.3987678289413452,
      "learning_rate": 3.0490377010282102e-06,
      "loss": 0.0396,
      "step": 14545
    },
    {
      "epoch": 0.8628544311306204,
      "grad_norm": 0.4383690655231476,
      "learning_rate": 3.0477194832586344e-06,
      "loss": 0.0052,
      "step": 14546
    },
    {
      "epoch": 0.8629137501482975,
      "grad_norm": 0.020381882786750793,
      "learning_rate": 3.046401265489059e-06,
      "loss": 0.0006,
      "step": 14547
    },
    {
      "epoch": 0.8629730691659746,
      "grad_norm": 0.12440840899944305,
      "learning_rate": 3.0450830477194836e-06,
      "loss": 0.0021,
      "step": 14548
    },
    {
      "epoch": 0.8630323881836517,
      "grad_norm": 8.079747200012207,
      "learning_rate": 3.043764829949908e-06,
      "loss": 0.1339,
      "step": 14549
    },
    {
      "epoch": 0.8630917072013288,
      "grad_norm": 21.385324478149414,
      "learning_rate": 3.0424466121803324e-06,
      "loss": 0.5244,
      "step": 14550
    },
    {
      "epoch": 0.8631510262190059,
      "grad_norm": 0.24265658855438232,
      "learning_rate": 3.0411283944107566e-06,
      "loss": 0.0029,
      "step": 14551
    },
    {
      "epoch": 0.8632103452366828,
      "grad_norm": 0.01989937759935856,
      "learning_rate": 3.0398101766411812e-06,
      "loss": 0.0004,
      "step": 14552
    },
    {
      "epoch": 0.8632696642543599,
      "grad_norm": 2.3212528228759766,
      "learning_rate": 3.0384919588716063e-06,
      "loss": 0.036,
      "step": 14553
    },
    {
      "epoch": 0.863328983272037,
      "grad_norm": 4.522676944732666,
      "learning_rate": 3.03717374110203e-06,
      "loss": 0.1058,
      "step": 14554
    },
    {
      "epoch": 0.8633883022897141,
      "grad_norm": 0.19660884141921997,
      "learning_rate": 3.035855523332455e-06,
      "loss": 0.0039,
      "step": 14555
    },
    {
      "epoch": 0.8634476213073912,
      "grad_norm": 5.291988372802734,
      "learning_rate": 3.0345373055628793e-06,
      "loss": 0.2682,
      "step": 14556
    },
    {
      "epoch": 0.8635069403250683,
      "grad_norm": 0.1285080909729004,
      "learning_rate": 3.033219087793304e-06,
      "loss": 0.0019,
      "step": 14557
    },
    {
      "epoch": 0.8635662593427453,
      "grad_norm": 1.1001996994018555,
      "learning_rate": 3.031900870023728e-06,
      "loss": 0.0107,
      "step": 14558
    },
    {
      "epoch": 0.8636255783604223,
      "grad_norm": 23.941930770874023,
      "learning_rate": 3.0305826522541527e-06,
      "loss": 0.6133,
      "step": 14559
    },
    {
      "epoch": 0.8636848973780994,
      "grad_norm": 8.795633316040039,
      "learning_rate": 3.0292644344845773e-06,
      "loss": 0.2151,
      "step": 14560
    },
    {
      "epoch": 0.8637442163957765,
      "grad_norm": 8.990671157836914,
      "learning_rate": 3.0279462167150015e-06,
      "loss": 0.1005,
      "step": 14561
    },
    {
      "epoch": 0.8638035354134536,
      "grad_norm": 0.7666391134262085,
      "learning_rate": 3.026627998945426e-06,
      "loss": 0.0073,
      "step": 14562
    },
    {
      "epoch": 0.8638628544311306,
      "grad_norm": 12.623273849487305,
      "learning_rate": 3.0253097811758503e-06,
      "loss": 0.6319,
      "step": 14563
    },
    {
      "epoch": 0.8639221734488077,
      "grad_norm": 15.869894027709961,
      "learning_rate": 3.023991563406275e-06,
      "loss": 0.2673,
      "step": 14564
    },
    {
      "epoch": 0.8639814924664847,
      "grad_norm": 21.218299865722656,
      "learning_rate": 3.0226733456366995e-06,
      "loss": 1.012,
      "step": 14565
    },
    {
      "epoch": 0.8640408114841618,
      "grad_norm": 3.994492530822754,
      "learning_rate": 3.0213551278671237e-06,
      "loss": 0.0246,
      "step": 14566
    },
    {
      "epoch": 0.8641001305018389,
      "grad_norm": 0.039171259850263596,
      "learning_rate": 3.0200369100975487e-06,
      "loss": 0.0006,
      "step": 14567
    },
    {
      "epoch": 0.864159449519516,
      "grad_norm": 8.257235527038574,
      "learning_rate": 3.0187186923279725e-06,
      "loss": 0.0967,
      "step": 14568
    },
    {
      "epoch": 0.864218768537193,
      "grad_norm": 0.10695117712020874,
      "learning_rate": 3.0174004745583975e-06,
      "loss": 0.0014,
      "step": 14569
    },
    {
      "epoch": 0.8642780875548701,
      "grad_norm": 0.5540171265602112,
      "learning_rate": 3.0160822567888217e-06,
      "loss": 0.0067,
      "step": 14570
    },
    {
      "epoch": 0.8643374065725472,
      "grad_norm": 1.0873759984970093,
      "learning_rate": 3.0147640390192463e-06,
      "loss": 0.0131,
      "step": 14571
    },
    {
      "epoch": 0.8643967255902242,
      "grad_norm": 0.038235172629356384,
      "learning_rate": 3.013445821249671e-06,
      "loss": 0.0009,
      "step": 14572
    },
    {
      "epoch": 0.8644560446079013,
      "grad_norm": 3.233713388442993,
      "learning_rate": 3.012127603480095e-06,
      "loss": 0.058,
      "step": 14573
    },
    {
      "epoch": 0.8645153636255783,
      "grad_norm": 1.6012166738510132,
      "learning_rate": 3.0108093857105197e-06,
      "loss": 0.01,
      "step": 14574
    },
    {
      "epoch": 0.8645746826432554,
      "grad_norm": 0.038450688123703,
      "learning_rate": 3.009491167940944e-06,
      "loss": 0.0005,
      "step": 14575
    },
    {
      "epoch": 0.8646340016609325,
      "grad_norm": 0.026712069287896156,
      "learning_rate": 3.0081729501713685e-06,
      "loss": 0.0007,
      "step": 14576
    },
    {
      "epoch": 0.8646933206786096,
      "grad_norm": 1.5835226774215698,
      "learning_rate": 3.006854732401793e-06,
      "loss": 0.0203,
      "step": 14577
    },
    {
      "epoch": 0.8647526396962867,
      "grad_norm": 3.871809482574463,
      "learning_rate": 3.0055365146322173e-06,
      "loss": 0.1416,
      "step": 14578
    },
    {
      "epoch": 0.8648119587139637,
      "grad_norm": 3.877926826477051,
      "learning_rate": 3.004218296862642e-06,
      "loss": 0.0535,
      "step": 14579
    },
    {
      "epoch": 0.8648712777316407,
      "grad_norm": 0.0982397273182869,
      "learning_rate": 3.002900079093066e-06,
      "loss": 0.0015,
      "step": 14580
    },
    {
      "epoch": 0.8649305967493178,
      "grad_norm": 0.2029849886894226,
      "learning_rate": 3.001581861323491e-06,
      "loss": 0.0028,
      "step": 14581
    },
    {
      "epoch": 0.8649899157669949,
      "grad_norm": 0.957946240901947,
      "learning_rate": 3.000263643553915e-06,
      "loss": 0.0106,
      "step": 14582
    },
    {
      "epoch": 0.865049234784672,
      "grad_norm": 0.00956936925649643,
      "learning_rate": 2.99894542578434e-06,
      "loss": 0.0003,
      "step": 14583
    },
    {
      "epoch": 0.8651085538023491,
      "grad_norm": 12.891656875610352,
      "learning_rate": 2.9976272080147645e-06,
      "loss": 0.7083,
      "step": 14584
    },
    {
      "epoch": 0.865167872820026,
      "grad_norm": 0.26363256573677063,
      "learning_rate": 2.9963089902451887e-06,
      "loss": 0.0017,
      "step": 14585
    },
    {
      "epoch": 0.8652271918377031,
      "grad_norm": 0.03863760083913803,
      "learning_rate": 2.9949907724756133e-06,
      "loss": 0.0009,
      "step": 14586
    },
    {
      "epoch": 0.8652865108553802,
      "grad_norm": 0.004437741357833147,
      "learning_rate": 2.9936725547060375e-06,
      "loss": 0.0001,
      "step": 14587
    },
    {
      "epoch": 0.8653458298730573,
      "grad_norm": 0.017391687259078026,
      "learning_rate": 2.992354336936462e-06,
      "loss": 0.0003,
      "step": 14588
    },
    {
      "epoch": 0.8654051488907344,
      "grad_norm": 30.751585006713867,
      "learning_rate": 2.9910361191668868e-06,
      "loss": 0.2736,
      "step": 14589
    },
    {
      "epoch": 0.8654644679084115,
      "grad_norm": 0.21462231874465942,
      "learning_rate": 2.989717901397311e-06,
      "loss": 0.0015,
      "step": 14590
    },
    {
      "epoch": 0.8655237869260886,
      "grad_norm": 11.326592445373535,
      "learning_rate": 2.9883996836277355e-06,
      "loss": 0.0696,
      "step": 14591
    },
    {
      "epoch": 0.8655831059437655,
      "grad_norm": 12.199835777282715,
      "learning_rate": 2.9870814658581597e-06,
      "loss": 0.15,
      "step": 14592
    },
    {
      "epoch": 0.8656424249614426,
      "grad_norm": 1.3686648607254028,
      "learning_rate": 2.9857632480885843e-06,
      "loss": 0.0659,
      "step": 14593
    },
    {
      "epoch": 0.8657017439791197,
      "grad_norm": 21.654296875,
      "learning_rate": 2.9844450303190085e-06,
      "loss": 0.1762,
      "step": 14594
    },
    {
      "epoch": 0.8657610629967968,
      "grad_norm": 4.3225789070129395,
      "learning_rate": 2.9831268125494336e-06,
      "loss": 0.0129,
      "step": 14595
    },
    {
      "epoch": 0.8658203820144739,
      "grad_norm": 0.11977575719356537,
      "learning_rate": 2.981808594779858e-06,
      "loss": 0.0018,
      "step": 14596
    },
    {
      "epoch": 0.865879701032151,
      "grad_norm": 11.400171279907227,
      "learning_rate": 2.9804903770102824e-06,
      "loss": 0.0783,
      "step": 14597
    },
    {
      "epoch": 0.8659390200498279,
      "grad_norm": 3.31166934967041,
      "learning_rate": 2.979172159240707e-06,
      "loss": 0.0157,
      "step": 14598
    },
    {
      "epoch": 0.865998339067505,
      "grad_norm": 8.497384071350098,
      "learning_rate": 2.977853941471131e-06,
      "loss": 0.0933,
      "step": 14599
    },
    {
      "epoch": 0.8660576580851821,
      "grad_norm": 0.017615128308534622,
      "learning_rate": 2.9765357237015558e-06,
      "loss": 0.0002,
      "step": 14600
    },
    {
      "epoch": 0.8661169771028592,
      "grad_norm": 13.666213989257812,
      "learning_rate": 2.9752175059319804e-06,
      "loss": 0.048,
      "step": 14601
    },
    {
      "epoch": 0.8661762961205363,
      "grad_norm": 17.606338500976562,
      "learning_rate": 2.9738992881624046e-06,
      "loss": 0.2764,
      "step": 14602
    },
    {
      "epoch": 0.8662356151382133,
      "grad_norm": 0.2596197724342346,
      "learning_rate": 2.972581070392829e-06,
      "loss": 0.0045,
      "step": 14603
    },
    {
      "epoch": 0.8662949341558904,
      "grad_norm": 0.5505529046058655,
      "learning_rate": 2.9712628526232534e-06,
      "loss": 0.0034,
      "step": 14604
    },
    {
      "epoch": 0.8663542531735674,
      "grad_norm": 0.02778199128806591,
      "learning_rate": 2.969944634853678e-06,
      "loss": 0.0005,
      "step": 14605
    },
    {
      "epoch": 0.8664135721912445,
      "grad_norm": 0.03988223895430565,
      "learning_rate": 2.968626417084102e-06,
      "loss": 0.0007,
      "step": 14606
    },
    {
      "epoch": 0.8664728912089216,
      "grad_norm": 6.994477272033691,
      "learning_rate": 2.9673081993145268e-06,
      "loss": 0.0394,
      "step": 14607
    },
    {
      "epoch": 0.8665322102265987,
      "grad_norm": 5.957925319671631,
      "learning_rate": 2.965989981544952e-06,
      "loss": 0.1724,
      "step": 14608
    },
    {
      "epoch": 0.8665915292442757,
      "grad_norm": 0.014799747616052628,
      "learning_rate": 2.964671763775376e-06,
      "loss": 0.0004,
      "step": 14609
    },
    {
      "epoch": 0.8666508482619528,
      "grad_norm": 0.047277577221393585,
      "learning_rate": 2.9633535460058006e-06,
      "loss": 0.0005,
      "step": 14610
    },
    {
      "epoch": 0.8667101672796298,
      "grad_norm": 0.08445662260055542,
      "learning_rate": 2.962035328236225e-06,
      "loss": 0.0012,
      "step": 14611
    },
    {
      "epoch": 0.8667694862973069,
      "grad_norm": 7.490971088409424,
      "learning_rate": 2.9607171104666494e-06,
      "loss": 0.0818,
      "step": 14612
    },
    {
      "epoch": 0.866828805314984,
      "grad_norm": 0.37876227498054504,
      "learning_rate": 2.959398892697074e-06,
      "loss": 0.0046,
      "step": 14613
    },
    {
      "epoch": 0.866888124332661,
      "grad_norm": 11.951593399047852,
      "learning_rate": 2.958080674927498e-06,
      "loss": 0.3342,
      "step": 14614
    },
    {
      "epoch": 0.8669474433503381,
      "grad_norm": 10.650755882263184,
      "learning_rate": 2.956762457157923e-06,
      "loss": 0.0442,
      "step": 14615
    },
    {
      "epoch": 0.8670067623680152,
      "grad_norm": 10.9216947555542,
      "learning_rate": 2.955444239388347e-06,
      "loss": 0.2892,
      "step": 14616
    },
    {
      "epoch": 0.8670660813856923,
      "grad_norm": 2.6301636695861816,
      "learning_rate": 2.9541260216187716e-06,
      "loss": 0.0276,
      "step": 14617
    },
    {
      "epoch": 0.8671254004033693,
      "grad_norm": 4.5995659828186035,
      "learning_rate": 2.952807803849196e-06,
      "loss": 0.5534,
      "step": 14618
    },
    {
      "epoch": 0.8671847194210464,
      "grad_norm": 11.26926040649414,
      "learning_rate": 2.9514895860796204e-06,
      "loss": 0.0539,
      "step": 14619
    },
    {
      "epoch": 0.8672440384387234,
      "grad_norm": 3.1188344955444336,
      "learning_rate": 2.9501713683100454e-06,
      "loss": 0.0308,
      "step": 14620
    },
    {
      "epoch": 0.8673033574564005,
      "grad_norm": 1.4645447731018066,
      "learning_rate": 2.948853150540469e-06,
      "loss": 0.0192,
      "step": 14621
    },
    {
      "epoch": 0.8673626764740776,
      "grad_norm": 40.731170654296875,
      "learning_rate": 2.9475349327708942e-06,
      "loss": 0.5647,
      "step": 14622
    },
    {
      "epoch": 0.8674219954917547,
      "grad_norm": 0.39930015802383423,
      "learning_rate": 2.9462167150013184e-06,
      "loss": 0.0023,
      "step": 14623
    },
    {
      "epoch": 0.8674813145094318,
      "grad_norm": 6.343020915985107,
      "learning_rate": 2.944898497231743e-06,
      "loss": 0.1369,
      "step": 14624
    },
    {
      "epoch": 0.8675406335271088,
      "grad_norm": 0.028736867010593414,
      "learning_rate": 2.9435802794621677e-06,
      "loss": 0.0007,
      "step": 14625
    },
    {
      "epoch": 0.8675999525447858,
      "grad_norm": 27.22304344177246,
      "learning_rate": 2.942262061692592e-06,
      "loss": 0.5689,
      "step": 14626
    },
    {
      "epoch": 0.8676592715624629,
      "grad_norm": 0.09013152867555618,
      "learning_rate": 2.9409438439230164e-06,
      "loss": 0.0015,
      "step": 14627
    },
    {
      "epoch": 0.86771859058014,
      "grad_norm": 7.598783016204834,
      "learning_rate": 2.9396256261534406e-06,
      "loss": 0.1725,
      "step": 14628
    },
    {
      "epoch": 0.8677779095978171,
      "grad_norm": 9.570361137390137,
      "learning_rate": 2.9383074083838652e-06,
      "loss": 0.6206,
      "step": 14629
    },
    {
      "epoch": 0.8678372286154942,
      "grad_norm": 17.854488372802734,
      "learning_rate": 2.93698919061429e-06,
      "loss": 0.3828,
      "step": 14630
    },
    {
      "epoch": 0.8678965476331711,
      "grad_norm": 0.052824996411800385,
      "learning_rate": 2.935670972844714e-06,
      "loss": 0.0012,
      "step": 14631
    },
    {
      "epoch": 0.8679558666508482,
      "grad_norm": 0.012482436373829842,
      "learning_rate": 2.9343527550751387e-06,
      "loss": 0.0002,
      "step": 14632
    },
    {
      "epoch": 0.8680151856685253,
      "grad_norm": 0.9609885811805725,
      "learning_rate": 2.933034537305563e-06,
      "loss": 0.0066,
      "step": 14633
    },
    {
      "epoch": 0.8680745046862024,
      "grad_norm": 0.1376059204339981,
      "learning_rate": 2.931716319535988e-06,
      "loss": 0.0011,
      "step": 14634
    },
    {
      "epoch": 0.8681338237038795,
      "grad_norm": 13.1847505569458,
      "learning_rate": 2.9303981017664116e-06,
      "loss": 0.4182,
      "step": 14635
    },
    {
      "epoch": 0.8681931427215566,
      "grad_norm": 3.432082414627075,
      "learning_rate": 2.9290798839968367e-06,
      "loss": 0.0323,
      "step": 14636
    },
    {
      "epoch": 0.8682524617392336,
      "grad_norm": 0.014450964517891407,
      "learning_rate": 2.9277616662272613e-06,
      "loss": 0.0004,
      "step": 14637
    },
    {
      "epoch": 0.8683117807569106,
      "grad_norm": 14.549220085144043,
      "learning_rate": 2.9264434484576855e-06,
      "loss": 0.2801,
      "step": 14638
    },
    {
      "epoch": 0.8683710997745877,
      "grad_norm": 0.053883910179138184,
      "learning_rate": 2.92512523068811e-06,
      "loss": 0.0009,
      "step": 14639
    },
    {
      "epoch": 0.8684304187922648,
      "grad_norm": 8.108330726623535,
      "learning_rate": 2.9238070129185343e-06,
      "loss": 0.0247,
      "step": 14640
    },
    {
      "epoch": 0.8684897378099419,
      "grad_norm": 8.571895599365234,
      "learning_rate": 2.922488795148959e-06,
      "loss": 0.0856,
      "step": 14641
    },
    {
      "epoch": 0.868549056827619,
      "grad_norm": 3.4880311489105225,
      "learning_rate": 2.9211705773793835e-06,
      "loss": 0.0333,
      "step": 14642
    },
    {
      "epoch": 0.868608375845296,
      "grad_norm": 16.954023361206055,
      "learning_rate": 2.9198523596098077e-06,
      "loss": 0.1383,
      "step": 14643
    },
    {
      "epoch": 0.868667694862973,
      "grad_norm": 0.018868975341320038,
      "learning_rate": 2.9185341418402323e-06,
      "loss": 0.0005,
      "step": 14644
    },
    {
      "epoch": 0.8687270138806501,
      "grad_norm": 27.081012725830078,
      "learning_rate": 2.9172159240706565e-06,
      "loss": 0.993,
      "step": 14645
    },
    {
      "epoch": 0.8687863328983272,
      "grad_norm": 0.018363112583756447,
      "learning_rate": 2.915897706301081e-06,
      "loss": 0.0003,
      "step": 14646
    },
    {
      "epoch": 0.8688456519160043,
      "grad_norm": 0.41353559494018555,
      "learning_rate": 2.9145794885315053e-06,
      "loss": 0.0048,
      "step": 14647
    },
    {
      "epoch": 0.8689049709336814,
      "grad_norm": 1.8543189764022827,
      "learning_rate": 2.9132612707619303e-06,
      "loss": 0.0128,
      "step": 14648
    },
    {
      "epoch": 0.8689642899513584,
      "grad_norm": 0.2661329209804535,
      "learning_rate": 2.911943052992355e-06,
      "loss": 0.0047,
      "step": 14649
    },
    {
      "epoch": 0.8690236089690355,
      "grad_norm": 1.8375290632247925,
      "learning_rate": 2.910624835222779e-06,
      "loss": 0.0143,
      "step": 14650
    },
    {
      "epoch": 0.8690829279867125,
      "grad_norm": 3.2319350242614746,
      "learning_rate": 2.9093066174532037e-06,
      "loss": 0.0837,
      "step": 14651
    },
    {
      "epoch": 0.8691422470043896,
      "grad_norm": 0.022754723206162453,
      "learning_rate": 2.907988399683628e-06,
      "loss": 0.0006,
      "step": 14652
    },
    {
      "epoch": 0.8692015660220667,
      "grad_norm": 27.187726974487305,
      "learning_rate": 2.9066701819140525e-06,
      "loss": 0.2838,
      "step": 14653
    },
    {
      "epoch": 0.8692608850397437,
      "grad_norm": 0.028724247589707375,
      "learning_rate": 2.905351964144477e-06,
      "loss": 0.0004,
      "step": 14654
    },
    {
      "epoch": 0.8693202040574208,
      "grad_norm": 3.071281671524048,
      "learning_rate": 2.9040337463749013e-06,
      "loss": 0.1862,
      "step": 14655
    },
    {
      "epoch": 0.8693795230750979,
      "grad_norm": 0.4329051971435547,
      "learning_rate": 2.902715528605326e-06,
      "loss": 0.0056,
      "step": 14656
    },
    {
      "epoch": 0.8694388420927749,
      "grad_norm": 0.008789192885160446,
      "learning_rate": 2.90139731083575e-06,
      "loss": 0.0002,
      "step": 14657
    },
    {
      "epoch": 0.869498161110452,
      "grad_norm": 1.9333577156066895,
      "learning_rate": 2.9000790930661747e-06,
      "loss": 0.0551,
      "step": 14658
    },
    {
      "epoch": 0.8695574801281291,
      "grad_norm": 36.62421798706055,
      "learning_rate": 2.898760875296599e-06,
      "loss": 0.0964,
      "step": 14659
    },
    {
      "epoch": 0.8696167991458061,
      "grad_norm": 0.008650860749185085,
      "learning_rate": 2.8974426575270235e-06,
      "loss": 0.0003,
      "step": 14660
    },
    {
      "epoch": 0.8696761181634832,
      "grad_norm": 14.480941772460938,
      "learning_rate": 2.8961244397574486e-06,
      "loss": 0.3916,
      "step": 14661
    },
    {
      "epoch": 0.8697354371811603,
      "grad_norm": 0.07983923703432083,
      "learning_rate": 2.8948062219878727e-06,
      "loss": 0.0009,
      "step": 14662
    },
    {
      "epoch": 0.8697947561988374,
      "grad_norm": 10.117612838745117,
      "learning_rate": 2.8934880042182973e-06,
      "loss": 0.5997,
      "step": 14663
    },
    {
      "epoch": 0.8698540752165144,
      "grad_norm": 0.19522584974765778,
      "learning_rate": 2.8921697864487215e-06,
      "loss": 0.004,
      "step": 14664
    },
    {
      "epoch": 0.8699133942341915,
      "grad_norm": 8.36611557006836,
      "learning_rate": 2.890851568679146e-06,
      "loss": 0.022,
      "step": 14665
    },
    {
      "epoch": 0.8699727132518685,
      "grad_norm": 0.016919249668717384,
      "learning_rate": 2.8895333509095708e-06,
      "loss": 0.0004,
      "step": 14666
    },
    {
      "epoch": 0.8700320322695456,
      "grad_norm": 0.2865995466709137,
      "learning_rate": 2.888215133139995e-06,
      "loss": 0.006,
      "step": 14667
    },
    {
      "epoch": 0.8700913512872227,
      "grad_norm": 8.063718795776367,
      "learning_rate": 2.8868969153704196e-06,
      "loss": 0.1496,
      "step": 14668
    },
    {
      "epoch": 0.8701506703048998,
      "grad_norm": 0.12309163808822632,
      "learning_rate": 2.8855786976008437e-06,
      "loss": 0.0013,
      "step": 14669
    },
    {
      "epoch": 0.8702099893225769,
      "grad_norm": 6.348081111907959,
      "learning_rate": 2.8842604798312684e-06,
      "loss": 0.0656,
      "step": 14670
    },
    {
      "epoch": 0.8702693083402538,
      "grad_norm": 0.3265577256679535,
      "learning_rate": 2.8829422620616925e-06,
      "loss": 0.0018,
      "step": 14671
    },
    {
      "epoch": 0.8703286273579309,
      "grad_norm": 0.05685482174158096,
      "learning_rate": 2.881624044292117e-06,
      "loss": 0.0008,
      "step": 14672
    },
    {
      "epoch": 0.870387946375608,
      "grad_norm": 50.538089752197266,
      "learning_rate": 2.880305826522542e-06,
      "loss": 0.4946,
      "step": 14673
    },
    {
      "epoch": 0.8704472653932851,
      "grad_norm": 6.242666721343994,
      "learning_rate": 2.878987608752966e-06,
      "loss": 0.192,
      "step": 14674
    },
    {
      "epoch": 0.8705065844109622,
      "grad_norm": 25.544391632080078,
      "learning_rate": 2.877669390983391e-06,
      "loss": 0.5797,
      "step": 14675
    },
    {
      "epoch": 0.8705659034286393,
      "grad_norm": 0.005057371687144041,
      "learning_rate": 2.876351173213815e-06,
      "loss": 0.0002,
      "step": 14676
    },
    {
      "epoch": 0.8706252224463162,
      "grad_norm": 0.23455911874771118,
      "learning_rate": 2.8750329554442398e-06,
      "loss": 0.0033,
      "step": 14677
    },
    {
      "epoch": 0.8706845414639933,
      "grad_norm": 8.160748481750488,
      "learning_rate": 2.8737147376746644e-06,
      "loss": 0.1213,
      "step": 14678
    },
    {
      "epoch": 0.8707438604816704,
      "grad_norm": 35.57299041748047,
      "learning_rate": 2.8723965199050886e-06,
      "loss": 1.878,
      "step": 14679
    },
    {
      "epoch": 0.8708031794993475,
      "grad_norm": 0.3448978364467621,
      "learning_rate": 2.871078302135513e-06,
      "loss": 0.0029,
      "step": 14680
    },
    {
      "epoch": 0.8708624985170246,
      "grad_norm": 5.582023620605469,
      "learning_rate": 2.8697600843659374e-06,
      "loss": 0.1868,
      "step": 14681
    },
    {
      "epoch": 0.8709218175347017,
      "grad_norm": 27.587574005126953,
      "learning_rate": 2.868441866596362e-06,
      "loss": 0.2105,
      "step": 14682
    },
    {
      "epoch": 0.8709811365523787,
      "grad_norm": 0.11499865353107452,
      "learning_rate": 2.867123648826786e-06,
      "loss": 0.001,
      "step": 14683
    },
    {
      "epoch": 0.8710404555700557,
      "grad_norm": 0.18472087383270264,
      "learning_rate": 2.8658054310572108e-06,
      "loss": 0.0013,
      "step": 14684
    },
    {
      "epoch": 0.8710997745877328,
      "grad_norm": 0.06533665955066681,
      "learning_rate": 2.8644872132876354e-06,
      "loss": 0.0006,
      "step": 14685
    },
    {
      "epoch": 0.8711590936054099,
      "grad_norm": 0.0025735788512974977,
      "learning_rate": 2.8631689955180596e-06,
      "loss": 0.0001,
      "step": 14686
    },
    {
      "epoch": 0.871218412623087,
      "grad_norm": 0.2409818321466446,
      "learning_rate": 2.8618507777484846e-06,
      "loss": 0.0033,
      "step": 14687
    },
    {
      "epoch": 0.871277731640764,
      "grad_norm": 0.02027912065386772,
      "learning_rate": 2.8605325599789084e-06,
      "loss": 0.0004,
      "step": 14688
    },
    {
      "epoch": 0.8713370506584411,
      "grad_norm": 0.2550692558288574,
      "learning_rate": 2.8592143422093334e-06,
      "loss": 0.0018,
      "step": 14689
    },
    {
      "epoch": 0.8713963696761181,
      "grad_norm": 9.131729125976562,
      "learning_rate": 2.857896124439758e-06,
      "loss": 0.0738,
      "step": 14690
    },
    {
      "epoch": 0.8714556886937952,
      "grad_norm": 0.9264254570007324,
      "learning_rate": 2.856577906670182e-06,
      "loss": 0.002,
      "step": 14691
    },
    {
      "epoch": 0.8715150077114723,
      "grad_norm": 21.880830764770508,
      "learning_rate": 2.855259688900607e-06,
      "loss": 0.6898,
      "step": 14692
    },
    {
      "epoch": 0.8715743267291494,
      "grad_norm": 7.6022186279296875,
      "learning_rate": 2.853941471131031e-06,
      "loss": 0.2574,
      "step": 14693
    },
    {
      "epoch": 0.8716336457468264,
      "grad_norm": 0.3001018464565277,
      "learning_rate": 2.8526232533614556e-06,
      "loss": 0.0041,
      "step": 14694
    },
    {
      "epoch": 0.8716929647645035,
      "grad_norm": 8.1895751953125,
      "learning_rate": 2.85130503559188e-06,
      "loss": 0.0723,
      "step": 14695
    },
    {
      "epoch": 0.8717522837821806,
      "grad_norm": 4.059491157531738,
      "learning_rate": 2.8499868178223044e-06,
      "loss": 0.0941,
      "step": 14696
    },
    {
      "epoch": 0.8718116027998576,
      "grad_norm": 0.09628530591726303,
      "learning_rate": 2.848668600052729e-06,
      "loss": 0.0024,
      "step": 14697
    },
    {
      "epoch": 0.8718709218175347,
      "grad_norm": 9.767889976501465,
      "learning_rate": 2.8473503822831532e-06,
      "loss": 0.0342,
      "step": 14698
    },
    {
      "epoch": 0.8719302408352118,
      "grad_norm": 2.3452308177948,
      "learning_rate": 2.846032164513578e-06,
      "loss": 0.0334,
      "step": 14699
    },
    {
      "epoch": 0.8719895598528888,
      "grad_norm": 0.25255581736564636,
      "learning_rate": 2.844713946744002e-06,
      "loss": 0.0041,
      "step": 14700
    },
    {
      "epoch": 0.8720488788705659,
      "grad_norm": 0.022950178012251854,
      "learning_rate": 2.843395728974427e-06,
      "loss": 0.0006,
      "step": 14701
    },
    {
      "epoch": 0.872108197888243,
      "grad_norm": 13.536993026733398,
      "learning_rate": 2.8420775112048517e-06,
      "loss": 0.3321,
      "step": 14702
    },
    {
      "epoch": 0.8721675169059201,
      "grad_norm": 15.33401870727539,
      "learning_rate": 2.840759293435276e-06,
      "loss": 0.699,
      "step": 14703
    },
    {
      "epoch": 0.8722268359235971,
      "grad_norm": 1.1676267385482788,
      "learning_rate": 2.8394410756657005e-06,
      "loss": 0.0053,
      "step": 14704
    },
    {
      "epoch": 0.8722861549412741,
      "grad_norm": 0.14772434532642365,
      "learning_rate": 2.8381228578961246e-06,
      "loss": 0.0016,
      "step": 14705
    },
    {
      "epoch": 0.8723454739589512,
      "grad_norm": 0.006824098527431488,
      "learning_rate": 2.8368046401265493e-06,
      "loss": 0.0002,
      "step": 14706
    },
    {
      "epoch": 0.8724047929766283,
      "grad_norm": 0.10483880341053009,
      "learning_rate": 2.8354864223569734e-06,
      "loss": 0.0014,
      "step": 14707
    },
    {
      "epoch": 0.8724641119943054,
      "grad_norm": 0.022645339369773865,
      "learning_rate": 2.834168204587398e-06,
      "loss": 0.0005,
      "step": 14708
    },
    {
      "epoch": 0.8725234310119825,
      "grad_norm": 50.14524459838867,
      "learning_rate": 2.8328499868178227e-06,
      "loss": 0.3877,
      "step": 14709
    },
    {
      "epoch": 0.8725827500296595,
      "grad_norm": 0.23680946230888367,
      "learning_rate": 2.831531769048247e-06,
      "loss": 0.0032,
      "step": 14710
    },
    {
      "epoch": 0.8726420690473365,
      "grad_norm": 10.199962615966797,
      "learning_rate": 2.8302135512786715e-06,
      "loss": 0.2668,
      "step": 14711
    },
    {
      "epoch": 0.8727013880650136,
      "grad_norm": 0.8601284623146057,
      "learning_rate": 2.8288953335090956e-06,
      "loss": 0.0054,
      "step": 14712
    },
    {
      "epoch": 0.8727607070826907,
      "grad_norm": 25.111162185668945,
      "learning_rate": 2.8275771157395203e-06,
      "loss": 0.0541,
      "step": 14713
    },
    {
      "epoch": 0.8728200261003678,
      "grad_norm": 11.34550666809082,
      "learning_rate": 2.8262588979699453e-06,
      "loss": 0.0646,
      "step": 14714
    },
    {
      "epoch": 0.8728793451180449,
      "grad_norm": 9.902538299560547,
      "learning_rate": 2.8249406802003695e-06,
      "loss": 0.131,
      "step": 14715
    },
    {
      "epoch": 0.872938664135722,
      "grad_norm": 8.396974563598633,
      "learning_rate": 2.823622462430794e-06,
      "loss": 0.2425,
      "step": 14716
    },
    {
      "epoch": 0.8729979831533989,
      "grad_norm": 0.034430406987667084,
      "learning_rate": 2.8223042446612183e-06,
      "loss": 0.0006,
      "step": 14717
    },
    {
      "epoch": 0.873057302171076,
      "grad_norm": 0.2829289436340332,
      "learning_rate": 2.820986026891643e-06,
      "loss": 0.0026,
      "step": 14718
    },
    {
      "epoch": 0.8731166211887531,
      "grad_norm": 7.096923351287842,
      "learning_rate": 2.819667809122067e-06,
      "loss": 0.3765,
      "step": 14719
    },
    {
      "epoch": 0.8731759402064302,
      "grad_norm": 0.08171429485082626,
      "learning_rate": 2.8183495913524917e-06,
      "loss": 0.0008,
      "step": 14720
    },
    {
      "epoch": 0.8732352592241073,
      "grad_norm": 0.5299201011657715,
      "learning_rate": 2.8170313735829163e-06,
      "loss": 0.0088,
      "step": 14721
    },
    {
      "epoch": 0.8732945782417844,
      "grad_norm": 1.0354225635528564,
      "learning_rate": 2.8157131558133405e-06,
      "loss": 0.0102,
      "step": 14722
    },
    {
      "epoch": 0.8733538972594613,
      "grad_norm": 0.008810281753540039,
      "learning_rate": 2.814394938043765e-06,
      "loss": 0.0003,
      "step": 14723
    },
    {
      "epoch": 0.8734132162771384,
      "grad_norm": 8.82516098022461,
      "learning_rate": 2.8130767202741893e-06,
      "loss": 0.2727,
      "step": 14724
    },
    {
      "epoch": 0.8734725352948155,
      "grad_norm": 6.778249740600586,
      "learning_rate": 2.811758502504614e-06,
      "loss": 0.3066,
      "step": 14725
    },
    {
      "epoch": 0.8735318543124926,
      "grad_norm": 0.0235645342618227,
      "learning_rate": 2.810440284735039e-06,
      "loss": 0.0007,
      "step": 14726
    },
    {
      "epoch": 0.8735911733301697,
      "grad_norm": 0.004428062122315168,
      "learning_rate": 2.8091220669654627e-06,
      "loss": 0.0002,
      "step": 14727
    },
    {
      "epoch": 0.8736504923478468,
      "grad_norm": 18.740419387817383,
      "learning_rate": 2.8078038491958877e-06,
      "loss": 0.288,
      "step": 14728
    },
    {
      "epoch": 0.8737098113655238,
      "grad_norm": 0.03156151622533798,
      "learning_rate": 2.806485631426312e-06,
      "loss": 0.0005,
      "step": 14729
    },
    {
      "epoch": 0.8737691303832008,
      "grad_norm": 0.30904123187065125,
      "learning_rate": 2.8051674136567365e-06,
      "loss": 0.0037,
      "step": 14730
    },
    {
      "epoch": 0.8738284494008779,
      "grad_norm": 12.386573791503906,
      "learning_rate": 2.8038491958871607e-06,
      "loss": 0.1819,
      "step": 14731
    },
    {
      "epoch": 0.873887768418555,
      "grad_norm": 21.841482162475586,
      "learning_rate": 2.8025309781175853e-06,
      "loss": 0.4799,
      "step": 14732
    },
    {
      "epoch": 0.8739470874362321,
      "grad_norm": 0.008494753390550613,
      "learning_rate": 2.80121276034801e-06,
      "loss": 0.0003,
      "step": 14733
    },
    {
      "epoch": 0.8740064064539091,
      "grad_norm": 48.570438385009766,
      "learning_rate": 2.799894542578434e-06,
      "loss": 0.3718,
      "step": 14734
    },
    {
      "epoch": 0.8740657254715862,
      "grad_norm": 1.005859375,
      "learning_rate": 2.7985763248088587e-06,
      "loss": 0.0146,
      "step": 14735
    },
    {
      "epoch": 0.8741250444892632,
      "grad_norm": 0.2487397938966751,
      "learning_rate": 2.797258107039283e-06,
      "loss": 0.0049,
      "step": 14736
    },
    {
      "epoch": 0.8741843635069403,
      "grad_norm": 0.028920302167534828,
      "learning_rate": 2.7959398892697075e-06,
      "loss": 0.0004,
      "step": 14737
    },
    {
      "epoch": 0.8742436825246174,
      "grad_norm": 16.383689880371094,
      "learning_rate": 2.794621671500132e-06,
      "loss": 0.1822,
      "step": 14738
    },
    {
      "epoch": 0.8743030015422945,
      "grad_norm": 0.45487427711486816,
      "learning_rate": 2.7933034537305563e-06,
      "loss": 0.0065,
      "step": 14739
    },
    {
      "epoch": 0.8743623205599715,
      "grad_norm": 0.14202220737934113,
      "learning_rate": 2.7919852359609814e-06,
      "loss": 0.0019,
      "step": 14740
    },
    {
      "epoch": 0.8744216395776486,
      "grad_norm": 9.081085205078125,
      "learning_rate": 2.790667018191405e-06,
      "loss": 0.1731,
      "step": 14741
    },
    {
      "epoch": 0.8744809585953257,
      "grad_norm": 0.9839968085289001,
      "learning_rate": 2.78934880042183e-06,
      "loss": 0.0107,
      "step": 14742
    },
    {
      "epoch": 0.8745402776130027,
      "grad_norm": 10.889182090759277,
      "learning_rate": 2.788030582652254e-06,
      "loss": 0.5531,
      "step": 14743
    },
    {
      "epoch": 0.8745995966306798,
      "grad_norm": 0.05930284410715103,
      "learning_rate": 2.786712364882679e-06,
      "loss": 0.0009,
      "step": 14744
    },
    {
      "epoch": 0.8746589156483568,
      "grad_norm": 0.0734594538807869,
      "learning_rate": 2.7853941471131036e-06,
      "loss": 0.001,
      "step": 14745
    },
    {
      "epoch": 0.8747182346660339,
      "grad_norm": 2.9882142543792725,
      "learning_rate": 2.7840759293435277e-06,
      "loss": 0.0278,
      "step": 14746
    },
    {
      "epoch": 0.874777553683711,
      "grad_norm": 0.07721385359764099,
      "learning_rate": 2.7827577115739524e-06,
      "loss": 0.0014,
      "step": 14747
    },
    {
      "epoch": 0.8748368727013881,
      "grad_norm": 9.026098251342773,
      "learning_rate": 2.7814394938043765e-06,
      "loss": 0.3217,
      "step": 14748
    },
    {
      "epoch": 0.8748961917190652,
      "grad_norm": 0.031454700976610184,
      "learning_rate": 2.780121276034801e-06,
      "loss": 0.0007,
      "step": 14749
    },
    {
      "epoch": 0.8749555107367422,
      "grad_norm": 2.800020456314087,
      "learning_rate": 2.7788030582652258e-06,
      "loss": 0.047,
      "step": 14750
    },
    {
      "epoch": 0.8750148297544192,
      "grad_norm": 1.2757322788238525,
      "learning_rate": 2.77748484049565e-06,
      "loss": 0.0164,
      "step": 14751
    },
    {
      "epoch": 0.8750741487720963,
      "grad_norm": 0.037751294672489166,
      "learning_rate": 2.7761666227260746e-06,
      "loss": 0.0007,
      "step": 14752
    },
    {
      "epoch": 0.8751334677897734,
      "grad_norm": 0.011649544350802898,
      "learning_rate": 2.7748484049564988e-06,
      "loss": 0.0003,
      "step": 14753
    },
    {
      "epoch": 0.8751927868074505,
      "grad_norm": 11.901318550109863,
      "learning_rate": 2.7735301871869238e-06,
      "loss": 0.3721,
      "step": 14754
    },
    {
      "epoch": 0.8752521058251276,
      "grad_norm": 10.800520896911621,
      "learning_rate": 2.7722119694173475e-06,
      "loss": 0.1168,
      "step": 14755
    },
    {
      "epoch": 0.8753114248428046,
      "grad_norm": 0.5254067182540894,
      "learning_rate": 2.7708937516477726e-06,
      "loss": 0.0087,
      "step": 14756
    },
    {
      "epoch": 0.8753707438604816,
      "grad_norm": 2.6256725788116455,
      "learning_rate": 2.769575533878197e-06,
      "loss": 0.043,
      "step": 14757
    },
    {
      "epoch": 0.8754300628781587,
      "grad_norm": 0.14051975309848785,
      "learning_rate": 2.7682573161086214e-06,
      "loss": 0.0022,
      "step": 14758
    },
    {
      "epoch": 0.8754893818958358,
      "grad_norm": 3.0587596893310547,
      "learning_rate": 2.766939098339046e-06,
      "loss": 0.0915,
      "step": 14759
    },
    {
      "epoch": 0.8755487009135129,
      "grad_norm": 5.981173038482666,
      "learning_rate": 2.76562088056947e-06,
      "loss": 0.1022,
      "step": 14760
    },
    {
      "epoch": 0.87560801993119,
      "grad_norm": 0.6109198927879333,
      "learning_rate": 2.7643026627998948e-06,
      "loss": 0.014,
      "step": 14761
    },
    {
      "epoch": 0.8756673389488671,
      "grad_norm": 16.931814193725586,
      "learning_rate": 2.7629844450303194e-06,
      "loss": 0.2962,
      "step": 14762
    },
    {
      "epoch": 0.875726657966544,
      "grad_norm": 1.3518319129943848,
      "learning_rate": 2.7616662272607436e-06,
      "loss": 0.019,
      "step": 14763
    },
    {
      "epoch": 0.8757859769842211,
      "grad_norm": 0.029075495898723602,
      "learning_rate": 2.760348009491168e-06,
      "loss": 0.0005,
      "step": 14764
    },
    {
      "epoch": 0.8758452960018982,
      "grad_norm": 9.039060592651367,
      "learning_rate": 2.7590297917215924e-06,
      "loss": 0.0686,
      "step": 14765
    },
    {
      "epoch": 0.8759046150195753,
      "grad_norm": 2.8844475746154785,
      "learning_rate": 2.757711573952017e-06,
      "loss": 0.0477,
      "step": 14766
    },
    {
      "epoch": 0.8759639340372524,
      "grad_norm": 1.363046407699585,
      "learning_rate": 2.756393356182441e-06,
      "loss": 0.0256,
      "step": 14767
    },
    {
      "epoch": 0.8760232530549295,
      "grad_norm": 0.13969683647155762,
      "learning_rate": 2.755075138412866e-06,
      "loss": 0.003,
      "step": 14768
    },
    {
      "epoch": 0.8760825720726064,
      "grad_norm": 0.01998397521674633,
      "learning_rate": 2.753756920643291e-06,
      "loss": 0.0004,
      "step": 14769
    },
    {
      "epoch": 0.8761418910902835,
      "grad_norm": 0.00838004145771265,
      "learning_rate": 2.752438702873715e-06,
      "loss": 0.0002,
      "step": 14770
    },
    {
      "epoch": 0.8762012101079606,
      "grad_norm": 6.123333930969238,
      "learning_rate": 2.7511204851041396e-06,
      "loss": 0.0245,
      "step": 14771
    },
    {
      "epoch": 0.8762605291256377,
      "grad_norm": 1.6424895524978638,
      "learning_rate": 2.749802267334564e-06,
      "loss": 0.0077,
      "step": 14772
    },
    {
      "epoch": 0.8763198481433148,
      "grad_norm": 0.6918115615844727,
      "learning_rate": 2.7484840495649884e-06,
      "loss": 0.0103,
      "step": 14773
    },
    {
      "epoch": 0.8763791671609918,
      "grad_norm": 2.817873239517212,
      "learning_rate": 2.747165831795413e-06,
      "loss": 0.0619,
      "step": 14774
    },
    {
      "epoch": 0.8764384861786689,
      "grad_norm": 0.05997190997004509,
      "learning_rate": 2.7458476140258372e-06,
      "loss": 0.0009,
      "step": 14775
    },
    {
      "epoch": 0.8764978051963459,
      "grad_norm": 9.794760704040527,
      "learning_rate": 2.744529396256262e-06,
      "loss": 0.1884,
      "step": 14776
    },
    {
      "epoch": 0.876557124214023,
      "grad_norm": 10.489660263061523,
      "learning_rate": 2.743211178486686e-06,
      "loss": 0.0566,
      "step": 14777
    },
    {
      "epoch": 0.8766164432317001,
      "grad_norm": 0.012757103890180588,
      "learning_rate": 2.7418929607171106e-06,
      "loss": 0.0003,
      "step": 14778
    },
    {
      "epoch": 0.8766757622493772,
      "grad_norm": 16.36029624938965,
      "learning_rate": 2.740574742947535e-06,
      "loss": 0.1039,
      "step": 14779
    },
    {
      "epoch": 0.8767350812670542,
      "grad_norm": 19.190582275390625,
      "learning_rate": 2.7392565251779594e-06,
      "loss": 0.7537,
      "step": 14780
    },
    {
      "epoch": 0.8767944002847313,
      "grad_norm": 4.136425018310547,
      "learning_rate": 2.7379383074083845e-06,
      "loss": 0.1244,
      "step": 14781
    },
    {
      "epoch": 0.8768537193024084,
      "grad_norm": 0.006822510622441769,
      "learning_rate": 2.7366200896388082e-06,
      "loss": 0.0002,
      "step": 14782
    },
    {
      "epoch": 0.8769130383200854,
      "grad_norm": 0.018539967015385628,
      "learning_rate": 2.7353018718692333e-06,
      "loss": 0.0004,
      "step": 14783
    },
    {
      "epoch": 0.8769723573377625,
      "grad_norm": 0.012014349922537804,
      "learning_rate": 2.7339836540996574e-06,
      "loss": 0.0003,
      "step": 14784
    },
    {
      "epoch": 0.8770316763554395,
      "grad_norm": 2.5613350868225098,
      "learning_rate": 2.732665436330082e-06,
      "loss": 0.1367,
      "step": 14785
    },
    {
      "epoch": 0.8770909953731166,
      "grad_norm": 0.00546450586989522,
      "learning_rate": 2.7313472185605067e-06,
      "loss": 0.0002,
      "step": 14786
    },
    {
      "epoch": 0.8771503143907937,
      "grad_norm": 0.01848839595913887,
      "learning_rate": 2.730029000790931e-06,
      "loss": 0.0004,
      "step": 14787
    },
    {
      "epoch": 0.8772096334084708,
      "grad_norm": 0.12521685659885406,
      "learning_rate": 2.7287107830213555e-06,
      "loss": 0.0016,
      "step": 14788
    },
    {
      "epoch": 0.8772689524261478,
      "grad_norm": 0.061056435108184814,
      "learning_rate": 2.7273925652517796e-06,
      "loss": 0.0006,
      "step": 14789
    },
    {
      "epoch": 0.8773282714438249,
      "grad_norm": 17.579296112060547,
      "learning_rate": 2.7260743474822043e-06,
      "loss": 0.2866,
      "step": 14790
    },
    {
      "epoch": 0.8773875904615019,
      "grad_norm": 0.008525781333446503,
      "learning_rate": 2.7247561297126284e-06,
      "loss": 0.0002,
      "step": 14791
    },
    {
      "epoch": 0.877446909479179,
      "grad_norm": 0.3504717946052551,
      "learning_rate": 2.723437911943053e-06,
      "loss": 0.0064,
      "step": 14792
    },
    {
      "epoch": 0.8775062284968561,
      "grad_norm": 3.5564301013946533,
      "learning_rate": 2.7221196941734777e-06,
      "loss": 0.0487,
      "step": 14793
    },
    {
      "epoch": 0.8775655475145332,
      "grad_norm": 0.07557666301727295,
      "learning_rate": 2.720801476403902e-06,
      "loss": 0.0012,
      "step": 14794
    },
    {
      "epoch": 0.8776248665322103,
      "grad_norm": 2.3672564029693604,
      "learning_rate": 2.719483258634327e-06,
      "loss": 0.0162,
      "step": 14795
    },
    {
      "epoch": 0.8776841855498873,
      "grad_norm": 0.3745761811733246,
      "learning_rate": 2.7181650408647507e-06,
      "loss": 0.0047,
      "step": 14796
    },
    {
      "epoch": 0.8777435045675643,
      "grad_norm": 8.071126937866211,
      "learning_rate": 2.7168468230951757e-06,
      "loss": 0.0425,
      "step": 14797
    },
    {
      "epoch": 0.8778028235852414,
      "grad_norm": 0.01167707797139883,
      "learning_rate": 2.7155286053256003e-06,
      "loss": 0.0003,
      "step": 14798
    },
    {
      "epoch": 0.8778621426029185,
      "grad_norm": 4.31454610824585,
      "learning_rate": 2.7142103875560245e-06,
      "loss": 0.0871,
      "step": 14799
    },
    {
      "epoch": 0.8779214616205956,
      "grad_norm": 0.7102363109588623,
      "learning_rate": 2.712892169786449e-06,
      "loss": 0.0041,
      "step": 14800
    },
    {
      "epoch": 0.8779807806382727,
      "grad_norm": 0.09821117669343948,
      "learning_rate": 2.7115739520168733e-06,
      "loss": 0.0019,
      "step": 14801
    },
    {
      "epoch": 0.8780400996559496,
      "grad_norm": 0.032421186566352844,
      "learning_rate": 2.710255734247298e-06,
      "loss": 0.0005,
      "step": 14802
    },
    {
      "epoch": 0.8780994186736267,
      "grad_norm": 6.579758644104004,
      "learning_rate": 2.708937516477722e-06,
      "loss": 0.3725,
      "step": 14803
    },
    {
      "epoch": 0.8781587376913038,
      "grad_norm": 0.03434029594063759,
      "learning_rate": 2.7076192987081467e-06,
      "loss": 0.0004,
      "step": 14804
    },
    {
      "epoch": 0.8782180567089809,
      "grad_norm": 4.030757904052734,
      "learning_rate": 2.7063010809385713e-06,
      "loss": 0.0394,
      "step": 14805
    },
    {
      "epoch": 0.878277375726658,
      "grad_norm": 2.3422157764434814,
      "learning_rate": 2.7049828631689955e-06,
      "loss": 0.0378,
      "step": 14806
    },
    {
      "epoch": 0.8783366947443351,
      "grad_norm": 0.024569060653448105,
      "learning_rate": 2.70366464539942e-06,
      "loss": 0.0006,
      "step": 14807
    },
    {
      "epoch": 0.8783960137620122,
      "grad_norm": 2.3883349895477295,
      "learning_rate": 2.7023464276298443e-06,
      "loss": 0.0085,
      "step": 14808
    },
    {
      "epoch": 0.8784553327796891,
      "grad_norm": 27.59809112548828,
      "learning_rate": 2.7010282098602693e-06,
      "loss": 1.5391,
      "step": 14809
    },
    {
      "epoch": 0.8785146517973662,
      "grad_norm": 0.17099915444850922,
      "learning_rate": 2.699709992090694e-06,
      "loss": 0.0023,
      "step": 14810
    },
    {
      "epoch": 0.8785739708150433,
      "grad_norm": 0.1194726899266243,
      "learning_rate": 2.698391774321118e-06,
      "loss": 0.0014,
      "step": 14811
    },
    {
      "epoch": 0.8786332898327204,
      "grad_norm": 2.2748568058013916,
      "learning_rate": 2.6970735565515427e-06,
      "loss": 0.0164,
      "step": 14812
    },
    {
      "epoch": 0.8786926088503975,
      "grad_norm": 29.962491989135742,
      "learning_rate": 2.695755338781967e-06,
      "loss": 0.2305,
      "step": 14813
    },
    {
      "epoch": 0.8787519278680745,
      "grad_norm": 5.659817695617676,
      "learning_rate": 2.6944371210123915e-06,
      "loss": 0.1225,
      "step": 14814
    },
    {
      "epoch": 0.8788112468857515,
      "grad_norm": 11.03980827331543,
      "learning_rate": 2.6931189032428157e-06,
      "loss": 0.2282,
      "step": 14815
    },
    {
      "epoch": 0.8788705659034286,
      "grad_norm": 0.016805008053779602,
      "learning_rate": 2.6918006854732403e-06,
      "loss": 0.0006,
      "step": 14816
    },
    {
      "epoch": 0.8789298849211057,
      "grad_norm": 0.20409750938415527,
      "learning_rate": 2.690482467703665e-06,
      "loss": 0.0015,
      "step": 14817
    },
    {
      "epoch": 0.8789892039387828,
      "grad_norm": 1.2260977029800415,
      "learning_rate": 2.689164249934089e-06,
      "loss": 0.0077,
      "step": 14818
    },
    {
      "epoch": 0.8790485229564599,
      "grad_norm": 0.8213498592376709,
      "learning_rate": 2.6878460321645137e-06,
      "loss": 0.0036,
      "step": 14819
    },
    {
      "epoch": 0.8791078419741369,
      "grad_norm": 0.013426322489976883,
      "learning_rate": 2.686527814394938e-06,
      "loss": 0.0003,
      "step": 14820
    },
    {
      "epoch": 0.879167160991814,
      "grad_norm": 4.246140480041504,
      "learning_rate": 2.6852095966253625e-06,
      "loss": 0.0503,
      "step": 14821
    },
    {
      "epoch": 0.879226480009491,
      "grad_norm": 0.1739559918642044,
      "learning_rate": 2.6838913788557876e-06,
      "loss": 0.0006,
      "step": 14822
    },
    {
      "epoch": 0.8792857990271681,
      "grad_norm": 3.4593234062194824,
      "learning_rate": 2.6825731610862118e-06,
      "loss": 0.0277,
      "step": 14823
    },
    {
      "epoch": 0.8793451180448452,
      "grad_norm": 0.010014506056904793,
      "learning_rate": 2.6812549433166364e-06,
      "loss": 0.0002,
      "step": 14824
    },
    {
      "epoch": 0.8794044370625222,
      "grad_norm": 0.10348421335220337,
      "learning_rate": 2.6799367255470605e-06,
      "loss": 0.0024,
      "step": 14825
    },
    {
      "epoch": 0.8794637560801993,
      "grad_norm": 0.11422878503799438,
      "learning_rate": 2.678618507777485e-06,
      "loss": 0.0022,
      "step": 14826
    },
    {
      "epoch": 0.8795230750978764,
      "grad_norm": 6.541881561279297,
      "learning_rate": 2.6773002900079093e-06,
      "loss": 0.1699,
      "step": 14827
    },
    {
      "epoch": 0.8795823941155535,
      "grad_norm": 16.604310989379883,
      "learning_rate": 2.675982072238334e-06,
      "loss": 0.1135,
      "step": 14828
    },
    {
      "epoch": 0.8796417131332305,
      "grad_norm": 1.600062608718872,
      "learning_rate": 2.6746638544687586e-06,
      "loss": 0.0174,
      "step": 14829
    },
    {
      "epoch": 0.8797010321509076,
      "grad_norm": 2.7502849102020264,
      "learning_rate": 2.6733456366991828e-06,
      "loss": 0.0314,
      "step": 14830
    },
    {
      "epoch": 0.8797603511685846,
      "grad_norm": 0.11250331252813339,
      "learning_rate": 2.6720274189296074e-06,
      "loss": 0.0017,
      "step": 14831
    },
    {
      "epoch": 0.8798196701862617,
      "grad_norm": 3.234916925430298,
      "learning_rate": 2.6707092011600316e-06,
      "loss": 0.057,
      "step": 14832
    },
    {
      "epoch": 0.8798789892039388,
      "grad_norm": 0.4259580075740814,
      "learning_rate": 2.669390983390456e-06,
      "loss": 0.0041,
      "step": 14833
    },
    {
      "epoch": 0.8799383082216159,
      "grad_norm": 9.231945037841797,
      "learning_rate": 2.668072765620881e-06,
      "loss": 0.1397,
      "step": 14834
    },
    {
      "epoch": 0.8799976272392929,
      "grad_norm": 24.15550422668457,
      "learning_rate": 2.666754547851305e-06,
      "loss": 0.2655,
      "step": 14835
    },
    {
      "epoch": 0.88005694625697,
      "grad_norm": 0.013627277687191963,
      "learning_rate": 2.66543633008173e-06,
      "loss": 0.0003,
      "step": 14836
    },
    {
      "epoch": 0.880116265274647,
      "grad_norm": 16.490400314331055,
      "learning_rate": 2.664118112312154e-06,
      "loss": 0.2224,
      "step": 14837
    },
    {
      "epoch": 0.8801755842923241,
      "grad_norm": 16.81479263305664,
      "learning_rate": 2.662799894542579e-06,
      "loss": 0.2059,
      "step": 14838
    },
    {
      "epoch": 0.8802349033100012,
      "grad_norm": 0.29928281903266907,
      "learning_rate": 2.661481676773003e-06,
      "loss": 0.0032,
      "step": 14839
    },
    {
      "epoch": 0.8802942223276783,
      "grad_norm": 8.499970436096191,
      "learning_rate": 2.6601634590034276e-06,
      "loss": 0.269,
      "step": 14840
    },
    {
      "epoch": 0.8803535413453554,
      "grad_norm": 0.06927710026502609,
      "learning_rate": 2.658845241233852e-06,
      "loss": 0.0009,
      "step": 14841
    },
    {
      "epoch": 0.8804128603630323,
      "grad_norm": 4.513315677642822,
      "learning_rate": 2.6575270234642764e-06,
      "loss": 0.0083,
      "step": 14842
    },
    {
      "epoch": 0.8804721793807094,
      "grad_norm": 4.46071195602417,
      "learning_rate": 2.656208805694701e-06,
      "loss": 0.042,
      "step": 14843
    },
    {
      "epoch": 0.8805314983983865,
      "grad_norm": 0.11795075982809067,
      "learning_rate": 2.654890587925125e-06,
      "loss": 0.0008,
      "step": 14844
    },
    {
      "epoch": 0.8805908174160636,
      "grad_norm": 0.12603212893009186,
      "learning_rate": 2.65357237015555e-06,
      "loss": 0.0013,
      "step": 14845
    },
    {
      "epoch": 0.8806501364337407,
      "grad_norm": 0.1794646978378296,
      "learning_rate": 2.6522541523859744e-06,
      "loss": 0.0023,
      "step": 14846
    },
    {
      "epoch": 0.8807094554514178,
      "grad_norm": 9.478180885314941,
      "learning_rate": 2.6509359346163986e-06,
      "loss": 0.102,
      "step": 14847
    },
    {
      "epoch": 0.8807687744690947,
      "grad_norm": 16.705421447753906,
      "learning_rate": 2.6496177168468236e-06,
      "loss": 0.6084,
      "step": 14848
    },
    {
      "epoch": 0.8808280934867718,
      "grad_norm": 24.519899368286133,
      "learning_rate": 2.6482994990772474e-06,
      "loss": 0.6177,
      "step": 14849
    },
    {
      "epoch": 0.8808874125044489,
      "grad_norm": 0.03080884926021099,
      "learning_rate": 2.6469812813076724e-06,
      "loss": 0.0006,
      "step": 14850
    },
    {
      "epoch": 0.880946731522126,
      "grad_norm": 1.1207654476165771,
      "learning_rate": 2.645663063538097e-06,
      "loss": 0.008,
      "step": 14851
    },
    {
      "epoch": 0.8810060505398031,
      "grad_norm": 1.5163066387176514,
      "learning_rate": 2.6443448457685212e-06,
      "loss": 0.0067,
      "step": 14852
    },
    {
      "epoch": 0.8810653695574802,
      "grad_norm": 0.11128849536180496,
      "learning_rate": 2.643026627998946e-06,
      "loss": 0.0016,
      "step": 14853
    },
    {
      "epoch": 0.8811246885751572,
      "grad_norm": 7.499031066894531,
      "learning_rate": 2.64170841022937e-06,
      "loss": 0.0412,
      "step": 14854
    },
    {
      "epoch": 0.8811840075928342,
      "grad_norm": 8.011241912841797,
      "learning_rate": 2.6403901924597946e-06,
      "loss": 0.1279,
      "step": 14855
    },
    {
      "epoch": 0.8812433266105113,
      "grad_norm": 7.606418609619141,
      "learning_rate": 2.639071974690219e-06,
      "loss": 0.2485,
      "step": 14856
    },
    {
      "epoch": 0.8813026456281884,
      "grad_norm": 11.249507904052734,
      "learning_rate": 2.6377537569206434e-06,
      "loss": 0.432,
      "step": 14857
    },
    {
      "epoch": 0.8813619646458655,
      "grad_norm": 0.010412697680294514,
      "learning_rate": 2.636435539151068e-06,
      "loss": 0.0002,
      "step": 14858
    },
    {
      "epoch": 0.8814212836635426,
      "grad_norm": 0.20688855648040771,
      "learning_rate": 2.6351173213814922e-06,
      "loss": 0.0024,
      "step": 14859
    },
    {
      "epoch": 0.8814806026812196,
      "grad_norm": 18.303895950317383,
      "learning_rate": 2.633799103611917e-06,
      "loss": 0.916,
      "step": 14860
    },
    {
      "epoch": 0.8815399216988966,
      "grad_norm": 1.6670440435409546,
      "learning_rate": 2.632480885842341e-06,
      "loss": 0.022,
      "step": 14861
    },
    {
      "epoch": 0.8815992407165737,
      "grad_norm": 0.00780366500839591,
      "learning_rate": 2.631162668072766e-06,
      "loss": 0.0002,
      "step": 14862
    },
    {
      "epoch": 0.8816585597342508,
      "grad_norm": 0.013856223784387112,
      "learning_rate": 2.6298444503031907e-06,
      "loss": 0.0003,
      "step": 14863
    },
    {
      "epoch": 0.8817178787519279,
      "grad_norm": 7.10850191116333,
      "learning_rate": 2.628526232533615e-06,
      "loss": 0.0889,
      "step": 14864
    },
    {
      "epoch": 0.881777197769605,
      "grad_norm": 0.26587584614753723,
      "learning_rate": 2.6272080147640395e-06,
      "loss": 0.0031,
      "step": 14865
    },
    {
      "epoch": 0.881836516787282,
      "grad_norm": 0.8538606762886047,
      "learning_rate": 2.6258897969944637e-06,
      "loss": 0.0151,
      "step": 14866
    },
    {
      "epoch": 0.8818958358049591,
      "grad_norm": 7.330077648162842,
      "learning_rate": 2.6245715792248883e-06,
      "loss": 0.0901,
      "step": 14867
    },
    {
      "epoch": 0.8819551548226361,
      "grad_norm": 0.024624546989798546,
      "learning_rate": 2.6232533614553125e-06,
      "loss": 0.0004,
      "step": 14868
    },
    {
      "epoch": 0.8820144738403132,
      "grad_norm": 0.012737379409372807,
      "learning_rate": 2.621935143685737e-06,
      "loss": 0.0003,
      "step": 14869
    },
    {
      "epoch": 0.8820737928579903,
      "grad_norm": 0.021784817799925804,
      "learning_rate": 2.6206169259161617e-06,
      "loss": 0.0004,
      "step": 14870
    },
    {
      "epoch": 0.8821331118756673,
      "grad_norm": 0.04344784468412399,
      "learning_rate": 2.619298708146586e-06,
      "loss": 0.0011,
      "step": 14871
    },
    {
      "epoch": 0.8821924308933444,
      "grad_norm": 0.021538404747843742,
      "learning_rate": 2.6179804903770105e-06,
      "loss": 0.0004,
      "step": 14872
    },
    {
      "epoch": 0.8822517499110215,
      "grad_norm": 0.6989273428916931,
      "learning_rate": 2.6166622726074347e-06,
      "loss": 0.0057,
      "step": 14873
    },
    {
      "epoch": 0.8823110689286986,
      "grad_norm": 0.3809240162372589,
      "learning_rate": 2.6153440548378593e-06,
      "loss": 0.0037,
      "step": 14874
    },
    {
      "epoch": 0.8823703879463756,
      "grad_norm": 9.213849067687988,
      "learning_rate": 2.6140258370682843e-06,
      "loss": 0.3542,
      "step": 14875
    },
    {
      "epoch": 0.8824297069640527,
      "grad_norm": 3.164430856704712,
      "learning_rate": 2.6127076192987085e-06,
      "loss": 0.0279,
      "step": 14876
    },
    {
      "epoch": 0.8824890259817297,
      "grad_norm": 8.321151733398438,
      "learning_rate": 2.611389401529133e-06,
      "loss": 0.2337,
      "step": 14877
    },
    {
      "epoch": 0.8825483449994068,
      "grad_norm": 4.3815226554870605,
      "learning_rate": 2.6100711837595573e-06,
      "loss": 0.0137,
      "step": 14878
    },
    {
      "epoch": 0.8826076640170839,
      "grad_norm": 0.027935879305005074,
      "learning_rate": 2.608752965989982e-06,
      "loss": 0.0005,
      "step": 14879
    },
    {
      "epoch": 0.882666983034761,
      "grad_norm": 0.05374268442392349,
      "learning_rate": 2.607434748220406e-06,
      "loss": 0.0016,
      "step": 14880
    },
    {
      "epoch": 0.882726302052438,
      "grad_norm": 1.8313220739364624,
      "learning_rate": 2.6061165304508307e-06,
      "loss": 0.0341,
      "step": 14881
    },
    {
      "epoch": 0.882785621070115,
      "grad_norm": 4.670956134796143,
      "learning_rate": 2.6047983126812553e-06,
      "loss": 0.4939,
      "step": 14882
    },
    {
      "epoch": 0.8828449400877921,
      "grad_norm": 1.1295857429504395,
      "learning_rate": 2.6034800949116795e-06,
      "loss": 0.0215,
      "step": 14883
    },
    {
      "epoch": 0.8829042591054692,
      "grad_norm": 0.011063714511692524,
      "learning_rate": 2.602161877142104e-06,
      "loss": 0.0003,
      "step": 14884
    },
    {
      "epoch": 0.8829635781231463,
      "grad_norm": 0.1065763384103775,
      "learning_rate": 2.6008436593725283e-06,
      "loss": 0.0028,
      "step": 14885
    },
    {
      "epoch": 0.8830228971408234,
      "grad_norm": 1.444061279296875,
      "learning_rate": 2.599525441602953e-06,
      "loss": 0.0104,
      "step": 14886
    },
    {
      "epoch": 0.8830822161585005,
      "grad_norm": 0.009699875488877296,
      "learning_rate": 2.598207223833378e-06,
      "loss": 0.0003,
      "step": 14887
    },
    {
      "epoch": 0.8831415351761774,
      "grad_norm": 15.044519424438477,
      "learning_rate": 2.5968890060638017e-06,
      "loss": 0.1128,
      "step": 14888
    },
    {
      "epoch": 0.8832008541938545,
      "grad_norm": 0.41300997138023376,
      "learning_rate": 2.5955707882942267e-06,
      "loss": 0.0055,
      "step": 14889
    },
    {
      "epoch": 0.8832601732115316,
      "grad_norm": 0.7589124441146851,
      "learning_rate": 2.594252570524651e-06,
      "loss": 0.0084,
      "step": 14890
    },
    {
      "epoch": 0.8833194922292087,
      "grad_norm": 0.3336983323097229,
      "learning_rate": 2.5929343527550755e-06,
      "loss": 0.0061,
      "step": 14891
    },
    {
      "epoch": 0.8833788112468858,
      "grad_norm": 0.06749347597360611,
      "learning_rate": 2.5916161349854997e-06,
      "loss": 0.0012,
      "step": 14892
    },
    {
      "epoch": 0.8834381302645629,
      "grad_norm": 1.934871792793274,
      "learning_rate": 2.5902979172159243e-06,
      "loss": 0.0242,
      "step": 14893
    },
    {
      "epoch": 0.8834974492822398,
      "grad_norm": 0.01103905588388443,
      "learning_rate": 2.588979699446349e-06,
      "loss": 0.0002,
      "step": 14894
    },
    {
      "epoch": 0.8835567682999169,
      "grad_norm": 0.01997946947813034,
      "learning_rate": 2.587661481676773e-06,
      "loss": 0.0003,
      "step": 14895
    },
    {
      "epoch": 0.883616087317594,
      "grad_norm": 2.3106250762939453,
      "learning_rate": 2.5863432639071977e-06,
      "loss": 0.1539,
      "step": 14896
    },
    {
      "epoch": 0.8836754063352711,
      "grad_norm": 0.5884008407592773,
      "learning_rate": 2.585025046137622e-06,
      "loss": 0.0035,
      "step": 14897
    },
    {
      "epoch": 0.8837347253529482,
      "grad_norm": 14.932547569274902,
      "learning_rate": 2.5837068283680465e-06,
      "loss": 0.1958,
      "step": 14898
    },
    {
      "epoch": 0.8837940443706253,
      "grad_norm": 30.3044490814209,
      "learning_rate": 2.582388610598471e-06,
      "loss": 0.2681,
      "step": 14899
    },
    {
      "epoch": 0.8838533633883023,
      "grad_norm": 0.013348043896257877,
      "learning_rate": 2.5810703928288953e-06,
      "loss": 0.0003,
      "step": 14900
    },
    {
      "epoch": 0.8839126824059793,
      "grad_norm": 1.3564198017120361,
      "learning_rate": 2.5797521750593204e-06,
      "loss": 0.0064,
      "step": 14901
    },
    {
      "epoch": 0.8839720014236564,
      "grad_norm": 1.4983793497085571,
      "learning_rate": 2.578433957289744e-06,
      "loss": 0.0213,
      "step": 14902
    },
    {
      "epoch": 0.8840313204413335,
      "grad_norm": 8.921266555786133,
      "learning_rate": 2.577115739520169e-06,
      "loss": 0.0765,
      "step": 14903
    },
    {
      "epoch": 0.8840906394590106,
      "grad_norm": 26.936309814453125,
      "learning_rate": 2.5757975217505934e-06,
      "loss": 0.6277,
      "step": 14904
    },
    {
      "epoch": 0.8841499584766876,
      "grad_norm": 7.370651721954346,
      "learning_rate": 2.574479303981018e-06,
      "loss": 0.0853,
      "step": 14905
    },
    {
      "epoch": 0.8842092774943647,
      "grad_norm": 0.16045664250850677,
      "learning_rate": 2.5731610862114426e-06,
      "loss": 0.0048,
      "step": 14906
    },
    {
      "epoch": 0.8842685965120418,
      "grad_norm": 0.06850072741508484,
      "learning_rate": 2.5718428684418668e-06,
      "loss": 0.0014,
      "step": 14907
    },
    {
      "epoch": 0.8843279155297188,
      "grad_norm": 0.04845098778605461,
      "learning_rate": 2.5705246506722914e-06,
      "loss": 0.0006,
      "step": 14908
    },
    {
      "epoch": 0.8843872345473959,
      "grad_norm": 0.019361095502972603,
      "learning_rate": 2.5692064329027156e-06,
      "loss": 0.0004,
      "step": 14909
    },
    {
      "epoch": 0.884446553565073,
      "grad_norm": 25.749422073364258,
      "learning_rate": 2.56788821513314e-06,
      "loss": 0.5457,
      "step": 14910
    },
    {
      "epoch": 0.88450587258275,
      "grad_norm": 0.037425849586725235,
      "learning_rate": 2.5665699973635648e-06,
      "loss": 0.0008,
      "step": 14911
    },
    {
      "epoch": 0.8845651916004271,
      "grad_norm": 12.456337928771973,
      "learning_rate": 2.565251779593989e-06,
      "loss": 0.3232,
      "step": 14912
    },
    {
      "epoch": 0.8846245106181042,
      "grad_norm": 0.45405420660972595,
      "learning_rate": 2.5639335618244136e-06,
      "loss": 0.0058,
      "step": 14913
    },
    {
      "epoch": 0.8846838296357812,
      "grad_norm": 0.37534818053245544,
      "learning_rate": 2.5626153440548378e-06,
      "loss": 0.0025,
      "step": 14914
    },
    {
      "epoch": 0.8847431486534583,
      "grad_norm": 0.5621738433837891,
      "learning_rate": 2.561297126285263e-06,
      "loss": 0.0055,
      "step": 14915
    },
    {
      "epoch": 0.8848024676711354,
      "grad_norm": 7.575554847717285,
      "learning_rate": 2.5599789085156866e-06,
      "loss": 0.3357,
      "step": 14916
    },
    {
      "epoch": 0.8848617866888124,
      "grad_norm": 0.9438936114311218,
      "learning_rate": 2.5586606907461116e-06,
      "loss": 0.0144,
      "step": 14917
    },
    {
      "epoch": 0.8849211057064895,
      "grad_norm": 0.025859778746962547,
      "learning_rate": 2.557342472976536e-06,
      "loss": 0.0007,
      "step": 14918
    },
    {
      "epoch": 0.8849804247241666,
      "grad_norm": 0.013550860807299614,
      "learning_rate": 2.5560242552069604e-06,
      "loss": 0.0004,
      "step": 14919
    },
    {
      "epoch": 0.8850397437418437,
      "grad_norm": 0.5797721147537231,
      "learning_rate": 2.554706037437385e-06,
      "loss": 0.0082,
      "step": 14920
    },
    {
      "epoch": 0.8850990627595207,
      "grad_norm": 0.03948352113366127,
      "learning_rate": 2.553387819667809e-06,
      "loss": 0.0006,
      "step": 14921
    },
    {
      "epoch": 0.8851583817771977,
      "grad_norm": 0.3038841187953949,
      "learning_rate": 2.552069601898234e-06,
      "loss": 0.0042,
      "step": 14922
    },
    {
      "epoch": 0.8852177007948748,
      "grad_norm": 0.03463304042816162,
      "learning_rate": 2.5507513841286584e-06,
      "loss": 0.0004,
      "step": 14923
    },
    {
      "epoch": 0.8852770198125519,
      "grad_norm": 2.268842935562134,
      "learning_rate": 2.5494331663590826e-06,
      "loss": 0.023,
      "step": 14924
    },
    {
      "epoch": 0.885336338830229,
      "grad_norm": 15.109891891479492,
      "learning_rate": 2.548114948589507e-06,
      "loss": 0.2189,
      "step": 14925
    },
    {
      "epoch": 0.8853956578479061,
      "grad_norm": 0.05454068258404732,
      "learning_rate": 2.5467967308199314e-06,
      "loss": 0.0014,
      "step": 14926
    },
    {
      "epoch": 0.885454976865583,
      "grad_norm": 5.334586143493652,
      "learning_rate": 2.545478513050356e-06,
      "loss": 0.1395,
      "step": 14927
    },
    {
      "epoch": 0.8855142958832601,
      "grad_norm": 3.201716899871826,
      "learning_rate": 2.54416029528078e-06,
      "loss": 0.0575,
      "step": 14928
    },
    {
      "epoch": 0.8855736149009372,
      "grad_norm": 6.047179222106934,
      "learning_rate": 2.5428420775112052e-06,
      "loss": 0.1366,
      "step": 14929
    },
    {
      "epoch": 0.8856329339186143,
      "grad_norm": 7.723416328430176,
      "learning_rate": 2.54152385974163e-06,
      "loss": 0.0737,
      "step": 14930
    },
    {
      "epoch": 0.8856922529362914,
      "grad_norm": 0.31805235147476196,
      "learning_rate": 2.540205641972054e-06,
      "loss": 0.0036,
      "step": 14931
    },
    {
      "epoch": 0.8857515719539685,
      "grad_norm": 2.468395471572876,
      "learning_rate": 2.5388874242024786e-06,
      "loss": 0.0409,
      "step": 14932
    },
    {
      "epoch": 0.8858108909716456,
      "grad_norm": 0.04470806196331978,
      "learning_rate": 2.537569206432903e-06,
      "loss": 0.0006,
      "step": 14933
    },
    {
      "epoch": 0.8858702099893225,
      "grad_norm": 0.5872378945350647,
      "learning_rate": 2.5362509886633274e-06,
      "loss": 0.0065,
      "step": 14934
    },
    {
      "epoch": 0.8859295290069996,
      "grad_norm": 0.026243867352604866,
      "learning_rate": 2.534932770893752e-06,
      "loss": 0.0003,
      "step": 14935
    },
    {
      "epoch": 0.8859888480246767,
      "grad_norm": 2.36055064201355,
      "learning_rate": 2.5336145531241762e-06,
      "loss": 0.0214,
      "step": 14936
    },
    {
      "epoch": 0.8860481670423538,
      "grad_norm": 0.38797706365585327,
      "learning_rate": 2.532296335354601e-06,
      "loss": 0.0052,
      "step": 14937
    },
    {
      "epoch": 0.8861074860600309,
      "grad_norm": 0.015579534694552422,
      "learning_rate": 2.530978117585025e-06,
      "loss": 0.0004,
      "step": 14938
    },
    {
      "epoch": 0.886166805077708,
      "grad_norm": 0.03096349909901619,
      "learning_rate": 2.5296598998154496e-06,
      "loss": 0.001,
      "step": 14939
    },
    {
      "epoch": 0.8862261240953849,
      "grad_norm": 0.5978389978408813,
      "learning_rate": 2.528341682045874e-06,
      "loss": 0.007,
      "step": 14940
    },
    {
      "epoch": 0.886285443113062,
      "grad_norm": 10.453812599182129,
      "learning_rate": 2.5270234642762984e-06,
      "loss": 0.1115,
      "step": 14941
    },
    {
      "epoch": 0.8863447621307391,
      "grad_norm": 4.542910099029541,
      "learning_rate": 2.5257052465067235e-06,
      "loss": 0.2451,
      "step": 14942
    },
    {
      "epoch": 0.8864040811484162,
      "grad_norm": 2.700411558151245,
      "learning_rate": 2.5243870287371477e-06,
      "loss": 0.0118,
      "step": 14943
    },
    {
      "epoch": 0.8864634001660933,
      "grad_norm": 0.04500851780176163,
      "learning_rate": 2.5230688109675723e-06,
      "loss": 0.0007,
      "step": 14944
    },
    {
      "epoch": 0.8865227191837703,
      "grad_norm": 2.8304502964019775,
      "learning_rate": 2.5217505931979965e-06,
      "loss": 0.0276,
      "step": 14945
    },
    {
      "epoch": 0.8865820382014474,
      "grad_norm": 0.0046812803484499454,
      "learning_rate": 2.520432375428421e-06,
      "loss": 0.0002,
      "step": 14946
    },
    {
      "epoch": 0.8866413572191244,
      "grad_norm": 0.36801496148109436,
      "learning_rate": 2.5191141576588457e-06,
      "loss": 0.0029,
      "step": 14947
    },
    {
      "epoch": 0.8867006762368015,
      "grad_norm": 0.3685204088687897,
      "learning_rate": 2.51779593988927e-06,
      "loss": 0.0038,
      "step": 14948
    },
    {
      "epoch": 0.8867599952544786,
      "grad_norm": 18.52433967590332,
      "learning_rate": 2.5164777221196945e-06,
      "loss": 0.1005,
      "step": 14949
    },
    {
      "epoch": 0.8868193142721557,
      "grad_norm": 29.30604362487793,
      "learning_rate": 2.5151595043501187e-06,
      "loss": 0.6354,
      "step": 14950
    },
    {
      "epoch": 0.8868786332898327,
      "grad_norm": 4.87054443359375,
      "learning_rate": 2.5138412865805433e-06,
      "loss": 0.0346,
      "step": 14951
    },
    {
      "epoch": 0.8869379523075098,
      "grad_norm": 10.780394554138184,
      "learning_rate": 2.5125230688109675e-06,
      "loss": 0.2443,
      "step": 14952
    },
    {
      "epoch": 0.8869972713251869,
      "grad_norm": 0.304706871509552,
      "learning_rate": 2.511204851041392e-06,
      "loss": 0.0017,
      "step": 14953
    },
    {
      "epoch": 0.8870565903428639,
      "grad_norm": 0.35044631361961365,
      "learning_rate": 2.509886633271817e-06,
      "loss": 0.0018,
      "step": 14954
    },
    {
      "epoch": 0.887115909360541,
      "grad_norm": 3.656707763671875,
      "learning_rate": 2.508568415502241e-06,
      "loss": 0.0401,
      "step": 14955
    },
    {
      "epoch": 0.887175228378218,
      "grad_norm": 3.5855185985565186,
      "learning_rate": 2.507250197732666e-06,
      "loss": 0.1036,
      "step": 14956
    },
    {
      "epoch": 0.8872345473958951,
      "grad_norm": 1.8075025081634521,
      "learning_rate": 2.50593197996309e-06,
      "loss": 0.0148,
      "step": 14957
    },
    {
      "epoch": 0.8872938664135722,
      "grad_norm": 0.15999053418636322,
      "learning_rate": 2.5046137621935147e-06,
      "loss": 0.0015,
      "step": 14958
    },
    {
      "epoch": 0.8873531854312493,
      "grad_norm": 0.05440153926610947,
      "learning_rate": 2.5032955444239393e-06,
      "loss": 0.0013,
      "step": 14959
    },
    {
      "epoch": 0.8874125044489263,
      "grad_norm": 0.0185086689889431,
      "learning_rate": 2.5019773266543635e-06,
      "loss": 0.0004,
      "step": 14960
    },
    {
      "epoch": 0.8874718234666034,
      "grad_norm": 0.031024564057588577,
      "learning_rate": 2.500659108884788e-06,
      "loss": 0.0007,
      "step": 14961
    },
    {
      "epoch": 0.8875311424842804,
      "grad_norm": 8.505011558532715,
      "learning_rate": 2.4993408911152127e-06,
      "loss": 0.0613,
      "step": 14962
    },
    {
      "epoch": 0.8875904615019575,
      "grad_norm": 0.059247009456157684,
      "learning_rate": 2.498022673345637e-06,
      "loss": 0.0011,
      "step": 14963
    },
    {
      "epoch": 0.8876497805196346,
      "grad_norm": 0.07039569318294525,
      "learning_rate": 2.4967044555760615e-06,
      "loss": 0.0016,
      "step": 14964
    },
    {
      "epoch": 0.8877090995373117,
      "grad_norm": 11.28990364074707,
      "learning_rate": 2.4953862378064857e-06,
      "loss": 0.3555,
      "step": 14965
    },
    {
      "epoch": 0.8877684185549888,
      "grad_norm": 8.470718383789062,
      "learning_rate": 2.4940680200369103e-06,
      "loss": 0.1022,
      "step": 14966
    },
    {
      "epoch": 0.8878277375726658,
      "grad_norm": 8.865449905395508,
      "learning_rate": 2.4927498022673345e-06,
      "loss": 0.1099,
      "step": 14967
    },
    {
      "epoch": 0.8878870565903428,
      "grad_norm": 0.029398012906312943,
      "learning_rate": 2.4914315844977595e-06,
      "loss": 0.0007,
      "step": 14968
    },
    {
      "epoch": 0.8879463756080199,
      "grad_norm": 0.040880851447582245,
      "learning_rate": 2.4901133667281837e-06,
      "loss": 0.0008,
      "step": 14969
    },
    {
      "epoch": 0.888005694625697,
      "grad_norm": 0.08240580558776855,
      "learning_rate": 2.4887951489586083e-06,
      "loss": 0.0006,
      "step": 14970
    },
    {
      "epoch": 0.8880650136433741,
      "grad_norm": 16.143543243408203,
      "learning_rate": 2.4874769311890325e-06,
      "loss": 0.5571,
      "step": 14971
    },
    {
      "epoch": 0.8881243326610512,
      "grad_norm": 0.015555894002318382,
      "learning_rate": 2.486158713419457e-06,
      "loss": 0.0004,
      "step": 14972
    },
    {
      "epoch": 0.8881836516787281,
      "grad_norm": 0.010300896130502224,
      "learning_rate": 2.4848404956498813e-06,
      "loss": 0.0003,
      "step": 14973
    },
    {
      "epoch": 0.8882429706964052,
      "grad_norm": 2.2623345851898193,
      "learning_rate": 2.483522277880306e-06,
      "loss": 0.0328,
      "step": 14974
    },
    {
      "epoch": 0.8883022897140823,
      "grad_norm": 0.10813265293836594,
      "learning_rate": 2.4822040601107305e-06,
      "loss": 0.0013,
      "step": 14975
    },
    {
      "epoch": 0.8883616087317594,
      "grad_norm": 17.25372886657715,
      "learning_rate": 2.480885842341155e-06,
      "loss": 0.6088,
      "step": 14976
    },
    {
      "epoch": 0.8884209277494365,
      "grad_norm": 1.0920559167861938,
      "learning_rate": 2.4795676245715793e-06,
      "loss": 0.01,
      "step": 14977
    },
    {
      "epoch": 0.8884802467671136,
      "grad_norm": 0.0708501935005188,
      "learning_rate": 2.478249406802004e-06,
      "loss": 0.0015,
      "step": 14978
    },
    {
      "epoch": 0.8885395657847907,
      "grad_norm": 11.407271385192871,
      "learning_rate": 2.476931189032428e-06,
      "loss": 0.1316,
      "step": 14979
    },
    {
      "epoch": 0.8885988848024676,
      "grad_norm": 0.025859858840703964,
      "learning_rate": 2.4756129712628527e-06,
      "loss": 0.0005,
      "step": 14980
    },
    {
      "epoch": 0.8886582038201447,
      "grad_norm": 0.03938253968954086,
      "learning_rate": 2.4742947534932774e-06,
      "loss": 0.0005,
      "step": 14981
    },
    {
      "epoch": 0.8887175228378218,
      "grad_norm": 12.932886123657227,
      "learning_rate": 2.472976535723702e-06,
      "loss": 0.0564,
      "step": 14982
    },
    {
      "epoch": 0.8887768418554989,
      "grad_norm": 0.03401007503271103,
      "learning_rate": 2.471658317954126e-06,
      "loss": 0.0004,
      "step": 14983
    },
    {
      "epoch": 0.888836160873176,
      "grad_norm": 7.281303405761719,
      "learning_rate": 2.4703401001845508e-06,
      "loss": 0.1485,
      "step": 14984
    },
    {
      "epoch": 0.888895479890853,
      "grad_norm": 7.909218788146973,
      "learning_rate": 2.469021882414975e-06,
      "loss": 0.8107,
      "step": 14985
    },
    {
      "epoch": 0.88895479890853,
      "grad_norm": 54.67862319946289,
      "learning_rate": 2.4677036646453996e-06,
      "loss": 0.7711,
      "step": 14986
    },
    {
      "epoch": 0.8890141179262071,
      "grad_norm": 1.533294916152954,
      "learning_rate": 2.466385446875824e-06,
      "loss": 0.0135,
      "step": 14987
    },
    {
      "epoch": 0.8890734369438842,
      "grad_norm": 0.8659529089927673,
      "learning_rate": 2.4650672291062484e-06,
      "loss": 0.0076,
      "step": 14988
    },
    {
      "epoch": 0.8891327559615613,
      "grad_norm": 0.008827387355268002,
      "learning_rate": 2.463749011336673e-06,
      "loss": 0.0003,
      "step": 14989
    },
    {
      "epoch": 0.8891920749792384,
      "grad_norm": 0.0026023085229098797,
      "learning_rate": 2.4624307935670976e-06,
      "loss": 0.0001,
      "step": 14990
    },
    {
      "epoch": 0.8892513939969154,
      "grad_norm": 17.89256477355957,
      "learning_rate": 2.4611125757975218e-06,
      "loss": 0.1977,
      "step": 14991
    },
    {
      "epoch": 0.8893107130145925,
      "grad_norm": 0.09886323660612106,
      "learning_rate": 2.4597943580279464e-06,
      "loss": 0.001,
      "step": 14992
    },
    {
      "epoch": 0.8893700320322695,
      "grad_norm": 14.581254005432129,
      "learning_rate": 2.458476140258371e-06,
      "loss": 0.2389,
      "step": 14993
    },
    {
      "epoch": 0.8894293510499466,
      "grad_norm": 0.05568332597613335,
      "learning_rate": 2.457157922488795e-06,
      "loss": 0.0013,
      "step": 14994
    },
    {
      "epoch": 0.8894886700676237,
      "grad_norm": 0.1806832253932953,
      "learning_rate": 2.45583970471922e-06,
      "loss": 0.0008,
      "step": 14995
    },
    {
      "epoch": 0.8895479890853007,
      "grad_norm": 0.13436563313007355,
      "learning_rate": 2.4545214869496444e-06,
      "loss": 0.003,
      "step": 14996
    },
    {
      "epoch": 0.8896073081029778,
      "grad_norm": 0.037031810730695724,
      "learning_rate": 2.4532032691800686e-06,
      "loss": 0.0004,
      "step": 14997
    },
    {
      "epoch": 0.8896666271206549,
      "grad_norm": 10.565141677856445,
      "learning_rate": 2.451885051410493e-06,
      "loss": 0.2617,
      "step": 14998
    },
    {
      "epoch": 0.889725946138332,
      "grad_norm": 0.05586951598525047,
      "learning_rate": 2.450566833640918e-06,
      "loss": 0.0011,
      "step": 14999
    },
    {
      "epoch": 0.889785265156009,
      "grad_norm": 0.02312588505446911,
      "learning_rate": 2.449248615871342e-06,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.8898445841736861,
      "grad_norm": 7.833201885223389,
      "learning_rate": 2.4479303981017666e-06,
      "loss": 0.3191,
      "step": 15001
    },
    {
      "epoch": 0.8899039031913631,
      "grad_norm": 0.07948534190654755,
      "learning_rate": 2.446612180332191e-06,
      "loss": 0.0015,
      "step": 15002
    },
    {
      "epoch": 0.8899632222090402,
      "grad_norm": 2.289628505706787,
      "learning_rate": 2.4452939625626154e-06,
      "loss": 0.019,
      "step": 15003
    },
    {
      "epoch": 0.8900225412267173,
      "grad_norm": 2.52256441116333,
      "learning_rate": 2.44397574479304e-06,
      "loss": 0.0638,
      "step": 15004
    },
    {
      "epoch": 0.8900818602443944,
      "grad_norm": 0.009095129556953907,
      "learning_rate": 2.4426575270234646e-06,
      "loss": 0.0002,
      "step": 15005
    },
    {
      "epoch": 0.8901411792620714,
      "grad_norm": 0.061936963349580765,
      "learning_rate": 2.441339309253889e-06,
      "loss": 0.0014,
      "step": 15006
    },
    {
      "epoch": 0.8902004982797485,
      "grad_norm": 0.05230613425374031,
      "learning_rate": 2.4400210914843134e-06,
      "loss": 0.0008,
      "step": 15007
    },
    {
      "epoch": 0.8902598172974255,
      "grad_norm": 1.2999831438064575,
      "learning_rate": 2.4387028737147376e-06,
      "loss": 0.0171,
      "step": 15008
    },
    {
      "epoch": 0.8903191363151026,
      "grad_norm": 4.2641496658325195,
      "learning_rate": 2.4373846559451622e-06,
      "loss": 0.4379,
      "step": 15009
    },
    {
      "epoch": 0.8903784553327797,
      "grad_norm": 10.136739730834961,
      "learning_rate": 2.436066438175587e-06,
      "loss": 0.2075,
      "step": 15010
    },
    {
      "epoch": 0.8904377743504568,
      "grad_norm": 1.3867624998092651,
      "learning_rate": 2.4347482204060114e-06,
      "loss": 0.0124,
      "step": 15011
    },
    {
      "epoch": 0.8904970933681339,
      "grad_norm": 0.037266310304403305,
      "learning_rate": 2.4334300026364356e-06,
      "loss": 0.0004,
      "step": 15012
    },
    {
      "epoch": 0.8905564123858108,
      "grad_norm": 0.017295794561505318,
      "learning_rate": 2.4321117848668602e-06,
      "loss": 0.0003,
      "step": 15013
    },
    {
      "epoch": 0.8906157314034879,
      "grad_norm": 53.156471252441406,
      "learning_rate": 2.4307935670972844e-06,
      "loss": 1.4323,
      "step": 15014
    },
    {
      "epoch": 0.890675050421165,
      "grad_norm": 0.9799289107322693,
      "learning_rate": 2.429475349327709e-06,
      "loss": 0.01,
      "step": 15015
    },
    {
      "epoch": 0.8907343694388421,
      "grad_norm": 5.563587665557861,
      "learning_rate": 2.4281571315581336e-06,
      "loss": 0.069,
      "step": 15016
    },
    {
      "epoch": 0.8907936884565192,
      "grad_norm": 5.004051685333252,
      "learning_rate": 2.4268389137885583e-06,
      "loss": 0.0416,
      "step": 15017
    },
    {
      "epoch": 0.8908530074741963,
      "grad_norm": 2.7445669174194336,
      "learning_rate": 2.4255206960189824e-06,
      "loss": 0.0784,
      "step": 15018
    },
    {
      "epoch": 0.8909123264918732,
      "grad_norm": 1.4710966348648071,
      "learning_rate": 2.424202478249407e-06,
      "loss": 0.0125,
      "step": 15019
    },
    {
      "epoch": 0.8909716455095503,
      "grad_norm": 0.03604384884238243,
      "learning_rate": 2.4228842604798312e-06,
      "loss": 0.0007,
      "step": 15020
    },
    {
      "epoch": 0.8910309645272274,
      "grad_norm": 33.572227478027344,
      "learning_rate": 2.421566042710256e-06,
      "loss": 0.1577,
      "step": 15021
    },
    {
      "epoch": 0.8910902835449045,
      "grad_norm": 0.2391110062599182,
      "learning_rate": 2.4202478249406805e-06,
      "loss": 0.001,
      "step": 15022
    },
    {
      "epoch": 0.8911496025625816,
      "grad_norm": 0.009655451402068138,
      "learning_rate": 2.418929607171105e-06,
      "loss": 0.0003,
      "step": 15023
    },
    {
      "epoch": 0.8912089215802587,
      "grad_norm": 0.97651207447052,
      "learning_rate": 2.4176113894015293e-06,
      "loss": 0.0076,
      "step": 15024
    },
    {
      "epoch": 0.8912682405979357,
      "grad_norm": 0.11900467425584793,
      "learning_rate": 2.416293171631954e-06,
      "loss": 0.0013,
      "step": 15025
    },
    {
      "epoch": 0.8913275596156127,
      "grad_norm": 0.11519518494606018,
      "learning_rate": 2.414974953862378e-06,
      "loss": 0.0017,
      "step": 15026
    },
    {
      "epoch": 0.8913868786332898,
      "grad_norm": 16.314422607421875,
      "learning_rate": 2.4136567360928027e-06,
      "loss": 1.0217,
      "step": 15027
    },
    {
      "epoch": 0.8914461976509669,
      "grad_norm": 0.010881457477807999,
      "learning_rate": 2.4123385183232273e-06,
      "loss": 0.0003,
      "step": 15028
    },
    {
      "epoch": 0.891505516668644,
      "grad_norm": 6.469221591949463,
      "learning_rate": 2.411020300553652e-06,
      "loss": 0.1214,
      "step": 15029
    },
    {
      "epoch": 0.8915648356863211,
      "grad_norm": 9.7703218460083,
      "learning_rate": 2.409702082784076e-06,
      "loss": 0.4259,
      "step": 15030
    },
    {
      "epoch": 0.8916241547039981,
      "grad_norm": 0.06239929795265198,
      "learning_rate": 2.4083838650145007e-06,
      "loss": 0.0014,
      "step": 15031
    },
    {
      "epoch": 0.8916834737216752,
      "grad_norm": 0.006233565974980593,
      "learning_rate": 2.407065647244925e-06,
      "loss": 0.0002,
      "step": 15032
    },
    {
      "epoch": 0.8917427927393522,
      "grad_norm": 0.0677112564444542,
      "learning_rate": 2.4057474294753495e-06,
      "loss": 0.0012,
      "step": 15033
    },
    {
      "epoch": 0.8918021117570293,
      "grad_norm": 9.26424503326416,
      "learning_rate": 2.404429211705774e-06,
      "loss": 0.1147,
      "step": 15034
    },
    {
      "epoch": 0.8918614307747064,
      "grad_norm": 0.16796676814556122,
      "learning_rate": 2.4031109939361987e-06,
      "loss": 0.0012,
      "step": 15035
    },
    {
      "epoch": 0.8919207497923834,
      "grad_norm": 1.4034141302108765,
      "learning_rate": 2.401792776166623e-06,
      "loss": 0.0079,
      "step": 15036
    },
    {
      "epoch": 0.8919800688100605,
      "grad_norm": 0.4064445197582245,
      "learning_rate": 2.4004745583970475e-06,
      "loss": 0.0052,
      "step": 15037
    },
    {
      "epoch": 0.8920393878277376,
      "grad_norm": 6.801870822906494,
      "learning_rate": 2.3991563406274717e-06,
      "loss": 0.1837,
      "step": 15038
    },
    {
      "epoch": 0.8920987068454146,
      "grad_norm": 0.5425722599029541,
      "learning_rate": 2.3978381228578963e-06,
      "loss": 0.0042,
      "step": 15039
    },
    {
      "epoch": 0.8921580258630917,
      "grad_norm": 16.629850387573242,
      "learning_rate": 2.396519905088321e-06,
      "loss": 0.2166,
      "step": 15040
    },
    {
      "epoch": 0.8922173448807688,
      "grad_norm": 2.2676994800567627,
      "learning_rate": 2.395201687318745e-06,
      "loss": 0.008,
      "step": 15041
    },
    {
      "epoch": 0.8922766638984458,
      "grad_norm": 15.434330940246582,
      "learning_rate": 2.3938834695491697e-06,
      "loss": 0.0605,
      "step": 15042
    },
    {
      "epoch": 0.8923359829161229,
      "grad_norm": 0.0995643138885498,
      "learning_rate": 2.3925652517795943e-06,
      "loss": 0.0012,
      "step": 15043
    },
    {
      "epoch": 0.8923953019338,
      "grad_norm": 3.620267868041992,
      "learning_rate": 2.3912470340100185e-06,
      "loss": 0.0465,
      "step": 15044
    },
    {
      "epoch": 0.8924546209514771,
      "grad_norm": 3.319411516189575,
      "learning_rate": 2.389928816240443e-06,
      "loss": 0.0376,
      "step": 15045
    },
    {
      "epoch": 0.8925139399691541,
      "grad_norm": 0.014844128862023354,
      "learning_rate": 2.3886105984708677e-06,
      "loss": 0.0005,
      "step": 15046
    },
    {
      "epoch": 0.8925732589868312,
      "grad_norm": 0.42702800035476685,
      "learning_rate": 2.387292380701292e-06,
      "loss": 0.0059,
      "step": 15047
    },
    {
      "epoch": 0.8926325780045082,
      "grad_norm": 4.3665642738342285,
      "learning_rate": 2.3859741629317165e-06,
      "loss": 0.0197,
      "step": 15048
    },
    {
      "epoch": 0.8926918970221853,
      "grad_norm": 0.34030184149742126,
      "learning_rate": 2.384655945162141e-06,
      "loss": 0.0038,
      "step": 15049
    },
    {
      "epoch": 0.8927512160398624,
      "grad_norm": 12.618062019348145,
      "learning_rate": 2.3833377273925653e-06,
      "loss": 0.2163,
      "step": 15050
    },
    {
      "epoch": 0.8928105350575395,
      "grad_norm": 0.6125357747077942,
      "learning_rate": 2.38201950962299e-06,
      "loss": 0.0037,
      "step": 15051
    },
    {
      "epoch": 0.8928698540752165,
      "grad_norm": 0.0613890066742897,
      "learning_rate": 2.3807012918534145e-06,
      "loss": 0.0009,
      "step": 15052
    },
    {
      "epoch": 0.8929291730928935,
      "grad_norm": 0.01281969714909792,
      "learning_rate": 2.3793830740838387e-06,
      "loss": 0.0003,
      "step": 15053
    },
    {
      "epoch": 0.8929884921105706,
      "grad_norm": 0.7559723258018494,
      "learning_rate": 2.3780648563142633e-06,
      "loss": 0.0102,
      "step": 15054
    },
    {
      "epoch": 0.8930478111282477,
      "grad_norm": 5.238470077514648,
      "learning_rate": 2.3767466385446875e-06,
      "loss": 0.0618,
      "step": 15055
    },
    {
      "epoch": 0.8931071301459248,
      "grad_norm": 0.3886675536632538,
      "learning_rate": 2.375428420775112e-06,
      "loss": 0.0051,
      "step": 15056
    },
    {
      "epoch": 0.8931664491636019,
      "grad_norm": 4.312697887420654,
      "learning_rate": 2.3741102030055368e-06,
      "loss": 0.024,
      "step": 15057
    },
    {
      "epoch": 0.893225768181279,
      "grad_norm": 9.681039810180664,
      "learning_rate": 2.3727919852359614e-06,
      "loss": 0.3983,
      "step": 15058
    },
    {
      "epoch": 0.8932850871989559,
      "grad_norm": 0.17155691981315613,
      "learning_rate": 2.3714737674663856e-06,
      "loss": 0.002,
      "step": 15059
    },
    {
      "epoch": 0.893344406216633,
      "grad_norm": 0.013896536082029343,
      "learning_rate": 2.37015554969681e-06,
      "loss": 0.0004,
      "step": 15060
    },
    {
      "epoch": 0.8934037252343101,
      "grad_norm": 0.4611368179321289,
      "learning_rate": 2.3688373319272343e-06,
      "loss": 0.0057,
      "step": 15061
    },
    {
      "epoch": 0.8934630442519872,
      "grad_norm": 0.1328258067369461,
      "learning_rate": 2.367519114157659e-06,
      "loss": 0.0009,
      "step": 15062
    },
    {
      "epoch": 0.8935223632696643,
      "grad_norm": 13.302412986755371,
      "learning_rate": 2.3662008963880836e-06,
      "loss": 0.4393,
      "step": 15063
    },
    {
      "epoch": 0.8935816822873414,
      "grad_norm": 18.215356826782227,
      "learning_rate": 2.364882678618508e-06,
      "loss": 0.306,
      "step": 15064
    },
    {
      "epoch": 0.8936410013050183,
      "grad_norm": 6.895071983337402,
      "learning_rate": 2.3635644608489324e-06,
      "loss": 0.0647,
      "step": 15065
    },
    {
      "epoch": 0.8937003203226954,
      "grad_norm": 39.28955078125,
      "learning_rate": 2.362246243079357e-06,
      "loss": 0.3509,
      "step": 15066
    },
    {
      "epoch": 0.8937596393403725,
      "grad_norm": 0.009401592426002026,
      "learning_rate": 2.360928025309781e-06,
      "loss": 0.0003,
      "step": 15067
    },
    {
      "epoch": 0.8938189583580496,
      "grad_norm": 0.45815110206604004,
      "learning_rate": 2.3596098075402058e-06,
      "loss": 0.0042,
      "step": 15068
    },
    {
      "epoch": 0.8938782773757267,
      "grad_norm": 0.003561013611033559,
      "learning_rate": 2.35829158977063e-06,
      "loss": 0.0001,
      "step": 15069
    },
    {
      "epoch": 0.8939375963934038,
      "grad_norm": 24.431432723999023,
      "learning_rate": 2.356973372001055e-06,
      "loss": 0.2412,
      "step": 15070
    },
    {
      "epoch": 0.8939969154110808,
      "grad_norm": 4.490010738372803,
      "learning_rate": 2.355655154231479e-06,
      "loss": 0.1422,
      "step": 15071
    },
    {
      "epoch": 0.8940562344287578,
      "grad_norm": 2.663538932800293,
      "learning_rate": 2.354336936461904e-06,
      "loss": 0.0242,
      "step": 15072
    },
    {
      "epoch": 0.8941155534464349,
      "grad_norm": 0.776965320110321,
      "learning_rate": 2.353018718692328e-06,
      "loss": 0.0144,
      "step": 15073
    },
    {
      "epoch": 0.894174872464112,
      "grad_norm": 0.052360739558935165,
      "learning_rate": 2.3517005009227526e-06,
      "loss": 0.0011,
      "step": 15074
    },
    {
      "epoch": 0.8942341914817891,
      "grad_norm": 0.01908664032816887,
      "learning_rate": 2.350382283153177e-06,
      "loss": 0.0003,
      "step": 15075
    },
    {
      "epoch": 0.8942935104994661,
      "grad_norm": 0.6095156073570251,
      "learning_rate": 2.349064065383602e-06,
      "loss": 0.0083,
      "step": 15076
    },
    {
      "epoch": 0.8943528295171432,
      "grad_norm": 21.049339294433594,
      "learning_rate": 2.347745847614026e-06,
      "loss": 0.3249,
      "step": 15077
    },
    {
      "epoch": 0.8944121485348203,
      "grad_norm": 5.107578277587891,
      "learning_rate": 2.3464276298444506e-06,
      "loss": 0.0945,
      "step": 15078
    },
    {
      "epoch": 0.8944714675524973,
      "grad_norm": 31.581789016723633,
      "learning_rate": 2.345109412074875e-06,
      "loss": 0.1468,
      "step": 15079
    },
    {
      "epoch": 0.8945307865701744,
      "grad_norm": 0.13584820926189423,
      "learning_rate": 2.3437911943052994e-06,
      "loss": 0.0026,
      "step": 15080
    },
    {
      "epoch": 0.8945901055878515,
      "grad_norm": 0.006828807760030031,
      "learning_rate": 2.342472976535724e-06,
      "loss": 0.0002,
      "step": 15081
    },
    {
      "epoch": 0.8946494246055285,
      "grad_norm": 9.15937328338623,
      "learning_rate": 2.3411547587661486e-06,
      "loss": 0.1441,
      "step": 15082
    },
    {
      "epoch": 0.8947087436232056,
      "grad_norm": 3.075472116470337,
      "learning_rate": 2.339836540996573e-06,
      "loss": 0.1007,
      "step": 15083
    },
    {
      "epoch": 0.8947680626408827,
      "grad_norm": 0.09139331430196762,
      "learning_rate": 2.3385183232269974e-06,
      "loss": 0.0012,
      "step": 15084
    },
    {
      "epoch": 0.8948273816585597,
      "grad_norm": 7.448808193206787,
      "learning_rate": 2.3372001054574216e-06,
      "loss": 0.2974,
      "step": 15085
    },
    {
      "epoch": 0.8948867006762368,
      "grad_norm": 11.99712085723877,
      "learning_rate": 2.3358818876878462e-06,
      "loss": 0.1657,
      "step": 15086
    },
    {
      "epoch": 0.8949460196939139,
      "grad_norm": 0.08626341074705124,
      "learning_rate": 2.334563669918271e-06,
      "loss": 0.0016,
      "step": 15087
    },
    {
      "epoch": 0.8950053387115909,
      "grad_norm": 1.8960227966308594,
      "learning_rate": 2.3332454521486954e-06,
      "loss": 0.0196,
      "step": 15088
    },
    {
      "epoch": 0.895064657729268,
      "grad_norm": 0.009512855671346188,
      "learning_rate": 2.3319272343791196e-06,
      "loss": 0.0003,
      "step": 15089
    },
    {
      "epoch": 0.8951239767469451,
      "grad_norm": 0.9609781503677368,
      "learning_rate": 2.3306090166095442e-06,
      "loss": 0.0049,
      "step": 15090
    },
    {
      "epoch": 0.8951832957646222,
      "grad_norm": 10.011127471923828,
      "learning_rate": 2.3292907988399684e-06,
      "loss": 0.4552,
      "step": 15091
    },
    {
      "epoch": 0.8952426147822992,
      "grad_norm": 0.08439041674137115,
      "learning_rate": 2.327972581070393e-06,
      "loss": 0.0008,
      "step": 15092
    },
    {
      "epoch": 0.8953019337999762,
      "grad_norm": 3.544830560684204,
      "learning_rate": 2.3266543633008177e-06,
      "loss": 0.038,
      "step": 15093
    },
    {
      "epoch": 0.8953612528176533,
      "grad_norm": 0.08955837786197662,
      "learning_rate": 2.325336145531242e-06,
      "loss": 0.0006,
      "step": 15094
    },
    {
      "epoch": 0.8954205718353304,
      "grad_norm": 0.20435082912445068,
      "learning_rate": 2.3240179277616665e-06,
      "loss": 0.0029,
      "step": 15095
    },
    {
      "epoch": 0.8954798908530075,
      "grad_norm": 5.374256134033203,
      "learning_rate": 2.322699709992091e-06,
      "loss": 0.4063,
      "step": 15096
    },
    {
      "epoch": 0.8955392098706846,
      "grad_norm": 7.542519569396973,
      "learning_rate": 2.3213814922225152e-06,
      "loss": 0.4907,
      "step": 15097
    },
    {
      "epoch": 0.8955985288883616,
      "grad_norm": 27.494752883911133,
      "learning_rate": 2.32006327445294e-06,
      "loss": 1.1036,
      "step": 15098
    },
    {
      "epoch": 0.8956578479060386,
      "grad_norm": 4.6345744132995605,
      "learning_rate": 2.3187450566833645e-06,
      "loss": 0.0416,
      "step": 15099
    },
    {
      "epoch": 0.8957171669237157,
      "grad_norm": 3.9982147216796875,
      "learning_rate": 2.3174268389137887e-06,
      "loss": 0.0475,
      "step": 15100
    },
    {
      "epoch": 0.8957764859413928,
      "grad_norm": 19.179466247558594,
      "learning_rate": 2.3161086211442133e-06,
      "loss": 1.0533,
      "step": 15101
    },
    {
      "epoch": 0.8958358049590699,
      "grad_norm": 0.6175296902656555,
      "learning_rate": 2.314790403374638e-06,
      "loss": 0.0141,
      "step": 15102
    },
    {
      "epoch": 0.895895123976747,
      "grad_norm": 12.126567840576172,
      "learning_rate": 2.313472185605062e-06,
      "loss": 0.3148,
      "step": 15103
    },
    {
      "epoch": 0.8959544429944241,
      "grad_norm": 1.715187907218933,
      "learning_rate": 2.3121539678354867e-06,
      "loss": 0.0097,
      "step": 15104
    },
    {
      "epoch": 0.896013762012101,
      "grad_norm": 6.4344587326049805,
      "learning_rate": 2.3108357500659113e-06,
      "loss": 0.138,
      "step": 15105
    },
    {
      "epoch": 0.8960730810297781,
      "grad_norm": 18.280677795410156,
      "learning_rate": 2.3095175322963355e-06,
      "loss": 0.5857,
      "step": 15106
    },
    {
      "epoch": 0.8961324000474552,
      "grad_norm": 0.006171852815896273,
      "learning_rate": 2.30819931452676e-06,
      "loss": 0.0002,
      "step": 15107
    },
    {
      "epoch": 0.8961917190651323,
      "grad_norm": 6.390181064605713,
      "learning_rate": 2.3068810967571843e-06,
      "loss": 0.1992,
      "step": 15108
    },
    {
      "epoch": 0.8962510380828094,
      "grad_norm": 14.159524917602539,
      "learning_rate": 2.305562878987609e-06,
      "loss": 0.1676,
      "step": 15109
    },
    {
      "epoch": 0.8963103571004865,
      "grad_norm": 0.03709103539586067,
      "learning_rate": 2.3042446612180335e-06,
      "loss": 0.0007,
      "step": 15110
    },
    {
      "epoch": 0.8963696761181635,
      "grad_norm": 0.016882959753274918,
      "learning_rate": 2.302926443448458e-06,
      "loss": 0.0004,
      "step": 15111
    },
    {
      "epoch": 0.8964289951358405,
      "grad_norm": 2.265825033187866,
      "learning_rate": 2.3016082256788823e-06,
      "loss": 0.0131,
      "step": 15112
    },
    {
      "epoch": 0.8964883141535176,
      "grad_norm": 0.005029027350246906,
      "learning_rate": 2.300290007909307e-06,
      "loss": 0.0001,
      "step": 15113
    },
    {
      "epoch": 0.8965476331711947,
      "grad_norm": 0.06912212818861008,
      "learning_rate": 2.298971790139731e-06,
      "loss": 0.0014,
      "step": 15114
    },
    {
      "epoch": 0.8966069521888718,
      "grad_norm": 1.9815081357955933,
      "learning_rate": 2.2976535723701557e-06,
      "loss": 0.0245,
      "step": 15115
    },
    {
      "epoch": 0.8966662712065488,
      "grad_norm": 7.864564895629883,
      "learning_rate": 2.2963353546005803e-06,
      "loss": 0.0712,
      "step": 15116
    },
    {
      "epoch": 0.8967255902242259,
      "grad_norm": 4.6194233894348145,
      "learning_rate": 2.295017136831005e-06,
      "loss": 0.0906,
      "step": 15117
    },
    {
      "epoch": 0.8967849092419029,
      "grad_norm": 0.08200570195913315,
      "learning_rate": 2.293698919061429e-06,
      "loss": 0.0015,
      "step": 15118
    },
    {
      "epoch": 0.89684422825958,
      "grad_norm": 0.005408252123743296,
      "learning_rate": 2.2923807012918537e-06,
      "loss": 0.0002,
      "step": 15119
    },
    {
      "epoch": 0.8969035472772571,
      "grad_norm": 0.3564310371875763,
      "learning_rate": 2.291062483522278e-06,
      "loss": 0.0034,
      "step": 15120
    },
    {
      "epoch": 0.8969628662949342,
      "grad_norm": 0.07478555291891098,
      "learning_rate": 2.2897442657527025e-06,
      "loss": 0.0009,
      "step": 15121
    },
    {
      "epoch": 0.8970221853126112,
      "grad_norm": 0.006199632305651903,
      "learning_rate": 2.2884260479831267e-06,
      "loss": 0.0002,
      "step": 15122
    },
    {
      "epoch": 0.8970815043302883,
      "grad_norm": 8.5889892578125,
      "learning_rate": 2.2871078302135517e-06,
      "loss": 0.1108,
      "step": 15123
    },
    {
      "epoch": 0.8971408233479654,
      "grad_norm": 0.02037345990538597,
      "learning_rate": 2.285789612443976e-06,
      "loss": 0.0004,
      "step": 15124
    },
    {
      "epoch": 0.8972001423656424,
      "grad_norm": 2.682459831237793,
      "learning_rate": 2.2844713946744005e-06,
      "loss": 0.0454,
      "step": 15125
    },
    {
      "epoch": 0.8972594613833195,
      "grad_norm": 47.09208297729492,
      "learning_rate": 2.2831531769048247e-06,
      "loss": 0.6767,
      "step": 15126
    },
    {
      "epoch": 0.8973187804009966,
      "grad_norm": 12.26294231414795,
      "learning_rate": 2.2818349591352493e-06,
      "loss": 0.23,
      "step": 15127
    },
    {
      "epoch": 0.8973780994186736,
      "grad_norm": 0.0035000392235815525,
      "learning_rate": 2.2805167413656735e-06,
      "loss": 0.0001,
      "step": 15128
    },
    {
      "epoch": 0.8974374184363507,
      "grad_norm": 0.014047541655600071,
      "learning_rate": 2.2791985235960986e-06,
      "loss": 0.0004,
      "step": 15129
    },
    {
      "epoch": 0.8974967374540278,
      "grad_norm": 0.05077410861849785,
      "learning_rate": 2.2778803058265227e-06,
      "loss": 0.0007,
      "step": 15130
    },
    {
      "epoch": 0.8975560564717048,
      "grad_norm": 20.675321578979492,
      "learning_rate": 2.2765620880569474e-06,
      "loss": 0.1728,
      "step": 15131
    },
    {
      "epoch": 0.8976153754893819,
      "grad_norm": 0.03576628118753433,
      "learning_rate": 2.2752438702873715e-06,
      "loss": 0.0008,
      "step": 15132
    },
    {
      "epoch": 0.897674694507059,
      "grad_norm": 8.540050506591797,
      "learning_rate": 2.273925652517796e-06,
      "loss": 0.2528,
      "step": 15133
    },
    {
      "epoch": 0.897734013524736,
      "grad_norm": 0.6533921360969543,
      "learning_rate": 2.2726074347482203e-06,
      "loss": 0.0058,
      "step": 15134
    },
    {
      "epoch": 0.8977933325424131,
      "grad_norm": 0.011498003266751766,
      "learning_rate": 2.2712892169786454e-06,
      "loss": 0.0003,
      "step": 15135
    },
    {
      "epoch": 0.8978526515600902,
      "grad_norm": 9.777548789978027,
      "learning_rate": 2.2699709992090696e-06,
      "loss": 0.3064,
      "step": 15136
    },
    {
      "epoch": 0.8979119705777673,
      "grad_norm": 25.494873046875,
      "learning_rate": 2.268652781439494e-06,
      "loss": 0.3065,
      "step": 15137
    },
    {
      "epoch": 0.8979712895954443,
      "grad_norm": 23.468822479248047,
      "learning_rate": 2.2673345636699184e-06,
      "loss": 0.2289,
      "step": 15138
    },
    {
      "epoch": 0.8980306086131213,
      "grad_norm": 1.2559943199157715,
      "learning_rate": 2.266016345900343e-06,
      "loss": 0.0132,
      "step": 15139
    },
    {
      "epoch": 0.8980899276307984,
      "grad_norm": 0.01518470048904419,
      "learning_rate": 2.264698128130767e-06,
      "loss": 0.0005,
      "step": 15140
    },
    {
      "epoch": 0.8981492466484755,
      "grad_norm": 0.8509828448295593,
      "learning_rate": 2.263379910361192e-06,
      "loss": 0.006,
      "step": 15141
    },
    {
      "epoch": 0.8982085656661526,
      "grad_norm": 0.26691168546676636,
      "learning_rate": 2.2620616925916164e-06,
      "loss": 0.0052,
      "step": 15142
    },
    {
      "epoch": 0.8982678846838297,
      "grad_norm": 0.006645461544394493,
      "learning_rate": 2.260743474822041e-06,
      "loss": 0.0002,
      "step": 15143
    },
    {
      "epoch": 0.8983272037015066,
      "grad_norm": 0.007406698539853096,
      "learning_rate": 2.259425257052465e-06,
      "loss": 0.0002,
      "step": 15144
    },
    {
      "epoch": 0.8983865227191837,
      "grad_norm": 4.402493476867676,
      "learning_rate": 2.2581070392828898e-06,
      "loss": 0.0545,
      "step": 15145
    },
    {
      "epoch": 0.8984458417368608,
      "grad_norm": 1.141135573387146,
      "learning_rate": 2.256788821513314e-06,
      "loss": 0.0052,
      "step": 15146
    },
    {
      "epoch": 0.8985051607545379,
      "grad_norm": 1.1516045331954956,
      "learning_rate": 2.2554706037437386e-06,
      "loss": 0.0086,
      "step": 15147
    },
    {
      "epoch": 0.898564479772215,
      "grad_norm": 5.26941442489624,
      "learning_rate": 2.254152385974163e-06,
      "loss": 0.0167,
      "step": 15148
    },
    {
      "epoch": 0.8986237987898921,
      "grad_norm": 1.1669461727142334,
      "learning_rate": 2.252834168204588e-06,
      "loss": 0.0119,
      "step": 15149
    },
    {
      "epoch": 0.8986831178075692,
      "grad_norm": 9.166728973388672,
      "learning_rate": 2.251515950435012e-06,
      "loss": 0.0925,
      "step": 15150
    },
    {
      "epoch": 0.8987424368252461,
      "grad_norm": 0.07459210604429245,
      "learning_rate": 2.2501977326654366e-06,
      "loss": 0.0011,
      "step": 15151
    },
    {
      "epoch": 0.8988017558429232,
      "grad_norm": 3.8164145946502686,
      "learning_rate": 2.2488795148958608e-06,
      "loss": 0.0465,
      "step": 15152
    },
    {
      "epoch": 0.8988610748606003,
      "grad_norm": 13.186793327331543,
      "learning_rate": 2.2475612971262854e-06,
      "loss": 0.2904,
      "step": 15153
    },
    {
      "epoch": 0.8989203938782774,
      "grad_norm": 4.743083477020264,
      "learning_rate": 2.24624307935671e-06,
      "loss": 0.0519,
      "step": 15154
    },
    {
      "epoch": 0.8989797128959545,
      "grad_norm": 0.006865571718662977,
      "learning_rate": 2.2449248615871346e-06,
      "loss": 0.0002,
      "step": 15155
    },
    {
      "epoch": 0.8990390319136315,
      "grad_norm": 0.16342055797576904,
      "learning_rate": 2.243606643817559e-06,
      "loss": 0.0021,
      "step": 15156
    },
    {
      "epoch": 0.8990983509313086,
      "grad_norm": 0.21390609443187714,
      "learning_rate": 2.2422884260479834e-06,
      "loss": 0.0025,
      "step": 15157
    },
    {
      "epoch": 0.8991576699489856,
      "grad_norm": 0.024771198630332947,
      "learning_rate": 2.2409702082784076e-06,
      "loss": 0.0006,
      "step": 15158
    },
    {
      "epoch": 0.8992169889666627,
      "grad_norm": 0.01289182249456644,
      "learning_rate": 2.2396519905088322e-06,
      "loss": 0.0003,
      "step": 15159
    },
    {
      "epoch": 0.8992763079843398,
      "grad_norm": 0.0334492027759552,
      "learning_rate": 2.238333772739257e-06,
      "loss": 0.0006,
      "step": 15160
    },
    {
      "epoch": 0.8993356270020169,
      "grad_norm": 0.029427656903862953,
      "learning_rate": 2.237015554969681e-06,
      "loss": 0.0007,
      "step": 15161
    },
    {
      "epoch": 0.8993949460196939,
      "grad_norm": 0.12320370972156525,
      "learning_rate": 2.2356973372001056e-06,
      "loss": 0.0012,
      "step": 15162
    },
    {
      "epoch": 0.899454265037371,
      "grad_norm": 0.9553602933883667,
      "learning_rate": 2.2343791194305302e-06,
      "loss": 0.01,
      "step": 15163
    },
    {
      "epoch": 0.899513584055048,
      "grad_norm": 0.11600074917078018,
      "learning_rate": 2.2330609016609544e-06,
      "loss": 0.0005,
      "step": 15164
    },
    {
      "epoch": 0.8995729030727251,
      "grad_norm": 0.0022439230233430862,
      "learning_rate": 2.231742683891379e-06,
      "loss": 0.0001,
      "step": 15165
    },
    {
      "epoch": 0.8996322220904022,
      "grad_norm": 0.0015871735522523522,
      "learning_rate": 2.2304244661218036e-06,
      "loss": 0.0,
      "step": 15166
    },
    {
      "epoch": 0.8996915411080793,
      "grad_norm": 0.5323719382286072,
      "learning_rate": 2.229106248352228e-06,
      "loss": 0.0053,
      "step": 15167
    },
    {
      "epoch": 0.8997508601257563,
      "grad_norm": 17.349815368652344,
      "learning_rate": 2.2277880305826524e-06,
      "loss": 0.9537,
      "step": 15168
    },
    {
      "epoch": 0.8998101791434334,
      "grad_norm": 0.01791144534945488,
      "learning_rate": 2.2264698128130766e-06,
      "loss": 0.0003,
      "step": 15169
    },
    {
      "epoch": 0.8998694981611105,
      "grad_norm": 0.005746415350586176,
      "learning_rate": 2.2251515950435012e-06,
      "loss": 0.0001,
      "step": 15170
    },
    {
      "epoch": 0.8999288171787875,
      "grad_norm": 7.028156757354736,
      "learning_rate": 2.223833377273926e-06,
      "loss": 0.0601,
      "step": 15171
    },
    {
      "epoch": 0.8999881361964646,
      "grad_norm": 0.3373810946941376,
      "learning_rate": 2.2225151595043505e-06,
      "loss": 0.0034,
      "step": 15172
    },
    {
      "epoch": 0.9000474552141416,
      "grad_norm": 0.08116570860147476,
      "learning_rate": 2.2211969417347746e-06,
      "loss": 0.0021,
      "step": 15173
    },
    {
      "epoch": 0.9001067742318187,
      "grad_norm": 9.758464813232422,
      "learning_rate": 2.2198787239651993e-06,
      "loss": 0.1036,
      "step": 15174
    },
    {
      "epoch": 0.9001660932494958,
      "grad_norm": 14.5169038772583,
      "learning_rate": 2.2185605061956234e-06,
      "loss": 0.7502,
      "step": 15175
    },
    {
      "epoch": 0.9002254122671729,
      "grad_norm": 17.036252975463867,
      "learning_rate": 2.217242288426048e-06,
      "loss": 0.4551,
      "step": 15176
    },
    {
      "epoch": 0.9002847312848499,
      "grad_norm": 0.02059471793472767,
      "learning_rate": 2.2159240706564727e-06,
      "loss": 0.0004,
      "step": 15177
    },
    {
      "epoch": 0.900344050302527,
      "grad_norm": 0.01127458456903696,
      "learning_rate": 2.2146058528868973e-06,
      "loss": 0.0003,
      "step": 15178
    },
    {
      "epoch": 0.900403369320204,
      "grad_norm": 0.01150992140173912,
      "learning_rate": 2.2132876351173215e-06,
      "loss": 0.0004,
      "step": 15179
    },
    {
      "epoch": 0.9004626883378811,
      "grad_norm": 11.32424259185791,
      "learning_rate": 2.211969417347746e-06,
      "loss": 0.1124,
      "step": 15180
    },
    {
      "epoch": 0.9005220073555582,
      "grad_norm": 7.894084930419922,
      "learning_rate": 2.2106511995781703e-06,
      "loss": 0.2591,
      "step": 15181
    },
    {
      "epoch": 0.9005813263732353,
      "grad_norm": 0.08919378370046616,
      "learning_rate": 2.209332981808595e-06,
      "loss": 0.0008,
      "step": 15182
    },
    {
      "epoch": 0.9006406453909124,
      "grad_norm": 0.5363408923149109,
      "learning_rate": 2.2080147640390195e-06,
      "loss": 0.0028,
      "step": 15183
    },
    {
      "epoch": 0.9006999644085893,
      "grad_norm": 0.26893168687820435,
      "learning_rate": 2.206696546269444e-06,
      "loss": 0.0023,
      "step": 15184
    },
    {
      "epoch": 0.9007592834262664,
      "grad_norm": 0.03935260325670242,
      "learning_rate": 2.2053783284998683e-06,
      "loss": 0.0007,
      "step": 15185
    },
    {
      "epoch": 0.9008186024439435,
      "grad_norm": 0.3796685039997101,
      "learning_rate": 2.204060110730293e-06,
      "loss": 0.0045,
      "step": 15186
    },
    {
      "epoch": 0.9008779214616206,
      "grad_norm": 25.596416473388672,
      "learning_rate": 2.202741892960717e-06,
      "loss": 0.2177,
      "step": 15187
    },
    {
      "epoch": 0.9009372404792977,
      "grad_norm": 21.99951934814453,
      "learning_rate": 2.2014236751911417e-06,
      "loss": 0.2121,
      "step": 15188
    },
    {
      "epoch": 0.9009965594969748,
      "grad_norm": 3.527759313583374,
      "learning_rate": 2.2001054574215663e-06,
      "loss": 0.2497,
      "step": 15189
    },
    {
      "epoch": 0.9010558785146517,
      "grad_norm": 0.033050987869501114,
      "learning_rate": 2.198787239651991e-06,
      "loss": 0.0002,
      "step": 15190
    },
    {
      "epoch": 0.9011151975323288,
      "grad_norm": 1.0270898342132568,
      "learning_rate": 2.197469021882415e-06,
      "loss": 0.0126,
      "step": 15191
    },
    {
      "epoch": 0.9011745165500059,
      "grad_norm": 0.01785125397145748,
      "learning_rate": 2.1961508041128397e-06,
      "loss": 0.0004,
      "step": 15192
    },
    {
      "epoch": 0.901233835567683,
      "grad_norm": 1.4592366218566895,
      "learning_rate": 2.194832586343264e-06,
      "loss": 0.0153,
      "step": 15193
    },
    {
      "epoch": 0.9012931545853601,
      "grad_norm": 6.658875942230225,
      "learning_rate": 2.1935143685736885e-06,
      "loss": 0.1036,
      "step": 15194
    },
    {
      "epoch": 0.9013524736030372,
      "grad_norm": 1.8327418565750122,
      "learning_rate": 2.192196150804113e-06,
      "loss": 0.0298,
      "step": 15195
    },
    {
      "epoch": 0.9014117926207142,
      "grad_norm": 10.092996597290039,
      "learning_rate": 2.1908779330345377e-06,
      "loss": 0.1683,
      "step": 15196
    },
    {
      "epoch": 0.9014711116383912,
      "grad_norm": 0.013437682762742043,
      "learning_rate": 2.189559715264962e-06,
      "loss": 0.0002,
      "step": 15197
    },
    {
      "epoch": 0.9015304306560683,
      "grad_norm": 11.652263641357422,
      "learning_rate": 2.1882414974953865e-06,
      "loss": 0.6738,
      "step": 15198
    },
    {
      "epoch": 0.9015897496737454,
      "grad_norm": 0.06853831559419632,
      "learning_rate": 2.1869232797258107e-06,
      "loss": 0.0007,
      "step": 15199
    },
    {
      "epoch": 0.9016490686914225,
      "grad_norm": 0.2833683490753174,
      "learning_rate": 2.1856050619562353e-06,
      "loss": 0.0052,
      "step": 15200
    },
    {
      "epoch": 0.9017083877090996,
      "grad_norm": 1.0970274209976196,
      "learning_rate": 2.18428684418666e-06,
      "loss": 0.0091,
      "step": 15201
    },
    {
      "epoch": 0.9017677067267766,
      "grad_norm": 5.741392135620117,
      "learning_rate": 2.1829686264170845e-06,
      "loss": 0.2891,
      "step": 15202
    },
    {
      "epoch": 0.9018270257444537,
      "grad_norm": 0.0342269092798233,
      "learning_rate": 2.1816504086475087e-06,
      "loss": 0.0006,
      "step": 15203
    },
    {
      "epoch": 0.9018863447621307,
      "grad_norm": 48.08864212036133,
      "learning_rate": 2.1803321908779333e-06,
      "loss": 0.6339,
      "step": 15204
    },
    {
      "epoch": 0.9019456637798078,
      "grad_norm": 0.0033019548282027245,
      "learning_rate": 2.1790139731083575e-06,
      "loss": 0.0001,
      "step": 15205
    },
    {
      "epoch": 0.9020049827974849,
      "grad_norm": 0.007155413739383221,
      "learning_rate": 2.177695755338782e-06,
      "loss": 0.0002,
      "step": 15206
    },
    {
      "epoch": 0.902064301815162,
      "grad_norm": 0.01799914799630642,
      "learning_rate": 2.1763775375692067e-06,
      "loss": 0.0003,
      "step": 15207
    },
    {
      "epoch": 0.902123620832839,
      "grad_norm": 0.058263786137104034,
      "learning_rate": 2.175059319799631e-06,
      "loss": 0.0009,
      "step": 15208
    },
    {
      "epoch": 0.9021829398505161,
      "grad_norm": 3.1846795082092285,
      "learning_rate": 2.1737411020300555e-06,
      "loss": 0.028,
      "step": 15209
    },
    {
      "epoch": 0.9022422588681931,
      "grad_norm": 0.02188112400472164,
      "learning_rate": 2.17242288426048e-06,
      "loss": 0.0005,
      "step": 15210
    },
    {
      "epoch": 0.9023015778858702,
      "grad_norm": 0.007097040303051472,
      "learning_rate": 2.1711046664909043e-06,
      "loss": 0.0002,
      "step": 15211
    },
    {
      "epoch": 0.9023608969035473,
      "grad_norm": 0.2695388197898865,
      "learning_rate": 2.169786448721329e-06,
      "loss": 0.0033,
      "step": 15212
    },
    {
      "epoch": 0.9024202159212243,
      "grad_norm": 23.02005958557129,
      "learning_rate": 2.1684682309517536e-06,
      "loss": 0.7713,
      "step": 15213
    },
    {
      "epoch": 0.9024795349389014,
      "grad_norm": 39.64262771606445,
      "learning_rate": 2.1671500131821777e-06,
      "loss": 0.6385,
      "step": 15214
    },
    {
      "epoch": 0.9025388539565785,
      "grad_norm": 0.012012811377644539,
      "learning_rate": 2.1658317954126024e-06,
      "loss": 0.0003,
      "step": 15215
    },
    {
      "epoch": 0.9025981729742556,
      "grad_norm": 0.21222975850105286,
      "learning_rate": 2.164513577643027e-06,
      "loss": 0.0048,
      "step": 15216
    },
    {
      "epoch": 0.9026574919919326,
      "grad_norm": 4.354191303253174,
      "learning_rate": 2.163195359873451e-06,
      "loss": 0.0138,
      "step": 15217
    },
    {
      "epoch": 0.9027168110096097,
      "grad_norm": 1.94114351272583,
      "learning_rate": 2.1618771421038758e-06,
      "loss": 0.0381,
      "step": 15218
    },
    {
      "epoch": 0.9027761300272867,
      "grad_norm": 2.2278904914855957,
      "learning_rate": 2.1605589243343004e-06,
      "loss": 0.0392,
      "step": 15219
    },
    {
      "epoch": 0.9028354490449638,
      "grad_norm": 16.786373138427734,
      "learning_rate": 2.1592407065647246e-06,
      "loss": 0.5989,
      "step": 15220
    },
    {
      "epoch": 0.9028947680626409,
      "grad_norm": 0.17824047803878784,
      "learning_rate": 2.157922488795149e-06,
      "loss": 0.0015,
      "step": 15221
    },
    {
      "epoch": 0.902954087080318,
      "grad_norm": 8.60084342956543,
      "learning_rate": 2.1566042710255734e-06,
      "loss": 0.1991,
      "step": 15222
    },
    {
      "epoch": 0.903013406097995,
      "grad_norm": 2.628183364868164,
      "learning_rate": 2.155286053255998e-06,
      "loss": 0.0345,
      "step": 15223
    },
    {
      "epoch": 0.903072725115672,
      "grad_norm": 1.2468632459640503,
      "learning_rate": 2.1539678354864226e-06,
      "loss": 0.012,
      "step": 15224
    },
    {
      "epoch": 0.9031320441333491,
      "grad_norm": 24.120351791381836,
      "learning_rate": 2.152649617716847e-06,
      "loss": 0.7361,
      "step": 15225
    },
    {
      "epoch": 0.9031913631510262,
      "grad_norm": 0.009611676447093487,
      "learning_rate": 2.1513313999472714e-06,
      "loss": 0.0002,
      "step": 15226
    },
    {
      "epoch": 0.9032506821687033,
      "grad_norm": 14.951918601989746,
      "learning_rate": 2.150013182177696e-06,
      "loss": 0.3531,
      "step": 15227
    },
    {
      "epoch": 0.9033100011863804,
      "grad_norm": 0.007883546873927116,
      "learning_rate": 2.14869496440812e-06,
      "loss": 0.0002,
      "step": 15228
    },
    {
      "epoch": 0.9033693202040575,
      "grad_norm": 25.143524169921875,
      "learning_rate": 2.147376746638545e-06,
      "loss": 0.224,
      "step": 15229
    },
    {
      "epoch": 0.9034286392217344,
      "grad_norm": 0.19820035994052887,
      "learning_rate": 2.1460585288689694e-06,
      "loss": 0.0044,
      "step": 15230
    },
    {
      "epoch": 0.9034879582394115,
      "grad_norm": 0.010501611977815628,
      "learning_rate": 2.144740311099394e-06,
      "loss": 0.0002,
      "step": 15231
    },
    {
      "epoch": 0.9035472772570886,
      "grad_norm": 0.14867696166038513,
      "learning_rate": 2.143422093329818e-06,
      "loss": 0.0023,
      "step": 15232
    },
    {
      "epoch": 0.9036065962747657,
      "grad_norm": 4.680543899536133,
      "learning_rate": 2.142103875560243e-06,
      "loss": 0.0432,
      "step": 15233
    },
    {
      "epoch": 0.9036659152924428,
      "grad_norm": 4.723781585693359,
      "learning_rate": 2.140785657790667e-06,
      "loss": 0.4352,
      "step": 15234
    },
    {
      "epoch": 0.9037252343101199,
      "grad_norm": 0.7345567345619202,
      "learning_rate": 2.1394674400210916e-06,
      "loss": 0.0041,
      "step": 15235
    },
    {
      "epoch": 0.903784553327797,
      "grad_norm": 0.10400574654340744,
      "learning_rate": 2.138149222251516e-06,
      "loss": 0.0012,
      "step": 15236
    },
    {
      "epoch": 0.9038438723454739,
      "grad_norm": 13.480640411376953,
      "learning_rate": 2.136831004481941e-06,
      "loss": 0.1245,
      "step": 15237
    },
    {
      "epoch": 0.903903191363151,
      "grad_norm": 0.0026689227670431137,
      "learning_rate": 2.135512786712365e-06,
      "loss": 0.0001,
      "step": 15238
    },
    {
      "epoch": 0.9039625103808281,
      "grad_norm": 0.025728264823555946,
      "learning_rate": 2.1341945689427896e-06,
      "loss": 0.0004,
      "step": 15239
    },
    {
      "epoch": 0.9040218293985052,
      "grad_norm": 0.020883874967694283,
      "learning_rate": 2.132876351173214e-06,
      "loss": 0.0004,
      "step": 15240
    },
    {
      "epoch": 0.9040811484161823,
      "grad_norm": 0.010433025658130646,
      "learning_rate": 2.1315581334036384e-06,
      "loss": 0.0004,
      "step": 15241
    },
    {
      "epoch": 0.9041404674338593,
      "grad_norm": 19.163747787475586,
      "learning_rate": 2.1302399156340626e-06,
      "loss": 0.4262,
      "step": 15242
    },
    {
      "epoch": 0.9041997864515363,
      "grad_norm": 1.6010289192199707,
      "learning_rate": 2.1289216978644876e-06,
      "loss": 0.039,
      "step": 15243
    },
    {
      "epoch": 0.9042591054692134,
      "grad_norm": 0.008051588200032711,
      "learning_rate": 2.127603480094912e-06,
      "loss": 0.0003,
      "step": 15244
    },
    {
      "epoch": 0.9043184244868905,
      "grad_norm": 4.414672374725342,
      "learning_rate": 2.1262852623253364e-06,
      "loss": 0.3553,
      "step": 15245
    },
    {
      "epoch": 0.9043777435045676,
      "grad_norm": 13.60832691192627,
      "learning_rate": 2.1249670445557606e-06,
      "loss": 0.6283,
      "step": 15246
    },
    {
      "epoch": 0.9044370625222447,
      "grad_norm": 1.159406304359436,
      "learning_rate": 2.1236488267861852e-06,
      "loss": 0.0027,
      "step": 15247
    },
    {
      "epoch": 0.9044963815399217,
      "grad_norm": 1.47812819480896,
      "learning_rate": 2.1223306090166094e-06,
      "loss": 0.0079,
      "step": 15248
    },
    {
      "epoch": 0.9045557005575988,
      "grad_norm": 0.03307197988033295,
      "learning_rate": 2.1210123912470345e-06,
      "loss": 0.0013,
      "step": 15249
    },
    {
      "epoch": 0.9046150195752758,
      "grad_norm": 16.064498901367188,
      "learning_rate": 2.1196941734774586e-06,
      "loss": 0.1661,
      "step": 15250
    },
    {
      "epoch": 0.9046743385929529,
      "grad_norm": 0.2907273471355438,
      "learning_rate": 2.1183759557078833e-06,
      "loss": 0.0013,
      "step": 15251
    },
    {
      "epoch": 0.90473365761063,
      "grad_norm": 0.11698576807975769,
      "learning_rate": 2.1170577379383074e-06,
      "loss": 0.0013,
      "step": 15252
    },
    {
      "epoch": 0.904792976628307,
      "grad_norm": 0.06226177141070366,
      "learning_rate": 2.115739520168732e-06,
      "loss": 0.0006,
      "step": 15253
    },
    {
      "epoch": 0.9048522956459841,
      "grad_norm": 0.27821606397628784,
      "learning_rate": 2.1144213023991562e-06,
      "loss": 0.0022,
      "step": 15254
    },
    {
      "epoch": 0.9049116146636612,
      "grad_norm": 0.050580140203237534,
      "learning_rate": 2.1131030846295813e-06,
      "loss": 0.0009,
      "step": 15255
    },
    {
      "epoch": 0.9049709336813382,
      "grad_norm": 0.004704124294221401,
      "learning_rate": 2.1117848668600055e-06,
      "loss": 0.0002,
      "step": 15256
    },
    {
      "epoch": 0.9050302526990153,
      "grad_norm": 0.2236502766609192,
      "learning_rate": 2.11046664909043e-06,
      "loss": 0.0037,
      "step": 15257
    },
    {
      "epoch": 0.9050895717166924,
      "grad_norm": 8.721307754516602,
      "learning_rate": 2.1091484313208543e-06,
      "loss": 0.0783,
      "step": 15258
    },
    {
      "epoch": 0.9051488907343694,
      "grad_norm": 33.85430908203125,
      "learning_rate": 2.107830213551279e-06,
      "loss": 0.5956,
      "step": 15259
    },
    {
      "epoch": 0.9052082097520465,
      "grad_norm": 0.0188018586486578,
      "learning_rate": 2.106511995781703e-06,
      "loss": 0.0004,
      "step": 15260
    },
    {
      "epoch": 0.9052675287697236,
      "grad_norm": 14.176762580871582,
      "learning_rate": 2.1051937780121277e-06,
      "loss": 0.2993,
      "step": 15261
    },
    {
      "epoch": 0.9053268477874007,
      "grad_norm": 32.145782470703125,
      "learning_rate": 2.1038755602425523e-06,
      "loss": 0.3832,
      "step": 15262
    },
    {
      "epoch": 0.9053861668050777,
      "grad_norm": 4.907063961029053,
      "learning_rate": 2.102557342472977e-06,
      "loss": 0.2065,
      "step": 15263
    },
    {
      "epoch": 0.9054454858227547,
      "grad_norm": 5.525570869445801,
      "learning_rate": 2.101239124703401e-06,
      "loss": 0.525,
      "step": 15264
    },
    {
      "epoch": 0.9055048048404318,
      "grad_norm": 13.78466796875,
      "learning_rate": 2.0999209069338257e-06,
      "loss": 0.921,
      "step": 15265
    },
    {
      "epoch": 0.9055641238581089,
      "grad_norm": 0.0117419408634305,
      "learning_rate": 2.09860268916425e-06,
      "loss": 0.0003,
      "step": 15266
    },
    {
      "epoch": 0.905623442875786,
      "grad_norm": 17.347660064697266,
      "learning_rate": 2.0972844713946745e-06,
      "loss": 0.3288,
      "step": 15267
    },
    {
      "epoch": 0.9056827618934631,
      "grad_norm": 0.008522837422788143,
      "learning_rate": 2.095966253625099e-06,
      "loss": 0.0003,
      "step": 15268
    },
    {
      "epoch": 0.9057420809111401,
      "grad_norm": 9.740330696105957,
      "learning_rate": 2.0946480358555237e-06,
      "loss": 0.0622,
      "step": 15269
    },
    {
      "epoch": 0.9058013999288171,
      "grad_norm": 2.4901599884033203,
      "learning_rate": 2.093329818085948e-06,
      "loss": 0.0217,
      "step": 15270
    },
    {
      "epoch": 0.9058607189464942,
      "grad_norm": 0.061082758009433746,
      "learning_rate": 2.0920116003163725e-06,
      "loss": 0.0006,
      "step": 15271
    },
    {
      "epoch": 0.9059200379641713,
      "grad_norm": 0.08867083489894867,
      "learning_rate": 2.0906933825467967e-06,
      "loss": 0.0014,
      "step": 15272
    },
    {
      "epoch": 0.9059793569818484,
      "grad_norm": 4.777927398681641,
      "learning_rate": 2.0893751647772213e-06,
      "loss": 0.0529,
      "step": 15273
    },
    {
      "epoch": 0.9060386759995255,
      "grad_norm": 0.20527783036231995,
      "learning_rate": 2.088056947007646e-06,
      "loss": 0.0033,
      "step": 15274
    },
    {
      "epoch": 0.9060979950172026,
      "grad_norm": 4.767375946044922,
      "learning_rate": 2.08673872923807e-06,
      "loss": 0.0528,
      "step": 15275
    },
    {
      "epoch": 0.9061573140348795,
      "grad_norm": 0.061710551381111145,
      "learning_rate": 2.0854205114684947e-06,
      "loss": 0.001,
      "step": 15276
    },
    {
      "epoch": 0.9062166330525566,
      "grad_norm": 14.413148880004883,
      "learning_rate": 2.0841022936989193e-06,
      "loss": 0.2031,
      "step": 15277
    },
    {
      "epoch": 0.9062759520702337,
      "grad_norm": 59.877830505371094,
      "learning_rate": 2.0827840759293435e-06,
      "loss": 2.7991,
      "step": 15278
    },
    {
      "epoch": 0.9063352710879108,
      "grad_norm": 0.386801540851593,
      "learning_rate": 2.081465858159768e-06,
      "loss": 0.003,
      "step": 15279
    },
    {
      "epoch": 0.9063945901055879,
      "grad_norm": 20.756135940551758,
      "learning_rate": 2.0801476403901927e-06,
      "loss": 0.8352,
      "step": 15280
    },
    {
      "epoch": 0.906453909123265,
      "grad_norm": 0.022699084132909775,
      "learning_rate": 2.078829422620617e-06,
      "loss": 0.0006,
      "step": 15281
    },
    {
      "epoch": 0.906513228140942,
      "grad_norm": 0.028982749208807945,
      "learning_rate": 2.0775112048510415e-06,
      "loss": 0.0004,
      "step": 15282
    },
    {
      "epoch": 0.906572547158619,
      "grad_norm": 7.988513946533203,
      "learning_rate": 2.076192987081466e-06,
      "loss": 0.2941,
      "step": 15283
    },
    {
      "epoch": 0.9066318661762961,
      "grad_norm": 4.812828540802002,
      "learning_rate": 2.0748747693118903e-06,
      "loss": 0.2685,
      "step": 15284
    },
    {
      "epoch": 0.9066911851939732,
      "grad_norm": 0.02679922990500927,
      "learning_rate": 2.073556551542315e-06,
      "loss": 0.0006,
      "step": 15285
    },
    {
      "epoch": 0.9067505042116503,
      "grad_norm": 0.5143218636512756,
      "learning_rate": 2.0722383337727395e-06,
      "loss": 0.0086,
      "step": 15286
    },
    {
      "epoch": 0.9068098232293273,
      "grad_norm": 0.013329360634088516,
      "learning_rate": 2.0709201160031637e-06,
      "loss": 0.0002,
      "step": 15287
    },
    {
      "epoch": 0.9068691422470044,
      "grad_norm": 9.029017448425293,
      "learning_rate": 2.0696018982335883e-06,
      "loss": 0.4173,
      "step": 15288
    },
    {
      "epoch": 0.9069284612646814,
      "grad_norm": 9.485307693481445,
      "learning_rate": 2.0682836804640125e-06,
      "loss": 0.0664,
      "step": 15289
    },
    {
      "epoch": 0.9069877802823585,
      "grad_norm": 0.3468307554721832,
      "learning_rate": 2.066965462694437e-06,
      "loss": 0.0048,
      "step": 15290
    },
    {
      "epoch": 0.9070470993000356,
      "grad_norm": 17.77218246459961,
      "learning_rate": 2.0656472449248618e-06,
      "loss": 1.5616,
      "step": 15291
    },
    {
      "epoch": 0.9071064183177127,
      "grad_norm": 0.008472985588014126,
      "learning_rate": 2.0643290271552864e-06,
      "loss": 0.0002,
      "step": 15292
    },
    {
      "epoch": 0.9071657373353897,
      "grad_norm": 0.011952569708228111,
      "learning_rate": 2.0630108093857106e-06,
      "loss": 0.0003,
      "step": 15293
    },
    {
      "epoch": 0.9072250563530668,
      "grad_norm": 0.14085930585861206,
      "learning_rate": 2.061692591616135e-06,
      "loss": 0.0009,
      "step": 15294
    },
    {
      "epoch": 0.9072843753707439,
      "grad_norm": 14.09472942352295,
      "learning_rate": 2.0603743738465594e-06,
      "loss": 0.2193,
      "step": 15295
    },
    {
      "epoch": 0.9073436943884209,
      "grad_norm": 0.0237090103328228,
      "learning_rate": 2.059056156076984e-06,
      "loss": 0.0003,
      "step": 15296
    },
    {
      "epoch": 0.907403013406098,
      "grad_norm": 0.12316262722015381,
      "learning_rate": 2.0577379383074086e-06,
      "loss": 0.0011,
      "step": 15297
    },
    {
      "epoch": 0.907462332423775,
      "grad_norm": 51.862728118896484,
      "learning_rate": 2.056419720537833e-06,
      "loss": 0.3008,
      "step": 15298
    },
    {
      "epoch": 0.9075216514414521,
      "grad_norm": 0.3221897780895233,
      "learning_rate": 2.0551015027682574e-06,
      "loss": 0.005,
      "step": 15299
    },
    {
      "epoch": 0.9075809704591292,
      "grad_norm": 0.006065958645194769,
      "learning_rate": 2.053783284998682e-06,
      "loss": 0.0002,
      "step": 15300
    },
    {
      "epoch": 0.9076402894768063,
      "grad_norm": 0.551544725894928,
      "learning_rate": 2.052465067229106e-06,
      "loss": 0.0051,
      "step": 15301
    },
    {
      "epoch": 0.9076996084944833,
      "grad_norm": 0.006768477614969015,
      "learning_rate": 2.051146849459531e-06,
      "loss": 0.0002,
      "step": 15302
    },
    {
      "epoch": 0.9077589275121604,
      "grad_norm": 0.6027024388313293,
      "learning_rate": 2.0498286316899554e-06,
      "loss": 0.0055,
      "step": 15303
    },
    {
      "epoch": 0.9078182465298374,
      "grad_norm": 3.640331268310547,
      "learning_rate": 2.04851041392038e-06,
      "loss": 0.0513,
      "step": 15304
    },
    {
      "epoch": 0.9078775655475145,
      "grad_norm": 0.010135438293218613,
      "learning_rate": 2.047192196150804e-06,
      "loss": 0.0002,
      "step": 15305
    },
    {
      "epoch": 0.9079368845651916,
      "grad_norm": 7.917585849761963,
      "learning_rate": 2.045873978381229e-06,
      "loss": 0.1016,
      "step": 15306
    },
    {
      "epoch": 0.9079962035828687,
      "grad_norm": 0.06461531668901443,
      "learning_rate": 2.044555760611653e-06,
      "loss": 0.0009,
      "step": 15307
    },
    {
      "epoch": 0.9080555226005458,
      "grad_norm": 0.12035659700632095,
      "learning_rate": 2.043237542842078e-06,
      "loss": 0.0012,
      "step": 15308
    },
    {
      "epoch": 0.9081148416182228,
      "grad_norm": 0.6577689051628113,
      "learning_rate": 2.041919325072502e-06,
      "loss": 0.0063,
      "step": 15309
    },
    {
      "epoch": 0.9081741606358998,
      "grad_norm": 10.639595031738281,
      "learning_rate": 2.040601107302927e-06,
      "loss": 0.5638,
      "step": 15310
    },
    {
      "epoch": 0.9082334796535769,
      "grad_norm": 0.039201680570840836,
      "learning_rate": 2.039282889533351e-06,
      "loss": 0.0009,
      "step": 15311
    },
    {
      "epoch": 0.908292798671254,
      "grad_norm": 8.157145500183105,
      "learning_rate": 2.0379646717637756e-06,
      "loss": 0.0372,
      "step": 15312
    },
    {
      "epoch": 0.9083521176889311,
      "grad_norm": 5.257298946380615,
      "learning_rate": 2.0366464539942e-06,
      "loss": 0.0686,
      "step": 15313
    },
    {
      "epoch": 0.9084114367066082,
      "grad_norm": 0.042422808706760406,
      "learning_rate": 2.0353282362246244e-06,
      "loss": 0.0005,
      "step": 15314
    },
    {
      "epoch": 0.9084707557242852,
      "grad_norm": 10.701263427734375,
      "learning_rate": 2.034010018455049e-06,
      "loss": 0.2965,
      "step": 15315
    },
    {
      "epoch": 0.9085300747419622,
      "grad_norm": 8.562868118286133,
      "learning_rate": 2.0326918006854736e-06,
      "loss": 0.0566,
      "step": 15316
    },
    {
      "epoch": 0.9085893937596393,
      "grad_norm": 5.485702991485596,
      "learning_rate": 2.031373582915898e-06,
      "loss": 0.055,
      "step": 15317
    },
    {
      "epoch": 0.9086487127773164,
      "grad_norm": 0.009183818474411964,
      "learning_rate": 2.0300553651463224e-06,
      "loss": 0.0003,
      "step": 15318
    },
    {
      "epoch": 0.9087080317949935,
      "grad_norm": 0.25838416814804077,
      "learning_rate": 2.0287371473767466e-06,
      "loss": 0.0016,
      "step": 15319
    },
    {
      "epoch": 0.9087673508126706,
      "grad_norm": 0.42386072874069214,
      "learning_rate": 2.0274189296071712e-06,
      "loss": 0.005,
      "step": 15320
    },
    {
      "epoch": 0.9088266698303477,
      "grad_norm": 4.8441009521484375,
      "learning_rate": 2.026100711837596e-06,
      "loss": 0.0279,
      "step": 15321
    },
    {
      "epoch": 0.9088859888480246,
      "grad_norm": 0.059276700019836426,
      "learning_rate": 2.0247824940680204e-06,
      "loss": 0.001,
      "step": 15322
    },
    {
      "epoch": 0.9089453078657017,
      "grad_norm": 1.577595829963684,
      "learning_rate": 2.0234642762984446e-06,
      "loss": 0.0119,
      "step": 15323
    },
    {
      "epoch": 0.9090046268833788,
      "grad_norm": 9.618172645568848,
      "learning_rate": 2.0221460585288692e-06,
      "loss": 0.528,
      "step": 15324
    },
    {
      "epoch": 0.9090639459010559,
      "grad_norm": 4.188662052154541,
      "learning_rate": 2.0208278407592934e-06,
      "loss": 0.0501,
      "step": 15325
    },
    {
      "epoch": 0.909123264918733,
      "grad_norm": 5.193520545959473,
      "learning_rate": 2.019509622989718e-06,
      "loss": 0.0647,
      "step": 15326
    },
    {
      "epoch": 0.90918258393641,
      "grad_norm": 0.7207737565040588,
      "learning_rate": 2.0181914052201427e-06,
      "loss": 0.0046,
      "step": 15327
    },
    {
      "epoch": 0.9092419029540871,
      "grad_norm": 8.542520523071289,
      "learning_rate": 2.016873187450567e-06,
      "loss": 0.3402,
      "step": 15328
    },
    {
      "epoch": 0.9093012219717641,
      "grad_norm": 6.082043647766113,
      "learning_rate": 2.0155549696809915e-06,
      "loss": 0.1439,
      "step": 15329
    },
    {
      "epoch": 0.9093605409894412,
      "grad_norm": 0.010781127028167248,
      "learning_rate": 2.014236751911416e-06,
      "loss": 0.0004,
      "step": 15330
    },
    {
      "epoch": 0.9094198600071183,
      "grad_norm": 1.2513355016708374,
      "learning_rate": 2.0129185341418403e-06,
      "loss": 0.0133,
      "step": 15331
    },
    {
      "epoch": 0.9094791790247954,
      "grad_norm": 11.593445777893066,
      "learning_rate": 2.011600316372265e-06,
      "loss": 0.5335,
      "step": 15332
    },
    {
      "epoch": 0.9095384980424724,
      "grad_norm": 0.006886865012347698,
      "learning_rate": 2.0102820986026895e-06,
      "loss": 0.0001,
      "step": 15333
    },
    {
      "epoch": 0.9095978170601495,
      "grad_norm": 8.320067405700684,
      "learning_rate": 2.0089638808331137e-06,
      "loss": 0.203,
      "step": 15334
    },
    {
      "epoch": 0.9096571360778265,
      "grad_norm": 43.92819595336914,
      "learning_rate": 2.0076456630635383e-06,
      "loss": 0.2692,
      "step": 15335
    },
    {
      "epoch": 0.9097164550955036,
      "grad_norm": 2.7673118114471436,
      "learning_rate": 2.006327445293963e-06,
      "loss": 0.0177,
      "step": 15336
    },
    {
      "epoch": 0.9097757741131807,
      "grad_norm": 0.3657269775867462,
      "learning_rate": 2.005009227524387e-06,
      "loss": 0.0036,
      "step": 15337
    },
    {
      "epoch": 0.9098350931308578,
      "grad_norm": 0.9316280484199524,
      "learning_rate": 2.0036910097548117e-06,
      "loss": 0.0113,
      "step": 15338
    },
    {
      "epoch": 0.9098944121485348,
      "grad_norm": 0.6624845266342163,
      "learning_rate": 2.0023727919852363e-06,
      "loss": 0.0039,
      "step": 15339
    },
    {
      "epoch": 0.9099537311662119,
      "grad_norm": 0.012808692641556263,
      "learning_rate": 2.0010545742156605e-06,
      "loss": 0.0004,
      "step": 15340
    },
    {
      "epoch": 0.910013050183889,
      "grad_norm": 7.667287826538086,
      "learning_rate": 1.999736356446085e-06,
      "loss": 0.2281,
      "step": 15341
    },
    {
      "epoch": 0.910072369201566,
      "grad_norm": 5.343481540679932,
      "learning_rate": 1.9984181386765093e-06,
      "loss": 0.0967,
      "step": 15342
    },
    {
      "epoch": 0.9101316882192431,
      "grad_norm": 2.6768276691436768,
      "learning_rate": 1.997099920906934e-06,
      "loss": 0.033,
      "step": 15343
    },
    {
      "epoch": 0.9101910072369201,
      "grad_norm": 0.11131943017244339,
      "learning_rate": 1.9957817031373585e-06,
      "loss": 0.002,
      "step": 15344
    },
    {
      "epoch": 0.9102503262545972,
      "grad_norm": 0.047849103808403015,
      "learning_rate": 1.994463485367783e-06,
      "loss": 0.0013,
      "step": 15345
    },
    {
      "epoch": 0.9103096452722743,
      "grad_norm": 5.004570007324219,
      "learning_rate": 1.9931452675982073e-06,
      "loss": 0.0447,
      "step": 15346
    },
    {
      "epoch": 0.9103689642899514,
      "grad_norm": 4.439413070678711,
      "learning_rate": 1.991827049828632e-06,
      "loss": 0.0533,
      "step": 15347
    },
    {
      "epoch": 0.9104282833076284,
      "grad_norm": 0.057625409215688705,
      "learning_rate": 1.990508832059056e-06,
      "loss": 0.001,
      "step": 15348
    },
    {
      "epoch": 0.9104876023253055,
      "grad_norm": 0.4751090407371521,
      "learning_rate": 1.9891906142894807e-06,
      "loss": 0.0042,
      "step": 15349
    },
    {
      "epoch": 0.9105469213429825,
      "grad_norm": 9.474424362182617,
      "learning_rate": 1.9878723965199053e-06,
      "loss": 0.1512,
      "step": 15350
    },
    {
      "epoch": 0.9106062403606596,
      "grad_norm": 0.6348178386688232,
      "learning_rate": 1.98655417875033e-06,
      "loss": 0.0051,
      "step": 15351
    },
    {
      "epoch": 0.9106655593783367,
      "grad_norm": 4.1824493408203125,
      "learning_rate": 1.985235960980754e-06,
      "loss": 0.0116,
      "step": 15352
    },
    {
      "epoch": 0.9107248783960138,
      "grad_norm": 0.005045769270509481,
      "learning_rate": 1.9839177432111787e-06,
      "loss": 0.0001,
      "step": 15353
    },
    {
      "epoch": 0.9107841974136909,
      "grad_norm": 0.02134992554783821,
      "learning_rate": 1.982599525441603e-06,
      "loss": 0.0006,
      "step": 15354
    },
    {
      "epoch": 0.9108435164313679,
      "grad_norm": 0.0032470696605741978,
      "learning_rate": 1.9812813076720275e-06,
      "loss": 0.0001,
      "step": 15355
    },
    {
      "epoch": 0.9109028354490449,
      "grad_norm": 1.3413281440734863,
      "learning_rate": 1.979963089902452e-06,
      "loss": 0.0087,
      "step": 15356
    },
    {
      "epoch": 0.910962154466722,
      "grad_norm": 39.41721725463867,
      "learning_rate": 1.9786448721328767e-06,
      "loss": 1.0235,
      "step": 15357
    },
    {
      "epoch": 0.9110214734843991,
      "grad_norm": 1.4551849365234375,
      "learning_rate": 1.977326654363301e-06,
      "loss": 0.0114,
      "step": 15358
    },
    {
      "epoch": 0.9110807925020762,
      "grad_norm": 0.2742534279823303,
      "learning_rate": 1.9760084365937255e-06,
      "loss": 0.0026,
      "step": 15359
    },
    {
      "epoch": 0.9111401115197533,
      "grad_norm": 0.02672758884727955,
      "learning_rate": 1.9746902188241497e-06,
      "loss": 0.0006,
      "step": 15360
    },
    {
      "epoch": 0.9111994305374304,
      "grad_norm": 25.698740005493164,
      "learning_rate": 1.9733720010545743e-06,
      "loss": 0.2422,
      "step": 15361
    },
    {
      "epoch": 0.9112587495551073,
      "grad_norm": 1.5859763622283936,
      "learning_rate": 1.972053783284999e-06,
      "loss": 0.0151,
      "step": 15362
    },
    {
      "epoch": 0.9113180685727844,
      "grad_norm": 0.010943729430437088,
      "learning_rate": 1.9707355655154236e-06,
      "loss": 0.0003,
      "step": 15363
    },
    {
      "epoch": 0.9113773875904615,
      "grad_norm": 0.6499407291412354,
      "learning_rate": 1.9694173477458477e-06,
      "loss": 0.0053,
      "step": 15364
    },
    {
      "epoch": 0.9114367066081386,
      "grad_norm": 0.009786447510123253,
      "learning_rate": 1.9680991299762724e-06,
      "loss": 0.0003,
      "step": 15365
    },
    {
      "epoch": 0.9114960256258157,
      "grad_norm": 0.013318001292645931,
      "learning_rate": 1.9667809122066965e-06,
      "loss": 0.0003,
      "step": 15366
    },
    {
      "epoch": 0.9115553446434927,
      "grad_norm": 0.011697022244334221,
      "learning_rate": 1.965462694437121e-06,
      "loss": 0.0002,
      "step": 15367
    },
    {
      "epoch": 0.9116146636611697,
      "grad_norm": 0.0071113151498138905,
      "learning_rate": 1.9641444766675458e-06,
      "loss": 0.0002,
      "step": 15368
    },
    {
      "epoch": 0.9116739826788468,
      "grad_norm": 0.7134367227554321,
      "learning_rate": 1.9628262588979704e-06,
      "loss": 0.0112,
      "step": 15369
    },
    {
      "epoch": 0.9117333016965239,
      "grad_norm": 0.09134809672832489,
      "learning_rate": 1.9615080411283946e-06,
      "loss": 0.0015,
      "step": 15370
    },
    {
      "epoch": 0.911792620714201,
      "grad_norm": 0.27969223260879517,
      "learning_rate": 1.960189823358819e-06,
      "loss": 0.001,
      "step": 15371
    },
    {
      "epoch": 0.9118519397318781,
      "grad_norm": 0.019886881113052368,
      "learning_rate": 1.9588716055892434e-06,
      "loss": 0.0004,
      "step": 15372
    },
    {
      "epoch": 0.9119112587495551,
      "grad_norm": 0.1297898292541504,
      "learning_rate": 1.957553387819668e-06,
      "loss": 0.0024,
      "step": 15373
    },
    {
      "epoch": 0.9119705777672322,
      "grad_norm": 2.4730403423309326,
      "learning_rate": 1.9562351700500926e-06,
      "loss": 0.0161,
      "step": 15374
    },
    {
      "epoch": 0.9120298967849092,
      "grad_norm": 11.153616905212402,
      "learning_rate": 1.954916952280517e-06,
      "loss": 0.5738,
      "step": 15375
    },
    {
      "epoch": 0.9120892158025863,
      "grad_norm": 0.39661189913749695,
      "learning_rate": 1.9535987345109414e-06,
      "loss": 0.0019,
      "step": 15376
    },
    {
      "epoch": 0.9121485348202634,
      "grad_norm": 0.04909198731184006,
      "learning_rate": 1.952280516741366e-06,
      "loss": 0.0009,
      "step": 15377
    },
    {
      "epoch": 0.9122078538379405,
      "grad_norm": 0.2793539762496948,
      "learning_rate": 1.95096229897179e-06,
      "loss": 0.0045,
      "step": 15378
    },
    {
      "epoch": 0.9122671728556175,
      "grad_norm": 15.01499080657959,
      "learning_rate": 1.9496440812022148e-06,
      "loss": 1.4726,
      "step": 15379
    },
    {
      "epoch": 0.9123264918732946,
      "grad_norm": 0.024639444425702095,
      "learning_rate": 1.9483258634326394e-06,
      "loss": 0.0005,
      "step": 15380
    },
    {
      "epoch": 0.9123858108909716,
      "grad_norm": 0.0836874395608902,
      "learning_rate": 1.9470076456630636e-06,
      "loss": 0.0015,
      "step": 15381
    },
    {
      "epoch": 0.9124451299086487,
      "grad_norm": 20.971900939941406,
      "learning_rate": 1.945689427893488e-06,
      "loss": 1.0644,
      "step": 15382
    },
    {
      "epoch": 0.9125044489263258,
      "grad_norm": 0.07987091690301895,
      "learning_rate": 1.944371210123913e-06,
      "loss": 0.0024,
      "step": 15383
    },
    {
      "epoch": 0.9125637679440028,
      "grad_norm": 11.44628620147705,
      "learning_rate": 1.943052992354337e-06,
      "loss": 0.6642,
      "step": 15384
    },
    {
      "epoch": 0.9126230869616799,
      "grad_norm": 0.013119397684931755,
      "learning_rate": 1.9417347745847616e-06,
      "loss": 0.0004,
      "step": 15385
    },
    {
      "epoch": 0.912682405979357,
      "grad_norm": 1.2691609859466553,
      "learning_rate": 1.940416556815186e-06,
      "loss": 0.0137,
      "step": 15386
    },
    {
      "epoch": 0.9127417249970341,
      "grad_norm": 0.00847670715302229,
      "learning_rate": 1.9390983390456104e-06,
      "loss": 0.0003,
      "step": 15387
    },
    {
      "epoch": 0.9128010440147111,
      "grad_norm": 2.382720947265625,
      "learning_rate": 1.937780121276035e-06,
      "loss": 0.0354,
      "step": 15388
    },
    {
      "epoch": 0.9128603630323882,
      "grad_norm": 0.03018602915108204,
      "learning_rate": 1.936461903506459e-06,
      "loss": 0.0007,
      "step": 15389
    },
    {
      "epoch": 0.9129196820500652,
      "grad_norm": 1.901968002319336,
      "learning_rate": 1.935143685736884e-06,
      "loss": 0.0459,
      "step": 15390
    },
    {
      "epoch": 0.9129790010677423,
      "grad_norm": 10.048795700073242,
      "learning_rate": 1.9338254679673084e-06,
      "loss": 0.1884,
      "step": 15391
    },
    {
      "epoch": 0.9130383200854194,
      "grad_norm": 0.05628586187958717,
      "learning_rate": 1.932507250197733e-06,
      "loss": 0.0006,
      "step": 15392
    },
    {
      "epoch": 0.9130976391030965,
      "grad_norm": 4.052269458770752,
      "learning_rate": 1.9311890324281572e-06,
      "loss": 0.0498,
      "step": 15393
    },
    {
      "epoch": 0.9131569581207735,
      "grad_norm": 0.8857295513153076,
      "learning_rate": 1.929870814658582e-06,
      "loss": 0.014,
      "step": 15394
    },
    {
      "epoch": 0.9132162771384505,
      "grad_norm": 0.028031442314386368,
      "learning_rate": 1.928552596889006e-06,
      "loss": 0.0004,
      "step": 15395
    },
    {
      "epoch": 0.9132755961561276,
      "grad_norm": 0.05018925294280052,
      "learning_rate": 1.9272343791194306e-06,
      "loss": 0.0005,
      "step": 15396
    },
    {
      "epoch": 0.9133349151738047,
      "grad_norm": 2.9448444843292236,
      "learning_rate": 1.9259161613498552e-06,
      "loss": 0.0238,
      "step": 15397
    },
    {
      "epoch": 0.9133942341914818,
      "grad_norm": 11.02858829498291,
      "learning_rate": 1.92459794358028e-06,
      "loss": 0.0595,
      "step": 15398
    },
    {
      "epoch": 0.9134535532091589,
      "grad_norm": 9.29173755645752,
      "learning_rate": 1.923279725810704e-06,
      "loss": 0.6009,
      "step": 15399
    },
    {
      "epoch": 0.913512872226836,
      "grad_norm": 0.2242864966392517,
      "learning_rate": 1.9219615080411286e-06,
      "loss": 0.0029,
      "step": 15400
    },
    {
      "epoch": 0.9135721912445129,
      "grad_norm": 21.7477970123291,
      "learning_rate": 1.920643290271553e-06,
      "loss": 0.6542,
      "step": 15401
    },
    {
      "epoch": 0.91363151026219,
      "grad_norm": 3.4124724864959717,
      "learning_rate": 1.9193250725019774e-06,
      "loss": 0.2451,
      "step": 15402
    },
    {
      "epoch": 0.9136908292798671,
      "grad_norm": 77.66131591796875,
      "learning_rate": 1.9180068547324016e-06,
      "loss": 1.3553,
      "step": 15403
    },
    {
      "epoch": 0.9137501482975442,
      "grad_norm": 0.01420742366462946,
      "learning_rate": 1.9166886369628267e-06,
      "loss": 0.0003,
      "step": 15404
    },
    {
      "epoch": 0.9138094673152213,
      "grad_norm": 17.837045669555664,
      "learning_rate": 1.915370419193251e-06,
      "loss": 0.3345,
      "step": 15405
    },
    {
      "epoch": 0.9138687863328984,
      "grad_norm": 11.875894546508789,
      "learning_rate": 1.9140522014236755e-06,
      "loss": 0.4204,
      "step": 15406
    },
    {
      "epoch": 0.9139281053505754,
      "grad_norm": 1.486917495727539,
      "learning_rate": 1.9127339836540996e-06,
      "loss": 0.0264,
      "step": 15407
    },
    {
      "epoch": 0.9139874243682524,
      "grad_norm": 8.516451835632324,
      "learning_rate": 1.9114157658845243e-06,
      "loss": 0.1322,
      "step": 15408
    },
    {
      "epoch": 0.9140467433859295,
      "grad_norm": 17.423128128051758,
      "learning_rate": 1.9100975481149484e-06,
      "loss": 0.0874,
      "step": 15409
    },
    {
      "epoch": 0.9141060624036066,
      "grad_norm": 8.5369234085083,
      "learning_rate": 1.9087793303453735e-06,
      "loss": 0.0957,
      "step": 15410
    },
    {
      "epoch": 0.9141653814212837,
      "grad_norm": 0.06921064108610153,
      "learning_rate": 1.9074611125757977e-06,
      "loss": 0.0018,
      "step": 15411
    },
    {
      "epoch": 0.9142247004389608,
      "grad_norm": 0.07531735301017761,
      "learning_rate": 1.906142894806222e-06,
      "loss": 0.0007,
      "step": 15412
    },
    {
      "epoch": 0.9142840194566378,
      "grad_norm": 0.5969643592834473,
      "learning_rate": 1.9048246770366467e-06,
      "loss": 0.0056,
      "step": 15413
    },
    {
      "epoch": 0.9143433384743148,
      "grad_norm": 3.0743260383605957,
      "learning_rate": 1.903506459267071e-06,
      "loss": 0.0286,
      "step": 15414
    },
    {
      "epoch": 0.9144026574919919,
      "grad_norm": 6.241702079772949,
      "learning_rate": 1.9021882414974955e-06,
      "loss": 0.0539,
      "step": 15415
    },
    {
      "epoch": 0.914461976509669,
      "grad_norm": 2.017951726913452,
      "learning_rate": 1.90087002372792e-06,
      "loss": 0.0064,
      "step": 15416
    },
    {
      "epoch": 0.9145212955273461,
      "grad_norm": 19.503799438476562,
      "learning_rate": 1.8995518059583445e-06,
      "loss": 0.2328,
      "step": 15417
    },
    {
      "epoch": 0.9145806145450232,
      "grad_norm": 0.17810246348381042,
      "learning_rate": 1.8982335881887689e-06,
      "loss": 0.0019,
      "step": 15418
    },
    {
      "epoch": 0.9146399335627002,
      "grad_norm": 9.1210298538208,
      "learning_rate": 1.8969153704191933e-06,
      "loss": 0.2171,
      "step": 15419
    },
    {
      "epoch": 0.9146992525803773,
      "grad_norm": 3.4263458251953125,
      "learning_rate": 1.8955971526496179e-06,
      "loss": 0.0321,
      "step": 15420
    },
    {
      "epoch": 0.9147585715980543,
      "grad_norm": 4.214890003204346,
      "learning_rate": 1.8942789348800423e-06,
      "loss": 0.033,
      "step": 15421
    },
    {
      "epoch": 0.9148178906157314,
      "grad_norm": 0.020804623141884804,
      "learning_rate": 1.892960717110467e-06,
      "loss": 0.0003,
      "step": 15422
    },
    {
      "epoch": 0.9148772096334085,
      "grad_norm": 28.931594848632812,
      "learning_rate": 1.8916424993408913e-06,
      "loss": 0.2849,
      "step": 15423
    },
    {
      "epoch": 0.9149365286510855,
      "grad_norm": 0.005296139977872372,
      "learning_rate": 1.8903242815713157e-06,
      "loss": 0.0001,
      "step": 15424
    },
    {
      "epoch": 0.9149958476687626,
      "grad_norm": 4.747145175933838,
      "learning_rate": 1.88900606380174e-06,
      "loss": 0.0412,
      "step": 15425
    },
    {
      "epoch": 0.9150551666864397,
      "grad_norm": 25.613414764404297,
      "learning_rate": 1.8876878460321645e-06,
      "loss": 0.3918,
      "step": 15426
    },
    {
      "epoch": 0.9151144857041167,
      "grad_norm": 15.848664283752441,
      "learning_rate": 1.886369628262589e-06,
      "loss": 0.3676,
      "step": 15427
    },
    {
      "epoch": 0.9151738047217938,
      "grad_norm": 5.380410194396973,
      "learning_rate": 1.8850514104930137e-06,
      "loss": 0.0932,
      "step": 15428
    },
    {
      "epoch": 0.9152331237394709,
      "grad_norm": 3.6874940395355225,
      "learning_rate": 1.8837331927234381e-06,
      "loss": 0.0286,
      "step": 15429
    },
    {
      "epoch": 0.9152924427571479,
      "grad_norm": 1.3641843795776367,
      "learning_rate": 1.8824149749538625e-06,
      "loss": 0.008,
      "step": 15430
    },
    {
      "epoch": 0.915351761774825,
      "grad_norm": 0.04092111811041832,
      "learning_rate": 1.881096757184287e-06,
      "loss": 0.0007,
      "step": 15431
    },
    {
      "epoch": 0.9154110807925021,
      "grad_norm": 0.10423973947763443,
      "learning_rate": 1.8797785394147113e-06,
      "loss": 0.0004,
      "step": 15432
    },
    {
      "epoch": 0.9154703998101792,
      "grad_norm": 0.019955139607191086,
      "learning_rate": 1.8784603216451357e-06,
      "loss": 0.0005,
      "step": 15433
    },
    {
      "epoch": 0.9155297188278562,
      "grad_norm": 0.011202368885278702,
      "learning_rate": 1.8771421038755605e-06,
      "loss": 0.0002,
      "step": 15434
    },
    {
      "epoch": 0.9155890378455332,
      "grad_norm": 4.3827080726623535,
      "learning_rate": 1.875823886105985e-06,
      "loss": 0.0801,
      "step": 15435
    },
    {
      "epoch": 0.9156483568632103,
      "grad_norm": 0.0909162238240242,
      "learning_rate": 1.8745056683364093e-06,
      "loss": 0.0016,
      "step": 15436
    },
    {
      "epoch": 0.9157076758808874,
      "grad_norm": 39.55376052856445,
      "learning_rate": 1.8731874505668337e-06,
      "loss": 0.4862,
      "step": 15437
    },
    {
      "epoch": 0.9157669948985645,
      "grad_norm": 7.235227584838867,
      "learning_rate": 1.8718692327972581e-06,
      "loss": 0.0743,
      "step": 15438
    },
    {
      "epoch": 0.9158263139162416,
      "grad_norm": 0.0402979739010334,
      "learning_rate": 1.8705510150276825e-06,
      "loss": 0.0007,
      "step": 15439
    },
    {
      "epoch": 0.9158856329339187,
      "grad_norm": 3.5075156688690186,
      "learning_rate": 1.8692327972581073e-06,
      "loss": 0.0283,
      "step": 15440
    },
    {
      "epoch": 0.9159449519515956,
      "grad_norm": 4.842467308044434,
      "learning_rate": 1.8679145794885317e-06,
      "loss": 0.0362,
      "step": 15441
    },
    {
      "epoch": 0.9160042709692727,
      "grad_norm": 7.610732555389404,
      "learning_rate": 1.8665963617189561e-06,
      "loss": 0.4286,
      "step": 15442
    },
    {
      "epoch": 0.9160635899869498,
      "grad_norm": 3.7669782638549805,
      "learning_rate": 1.8652781439493805e-06,
      "loss": 0.0593,
      "step": 15443
    },
    {
      "epoch": 0.9161229090046269,
      "grad_norm": 0.03191140666604042,
      "learning_rate": 1.863959926179805e-06,
      "loss": 0.0005,
      "step": 15444
    },
    {
      "epoch": 0.916182228022304,
      "grad_norm": 0.07788880169391632,
      "learning_rate": 1.8626417084102293e-06,
      "loss": 0.0011,
      "step": 15445
    },
    {
      "epoch": 0.9162415470399811,
      "grad_norm": 0.8528055548667908,
      "learning_rate": 1.8613234906406542e-06,
      "loss": 0.0028,
      "step": 15446
    },
    {
      "epoch": 0.916300866057658,
      "grad_norm": 0.6067870259284973,
      "learning_rate": 1.8600052728710786e-06,
      "loss": 0.003,
      "step": 15447
    },
    {
      "epoch": 0.9163601850753351,
      "grad_norm": 0.009276935830712318,
      "learning_rate": 1.858687055101503e-06,
      "loss": 0.0002,
      "step": 15448
    },
    {
      "epoch": 0.9164195040930122,
      "grad_norm": 50.036495208740234,
      "learning_rate": 1.8573688373319274e-06,
      "loss": 1.7141,
      "step": 15449
    },
    {
      "epoch": 0.9164788231106893,
      "grad_norm": 1.671690583229065,
      "learning_rate": 1.8560506195623518e-06,
      "loss": 0.0198,
      "step": 15450
    },
    {
      "epoch": 0.9165381421283664,
      "grad_norm": 0.15074439346790314,
      "learning_rate": 1.8547324017927762e-06,
      "loss": 0.0006,
      "step": 15451
    },
    {
      "epoch": 0.9165974611460435,
      "grad_norm": 12.153923034667969,
      "learning_rate": 1.853414184023201e-06,
      "loss": 0.0916,
      "step": 15452
    },
    {
      "epoch": 0.9166567801637205,
      "grad_norm": 1.2110304832458496,
      "learning_rate": 1.8520959662536254e-06,
      "loss": 0.008,
      "step": 15453
    },
    {
      "epoch": 0.9167160991813975,
      "grad_norm": 4.977306365966797,
      "learning_rate": 1.8507777484840498e-06,
      "loss": 0.1092,
      "step": 15454
    },
    {
      "epoch": 0.9167754181990746,
      "grad_norm": 0.3735201358795166,
      "learning_rate": 1.8494595307144742e-06,
      "loss": 0.0053,
      "step": 15455
    },
    {
      "epoch": 0.9168347372167517,
      "grad_norm": 0.016422733664512634,
      "learning_rate": 1.8481413129448986e-06,
      "loss": 0.0004,
      "step": 15456
    },
    {
      "epoch": 0.9168940562344288,
      "grad_norm": 11.65554141998291,
      "learning_rate": 1.846823095175323e-06,
      "loss": 0.1619,
      "step": 15457
    },
    {
      "epoch": 0.9169533752521059,
      "grad_norm": 2.489901065826416,
      "learning_rate": 1.8455048774057476e-06,
      "loss": 0.0365,
      "step": 15458
    },
    {
      "epoch": 0.9170126942697829,
      "grad_norm": 0.01804235577583313,
      "learning_rate": 1.8441866596361722e-06,
      "loss": 0.0005,
      "step": 15459
    },
    {
      "epoch": 0.9170720132874599,
      "grad_norm": 9.87020492553711,
      "learning_rate": 1.8428684418665966e-06,
      "loss": 0.1336,
      "step": 15460
    },
    {
      "epoch": 0.917131332305137,
      "grad_norm": 0.013789399527013302,
      "learning_rate": 1.841550224097021e-06,
      "loss": 0.0002,
      "step": 15461
    },
    {
      "epoch": 0.9171906513228141,
      "grad_norm": 4.846529960632324,
      "learning_rate": 1.8402320063274454e-06,
      "loss": 0.1288,
      "step": 15462
    },
    {
      "epoch": 0.9172499703404912,
      "grad_norm": 0.026191120967268944,
      "learning_rate": 1.8389137885578698e-06,
      "loss": 0.0006,
      "step": 15463
    },
    {
      "epoch": 0.9173092893581682,
      "grad_norm": 0.9915673732757568,
      "learning_rate": 1.8375955707882944e-06,
      "loss": 0.0123,
      "step": 15464
    },
    {
      "epoch": 0.9173686083758453,
      "grad_norm": 0.019978754222393036,
      "learning_rate": 1.8362773530187188e-06,
      "loss": 0.0005,
      "step": 15465
    },
    {
      "epoch": 0.9174279273935224,
      "grad_norm": 0.2189740389585495,
      "learning_rate": 1.8349591352491434e-06,
      "loss": 0.0021,
      "step": 15466
    },
    {
      "epoch": 0.9174872464111994,
      "grad_norm": 0.009193419478833675,
      "learning_rate": 1.8336409174795678e-06,
      "loss": 0.0003,
      "step": 15467
    },
    {
      "epoch": 0.9175465654288765,
      "grad_norm": 13.286340713500977,
      "learning_rate": 1.8323226997099922e-06,
      "loss": 0.2915,
      "step": 15468
    },
    {
      "epoch": 0.9176058844465536,
      "grad_norm": 3.527815341949463,
      "learning_rate": 1.8310044819404166e-06,
      "loss": 0.035,
      "step": 15469
    },
    {
      "epoch": 0.9176652034642306,
      "grad_norm": 37.93297576904297,
      "learning_rate": 1.8296862641708412e-06,
      "loss": 0.5298,
      "step": 15470
    },
    {
      "epoch": 0.9177245224819077,
      "grad_norm": 0.9239441156387329,
      "learning_rate": 1.8283680464012656e-06,
      "loss": 0.0049,
      "step": 15471
    },
    {
      "epoch": 0.9177838414995848,
      "grad_norm": 12.849601745605469,
      "learning_rate": 1.82704982863169e-06,
      "loss": 0.5314,
      "step": 15472
    },
    {
      "epoch": 0.9178431605172618,
      "grad_norm": 0.6582280397415161,
      "learning_rate": 1.8257316108621146e-06,
      "loss": 0.0078,
      "step": 15473
    },
    {
      "epoch": 0.9179024795349389,
      "grad_norm": 0.005628766026347876,
      "learning_rate": 1.824413393092539e-06,
      "loss": 0.0001,
      "step": 15474
    },
    {
      "epoch": 0.917961798552616,
      "grad_norm": 0.18192316591739655,
      "learning_rate": 1.8230951753229634e-06,
      "loss": 0.0024,
      "step": 15475
    },
    {
      "epoch": 0.918021117570293,
      "grad_norm": 12.625480651855469,
      "learning_rate": 1.821776957553388e-06,
      "loss": 0.2454,
      "step": 15476
    },
    {
      "epoch": 0.9180804365879701,
      "grad_norm": 0.9322357773780823,
      "learning_rate": 1.8204587397838124e-06,
      "loss": 0.0115,
      "step": 15477
    },
    {
      "epoch": 0.9181397556056472,
      "grad_norm": 0.028165042400360107,
      "learning_rate": 1.8191405220142368e-06,
      "loss": 0.0005,
      "step": 15478
    },
    {
      "epoch": 0.9181990746233243,
      "grad_norm": 0.1880306601524353,
      "learning_rate": 1.8178223042446612e-06,
      "loss": 0.0032,
      "step": 15479
    },
    {
      "epoch": 0.9182583936410013,
      "grad_norm": 0.030690226703882217,
      "learning_rate": 1.8165040864750858e-06,
      "loss": 0.0006,
      "step": 15480
    },
    {
      "epoch": 0.9183177126586783,
      "grad_norm": 0.24304647743701935,
      "learning_rate": 1.8151858687055102e-06,
      "loss": 0.0034,
      "step": 15481
    },
    {
      "epoch": 0.9183770316763554,
      "grad_norm": 25.61851692199707,
      "learning_rate": 1.8138676509359349e-06,
      "loss": 1.0731,
      "step": 15482
    },
    {
      "epoch": 0.9184363506940325,
      "grad_norm": 0.6497281789779663,
      "learning_rate": 1.8125494331663593e-06,
      "loss": 0.006,
      "step": 15483
    },
    {
      "epoch": 0.9184956697117096,
      "grad_norm": 64.71283721923828,
      "learning_rate": 1.8112312153967837e-06,
      "loss": 0.2687,
      "step": 15484
    },
    {
      "epoch": 0.9185549887293867,
      "grad_norm": 0.004077516030520201,
      "learning_rate": 1.809912997627208e-06,
      "loss": 0.0002,
      "step": 15485
    },
    {
      "epoch": 0.9186143077470638,
      "grad_norm": 0.011119014583528042,
      "learning_rate": 1.8085947798576324e-06,
      "loss": 0.0003,
      "step": 15486
    },
    {
      "epoch": 0.9186736267647407,
      "grad_norm": 0.318941205739975,
      "learning_rate": 1.807276562088057e-06,
      "loss": 0.0032,
      "step": 15487
    },
    {
      "epoch": 0.9187329457824178,
      "grad_norm": 1.8321834802627563,
      "learning_rate": 1.8059583443184817e-06,
      "loss": 0.015,
      "step": 15488
    },
    {
      "epoch": 0.9187922648000949,
      "grad_norm": 0.012222875840961933,
      "learning_rate": 1.804640126548906e-06,
      "loss": 0.0003,
      "step": 15489
    },
    {
      "epoch": 0.918851583817772,
      "grad_norm": 23.798133850097656,
      "learning_rate": 1.8033219087793305e-06,
      "loss": 0.5777,
      "step": 15490
    },
    {
      "epoch": 0.9189109028354491,
      "grad_norm": 0.11332463473081589,
      "learning_rate": 1.8020036910097549e-06,
      "loss": 0.0014,
      "step": 15491
    },
    {
      "epoch": 0.9189702218531262,
      "grad_norm": 5.595620155334473,
      "learning_rate": 1.8006854732401793e-06,
      "loss": 0.4068,
      "step": 15492
    },
    {
      "epoch": 0.9190295408708031,
      "grad_norm": 4.866757392883301,
      "learning_rate": 1.7993672554706037e-06,
      "loss": 0.0168,
      "step": 15493
    },
    {
      "epoch": 0.9190888598884802,
      "grad_norm": 55.202392578125,
      "learning_rate": 1.7980490377010285e-06,
      "loss": 1.6374,
      "step": 15494
    },
    {
      "epoch": 0.9191481789061573,
      "grad_norm": 2.8250911235809326,
      "learning_rate": 1.7967308199314529e-06,
      "loss": 0.0225,
      "step": 15495
    },
    {
      "epoch": 0.9192074979238344,
      "grad_norm": 0.055964820086956024,
      "learning_rate": 1.7954126021618773e-06,
      "loss": 0.0012,
      "step": 15496
    },
    {
      "epoch": 0.9192668169415115,
      "grad_norm": 4.392120838165283,
      "learning_rate": 1.7940943843923017e-06,
      "loss": 0.0665,
      "step": 15497
    },
    {
      "epoch": 0.9193261359591886,
      "grad_norm": 15.20761489868164,
      "learning_rate": 1.792776166622726e-06,
      "loss": 0.3032,
      "step": 15498
    },
    {
      "epoch": 0.9193854549768656,
      "grad_norm": 0.19385582208633423,
      "learning_rate": 1.7914579488531505e-06,
      "loss": 0.0053,
      "step": 15499
    },
    {
      "epoch": 0.9194447739945426,
      "grad_norm": 6.818828105926514,
      "learning_rate": 1.7901397310835753e-06,
      "loss": 0.6794,
      "step": 15500
    },
    {
      "epoch": 0.9195040930122197,
      "grad_norm": 25.889446258544922,
      "learning_rate": 1.7888215133139997e-06,
      "loss": 0.4663,
      "step": 15501
    },
    {
      "epoch": 0.9195634120298968,
      "grad_norm": 16.40984535217285,
      "learning_rate": 1.787503295544424e-06,
      "loss": 0.3972,
      "step": 15502
    },
    {
      "epoch": 0.9196227310475739,
      "grad_norm": 0.4795045256614685,
      "learning_rate": 1.7861850777748485e-06,
      "loss": 0.0023,
      "step": 15503
    },
    {
      "epoch": 0.9196820500652509,
      "grad_norm": 0.049807947129011154,
      "learning_rate": 1.784866860005273e-06,
      "loss": 0.0007,
      "step": 15504
    },
    {
      "epoch": 0.919741369082928,
      "grad_norm": 62.8626594543457,
      "learning_rate": 1.7835486422356973e-06,
      "loss": 0.8835,
      "step": 15505
    },
    {
      "epoch": 0.919800688100605,
      "grad_norm": 0.06872233748435974,
      "learning_rate": 1.7822304244661221e-06,
      "loss": 0.0008,
      "step": 15506
    },
    {
      "epoch": 0.9198600071182821,
      "grad_norm": 0.11612745374441147,
      "learning_rate": 1.7809122066965465e-06,
      "loss": 0.0017,
      "step": 15507
    },
    {
      "epoch": 0.9199193261359592,
      "grad_norm": 0.10152655094861984,
      "learning_rate": 1.779593988926971e-06,
      "loss": 0.0012,
      "step": 15508
    },
    {
      "epoch": 0.9199786451536363,
      "grad_norm": 19.381784439086914,
      "learning_rate": 1.7782757711573953e-06,
      "loss": 0.5206,
      "step": 15509
    },
    {
      "epoch": 0.9200379641713133,
      "grad_norm": 15.7775297164917,
      "learning_rate": 1.7769575533878197e-06,
      "loss": 0.3534,
      "step": 15510
    },
    {
      "epoch": 0.9200972831889904,
      "grad_norm": 0.09926408529281616,
      "learning_rate": 1.7756393356182441e-06,
      "loss": 0.0015,
      "step": 15511
    },
    {
      "epoch": 0.9201566022066675,
      "grad_norm": 7.801486968994141,
      "learning_rate": 1.774321117848669e-06,
      "loss": 0.3797,
      "step": 15512
    },
    {
      "epoch": 0.9202159212243445,
      "grad_norm": 2.417431592941284,
      "learning_rate": 1.7730029000790933e-06,
      "loss": 0.0124,
      "step": 15513
    },
    {
      "epoch": 0.9202752402420216,
      "grad_norm": 0.8872957825660706,
      "learning_rate": 1.7716846823095177e-06,
      "loss": 0.0095,
      "step": 15514
    },
    {
      "epoch": 0.9203345592596986,
      "grad_norm": 27.28099250793457,
      "learning_rate": 1.7703664645399421e-06,
      "loss": 0.3823,
      "step": 15515
    },
    {
      "epoch": 0.9203938782773757,
      "grad_norm": 4.829246520996094,
      "learning_rate": 1.7690482467703665e-06,
      "loss": 0.0555,
      "step": 15516
    },
    {
      "epoch": 0.9204531972950528,
      "grad_norm": 0.10841760039329529,
      "learning_rate": 1.767730029000791e-06,
      "loss": 0.0009,
      "step": 15517
    },
    {
      "epoch": 0.9205125163127299,
      "grad_norm": 0.02871549129486084,
      "learning_rate": 1.7664118112312155e-06,
      "loss": 0.0005,
      "step": 15518
    },
    {
      "epoch": 0.9205718353304069,
      "grad_norm": 1.0458707809448242,
      "learning_rate": 1.7650935934616402e-06,
      "loss": 0.0098,
      "step": 15519
    },
    {
      "epoch": 0.920631154348084,
      "grad_norm": 0.025351470336318016,
      "learning_rate": 1.7637753756920646e-06,
      "loss": 0.0004,
      "step": 15520
    },
    {
      "epoch": 0.920690473365761,
      "grad_norm": 5.109758377075195,
      "learning_rate": 1.762457157922489e-06,
      "loss": 0.0401,
      "step": 15521
    },
    {
      "epoch": 0.9207497923834381,
      "grad_norm": 0.022566942498087883,
      "learning_rate": 1.7611389401529133e-06,
      "loss": 0.0004,
      "step": 15522
    },
    {
      "epoch": 0.9208091114011152,
      "grad_norm": 2.1253223419189453,
      "learning_rate": 1.759820722383338e-06,
      "loss": 0.0416,
      "step": 15523
    },
    {
      "epoch": 0.9208684304187923,
      "grad_norm": 23.674848556518555,
      "learning_rate": 1.7585025046137624e-06,
      "loss": 1.0378,
      "step": 15524
    },
    {
      "epoch": 0.9209277494364694,
      "grad_norm": 7.857296466827393,
      "learning_rate": 1.7571842868441868e-06,
      "loss": 0.1069,
      "step": 15525
    },
    {
      "epoch": 0.9209870684541464,
      "grad_norm": 15.471549987792969,
      "learning_rate": 1.7558660690746114e-06,
      "loss": 0.1951,
      "step": 15526
    },
    {
      "epoch": 0.9210463874718234,
      "grad_norm": 0.007252180483192205,
      "learning_rate": 1.7545478513050358e-06,
      "loss": 0.0003,
      "step": 15527
    },
    {
      "epoch": 0.9211057064895005,
      "grad_norm": 0.03480399027466774,
      "learning_rate": 1.7532296335354602e-06,
      "loss": 0.0003,
      "step": 15528
    },
    {
      "epoch": 0.9211650255071776,
      "grad_norm": 2.1025686264038086,
      "learning_rate": 1.7519114157658848e-06,
      "loss": 0.0246,
      "step": 15529
    },
    {
      "epoch": 0.9212243445248547,
      "grad_norm": 1.0519487857818604,
      "learning_rate": 1.7505931979963092e-06,
      "loss": 0.006,
      "step": 15530
    },
    {
      "epoch": 0.9212836635425318,
      "grad_norm": 5.577579021453857,
      "learning_rate": 1.7492749802267336e-06,
      "loss": 0.1191,
      "step": 15531
    },
    {
      "epoch": 0.9213429825602089,
      "grad_norm": 0.12930457293987274,
      "learning_rate": 1.747956762457158e-06,
      "loss": 0.0018,
      "step": 15532
    },
    {
      "epoch": 0.9214023015778858,
      "grad_norm": 10.534045219421387,
      "learning_rate": 1.7466385446875826e-06,
      "loss": 0.5223,
      "step": 15533
    },
    {
      "epoch": 0.9214616205955629,
      "grad_norm": 2.9562692642211914,
      "learning_rate": 1.745320326918007e-06,
      "loss": 0.0223,
      "step": 15534
    },
    {
      "epoch": 0.92152093961324,
      "grad_norm": 0.010723503306508064,
      "learning_rate": 1.7440021091484316e-06,
      "loss": 0.0003,
      "step": 15535
    },
    {
      "epoch": 0.9215802586309171,
      "grad_norm": 3.527832508087158,
      "learning_rate": 1.742683891378856e-06,
      "loss": 0.3742,
      "step": 15536
    },
    {
      "epoch": 0.9216395776485942,
      "grad_norm": 0.438127338886261,
      "learning_rate": 1.7413656736092804e-06,
      "loss": 0.007,
      "step": 15537
    },
    {
      "epoch": 0.9216988966662713,
      "grad_norm": 14.086499214172363,
      "learning_rate": 1.7400474558397048e-06,
      "loss": 0.3184,
      "step": 15538
    },
    {
      "epoch": 0.9217582156839482,
      "grad_norm": 0.03126790374517441,
      "learning_rate": 1.7387292380701292e-06,
      "loss": 0.0005,
      "step": 15539
    },
    {
      "epoch": 0.9218175347016253,
      "grad_norm": 0.08612720668315887,
      "learning_rate": 1.7374110203005538e-06,
      "loss": 0.0008,
      "step": 15540
    },
    {
      "epoch": 0.9218768537193024,
      "grad_norm": 0.7003993391990662,
      "learning_rate": 1.7360928025309784e-06,
      "loss": 0.0069,
      "step": 15541
    },
    {
      "epoch": 0.9219361727369795,
      "grad_norm": 6.543764591217041,
      "learning_rate": 1.7347745847614028e-06,
      "loss": 0.2188,
      "step": 15542
    },
    {
      "epoch": 0.9219954917546566,
      "grad_norm": 0.033512238413095474,
      "learning_rate": 1.7334563669918272e-06,
      "loss": 0.0005,
      "step": 15543
    },
    {
      "epoch": 0.9220548107723336,
      "grad_norm": 14.970770835876465,
      "learning_rate": 1.7321381492222516e-06,
      "loss": 0.3249,
      "step": 15544
    },
    {
      "epoch": 0.9221141297900107,
      "grad_norm": 0.03487890586256981,
      "learning_rate": 1.730819931452676e-06,
      "loss": 0.0008,
      "step": 15545
    },
    {
      "epoch": 0.9221734488076877,
      "grad_norm": 0.8060035109519958,
      "learning_rate": 1.7295017136831004e-06,
      "loss": 0.0085,
      "step": 15546
    },
    {
      "epoch": 0.9222327678253648,
      "grad_norm": 0.1450374871492386,
      "learning_rate": 1.7281834959135252e-06,
      "loss": 0.0024,
      "step": 15547
    },
    {
      "epoch": 0.9222920868430419,
      "grad_norm": 0.018157145008444786,
      "learning_rate": 1.7268652781439496e-06,
      "loss": 0.0004,
      "step": 15548
    },
    {
      "epoch": 0.922351405860719,
      "grad_norm": 0.028731513768434525,
      "learning_rate": 1.725547060374374e-06,
      "loss": 0.0006,
      "step": 15549
    },
    {
      "epoch": 0.922410724878396,
      "grad_norm": 4.639113426208496,
      "learning_rate": 1.7242288426047984e-06,
      "loss": 0.1536,
      "step": 15550
    },
    {
      "epoch": 0.9224700438960731,
      "grad_norm": 0.11572141200304031,
      "learning_rate": 1.7229106248352228e-06,
      "loss": 0.0009,
      "step": 15551
    },
    {
      "epoch": 0.9225293629137501,
      "grad_norm": 0.004842958878725767,
      "learning_rate": 1.7215924070656472e-06,
      "loss": 0.0001,
      "step": 15552
    },
    {
      "epoch": 0.9225886819314272,
      "grad_norm": 27.10088539123535,
      "learning_rate": 1.720274189296072e-06,
      "loss": 0.1243,
      "step": 15553
    },
    {
      "epoch": 0.9226480009491043,
      "grad_norm": 1.0631693601608276,
      "learning_rate": 1.7189559715264964e-06,
      "loss": 0.0082,
      "step": 15554
    },
    {
      "epoch": 0.9227073199667813,
      "grad_norm": 17.572345733642578,
      "learning_rate": 1.7176377537569208e-06,
      "loss": 0.6244,
      "step": 15555
    },
    {
      "epoch": 0.9227666389844584,
      "grad_norm": 8.996655464172363,
      "learning_rate": 1.7163195359873452e-06,
      "loss": 0.2032,
      "step": 15556
    },
    {
      "epoch": 0.9228259580021355,
      "grad_norm": 0.020412737503647804,
      "learning_rate": 1.7150013182177696e-06,
      "loss": 0.0005,
      "step": 15557
    },
    {
      "epoch": 0.9228852770198126,
      "grad_norm": 4.570582866668701,
      "learning_rate": 1.713683100448194e-06,
      "loss": 0.053,
      "step": 15558
    },
    {
      "epoch": 0.9229445960374896,
      "grad_norm": 2.179083824157715,
      "learning_rate": 1.7123648826786189e-06,
      "loss": 0.0139,
      "step": 15559
    },
    {
      "epoch": 0.9230039150551667,
      "grad_norm": 0.004531770013272762,
      "learning_rate": 1.7110466649090433e-06,
      "loss": 0.0001,
      "step": 15560
    },
    {
      "epoch": 0.9230632340728437,
      "grad_norm": 0.016811668872833252,
      "learning_rate": 1.7097284471394677e-06,
      "loss": 0.0003,
      "step": 15561
    },
    {
      "epoch": 0.9231225530905208,
      "grad_norm": 0.11364470422267914,
      "learning_rate": 1.708410229369892e-06,
      "loss": 0.0012,
      "step": 15562
    },
    {
      "epoch": 0.9231818721081979,
      "grad_norm": 0.7917041778564453,
      "learning_rate": 1.7070920116003165e-06,
      "loss": 0.0091,
      "step": 15563
    },
    {
      "epoch": 0.923241191125875,
      "grad_norm": 44.19798278808594,
      "learning_rate": 1.7057737938307409e-06,
      "loss": 0.7082,
      "step": 15564
    },
    {
      "epoch": 0.9233005101435521,
      "grad_norm": 0.7903349995613098,
      "learning_rate": 1.7044555760611657e-06,
      "loss": 0.0097,
      "step": 15565
    },
    {
      "epoch": 0.923359829161229,
      "grad_norm": 0.5384795069694519,
      "learning_rate": 1.70313735829159e-06,
      "loss": 0.0031,
      "step": 15566
    },
    {
      "epoch": 0.9234191481789061,
      "grad_norm": 0.5437121987342834,
      "learning_rate": 1.7018191405220145e-06,
      "loss": 0.0068,
      "step": 15567
    },
    {
      "epoch": 0.9234784671965832,
      "grad_norm": 3.481501340866089,
      "learning_rate": 1.7005009227524389e-06,
      "loss": 0.0192,
      "step": 15568
    },
    {
      "epoch": 0.9235377862142603,
      "grad_norm": 20.002899169921875,
      "learning_rate": 1.6991827049828633e-06,
      "loss": 0.2369,
      "step": 15569
    },
    {
      "epoch": 0.9235971052319374,
      "grad_norm": 0.038405973464250565,
      "learning_rate": 1.6978644872132877e-06,
      "loss": 0.0007,
      "step": 15570
    },
    {
      "epoch": 0.9236564242496145,
      "grad_norm": 1.0945887565612793,
      "learning_rate": 1.6965462694437123e-06,
      "loss": 0.0109,
      "step": 15571
    },
    {
      "epoch": 0.9237157432672914,
      "grad_norm": 0.024356145411729813,
      "learning_rate": 1.6952280516741369e-06,
      "loss": 0.0004,
      "step": 15572
    },
    {
      "epoch": 0.9237750622849685,
      "grad_norm": 0.822395384311676,
      "learning_rate": 1.6939098339045613e-06,
      "loss": 0.0118,
      "step": 15573
    },
    {
      "epoch": 0.9238343813026456,
      "grad_norm": 4.821532249450684,
      "learning_rate": 1.6925916161349857e-06,
      "loss": 0.3073,
      "step": 15574
    },
    {
      "epoch": 0.9238937003203227,
      "grad_norm": 0.06417491286993027,
      "learning_rate": 1.69127339836541e-06,
      "loss": 0.0014,
      "step": 15575
    },
    {
      "epoch": 0.9239530193379998,
      "grad_norm": 4.283315658569336,
      "learning_rate": 1.6899551805958345e-06,
      "loss": 0.1238,
      "step": 15576
    },
    {
      "epoch": 0.9240123383556769,
      "grad_norm": 0.5239587426185608,
      "learning_rate": 1.688636962826259e-06,
      "loss": 0.0069,
      "step": 15577
    },
    {
      "epoch": 0.924071657373354,
      "grad_norm": 7.657352447509766,
      "learning_rate": 1.6873187450566835e-06,
      "loss": 0.3544,
      "step": 15578
    },
    {
      "epoch": 0.9241309763910309,
      "grad_norm": 0.06917653232812881,
      "learning_rate": 1.6860005272871081e-06,
      "loss": 0.0008,
      "step": 15579
    },
    {
      "epoch": 0.924190295408708,
      "grad_norm": 11.83534049987793,
      "learning_rate": 1.6846823095175325e-06,
      "loss": 0.0992,
      "step": 15580
    },
    {
      "epoch": 0.9242496144263851,
      "grad_norm": 0.014732887968420982,
      "learning_rate": 1.683364091747957e-06,
      "loss": 0.0002,
      "step": 15581
    },
    {
      "epoch": 0.9243089334440622,
      "grad_norm": 6.459695339202881,
      "learning_rate": 1.6820458739783813e-06,
      "loss": 0.0854,
      "step": 15582
    },
    {
      "epoch": 0.9243682524617393,
      "grad_norm": 8.028871536254883,
      "learning_rate": 1.680727656208806e-06,
      "loss": 0.1542,
      "step": 15583
    },
    {
      "epoch": 0.9244275714794163,
      "grad_norm": 0.2742660343647003,
      "learning_rate": 1.6794094384392303e-06,
      "loss": 0.0035,
      "step": 15584
    },
    {
      "epoch": 0.9244868904970933,
      "grad_norm": 0.3181378245353699,
      "learning_rate": 1.6780912206696547e-06,
      "loss": 0.0052,
      "step": 15585
    },
    {
      "epoch": 0.9245462095147704,
      "grad_norm": 7.435741901397705,
      "learning_rate": 1.6767730029000793e-06,
      "loss": 0.2146,
      "step": 15586
    },
    {
      "epoch": 0.9246055285324475,
      "grad_norm": 7.129079818725586,
      "learning_rate": 1.6754547851305037e-06,
      "loss": 0.0809,
      "step": 15587
    },
    {
      "epoch": 0.9246648475501246,
      "grad_norm": 13.245694160461426,
      "learning_rate": 1.6741365673609281e-06,
      "loss": 0.3885,
      "step": 15588
    },
    {
      "epoch": 0.9247241665678017,
      "grad_norm": 14.763558387756348,
      "learning_rate": 1.6728183495913527e-06,
      "loss": 0.5418,
      "step": 15589
    },
    {
      "epoch": 0.9247834855854787,
      "grad_norm": 14.798271179199219,
      "learning_rate": 1.6715001318217771e-06,
      "loss": 0.2565,
      "step": 15590
    },
    {
      "epoch": 0.9248428046031558,
      "grad_norm": 0.16573484241962433,
      "learning_rate": 1.6701819140522015e-06,
      "loss": 0.0019,
      "step": 15591
    },
    {
      "epoch": 0.9249021236208328,
      "grad_norm": 15.438607215881348,
      "learning_rate": 1.668863696282626e-06,
      "loss": 0.1005,
      "step": 15592
    },
    {
      "epoch": 0.9249614426385099,
      "grad_norm": 11.275400161743164,
      "learning_rate": 1.6675454785130503e-06,
      "loss": 0.1787,
      "step": 15593
    },
    {
      "epoch": 0.925020761656187,
      "grad_norm": 0.36090874671936035,
      "learning_rate": 1.666227260743475e-06,
      "loss": 0.0034,
      "step": 15594
    },
    {
      "epoch": 0.925080080673864,
      "grad_norm": 0.02264472097158432,
      "learning_rate": 1.6649090429738995e-06,
      "loss": 0.0005,
      "step": 15595
    },
    {
      "epoch": 0.9251393996915411,
      "grad_norm": 13.834007263183594,
      "learning_rate": 1.663590825204324e-06,
      "loss": 0.0439,
      "step": 15596
    },
    {
      "epoch": 0.9251987187092182,
      "grad_norm": 0.0228450708091259,
      "learning_rate": 1.6622726074347483e-06,
      "loss": 0.0006,
      "step": 15597
    },
    {
      "epoch": 0.9252580377268952,
      "grad_norm": 9.910246849060059,
      "learning_rate": 1.6609543896651727e-06,
      "loss": 0.4374,
      "step": 15598
    },
    {
      "epoch": 0.9253173567445723,
      "grad_norm": 1.5388048887252808,
      "learning_rate": 1.6596361718955971e-06,
      "loss": 0.0196,
      "step": 15599
    },
    {
      "epoch": 0.9253766757622494,
      "grad_norm": 0.0997847467660904,
      "learning_rate": 1.6583179541260215e-06,
      "loss": 0.0013,
      "step": 15600
    },
    {
      "epoch": 0.9254359947799264,
      "grad_norm": 0.07177000492811203,
      "learning_rate": 1.6569997363564464e-06,
      "loss": 0.0009,
      "step": 15601
    },
    {
      "epoch": 0.9254953137976035,
      "grad_norm": 0.04813917353749275,
      "learning_rate": 1.6556815185868708e-06,
      "loss": 0.0009,
      "step": 15602
    },
    {
      "epoch": 0.9255546328152806,
      "grad_norm": 0.47962629795074463,
      "learning_rate": 1.6543633008172952e-06,
      "loss": 0.0037,
      "step": 15603
    },
    {
      "epoch": 0.9256139518329577,
      "grad_norm": 0.07513071596622467,
      "learning_rate": 1.6530450830477196e-06,
      "loss": 0.0006,
      "step": 15604
    },
    {
      "epoch": 0.9256732708506347,
      "grad_norm": 0.018334945663809776,
      "learning_rate": 1.651726865278144e-06,
      "loss": 0.0005,
      "step": 15605
    },
    {
      "epoch": 0.9257325898683118,
      "grad_norm": 0.013209875673055649,
      "learning_rate": 1.6504086475085684e-06,
      "loss": 0.0003,
      "step": 15606
    },
    {
      "epoch": 0.9257919088859888,
      "grad_norm": 0.013335684314370155,
      "learning_rate": 1.6490904297389932e-06,
      "loss": 0.0002,
      "step": 15607
    },
    {
      "epoch": 0.9258512279036659,
      "grad_norm": 0.39817988872528076,
      "learning_rate": 1.6477722119694176e-06,
      "loss": 0.0043,
      "step": 15608
    },
    {
      "epoch": 0.925910546921343,
      "grad_norm": 30.8643798828125,
      "learning_rate": 1.646453994199842e-06,
      "loss": 1.2685,
      "step": 15609
    },
    {
      "epoch": 0.9259698659390201,
      "grad_norm": 0.2586178779602051,
      "learning_rate": 1.6451357764302664e-06,
      "loss": 0.0043,
      "step": 15610
    },
    {
      "epoch": 0.9260291849566972,
      "grad_norm": 0.009662740863859653,
      "learning_rate": 1.6438175586606908e-06,
      "loss": 0.0002,
      "step": 15611
    },
    {
      "epoch": 0.9260885039743741,
      "grad_norm": 0.1278316080570221,
      "learning_rate": 1.6424993408911152e-06,
      "loss": 0.0016,
      "step": 15612
    },
    {
      "epoch": 0.9261478229920512,
      "grad_norm": 57.347591400146484,
      "learning_rate": 1.64118112312154e-06,
      "loss": 0.7871,
      "step": 15613
    },
    {
      "epoch": 0.9262071420097283,
      "grad_norm": 1.984917163848877,
      "learning_rate": 1.6398629053519644e-06,
      "loss": 0.0178,
      "step": 15614
    },
    {
      "epoch": 0.9262664610274054,
      "grad_norm": 0.003844678867608309,
      "learning_rate": 1.6385446875823888e-06,
      "loss": 0.0001,
      "step": 15615
    },
    {
      "epoch": 0.9263257800450825,
      "grad_norm": 10.116451263427734,
      "learning_rate": 1.6372264698128132e-06,
      "loss": 0.2985,
      "step": 15616
    },
    {
      "epoch": 0.9263850990627596,
      "grad_norm": 0.2500574588775635,
      "learning_rate": 1.6359082520432376e-06,
      "loss": 0.0011,
      "step": 15617
    },
    {
      "epoch": 0.9264444180804365,
      "grad_norm": 1.4320544004440308,
      "learning_rate": 1.634590034273662e-06,
      "loss": 0.01,
      "step": 15618
    },
    {
      "epoch": 0.9265037370981136,
      "grad_norm": 0.1756952852010727,
      "learning_rate": 1.6332718165040868e-06,
      "loss": 0.0027,
      "step": 15619
    },
    {
      "epoch": 0.9265630561157907,
      "grad_norm": 11.640276908874512,
      "learning_rate": 1.6319535987345112e-06,
      "loss": 0.0905,
      "step": 15620
    },
    {
      "epoch": 0.9266223751334678,
      "grad_norm": 3.307849884033203,
      "learning_rate": 1.6306353809649356e-06,
      "loss": 0.0245,
      "step": 15621
    },
    {
      "epoch": 0.9266816941511449,
      "grad_norm": 11.328581809997559,
      "learning_rate": 1.62931716319536e-06,
      "loss": 0.1842,
      "step": 15622
    },
    {
      "epoch": 0.926741013168822,
      "grad_norm": 2.4641435146331787,
      "learning_rate": 1.6279989454257844e-06,
      "loss": 0.0151,
      "step": 15623
    },
    {
      "epoch": 0.926800332186499,
      "grad_norm": 0.1479731947183609,
      "learning_rate": 1.6266807276562088e-06,
      "loss": 0.0012,
      "step": 15624
    },
    {
      "epoch": 0.926859651204176,
      "grad_norm": 0.10112925618886948,
      "learning_rate": 1.6253625098866334e-06,
      "loss": 0.0016,
      "step": 15625
    },
    {
      "epoch": 0.9269189702218531,
      "grad_norm": 1.1210302114486694,
      "learning_rate": 1.624044292117058e-06,
      "loss": 0.0228,
      "step": 15626
    },
    {
      "epoch": 0.9269782892395302,
      "grad_norm": 4.432094097137451,
      "learning_rate": 1.6227260743474824e-06,
      "loss": 0.0327,
      "step": 15627
    },
    {
      "epoch": 0.9270376082572073,
      "grad_norm": 0.033489201217889786,
      "learning_rate": 1.6214078565779068e-06,
      "loss": 0.0004,
      "step": 15628
    },
    {
      "epoch": 0.9270969272748844,
      "grad_norm": 0.1315634399652481,
      "learning_rate": 1.6200896388083312e-06,
      "loss": 0.0015,
      "step": 15629
    },
    {
      "epoch": 0.9271562462925614,
      "grad_norm": 0.062341298907995224,
      "learning_rate": 1.6187714210387556e-06,
      "loss": 0.001,
      "step": 15630
    },
    {
      "epoch": 0.9272155653102384,
      "grad_norm": 16.392305374145508,
      "learning_rate": 1.6174532032691802e-06,
      "loss": 0.5244,
      "step": 15631
    },
    {
      "epoch": 0.9272748843279155,
      "grad_norm": 45.6807975769043,
      "learning_rate": 1.6161349854996046e-06,
      "loss": 0.1447,
      "step": 15632
    },
    {
      "epoch": 0.9273342033455926,
      "grad_norm": 0.799169659614563,
      "learning_rate": 1.6148167677300292e-06,
      "loss": 0.0051,
      "step": 15633
    },
    {
      "epoch": 0.9273935223632697,
      "grad_norm": 7.30076265335083,
      "learning_rate": 1.6134985499604536e-06,
      "loss": 0.1362,
      "step": 15634
    },
    {
      "epoch": 0.9274528413809467,
      "grad_norm": 0.42852583527565,
      "learning_rate": 1.612180332190878e-06,
      "loss": 0.0043,
      "step": 15635
    },
    {
      "epoch": 0.9275121603986238,
      "grad_norm": 6.3372015953063965,
      "learning_rate": 1.6108621144213024e-06,
      "loss": 0.0143,
      "step": 15636
    },
    {
      "epoch": 0.9275714794163009,
      "grad_norm": 23.994853973388672,
      "learning_rate": 1.609543896651727e-06,
      "loss": 0.1158,
      "step": 15637
    },
    {
      "epoch": 0.9276307984339779,
      "grad_norm": 0.7051871418952942,
      "learning_rate": 1.6082256788821515e-06,
      "loss": 0.0069,
      "step": 15638
    },
    {
      "epoch": 0.927690117451655,
      "grad_norm": 0.030313177034258842,
      "learning_rate": 1.6069074611125758e-06,
      "loss": 0.0006,
      "step": 15639
    },
    {
      "epoch": 0.9277494364693321,
      "grad_norm": 0.20903755724430084,
      "learning_rate": 1.6055892433430005e-06,
      "loss": 0.004,
      "step": 15640
    },
    {
      "epoch": 0.9278087554870091,
      "grad_norm": 0.061478257179260254,
      "learning_rate": 1.6042710255734249e-06,
      "loss": 0.0006,
      "step": 15641
    },
    {
      "epoch": 0.9278680745046862,
      "grad_norm": 6.801938056945801,
      "learning_rate": 1.6029528078038493e-06,
      "loss": 0.2559,
      "step": 15642
    },
    {
      "epoch": 0.9279273935223633,
      "grad_norm": 1.8329774141311646,
      "learning_rate": 1.6016345900342739e-06,
      "loss": 0.0416,
      "step": 15643
    },
    {
      "epoch": 0.9279867125400403,
      "grad_norm": 0.16878685355186462,
      "learning_rate": 1.6003163722646983e-06,
      "loss": 0.0023,
      "step": 15644
    },
    {
      "epoch": 0.9280460315577174,
      "grad_norm": 16.228179931640625,
      "learning_rate": 1.5989981544951227e-06,
      "loss": 0.2686,
      "step": 15645
    },
    {
      "epoch": 0.9281053505753944,
      "grad_norm": 13.634057998657227,
      "learning_rate": 1.597679936725547e-06,
      "loss": 0.391,
      "step": 15646
    },
    {
      "epoch": 0.9281646695930715,
      "grad_norm": 0.013479224406182766,
      "learning_rate": 1.5963617189559717e-06,
      "loss": 0.0003,
      "step": 15647
    },
    {
      "epoch": 0.9282239886107486,
      "grad_norm": 19.847856521606445,
      "learning_rate": 1.595043501186396e-06,
      "loss": 0.7127,
      "step": 15648
    },
    {
      "epoch": 0.9282833076284257,
      "grad_norm": 2.3511221408843994,
      "learning_rate": 1.5937252834168207e-06,
      "loss": 0.0308,
      "step": 15649
    },
    {
      "epoch": 0.9283426266461028,
      "grad_norm": 0.020660214126110077,
      "learning_rate": 1.592407065647245e-06,
      "loss": 0.0003,
      "step": 15650
    },
    {
      "epoch": 0.9284019456637798,
      "grad_norm": 0.009623941965401173,
      "learning_rate": 1.5910888478776695e-06,
      "loss": 0.0002,
      "step": 15651
    },
    {
      "epoch": 0.9284612646814568,
      "grad_norm": 20.623241424560547,
      "learning_rate": 1.5897706301080939e-06,
      "loss": 0.462,
      "step": 15652
    },
    {
      "epoch": 0.9285205836991339,
      "grad_norm": 0.6191151142120361,
      "learning_rate": 1.5884524123385183e-06,
      "loss": 0.0049,
      "step": 15653
    },
    {
      "epoch": 0.928579902716811,
      "grad_norm": 7.401211738586426,
      "learning_rate": 1.5871341945689429e-06,
      "loss": 0.079,
      "step": 15654
    },
    {
      "epoch": 0.9286392217344881,
      "grad_norm": 6.327928066253662,
      "learning_rate": 1.5858159767993675e-06,
      "loss": 0.2056,
      "step": 15655
    },
    {
      "epoch": 0.9286985407521652,
      "grad_norm": 1.2361057996749878,
      "learning_rate": 1.584497759029792e-06,
      "loss": 0.0093,
      "step": 15656
    },
    {
      "epoch": 0.9287578597698423,
      "grad_norm": 0.1317448914051056,
      "learning_rate": 1.5831795412602163e-06,
      "loss": 0.0015,
      "step": 15657
    },
    {
      "epoch": 0.9288171787875192,
      "grad_norm": 5.181585311889648,
      "learning_rate": 1.5818613234906407e-06,
      "loss": 0.0599,
      "step": 15658
    },
    {
      "epoch": 0.9288764978051963,
      "grad_norm": 0.06422408670186996,
      "learning_rate": 1.580543105721065e-06,
      "loss": 0.001,
      "step": 15659
    },
    {
      "epoch": 0.9289358168228734,
      "grad_norm": 0.5769057869911194,
      "learning_rate": 1.5792248879514895e-06,
      "loss": 0.0091,
      "step": 15660
    },
    {
      "epoch": 0.9289951358405505,
      "grad_norm": 0.028610698878765106,
      "learning_rate": 1.5779066701819143e-06,
      "loss": 0.0007,
      "step": 15661
    },
    {
      "epoch": 0.9290544548582276,
      "grad_norm": 1.3786481618881226,
      "learning_rate": 1.5765884524123387e-06,
      "loss": 0.0139,
      "step": 15662
    },
    {
      "epoch": 0.9291137738759047,
      "grad_norm": 0.43439263105392456,
      "learning_rate": 1.5752702346427631e-06,
      "loss": 0.0044,
      "step": 15663
    },
    {
      "epoch": 0.9291730928935816,
      "grad_norm": 5.4799933433532715,
      "learning_rate": 1.5739520168731875e-06,
      "loss": 0.1938,
      "step": 15664
    },
    {
      "epoch": 0.9292324119112587,
      "grad_norm": 7.010033130645752,
      "learning_rate": 1.572633799103612e-06,
      "loss": 0.0815,
      "step": 15665
    },
    {
      "epoch": 0.9292917309289358,
      "grad_norm": 4.917458534240723,
      "learning_rate": 1.5713155813340363e-06,
      "loss": 0.0582,
      "step": 15666
    },
    {
      "epoch": 0.9293510499466129,
      "grad_norm": 0.09114165604114532,
      "learning_rate": 1.5699973635644611e-06,
      "loss": 0.0011,
      "step": 15667
    },
    {
      "epoch": 0.92941036896429,
      "grad_norm": 0.008142629638314247,
      "learning_rate": 1.5686791457948855e-06,
      "loss": 0.0001,
      "step": 15668
    },
    {
      "epoch": 0.929469687981967,
      "grad_norm": 19.709747314453125,
      "learning_rate": 1.56736092802531e-06,
      "loss": 0.6912,
      "step": 15669
    },
    {
      "epoch": 0.9295290069996441,
      "grad_norm": 0.0026538206730037928,
      "learning_rate": 1.5660427102557343e-06,
      "loss": 0.0001,
      "step": 15670
    },
    {
      "epoch": 0.9295883260173211,
      "grad_norm": 22.842628479003906,
      "learning_rate": 1.5647244924861587e-06,
      "loss": 1.2698,
      "step": 15671
    },
    {
      "epoch": 0.9296476450349982,
      "grad_norm": 7.0811591148376465,
      "learning_rate": 1.5634062747165831e-06,
      "loss": 0.1489,
      "step": 15672
    },
    {
      "epoch": 0.9297069640526753,
      "grad_norm": 11.943693161010742,
      "learning_rate": 1.562088056947008e-06,
      "loss": 0.0758,
      "step": 15673
    },
    {
      "epoch": 0.9297662830703524,
      "grad_norm": 0.017034467309713364,
      "learning_rate": 1.5607698391774323e-06,
      "loss": 0.0003,
      "step": 15674
    },
    {
      "epoch": 0.9298256020880294,
      "grad_norm": 0.20620565116405487,
      "learning_rate": 1.5594516214078567e-06,
      "loss": 0.0035,
      "step": 15675
    },
    {
      "epoch": 0.9298849211057065,
      "grad_norm": 12.987846374511719,
      "learning_rate": 1.5581334036382811e-06,
      "loss": 0.0736,
      "step": 15676
    },
    {
      "epoch": 0.9299442401233835,
      "grad_norm": 10.07801342010498,
      "learning_rate": 1.5568151858687055e-06,
      "loss": 0.3354,
      "step": 15677
    },
    {
      "epoch": 0.9300035591410606,
      "grad_norm": 1.7471592426300049,
      "learning_rate": 1.55549696809913e-06,
      "loss": 0.0158,
      "step": 15678
    },
    {
      "epoch": 0.9300628781587377,
      "grad_norm": 0.14295728504657745,
      "learning_rate": 1.5541787503295548e-06,
      "loss": 0.0021,
      "step": 15679
    },
    {
      "epoch": 0.9301221971764148,
      "grad_norm": 4.580138683319092,
      "learning_rate": 1.5528605325599792e-06,
      "loss": 0.0452,
      "step": 15680
    },
    {
      "epoch": 0.9301815161940918,
      "grad_norm": 0.0177024994045496,
      "learning_rate": 1.5515423147904036e-06,
      "loss": 0.0003,
      "step": 15681
    },
    {
      "epoch": 0.9302408352117689,
      "grad_norm": 4.653931140899658,
      "learning_rate": 1.550224097020828e-06,
      "loss": 0.0717,
      "step": 15682
    },
    {
      "epoch": 0.930300154229446,
      "grad_norm": 13.598736763000488,
      "learning_rate": 1.5489058792512524e-06,
      "loss": 0.1328,
      "step": 15683
    },
    {
      "epoch": 0.930359473247123,
      "grad_norm": 0.0769709125161171,
      "learning_rate": 1.5475876614816768e-06,
      "loss": 0.0012,
      "step": 15684
    },
    {
      "epoch": 0.9304187922648001,
      "grad_norm": 0.4386693835258484,
      "learning_rate": 1.5462694437121014e-06,
      "loss": 0.0053,
      "step": 15685
    },
    {
      "epoch": 0.9304781112824771,
      "grad_norm": 0.02647196128964424,
      "learning_rate": 1.544951225942526e-06,
      "loss": 0.0005,
      "step": 15686
    },
    {
      "epoch": 0.9305374303001542,
      "grad_norm": 0.17113900184631348,
      "learning_rate": 1.5436330081729504e-06,
      "loss": 0.0021,
      "step": 15687
    },
    {
      "epoch": 0.9305967493178313,
      "grad_norm": 4.619253635406494,
      "learning_rate": 1.5423147904033748e-06,
      "loss": 0.2093,
      "step": 15688
    },
    {
      "epoch": 0.9306560683355084,
      "grad_norm": 0.01785808429121971,
      "learning_rate": 1.5409965726337992e-06,
      "loss": 0.0003,
      "step": 15689
    },
    {
      "epoch": 0.9307153873531855,
      "grad_norm": 3.823434829711914,
      "learning_rate": 1.5396783548642236e-06,
      "loss": 0.0826,
      "step": 15690
    },
    {
      "epoch": 0.9307747063708625,
      "grad_norm": 9.3535737991333,
      "learning_rate": 1.5383601370946482e-06,
      "loss": 0.2676,
      "step": 15691
    },
    {
      "epoch": 0.9308340253885395,
      "grad_norm": 0.20865599811077118,
      "learning_rate": 1.5370419193250726e-06,
      "loss": 0.0036,
      "step": 15692
    },
    {
      "epoch": 0.9308933444062166,
      "grad_norm": 0.060429006814956665,
      "learning_rate": 1.5357237015554972e-06,
      "loss": 0.0012,
      "step": 15693
    },
    {
      "epoch": 0.9309526634238937,
      "grad_norm": 0.016460862010717392,
      "learning_rate": 1.5344054837859216e-06,
      "loss": 0.0001,
      "step": 15694
    },
    {
      "epoch": 0.9310119824415708,
      "grad_norm": 8.809017181396484,
      "learning_rate": 1.533087266016346e-06,
      "loss": 0.0534,
      "step": 15695
    },
    {
      "epoch": 0.9310713014592479,
      "grad_norm": 0.15711742639541626,
      "learning_rate": 1.5317690482467704e-06,
      "loss": 0.0023,
      "step": 15696
    },
    {
      "epoch": 0.9311306204769249,
      "grad_norm": 0.7259597182273865,
      "learning_rate": 1.530450830477195e-06,
      "loss": 0.01,
      "step": 15697
    },
    {
      "epoch": 0.9311899394946019,
      "grad_norm": 12.56486988067627,
      "learning_rate": 1.5291326127076194e-06,
      "loss": 0.0602,
      "step": 15698
    },
    {
      "epoch": 0.931249258512279,
      "grad_norm": 0.8021811842918396,
      "learning_rate": 1.5278143949380438e-06,
      "loss": 0.0132,
      "step": 15699
    },
    {
      "epoch": 0.9313085775299561,
      "grad_norm": 5.959918022155762,
      "learning_rate": 1.5264961771684684e-06,
      "loss": 0.2653,
      "step": 15700
    },
    {
      "epoch": 0.9313678965476332,
      "grad_norm": 0.8673830628395081,
      "learning_rate": 1.5251779593988928e-06,
      "loss": 0.007,
      "step": 15701
    },
    {
      "epoch": 0.9314272155653103,
      "grad_norm": 1.5392553806304932,
      "learning_rate": 1.5238597416293172e-06,
      "loss": 0.0151,
      "step": 15702
    },
    {
      "epoch": 0.9314865345829874,
      "grad_norm": 0.012562807649374008,
      "learning_rate": 1.5225415238597418e-06,
      "loss": 0.0003,
      "step": 15703
    },
    {
      "epoch": 0.9315458536006643,
      "grad_norm": 6.247111797332764,
      "learning_rate": 1.5212233060901662e-06,
      "loss": 0.6166,
      "step": 15704
    },
    {
      "epoch": 0.9316051726183414,
      "grad_norm": 0.025648601353168488,
      "learning_rate": 1.5199050883205906e-06,
      "loss": 0.0007,
      "step": 15705
    },
    {
      "epoch": 0.9316644916360185,
      "grad_norm": 22.697420120239258,
      "learning_rate": 1.518586870551015e-06,
      "loss": 0.1715,
      "step": 15706
    },
    {
      "epoch": 0.9317238106536956,
      "grad_norm": 9.314913749694824,
      "learning_rate": 1.5172686527814396e-06,
      "loss": 0.1057,
      "step": 15707
    },
    {
      "epoch": 0.9317831296713727,
      "grad_norm": 0.23654741048812866,
      "learning_rate": 1.515950435011864e-06,
      "loss": 0.0008,
      "step": 15708
    },
    {
      "epoch": 0.9318424486890498,
      "grad_norm": 0.7732269167900085,
      "learning_rate": 1.5146322172422886e-06,
      "loss": 0.006,
      "step": 15709
    },
    {
      "epoch": 0.9319017677067267,
      "grad_norm": 0.8272344470024109,
      "learning_rate": 1.513313999472713e-06,
      "loss": 0.0124,
      "step": 15710
    },
    {
      "epoch": 0.9319610867244038,
      "grad_norm": 20.525283813476562,
      "learning_rate": 1.5119957817031374e-06,
      "loss": 0.0718,
      "step": 15711
    },
    {
      "epoch": 0.9320204057420809,
      "grad_norm": 0.1327141523361206,
      "learning_rate": 1.5106775639335618e-06,
      "loss": 0.0015,
      "step": 15712
    },
    {
      "epoch": 0.932079724759758,
      "grad_norm": 26.23468017578125,
      "learning_rate": 1.5093593461639862e-06,
      "loss": 1.1202,
      "step": 15713
    },
    {
      "epoch": 0.9321390437774351,
      "grad_norm": 0.10922354459762573,
      "learning_rate": 1.5080411283944108e-06,
      "loss": 0.0012,
      "step": 15714
    },
    {
      "epoch": 0.9321983627951121,
      "grad_norm": 4.086476802825928,
      "learning_rate": 1.5067229106248355e-06,
      "loss": 0.2921,
      "step": 15715
    },
    {
      "epoch": 0.9322576818127892,
      "grad_norm": 0.7472602128982544,
      "learning_rate": 1.5054046928552599e-06,
      "loss": 0.009,
      "step": 15716
    },
    {
      "epoch": 0.9323170008304662,
      "grad_norm": 0.007601828780025244,
      "learning_rate": 1.5040864750856843e-06,
      "loss": 0.0002,
      "step": 15717
    },
    {
      "epoch": 0.9323763198481433,
      "grad_norm": 2.664425849914551,
      "learning_rate": 1.5027682573161087e-06,
      "loss": 0.0443,
      "step": 15718
    },
    {
      "epoch": 0.9324356388658204,
      "grad_norm": 25.119539260864258,
      "learning_rate": 1.501450039546533e-06,
      "loss": 0.479,
      "step": 15719
    },
    {
      "epoch": 0.9324949578834975,
      "grad_norm": 8.215121269226074,
      "learning_rate": 1.5001318217769574e-06,
      "loss": 0.1893,
      "step": 15720
    },
    {
      "epoch": 0.9325542769011745,
      "grad_norm": 0.09709753096103668,
      "learning_rate": 1.4988136040073823e-06,
      "loss": 0.0013,
      "step": 15721
    },
    {
      "epoch": 0.9326135959188516,
      "grad_norm": 2.708615303039551,
      "learning_rate": 1.4974953862378067e-06,
      "loss": 0.0185,
      "step": 15722
    },
    {
      "epoch": 0.9326729149365286,
      "grad_norm": 0.05433126538991928,
      "learning_rate": 1.496177168468231e-06,
      "loss": 0.0006,
      "step": 15723
    },
    {
      "epoch": 0.9327322339542057,
      "grad_norm": 0.019915949553251266,
      "learning_rate": 1.4948589506986555e-06,
      "loss": 0.0005,
      "step": 15724
    },
    {
      "epoch": 0.9327915529718828,
      "grad_norm": 0.38725563883781433,
      "learning_rate": 1.4935407329290799e-06,
      "loss": 0.0018,
      "step": 15725
    },
    {
      "epoch": 0.9328508719895598,
      "grad_norm": 0.15890072286128998,
      "learning_rate": 1.4922225151595043e-06,
      "loss": 0.0016,
      "step": 15726
    },
    {
      "epoch": 0.9329101910072369,
      "grad_norm": 23.886768341064453,
      "learning_rate": 1.490904297389929e-06,
      "loss": 0.3524,
      "step": 15727
    },
    {
      "epoch": 0.932969510024914,
      "grad_norm": 0.08157383650541306,
      "learning_rate": 1.4895860796203535e-06,
      "loss": 0.001,
      "step": 15728
    },
    {
      "epoch": 0.9330288290425911,
      "grad_norm": 5.725703239440918,
      "learning_rate": 1.4882678618507779e-06,
      "loss": 0.0667,
      "step": 15729
    },
    {
      "epoch": 0.9330881480602681,
      "grad_norm": 0.7324819564819336,
      "learning_rate": 1.4869496440812023e-06,
      "loss": 0.0053,
      "step": 15730
    },
    {
      "epoch": 0.9331474670779452,
      "grad_norm": 0.7915191054344177,
      "learning_rate": 1.4856314263116267e-06,
      "loss": 0.0065,
      "step": 15731
    },
    {
      "epoch": 0.9332067860956222,
      "grad_norm": 49.996910095214844,
      "learning_rate": 1.484313208542051e-06,
      "loss": 0.1116,
      "step": 15732
    },
    {
      "epoch": 0.9332661051132993,
      "grad_norm": 10.946091651916504,
      "learning_rate": 1.482994990772476e-06,
      "loss": 0.2513,
      "step": 15733
    },
    {
      "epoch": 0.9333254241309764,
      "grad_norm": 3.7110114097595215,
      "learning_rate": 1.4816767730029003e-06,
      "loss": 0.0427,
      "step": 15734
    },
    {
      "epoch": 0.9333847431486535,
      "grad_norm": 0.18606141209602356,
      "learning_rate": 1.4803585552333247e-06,
      "loss": 0.0042,
      "step": 15735
    },
    {
      "epoch": 0.9334440621663306,
      "grad_norm": 0.00968228094279766,
      "learning_rate": 1.479040337463749e-06,
      "loss": 0.0003,
      "step": 15736
    },
    {
      "epoch": 0.9335033811840076,
      "grad_norm": 33.01404571533203,
      "learning_rate": 1.4777221196941735e-06,
      "loss": 0.7892,
      "step": 15737
    },
    {
      "epoch": 0.9335627002016846,
      "grad_norm": 0.007497456390410662,
      "learning_rate": 1.476403901924598e-06,
      "loss": 0.0003,
      "step": 15738
    },
    {
      "epoch": 0.9336220192193617,
      "grad_norm": 22.086353302001953,
      "learning_rate": 1.4750856841550227e-06,
      "loss": 0.7515,
      "step": 15739
    },
    {
      "epoch": 0.9336813382370388,
      "grad_norm": 0.03177988901734352,
      "learning_rate": 1.4737674663854471e-06,
      "loss": 0.0007,
      "step": 15740
    },
    {
      "epoch": 0.9337406572547159,
      "grad_norm": 10.831085205078125,
      "learning_rate": 1.4724492486158715e-06,
      "loss": 0.0512,
      "step": 15741
    },
    {
      "epoch": 0.933799976272393,
      "grad_norm": 2.221245050430298,
      "learning_rate": 1.471131030846296e-06,
      "loss": 0.0139,
      "step": 15742
    },
    {
      "epoch": 0.93385929529007,
      "grad_norm": 0.006875758524984121,
      "learning_rate": 1.4698128130767203e-06,
      "loss": 0.0002,
      "step": 15743
    },
    {
      "epoch": 0.933918614307747,
      "grad_norm": 18.565824508666992,
      "learning_rate": 1.468494595307145e-06,
      "loss": 1.0169,
      "step": 15744
    },
    {
      "epoch": 0.9339779333254241,
      "grad_norm": 6.9506096839904785,
      "learning_rate": 1.4671763775375693e-06,
      "loss": 0.0598,
      "step": 15745
    },
    {
      "epoch": 0.9340372523431012,
      "grad_norm": 0.10709651559591293,
      "learning_rate": 1.465858159767994e-06,
      "loss": 0.0009,
      "step": 15746
    },
    {
      "epoch": 0.9340965713607783,
      "grad_norm": 0.03423496335744858,
      "learning_rate": 1.4645399419984183e-06,
      "loss": 0.0006,
      "step": 15747
    },
    {
      "epoch": 0.9341558903784554,
      "grad_norm": 18.69034194946289,
      "learning_rate": 1.4632217242288427e-06,
      "loss": 0.2947,
      "step": 15748
    },
    {
      "epoch": 0.9342152093961325,
      "grad_norm": 2.0188024044036865,
      "learning_rate": 1.4619035064592671e-06,
      "loss": 0.0305,
      "step": 15749
    },
    {
      "epoch": 0.9342745284138094,
      "grad_norm": 0.05235305428504944,
      "learning_rate": 1.4605852886896917e-06,
      "loss": 0.0006,
      "step": 15750
    },
    {
      "epoch": 0.9343338474314865,
      "grad_norm": 8.265420913696289,
      "learning_rate": 1.4592670709201161e-06,
      "loss": 0.3235,
      "step": 15751
    },
    {
      "epoch": 0.9343931664491636,
      "grad_norm": 16.16039276123047,
      "learning_rate": 1.4579488531505405e-06,
      "loss": 0.1612,
      "step": 15752
    },
    {
      "epoch": 0.9344524854668407,
      "grad_norm": 5.8165130615234375,
      "learning_rate": 1.4566306353809652e-06,
      "loss": 0.1409,
      "step": 15753
    },
    {
      "epoch": 0.9345118044845178,
      "grad_norm": 0.5311610698699951,
      "learning_rate": 1.4553124176113896e-06,
      "loss": 0.0048,
      "step": 15754
    },
    {
      "epoch": 0.9345711235021948,
      "grad_norm": 0.9568615555763245,
      "learning_rate": 1.453994199841814e-06,
      "loss": 0.0129,
      "step": 15755
    },
    {
      "epoch": 0.9346304425198718,
      "grad_norm": 8.36351203918457,
      "learning_rate": 1.4526759820722386e-06,
      "loss": 0.0569,
      "step": 15756
    },
    {
      "epoch": 0.9346897615375489,
      "grad_norm": 18.10350799560547,
      "learning_rate": 1.451357764302663e-06,
      "loss": 0.2502,
      "step": 15757
    },
    {
      "epoch": 0.934749080555226,
      "grad_norm": 0.24380552768707275,
      "learning_rate": 1.4500395465330874e-06,
      "loss": 0.0036,
      "step": 15758
    },
    {
      "epoch": 0.9348083995729031,
      "grad_norm": 8.855100631713867,
      "learning_rate": 1.4487213287635118e-06,
      "loss": 0.3059,
      "step": 15759
    },
    {
      "epoch": 0.9348677185905802,
      "grad_norm": 0.022717341780662537,
      "learning_rate": 1.4474031109939364e-06,
      "loss": 0.0002,
      "step": 15760
    },
    {
      "epoch": 0.9349270376082572,
      "grad_norm": 48.29875564575195,
      "learning_rate": 1.4460848932243608e-06,
      "loss": 0.4525,
      "step": 15761
    },
    {
      "epoch": 0.9349863566259343,
      "grad_norm": 0.03645779937505722,
      "learning_rate": 1.4447666754547854e-06,
      "loss": 0.0006,
      "step": 15762
    },
    {
      "epoch": 0.9350456756436113,
      "grad_norm": 15.61771011352539,
      "learning_rate": 1.4434484576852098e-06,
      "loss": 0.145,
      "step": 15763
    },
    {
      "epoch": 0.9351049946612884,
      "grad_norm": 0.1399378776550293,
      "learning_rate": 1.4421302399156342e-06,
      "loss": 0.0012,
      "step": 15764
    },
    {
      "epoch": 0.9351643136789655,
      "grad_norm": 1.2512972354888916,
      "learning_rate": 1.4408120221460586e-06,
      "loss": 0.0033,
      "step": 15765
    },
    {
      "epoch": 0.9352236326966425,
      "grad_norm": 16.958436965942383,
      "learning_rate": 1.439493804376483e-06,
      "loss": 0.4757,
      "step": 15766
    },
    {
      "epoch": 0.9352829517143196,
      "grad_norm": 0.4996979534626007,
      "learning_rate": 1.4381755866069076e-06,
      "loss": 0.0053,
      "step": 15767
    },
    {
      "epoch": 0.9353422707319967,
      "grad_norm": 0.2250029742717743,
      "learning_rate": 1.4368573688373322e-06,
      "loss": 0.0025,
      "step": 15768
    },
    {
      "epoch": 0.9354015897496738,
      "grad_norm": 11.203995704650879,
      "learning_rate": 1.4355391510677566e-06,
      "loss": 1.3715,
      "step": 15769
    },
    {
      "epoch": 0.9354609087673508,
      "grad_norm": 0.06707540154457092,
      "learning_rate": 1.434220933298181e-06,
      "loss": 0.0002,
      "step": 15770
    },
    {
      "epoch": 0.9355202277850279,
      "grad_norm": 1.6440402269363403,
      "learning_rate": 1.4329027155286054e-06,
      "loss": 0.0066,
      "step": 15771
    },
    {
      "epoch": 0.9355795468027049,
      "grad_norm": 0.028326096013188362,
      "learning_rate": 1.4315844977590298e-06,
      "loss": 0.0007,
      "step": 15772
    },
    {
      "epoch": 0.935638865820382,
      "grad_norm": 2.7388522624969482,
      "learning_rate": 1.4302662799894542e-06,
      "loss": 0.0242,
      "step": 15773
    },
    {
      "epoch": 0.9356981848380591,
      "grad_norm": 21.32570457458496,
      "learning_rate": 1.428948062219879e-06,
      "loss": 0.3721,
      "step": 15774
    },
    {
      "epoch": 0.9357575038557362,
      "grad_norm": 2.722442626953125,
      "learning_rate": 1.4276298444503034e-06,
      "loss": 0.0157,
      "step": 15775
    },
    {
      "epoch": 0.9358168228734132,
      "grad_norm": 0.17374709248542786,
      "learning_rate": 1.4263116266807278e-06,
      "loss": 0.0017,
      "step": 15776
    },
    {
      "epoch": 0.9358761418910903,
      "grad_norm": 0.0072937533259391785,
      "learning_rate": 1.4249934089111522e-06,
      "loss": 0.0002,
      "step": 15777
    },
    {
      "epoch": 0.9359354609087673,
      "grad_norm": 0.013139808550477028,
      "learning_rate": 1.4236751911415766e-06,
      "loss": 0.0003,
      "step": 15778
    },
    {
      "epoch": 0.9359947799264444,
      "grad_norm": 0.07970549166202545,
      "learning_rate": 1.422356973372001e-06,
      "loss": 0.0009,
      "step": 15779
    },
    {
      "epoch": 0.9360540989441215,
      "grad_norm": 0.011478442698717117,
      "learning_rate": 1.4210387556024258e-06,
      "loss": 0.0004,
      "step": 15780
    },
    {
      "epoch": 0.9361134179617986,
      "grad_norm": 10.432838439941406,
      "learning_rate": 1.4197205378328502e-06,
      "loss": 0.3991,
      "step": 15781
    },
    {
      "epoch": 0.9361727369794757,
      "grad_norm": 1.572012186050415,
      "learning_rate": 1.4184023200632746e-06,
      "loss": 0.0404,
      "step": 15782
    },
    {
      "epoch": 0.9362320559971526,
      "grad_norm": 4.678531169891357,
      "learning_rate": 1.417084102293699e-06,
      "loss": 0.0339,
      "step": 15783
    },
    {
      "epoch": 0.9362913750148297,
      "grad_norm": 16.634056091308594,
      "learning_rate": 1.4157658845241234e-06,
      "loss": 0.3252,
      "step": 15784
    },
    {
      "epoch": 0.9363506940325068,
      "grad_norm": 7.827529430389404,
      "learning_rate": 1.4144476667545478e-06,
      "loss": 0.1294,
      "step": 15785
    },
    {
      "epoch": 0.9364100130501839,
      "grad_norm": 0.32740068435668945,
      "learning_rate": 1.4131294489849726e-06,
      "loss": 0.006,
      "step": 15786
    },
    {
      "epoch": 0.936469332067861,
      "grad_norm": 0.13158273696899414,
      "learning_rate": 1.411811231215397e-06,
      "loss": 0.0012,
      "step": 15787
    },
    {
      "epoch": 0.9365286510855381,
      "grad_norm": 4.457107067108154,
      "learning_rate": 1.4104930134458214e-06,
      "loss": 0.0527,
      "step": 15788
    },
    {
      "epoch": 0.936587970103215,
      "grad_norm": 0.3018842339515686,
      "learning_rate": 1.4091747956762458e-06,
      "loss": 0.0033,
      "step": 15789
    },
    {
      "epoch": 0.9366472891208921,
      "grad_norm": 0.1632593423128128,
      "learning_rate": 1.4078565779066702e-06,
      "loss": 0.002,
      "step": 15790
    },
    {
      "epoch": 0.9367066081385692,
      "grad_norm": 0.05912545695900917,
      "learning_rate": 1.4065383601370946e-06,
      "loss": 0.0009,
      "step": 15791
    },
    {
      "epoch": 0.9367659271562463,
      "grad_norm": 0.5163523554801941,
      "learning_rate": 1.4052201423675195e-06,
      "loss": 0.006,
      "step": 15792
    },
    {
      "epoch": 0.9368252461739234,
      "grad_norm": 0.019642751663923264,
      "learning_rate": 1.4039019245979439e-06,
      "loss": 0.0005,
      "step": 15793
    },
    {
      "epoch": 0.9368845651916005,
      "grad_norm": 1.6605695486068726,
      "learning_rate": 1.4025837068283683e-06,
      "loss": 0.0138,
      "step": 15794
    },
    {
      "epoch": 0.9369438842092775,
      "grad_norm": 8.959746360778809,
      "learning_rate": 1.4012654890587927e-06,
      "loss": 0.1964,
      "step": 15795
    },
    {
      "epoch": 0.9370032032269545,
      "grad_norm": 10.413305282592773,
      "learning_rate": 1.399947271289217e-06,
      "loss": 0.4706,
      "step": 15796
    },
    {
      "epoch": 0.9370625222446316,
      "grad_norm": 0.028599396347999573,
      "learning_rate": 1.3986290535196415e-06,
      "loss": 0.0005,
      "step": 15797
    },
    {
      "epoch": 0.9371218412623087,
      "grad_norm": 4.951859474182129,
      "learning_rate": 1.397310835750066e-06,
      "loss": 0.2212,
      "step": 15798
    },
    {
      "epoch": 0.9371811602799858,
      "grad_norm": 51.310462951660156,
      "learning_rate": 1.3959926179804907e-06,
      "loss": 0.7063,
      "step": 15799
    },
    {
      "epoch": 0.9372404792976629,
      "grad_norm": 0.010523565113544464,
      "learning_rate": 1.394674400210915e-06,
      "loss": 0.0003,
      "step": 15800
    },
    {
      "epoch": 0.9372997983153399,
      "grad_norm": 0.031160613521933556,
      "learning_rate": 1.3933561824413395e-06,
      "loss": 0.0006,
      "step": 15801
    },
    {
      "epoch": 0.9373591173330169,
      "grad_norm": 20.517192840576172,
      "learning_rate": 1.3920379646717639e-06,
      "loss": 0.2045,
      "step": 15802
    },
    {
      "epoch": 0.937418436350694,
      "grad_norm": 0.05339377000927925,
      "learning_rate": 1.3907197469021883e-06,
      "loss": 0.0006,
      "step": 15803
    },
    {
      "epoch": 0.9374777553683711,
      "grad_norm": 9.276525497436523,
      "learning_rate": 1.3894015291326129e-06,
      "loss": 0.1156,
      "step": 15804
    },
    {
      "epoch": 0.9375370743860482,
      "grad_norm": 0.005717633292078972,
      "learning_rate": 1.3880833113630373e-06,
      "loss": 0.0002,
      "step": 15805
    },
    {
      "epoch": 0.9375963934037252,
      "grad_norm": 0.04355550929903984,
      "learning_rate": 1.3867650935934619e-06,
      "loss": 0.0006,
      "step": 15806
    },
    {
      "epoch": 0.9376557124214023,
      "grad_norm": 0.011049903929233551,
      "learning_rate": 1.3854468758238863e-06,
      "loss": 0.0005,
      "step": 15807
    },
    {
      "epoch": 0.9377150314390794,
      "grad_norm": 23.33757781982422,
      "learning_rate": 1.3841286580543107e-06,
      "loss": 1.1985,
      "step": 15808
    },
    {
      "epoch": 0.9377743504567564,
      "grad_norm": 1.375985026359558,
      "learning_rate": 1.382810440284735e-06,
      "loss": 0.012,
      "step": 15809
    },
    {
      "epoch": 0.9378336694744335,
      "grad_norm": 3.4723143577575684,
      "learning_rate": 1.3814922225151597e-06,
      "loss": 0.0181,
      "step": 15810
    },
    {
      "epoch": 0.9378929884921106,
      "grad_norm": 11.363311767578125,
      "learning_rate": 1.380174004745584e-06,
      "loss": 0.1792,
      "step": 15811
    },
    {
      "epoch": 0.9379523075097876,
      "grad_norm": 25.19193458557129,
      "learning_rate": 1.3788557869760085e-06,
      "loss": 0.2189,
      "step": 15812
    },
    {
      "epoch": 0.9380116265274647,
      "grad_norm": 22.196950912475586,
      "learning_rate": 1.377537569206433e-06,
      "loss": 0.701,
      "step": 15813
    },
    {
      "epoch": 0.9380709455451418,
      "grad_norm": 0.028895433992147446,
      "learning_rate": 1.3762193514368575e-06,
      "loss": 0.0006,
      "step": 15814
    },
    {
      "epoch": 0.9381302645628189,
      "grad_norm": 1.3651807308197021,
      "learning_rate": 1.374901133667282e-06,
      "loss": 0.0122,
      "step": 15815
    },
    {
      "epoch": 0.9381895835804959,
      "grad_norm": 1.4515256881713867,
      "learning_rate": 1.3735829158977065e-06,
      "loss": 0.0176,
      "step": 15816
    },
    {
      "epoch": 0.938248902598173,
      "grad_norm": 4.115909576416016,
      "learning_rate": 1.372264698128131e-06,
      "loss": 0.0175,
      "step": 15817
    },
    {
      "epoch": 0.93830822161585,
      "grad_norm": 1.5436058044433594,
      "learning_rate": 1.3709464803585553e-06,
      "loss": 0.0203,
      "step": 15818
    },
    {
      "epoch": 0.9383675406335271,
      "grad_norm": 0.23563426733016968,
      "learning_rate": 1.3696282625889797e-06,
      "loss": 0.0034,
      "step": 15819
    },
    {
      "epoch": 0.9384268596512042,
      "grad_norm": 23.83773422241211,
      "learning_rate": 1.3683100448194041e-06,
      "loss": 0.1856,
      "step": 15820
    },
    {
      "epoch": 0.9384861786688813,
      "grad_norm": 0.0066976724192500114,
      "learning_rate": 1.3669918270498287e-06,
      "loss": 0.0001,
      "step": 15821
    },
    {
      "epoch": 0.9385454976865583,
      "grad_norm": 1.0531892776489258,
      "learning_rate": 1.3656736092802533e-06,
      "loss": 0.0211,
      "step": 15822
    },
    {
      "epoch": 0.9386048167042353,
      "grad_norm": 8.546732902526855,
      "learning_rate": 1.3643553915106777e-06,
      "loss": 0.0946,
      "step": 15823
    },
    {
      "epoch": 0.9386641357219124,
      "grad_norm": 4.097128868103027,
      "learning_rate": 1.3630371737411021e-06,
      "loss": 0.0689,
      "step": 15824
    },
    {
      "epoch": 0.9387234547395895,
      "grad_norm": 5.783756256103516,
      "learning_rate": 1.3617189559715265e-06,
      "loss": 0.0804,
      "step": 15825
    },
    {
      "epoch": 0.9387827737572666,
      "grad_norm": 5.346340179443359,
      "learning_rate": 1.360400738201951e-06,
      "loss": 0.2171,
      "step": 15826
    },
    {
      "epoch": 0.9388420927749437,
      "grad_norm": 0.005135175306349993,
      "learning_rate": 1.3590825204323753e-06,
      "loss": 0.0001,
      "step": 15827
    },
    {
      "epoch": 0.9389014117926208,
      "grad_norm": 0.26856306195259094,
      "learning_rate": 1.3577643026628001e-06,
      "loss": 0.0025,
      "step": 15828
    },
    {
      "epoch": 0.9389607308102977,
      "grad_norm": 53.8115119934082,
      "learning_rate": 1.3564460848932245e-06,
      "loss": 1.1593,
      "step": 15829
    },
    {
      "epoch": 0.9390200498279748,
      "grad_norm": 3.0815224647521973,
      "learning_rate": 1.355127867123649e-06,
      "loss": 0.0102,
      "step": 15830
    },
    {
      "epoch": 0.9390793688456519,
      "grad_norm": 4.932702541351318,
      "learning_rate": 1.3538096493540733e-06,
      "loss": 0.1115,
      "step": 15831
    },
    {
      "epoch": 0.939138687863329,
      "grad_norm": 0.05021677538752556,
      "learning_rate": 1.3524914315844977e-06,
      "loss": 0.001,
      "step": 15832
    },
    {
      "epoch": 0.9391980068810061,
      "grad_norm": 0.047686897218227386,
      "learning_rate": 1.3511732138149221e-06,
      "loss": 0.0008,
      "step": 15833
    },
    {
      "epoch": 0.9392573258986832,
      "grad_norm": 1.1393667459487915,
      "learning_rate": 1.349854996045347e-06,
      "loss": 0.0093,
      "step": 15834
    },
    {
      "epoch": 0.9393166449163601,
      "grad_norm": 9.238192558288574,
      "learning_rate": 1.3485367782757714e-06,
      "loss": 0.5358,
      "step": 15835
    },
    {
      "epoch": 0.9393759639340372,
      "grad_norm": 18.500778198242188,
      "learning_rate": 1.3472185605061958e-06,
      "loss": 0.2789,
      "step": 15836
    },
    {
      "epoch": 0.9394352829517143,
      "grad_norm": 0.579762876033783,
      "learning_rate": 1.3459003427366202e-06,
      "loss": 0.0045,
      "step": 15837
    },
    {
      "epoch": 0.9394946019693914,
      "grad_norm": 0.06663946807384491,
      "learning_rate": 1.3445821249670446e-06,
      "loss": 0.001,
      "step": 15838
    },
    {
      "epoch": 0.9395539209870685,
      "grad_norm": 9.151900291442871,
      "learning_rate": 1.343263907197469e-06,
      "loss": 0.1121,
      "step": 15839
    },
    {
      "epoch": 0.9396132400047456,
      "grad_norm": 0.1382063627243042,
      "learning_rate": 1.3419456894278938e-06,
      "loss": 0.0012,
      "step": 15840
    },
    {
      "epoch": 0.9396725590224226,
      "grad_norm": 6.60920524597168,
      "learning_rate": 1.3406274716583182e-06,
      "loss": 0.065,
      "step": 15841
    },
    {
      "epoch": 0.9397318780400996,
      "grad_norm": 6.800741195678711,
      "learning_rate": 1.3393092538887426e-06,
      "loss": 0.1401,
      "step": 15842
    },
    {
      "epoch": 0.9397911970577767,
      "grad_norm": 0.04019227996468544,
      "learning_rate": 1.337991036119167e-06,
      "loss": 0.0008,
      "step": 15843
    },
    {
      "epoch": 0.9398505160754538,
      "grad_norm": 0.019025852903723717,
      "learning_rate": 1.3366728183495914e-06,
      "loss": 0.0005,
      "step": 15844
    },
    {
      "epoch": 0.9399098350931309,
      "grad_norm": 4.012974262237549,
      "learning_rate": 1.3353546005800158e-06,
      "loss": 0.0248,
      "step": 15845
    },
    {
      "epoch": 0.939969154110808,
      "grad_norm": 0.009926014579832554,
      "learning_rate": 1.3340363828104406e-06,
      "loss": 0.0003,
      "step": 15846
    },
    {
      "epoch": 0.940028473128485,
      "grad_norm": 5.243889331817627,
      "learning_rate": 1.332718165040865e-06,
      "loss": 0.3868,
      "step": 15847
    },
    {
      "epoch": 0.940087792146162,
      "grad_norm": 4.811774253845215,
      "learning_rate": 1.3313999472712894e-06,
      "loss": 0.0496,
      "step": 15848
    },
    {
      "epoch": 0.9401471111638391,
      "grad_norm": 0.039986371994018555,
      "learning_rate": 1.3300817295017138e-06,
      "loss": 0.001,
      "step": 15849
    },
    {
      "epoch": 0.9402064301815162,
      "grad_norm": 0.018093382939696312,
      "learning_rate": 1.3287635117321382e-06,
      "loss": 0.0003,
      "step": 15850
    },
    {
      "epoch": 0.9402657491991933,
      "grad_norm": 0.7254278063774109,
      "learning_rate": 1.3274452939625626e-06,
      "loss": 0.0113,
      "step": 15851
    },
    {
      "epoch": 0.9403250682168703,
      "grad_norm": 3.7542176246643066,
      "learning_rate": 1.3261270761929872e-06,
      "loss": 0.0974,
      "step": 15852
    },
    {
      "epoch": 0.9403843872345474,
      "grad_norm": 9.794119834899902,
      "learning_rate": 1.3248088584234118e-06,
      "loss": 0.2207,
      "step": 15853
    },
    {
      "epoch": 0.9404437062522245,
      "grad_norm": 0.02235720120370388,
      "learning_rate": 1.3234906406538362e-06,
      "loss": 0.0003,
      "step": 15854
    },
    {
      "epoch": 0.9405030252699015,
      "grad_norm": 0.6015721559524536,
      "learning_rate": 1.3221724228842606e-06,
      "loss": 0.005,
      "step": 15855
    },
    {
      "epoch": 0.9405623442875786,
      "grad_norm": 2.936528205871582,
      "learning_rate": 1.320854205114685e-06,
      "loss": 0.0638,
      "step": 15856
    },
    {
      "epoch": 0.9406216633052557,
      "grad_norm": 1.2592487335205078,
      "learning_rate": 1.3195359873451094e-06,
      "loss": 0.0044,
      "step": 15857
    },
    {
      "epoch": 0.9406809823229327,
      "grad_norm": 0.0820602998137474,
      "learning_rate": 1.318217769575534e-06,
      "loss": 0.001,
      "step": 15858
    },
    {
      "epoch": 0.9407403013406098,
      "grad_norm": 0.24529443681240082,
      "learning_rate": 1.3168995518059584e-06,
      "loss": 0.003,
      "step": 15859
    },
    {
      "epoch": 0.9407996203582869,
      "grad_norm": 0.008550894446671009,
      "learning_rate": 1.315581334036383e-06,
      "loss": 0.0003,
      "step": 15860
    },
    {
      "epoch": 0.940858939375964,
      "grad_norm": 0.4602685570716858,
      "learning_rate": 1.3142631162668074e-06,
      "loss": 0.0036,
      "step": 15861
    },
    {
      "epoch": 0.940918258393641,
      "grad_norm": 0.013444580137729645,
      "learning_rate": 1.3129448984972318e-06,
      "loss": 0.0003,
      "step": 15862
    },
    {
      "epoch": 0.940977577411318,
      "grad_norm": 8.922083854675293,
      "learning_rate": 1.3116266807276562e-06,
      "loss": 0.1046,
      "step": 15863
    },
    {
      "epoch": 0.9410368964289951,
      "grad_norm": 0.00345497764647007,
      "learning_rate": 1.3103084629580808e-06,
      "loss": 0.0001,
      "step": 15864
    },
    {
      "epoch": 0.9410962154466722,
      "grad_norm": 0.10022702813148499,
      "learning_rate": 1.3089902451885052e-06,
      "loss": 0.0012,
      "step": 15865
    },
    {
      "epoch": 0.9411555344643493,
      "grad_norm": 0.6755108833312988,
      "learning_rate": 1.3076720274189296e-06,
      "loss": 0.0093,
      "step": 15866
    },
    {
      "epoch": 0.9412148534820264,
      "grad_norm": 0.05035461485385895,
      "learning_rate": 1.3063538096493542e-06,
      "loss": 0.001,
      "step": 15867
    },
    {
      "epoch": 0.9412741724997034,
      "grad_norm": 0.061973486095666885,
      "learning_rate": 1.3050355918797786e-06,
      "loss": 0.0008,
      "step": 15868
    },
    {
      "epoch": 0.9413334915173804,
      "grad_norm": 0.02280505746603012,
      "learning_rate": 1.303717374110203e-06,
      "loss": 0.0003,
      "step": 15869
    },
    {
      "epoch": 0.9413928105350575,
      "grad_norm": 0.047655005007982254,
      "learning_rate": 1.3023991563406277e-06,
      "loss": 0.0007,
      "step": 15870
    },
    {
      "epoch": 0.9414521295527346,
      "grad_norm": 1.774397611618042,
      "learning_rate": 1.301080938571052e-06,
      "loss": 0.0176,
      "step": 15871
    },
    {
      "epoch": 0.9415114485704117,
      "grad_norm": 49.28373336791992,
      "learning_rate": 1.2997627208014765e-06,
      "loss": 0.6519,
      "step": 15872
    },
    {
      "epoch": 0.9415707675880888,
      "grad_norm": 32.5615348815918,
      "learning_rate": 1.2984445030319009e-06,
      "loss": 0.4251,
      "step": 15873
    },
    {
      "epoch": 0.9416300866057659,
      "grad_norm": 0.49249905347824097,
      "learning_rate": 1.2971262852623255e-06,
      "loss": 0.0048,
      "step": 15874
    },
    {
      "epoch": 0.9416894056234428,
      "grad_norm": 0.16521209478378296,
      "learning_rate": 1.2958080674927499e-06,
      "loss": 0.0021,
      "step": 15875
    },
    {
      "epoch": 0.9417487246411199,
      "grad_norm": 0.3191063106060028,
      "learning_rate": 1.2944898497231745e-06,
      "loss": 0.004,
      "step": 15876
    },
    {
      "epoch": 0.941808043658797,
      "grad_norm": 9.664393424987793,
      "learning_rate": 1.2931716319535989e-06,
      "loss": 0.6775,
      "step": 15877
    },
    {
      "epoch": 0.9418673626764741,
      "grad_norm": 8.72431755065918,
      "learning_rate": 1.2918534141840233e-06,
      "loss": 0.0503,
      "step": 15878
    },
    {
      "epoch": 0.9419266816941512,
      "grad_norm": 14.35499382019043,
      "learning_rate": 1.2905351964144477e-06,
      "loss": 0.2749,
      "step": 15879
    },
    {
      "epoch": 0.9419860007118283,
      "grad_norm": 0.6686307191848755,
      "learning_rate": 1.289216978644872e-06,
      "loss": 0.0055,
      "step": 15880
    },
    {
      "epoch": 0.9420453197295052,
      "grad_norm": 0.040330469608306885,
      "learning_rate": 1.2878987608752967e-06,
      "loss": 0.0007,
      "step": 15881
    },
    {
      "epoch": 0.9421046387471823,
      "grad_norm": 0.3706994652748108,
      "learning_rate": 1.2865805431057213e-06,
      "loss": 0.004,
      "step": 15882
    },
    {
      "epoch": 0.9421639577648594,
      "grad_norm": 2.438021183013916,
      "learning_rate": 1.2852623253361457e-06,
      "loss": 0.1111,
      "step": 15883
    },
    {
      "epoch": 0.9422232767825365,
      "grad_norm": 20.174560546875,
      "learning_rate": 1.28394410756657e-06,
      "loss": 0.2623,
      "step": 15884
    },
    {
      "epoch": 0.9422825958002136,
      "grad_norm": 1.4940056800842285,
      "learning_rate": 1.2826258897969945e-06,
      "loss": 0.0134,
      "step": 15885
    },
    {
      "epoch": 0.9423419148178906,
      "grad_norm": 0.5262418389320374,
      "learning_rate": 1.2813076720274189e-06,
      "loss": 0.0037,
      "step": 15886
    },
    {
      "epoch": 0.9424012338355677,
      "grad_norm": 1.2067824602127075,
      "learning_rate": 1.2799894542578433e-06,
      "loss": 0.0124,
      "step": 15887
    },
    {
      "epoch": 0.9424605528532447,
      "grad_norm": 3.5724823474884033,
      "learning_rate": 1.278671236488268e-06,
      "loss": 0.0187,
      "step": 15888
    },
    {
      "epoch": 0.9425198718709218,
      "grad_norm": 0.3237290382385254,
      "learning_rate": 1.2773530187186925e-06,
      "loss": 0.0042,
      "step": 15889
    },
    {
      "epoch": 0.9425791908885989,
      "grad_norm": 5.974287033081055,
      "learning_rate": 1.276034800949117e-06,
      "loss": 0.195,
      "step": 15890
    },
    {
      "epoch": 0.942638509906276,
      "grad_norm": 4.72486686706543,
      "learning_rate": 1.2747165831795413e-06,
      "loss": 0.1241,
      "step": 15891
    },
    {
      "epoch": 0.942697828923953,
      "grad_norm": 0.03905412554740906,
      "learning_rate": 1.2733983654099657e-06,
      "loss": 0.0007,
      "step": 15892
    },
    {
      "epoch": 0.9427571479416301,
      "grad_norm": 17.917442321777344,
      "learning_rate": 1.27208014764039e-06,
      "loss": 0.3289,
      "step": 15893
    },
    {
      "epoch": 0.9428164669593072,
      "grad_norm": 5.061367511749268,
      "learning_rate": 1.270761929870815e-06,
      "loss": 0.313,
      "step": 15894
    },
    {
      "epoch": 0.9428757859769842,
      "grad_norm": 3.416651487350464,
      "learning_rate": 1.2694437121012393e-06,
      "loss": 0.0267,
      "step": 15895
    },
    {
      "epoch": 0.9429351049946613,
      "grad_norm": 30.648691177368164,
      "learning_rate": 1.2681254943316637e-06,
      "loss": 0.7809,
      "step": 15896
    },
    {
      "epoch": 0.9429944240123384,
      "grad_norm": 0.2622646391391754,
      "learning_rate": 1.2668072765620881e-06,
      "loss": 0.0029,
      "step": 15897
    },
    {
      "epoch": 0.9430537430300154,
      "grad_norm": 13.030200004577637,
      "learning_rate": 1.2654890587925125e-06,
      "loss": 0.3457,
      "step": 15898
    },
    {
      "epoch": 0.9431130620476925,
      "grad_norm": 0.014753369614481926,
      "learning_rate": 1.264170841022937e-06,
      "loss": 0.0004,
      "step": 15899
    },
    {
      "epoch": 0.9431723810653696,
      "grad_norm": 4.296821117401123,
      "learning_rate": 1.2628526232533617e-06,
      "loss": 0.7771,
      "step": 15900
    },
    {
      "epoch": 0.9432317000830466,
      "grad_norm": 0.9638357162475586,
      "learning_rate": 1.2615344054837861e-06,
      "loss": 0.006,
      "step": 15901
    },
    {
      "epoch": 0.9432910191007237,
      "grad_norm": 17.854755401611328,
      "learning_rate": 1.2602161877142105e-06,
      "loss": 0.63,
      "step": 15902
    },
    {
      "epoch": 0.9433503381184007,
      "grad_norm": 0.4680835008621216,
      "learning_rate": 1.258897969944635e-06,
      "loss": 0.0033,
      "step": 15903
    },
    {
      "epoch": 0.9434096571360778,
      "grad_norm": 11.310108184814453,
      "learning_rate": 1.2575797521750593e-06,
      "loss": 0.3172,
      "step": 15904
    },
    {
      "epoch": 0.9434689761537549,
      "grad_norm": 8.981752395629883,
      "learning_rate": 1.2562615344054837e-06,
      "loss": 1.0227,
      "step": 15905
    },
    {
      "epoch": 0.943528295171432,
      "grad_norm": 12.230469703674316,
      "learning_rate": 1.2549433166359086e-06,
      "loss": 0.0964,
      "step": 15906
    },
    {
      "epoch": 0.9435876141891091,
      "grad_norm": 0.07812529057264328,
      "learning_rate": 1.253625098866333e-06,
      "loss": 0.0009,
      "step": 15907
    },
    {
      "epoch": 0.943646933206786,
      "grad_norm": 7.156338691711426,
      "learning_rate": 1.2523068810967574e-06,
      "loss": 0.5229,
      "step": 15908
    },
    {
      "epoch": 0.9437062522244631,
      "grad_norm": 0.0876576155424118,
      "learning_rate": 1.2509886633271818e-06,
      "loss": 0.0013,
      "step": 15909
    },
    {
      "epoch": 0.9437655712421402,
      "grad_norm": 8.740632057189941,
      "learning_rate": 1.2496704455576064e-06,
      "loss": 0.0602,
      "step": 15910
    },
    {
      "epoch": 0.9438248902598173,
      "grad_norm": 5.04353666305542,
      "learning_rate": 1.2483522277880308e-06,
      "loss": 0.0425,
      "step": 15911
    },
    {
      "epoch": 0.9438842092774944,
      "grad_norm": 0.21391677856445312,
      "learning_rate": 1.2470340100184552e-06,
      "loss": 0.0029,
      "step": 15912
    },
    {
      "epoch": 0.9439435282951715,
      "grad_norm": 3.7114598751068115,
      "learning_rate": 1.2457157922488798e-06,
      "loss": 0.0354,
      "step": 15913
    },
    {
      "epoch": 0.9440028473128484,
      "grad_norm": 0.09067443758249283,
      "learning_rate": 1.2443975744793042e-06,
      "loss": 0.0011,
      "step": 15914
    },
    {
      "epoch": 0.9440621663305255,
      "grad_norm": 14.920781135559082,
      "learning_rate": 1.2430793567097286e-06,
      "loss": 0.1867,
      "step": 15915
    },
    {
      "epoch": 0.9441214853482026,
      "grad_norm": 4.542626857757568,
      "learning_rate": 1.241761138940153e-06,
      "loss": 0.0191,
      "step": 15916
    },
    {
      "epoch": 0.9441808043658797,
      "grad_norm": 0.05980512127280235,
      "learning_rate": 1.2404429211705776e-06,
      "loss": 0.0011,
      "step": 15917
    },
    {
      "epoch": 0.9442401233835568,
      "grad_norm": 0.2085953652858734,
      "learning_rate": 1.239124703401002e-06,
      "loss": 0.0021,
      "step": 15918
    },
    {
      "epoch": 0.9442994424012339,
      "grad_norm": 0.28894129395484924,
      "learning_rate": 1.2378064856314264e-06,
      "loss": 0.0035,
      "step": 15919
    },
    {
      "epoch": 0.944358761418911,
      "grad_norm": 14.119064331054688,
      "learning_rate": 1.236488267861851e-06,
      "loss": 0.0838,
      "step": 15920
    },
    {
      "epoch": 0.9444180804365879,
      "grad_norm": 0.014115070924162865,
      "learning_rate": 1.2351700500922754e-06,
      "loss": 0.0002,
      "step": 15921
    },
    {
      "epoch": 0.944477399454265,
      "grad_norm": 0.47588589787483215,
      "learning_rate": 1.2338518323226998e-06,
      "loss": 0.0054,
      "step": 15922
    },
    {
      "epoch": 0.9445367184719421,
      "grad_norm": 0.03087073564529419,
      "learning_rate": 1.2325336145531242e-06,
      "loss": 0.001,
      "step": 15923
    },
    {
      "epoch": 0.9445960374896192,
      "grad_norm": 15.859435081481934,
      "learning_rate": 1.2312153967835488e-06,
      "loss": 0.2636,
      "step": 15924
    },
    {
      "epoch": 0.9446553565072963,
      "grad_norm": 0.045053791254758835,
      "learning_rate": 1.2298971790139732e-06,
      "loss": 0.0006,
      "step": 15925
    },
    {
      "epoch": 0.9447146755249733,
      "grad_norm": 0.06682314723730087,
      "learning_rate": 1.2285789612443976e-06,
      "loss": 0.0016,
      "step": 15926
    },
    {
      "epoch": 0.9447739945426503,
      "grad_norm": 0.9529860615730286,
      "learning_rate": 1.2272607434748222e-06,
      "loss": 0.0071,
      "step": 15927
    },
    {
      "epoch": 0.9448333135603274,
      "grad_norm": 0.15860450267791748,
      "learning_rate": 1.2259425257052466e-06,
      "loss": 0.0027,
      "step": 15928
    },
    {
      "epoch": 0.9448926325780045,
      "grad_norm": 15.86110782623291,
      "learning_rate": 1.224624307935671e-06,
      "loss": 0.236,
      "step": 15929
    },
    {
      "epoch": 0.9449519515956816,
      "grad_norm": 29.906686782836914,
      "learning_rate": 1.2233060901660954e-06,
      "loss": 0.4202,
      "step": 15930
    },
    {
      "epoch": 0.9450112706133587,
      "grad_norm": 0.8035348653793335,
      "learning_rate": 1.22198787239652e-06,
      "loss": 0.0112,
      "step": 15931
    },
    {
      "epoch": 0.9450705896310357,
      "grad_norm": 0.0030187934171408415,
      "learning_rate": 1.2206696546269444e-06,
      "loss": 0.0001,
      "step": 15932
    },
    {
      "epoch": 0.9451299086487128,
      "grad_norm": 0.5019248127937317,
      "learning_rate": 1.2193514368573688e-06,
      "loss": 0.0031,
      "step": 15933
    },
    {
      "epoch": 0.9451892276663898,
      "grad_norm": 12.290477752685547,
      "learning_rate": 1.2180332190877934e-06,
      "loss": 0.1335,
      "step": 15934
    },
    {
      "epoch": 0.9452485466840669,
      "grad_norm": 0.39499908685684204,
      "learning_rate": 1.2167150013182178e-06,
      "loss": 0.0021,
      "step": 15935
    },
    {
      "epoch": 0.945307865701744,
      "grad_norm": 10.441871643066406,
      "learning_rate": 1.2153967835486422e-06,
      "loss": 0.1502,
      "step": 15936
    },
    {
      "epoch": 0.945367184719421,
      "grad_norm": 0.016032621264457703,
      "learning_rate": 1.2140785657790668e-06,
      "loss": 0.0004,
      "step": 15937
    },
    {
      "epoch": 0.9454265037370981,
      "grad_norm": 0.011315849609673023,
      "learning_rate": 1.2127603480094912e-06,
      "loss": 0.0003,
      "step": 15938
    },
    {
      "epoch": 0.9454858227547752,
      "grad_norm": 3.5686850547790527,
      "learning_rate": 1.2114421302399156e-06,
      "loss": 0.0521,
      "step": 15939
    },
    {
      "epoch": 0.9455451417724523,
      "grad_norm": 4.17958402633667,
      "learning_rate": 1.2101239124703402e-06,
      "loss": 0.0439,
      "step": 15940
    },
    {
      "epoch": 0.9456044607901293,
      "grad_norm": 17.986896514892578,
      "learning_rate": 1.2088056947007646e-06,
      "loss": 0.1048,
      "step": 15941
    },
    {
      "epoch": 0.9456637798078064,
      "grad_norm": 12.209094047546387,
      "learning_rate": 1.207487476931189e-06,
      "loss": 0.3752,
      "step": 15942
    },
    {
      "epoch": 0.9457230988254834,
      "grad_norm": 0.1116764098405838,
      "learning_rate": 1.2061692591616136e-06,
      "loss": 0.0016,
      "step": 15943
    },
    {
      "epoch": 0.9457824178431605,
      "grad_norm": 0.3248234987258911,
      "learning_rate": 1.204851041392038e-06,
      "loss": 0.0035,
      "step": 15944
    },
    {
      "epoch": 0.9458417368608376,
      "grad_norm": 0.14683178067207336,
      "learning_rate": 1.2035328236224624e-06,
      "loss": 0.0016,
      "step": 15945
    },
    {
      "epoch": 0.9459010558785147,
      "grad_norm": 3.722132921218872,
      "learning_rate": 1.202214605852887e-06,
      "loss": 0.0211,
      "step": 15946
    },
    {
      "epoch": 0.9459603748961917,
      "grad_norm": 5.358144760131836,
      "learning_rate": 1.2008963880833114e-06,
      "loss": 0.1204,
      "step": 15947
    },
    {
      "epoch": 0.9460196939138688,
      "grad_norm": 7.648887634277344,
      "learning_rate": 1.1995781703137358e-06,
      "loss": 0.1812,
      "step": 15948
    },
    {
      "epoch": 0.9460790129315458,
      "grad_norm": 1.9785313606262207,
      "learning_rate": 1.1982599525441605e-06,
      "loss": 0.022,
      "step": 15949
    },
    {
      "epoch": 0.9461383319492229,
      "grad_norm": 6.159678936004639,
      "learning_rate": 1.1969417347745849e-06,
      "loss": 0.0596,
      "step": 15950
    },
    {
      "epoch": 0.9461976509669,
      "grad_norm": 0.007989716716110706,
      "learning_rate": 1.1956235170050093e-06,
      "loss": 0.0003,
      "step": 15951
    },
    {
      "epoch": 0.9462569699845771,
      "grad_norm": 0.8385679125785828,
      "learning_rate": 1.1943052992354339e-06,
      "loss": 0.0054,
      "step": 15952
    },
    {
      "epoch": 0.9463162890022542,
      "grad_norm": 12.25582504272461,
      "learning_rate": 1.1929870814658583e-06,
      "loss": 0.1204,
      "step": 15953
    },
    {
      "epoch": 0.9463756080199311,
      "grad_norm": 0.017673257738351822,
      "learning_rate": 1.1916688636962827e-06,
      "loss": 0.0002,
      "step": 15954
    },
    {
      "epoch": 0.9464349270376082,
      "grad_norm": 0.7004281282424927,
      "learning_rate": 1.1903506459267073e-06,
      "loss": 0.0076,
      "step": 15955
    },
    {
      "epoch": 0.9464942460552853,
      "grad_norm": 0.1417904943227768,
      "learning_rate": 1.1890324281571317e-06,
      "loss": 0.0035,
      "step": 15956
    },
    {
      "epoch": 0.9465535650729624,
      "grad_norm": 0.7458388805389404,
      "learning_rate": 1.187714210387556e-06,
      "loss": 0.0071,
      "step": 15957
    },
    {
      "epoch": 0.9466128840906395,
      "grad_norm": 0.1395084708929062,
      "learning_rate": 1.1863959926179807e-06,
      "loss": 0.002,
      "step": 15958
    },
    {
      "epoch": 0.9466722031083166,
      "grad_norm": 0.009032441303133965,
      "learning_rate": 1.185077774848405e-06,
      "loss": 0.0002,
      "step": 15959
    },
    {
      "epoch": 0.9467315221259935,
      "grad_norm": 0.01468273252248764,
      "learning_rate": 1.1837595570788295e-06,
      "loss": 0.0003,
      "step": 15960
    },
    {
      "epoch": 0.9467908411436706,
      "grad_norm": 0.48931241035461426,
      "learning_rate": 1.182441339309254e-06,
      "loss": 0.0049,
      "step": 15961
    },
    {
      "epoch": 0.9468501601613477,
      "grad_norm": 0.09558773785829544,
      "learning_rate": 1.1811231215396785e-06,
      "loss": 0.0015,
      "step": 15962
    },
    {
      "epoch": 0.9469094791790248,
      "grad_norm": 0.6783319115638733,
      "learning_rate": 1.1798049037701029e-06,
      "loss": 0.0054,
      "step": 15963
    },
    {
      "epoch": 0.9469687981967019,
      "grad_norm": 0.02615913189947605,
      "learning_rate": 1.1784866860005275e-06,
      "loss": 0.0009,
      "step": 15964
    },
    {
      "epoch": 0.947028117214379,
      "grad_norm": 3.0663304328918457,
      "learning_rate": 1.177168468230952e-06,
      "loss": 0.0273,
      "step": 15965
    },
    {
      "epoch": 0.947087436232056,
      "grad_norm": 0.01404435746371746,
      "learning_rate": 1.1758502504613763e-06,
      "loss": 0.0002,
      "step": 15966
    },
    {
      "epoch": 0.947146755249733,
      "grad_norm": 35.296478271484375,
      "learning_rate": 1.174532032691801e-06,
      "loss": 0.3232,
      "step": 15967
    },
    {
      "epoch": 0.9472060742674101,
      "grad_norm": 15.149107933044434,
      "learning_rate": 1.1732138149222253e-06,
      "loss": 0.5269,
      "step": 15968
    },
    {
      "epoch": 0.9472653932850872,
      "grad_norm": 0.010983070358633995,
      "learning_rate": 1.1718955971526497e-06,
      "loss": 0.0003,
      "step": 15969
    },
    {
      "epoch": 0.9473247123027643,
      "grad_norm": 0.011614919640123844,
      "learning_rate": 1.1705773793830743e-06,
      "loss": 0.0002,
      "step": 15970
    },
    {
      "epoch": 0.9473840313204414,
      "grad_norm": 13.452533721923828,
      "learning_rate": 1.1692591616134987e-06,
      "loss": 0.1029,
      "step": 15971
    },
    {
      "epoch": 0.9474433503381184,
      "grad_norm": 8.296422004699707,
      "learning_rate": 1.1679409438439231e-06,
      "loss": 0.1386,
      "step": 15972
    },
    {
      "epoch": 0.9475026693557954,
      "grad_norm": 0.13451747596263885,
      "learning_rate": 1.1666227260743477e-06,
      "loss": 0.0018,
      "step": 15973
    },
    {
      "epoch": 0.9475619883734725,
      "grad_norm": 1.1635931730270386,
      "learning_rate": 1.1653045083047721e-06,
      "loss": 0.0186,
      "step": 15974
    },
    {
      "epoch": 0.9476213073911496,
      "grad_norm": 9.973149299621582,
      "learning_rate": 1.1639862905351965e-06,
      "loss": 0.1635,
      "step": 15975
    },
    {
      "epoch": 0.9476806264088267,
      "grad_norm": 0.0547705814242363,
      "learning_rate": 1.162668072765621e-06,
      "loss": 0.0007,
      "step": 15976
    },
    {
      "epoch": 0.9477399454265037,
      "grad_norm": 0.1920856088399887,
      "learning_rate": 1.1613498549960455e-06,
      "loss": 0.0019,
      "step": 15977
    },
    {
      "epoch": 0.9477992644441808,
      "grad_norm": 0.0062416126020252705,
      "learning_rate": 1.16003163722647e-06,
      "loss": 0.0002,
      "step": 15978
    },
    {
      "epoch": 0.9478585834618579,
      "grad_norm": 0.011755366809666157,
      "learning_rate": 1.1587134194568943e-06,
      "loss": 0.0002,
      "step": 15979
    },
    {
      "epoch": 0.9479179024795349,
      "grad_norm": 0.15989181399345398,
      "learning_rate": 1.157395201687319e-06,
      "loss": 0.0021,
      "step": 15980
    },
    {
      "epoch": 0.947977221497212,
      "grad_norm": 0.08575671911239624,
      "learning_rate": 1.1560769839177433e-06,
      "loss": 0.0014,
      "step": 15981
    },
    {
      "epoch": 0.9480365405148891,
      "grad_norm": 22.00012969970703,
      "learning_rate": 1.1547587661481677e-06,
      "loss": 0.465,
      "step": 15982
    },
    {
      "epoch": 0.9480958595325661,
      "grad_norm": 0.035160526633262634,
      "learning_rate": 1.1534405483785921e-06,
      "loss": 0.0005,
      "step": 15983
    },
    {
      "epoch": 0.9481551785502432,
      "grad_norm": 0.012068740092217922,
      "learning_rate": 1.1521223306090167e-06,
      "loss": 0.0002,
      "step": 15984
    },
    {
      "epoch": 0.9482144975679203,
      "grad_norm": 3.9657888412475586,
      "learning_rate": 1.1508041128394411e-06,
      "loss": 0.0756,
      "step": 15985
    },
    {
      "epoch": 0.9482738165855974,
      "grad_norm": 0.007801930885761976,
      "learning_rate": 1.1494858950698655e-06,
      "loss": 0.0003,
      "step": 15986
    },
    {
      "epoch": 0.9483331356032744,
      "grad_norm": 0.9665483236312866,
      "learning_rate": 1.1481676773002902e-06,
      "loss": 0.0107,
      "step": 15987
    },
    {
      "epoch": 0.9483924546209515,
      "grad_norm": 10.520241737365723,
      "learning_rate": 1.1468494595307146e-06,
      "loss": 0.224,
      "step": 15988
    },
    {
      "epoch": 0.9484517736386285,
      "grad_norm": 15.931726455688477,
      "learning_rate": 1.145531241761139e-06,
      "loss": 0.0436,
      "step": 15989
    },
    {
      "epoch": 0.9485110926563056,
      "grad_norm": 0.25013214349746704,
      "learning_rate": 1.1442130239915634e-06,
      "loss": 0.0026,
      "step": 15990
    },
    {
      "epoch": 0.9485704116739827,
      "grad_norm": 0.21566906571388245,
      "learning_rate": 1.142894806221988e-06,
      "loss": 0.0023,
      "step": 15991
    },
    {
      "epoch": 0.9486297306916598,
      "grad_norm": 0.014784534461796284,
      "learning_rate": 1.1415765884524124e-06,
      "loss": 0.0002,
      "step": 15992
    },
    {
      "epoch": 0.9486890497093368,
      "grad_norm": 11.625316619873047,
      "learning_rate": 1.1402583706828368e-06,
      "loss": 1.0881,
      "step": 15993
    },
    {
      "epoch": 0.9487483687270138,
      "grad_norm": 21.26022720336914,
      "learning_rate": 1.1389401529132614e-06,
      "loss": 0.3148,
      "step": 15994
    },
    {
      "epoch": 0.9488076877446909,
      "grad_norm": 3.9584121704101562,
      "learning_rate": 1.1376219351436858e-06,
      "loss": 0.0401,
      "step": 15995
    },
    {
      "epoch": 0.948867006762368,
      "grad_norm": 0.03740578144788742,
      "learning_rate": 1.1363037173741102e-06,
      "loss": 0.0004,
      "step": 15996
    },
    {
      "epoch": 0.9489263257800451,
      "grad_norm": 8.69761848449707,
      "learning_rate": 1.1349854996045348e-06,
      "loss": 0.1453,
      "step": 15997
    },
    {
      "epoch": 0.9489856447977222,
      "grad_norm": 0.024609630927443504,
      "learning_rate": 1.1336672818349592e-06,
      "loss": 0.0004,
      "step": 15998
    },
    {
      "epoch": 0.9490449638153993,
      "grad_norm": 5.204351425170898,
      "learning_rate": 1.1323490640653836e-06,
      "loss": 0.1266,
      "step": 15999
    },
    {
      "epoch": 0.9491042828330762,
      "grad_norm": 1.305137276649475,
      "learning_rate": 1.1310308462958082e-06,
      "loss": 0.0097,
      "step": 16000
    },
    {
      "epoch": 0.9491636018507533,
      "grad_norm": 6.563284873962402,
      "learning_rate": 1.1297126285262326e-06,
      "loss": 0.1416,
      "step": 16001
    },
    {
      "epoch": 0.9492229208684304,
      "grad_norm": 4.2431840896606445,
      "learning_rate": 1.128394410756657e-06,
      "loss": 0.0942,
      "step": 16002
    },
    {
      "epoch": 0.9492822398861075,
      "grad_norm": 0.08248506486415863,
      "learning_rate": 1.1270761929870816e-06,
      "loss": 0.0012,
      "step": 16003
    },
    {
      "epoch": 0.9493415589037846,
      "grad_norm": 0.6957958340644836,
      "learning_rate": 1.125757975217506e-06,
      "loss": 0.0076,
      "step": 16004
    },
    {
      "epoch": 0.9494008779214617,
      "grad_norm": 29.405847549438477,
      "learning_rate": 1.1244397574479304e-06,
      "loss": 0.4245,
      "step": 16005
    },
    {
      "epoch": 0.9494601969391386,
      "grad_norm": 1.0177900791168213,
      "learning_rate": 1.123121539678355e-06,
      "loss": 0.0084,
      "step": 16006
    },
    {
      "epoch": 0.9495195159568157,
      "grad_norm": 0.028819411993026733,
      "learning_rate": 1.1218033219087794e-06,
      "loss": 0.0007,
      "step": 16007
    },
    {
      "epoch": 0.9495788349744928,
      "grad_norm": 6.993620872497559,
      "learning_rate": 1.1204851041392038e-06,
      "loss": 0.1621,
      "step": 16008
    },
    {
      "epoch": 0.9496381539921699,
      "grad_norm": 0.30994999408721924,
      "learning_rate": 1.1191668863696284e-06,
      "loss": 0.0036,
      "step": 16009
    },
    {
      "epoch": 0.949697473009847,
      "grad_norm": 0.08371789753437042,
      "learning_rate": 1.1178486686000528e-06,
      "loss": 0.001,
      "step": 16010
    },
    {
      "epoch": 0.949756792027524,
      "grad_norm": 0.07778258621692657,
      "learning_rate": 1.1165304508304772e-06,
      "loss": 0.001,
      "step": 16011
    },
    {
      "epoch": 0.9498161110452011,
      "grad_norm": 3.4636783599853516,
      "learning_rate": 1.1152122330609018e-06,
      "loss": 0.0569,
      "step": 16012
    },
    {
      "epoch": 0.9498754300628781,
      "grad_norm": 0.366812139749527,
      "learning_rate": 1.1138940152913262e-06,
      "loss": 0.0029,
      "step": 16013
    },
    {
      "epoch": 0.9499347490805552,
      "grad_norm": 0.0207610335201025,
      "learning_rate": 1.1125757975217506e-06,
      "loss": 0.0005,
      "step": 16014
    },
    {
      "epoch": 0.9499940680982323,
      "grad_norm": 9.785091400146484,
      "learning_rate": 1.1112575797521752e-06,
      "loss": 0.1092,
      "step": 16015
    },
    {
      "epoch": 0.9500533871159094,
      "grad_norm": 1.1297345161437988,
      "learning_rate": 1.1099393619825996e-06,
      "loss": 0.0104,
      "step": 16016
    },
    {
      "epoch": 0.9501127061335864,
      "grad_norm": 0.0037194432225078344,
      "learning_rate": 1.108621144213024e-06,
      "loss": 0.0001,
      "step": 16017
    },
    {
      "epoch": 0.9501720251512635,
      "grad_norm": 1.4569799900054932,
      "learning_rate": 1.1073029264434486e-06,
      "loss": 0.0278,
      "step": 16018
    },
    {
      "epoch": 0.9502313441689406,
      "grad_norm": 0.19864600896835327,
      "learning_rate": 1.105984708673873e-06,
      "loss": 0.0031,
      "step": 16019
    },
    {
      "epoch": 0.9502906631866176,
      "grad_norm": 10.335331916809082,
      "learning_rate": 1.1046664909042974e-06,
      "loss": 0.1986,
      "step": 16020
    },
    {
      "epoch": 0.9503499822042947,
      "grad_norm": 5.761628150939941,
      "learning_rate": 1.103348273134722e-06,
      "loss": 0.1164,
      "step": 16021
    },
    {
      "epoch": 0.9504093012219718,
      "grad_norm": 0.019133826717734337,
      "learning_rate": 1.1020300553651464e-06,
      "loss": 0.0004,
      "step": 16022
    },
    {
      "epoch": 0.9504686202396488,
      "grad_norm": 7.203949451446533,
      "learning_rate": 1.1007118375955708e-06,
      "loss": 0.0518,
      "step": 16023
    },
    {
      "epoch": 0.9505279392573259,
      "grad_norm": 0.06261047720909119,
      "learning_rate": 1.0993936198259955e-06,
      "loss": 0.0012,
      "step": 16024
    },
    {
      "epoch": 0.950587258275003,
      "grad_norm": 0.03267066553235054,
      "learning_rate": 1.0980754020564199e-06,
      "loss": 0.0003,
      "step": 16025
    },
    {
      "epoch": 0.95064657729268,
      "grad_norm": 1.5890909433364868,
      "learning_rate": 1.0967571842868443e-06,
      "loss": 0.0374,
      "step": 16026
    },
    {
      "epoch": 0.9507058963103571,
      "grad_norm": 21.69858741760254,
      "learning_rate": 1.0954389665172689e-06,
      "loss": 0.5635,
      "step": 16027
    },
    {
      "epoch": 0.9507652153280342,
      "grad_norm": 0.03140909969806671,
      "learning_rate": 1.0941207487476933e-06,
      "loss": 0.0009,
      "step": 16028
    },
    {
      "epoch": 0.9508245343457112,
      "grad_norm": 0.4264041781425476,
      "learning_rate": 1.0928025309781177e-06,
      "loss": 0.0045,
      "step": 16029
    },
    {
      "epoch": 0.9508838533633883,
      "grad_norm": 0.07068129628896713,
      "learning_rate": 1.0914843132085423e-06,
      "loss": 0.0008,
      "step": 16030
    },
    {
      "epoch": 0.9509431723810654,
      "grad_norm": 0.02930362895131111,
      "learning_rate": 1.0901660954389667e-06,
      "loss": 0.0002,
      "step": 16031
    },
    {
      "epoch": 0.9510024913987425,
      "grad_norm": 0.02179393544793129,
      "learning_rate": 1.088847877669391e-06,
      "loss": 0.0005,
      "step": 16032
    },
    {
      "epoch": 0.9510618104164195,
      "grad_norm": 7.72715425491333,
      "learning_rate": 1.0875296598998155e-06,
      "loss": 0.0813,
      "step": 16033
    },
    {
      "epoch": 0.9511211294340965,
      "grad_norm": 0.3061091899871826,
      "learning_rate": 1.08621144213024e-06,
      "loss": 0.0053,
      "step": 16034
    },
    {
      "epoch": 0.9511804484517736,
      "grad_norm": 10.676630020141602,
      "learning_rate": 1.0848932243606645e-06,
      "loss": 0.1149,
      "step": 16035
    },
    {
      "epoch": 0.9512397674694507,
      "grad_norm": 2.5531857013702393,
      "learning_rate": 1.0835750065910889e-06,
      "loss": 0.0174,
      "step": 16036
    },
    {
      "epoch": 0.9512990864871278,
      "grad_norm": 25.376667022705078,
      "learning_rate": 1.0822567888215135e-06,
      "loss": 0.2951,
      "step": 16037
    },
    {
      "epoch": 0.9513584055048049,
      "grad_norm": 5.402228832244873,
      "learning_rate": 1.0809385710519379e-06,
      "loss": 0.0547,
      "step": 16038
    },
    {
      "epoch": 0.9514177245224819,
      "grad_norm": 2.273864507675171,
      "learning_rate": 1.0796203532823623e-06,
      "loss": 0.0299,
      "step": 16039
    },
    {
      "epoch": 0.9514770435401589,
      "grad_norm": 0.21453702449798584,
      "learning_rate": 1.0783021355127867e-06,
      "loss": 0.0008,
      "step": 16040
    },
    {
      "epoch": 0.951536362557836,
      "grad_norm": 1.3929227590560913,
      "learning_rate": 1.0769839177432113e-06,
      "loss": 0.0058,
      "step": 16041
    },
    {
      "epoch": 0.9515956815755131,
      "grad_norm": 0.048840757459402084,
      "learning_rate": 1.0756656999736357e-06,
      "loss": 0.0013,
      "step": 16042
    },
    {
      "epoch": 0.9516550005931902,
      "grad_norm": 0.18282678723335266,
      "learning_rate": 1.07434748220406e-06,
      "loss": 0.003,
      "step": 16043
    },
    {
      "epoch": 0.9517143196108673,
      "grad_norm": 2.3147096633911133,
      "learning_rate": 1.0730292644344847e-06,
      "loss": 0.0318,
      "step": 16044
    },
    {
      "epoch": 0.9517736386285444,
      "grad_norm": 4.447174549102783,
      "learning_rate": 1.071711046664909e-06,
      "loss": 0.03,
      "step": 16045
    },
    {
      "epoch": 0.9518329576462213,
      "grad_norm": 15.115548133850098,
      "learning_rate": 1.0703928288953335e-06,
      "loss": 0.9982,
      "step": 16046
    },
    {
      "epoch": 0.9518922766638984,
      "grad_norm": 0.22399704158306122,
      "learning_rate": 1.069074611125758e-06,
      "loss": 0.003,
      "step": 16047
    },
    {
      "epoch": 0.9519515956815755,
      "grad_norm": 6.143457889556885,
      "learning_rate": 1.0677563933561825e-06,
      "loss": 0.0603,
      "step": 16048
    },
    {
      "epoch": 0.9520109146992526,
      "grad_norm": 14.427680969238281,
      "learning_rate": 1.066438175586607e-06,
      "loss": 0.7016,
      "step": 16049
    },
    {
      "epoch": 0.9520702337169297,
      "grad_norm": 0.776247501373291,
      "learning_rate": 1.0651199578170313e-06,
      "loss": 0.008,
      "step": 16050
    },
    {
      "epoch": 0.9521295527346068,
      "grad_norm": 0.4703872799873352,
      "learning_rate": 1.063801740047456e-06,
      "loss": 0.0064,
      "step": 16051
    },
    {
      "epoch": 0.9521888717522837,
      "grad_norm": 10.796806335449219,
      "learning_rate": 1.0624835222778803e-06,
      "loss": 0.5514,
      "step": 16052
    },
    {
      "epoch": 0.9522481907699608,
      "grad_norm": 0.007807079236954451,
      "learning_rate": 1.0611653045083047e-06,
      "loss": 0.0002,
      "step": 16053
    },
    {
      "epoch": 0.9523075097876379,
      "grad_norm": 14.772582054138184,
      "learning_rate": 1.0598470867387293e-06,
      "loss": 0.4701,
      "step": 16054
    },
    {
      "epoch": 0.952366828805315,
      "grad_norm": 0.4607046842575073,
      "learning_rate": 1.0585288689691537e-06,
      "loss": 0.0036,
      "step": 16055
    },
    {
      "epoch": 0.9524261478229921,
      "grad_norm": 36.06282043457031,
      "learning_rate": 1.0572106511995781e-06,
      "loss": 0.712,
      "step": 16056
    },
    {
      "epoch": 0.9524854668406691,
      "grad_norm": 6.215865612030029,
      "learning_rate": 1.0558924334300027e-06,
      "loss": 0.0268,
      "step": 16057
    },
    {
      "epoch": 0.9525447858583462,
      "grad_norm": 0.1095278188586235,
      "learning_rate": 1.0545742156604271e-06,
      "loss": 0.0014,
      "step": 16058
    },
    {
      "epoch": 0.9526041048760232,
      "grad_norm": 3.6601877212524414,
      "learning_rate": 1.0532559978908515e-06,
      "loss": 0.0546,
      "step": 16059
    },
    {
      "epoch": 0.9526634238937003,
      "grad_norm": 13.503628730773926,
      "learning_rate": 1.0519377801212761e-06,
      "loss": 0.2699,
      "step": 16060
    },
    {
      "epoch": 0.9527227429113774,
      "grad_norm": 8.681609153747559,
      "learning_rate": 1.0506195623517005e-06,
      "loss": 0.4721,
      "step": 16061
    },
    {
      "epoch": 0.9527820619290545,
      "grad_norm": 0.03683221712708473,
      "learning_rate": 1.049301344582125e-06,
      "loss": 0.0008,
      "step": 16062
    },
    {
      "epoch": 0.9528413809467315,
      "grad_norm": 0.9241763353347778,
      "learning_rate": 1.0479831268125495e-06,
      "loss": 0.017,
      "step": 16063
    },
    {
      "epoch": 0.9529006999644086,
      "grad_norm": 0.16878367960453033,
      "learning_rate": 1.046664909042974e-06,
      "loss": 0.0005,
      "step": 16064
    },
    {
      "epoch": 0.9529600189820857,
      "grad_norm": 0.17715981602668762,
      "learning_rate": 1.0453466912733983e-06,
      "loss": 0.0032,
      "step": 16065
    },
    {
      "epoch": 0.9530193379997627,
      "grad_norm": 1.9725462198257446,
      "learning_rate": 1.044028473503823e-06,
      "loss": 0.0318,
      "step": 16066
    },
    {
      "epoch": 0.9530786570174398,
      "grad_norm": 0.15479561686515808,
      "learning_rate": 1.0427102557342474e-06,
      "loss": 0.0016,
      "step": 16067
    },
    {
      "epoch": 0.9531379760351169,
      "grad_norm": 1.2403433322906494,
      "learning_rate": 1.0413920379646718e-06,
      "loss": 0.012,
      "step": 16068
    },
    {
      "epoch": 0.9531972950527939,
      "grad_norm": 4.537717342376709,
      "learning_rate": 1.0400738201950964e-06,
      "loss": 0.053,
      "step": 16069
    },
    {
      "epoch": 0.953256614070471,
      "grad_norm": 0.011503677815198898,
      "learning_rate": 1.0387556024255208e-06,
      "loss": 0.0003,
      "step": 16070
    },
    {
      "epoch": 0.9533159330881481,
      "grad_norm": 0.02158346213400364,
      "learning_rate": 1.0374373846559452e-06,
      "loss": 0.0006,
      "step": 16071
    },
    {
      "epoch": 0.9533752521058251,
      "grad_norm": 20.460542678833008,
      "learning_rate": 1.0361191668863698e-06,
      "loss": 1.596,
      "step": 16072
    },
    {
      "epoch": 0.9534345711235022,
      "grad_norm": 0.005323798395693302,
      "learning_rate": 1.0348009491167942e-06,
      "loss": 0.0002,
      "step": 16073
    },
    {
      "epoch": 0.9534938901411792,
      "grad_norm": 0.7404912114143372,
      "learning_rate": 1.0334827313472186e-06,
      "loss": 0.0114,
      "step": 16074
    },
    {
      "epoch": 0.9535532091588563,
      "grad_norm": 35.55229568481445,
      "learning_rate": 1.0321645135776432e-06,
      "loss": 0.0383,
      "step": 16075
    },
    {
      "epoch": 0.9536125281765334,
      "grad_norm": 7.2107062339782715,
      "learning_rate": 1.0308462958080676e-06,
      "loss": 0.1873,
      "step": 16076
    },
    {
      "epoch": 0.9536718471942105,
      "grad_norm": 0.0840827003121376,
      "learning_rate": 1.029528078038492e-06,
      "loss": 0.0008,
      "step": 16077
    },
    {
      "epoch": 0.9537311662118876,
      "grad_norm": 5.157329082489014,
      "learning_rate": 1.0282098602689166e-06,
      "loss": 0.0662,
      "step": 16078
    },
    {
      "epoch": 0.9537904852295646,
      "grad_norm": 0.03557984158396721,
      "learning_rate": 1.026891642499341e-06,
      "loss": 0.0006,
      "step": 16079
    },
    {
      "epoch": 0.9538498042472416,
      "grad_norm": 13.21860122680664,
      "learning_rate": 1.0255734247297656e-06,
      "loss": 0.3904,
      "step": 16080
    },
    {
      "epoch": 0.9539091232649187,
      "grad_norm": 0.0490526407957077,
      "learning_rate": 1.02425520696019e-06,
      "loss": 0.0009,
      "step": 16081
    },
    {
      "epoch": 0.9539684422825958,
      "grad_norm": 0.03231881558895111,
      "learning_rate": 1.0229369891906144e-06,
      "loss": 0.0008,
      "step": 16082
    },
    {
      "epoch": 0.9540277613002729,
      "grad_norm": 0.5265414714813232,
      "learning_rate": 1.021618771421039e-06,
      "loss": 0.0056,
      "step": 16083
    },
    {
      "epoch": 0.95408708031795,
      "grad_norm": 2.1546363830566406,
      "learning_rate": 1.0203005536514634e-06,
      "loss": 0.0319,
      "step": 16084
    },
    {
      "epoch": 0.954146399335627,
      "grad_norm": 0.03959597274661064,
      "learning_rate": 1.0189823358818878e-06,
      "loss": 0.0006,
      "step": 16085
    },
    {
      "epoch": 0.954205718353304,
      "grad_norm": 56.8049430847168,
      "learning_rate": 1.0176641181123122e-06,
      "loss": 0.8626,
      "step": 16086
    },
    {
      "epoch": 0.9542650373709811,
      "grad_norm": 0.027824411168694496,
      "learning_rate": 1.0163459003427368e-06,
      "loss": 0.0006,
      "step": 16087
    },
    {
      "epoch": 0.9543243563886582,
      "grad_norm": 21.477983474731445,
      "learning_rate": 1.0150276825731612e-06,
      "loss": 0.4295,
      "step": 16088
    },
    {
      "epoch": 0.9543836754063353,
      "grad_norm": 6.802730083465576,
      "learning_rate": 1.0137094648035856e-06,
      "loss": 0.5246,
      "step": 16089
    },
    {
      "epoch": 0.9544429944240124,
      "grad_norm": 4.263770580291748,
      "learning_rate": 1.0123912470340102e-06,
      "loss": 0.1532,
      "step": 16090
    },
    {
      "epoch": 0.9545023134416895,
      "grad_norm": 0.04074439778923988,
      "learning_rate": 1.0110730292644346e-06,
      "loss": 0.0005,
      "step": 16091
    },
    {
      "epoch": 0.9545616324593664,
      "grad_norm": 3.2104194164276123,
      "learning_rate": 1.009754811494859e-06,
      "loss": 0.0306,
      "step": 16092
    },
    {
      "epoch": 0.9546209514770435,
      "grad_norm": 6.397661209106445,
      "learning_rate": 1.0084365937252834e-06,
      "loss": 0.7015,
      "step": 16093
    },
    {
      "epoch": 0.9546802704947206,
      "grad_norm": 5.878299236297607,
      "learning_rate": 1.007118375955708e-06,
      "loss": 0.0199,
      "step": 16094
    },
    {
      "epoch": 0.9547395895123977,
      "grad_norm": 6.960354328155518,
      "learning_rate": 1.0058001581861324e-06,
      "loss": 0.0939,
      "step": 16095
    },
    {
      "epoch": 0.9547989085300748,
      "grad_norm": 4.02441930770874,
      "learning_rate": 1.0044819404165568e-06,
      "loss": 0.1435,
      "step": 16096
    },
    {
      "epoch": 0.9548582275477518,
      "grad_norm": 10.992634773254395,
      "learning_rate": 1.0031637226469814e-06,
      "loss": 0.1522,
      "step": 16097
    },
    {
      "epoch": 0.9549175465654289,
      "grad_norm": 0.9388334155082703,
      "learning_rate": 1.0018455048774058e-06,
      "loss": 0.012,
      "step": 16098
    },
    {
      "epoch": 0.9549768655831059,
      "grad_norm": 0.027697447687387466,
      "learning_rate": 1.0005272871078302e-06,
      "loss": 0.0005,
      "step": 16099
    },
    {
      "epoch": 0.955036184600783,
      "grad_norm": 0.17793111503124237,
      "learning_rate": 9.992090693382546e-07,
      "loss": 0.0014,
      "step": 16100
    },
    {
      "epoch": 0.9550955036184601,
      "grad_norm": 2.400840997695923,
      "learning_rate": 9.978908515686792e-07,
      "loss": 0.0143,
      "step": 16101
    },
    {
      "epoch": 0.9551548226361372,
      "grad_norm": 5.828314304351807,
      "learning_rate": 9.965726337991036e-07,
      "loss": 0.1471,
      "step": 16102
    },
    {
      "epoch": 0.9552141416538142,
      "grad_norm": 13.39708137512207,
      "learning_rate": 9.95254416029528e-07,
      "loss": 0.5245,
      "step": 16103
    },
    {
      "epoch": 0.9552734606714913,
      "grad_norm": 10.274394989013672,
      "learning_rate": 9.939361982599527e-07,
      "loss": 0.5878,
      "step": 16104
    },
    {
      "epoch": 0.9553327796891683,
      "grad_norm": 0.09270652383565903,
      "learning_rate": 9.92617980490377e-07,
      "loss": 0.0011,
      "step": 16105
    },
    {
      "epoch": 0.9553920987068454,
      "grad_norm": 0.752073347568512,
      "learning_rate": 9.912997627208015e-07,
      "loss": 0.0173,
      "step": 16106
    },
    {
      "epoch": 0.9554514177245225,
      "grad_norm": 4.081997394561768,
      "learning_rate": 9.89981544951226e-07,
      "loss": 0.0694,
      "step": 16107
    },
    {
      "epoch": 0.9555107367421996,
      "grad_norm": 0.19034118950366974,
      "learning_rate": 9.886633271816505e-07,
      "loss": 0.0022,
      "step": 16108
    },
    {
      "epoch": 0.9555700557598766,
      "grad_norm": 0.05064678192138672,
      "learning_rate": 9.873451094120749e-07,
      "loss": 0.0007,
      "step": 16109
    },
    {
      "epoch": 0.9556293747775537,
      "grad_norm": 0.7077484130859375,
      "learning_rate": 9.860268916424995e-07,
      "loss": 0.0042,
      "step": 16110
    },
    {
      "epoch": 0.9556886937952308,
      "grad_norm": 0.012769204564392567,
      "learning_rate": 9.847086738729239e-07,
      "loss": 0.0002,
      "step": 16111
    },
    {
      "epoch": 0.9557480128129078,
      "grad_norm": 0.016873689368367195,
      "learning_rate": 9.833904561033483e-07,
      "loss": 0.0005,
      "step": 16112
    },
    {
      "epoch": 0.9558073318305849,
      "grad_norm": 4.667020320892334,
      "learning_rate": 9.820722383337729e-07,
      "loss": 0.0596,
      "step": 16113
    },
    {
      "epoch": 0.955866650848262,
      "grad_norm": 0.04318714141845703,
      "learning_rate": 9.807540205641973e-07,
      "loss": 0.0009,
      "step": 16114
    },
    {
      "epoch": 0.955925969865939,
      "grad_norm": 0.21628595888614655,
      "learning_rate": 9.794358027946217e-07,
      "loss": 0.0026,
      "step": 16115
    },
    {
      "epoch": 0.9559852888836161,
      "grad_norm": 0.02241983264684677,
      "learning_rate": 9.781175850250463e-07,
      "loss": 0.0004,
      "step": 16116
    },
    {
      "epoch": 0.9560446079012932,
      "grad_norm": 3.0857324600219727,
      "learning_rate": 9.767993672554707e-07,
      "loss": 0.0068,
      "step": 16117
    },
    {
      "epoch": 0.9561039269189702,
      "grad_norm": 0.008519436232745647,
      "learning_rate": 9.75481149485895e-07,
      "loss": 0.0003,
      "step": 16118
    },
    {
      "epoch": 0.9561632459366473,
      "grad_norm": 3.7047581672668457,
      "learning_rate": 9.741629317163197e-07,
      "loss": 0.0305,
      "step": 16119
    },
    {
      "epoch": 0.9562225649543243,
      "grad_norm": 8.818098068237305,
      "learning_rate": 9.72844713946744e-07,
      "loss": 0.0876,
      "step": 16120
    },
    {
      "epoch": 0.9562818839720014,
      "grad_norm": 31.319366455078125,
      "learning_rate": 9.715264961771685e-07,
      "loss": 0.8232,
      "step": 16121
    },
    {
      "epoch": 0.9563412029896785,
      "grad_norm": 0.013327316381037235,
      "learning_rate": 9.70208278407593e-07,
      "loss": 0.0003,
      "step": 16122
    },
    {
      "epoch": 0.9564005220073556,
      "grad_norm": 9.967917442321777,
      "learning_rate": 9.688900606380175e-07,
      "loss": 0.2132,
      "step": 16123
    },
    {
      "epoch": 0.9564598410250327,
      "grad_norm": 0.009803690016269684,
      "learning_rate": 9.67571842868442e-07,
      "loss": 0.0003,
      "step": 16124
    },
    {
      "epoch": 0.9565191600427096,
      "grad_norm": 15.680354118347168,
      "learning_rate": 9.662536250988665e-07,
      "loss": 0.2394,
      "step": 16125
    },
    {
      "epoch": 0.9565784790603867,
      "grad_norm": 1.119387149810791,
      "learning_rate": 9.64935407329291e-07,
      "loss": 0.0153,
      "step": 16126
    },
    {
      "epoch": 0.9566377980780638,
      "grad_norm": 0.048073660582304,
      "learning_rate": 9.636171895597153e-07,
      "loss": 0.0007,
      "step": 16127
    },
    {
      "epoch": 0.9566971170957409,
      "grad_norm": 0.0220837090164423,
      "learning_rate": 9.6229897179014e-07,
      "loss": 0.0003,
      "step": 16128
    },
    {
      "epoch": 0.956756436113418,
      "grad_norm": 0.22242534160614014,
      "learning_rate": 9.609807540205643e-07,
      "loss": 0.0043,
      "step": 16129
    },
    {
      "epoch": 0.9568157551310951,
      "grad_norm": 8.556258201599121,
      "learning_rate": 9.596625362509887e-07,
      "loss": 0.3887,
      "step": 16130
    },
    {
      "epoch": 0.956875074148772,
      "grad_norm": 2.86165452003479,
      "learning_rate": 9.583443184814133e-07,
      "loss": 0.0137,
      "step": 16131
    },
    {
      "epoch": 0.9569343931664491,
      "grad_norm": 15.649707794189453,
      "learning_rate": 9.570261007118377e-07,
      "loss": 0.4356,
      "step": 16132
    },
    {
      "epoch": 0.9569937121841262,
      "grad_norm": 0.021381493657827377,
      "learning_rate": 9.557078829422621e-07,
      "loss": 0.0004,
      "step": 16133
    },
    {
      "epoch": 0.9570530312018033,
      "grad_norm": 0.004920778330415487,
      "learning_rate": 9.543896651726867e-07,
      "loss": 0.0002,
      "step": 16134
    },
    {
      "epoch": 0.9571123502194804,
      "grad_norm": 0.1074686050415039,
      "learning_rate": 9.53071447403111e-07,
      "loss": 0.0019,
      "step": 16135
    },
    {
      "epoch": 0.9571716692371575,
      "grad_norm": 3.542311668395996,
      "learning_rate": 9.517532296335355e-07,
      "loss": 0.0383,
      "step": 16136
    },
    {
      "epoch": 0.9572309882548345,
      "grad_norm": 0.6725587844848633,
      "learning_rate": 9.5043501186396e-07,
      "loss": 0.0067,
      "step": 16137
    },
    {
      "epoch": 0.9572903072725115,
      "grad_norm": 0.05064695328474045,
      "learning_rate": 9.491167940943844e-07,
      "loss": 0.0008,
      "step": 16138
    },
    {
      "epoch": 0.9573496262901886,
      "grad_norm": 10.639128684997559,
      "learning_rate": 9.477985763248089e-07,
      "loss": 0.1348,
      "step": 16139
    },
    {
      "epoch": 0.9574089453078657,
      "grad_norm": 0.15533633530139923,
      "learning_rate": 9.464803585552334e-07,
      "loss": 0.0016,
      "step": 16140
    },
    {
      "epoch": 0.9574682643255428,
      "grad_norm": 21.010536193847656,
      "learning_rate": 9.451621407856578e-07,
      "loss": 0.4979,
      "step": 16141
    },
    {
      "epoch": 0.9575275833432199,
      "grad_norm": 0.8313354849815369,
      "learning_rate": 9.438439230160822e-07,
      "loss": 0.0042,
      "step": 16142
    },
    {
      "epoch": 0.9575869023608969,
      "grad_norm": 9.474853515625,
      "learning_rate": 9.425257052465069e-07,
      "loss": 0.5365,
      "step": 16143
    },
    {
      "epoch": 0.957646221378574,
      "grad_norm": 0.09299743920564651,
      "learning_rate": 9.412074874769313e-07,
      "loss": 0.0019,
      "step": 16144
    },
    {
      "epoch": 0.957705540396251,
      "grad_norm": 0.8141263127326965,
      "learning_rate": 9.398892697073557e-07,
      "loss": 0.0093,
      "step": 16145
    },
    {
      "epoch": 0.9577648594139281,
      "grad_norm": 7.623733043670654,
      "learning_rate": 9.385710519377803e-07,
      "loss": 0.1746,
      "step": 16146
    },
    {
      "epoch": 0.9578241784316052,
      "grad_norm": 0.019615203142166138,
      "learning_rate": 9.372528341682047e-07,
      "loss": 0.0003,
      "step": 16147
    },
    {
      "epoch": 0.9578834974492823,
      "grad_norm": 6.122026443481445,
      "learning_rate": 9.359346163986291e-07,
      "loss": 0.0811,
      "step": 16148
    },
    {
      "epoch": 0.9579428164669593,
      "grad_norm": 0.02781059220433235,
      "learning_rate": 9.346163986290537e-07,
      "loss": 0.0004,
      "step": 16149
    },
    {
      "epoch": 0.9580021354846364,
      "grad_norm": 0.004539788700640202,
      "learning_rate": 9.332981808594781e-07,
      "loss": 0.0002,
      "step": 16150
    },
    {
      "epoch": 0.9580614545023134,
      "grad_norm": 12.471686363220215,
      "learning_rate": 9.319799630899025e-07,
      "loss": 0.2641,
      "step": 16151
    },
    {
      "epoch": 0.9581207735199905,
      "grad_norm": 0.0071035949513316154,
      "learning_rate": 9.306617453203271e-07,
      "loss": 0.0002,
      "step": 16152
    },
    {
      "epoch": 0.9581800925376676,
      "grad_norm": 7.993930816650391,
      "learning_rate": 9.293435275507515e-07,
      "loss": 0.1164,
      "step": 16153
    },
    {
      "epoch": 0.9582394115553446,
      "grad_norm": 0.1373201459646225,
      "learning_rate": 9.280253097811759e-07,
      "loss": 0.0017,
      "step": 16154
    },
    {
      "epoch": 0.9582987305730217,
      "grad_norm": 6.535000324249268,
      "learning_rate": 9.267070920116005e-07,
      "loss": 0.164,
      "step": 16155
    },
    {
      "epoch": 0.9583580495906988,
      "grad_norm": 2.9684174060821533,
      "learning_rate": 9.253888742420249e-07,
      "loss": 0.0343,
      "step": 16156
    },
    {
      "epoch": 0.9584173686083759,
      "grad_norm": 0.028699710965156555,
      "learning_rate": 9.240706564724493e-07,
      "loss": 0.0005,
      "step": 16157
    },
    {
      "epoch": 0.9584766876260529,
      "grad_norm": 0.054744426161050797,
      "learning_rate": 9.227524387028738e-07,
      "loss": 0.0005,
      "step": 16158
    },
    {
      "epoch": 0.95853600664373,
      "grad_norm": 10.638599395751953,
      "learning_rate": 9.214342209332983e-07,
      "loss": 0.2028,
      "step": 16159
    },
    {
      "epoch": 0.958595325661407,
      "grad_norm": 0.09261385351419449,
      "learning_rate": 9.201160031637227e-07,
      "loss": 0.0022,
      "step": 16160
    },
    {
      "epoch": 0.9586546446790841,
      "grad_norm": 7.627538204193115,
      "learning_rate": 9.187977853941472e-07,
      "loss": 0.204,
      "step": 16161
    },
    {
      "epoch": 0.9587139636967612,
      "grad_norm": 0.5693323612213135,
      "learning_rate": 9.174795676245717e-07,
      "loss": 0.0054,
      "step": 16162
    },
    {
      "epoch": 0.9587732827144383,
      "grad_norm": 2.940927505493164,
      "learning_rate": 9.161613498549961e-07,
      "loss": 0.0129,
      "step": 16163
    },
    {
      "epoch": 0.9588326017321153,
      "grad_norm": 5.362703800201416,
      "learning_rate": 9.148431320854206e-07,
      "loss": 0.057,
      "step": 16164
    },
    {
      "epoch": 0.9588919207497923,
      "grad_norm": 14.732117652893066,
      "learning_rate": 9.13524914315845e-07,
      "loss": 0.0927,
      "step": 16165
    },
    {
      "epoch": 0.9589512397674694,
      "grad_norm": 13.071375846862793,
      "learning_rate": 9.122066965462695e-07,
      "loss": 0.0938,
      "step": 16166
    },
    {
      "epoch": 0.9590105587851465,
      "grad_norm": 15.156435012817383,
      "learning_rate": 9.10888478776694e-07,
      "loss": 0.2321,
      "step": 16167
    },
    {
      "epoch": 0.9590698778028236,
      "grad_norm": 6.305444240570068,
      "learning_rate": 9.095702610071184e-07,
      "loss": 0.0505,
      "step": 16168
    },
    {
      "epoch": 0.9591291968205007,
      "grad_norm": 1.1175251007080078,
      "learning_rate": 9.082520432375429e-07,
      "loss": 0.0082,
      "step": 16169
    },
    {
      "epoch": 0.9591885158381778,
      "grad_norm": 13.932180404663086,
      "learning_rate": 9.069338254679674e-07,
      "loss": 0.1248,
      "step": 16170
    },
    {
      "epoch": 0.9592478348558547,
      "grad_norm": 0.11172330379486084,
      "learning_rate": 9.056156076983918e-07,
      "loss": 0.0018,
      "step": 16171
    },
    {
      "epoch": 0.9593071538735318,
      "grad_norm": 0.10364074259996414,
      "learning_rate": 9.042973899288162e-07,
      "loss": 0.0021,
      "step": 16172
    },
    {
      "epoch": 0.9593664728912089,
      "grad_norm": 0.4005710780620575,
      "learning_rate": 9.029791721592408e-07,
      "loss": 0.0037,
      "step": 16173
    },
    {
      "epoch": 0.959425791908886,
      "grad_norm": 0.35437342524528503,
      "learning_rate": 9.016609543896652e-07,
      "loss": 0.0067,
      "step": 16174
    },
    {
      "epoch": 0.9594851109265631,
      "grad_norm": 0.01459166593849659,
      "learning_rate": 9.003427366200896e-07,
      "loss": 0.0003,
      "step": 16175
    },
    {
      "epoch": 0.9595444299442402,
      "grad_norm": 2.4470160007476807,
      "learning_rate": 8.990245188505142e-07,
      "loss": 0.0705,
      "step": 16176
    },
    {
      "epoch": 0.9596037489619171,
      "grad_norm": 0.19333916902542114,
      "learning_rate": 8.977063010809386e-07,
      "loss": 0.0026,
      "step": 16177
    },
    {
      "epoch": 0.9596630679795942,
      "grad_norm": 0.17776942253112793,
      "learning_rate": 8.96388083311363e-07,
      "loss": 0.0018,
      "step": 16178
    },
    {
      "epoch": 0.9597223869972713,
      "grad_norm": 0.16332709789276123,
      "learning_rate": 8.950698655417877e-07,
      "loss": 0.0028,
      "step": 16179
    },
    {
      "epoch": 0.9597817060149484,
      "grad_norm": 2.5746195316314697,
      "learning_rate": 8.93751647772212e-07,
      "loss": 0.0157,
      "step": 16180
    },
    {
      "epoch": 0.9598410250326255,
      "grad_norm": 4.3140788078308105,
      "learning_rate": 8.924334300026364e-07,
      "loss": 0.1077,
      "step": 16181
    },
    {
      "epoch": 0.9599003440503026,
      "grad_norm": 0.8007919192314148,
      "learning_rate": 8.911152122330611e-07,
      "loss": 0.0091,
      "step": 16182
    },
    {
      "epoch": 0.9599596630679796,
      "grad_norm": 0.7820727825164795,
      "learning_rate": 8.897969944634855e-07,
      "loss": 0.0103,
      "step": 16183
    },
    {
      "epoch": 0.9600189820856566,
      "grad_norm": 1.1223622560501099,
      "learning_rate": 8.884787766939099e-07,
      "loss": 0.0056,
      "step": 16184
    },
    {
      "epoch": 0.9600783011033337,
      "grad_norm": 0.06555847078561783,
      "learning_rate": 8.871605589243345e-07,
      "loss": 0.001,
      "step": 16185
    },
    {
      "epoch": 0.9601376201210108,
      "grad_norm": 0.8531484603881836,
      "learning_rate": 8.858423411547589e-07,
      "loss": 0.0067,
      "step": 16186
    },
    {
      "epoch": 0.9601969391386879,
      "grad_norm": 0.029447147622704506,
      "learning_rate": 8.845241233851833e-07,
      "loss": 0.0006,
      "step": 16187
    },
    {
      "epoch": 0.960256258156365,
      "grad_norm": 70.15840911865234,
      "learning_rate": 8.832059056156078e-07,
      "loss": 0.3506,
      "step": 16188
    },
    {
      "epoch": 0.960315577174042,
      "grad_norm": 11.7805814743042,
      "learning_rate": 8.818876878460323e-07,
      "loss": 0.2986,
      "step": 16189
    },
    {
      "epoch": 0.9603748961917191,
      "grad_norm": 18.850051879882812,
      "learning_rate": 8.805694700764567e-07,
      "loss": 0.4997,
      "step": 16190
    },
    {
      "epoch": 0.9604342152093961,
      "grad_norm": 3.9959332942962646,
      "learning_rate": 8.792512523068812e-07,
      "loss": 0.0315,
      "step": 16191
    },
    {
      "epoch": 0.9604935342270732,
      "grad_norm": 94.60287475585938,
      "learning_rate": 8.779330345373057e-07,
      "loss": 0.6038,
      "step": 16192
    },
    {
      "epoch": 0.9605528532447503,
      "grad_norm": 0.12393474578857422,
      "learning_rate": 8.766148167677301e-07,
      "loss": 0.0014,
      "step": 16193
    },
    {
      "epoch": 0.9606121722624273,
      "grad_norm": 33.57622528076172,
      "learning_rate": 8.752965989981546e-07,
      "loss": 0.0954,
      "step": 16194
    },
    {
      "epoch": 0.9606714912801044,
      "grad_norm": 31.323898315429688,
      "learning_rate": 8.73978381228579e-07,
      "loss": 0.1881,
      "step": 16195
    },
    {
      "epoch": 0.9607308102977815,
      "grad_norm": 0.613318681716919,
      "learning_rate": 8.726601634590035e-07,
      "loss": 0.0081,
      "step": 16196
    },
    {
      "epoch": 0.9607901293154585,
      "grad_norm": 0.02091953158378601,
      "learning_rate": 8.71341945689428e-07,
      "loss": 0.0007,
      "step": 16197
    },
    {
      "epoch": 0.9608494483331356,
      "grad_norm": 10.929462432861328,
      "learning_rate": 8.700237279198524e-07,
      "loss": 0.9703,
      "step": 16198
    },
    {
      "epoch": 0.9609087673508127,
      "grad_norm": 3.1305553913116455,
      "learning_rate": 8.687055101502769e-07,
      "loss": 0.0416,
      "step": 16199
    },
    {
      "epoch": 0.9609680863684897,
      "grad_norm": 0.5686432719230652,
      "learning_rate": 8.673872923807014e-07,
      "loss": 0.0087,
      "step": 16200
    },
    {
      "epoch": 0.9610274053861668,
      "grad_norm": 0.0504915714263916,
      "learning_rate": 8.660690746111258e-07,
      "loss": 0.0013,
      "step": 16201
    },
    {
      "epoch": 0.9610867244038439,
      "grad_norm": 1.06662917137146,
      "learning_rate": 8.647508568415502e-07,
      "loss": 0.0142,
      "step": 16202
    },
    {
      "epoch": 0.961146043421521,
      "grad_norm": 0.1292799860239029,
      "learning_rate": 8.634326390719748e-07,
      "loss": 0.0012,
      "step": 16203
    },
    {
      "epoch": 0.961205362439198,
      "grad_norm": 0.9900754690170288,
      "learning_rate": 8.621144213023992e-07,
      "loss": 0.0044,
      "step": 16204
    },
    {
      "epoch": 0.961264681456875,
      "grad_norm": 0.021732015535235405,
      "learning_rate": 8.607962035328236e-07,
      "loss": 0.0006,
      "step": 16205
    },
    {
      "epoch": 0.9613240004745521,
      "grad_norm": 0.31789878010749817,
      "learning_rate": 8.594779857632482e-07,
      "loss": 0.0063,
      "step": 16206
    },
    {
      "epoch": 0.9613833194922292,
      "grad_norm": 17.27614974975586,
      "learning_rate": 8.581597679936726e-07,
      "loss": 0.5244,
      "step": 16207
    },
    {
      "epoch": 0.9614426385099063,
      "grad_norm": 0.5561959147453308,
      "learning_rate": 8.56841550224097e-07,
      "loss": 0.0067,
      "step": 16208
    },
    {
      "epoch": 0.9615019575275834,
      "grad_norm": 0.0850987657904625,
      "learning_rate": 8.555233324545216e-07,
      "loss": 0.002,
      "step": 16209
    },
    {
      "epoch": 0.9615612765452604,
      "grad_norm": 4.325990200042725,
      "learning_rate": 8.54205114684946e-07,
      "loss": 0.0869,
      "step": 16210
    },
    {
      "epoch": 0.9616205955629374,
      "grad_norm": 21.4696044921875,
      "learning_rate": 8.528868969153704e-07,
      "loss": 0.239,
      "step": 16211
    },
    {
      "epoch": 0.9616799145806145,
      "grad_norm": 0.4033117890357971,
      "learning_rate": 8.51568679145795e-07,
      "loss": 0.0044,
      "step": 16212
    },
    {
      "epoch": 0.9617392335982916,
      "grad_norm": 11.823328971862793,
      "learning_rate": 8.502504613762194e-07,
      "loss": 0.4281,
      "step": 16213
    },
    {
      "epoch": 0.9617985526159687,
      "grad_norm": 5.248660087585449,
      "learning_rate": 8.489322436066438e-07,
      "loss": 0.025,
      "step": 16214
    },
    {
      "epoch": 0.9618578716336458,
      "grad_norm": 0.01881466619670391,
      "learning_rate": 8.476140258370684e-07,
      "loss": 0.0005,
      "step": 16215
    },
    {
      "epoch": 0.9619171906513229,
      "grad_norm": 0.020544903352856636,
      "learning_rate": 8.462958080674928e-07,
      "loss": 0.0006,
      "step": 16216
    },
    {
      "epoch": 0.9619765096689998,
      "grad_norm": 0.03119552507996559,
      "learning_rate": 8.449775902979172e-07,
      "loss": 0.0004,
      "step": 16217
    },
    {
      "epoch": 0.9620358286866769,
      "grad_norm": 12.059318542480469,
      "learning_rate": 8.436593725283417e-07,
      "loss": 0.3756,
      "step": 16218
    },
    {
      "epoch": 0.962095147704354,
      "grad_norm": 2.5515482425689697,
      "learning_rate": 8.423411547587663e-07,
      "loss": 0.0101,
      "step": 16219
    },
    {
      "epoch": 0.9621544667220311,
      "grad_norm": 0.9673457145690918,
      "learning_rate": 8.410229369891907e-07,
      "loss": 0.0098,
      "step": 16220
    },
    {
      "epoch": 0.9622137857397082,
      "grad_norm": 4.553464412689209,
      "learning_rate": 8.397047192196152e-07,
      "loss": 0.1085,
      "step": 16221
    },
    {
      "epoch": 0.9622731047573853,
      "grad_norm": 0.02997952699661255,
      "learning_rate": 8.383865014500397e-07,
      "loss": 0.0006,
      "step": 16222
    },
    {
      "epoch": 0.9623324237750623,
      "grad_norm": 0.019886573776602745,
      "learning_rate": 8.370682836804641e-07,
      "loss": 0.0005,
      "step": 16223
    },
    {
      "epoch": 0.9623917427927393,
      "grad_norm": 21.181184768676758,
      "learning_rate": 8.357500659108886e-07,
      "loss": 0.3474,
      "step": 16224
    },
    {
      "epoch": 0.9624510618104164,
      "grad_norm": 0.13937418162822723,
      "learning_rate": 8.34431848141313e-07,
      "loss": 0.003,
      "step": 16225
    },
    {
      "epoch": 0.9625103808280935,
      "grad_norm": 0.21143600344657898,
      "learning_rate": 8.331136303717375e-07,
      "loss": 0.0031,
      "step": 16226
    },
    {
      "epoch": 0.9625696998457706,
      "grad_norm": 0.24159181118011475,
      "learning_rate": 8.31795412602162e-07,
      "loss": 0.0038,
      "step": 16227
    },
    {
      "epoch": 0.9626290188634476,
      "grad_norm": 39.60993576049805,
      "learning_rate": 8.304771948325864e-07,
      "loss": 0.888,
      "step": 16228
    },
    {
      "epoch": 0.9626883378811247,
      "grad_norm": 0.21164198219776154,
      "learning_rate": 8.291589770630108e-07,
      "loss": 0.0035,
      "step": 16229
    },
    {
      "epoch": 0.9627476568988017,
      "grad_norm": 23.227750778198242,
      "learning_rate": 8.278407592934354e-07,
      "loss": 0.8672,
      "step": 16230
    },
    {
      "epoch": 0.9628069759164788,
      "grad_norm": 1.8768625259399414,
      "learning_rate": 8.265225415238598e-07,
      "loss": 0.0146,
      "step": 16231
    },
    {
      "epoch": 0.9628662949341559,
      "grad_norm": 0.22818274796009064,
      "learning_rate": 8.252043237542842e-07,
      "loss": 0.0029,
      "step": 16232
    },
    {
      "epoch": 0.962925613951833,
      "grad_norm": 1.8241081237792969,
      "learning_rate": 8.238861059847088e-07,
      "loss": 0.0151,
      "step": 16233
    },
    {
      "epoch": 0.96298493296951,
      "grad_norm": 4.697529315948486,
      "learning_rate": 8.225678882151332e-07,
      "loss": 0.069,
      "step": 16234
    },
    {
      "epoch": 0.9630442519871871,
      "grad_norm": 15.340617179870605,
      "learning_rate": 8.212496704455576e-07,
      "loss": 0.7285,
      "step": 16235
    },
    {
      "epoch": 0.9631035710048642,
      "grad_norm": 0.016830770298838615,
      "learning_rate": 8.199314526759822e-07,
      "loss": 0.0004,
      "step": 16236
    },
    {
      "epoch": 0.9631628900225412,
      "grad_norm": 30.05327796936035,
      "learning_rate": 8.186132349064066e-07,
      "loss": 0.6404,
      "step": 16237
    },
    {
      "epoch": 0.9632222090402183,
      "grad_norm": 0.13824142515659332,
      "learning_rate": 8.17295017136831e-07,
      "loss": 0.0015,
      "step": 16238
    },
    {
      "epoch": 0.9632815280578954,
      "grad_norm": 2.7311952114105225,
      "learning_rate": 8.159767993672556e-07,
      "loss": 0.0287,
      "step": 16239
    },
    {
      "epoch": 0.9633408470755724,
      "grad_norm": 0.009905092418193817,
      "learning_rate": 8.1465858159768e-07,
      "loss": 0.0002,
      "step": 16240
    },
    {
      "epoch": 0.9634001660932495,
      "grad_norm": 0.6466019153594971,
      "learning_rate": 8.133403638281044e-07,
      "loss": 0.009,
      "step": 16241
    },
    {
      "epoch": 0.9634594851109266,
      "grad_norm": 1.814988136291504,
      "learning_rate": 8.12022146058529e-07,
      "loss": 0.035,
      "step": 16242
    },
    {
      "epoch": 0.9635188041286036,
      "grad_norm": 17.937519073486328,
      "learning_rate": 8.107039282889534e-07,
      "loss": 1.3092,
      "step": 16243
    },
    {
      "epoch": 0.9635781231462807,
      "grad_norm": 0.14184758067131042,
      "learning_rate": 8.093857105193778e-07,
      "loss": 0.0022,
      "step": 16244
    },
    {
      "epoch": 0.9636374421639577,
      "grad_norm": 0.2616497278213501,
      "learning_rate": 8.080674927498023e-07,
      "loss": 0.0031,
      "step": 16245
    },
    {
      "epoch": 0.9636967611816348,
      "grad_norm": 0.069576196372509,
      "learning_rate": 8.067492749802268e-07,
      "loss": 0.0016,
      "step": 16246
    },
    {
      "epoch": 0.9637560801993119,
      "grad_norm": 0.08164661377668381,
      "learning_rate": 8.054310572106512e-07,
      "loss": 0.0016,
      "step": 16247
    },
    {
      "epoch": 0.963815399216989,
      "grad_norm": 10.90000057220459,
      "learning_rate": 8.041128394410757e-07,
      "loss": 0.4014,
      "step": 16248
    },
    {
      "epoch": 0.9638747182346661,
      "grad_norm": 11.507530212402344,
      "learning_rate": 8.027946216715002e-07,
      "loss": 0.2466,
      "step": 16249
    },
    {
      "epoch": 0.9639340372523431,
      "grad_norm": 4.2640228271484375,
      "learning_rate": 8.014764039019246e-07,
      "loss": 0.0995,
      "step": 16250
    },
    {
      "epoch": 0.9639933562700201,
      "grad_norm": 6.250158309936523,
      "learning_rate": 8.001581861323491e-07,
      "loss": 0.076,
      "step": 16251
    },
    {
      "epoch": 0.9640526752876972,
      "grad_norm": 9.42575454711914,
      "learning_rate": 7.988399683627735e-07,
      "loss": 0.3775,
      "step": 16252
    },
    {
      "epoch": 0.9641119943053743,
      "grad_norm": 0.007519423495978117,
      "learning_rate": 7.97521750593198e-07,
      "loss": 0.0002,
      "step": 16253
    },
    {
      "epoch": 0.9641713133230514,
      "grad_norm": 0.00444185733795166,
      "learning_rate": 7.962035328236225e-07,
      "loss": 0.0001,
      "step": 16254
    },
    {
      "epoch": 0.9642306323407285,
      "grad_norm": 1.2152513265609741,
      "learning_rate": 7.948853150540469e-07,
      "loss": 0.009,
      "step": 16255
    },
    {
      "epoch": 0.9642899513584055,
      "grad_norm": 0.012062415480613708,
      "learning_rate": 7.935670972844714e-07,
      "loss": 0.0002,
      "step": 16256
    },
    {
      "epoch": 0.9643492703760825,
      "grad_norm": 0.0923716202378273,
      "learning_rate": 7.92248879514896e-07,
      "loss": 0.0011,
      "step": 16257
    },
    {
      "epoch": 0.9644085893937596,
      "grad_norm": 0.01960265263915062,
      "learning_rate": 7.909306617453203e-07,
      "loss": 0.0005,
      "step": 16258
    },
    {
      "epoch": 0.9644679084114367,
      "grad_norm": 7.676118850708008,
      "learning_rate": 7.896124439757447e-07,
      "loss": 0.1323,
      "step": 16259
    },
    {
      "epoch": 0.9645272274291138,
      "grad_norm": 0.10589995980262756,
      "learning_rate": 7.882942262061694e-07,
      "loss": 0.0008,
      "step": 16260
    },
    {
      "epoch": 0.9645865464467909,
      "grad_norm": 0.043477267026901245,
      "learning_rate": 7.869760084365938e-07,
      "loss": 0.001,
      "step": 16261
    },
    {
      "epoch": 0.964645865464468,
      "grad_norm": 0.012652617879211903,
      "learning_rate": 7.856577906670182e-07,
      "loss": 0.0003,
      "step": 16262
    },
    {
      "epoch": 0.9647051844821449,
      "grad_norm": 13.091132164001465,
      "learning_rate": 7.843395728974428e-07,
      "loss": 0.306,
      "step": 16263
    },
    {
      "epoch": 0.964764503499822,
      "grad_norm": 0.45410841703414917,
      "learning_rate": 7.830213551278672e-07,
      "loss": 0.0045,
      "step": 16264
    },
    {
      "epoch": 0.9648238225174991,
      "grad_norm": 44.53219985961914,
      "learning_rate": 7.817031373582916e-07,
      "loss": 0.8049,
      "step": 16265
    },
    {
      "epoch": 0.9648831415351762,
      "grad_norm": 0.02002161182463169,
      "learning_rate": 7.803849195887162e-07,
      "loss": 0.0005,
      "step": 16266
    },
    {
      "epoch": 0.9649424605528533,
      "grad_norm": 5.222603797912598,
      "learning_rate": 7.790667018191406e-07,
      "loss": 0.1291,
      "step": 16267
    },
    {
      "epoch": 0.9650017795705303,
      "grad_norm": 0.031189221888780594,
      "learning_rate": 7.77748484049565e-07,
      "loss": 0.0006,
      "step": 16268
    },
    {
      "epoch": 0.9650610985882074,
      "grad_norm": 20.728559494018555,
      "learning_rate": 7.764302662799896e-07,
      "loss": 0.3718,
      "step": 16269
    },
    {
      "epoch": 0.9651204176058844,
      "grad_norm": 0.31937795877456665,
      "learning_rate": 7.75112048510414e-07,
      "loss": 0.001,
      "step": 16270
    },
    {
      "epoch": 0.9651797366235615,
      "grad_norm": 7.265303134918213,
      "learning_rate": 7.737938307408384e-07,
      "loss": 0.7656,
      "step": 16271
    },
    {
      "epoch": 0.9652390556412386,
      "grad_norm": 0.034272607415914536,
      "learning_rate": 7.72475612971263e-07,
      "loss": 0.0007,
      "step": 16272
    },
    {
      "epoch": 0.9652983746589157,
      "grad_norm": 0.04134255647659302,
      "learning_rate": 7.711573952016874e-07,
      "loss": 0.0003,
      "step": 16273
    },
    {
      "epoch": 0.9653576936765927,
      "grad_norm": 0.01682564802467823,
      "learning_rate": 7.698391774321118e-07,
      "loss": 0.0003,
      "step": 16274
    },
    {
      "epoch": 0.9654170126942698,
      "grad_norm": 2.2818992137908936,
      "learning_rate": 7.685209596625363e-07,
      "loss": 0.0179,
      "step": 16275
    },
    {
      "epoch": 0.9654763317119468,
      "grad_norm": 0.011514613404870033,
      "learning_rate": 7.672027418929608e-07,
      "loss": 0.0003,
      "step": 16276
    },
    {
      "epoch": 0.9655356507296239,
      "grad_norm": 0.16023437678813934,
      "learning_rate": 7.658845241233852e-07,
      "loss": 0.0013,
      "step": 16277
    },
    {
      "epoch": 0.965594969747301,
      "grad_norm": 2.1160950660705566,
      "learning_rate": 7.645663063538097e-07,
      "loss": 0.013,
      "step": 16278
    },
    {
      "epoch": 0.965654288764978,
      "grad_norm": 0.0551118403673172,
      "learning_rate": 7.632480885842342e-07,
      "loss": 0.0009,
      "step": 16279
    },
    {
      "epoch": 0.9657136077826551,
      "grad_norm": 0.00481907045468688,
      "learning_rate": 7.619298708146586e-07,
      "loss": 0.0001,
      "step": 16280
    },
    {
      "epoch": 0.9657729268003322,
      "grad_norm": 0.0161755234003067,
      "learning_rate": 7.606116530450831e-07,
      "loss": 0.0002,
      "step": 16281
    },
    {
      "epoch": 0.9658322458180093,
      "grad_norm": 6.558807373046875,
      "learning_rate": 7.592934352755075e-07,
      "loss": 0.1732,
      "step": 16282
    },
    {
      "epoch": 0.9658915648356863,
      "grad_norm": 26.31756591796875,
      "learning_rate": 7.57975217505932e-07,
      "loss": 0.0552,
      "step": 16283
    },
    {
      "epoch": 0.9659508838533634,
      "grad_norm": 0.039771851152181625,
      "learning_rate": 7.566569997363565e-07,
      "loss": 0.0007,
      "step": 16284
    },
    {
      "epoch": 0.9660102028710404,
      "grad_norm": 0.25643450021743774,
      "learning_rate": 7.553387819667809e-07,
      "loss": 0.0024,
      "step": 16285
    },
    {
      "epoch": 0.9660695218887175,
      "grad_norm": 7.333605766296387,
      "learning_rate": 7.540205641972054e-07,
      "loss": 0.3527,
      "step": 16286
    },
    {
      "epoch": 0.9661288409063946,
      "grad_norm": 1.0580919981002808,
      "learning_rate": 7.527023464276299e-07,
      "loss": 0.0138,
      "step": 16287
    },
    {
      "epoch": 0.9661881599240717,
      "grad_norm": 0.8513107895851135,
      "learning_rate": 7.513841286580543e-07,
      "loss": 0.009,
      "step": 16288
    },
    {
      "epoch": 0.9662474789417487,
      "grad_norm": 0.26459160447120667,
      "learning_rate": 7.500659108884787e-07,
      "loss": 0.0033,
      "step": 16289
    },
    {
      "epoch": 0.9663067979594258,
      "grad_norm": 16.357807159423828,
      "learning_rate": 7.487476931189033e-07,
      "loss": 0.0775,
      "step": 16290
    },
    {
      "epoch": 0.9663661169771028,
      "grad_norm": 0.023173365741968155,
      "learning_rate": 7.474294753493277e-07,
      "loss": 0.0005,
      "step": 16291
    },
    {
      "epoch": 0.9664254359947799,
      "grad_norm": 14.169755935668945,
      "learning_rate": 7.461112575797521e-07,
      "loss": 1.3055,
      "step": 16292
    },
    {
      "epoch": 0.966484755012457,
      "grad_norm": 5.601105690002441,
      "learning_rate": 7.447930398101767e-07,
      "loss": 0.0559,
      "step": 16293
    },
    {
      "epoch": 0.9665440740301341,
      "grad_norm": 7.330540180206299,
      "learning_rate": 7.434748220406011e-07,
      "loss": 0.0782,
      "step": 16294
    },
    {
      "epoch": 0.9666033930478112,
      "grad_norm": 10.210704803466797,
      "learning_rate": 7.421566042710255e-07,
      "loss": 0.0559,
      "step": 16295
    },
    {
      "epoch": 0.9666627120654881,
      "grad_norm": 3.0445289611816406,
      "learning_rate": 7.408383865014502e-07,
      "loss": 0.0437,
      "step": 16296
    },
    {
      "epoch": 0.9667220310831652,
      "grad_norm": 5.363447189331055,
      "learning_rate": 7.395201687318746e-07,
      "loss": 0.1361,
      "step": 16297
    },
    {
      "epoch": 0.9667813501008423,
      "grad_norm": 7.258955955505371,
      "learning_rate": 7.38201950962299e-07,
      "loss": 0.0795,
      "step": 16298
    },
    {
      "epoch": 0.9668406691185194,
      "grad_norm": 0.04464713856577873,
      "learning_rate": 7.368837331927236e-07,
      "loss": 0.0006,
      "step": 16299
    },
    {
      "epoch": 0.9668999881361965,
      "grad_norm": 0.06779926270246506,
      "learning_rate": 7.35565515423148e-07,
      "loss": 0.0012,
      "step": 16300
    },
    {
      "epoch": 0.9669593071538736,
      "grad_norm": 0.055748727172613144,
      "learning_rate": 7.342472976535725e-07,
      "loss": 0.0008,
      "step": 16301
    },
    {
      "epoch": 0.9670186261715505,
      "grad_norm": 7.732570648193359,
      "learning_rate": 7.32929079883997e-07,
      "loss": 0.5789,
      "step": 16302
    },
    {
      "epoch": 0.9670779451892276,
      "grad_norm": 12.860113143920898,
      "learning_rate": 7.316108621144214e-07,
      "loss": 0.615,
      "step": 16303
    },
    {
      "epoch": 0.9671372642069047,
      "grad_norm": 0.009153713472187519,
      "learning_rate": 7.302926443448459e-07,
      "loss": 0.0003,
      "step": 16304
    },
    {
      "epoch": 0.9671965832245818,
      "grad_norm": 0.11573562771081924,
      "learning_rate": 7.289744265752703e-07,
      "loss": 0.002,
      "step": 16305
    },
    {
      "epoch": 0.9672559022422589,
      "grad_norm": 1.9878160953521729,
      "learning_rate": 7.276562088056948e-07,
      "loss": 0.0122,
      "step": 16306
    },
    {
      "epoch": 0.967315221259936,
      "grad_norm": 2.0427072048187256,
      "learning_rate": 7.263379910361193e-07,
      "loss": 0.0257,
      "step": 16307
    },
    {
      "epoch": 0.967374540277613,
      "grad_norm": 0.0922980010509491,
      "learning_rate": 7.250197732665437e-07,
      "loss": 0.0015,
      "step": 16308
    },
    {
      "epoch": 0.96743385929529,
      "grad_norm": 0.5902493000030518,
      "learning_rate": 7.237015554969682e-07,
      "loss": 0.002,
      "step": 16309
    },
    {
      "epoch": 0.9674931783129671,
      "grad_norm": 0.03566400334239006,
      "learning_rate": 7.223833377273927e-07,
      "loss": 0.001,
      "step": 16310
    },
    {
      "epoch": 0.9675524973306442,
      "grad_norm": 2.7333481311798096,
      "learning_rate": 7.210651199578171e-07,
      "loss": 0.0883,
      "step": 16311
    },
    {
      "epoch": 0.9676118163483213,
      "grad_norm": 6.013026714324951,
      "learning_rate": 7.197469021882415e-07,
      "loss": 0.2716,
      "step": 16312
    },
    {
      "epoch": 0.9676711353659984,
      "grad_norm": 0.04628926143050194,
      "learning_rate": 7.184286844186661e-07,
      "loss": 0.0007,
      "step": 16313
    },
    {
      "epoch": 0.9677304543836754,
      "grad_norm": 0.00600261939689517,
      "learning_rate": 7.171104666490905e-07,
      "loss": 0.0001,
      "step": 16314
    },
    {
      "epoch": 0.9677897734013525,
      "grad_norm": 0.04488397762179375,
      "learning_rate": 7.157922488795149e-07,
      "loss": 0.0011,
      "step": 16315
    },
    {
      "epoch": 0.9678490924190295,
      "grad_norm": 0.04955097660422325,
      "learning_rate": 7.144740311099395e-07,
      "loss": 0.0012,
      "step": 16316
    },
    {
      "epoch": 0.9679084114367066,
      "grad_norm": 7.329621315002441,
      "learning_rate": 7.131558133403639e-07,
      "loss": 0.1259,
      "step": 16317
    },
    {
      "epoch": 0.9679677304543837,
      "grad_norm": 11.191032409667969,
      "learning_rate": 7.118375955707883e-07,
      "loss": 0.0717,
      "step": 16318
    },
    {
      "epoch": 0.9680270494720608,
      "grad_norm": 0.28583094477653503,
      "learning_rate": 7.105193778012129e-07,
      "loss": 0.0023,
      "step": 16319
    },
    {
      "epoch": 0.9680863684897378,
      "grad_norm": 6.824085235595703,
      "learning_rate": 7.092011600316373e-07,
      "loss": 0.2012,
      "step": 16320
    },
    {
      "epoch": 0.9681456875074149,
      "grad_norm": 19.29973793029785,
      "learning_rate": 7.078829422620617e-07,
      "loss": 0.2652,
      "step": 16321
    },
    {
      "epoch": 0.9682050065250919,
      "grad_norm": 0.007021726109087467,
      "learning_rate": 7.065647244924863e-07,
      "loss": 0.0002,
      "step": 16322
    },
    {
      "epoch": 0.968264325542769,
      "grad_norm": 0.00910758227109909,
      "learning_rate": 7.052465067229107e-07,
      "loss": 0.0003,
      "step": 16323
    },
    {
      "epoch": 0.9683236445604461,
      "grad_norm": 0.08682918548583984,
      "learning_rate": 7.039282889533351e-07,
      "loss": 0.0015,
      "step": 16324
    },
    {
      "epoch": 0.9683829635781231,
      "grad_norm": 0.1967959851026535,
      "learning_rate": 7.026100711837597e-07,
      "loss": 0.0008,
      "step": 16325
    },
    {
      "epoch": 0.9684422825958002,
      "grad_norm": 0.8427593111991882,
      "learning_rate": 7.012918534141841e-07,
      "loss": 0.0174,
      "step": 16326
    },
    {
      "epoch": 0.9685016016134773,
      "grad_norm": 3.4428069591522217,
      "learning_rate": 6.999736356446085e-07,
      "loss": 0.0414,
      "step": 16327
    },
    {
      "epoch": 0.9685609206311544,
      "grad_norm": 1.7199323177337646,
      "learning_rate": 6.98655417875033e-07,
      "loss": 0.0255,
      "step": 16328
    },
    {
      "epoch": 0.9686202396488314,
      "grad_norm": 0.16366805136203766,
      "learning_rate": 6.973372001054575e-07,
      "loss": 0.0019,
      "step": 16329
    },
    {
      "epoch": 0.9686795586665085,
      "grad_norm": 4.39982795715332,
      "learning_rate": 6.960189823358819e-07,
      "loss": 0.011,
      "step": 16330
    },
    {
      "epoch": 0.9687388776841855,
      "grad_norm": 4.9843621253967285,
      "learning_rate": 6.947007645663064e-07,
      "loss": 0.1044,
      "step": 16331
    },
    {
      "epoch": 0.9687981967018626,
      "grad_norm": 8.06826114654541,
      "learning_rate": 6.933825467967309e-07,
      "loss": 0.0475,
      "step": 16332
    },
    {
      "epoch": 0.9688575157195397,
      "grad_norm": 5.139230251312256,
      "learning_rate": 6.920643290271553e-07,
      "loss": 0.0674,
      "step": 16333
    },
    {
      "epoch": 0.9689168347372168,
      "grad_norm": 23.19317626953125,
      "learning_rate": 6.907461112575798e-07,
      "loss": 0.395,
      "step": 16334
    },
    {
      "epoch": 0.9689761537548938,
      "grad_norm": 10.412919044494629,
      "learning_rate": 6.894278934880042e-07,
      "loss": 0.6687,
      "step": 16335
    },
    {
      "epoch": 0.9690354727725708,
      "grad_norm": 0.016856973990797997,
      "learning_rate": 6.881096757184288e-07,
      "loss": 0.0005,
      "step": 16336
    },
    {
      "epoch": 0.9690947917902479,
      "grad_norm": 1.5251946449279785,
      "learning_rate": 6.867914579488533e-07,
      "loss": 0.0244,
      "step": 16337
    },
    {
      "epoch": 0.969154110807925,
      "grad_norm": 0.017936259508132935,
      "learning_rate": 6.854732401792777e-07,
      "loss": 0.0005,
      "step": 16338
    },
    {
      "epoch": 0.9692134298256021,
      "grad_norm": 15.270734786987305,
      "learning_rate": 6.841550224097021e-07,
      "loss": 0.3285,
      "step": 16339
    },
    {
      "epoch": 0.9692727488432792,
      "grad_norm": 15.047517776489258,
      "learning_rate": 6.828368046401267e-07,
      "loss": 0.2567,
      "step": 16340
    },
    {
      "epoch": 0.9693320678609563,
      "grad_norm": 0.06916682422161102,
      "learning_rate": 6.815185868705511e-07,
      "loss": 0.0014,
      "step": 16341
    },
    {
      "epoch": 0.9693913868786332,
      "grad_norm": 7.607852935791016,
      "learning_rate": 6.802003691009755e-07,
      "loss": 0.1472,
      "step": 16342
    },
    {
      "epoch": 0.9694507058963103,
      "grad_norm": 0.022905966266989708,
      "learning_rate": 6.788821513314001e-07,
      "loss": 0.0004,
      "step": 16343
    },
    {
      "epoch": 0.9695100249139874,
      "grad_norm": 8.590229034423828,
      "learning_rate": 6.775639335618245e-07,
      "loss": 0.1631,
      "step": 16344
    },
    {
      "epoch": 0.9695693439316645,
      "grad_norm": 0.02193889394402504,
      "learning_rate": 6.762457157922489e-07,
      "loss": 0.0004,
      "step": 16345
    },
    {
      "epoch": 0.9696286629493416,
      "grad_norm": 0.8305962085723877,
      "learning_rate": 6.749274980226735e-07,
      "loss": 0.008,
      "step": 16346
    },
    {
      "epoch": 0.9696879819670187,
      "grad_norm": 18.18979263305664,
      "learning_rate": 6.736092802530979e-07,
      "loss": 0.5875,
      "step": 16347
    },
    {
      "epoch": 0.9697473009846957,
      "grad_norm": 0.03047548048198223,
      "learning_rate": 6.722910624835223e-07,
      "loss": 0.0007,
      "step": 16348
    },
    {
      "epoch": 0.9698066200023727,
      "grad_norm": 0.009243788197636604,
      "learning_rate": 6.709728447139469e-07,
      "loss": 0.0003,
      "step": 16349
    },
    {
      "epoch": 0.9698659390200498,
      "grad_norm": 14.814188003540039,
      "learning_rate": 6.696546269443713e-07,
      "loss": 0.6162,
      "step": 16350
    },
    {
      "epoch": 0.9699252580377269,
      "grad_norm": 15.210001945495605,
      "learning_rate": 6.683364091747957e-07,
      "loss": 0.0698,
      "step": 16351
    },
    {
      "epoch": 0.969984577055404,
      "grad_norm": 0.07043334096670151,
      "learning_rate": 6.670181914052203e-07,
      "loss": 0.0006,
      "step": 16352
    },
    {
      "epoch": 0.9700438960730811,
      "grad_norm": 0.18162666261196136,
      "learning_rate": 6.656999736356447e-07,
      "loss": 0.0027,
      "step": 16353
    },
    {
      "epoch": 0.9701032150907581,
      "grad_norm": 2.030465841293335,
      "learning_rate": 6.643817558660691e-07,
      "loss": 0.0162,
      "step": 16354
    },
    {
      "epoch": 0.9701625341084351,
      "grad_norm": 0.004681479651480913,
      "learning_rate": 6.630635380964936e-07,
      "loss": 0.0001,
      "step": 16355
    },
    {
      "epoch": 0.9702218531261122,
      "grad_norm": 3.745251417160034,
      "learning_rate": 6.617453203269181e-07,
      "loss": 0.0229,
      "step": 16356
    },
    {
      "epoch": 0.9702811721437893,
      "grad_norm": 0.16810907423496246,
      "learning_rate": 6.604271025573425e-07,
      "loss": 0.0031,
      "step": 16357
    },
    {
      "epoch": 0.9703404911614664,
      "grad_norm": 3.557136058807373,
      "learning_rate": 6.59108884787767e-07,
      "loss": 0.4119,
      "step": 16358
    },
    {
      "epoch": 0.9703998101791435,
      "grad_norm": 0.11497391015291214,
      "learning_rate": 6.577906670181915e-07,
      "loss": 0.0014,
      "step": 16359
    },
    {
      "epoch": 0.9704591291968205,
      "grad_norm": 2.0116779804229736,
      "learning_rate": 6.564724492486159e-07,
      "loss": 0.022,
      "step": 16360
    },
    {
      "epoch": 0.9705184482144976,
      "grad_norm": 0.015654344111680984,
      "learning_rate": 6.551542314790404e-07,
      "loss": 0.0003,
      "step": 16361
    },
    {
      "epoch": 0.9705777672321746,
      "grad_norm": 0.179783433675766,
      "learning_rate": 6.538360137094648e-07,
      "loss": 0.0027,
      "step": 16362
    },
    {
      "epoch": 0.9706370862498517,
      "grad_norm": 0.1439015418291092,
      "learning_rate": 6.525177959398893e-07,
      "loss": 0.0024,
      "step": 16363
    },
    {
      "epoch": 0.9706964052675288,
      "grad_norm": 0.09017729759216309,
      "learning_rate": 6.511995781703138e-07,
      "loss": 0.001,
      "step": 16364
    },
    {
      "epoch": 0.9707557242852058,
      "grad_norm": 2.1916253566741943,
      "learning_rate": 6.498813604007382e-07,
      "loss": 0.0113,
      "step": 16365
    },
    {
      "epoch": 0.9708150433028829,
      "grad_norm": 0.0895838737487793,
      "learning_rate": 6.485631426311627e-07,
      "loss": 0.0007,
      "step": 16366
    },
    {
      "epoch": 0.97087436232056,
      "grad_norm": 0.15707242488861084,
      "learning_rate": 6.472449248615872e-07,
      "loss": 0.0018,
      "step": 16367
    },
    {
      "epoch": 0.970933681338237,
      "grad_norm": 0.05640888214111328,
      "learning_rate": 6.459267070920116e-07,
      "loss": 0.0008,
      "step": 16368
    },
    {
      "epoch": 0.9709930003559141,
      "grad_norm": 0.5115936398506165,
      "learning_rate": 6.44608489322436e-07,
      "loss": 0.0045,
      "step": 16369
    },
    {
      "epoch": 0.9710523193735912,
      "grad_norm": 12.317693710327148,
      "learning_rate": 6.432902715528606e-07,
      "loss": 0.6433,
      "step": 16370
    },
    {
      "epoch": 0.9711116383912682,
      "grad_norm": 0.7308189272880554,
      "learning_rate": 6.41972053783285e-07,
      "loss": 0.0069,
      "step": 16371
    },
    {
      "epoch": 0.9711709574089453,
      "grad_norm": 5.922469139099121,
      "learning_rate": 6.406538360137094e-07,
      "loss": 0.6143,
      "step": 16372
    },
    {
      "epoch": 0.9712302764266224,
      "grad_norm": 0.01975395902991295,
      "learning_rate": 6.39335618244134e-07,
      "loss": 0.0005,
      "step": 16373
    },
    {
      "epoch": 0.9712895954442995,
      "grad_norm": 0.02141045406460762,
      "learning_rate": 6.380174004745585e-07,
      "loss": 0.0003,
      "step": 16374
    },
    {
      "epoch": 0.9713489144619765,
      "grad_norm": 7.2951154708862305,
      "learning_rate": 6.366991827049828e-07,
      "loss": 0.1772,
      "step": 16375
    },
    {
      "epoch": 0.9714082334796535,
      "grad_norm": 3.4666059017181396,
      "learning_rate": 6.353809649354075e-07,
      "loss": 0.0192,
      "step": 16376
    },
    {
      "epoch": 0.9714675524973306,
      "grad_norm": 0.3300516605377197,
      "learning_rate": 6.340627471658319e-07,
      "loss": 0.0069,
      "step": 16377
    },
    {
      "epoch": 0.9715268715150077,
      "grad_norm": 6.681051731109619,
      "learning_rate": 6.327445293962563e-07,
      "loss": 0.1652,
      "step": 16378
    },
    {
      "epoch": 0.9715861905326848,
      "grad_norm": 21.13579750061035,
      "learning_rate": 6.314263116266809e-07,
      "loss": 0.8198,
      "step": 16379
    },
    {
      "epoch": 0.9716455095503619,
      "grad_norm": 0.105470672249794,
      "learning_rate": 6.301080938571053e-07,
      "loss": 0.0015,
      "step": 16380
    },
    {
      "epoch": 0.9717048285680389,
      "grad_norm": 15.757888793945312,
      "learning_rate": 6.287898760875297e-07,
      "loss": 0.5428,
      "step": 16381
    },
    {
      "epoch": 0.9717641475857159,
      "grad_norm": 0.25721827149391174,
      "learning_rate": 6.274716583179543e-07,
      "loss": 0.0028,
      "step": 16382
    },
    {
      "epoch": 0.971823466603393,
      "grad_norm": 0.1051289439201355,
      "learning_rate": 6.261534405483787e-07,
      "loss": 0.0009,
      "step": 16383
    },
    {
      "epoch": 0.9718827856210701,
      "grad_norm": 0.022735770791769028,
      "learning_rate": 6.248352227788032e-07,
      "loss": 0.0003,
      "step": 16384
    },
    {
      "epoch": 0.9719421046387472,
      "grad_norm": 0.015386680141091347,
      "learning_rate": 6.235170050092276e-07,
      "loss": 0.0006,
      "step": 16385
    },
    {
      "epoch": 0.9720014236564243,
      "grad_norm": 17.686779022216797,
      "learning_rate": 6.221987872396521e-07,
      "loss": 0.4407,
      "step": 16386
    },
    {
      "epoch": 0.9720607426741014,
      "grad_norm": 0.3848770260810852,
      "learning_rate": 6.208805694700765e-07,
      "loss": 0.0032,
      "step": 16387
    },
    {
      "epoch": 0.9721200616917783,
      "grad_norm": 0.3279126286506653,
      "learning_rate": 6.19562351700501e-07,
      "loss": 0.0042,
      "step": 16388
    },
    {
      "epoch": 0.9721793807094554,
      "grad_norm": 44.71095657348633,
      "learning_rate": 6.182441339309255e-07,
      "loss": 0.0654,
      "step": 16389
    },
    {
      "epoch": 0.9722386997271325,
      "grad_norm": 0.019477983936667442,
      "learning_rate": 6.169259161613499e-07,
      "loss": 0.0006,
      "step": 16390
    },
    {
      "epoch": 0.9722980187448096,
      "grad_norm": 0.14364716410636902,
      "learning_rate": 6.156076983917744e-07,
      "loss": 0.0015,
      "step": 16391
    },
    {
      "epoch": 0.9723573377624867,
      "grad_norm": 12.630380630493164,
      "learning_rate": 6.142894806221988e-07,
      "loss": 0.3606,
      "step": 16392
    },
    {
      "epoch": 0.9724166567801638,
      "grad_norm": 0.024568777531385422,
      "learning_rate": 6.129712628526233e-07,
      "loss": 0.0006,
      "step": 16393
    },
    {
      "epoch": 0.9724759757978408,
      "grad_norm": 0.03492572903633118,
      "learning_rate": 6.116530450830477e-07,
      "loss": 0.0007,
      "step": 16394
    },
    {
      "epoch": 0.9725352948155178,
      "grad_norm": 0.07549145817756653,
      "learning_rate": 6.103348273134722e-07,
      "loss": 0.0009,
      "step": 16395
    },
    {
      "epoch": 0.9725946138331949,
      "grad_norm": 6.866258144378662,
      "learning_rate": 6.090166095438967e-07,
      "loss": 0.074,
      "step": 16396
    },
    {
      "epoch": 0.972653932850872,
      "grad_norm": 0.023244841024279594,
      "learning_rate": 6.076983917743211e-07,
      "loss": 0.0005,
      "step": 16397
    },
    {
      "epoch": 0.9727132518685491,
      "grad_norm": 3.721371650695801,
      "learning_rate": 6.063801740047456e-07,
      "loss": 0.0572,
      "step": 16398
    },
    {
      "epoch": 0.9727725708862262,
      "grad_norm": 0.0050086393021047115,
      "learning_rate": 6.050619562351701e-07,
      "loss": 0.0002,
      "step": 16399
    },
    {
      "epoch": 0.9728318899039032,
      "grad_norm": 0.02444007433950901,
      "learning_rate": 6.037437384655945e-07,
      "loss": 0.0007,
      "step": 16400
    },
    {
      "epoch": 0.9728912089215802,
      "grad_norm": 0.19577708840370178,
      "learning_rate": 6.02425520696019e-07,
      "loss": 0.0009,
      "step": 16401
    },
    {
      "epoch": 0.9729505279392573,
      "grad_norm": 4.50404691696167,
      "learning_rate": 6.011073029264435e-07,
      "loss": 0.0523,
      "step": 16402
    },
    {
      "epoch": 0.9730098469569344,
      "grad_norm": 0.08582966774702072,
      "learning_rate": 5.997890851568679e-07,
      "loss": 0.001,
      "step": 16403
    },
    {
      "epoch": 0.9730691659746115,
      "grad_norm": 0.025416970252990723,
      "learning_rate": 5.984708673872924e-07,
      "loss": 0.0004,
      "step": 16404
    },
    {
      "epoch": 0.9731284849922885,
      "grad_norm": 0.3704165518283844,
      "learning_rate": 5.971526496177169e-07,
      "loss": 0.0048,
      "step": 16405
    },
    {
      "epoch": 0.9731878040099656,
      "grad_norm": 2.298098564147949,
      "learning_rate": 5.958344318481413e-07,
      "loss": 0.0898,
      "step": 16406
    },
    {
      "epoch": 0.9732471230276427,
      "grad_norm": 0.2397901564836502,
      "learning_rate": 5.945162140785658e-07,
      "loss": 0.0028,
      "step": 16407
    },
    {
      "epoch": 0.9733064420453197,
      "grad_norm": 5.66522216796875,
      "learning_rate": 5.931979963089903e-07,
      "loss": 0.0613,
      "step": 16408
    },
    {
      "epoch": 0.9733657610629968,
      "grad_norm": 11.731990814208984,
      "learning_rate": 5.918797785394147e-07,
      "loss": 0.1876,
      "step": 16409
    },
    {
      "epoch": 0.9734250800806739,
      "grad_norm": 0.009452084079384804,
      "learning_rate": 5.905615607698392e-07,
      "loss": 0.0003,
      "step": 16410
    },
    {
      "epoch": 0.9734843990983509,
      "grad_norm": 0.3430579900741577,
      "learning_rate": 5.892433430002637e-07,
      "loss": 0.0022,
      "step": 16411
    },
    {
      "epoch": 0.973543718116028,
      "grad_norm": 2.5962555408477783,
      "learning_rate": 5.879251252306881e-07,
      "loss": 0.0167,
      "step": 16412
    },
    {
      "epoch": 0.9736030371337051,
      "grad_norm": 0.03833393007516861,
      "learning_rate": 5.866069074611127e-07,
      "loss": 0.0008,
      "step": 16413
    },
    {
      "epoch": 0.9736623561513821,
      "grad_norm": 0.017852557823061943,
      "learning_rate": 5.852886896915372e-07,
      "loss": 0.0004,
      "step": 16414
    },
    {
      "epoch": 0.9737216751690592,
      "grad_norm": 0.8590336441993713,
      "learning_rate": 5.839704719219616e-07,
      "loss": 0.017,
      "step": 16415
    },
    {
      "epoch": 0.9737809941867362,
      "grad_norm": 1.1604617834091187,
      "learning_rate": 5.826522541523861e-07,
      "loss": 0.0092,
      "step": 16416
    },
    {
      "epoch": 0.9738403132044133,
      "grad_norm": 0.21097959578037262,
      "learning_rate": 5.813340363828105e-07,
      "loss": 0.0025,
      "step": 16417
    },
    {
      "epoch": 0.9738996322220904,
      "grad_norm": 0.47211650013923645,
      "learning_rate": 5.80015818613235e-07,
      "loss": 0.0034,
      "step": 16418
    },
    {
      "epoch": 0.9739589512397675,
      "grad_norm": 0.07166002690792084,
      "learning_rate": 5.786976008436595e-07,
      "loss": 0.0011,
      "step": 16419
    },
    {
      "epoch": 0.9740182702574446,
      "grad_norm": 24.820545196533203,
      "learning_rate": 5.773793830740839e-07,
      "loss": 1.144,
      "step": 16420
    },
    {
      "epoch": 0.9740775892751216,
      "grad_norm": 2.1160898208618164,
      "learning_rate": 5.760611653045084e-07,
      "loss": 0.0621,
      "step": 16421
    },
    {
      "epoch": 0.9741369082927986,
      "grad_norm": 0.4461136758327484,
      "learning_rate": 5.747429475349328e-07,
      "loss": 0.005,
      "step": 16422
    },
    {
      "epoch": 0.9741962273104757,
      "grad_norm": 15.190763473510742,
      "learning_rate": 5.734247297653573e-07,
      "loss": 0.3523,
      "step": 16423
    },
    {
      "epoch": 0.9742555463281528,
      "grad_norm": 0.019539469853043556,
      "learning_rate": 5.721065119957817e-07,
      "loss": 0.0004,
      "step": 16424
    },
    {
      "epoch": 0.9743148653458299,
      "grad_norm": 0.7432742714881897,
      "learning_rate": 5.707882942262062e-07,
      "loss": 0.002,
      "step": 16425
    },
    {
      "epoch": 0.974374184363507,
      "grad_norm": 0.015331512317061424,
      "learning_rate": 5.694700764566307e-07,
      "loss": 0.0004,
      "step": 16426
    },
    {
      "epoch": 0.9744335033811841,
      "grad_norm": 19.01565170288086,
      "learning_rate": 5.681518586870551e-07,
      "loss": 0.5,
      "step": 16427
    },
    {
      "epoch": 0.974492822398861,
      "grad_norm": 11.909299850463867,
      "learning_rate": 5.668336409174796e-07,
      "loss": 0.1626,
      "step": 16428
    },
    {
      "epoch": 0.9745521414165381,
      "grad_norm": 2.8881800174713135,
      "learning_rate": 5.655154231479041e-07,
      "loss": 0.0386,
      "step": 16429
    },
    {
      "epoch": 0.9746114604342152,
      "grad_norm": 15.097310066223145,
      "learning_rate": 5.641972053783285e-07,
      "loss": 0.2416,
      "step": 16430
    },
    {
      "epoch": 0.9746707794518923,
      "grad_norm": 0.04327796772122383,
      "learning_rate": 5.62878987608753e-07,
      "loss": 0.0005,
      "step": 16431
    },
    {
      "epoch": 0.9747300984695694,
      "grad_norm": 0.07011515647172928,
      "learning_rate": 5.615607698391775e-07,
      "loss": 0.0008,
      "step": 16432
    },
    {
      "epoch": 0.9747894174872465,
      "grad_norm": 8.471747398376465,
      "learning_rate": 5.602425520696019e-07,
      "loss": 0.1741,
      "step": 16433
    },
    {
      "epoch": 0.9748487365049234,
      "grad_norm": 0.03527221828699112,
      "learning_rate": 5.589243343000264e-07,
      "loss": 0.0005,
      "step": 16434
    },
    {
      "epoch": 0.9749080555226005,
      "grad_norm": 0.019044190645217896,
      "learning_rate": 5.576061165304509e-07,
      "loss": 0.0004,
      "step": 16435
    },
    {
      "epoch": 0.9749673745402776,
      "grad_norm": 0.09120836853981018,
      "learning_rate": 5.562878987608753e-07,
      "loss": 0.0015,
      "step": 16436
    },
    {
      "epoch": 0.9750266935579547,
      "grad_norm": 0.015466652810573578,
      "learning_rate": 5.549696809912998e-07,
      "loss": 0.0004,
      "step": 16437
    },
    {
      "epoch": 0.9750860125756318,
      "grad_norm": 18.256532669067383,
      "learning_rate": 5.536514632217243e-07,
      "loss": 0.1418,
      "step": 16438
    },
    {
      "epoch": 0.9751453315933089,
      "grad_norm": 9.924761772155762,
      "learning_rate": 5.523332454521487e-07,
      "loss": 0.4236,
      "step": 16439
    },
    {
      "epoch": 0.9752046506109859,
      "grad_norm": 0.0332980714738369,
      "learning_rate": 5.510150276825732e-07,
      "loss": 0.0005,
      "step": 16440
    },
    {
      "epoch": 0.9752639696286629,
      "grad_norm": 14.988512992858887,
      "learning_rate": 5.496968099129977e-07,
      "loss": 0.2076,
      "step": 16441
    },
    {
      "epoch": 0.97532328864634,
      "grad_norm": 10.272249221801758,
      "learning_rate": 5.483785921434221e-07,
      "loss": 0.7854,
      "step": 16442
    },
    {
      "epoch": 0.9753826076640171,
      "grad_norm": 39.04734420776367,
      "learning_rate": 5.470603743738466e-07,
      "loss": 1.0974,
      "step": 16443
    },
    {
      "epoch": 0.9754419266816942,
      "grad_norm": 0.05374866724014282,
      "learning_rate": 5.457421566042711e-07,
      "loss": 0.0008,
      "step": 16444
    },
    {
      "epoch": 0.9755012456993712,
      "grad_norm": 0.34422194957733154,
      "learning_rate": 5.444239388346955e-07,
      "loss": 0.0056,
      "step": 16445
    },
    {
      "epoch": 0.9755605647170483,
      "grad_norm": 2.8195018768310547,
      "learning_rate": 5.4310572106512e-07,
      "loss": 0.011,
      "step": 16446
    },
    {
      "epoch": 0.9756198837347253,
      "grad_norm": 0.10882840305566788,
      "learning_rate": 5.417875032955444e-07,
      "loss": 0.0014,
      "step": 16447
    },
    {
      "epoch": 0.9756792027524024,
      "grad_norm": 1.140275239944458,
      "learning_rate": 5.404692855259689e-07,
      "loss": 0.016,
      "step": 16448
    },
    {
      "epoch": 0.9757385217700795,
      "grad_norm": 10.227039337158203,
      "learning_rate": 5.391510677563933e-07,
      "loss": 0.1203,
      "step": 16449
    },
    {
      "epoch": 0.9757978407877566,
      "grad_norm": 10.85009765625,
      "learning_rate": 5.378328499868178e-07,
      "loss": 0.3847,
      "step": 16450
    },
    {
      "epoch": 0.9758571598054336,
      "grad_norm": 0.4025317430496216,
      "learning_rate": 5.365146322172424e-07,
      "loss": 0.0028,
      "step": 16451
    },
    {
      "epoch": 0.9759164788231107,
      "grad_norm": 10.292108535766602,
      "learning_rate": 5.351964144476667e-07,
      "loss": 0.7055,
      "step": 16452
    },
    {
      "epoch": 0.9759757978407878,
      "grad_norm": 1.2911221981048584,
      "learning_rate": 5.338781966780913e-07,
      "loss": 0.0147,
      "step": 16453
    },
    {
      "epoch": 0.9760351168584648,
      "grad_norm": 52.304786682128906,
      "learning_rate": 5.325599789085157e-07,
      "loss": 2.2765,
      "step": 16454
    },
    {
      "epoch": 0.9760944358761419,
      "grad_norm": 10.619792938232422,
      "learning_rate": 5.312417611389402e-07,
      "loss": 0.4148,
      "step": 16455
    },
    {
      "epoch": 0.976153754893819,
      "grad_norm": 0.06411765515804291,
      "learning_rate": 5.299235433693647e-07,
      "loss": 0.001,
      "step": 16456
    },
    {
      "epoch": 0.976213073911496,
      "grad_norm": 0.488266259431839,
      "learning_rate": 5.286053255997891e-07,
      "loss": 0.0052,
      "step": 16457
    },
    {
      "epoch": 0.9762723929291731,
      "grad_norm": 1.4861929416656494,
      "learning_rate": 5.272871078302136e-07,
      "loss": 0.0135,
      "step": 16458
    },
    {
      "epoch": 0.9763317119468502,
      "grad_norm": 1.5212512016296387,
      "learning_rate": 5.259688900606381e-07,
      "loss": 0.0081,
      "step": 16459
    },
    {
      "epoch": 0.9763910309645272,
      "grad_norm": 11.474404335021973,
      "learning_rate": 5.246506722910625e-07,
      "loss": 0.0958,
      "step": 16460
    },
    {
      "epoch": 0.9764503499822043,
      "grad_norm": 3.101822853088379,
      "learning_rate": 5.23332454521487e-07,
      "loss": 0.0427,
      "step": 16461
    },
    {
      "epoch": 0.9765096689998813,
      "grad_norm": 0.058348413556814194,
      "learning_rate": 5.220142367519115e-07,
      "loss": 0.0009,
      "step": 16462
    },
    {
      "epoch": 0.9765689880175584,
      "grad_norm": 1.7617360353469849,
      "learning_rate": 5.206960189823359e-07,
      "loss": 0.0123,
      "step": 16463
    },
    {
      "epoch": 0.9766283070352355,
      "grad_norm": 0.7688526511192322,
      "learning_rate": 5.193778012127604e-07,
      "loss": 0.0061,
      "step": 16464
    },
    {
      "epoch": 0.9766876260529126,
      "grad_norm": 0.3461131453514099,
      "learning_rate": 5.180595834431849e-07,
      "loss": 0.0058,
      "step": 16465
    },
    {
      "epoch": 0.9767469450705897,
      "grad_norm": 0.04463459551334381,
      "learning_rate": 5.167413656736093e-07,
      "loss": 0.001,
      "step": 16466
    },
    {
      "epoch": 0.9768062640882667,
      "grad_norm": 0.5529000163078308,
      "learning_rate": 5.154231479040338e-07,
      "loss": 0.0064,
      "step": 16467
    },
    {
      "epoch": 0.9768655831059437,
      "grad_norm": 2.500033378601074,
      "learning_rate": 5.141049301344583e-07,
      "loss": 0.0247,
      "step": 16468
    },
    {
      "epoch": 0.9769249021236208,
      "grad_norm": 0.013751182705163956,
      "learning_rate": 5.127867123648828e-07,
      "loss": 0.0002,
      "step": 16469
    },
    {
      "epoch": 0.9769842211412979,
      "grad_norm": 0.008808987215161324,
      "learning_rate": 5.114684945953072e-07,
      "loss": 0.0002,
      "step": 16470
    },
    {
      "epoch": 0.977043540158975,
      "grad_norm": 3.5643160343170166,
      "learning_rate": 5.101502768257317e-07,
      "loss": 0.0179,
      "step": 16471
    },
    {
      "epoch": 0.9771028591766521,
      "grad_norm": 6.209362030029297,
      "learning_rate": 5.088320590561561e-07,
      "loss": 0.0485,
      "step": 16472
    },
    {
      "epoch": 0.9771621781943292,
      "grad_norm": 22.16225814819336,
      "learning_rate": 5.075138412865806e-07,
      "loss": 1.313,
      "step": 16473
    },
    {
      "epoch": 0.9772214972120061,
      "grad_norm": 0.01292781438678503,
      "learning_rate": 5.061956235170051e-07,
      "loss": 0.0002,
      "step": 16474
    },
    {
      "epoch": 0.9772808162296832,
      "grad_norm": 0.014445881359279156,
      "learning_rate": 5.048774057474295e-07,
      "loss": 0.0003,
      "step": 16475
    },
    {
      "epoch": 0.9773401352473603,
      "grad_norm": 0.7318101525306702,
      "learning_rate": 5.03559187977854e-07,
      "loss": 0.004,
      "step": 16476
    },
    {
      "epoch": 0.9773994542650374,
      "grad_norm": 0.7840045690536499,
      "learning_rate": 5.022409702082784e-07,
      "loss": 0.0119,
      "step": 16477
    },
    {
      "epoch": 0.9774587732827145,
      "grad_norm": 9.2589750289917,
      "learning_rate": 5.009227524387029e-07,
      "loss": 0.2794,
      "step": 16478
    },
    {
      "epoch": 0.9775180923003916,
      "grad_norm": 9.515874862670898,
      "learning_rate": 4.996045346691273e-07,
      "loss": 0.3415,
      "step": 16479
    },
    {
      "epoch": 0.9775774113180685,
      "grad_norm": 6.641185760498047,
      "learning_rate": 4.982863168995518e-07,
      "loss": 0.029,
      "step": 16480
    },
    {
      "epoch": 0.9776367303357456,
      "grad_norm": 0.06908135861158371,
      "learning_rate": 4.969680991299763e-07,
      "loss": 0.0012,
      "step": 16481
    },
    {
      "epoch": 0.9776960493534227,
      "grad_norm": 0.02723073773086071,
      "learning_rate": 4.956498813604007e-07,
      "loss": 0.0007,
      "step": 16482
    },
    {
      "epoch": 0.9777553683710998,
      "grad_norm": 1.1033401489257812,
      "learning_rate": 4.943316635908252e-07,
      "loss": 0.0079,
      "step": 16483
    },
    {
      "epoch": 0.9778146873887769,
      "grad_norm": 0.05237153545022011,
      "learning_rate": 4.930134458212497e-07,
      "loss": 0.0014,
      "step": 16484
    },
    {
      "epoch": 0.9778740064064539,
      "grad_norm": 1.2559661865234375,
      "learning_rate": 4.916952280516741e-07,
      "loss": 0.0229,
      "step": 16485
    },
    {
      "epoch": 0.977933325424131,
      "grad_norm": 5.677048206329346,
      "learning_rate": 4.903770102820986e-07,
      "loss": 0.105,
      "step": 16486
    },
    {
      "epoch": 0.977992644441808,
      "grad_norm": 7.228744029998779,
      "learning_rate": 4.890587925125231e-07,
      "loss": 0.284,
      "step": 16487
    },
    {
      "epoch": 0.9780519634594851,
      "grad_norm": 0.2493942677974701,
      "learning_rate": 4.877405747429475e-07,
      "loss": 0.0022,
      "step": 16488
    },
    {
      "epoch": 0.9781112824771622,
      "grad_norm": 0.027905112132430077,
      "learning_rate": 4.86422356973372e-07,
      "loss": 0.0005,
      "step": 16489
    },
    {
      "epoch": 0.9781706014948393,
      "grad_norm": 3.8504788875579834,
      "learning_rate": 4.851041392037966e-07,
      "loss": 0.0414,
      "step": 16490
    },
    {
      "epoch": 0.9782299205125163,
      "grad_norm": 0.005204640328884125,
      "learning_rate": 4.83785921434221e-07,
      "loss": 0.0001,
      "step": 16491
    },
    {
      "epoch": 0.9782892395301934,
      "grad_norm": 0.024340016767382622,
      "learning_rate": 4.824677036646455e-07,
      "loss": 0.0009,
      "step": 16492
    },
    {
      "epoch": 0.9783485585478704,
      "grad_norm": 12.005291938781738,
      "learning_rate": 4.8114948589507e-07,
      "loss": 0.0781,
      "step": 16493
    },
    {
      "epoch": 0.9784078775655475,
      "grad_norm": 0.2744878828525543,
      "learning_rate": 4.798312681254944e-07,
      "loss": 0.0026,
      "step": 16494
    },
    {
      "epoch": 0.9784671965832246,
      "grad_norm": 0.10427479445934296,
      "learning_rate": 4.785130503559189e-07,
      "loss": 0.0007,
      "step": 16495
    },
    {
      "epoch": 0.9785265156009016,
      "grad_norm": 0.10177603363990784,
      "learning_rate": 4.771948325863434e-07,
      "loss": 0.0014,
      "step": 16496
    },
    {
      "epoch": 0.9785858346185787,
      "grad_norm": 0.01632724516093731,
      "learning_rate": 4.7587661481676777e-07,
      "loss": 0.0004,
      "step": 16497
    },
    {
      "epoch": 0.9786451536362558,
      "grad_norm": 0.018166663125157356,
      "learning_rate": 4.745583970471922e-07,
      "loss": 0.0004,
      "step": 16498
    },
    {
      "epoch": 0.9787044726539329,
      "grad_norm": 0.038142748177051544,
      "learning_rate": 4.732401792776167e-07,
      "loss": 0.0006,
      "step": 16499
    },
    {
      "epoch": 0.9787637916716099,
      "grad_norm": 0.07577402889728546,
      "learning_rate": 4.719219615080411e-07,
      "loss": 0.0012,
      "step": 16500
    },
    {
      "epoch": 0.978823110689287,
      "grad_norm": 1.031173825263977,
      "learning_rate": 4.7060374373846563e-07,
      "loss": 0.0096,
      "step": 16501
    },
    {
      "epoch": 0.978882429706964,
      "grad_norm": 0.01823854073882103,
      "learning_rate": 4.6928552596889013e-07,
      "loss": 0.0004,
      "step": 16502
    },
    {
      "epoch": 0.9789417487246411,
      "grad_norm": 0.04706084728240967,
      "learning_rate": 4.6796730819931453e-07,
      "loss": 0.0009,
      "step": 16503
    },
    {
      "epoch": 0.9790010677423182,
      "grad_norm": 11.269729614257812,
      "learning_rate": 4.6664909042973904e-07,
      "loss": 1.6846,
      "step": 16504
    },
    {
      "epoch": 0.9790603867599953,
      "grad_norm": 0.8322052359580994,
      "learning_rate": 4.6533087266016354e-07,
      "loss": 0.0145,
      "step": 16505
    },
    {
      "epoch": 0.9791197057776723,
      "grad_norm": 1.6129611730575562,
      "learning_rate": 4.6401265489058794e-07,
      "loss": 0.0213,
      "step": 16506
    },
    {
      "epoch": 0.9791790247953494,
      "grad_norm": 0.3971524238586426,
      "learning_rate": 4.6269443712101244e-07,
      "loss": 0.0013,
      "step": 16507
    },
    {
      "epoch": 0.9792383438130264,
      "grad_norm": 0.04497148469090462,
      "learning_rate": 4.613762193514369e-07,
      "loss": 0.001,
      "step": 16508
    },
    {
      "epoch": 0.9792976628307035,
      "grad_norm": 0.01297982968389988,
      "learning_rate": 4.6005800158186135e-07,
      "loss": 0.0003,
      "step": 16509
    },
    {
      "epoch": 0.9793569818483806,
      "grad_norm": 16.68779754638672,
      "learning_rate": 4.5873978381228585e-07,
      "loss": 1.1641,
      "step": 16510
    },
    {
      "epoch": 0.9794163008660577,
      "grad_norm": 12.283122062683105,
      "learning_rate": 4.574215660427103e-07,
      "loss": 0.1429,
      "step": 16511
    },
    {
      "epoch": 0.9794756198837348,
      "grad_norm": 13.284655570983887,
      "learning_rate": 4.5610334827313476e-07,
      "loss": 0.599,
      "step": 16512
    },
    {
      "epoch": 0.9795349389014117,
      "grad_norm": 10.908125877380371,
      "learning_rate": 4.547851305035592e-07,
      "loss": 0.149,
      "step": 16513
    },
    {
      "epoch": 0.9795942579190888,
      "grad_norm": 5.904818058013916,
      "learning_rate": 4.534669127339837e-07,
      "loss": 0.2173,
      "step": 16514
    },
    {
      "epoch": 0.9796535769367659,
      "grad_norm": 0.22571270167827606,
      "learning_rate": 4.521486949644081e-07,
      "loss": 0.0033,
      "step": 16515
    },
    {
      "epoch": 0.979712895954443,
      "grad_norm": 6.058774948120117,
      "learning_rate": 4.508304771948326e-07,
      "loss": 0.0159,
      "step": 16516
    },
    {
      "epoch": 0.9797722149721201,
      "grad_norm": 5.157289028167725,
      "learning_rate": 4.495122594252571e-07,
      "loss": 0.1031,
      "step": 16517
    },
    {
      "epoch": 0.9798315339897972,
      "grad_norm": 0.0798264741897583,
      "learning_rate": 4.481940416556815e-07,
      "loss": 0.0007,
      "step": 16518
    },
    {
      "epoch": 0.9798908530074742,
      "grad_norm": 10.45186710357666,
      "learning_rate": 4.46875823886106e-07,
      "loss": 0.2338,
      "step": 16519
    },
    {
      "epoch": 0.9799501720251512,
      "grad_norm": 0.0984790176153183,
      "learning_rate": 4.4555760611653053e-07,
      "loss": 0.0013,
      "step": 16520
    },
    {
      "epoch": 0.9800094910428283,
      "grad_norm": 0.10784834623336792,
      "learning_rate": 4.4423938834695493e-07,
      "loss": 0.0016,
      "step": 16521
    },
    {
      "epoch": 0.9800688100605054,
      "grad_norm": 0.006925355643033981,
      "learning_rate": 4.4292117057737943e-07,
      "loss": 0.0002,
      "step": 16522
    },
    {
      "epoch": 0.9801281290781825,
      "grad_norm": 5.015237331390381,
      "learning_rate": 4.416029528078039e-07,
      "loss": 0.0993,
      "step": 16523
    },
    {
      "epoch": 0.9801874480958596,
      "grad_norm": 27.488061904907227,
      "learning_rate": 4.4028473503822834e-07,
      "loss": 0.7511,
      "step": 16524
    },
    {
      "epoch": 0.9802467671135366,
      "grad_norm": 6.245671272277832,
      "learning_rate": 4.3896651726865284e-07,
      "loss": 0.3974,
      "step": 16525
    },
    {
      "epoch": 0.9803060861312136,
      "grad_norm": 57.493125915527344,
      "learning_rate": 4.376482994990773e-07,
      "loss": 0.6493,
      "step": 16526
    },
    {
      "epoch": 0.9803654051488907,
      "grad_norm": 0.15597034990787506,
      "learning_rate": 4.3633008172950175e-07,
      "loss": 0.0017,
      "step": 16527
    },
    {
      "epoch": 0.9804247241665678,
      "grad_norm": 7.402353763580322,
      "learning_rate": 4.350118639599262e-07,
      "loss": 0.0277,
      "step": 16528
    },
    {
      "epoch": 0.9804840431842449,
      "grad_norm": 0.04148934409022331,
      "learning_rate": 4.336936461903507e-07,
      "loss": 0.0006,
      "step": 16529
    },
    {
      "epoch": 0.980543362201922,
      "grad_norm": 3.1626930236816406,
      "learning_rate": 4.323754284207751e-07,
      "loss": 0.0437,
      "step": 16530
    },
    {
      "epoch": 0.980602681219599,
      "grad_norm": 56.62350845336914,
      "learning_rate": 4.310572106511996e-07,
      "loss": 0.2618,
      "step": 16531
    },
    {
      "epoch": 0.9806620002372761,
      "grad_norm": 0.47986364364624023,
      "learning_rate": 4.297389928816241e-07,
      "loss": 0.0052,
      "step": 16532
    },
    {
      "epoch": 0.9807213192549531,
      "grad_norm": 1.0548471212387085,
      "learning_rate": 4.284207751120485e-07,
      "loss": 0.0049,
      "step": 16533
    },
    {
      "epoch": 0.9807806382726302,
      "grad_norm": 12.702747344970703,
      "learning_rate": 4.27102557342473e-07,
      "loss": 0.0262,
      "step": 16534
    },
    {
      "epoch": 0.9808399572903073,
      "grad_norm": 2.088772773742676,
      "learning_rate": 4.257843395728975e-07,
      "loss": 0.0258,
      "step": 16535
    },
    {
      "epoch": 0.9808992763079843,
      "grad_norm": 0.06839822232723236,
      "learning_rate": 4.244661218033219e-07,
      "loss": 0.0014,
      "step": 16536
    },
    {
      "epoch": 0.9809585953256614,
      "grad_norm": 0.35050150752067566,
      "learning_rate": 4.231479040337464e-07,
      "loss": 0.0019,
      "step": 16537
    },
    {
      "epoch": 0.9810179143433385,
      "grad_norm": 7.970123291015625,
      "learning_rate": 4.218296862641709e-07,
      "loss": 0.1229,
      "step": 16538
    },
    {
      "epoch": 0.9810772333610155,
      "grad_norm": 1.6891916990280151,
      "learning_rate": 4.205114684945953e-07,
      "loss": 0.0311,
      "step": 16539
    },
    {
      "epoch": 0.9811365523786926,
      "grad_norm": 5.56175422668457,
      "learning_rate": 4.1919325072501983e-07,
      "loss": 0.0408,
      "step": 16540
    },
    {
      "epoch": 0.9811958713963697,
      "grad_norm": 0.9212081432342529,
      "learning_rate": 4.178750329554443e-07,
      "loss": 0.008,
      "step": 16541
    },
    {
      "epoch": 0.9812551904140467,
      "grad_norm": 0.026819942519068718,
      "learning_rate": 4.1655681518586873e-07,
      "loss": 0.0004,
      "step": 16542
    },
    {
      "epoch": 0.9813145094317238,
      "grad_norm": 14.330839157104492,
      "learning_rate": 4.152385974162932e-07,
      "loss": 0.4049,
      "step": 16543
    },
    {
      "epoch": 0.9813738284494009,
      "grad_norm": 0.045467887073755264,
      "learning_rate": 4.139203796467177e-07,
      "loss": 0.0006,
      "step": 16544
    },
    {
      "epoch": 0.981433147467078,
      "grad_norm": 0.09882679581642151,
      "learning_rate": 4.126021618771421e-07,
      "loss": 0.0016,
      "step": 16545
    },
    {
      "epoch": 0.981492466484755,
      "grad_norm": 0.02829889953136444,
      "learning_rate": 4.112839441075666e-07,
      "loss": 0.0005,
      "step": 16546
    },
    {
      "epoch": 0.981551785502432,
      "grad_norm": 0.02525143511593342,
      "learning_rate": 4.099657263379911e-07,
      "loss": 0.0007,
      "step": 16547
    },
    {
      "epoch": 0.9816111045201091,
      "grad_norm": 0.4728648364543915,
      "learning_rate": 4.086475085684155e-07,
      "loss": 0.0047,
      "step": 16548
    },
    {
      "epoch": 0.9816704235377862,
      "grad_norm": 2.0939459800720215,
      "learning_rate": 4.0732929079884e-07,
      "loss": 0.0212,
      "step": 16549
    },
    {
      "epoch": 0.9817297425554633,
      "grad_norm": 17.41649055480957,
      "learning_rate": 4.060110730292645e-07,
      "loss": 0.6035,
      "step": 16550
    },
    {
      "epoch": 0.9817890615731404,
      "grad_norm": 22.46145248413086,
      "learning_rate": 4.046928552596889e-07,
      "loss": 0.1671,
      "step": 16551
    },
    {
      "epoch": 0.9818483805908175,
      "grad_norm": 0.09147541970014572,
      "learning_rate": 4.033746374901134e-07,
      "loss": 0.0013,
      "step": 16552
    },
    {
      "epoch": 0.9819076996084944,
      "grad_norm": 9.939496994018555,
      "learning_rate": 4.0205641972053786e-07,
      "loss": 0.1226,
      "step": 16553
    },
    {
      "epoch": 0.9819670186261715,
      "grad_norm": 8.920239448547363,
      "learning_rate": 4.007382019509623e-07,
      "loss": 0.4215,
      "step": 16554
    },
    {
      "epoch": 0.9820263376438486,
      "grad_norm": 0.013422385789453983,
      "learning_rate": 3.9941998418138677e-07,
      "loss": 0.0003,
      "step": 16555
    },
    {
      "epoch": 0.9820856566615257,
      "grad_norm": 0.1455291509628296,
      "learning_rate": 3.9810176641181127e-07,
      "loss": 0.0016,
      "step": 16556
    },
    {
      "epoch": 0.9821449756792028,
      "grad_norm": 0.023370467126369476,
      "learning_rate": 3.967835486422357e-07,
      "loss": 0.0005,
      "step": 16557
    },
    {
      "epoch": 0.9822042946968799,
      "grad_norm": 0.01394458394497633,
      "learning_rate": 3.954653308726602e-07,
      "loss": 0.0003,
      "step": 16558
    },
    {
      "epoch": 0.9822636137145568,
      "grad_norm": 0.01850958541035652,
      "learning_rate": 3.941471131030847e-07,
      "loss": 0.0004,
      "step": 16559
    },
    {
      "epoch": 0.9823229327322339,
      "grad_norm": 0.024037592113018036,
      "learning_rate": 3.928288953335091e-07,
      "loss": 0.0004,
      "step": 16560
    },
    {
      "epoch": 0.982382251749911,
      "grad_norm": 0.1565188318490982,
      "learning_rate": 3.915106775639336e-07,
      "loss": 0.0041,
      "step": 16561
    },
    {
      "epoch": 0.9824415707675881,
      "grad_norm": 7.879676818847656,
      "learning_rate": 3.901924597943581e-07,
      "loss": 0.098,
      "step": 16562
    },
    {
      "epoch": 0.9825008897852652,
      "grad_norm": 51.90363693237305,
      "learning_rate": 3.888742420247825e-07,
      "loss": 0.1887,
      "step": 16563
    },
    {
      "epoch": 0.9825602088029423,
      "grad_norm": 12.100496292114258,
      "learning_rate": 3.87556024255207e-07,
      "loss": 0.4548,
      "step": 16564
    },
    {
      "epoch": 0.9826195278206193,
      "grad_norm": 0.6925472021102905,
      "learning_rate": 3.862378064856315e-07,
      "loss": 0.009,
      "step": 16565
    },
    {
      "epoch": 0.9826788468382963,
      "grad_norm": 1.1210386753082275,
      "learning_rate": 3.849195887160559e-07,
      "loss": 0.012,
      "step": 16566
    },
    {
      "epoch": 0.9827381658559734,
      "grad_norm": 0.29925236105918884,
      "learning_rate": 3.836013709464804e-07,
      "loss": 0.0026,
      "step": 16567
    },
    {
      "epoch": 0.9827974848736505,
      "grad_norm": 1.0848543643951416,
      "learning_rate": 3.8228315317690485e-07,
      "loss": 0.0094,
      "step": 16568
    },
    {
      "epoch": 0.9828568038913276,
      "grad_norm": 0.012159204110503197,
      "learning_rate": 3.809649354073293e-07,
      "loss": 0.0006,
      "step": 16569
    },
    {
      "epoch": 0.9829161229090047,
      "grad_norm": 1.4075219631195068,
      "learning_rate": 3.7964671763775375e-07,
      "loss": 0.003,
      "step": 16570
    },
    {
      "epoch": 0.9829754419266817,
      "grad_norm": 3.8127684593200684,
      "learning_rate": 3.7832849986817826e-07,
      "loss": 0.0247,
      "step": 16571
    },
    {
      "epoch": 0.9830347609443587,
      "grad_norm": 0.01928078942000866,
      "learning_rate": 3.770102820986027e-07,
      "loss": 0.0002,
      "step": 16572
    },
    {
      "epoch": 0.9830940799620358,
      "grad_norm": 0.3526494801044464,
      "learning_rate": 3.7569206432902716e-07,
      "loss": 0.0035,
      "step": 16573
    },
    {
      "epoch": 0.9831533989797129,
      "grad_norm": 0.01274169608950615,
      "learning_rate": 3.7437384655945167e-07,
      "loss": 0.0004,
      "step": 16574
    },
    {
      "epoch": 0.98321271799739,
      "grad_norm": 0.8657920956611633,
      "learning_rate": 3.7305562878987607e-07,
      "loss": 0.0092,
      "step": 16575
    },
    {
      "epoch": 0.983272037015067,
      "grad_norm": 0.11130154132843018,
      "learning_rate": 3.7173741102030057e-07,
      "loss": 0.0013,
      "step": 16576
    },
    {
      "epoch": 0.9833313560327441,
      "grad_norm": 0.02317838743329048,
      "learning_rate": 3.704191932507251e-07,
      "loss": 0.0005,
      "step": 16577
    },
    {
      "epoch": 0.9833906750504212,
      "grad_norm": 0.2028205245733261,
      "learning_rate": 3.691009754811495e-07,
      "loss": 0.0038,
      "step": 16578
    },
    {
      "epoch": 0.9834499940680982,
      "grad_norm": 0.4875221252441406,
      "learning_rate": 3.67782757711574e-07,
      "loss": 0.0112,
      "step": 16579
    },
    {
      "epoch": 0.9835093130857753,
      "grad_norm": 0.13390472531318665,
      "learning_rate": 3.664645399419985e-07,
      "loss": 0.0016,
      "step": 16580
    },
    {
      "epoch": 0.9835686321034524,
      "grad_norm": 0.1992790549993515,
      "learning_rate": 3.6514632217242294e-07,
      "loss": 0.0019,
      "step": 16581
    },
    {
      "epoch": 0.9836279511211294,
      "grad_norm": 0.2205183058977127,
      "learning_rate": 3.638281044028474e-07,
      "loss": 0.0046,
      "step": 16582
    },
    {
      "epoch": 0.9836872701388065,
      "grad_norm": 8.627826690673828,
      "learning_rate": 3.6250988663327184e-07,
      "loss": 0.397,
      "step": 16583
    },
    {
      "epoch": 0.9837465891564836,
      "grad_norm": 0.04726925119757652,
      "learning_rate": 3.6119166886369634e-07,
      "loss": 0.0007,
      "step": 16584
    },
    {
      "epoch": 0.9838059081741606,
      "grad_norm": 0.06743668764829636,
      "learning_rate": 3.5987345109412074e-07,
      "loss": 0.0012,
      "step": 16585
    },
    {
      "epoch": 0.9838652271918377,
      "grad_norm": 0.2028338611125946,
      "learning_rate": 3.5855523332454525e-07,
      "loss": 0.0007,
      "step": 16586
    },
    {
      "epoch": 0.9839245462095147,
      "grad_norm": 12.033016204833984,
      "learning_rate": 3.5723701555496975e-07,
      "loss": 0.3618,
      "step": 16587
    },
    {
      "epoch": 0.9839838652271918,
      "grad_norm": 0.22235098481178284,
      "learning_rate": 3.5591879778539415e-07,
      "loss": 0.0011,
      "step": 16588
    },
    {
      "epoch": 0.9840431842448689,
      "grad_norm": 0.01051681861281395,
      "learning_rate": 3.5460058001581866e-07,
      "loss": 0.0003,
      "step": 16589
    },
    {
      "epoch": 0.984102503262546,
      "grad_norm": 0.5119831562042236,
      "learning_rate": 3.5328236224624316e-07,
      "loss": 0.0067,
      "step": 16590
    },
    {
      "epoch": 0.9841618222802231,
      "grad_norm": 0.016324913129210472,
      "learning_rate": 3.5196414447666756e-07,
      "loss": 0.0004,
      "step": 16591
    },
    {
      "epoch": 0.9842211412979001,
      "grad_norm": 24.776514053344727,
      "learning_rate": 3.5064592670709206e-07,
      "loss": 0.3427,
      "step": 16592
    },
    {
      "epoch": 0.9842804603155771,
      "grad_norm": 0.3636864125728607,
      "learning_rate": 3.493277089375165e-07,
      "loss": 0.0035,
      "step": 16593
    },
    {
      "epoch": 0.9843397793332542,
      "grad_norm": 0.008110634051263332,
      "learning_rate": 3.4800949116794097e-07,
      "loss": 0.0002,
      "step": 16594
    },
    {
      "epoch": 0.9843990983509313,
      "grad_norm": 0.027408137917518616,
      "learning_rate": 3.4669127339836547e-07,
      "loss": 0.0005,
      "step": 16595
    },
    {
      "epoch": 0.9844584173686084,
      "grad_norm": 15.764689445495605,
      "learning_rate": 3.453730556287899e-07,
      "loss": 0.2452,
      "step": 16596
    },
    {
      "epoch": 0.9845177363862855,
      "grad_norm": 0.04227295517921448,
      "learning_rate": 3.440548378592144e-07,
      "loss": 0.0007,
      "step": 16597
    },
    {
      "epoch": 0.9845770554039626,
      "grad_norm": 0.14966058731079102,
      "learning_rate": 3.4273662008963883e-07,
      "loss": 0.0022,
      "step": 16598
    },
    {
      "epoch": 0.9846363744216395,
      "grad_norm": 0.2459515631198883,
      "learning_rate": 3.4141840232006333e-07,
      "loss": 0.0022,
      "step": 16599
    },
    {
      "epoch": 0.9846956934393166,
      "grad_norm": 1.295932412147522,
      "learning_rate": 3.4010018455048773e-07,
      "loss": 0.0144,
      "step": 16600
    },
    {
      "epoch": 0.9847550124569937,
      "grad_norm": 3.763580560684204,
      "learning_rate": 3.3878196678091224e-07,
      "loss": 0.0136,
      "step": 16601
    },
    {
      "epoch": 0.9848143314746708,
      "grad_norm": 0.3891621232032776,
      "learning_rate": 3.3746374901133674e-07,
      "loss": 0.0032,
      "step": 16602
    },
    {
      "epoch": 0.9848736504923479,
      "grad_norm": 0.1329210251569748,
      "learning_rate": 3.3614553124176114e-07,
      "loss": 0.0013,
      "step": 16603
    },
    {
      "epoch": 0.984932969510025,
      "grad_norm": 0.18262237310409546,
      "learning_rate": 3.3482731347218565e-07,
      "loss": 0.0003,
      "step": 16604
    },
    {
      "epoch": 0.9849922885277019,
      "grad_norm": 9.387657165527344,
      "learning_rate": 3.3350909570261015e-07,
      "loss": 0.4551,
      "step": 16605
    },
    {
      "epoch": 0.985051607545379,
      "grad_norm": 13.928678512573242,
      "learning_rate": 3.3219087793303455e-07,
      "loss": 0.1351,
      "step": 16606
    },
    {
      "epoch": 0.9851109265630561,
      "grad_norm": 0.03341524675488472,
      "learning_rate": 3.3087266016345905e-07,
      "loss": 0.0004,
      "step": 16607
    },
    {
      "epoch": 0.9851702455807332,
      "grad_norm": 0.7711005806922913,
      "learning_rate": 3.295544423938835e-07,
      "loss": 0.011,
      "step": 16608
    },
    {
      "epoch": 0.9852295645984103,
      "grad_norm": 0.005543831270188093,
      "learning_rate": 3.2823622462430796e-07,
      "loss": 0.0002,
      "step": 16609
    },
    {
      "epoch": 0.9852888836160874,
      "grad_norm": 0.17694829404354095,
      "learning_rate": 3.269180068547324e-07,
      "loss": 0.0028,
      "step": 16610
    },
    {
      "epoch": 0.9853482026337644,
      "grad_norm": 0.2332063913345337,
      "learning_rate": 3.255997890851569e-07,
      "loss": 0.0026,
      "step": 16611
    },
    {
      "epoch": 0.9854075216514414,
      "grad_norm": 0.026690445840358734,
      "learning_rate": 3.2428157131558137e-07,
      "loss": 0.0004,
      "step": 16612
    },
    {
      "epoch": 0.9854668406691185,
      "grad_norm": 3.000370979309082,
      "learning_rate": 3.229633535460058e-07,
      "loss": 0.0214,
      "step": 16613
    },
    {
      "epoch": 0.9855261596867956,
      "grad_norm": 10.25568962097168,
      "learning_rate": 3.216451357764303e-07,
      "loss": 0.2084,
      "step": 16614
    },
    {
      "epoch": 0.9855854787044727,
      "grad_norm": 0.04634890332818031,
      "learning_rate": 3.203269180068547e-07,
      "loss": 0.001,
      "step": 16615
    },
    {
      "epoch": 0.9856447977221497,
      "grad_norm": 0.21551817655563354,
      "learning_rate": 3.190087002372792e-07,
      "loss": 0.0036,
      "step": 16616
    },
    {
      "epoch": 0.9857041167398268,
      "grad_norm": 7.57593297958374,
      "learning_rate": 3.1769048246770373e-07,
      "loss": 0.5717,
      "step": 16617
    },
    {
      "epoch": 0.9857634357575038,
      "grad_norm": 0.17984162271022797,
      "learning_rate": 3.1637226469812813e-07,
      "loss": 0.0017,
      "step": 16618
    },
    {
      "epoch": 0.9858227547751809,
      "grad_norm": 2.0892374515533447,
      "learning_rate": 3.1505404692855263e-07,
      "loss": 0.015,
      "step": 16619
    },
    {
      "epoch": 0.985882073792858,
      "grad_norm": 0.017319709062576294,
      "learning_rate": 3.1373582915897714e-07,
      "loss": 0.0004,
      "step": 16620
    },
    {
      "epoch": 0.9859413928105351,
      "grad_norm": 0.027638724073767662,
      "learning_rate": 3.124176113894016e-07,
      "loss": 0.0005,
      "step": 16621
    },
    {
      "epoch": 0.9860007118282121,
      "grad_norm": 12.848138809204102,
      "learning_rate": 3.1109939361982604e-07,
      "loss": 0.5906,
      "step": 16622
    },
    {
      "epoch": 0.9860600308458892,
      "grad_norm": 2.1650867462158203,
      "learning_rate": 3.097811758502505e-07,
      "loss": 0.0103,
      "step": 16623
    },
    {
      "epoch": 0.9861193498635663,
      "grad_norm": 0.4753192365169525,
      "learning_rate": 3.0846295808067495e-07,
      "loss": 0.0123,
      "step": 16624
    },
    {
      "epoch": 0.9861786688812433,
      "grad_norm": 2.8454113006591797,
      "learning_rate": 3.071447403110994e-07,
      "loss": 0.0388,
      "step": 16625
    },
    {
      "epoch": 0.9862379878989204,
      "grad_norm": 0.4589354395866394,
      "learning_rate": 3.0582652254152385e-07,
      "loss": 0.005,
      "step": 16626
    },
    {
      "epoch": 0.9862973069165974,
      "grad_norm": 0.027805648744106293,
      "learning_rate": 3.0450830477194835e-07,
      "loss": 0.0005,
      "step": 16627
    },
    {
      "epoch": 0.9863566259342745,
      "grad_norm": 0.04900093004107475,
      "learning_rate": 3.031900870023728e-07,
      "loss": 0.0005,
      "step": 16628
    },
    {
      "epoch": 0.9864159449519516,
      "grad_norm": 9.090080261230469,
      "learning_rate": 3.0187186923279726e-07,
      "loss": 0.3648,
      "step": 16629
    },
    {
      "epoch": 0.9864752639696287,
      "grad_norm": 0.023886747658252716,
      "learning_rate": 3.0055365146322176e-07,
      "loss": 0.0003,
      "step": 16630
    },
    {
      "epoch": 0.9865345829873057,
      "grad_norm": 0.3456513583660126,
      "learning_rate": 2.992354336936462e-07,
      "loss": 0.0026,
      "step": 16631
    },
    {
      "epoch": 0.9865939020049828,
      "grad_norm": 3.9945476055145264,
      "learning_rate": 2.9791721592407067e-07,
      "loss": 0.0842,
      "step": 16632
    },
    {
      "epoch": 0.9866532210226598,
      "grad_norm": 9.388025283813477,
      "learning_rate": 2.9659899815449517e-07,
      "loss": 0.4997,
      "step": 16633
    },
    {
      "epoch": 0.9867125400403369,
      "grad_norm": 0.17301036417484283,
      "learning_rate": 2.952807803849196e-07,
      "loss": 0.0025,
      "step": 16634
    },
    {
      "epoch": 0.986771859058014,
      "grad_norm": 0.069509357213974,
      "learning_rate": 2.939625626153441e-07,
      "loss": 0.0016,
      "step": 16635
    },
    {
      "epoch": 0.9868311780756911,
      "grad_norm": 0.010867016389966011,
      "learning_rate": 2.926443448457686e-07,
      "loss": 0.0002,
      "step": 16636
    },
    {
      "epoch": 0.9868904970933682,
      "grad_norm": 0.05701792612671852,
      "learning_rate": 2.9132612707619303e-07,
      "loss": 0.0011,
      "step": 16637
    },
    {
      "epoch": 0.9869498161110452,
      "grad_norm": 10.069558143615723,
      "learning_rate": 2.900079093066175e-07,
      "loss": 1.0121,
      "step": 16638
    },
    {
      "epoch": 0.9870091351287222,
      "grad_norm": 0.002423922996968031,
      "learning_rate": 2.8868969153704193e-07,
      "loss": 0.0001,
      "step": 16639
    },
    {
      "epoch": 0.9870684541463993,
      "grad_norm": 5.1542768478393555,
      "learning_rate": 2.873714737674664e-07,
      "loss": 0.2378,
      "step": 16640
    },
    {
      "epoch": 0.9871277731640764,
      "grad_norm": 0.6622421145439148,
      "learning_rate": 2.8605325599789084e-07,
      "loss": 0.0059,
      "step": 16641
    },
    {
      "epoch": 0.9871870921817535,
      "grad_norm": 1.9780428409576416,
      "learning_rate": 2.8473503822831534e-07,
      "loss": 0.0041,
      "step": 16642
    },
    {
      "epoch": 0.9872464111994306,
      "grad_norm": 0.04622386768460274,
      "learning_rate": 2.834168204587398e-07,
      "loss": 0.0008,
      "step": 16643
    },
    {
      "epoch": 0.9873057302171077,
      "grad_norm": 1.5794950723648071,
      "learning_rate": 2.8209860268916425e-07,
      "loss": 0.0124,
      "step": 16644
    },
    {
      "epoch": 0.9873650492347846,
      "grad_norm": 6.5100274085998535,
      "learning_rate": 2.8078038491958875e-07,
      "loss": 0.3302,
      "step": 16645
    },
    {
      "epoch": 0.9874243682524617,
      "grad_norm": 0.023288846015930176,
      "learning_rate": 2.794621671500132e-07,
      "loss": 0.0003,
      "step": 16646
    },
    {
      "epoch": 0.9874836872701388,
      "grad_norm": 7.310367584228516,
      "learning_rate": 2.7814394938043765e-07,
      "loss": 0.231,
      "step": 16647
    },
    {
      "epoch": 0.9875430062878159,
      "grad_norm": 0.00906453002244234,
      "learning_rate": 2.7682573161086216e-07,
      "loss": 0.0002,
      "step": 16648
    },
    {
      "epoch": 0.987602325305493,
      "grad_norm": 0.056769855320453644,
      "learning_rate": 2.755075138412866e-07,
      "loss": 0.0008,
      "step": 16649
    },
    {
      "epoch": 0.98766164432317,
      "grad_norm": 7.773923873901367,
      "learning_rate": 2.7418929607171106e-07,
      "loss": 0.113,
      "step": 16650
    },
    {
      "epoch": 0.987720963340847,
      "grad_norm": 11.090575218200684,
      "learning_rate": 2.7287107830213557e-07,
      "loss": 0.0298,
      "step": 16651
    },
    {
      "epoch": 0.9877802823585241,
      "grad_norm": 2.572849750518799,
      "learning_rate": 2.7155286053256e-07,
      "loss": 0.023,
      "step": 16652
    },
    {
      "epoch": 0.9878396013762012,
      "grad_norm": 0.011241180822253227,
      "learning_rate": 2.7023464276298447e-07,
      "loss": 0.0003,
      "step": 16653
    },
    {
      "epoch": 0.9878989203938783,
      "grad_norm": 0.3567451238632202,
      "learning_rate": 2.689164249934089e-07,
      "loss": 0.0048,
      "step": 16654
    },
    {
      "epoch": 0.9879582394115554,
      "grad_norm": 13.814179420471191,
      "learning_rate": 2.675982072238334e-07,
      "loss": 0.139,
      "step": 16655
    },
    {
      "epoch": 0.9880175584292324,
      "grad_norm": 1.252034306526184,
      "learning_rate": 2.662799894542578e-07,
      "loss": 0.0204,
      "step": 16656
    },
    {
      "epoch": 0.9880768774469095,
      "grad_norm": 6.8537774085998535,
      "learning_rate": 2.6496177168468233e-07,
      "loss": 0.8835,
      "step": 16657
    },
    {
      "epoch": 0.9881361964645865,
      "grad_norm": 1.474799633026123,
      "learning_rate": 2.636435539151068e-07,
      "loss": 0.007,
      "step": 16658
    },
    {
      "epoch": 0.9881955154822636,
      "grad_norm": 16.068805694580078,
      "learning_rate": 2.6232533614553123e-07,
      "loss": 0.0581,
      "step": 16659
    },
    {
      "epoch": 0.9882548344999407,
      "grad_norm": 0.1099780797958374,
      "learning_rate": 2.6100711837595574e-07,
      "loss": 0.0011,
      "step": 16660
    },
    {
      "epoch": 0.9883141535176178,
      "grad_norm": 1.7884788513183594,
      "learning_rate": 2.596889006063802e-07,
      "loss": 0.0115,
      "step": 16661
    },
    {
      "epoch": 0.9883734725352948,
      "grad_norm": 5.1656293869018555,
      "learning_rate": 2.5837068283680464e-07,
      "loss": 0.0814,
      "step": 16662
    },
    {
      "epoch": 0.9884327915529719,
      "grad_norm": 0.09144269675016403,
      "learning_rate": 2.5705246506722915e-07,
      "loss": 0.0018,
      "step": 16663
    },
    {
      "epoch": 0.9884921105706489,
      "grad_norm": 19.679718017578125,
      "learning_rate": 2.557342472976536e-07,
      "loss": 0.0565,
      "step": 16664
    },
    {
      "epoch": 0.988551429588326,
      "grad_norm": 0.04548932984471321,
      "learning_rate": 2.5441602952807805e-07,
      "loss": 0.0007,
      "step": 16665
    },
    {
      "epoch": 0.9886107486060031,
      "grad_norm": 0.01995760202407837,
      "learning_rate": 2.5309781175850256e-07,
      "loss": 0.0005,
      "step": 16666
    },
    {
      "epoch": 0.9886700676236801,
      "grad_norm": 0.5542674660682678,
      "learning_rate": 2.51779593988927e-07,
      "loss": 0.0041,
      "step": 16667
    },
    {
      "epoch": 0.9887293866413572,
      "grad_norm": 0.35382014513015747,
      "learning_rate": 2.5046137621935146e-07,
      "loss": 0.0057,
      "step": 16668
    },
    {
      "epoch": 0.9887887056590343,
      "grad_norm": 0.0042570605874061584,
      "learning_rate": 2.491431584497759e-07,
      "loss": 0.0001,
      "step": 16669
    },
    {
      "epoch": 0.9888480246767114,
      "grad_norm": 8.898367881774902,
      "learning_rate": 2.4782494068020036e-07,
      "loss": 0.6824,
      "step": 16670
    },
    {
      "epoch": 0.9889073436943884,
      "grad_norm": 0.06263615936040878,
      "learning_rate": 2.4650672291062487e-07,
      "loss": 0.0011,
      "step": 16671
    },
    {
      "epoch": 0.9889666627120655,
      "grad_norm": 0.03726138547062874,
      "learning_rate": 2.451885051410493e-07,
      "loss": 0.0005,
      "step": 16672
    },
    {
      "epoch": 0.9890259817297425,
      "grad_norm": 9.09707260131836,
      "learning_rate": 2.4387028737147377e-07,
      "loss": 0.1011,
      "step": 16673
    },
    {
      "epoch": 0.9890853007474196,
      "grad_norm": 4.671792030334473,
      "learning_rate": 2.425520696018983e-07,
      "loss": 0.191,
      "step": 16674
    },
    {
      "epoch": 0.9891446197650967,
      "grad_norm": 0.00997888669371605,
      "learning_rate": 2.4123385183232273e-07,
      "loss": 0.0002,
      "step": 16675
    },
    {
      "epoch": 0.9892039387827738,
      "grad_norm": 0.010950909927487373,
      "learning_rate": 2.399156340627472e-07,
      "loss": 0.0003,
      "step": 16676
    },
    {
      "epoch": 0.9892632578004509,
      "grad_norm": 0.1670956015586853,
      "learning_rate": 2.385974162931717e-07,
      "loss": 0.0015,
      "step": 16677
    },
    {
      "epoch": 0.9893225768181279,
      "grad_norm": 0.02507508359849453,
      "learning_rate": 2.372791985235961e-07,
      "loss": 0.0004,
      "step": 16678
    },
    {
      "epoch": 0.9893818958358049,
      "grad_norm": 0.0910484716296196,
      "learning_rate": 2.3596098075402056e-07,
      "loss": 0.002,
      "step": 16679
    },
    {
      "epoch": 0.989441214853482,
      "grad_norm": 4.224977016448975,
      "learning_rate": 2.3464276298444507e-07,
      "loss": 0.0664,
      "step": 16680
    },
    {
      "epoch": 0.9895005338711591,
      "grad_norm": 0.0414433628320694,
      "learning_rate": 2.3332454521486952e-07,
      "loss": 0.0006,
      "step": 16681
    },
    {
      "epoch": 0.9895598528888362,
      "grad_norm": 0.5194571018218994,
      "learning_rate": 2.3200632744529397e-07,
      "loss": 0.0032,
      "step": 16682
    },
    {
      "epoch": 0.9896191719065133,
      "grad_norm": 2.9126415252685547,
      "learning_rate": 2.3068810967571845e-07,
      "loss": 0.0612,
      "step": 16683
    },
    {
      "epoch": 0.9896784909241902,
      "grad_norm": 24.41538429260254,
      "learning_rate": 2.2936989190614293e-07,
      "loss": 0.3228,
      "step": 16684
    },
    {
      "epoch": 0.9897378099418673,
      "grad_norm": 2.4191722869873047,
      "learning_rate": 2.2805167413656738e-07,
      "loss": 0.0211,
      "step": 16685
    },
    {
      "epoch": 0.9897971289595444,
      "grad_norm": 0.05306294560432434,
      "learning_rate": 2.2673345636699186e-07,
      "loss": 0.0008,
      "step": 16686
    },
    {
      "epoch": 0.9898564479772215,
      "grad_norm": 0.06702324002981186,
      "learning_rate": 2.254152385974163e-07,
      "loss": 0.0017,
      "step": 16687
    },
    {
      "epoch": 0.9899157669948986,
      "grad_norm": 0.0867433026432991,
      "learning_rate": 2.2409702082784076e-07,
      "loss": 0.001,
      "step": 16688
    },
    {
      "epoch": 0.9899750860125757,
      "grad_norm": 0.061764057725667953,
      "learning_rate": 2.2277880305826526e-07,
      "loss": 0.001,
      "step": 16689
    },
    {
      "epoch": 0.9900344050302528,
      "grad_norm": 0.033285923302173615,
      "learning_rate": 2.2146058528868972e-07,
      "loss": 0.0005,
      "step": 16690
    },
    {
      "epoch": 0.9900937240479297,
      "grad_norm": 0.3927360773086548,
      "learning_rate": 2.2014236751911417e-07,
      "loss": 0.0024,
      "step": 16691
    },
    {
      "epoch": 0.9901530430656068,
      "grad_norm": 5.793456077575684,
      "learning_rate": 2.1882414974953865e-07,
      "loss": 0.1947,
      "step": 16692
    },
    {
      "epoch": 0.9902123620832839,
      "grad_norm": 3.559171438217163,
      "learning_rate": 2.175059319799631e-07,
      "loss": 0.0322,
      "step": 16693
    },
    {
      "epoch": 0.990271681100961,
      "grad_norm": 0.0507124699652195,
      "learning_rate": 2.1618771421038755e-07,
      "loss": 0.0007,
      "step": 16694
    },
    {
      "epoch": 0.9903310001186381,
      "grad_norm": 0.2234257310628891,
      "learning_rate": 2.1486949644081206e-07,
      "loss": 0.0023,
      "step": 16695
    },
    {
      "epoch": 0.9903903191363151,
      "grad_norm": 5.938709735870361,
      "learning_rate": 2.135512786712365e-07,
      "loss": 0.0472,
      "step": 16696
    },
    {
      "epoch": 0.9904496381539921,
      "grad_norm": 0.022610977292060852,
      "learning_rate": 2.1223306090166096e-07,
      "loss": 0.0004,
      "step": 16697
    },
    {
      "epoch": 0.9905089571716692,
      "grad_norm": 0.00500855129212141,
      "learning_rate": 2.1091484313208544e-07,
      "loss": 0.0001,
      "step": 16698
    },
    {
      "epoch": 0.9905682761893463,
      "grad_norm": 8.532953262329102,
      "learning_rate": 2.0959662536250992e-07,
      "loss": 0.1271,
      "step": 16699
    },
    {
      "epoch": 0.9906275952070234,
      "grad_norm": 0.26508018374443054,
      "learning_rate": 2.0827840759293437e-07,
      "loss": 0.0037,
      "step": 16700
    },
    {
      "epoch": 0.9906869142247005,
      "grad_norm": 14.992379188537598,
      "learning_rate": 2.0696018982335885e-07,
      "loss": 0.0927,
      "step": 16701
    },
    {
      "epoch": 0.9907462332423775,
      "grad_norm": 4.095189094543457,
      "learning_rate": 2.056419720537833e-07,
      "loss": 0.0667,
      "step": 16702
    },
    {
      "epoch": 0.9908055522600546,
      "grad_norm": 3.315593719482422,
      "learning_rate": 2.0432375428420775e-07,
      "loss": 0.0113,
      "step": 16703
    },
    {
      "epoch": 0.9908648712777316,
      "grad_norm": 3.2912721633911133,
      "learning_rate": 2.0300553651463225e-07,
      "loss": 0.037,
      "step": 16704
    },
    {
      "epoch": 0.9909241902954087,
      "grad_norm": 2.558509349822998,
      "learning_rate": 2.016873187450567e-07,
      "loss": 0.0197,
      "step": 16705
    },
    {
      "epoch": 0.9909835093130858,
      "grad_norm": 0.003855066141113639,
      "learning_rate": 2.0036910097548116e-07,
      "loss": 0.0002,
      "step": 16706
    },
    {
      "epoch": 0.9910428283307628,
      "grad_norm": 0.05207828804850578,
      "learning_rate": 1.9905088320590564e-07,
      "loss": 0.0007,
      "step": 16707
    },
    {
      "epoch": 0.9911021473484399,
      "grad_norm": 0.05188640207052231,
      "learning_rate": 1.977326654363301e-07,
      "loss": 0.0013,
      "step": 16708
    },
    {
      "epoch": 0.991161466366117,
      "grad_norm": 1.2212506532669067,
      "learning_rate": 1.9641444766675454e-07,
      "loss": 0.024,
      "step": 16709
    },
    {
      "epoch": 0.991220785383794,
      "grad_norm": 8.30567455291748,
      "learning_rate": 1.9509622989717904e-07,
      "loss": 0.1884,
      "step": 16710
    },
    {
      "epoch": 0.9912801044014711,
      "grad_norm": 0.17853832244873047,
      "learning_rate": 1.937780121276035e-07,
      "loss": 0.001,
      "step": 16711
    },
    {
      "epoch": 0.9913394234191482,
      "grad_norm": 0.1094651073217392,
      "learning_rate": 1.9245979435802795e-07,
      "loss": 0.0007,
      "step": 16712
    },
    {
      "epoch": 0.9913987424368252,
      "grad_norm": 0.04302991181612015,
      "learning_rate": 1.9114157658845243e-07,
      "loss": 0.0004,
      "step": 16713
    },
    {
      "epoch": 0.9914580614545023,
      "grad_norm": 0.3034951090812683,
      "learning_rate": 1.8982335881887688e-07,
      "loss": 0.0049,
      "step": 16714
    },
    {
      "epoch": 0.9915173804721794,
      "grad_norm": 0.10245823115110397,
      "learning_rate": 1.8850514104930136e-07,
      "loss": 0.0012,
      "step": 16715
    },
    {
      "epoch": 0.9915766994898565,
      "grad_norm": 0.031872279942035675,
      "learning_rate": 1.8718692327972583e-07,
      "loss": 0.0008,
      "step": 16716
    },
    {
      "epoch": 0.9916360185075335,
      "grad_norm": 8.594929695129395,
      "learning_rate": 1.8586870551015029e-07,
      "loss": 0.2702,
      "step": 16717
    },
    {
      "epoch": 0.9916953375252106,
      "grad_norm": 0.03577262908220291,
      "learning_rate": 1.8455048774057474e-07,
      "loss": 0.0007,
      "step": 16718
    },
    {
      "epoch": 0.9917546565428876,
      "grad_norm": 0.8185456395149231,
      "learning_rate": 1.8323226997099924e-07,
      "loss": 0.0105,
      "step": 16719
    },
    {
      "epoch": 0.9918139755605647,
      "grad_norm": 25.3856258392334,
      "learning_rate": 1.819140522014237e-07,
      "loss": 1.6856,
      "step": 16720
    },
    {
      "epoch": 0.9918732945782418,
      "grad_norm": 6.778267860412598,
      "learning_rate": 1.8059583443184817e-07,
      "loss": 0.1586,
      "step": 16721
    },
    {
      "epoch": 0.9919326135959189,
      "grad_norm": 0.008801757358014584,
      "learning_rate": 1.7927761666227262e-07,
      "loss": 0.0004,
      "step": 16722
    },
    {
      "epoch": 0.991991932613596,
      "grad_norm": 0.32291460037231445,
      "learning_rate": 1.7795939889269708e-07,
      "loss": 0.0032,
      "step": 16723
    },
    {
      "epoch": 0.992051251631273,
      "grad_norm": 0.21397392451763153,
      "learning_rate": 1.7664118112312158e-07,
      "loss": 0.0018,
      "step": 16724
    },
    {
      "epoch": 0.99211057064895,
      "grad_norm": 12.09290599822998,
      "learning_rate": 1.7532296335354603e-07,
      "loss": 0.1498,
      "step": 16725
    },
    {
      "epoch": 0.9921698896666271,
      "grad_norm": 0.004813558422029018,
      "learning_rate": 1.7400474558397048e-07,
      "loss": 0.0001,
      "step": 16726
    },
    {
      "epoch": 0.9922292086843042,
      "grad_norm": 18.683231353759766,
      "learning_rate": 1.7268652781439496e-07,
      "loss": 0.6116,
      "step": 16727
    },
    {
      "epoch": 0.9922885277019813,
      "grad_norm": 0.1327219009399414,
      "learning_rate": 1.7136831004481941e-07,
      "loss": 0.0014,
      "step": 16728
    },
    {
      "epoch": 0.9923478467196584,
      "grad_norm": 0.047624897211790085,
      "learning_rate": 1.7005009227524387e-07,
      "loss": 0.0006,
      "step": 16729
    },
    {
      "epoch": 0.9924071657373353,
      "grad_norm": 6.6834282875061035,
      "learning_rate": 1.6873187450566837e-07,
      "loss": 0.0579,
      "step": 16730
    },
    {
      "epoch": 0.9924664847550124,
      "grad_norm": 0.5808802247047424,
      "learning_rate": 1.6741365673609282e-07,
      "loss": 0.0055,
      "step": 16731
    },
    {
      "epoch": 0.9925258037726895,
      "grad_norm": 0.7338782548904419,
      "learning_rate": 1.6609543896651727e-07,
      "loss": 0.012,
      "step": 16732
    },
    {
      "epoch": 0.9925851227903666,
      "grad_norm": 1.042118787765503,
      "learning_rate": 1.6477722119694175e-07,
      "loss": 0.0055,
      "step": 16733
    },
    {
      "epoch": 0.9926444418080437,
      "grad_norm": 0.3262324631214142,
      "learning_rate": 1.634590034273662e-07,
      "loss": 0.0039,
      "step": 16734
    },
    {
      "epoch": 0.9927037608257208,
      "grad_norm": 3.776611566543579,
      "learning_rate": 1.6214078565779068e-07,
      "loss": 0.0713,
      "step": 16735
    },
    {
      "epoch": 0.9927630798433978,
      "grad_norm": 0.03484965115785599,
      "learning_rate": 1.6082256788821516e-07,
      "loss": 0.0004,
      "step": 16736
    },
    {
      "epoch": 0.9928223988610748,
      "grad_norm": 0.03903716057538986,
      "learning_rate": 1.595043501186396e-07,
      "loss": 0.0006,
      "step": 16737
    },
    {
      "epoch": 0.9928817178787519,
      "grad_norm": 0.09604576975107193,
      "learning_rate": 1.5818613234906406e-07,
      "loss": 0.0011,
      "step": 16738
    },
    {
      "epoch": 0.992941036896429,
      "grad_norm": 12.422865867614746,
      "learning_rate": 1.5686791457948857e-07,
      "loss": 0.505,
      "step": 16739
    },
    {
      "epoch": 0.9930003559141061,
      "grad_norm": 9.234237670898438,
      "learning_rate": 1.5554969680991302e-07,
      "loss": 0.1592,
      "step": 16740
    },
    {
      "epoch": 0.9930596749317832,
      "grad_norm": 0.01716056652367115,
      "learning_rate": 1.5423147904033747e-07,
      "loss": 0.0003,
      "step": 16741
    },
    {
      "epoch": 0.9931189939494602,
      "grad_norm": 44.7581672668457,
      "learning_rate": 1.5291326127076192e-07,
      "loss": 0.3947,
      "step": 16742
    },
    {
      "epoch": 0.9931783129671372,
      "grad_norm": 0.0215273667126894,
      "learning_rate": 1.515950435011864e-07,
      "loss": 0.0009,
      "step": 16743
    },
    {
      "epoch": 0.9932376319848143,
      "grad_norm": 10.565140724182129,
      "learning_rate": 1.5027682573161088e-07,
      "loss": 0.1161,
      "step": 16744
    },
    {
      "epoch": 0.9932969510024914,
      "grad_norm": 0.0044597056694328785,
      "learning_rate": 1.4895860796203533e-07,
      "loss": 0.0001,
      "step": 16745
    },
    {
      "epoch": 0.9933562700201685,
      "grad_norm": 0.002790806582197547,
      "learning_rate": 1.476403901924598e-07,
      "loss": 0.0001,
      "step": 16746
    },
    {
      "epoch": 0.9934155890378455,
      "grad_norm": 17.487077713012695,
      "learning_rate": 1.463221724228843e-07,
      "loss": 0.3255,
      "step": 16747
    },
    {
      "epoch": 0.9934749080555226,
      "grad_norm": 0.0173819400370121,
      "learning_rate": 1.4500395465330874e-07,
      "loss": 0.0004,
      "step": 16748
    },
    {
      "epoch": 0.9935342270731997,
      "grad_norm": 9.18002986907959,
      "learning_rate": 1.436857368837332e-07,
      "loss": 0.2055,
      "step": 16749
    },
    {
      "epoch": 0.9935935460908767,
      "grad_norm": 0.20664523541927338,
      "learning_rate": 1.4236751911415767e-07,
      "loss": 0.0028,
      "step": 16750
    },
    {
      "epoch": 0.9936528651085538,
      "grad_norm": 13.311866760253906,
      "learning_rate": 1.4104930134458212e-07,
      "loss": 0.0552,
      "step": 16751
    },
    {
      "epoch": 0.9937121841262309,
      "grad_norm": 0.008750452660024166,
      "learning_rate": 1.397310835750066e-07,
      "loss": 0.0003,
      "step": 16752
    },
    {
      "epoch": 0.9937715031439079,
      "grad_norm": 0.16135767102241516,
      "learning_rate": 1.3841286580543108e-07,
      "loss": 0.0022,
      "step": 16753
    },
    {
      "epoch": 0.993830822161585,
      "grad_norm": 11.143030166625977,
      "learning_rate": 1.3709464803585553e-07,
      "loss": 0.2787,
      "step": 16754
    },
    {
      "epoch": 0.9938901411792621,
      "grad_norm": 0.16885323822498322,
      "learning_rate": 1.3577643026628e-07,
      "loss": 0.0006,
      "step": 16755
    },
    {
      "epoch": 0.9939494601969392,
      "grad_norm": 0.1405816674232483,
      "learning_rate": 1.3445821249670446e-07,
      "loss": 0.0012,
      "step": 16756
    },
    {
      "epoch": 0.9940087792146162,
      "grad_norm": 0.9975290894508362,
      "learning_rate": 1.331399947271289e-07,
      "loss": 0.0113,
      "step": 16757
    },
    {
      "epoch": 0.9940680982322933,
      "grad_norm": 14.382606506347656,
      "learning_rate": 1.318217769575534e-07,
      "loss": 0.4335,
      "step": 16758
    },
    {
      "epoch": 0.9941274172499703,
      "grad_norm": 21.325634002685547,
      "learning_rate": 1.3050355918797787e-07,
      "loss": 0.2288,
      "step": 16759
    },
    {
      "epoch": 0.9941867362676474,
      "grad_norm": 0.01171222236007452,
      "learning_rate": 1.2918534141840232e-07,
      "loss": 0.0003,
      "step": 16760
    },
    {
      "epoch": 0.9942460552853245,
      "grad_norm": 0.17875035107135773,
      "learning_rate": 1.278671236488268e-07,
      "loss": 0.0029,
      "step": 16761
    },
    {
      "epoch": 0.9943053743030016,
      "grad_norm": 0.007016192190349102,
      "learning_rate": 1.2654890587925128e-07,
      "loss": 0.0001,
      "step": 16762
    },
    {
      "epoch": 0.9943646933206786,
      "grad_norm": 1.4083447456359863,
      "learning_rate": 1.2523068810967573e-07,
      "loss": 0.0388,
      "step": 16763
    },
    {
      "epoch": 0.9944240123383556,
      "grad_norm": 8.94624137878418,
      "learning_rate": 1.2391247034010018e-07,
      "loss": 0.1905,
      "step": 16764
    },
    {
      "epoch": 0.9944833313560327,
      "grad_norm": 56.24187088012695,
      "learning_rate": 1.2259425257052466e-07,
      "loss": 1.0546,
      "step": 16765
    },
    {
      "epoch": 0.9945426503737098,
      "grad_norm": 0.06481913477182388,
      "learning_rate": 1.2127603480094914e-07,
      "loss": 0.0015,
      "step": 16766
    },
    {
      "epoch": 0.9946019693913869,
      "grad_norm": 0.38923776149749756,
      "learning_rate": 1.199578170313736e-07,
      "loss": 0.0019,
      "step": 16767
    },
    {
      "epoch": 0.994661288409064,
      "grad_norm": 7.289028167724609,
      "learning_rate": 1.1863959926179805e-07,
      "loss": 0.0416,
      "step": 16768
    },
    {
      "epoch": 0.9947206074267411,
      "grad_norm": 4.2563300132751465,
      "learning_rate": 1.1732138149222253e-07,
      "loss": 0.0373,
      "step": 16769
    },
    {
      "epoch": 0.994779926444418,
      "grad_norm": 0.13637104630470276,
      "learning_rate": 1.1600316372264699e-07,
      "loss": 0.0013,
      "step": 16770
    },
    {
      "epoch": 0.9948392454620951,
      "grad_norm": 26.61781883239746,
      "learning_rate": 1.1468494595307146e-07,
      "loss": 0.4897,
      "step": 16771
    },
    {
      "epoch": 0.9948985644797722,
      "grad_norm": 0.642498791217804,
      "learning_rate": 1.1336672818349593e-07,
      "loss": 0.0075,
      "step": 16772
    },
    {
      "epoch": 0.9949578834974493,
      "grad_norm": 1.2124584913253784,
      "learning_rate": 1.1204851041392038e-07,
      "loss": 0.0078,
      "step": 16773
    },
    {
      "epoch": 0.9950172025151264,
      "grad_norm": 0.09816238284111023,
      "learning_rate": 1.1073029264434486e-07,
      "loss": 0.001,
      "step": 16774
    },
    {
      "epoch": 0.9950765215328035,
      "grad_norm": 0.1319802850484848,
      "learning_rate": 1.0941207487476932e-07,
      "loss": 0.0019,
      "step": 16775
    },
    {
      "epoch": 0.9951358405504804,
      "grad_norm": 52.50084686279297,
      "learning_rate": 1.0809385710519378e-07,
      "loss": 0.0675,
      "step": 16776
    },
    {
      "epoch": 0.9951951595681575,
      "grad_norm": 7.479076385498047,
      "learning_rate": 1.0677563933561825e-07,
      "loss": 0.754,
      "step": 16777
    },
    {
      "epoch": 0.9952544785858346,
      "grad_norm": 5.5611724853515625,
      "learning_rate": 1.0545742156604272e-07,
      "loss": 0.3274,
      "step": 16778
    },
    {
      "epoch": 0.9953137976035117,
      "grad_norm": 0.054326992481946945,
      "learning_rate": 1.0413920379646718e-07,
      "loss": 0.0006,
      "step": 16779
    },
    {
      "epoch": 0.9953731166211888,
      "grad_norm": 0.027979178354144096,
      "learning_rate": 1.0282098602689165e-07,
      "loss": 0.0005,
      "step": 16780
    },
    {
      "epoch": 0.9954324356388659,
      "grad_norm": 3.7231521606445312,
      "learning_rate": 1.0150276825731613e-07,
      "loss": 0.0265,
      "step": 16781
    },
    {
      "epoch": 0.9954917546565429,
      "grad_norm": 2.0305261611938477,
      "learning_rate": 1.0018455048774058e-07,
      "loss": 0.0352,
      "step": 16782
    },
    {
      "epoch": 0.9955510736742199,
      "grad_norm": 1.2121647596359253,
      "learning_rate": 9.886633271816504e-08,
      "loss": 0.016,
      "step": 16783
    },
    {
      "epoch": 0.995610392691897,
      "grad_norm": 0.6057296395301819,
      "learning_rate": 9.754811494858952e-08,
      "loss": 0.0019,
      "step": 16784
    },
    {
      "epoch": 0.9956697117095741,
      "grad_norm": 0.0064286524429917336,
      "learning_rate": 9.622989717901397e-08,
      "loss": 0.0002,
      "step": 16785
    },
    {
      "epoch": 0.9957290307272512,
      "grad_norm": 9.166298866271973,
      "learning_rate": 9.491167940943844e-08,
      "loss": 0.1625,
      "step": 16786
    },
    {
      "epoch": 0.9957883497449282,
      "grad_norm": 4.516119003295898,
      "learning_rate": 9.359346163986292e-08,
      "loss": 0.1245,
      "step": 16787
    },
    {
      "epoch": 0.9958476687626053,
      "grad_norm": 3.1973133087158203,
      "learning_rate": 9.227524387028737e-08,
      "loss": 0.0318,
      "step": 16788
    },
    {
      "epoch": 0.9959069877802823,
      "grad_norm": 1.0991133451461792,
      "learning_rate": 9.095702610071185e-08,
      "loss": 0.0121,
      "step": 16789
    },
    {
      "epoch": 0.9959663067979594,
      "grad_norm": 0.16459313035011292,
      "learning_rate": 8.963880833113631e-08,
      "loss": 0.0044,
      "step": 16790
    },
    {
      "epoch": 0.9960256258156365,
      "grad_norm": 3.869410276412964,
      "learning_rate": 8.832059056156079e-08,
      "loss": 0.043,
      "step": 16791
    },
    {
      "epoch": 0.9960849448333136,
      "grad_norm": 0.03720823675394058,
      "learning_rate": 8.700237279198524e-08,
      "loss": 0.0012,
      "step": 16792
    },
    {
      "epoch": 0.9961442638509906,
      "grad_norm": 0.7409080266952515,
      "learning_rate": 8.568415502240971e-08,
      "loss": 0.0049,
      "step": 16793
    },
    {
      "epoch": 0.9962035828686677,
      "grad_norm": 18.891401290893555,
      "learning_rate": 8.436593725283419e-08,
      "loss": 0.6909,
      "step": 16794
    },
    {
      "epoch": 0.9962629018863448,
      "grad_norm": 0.43853580951690674,
      "learning_rate": 8.304771948325864e-08,
      "loss": 0.0088,
      "step": 16795
    },
    {
      "epoch": 0.9963222209040218,
      "grad_norm": 0.13262714445590973,
      "learning_rate": 8.17295017136831e-08,
      "loss": 0.0008,
      "step": 16796
    },
    {
      "epoch": 0.9963815399216989,
      "grad_norm": 0.01076393760740757,
      "learning_rate": 8.041128394410758e-08,
      "loss": 0.0003,
      "step": 16797
    },
    {
      "epoch": 0.996440858939376,
      "grad_norm": 13.294310569763184,
      "learning_rate": 7.909306617453203e-08,
      "loss": 0.1042,
      "step": 16798
    },
    {
      "epoch": 0.996500177957053,
      "grad_norm": 0.7105979919433594,
      "learning_rate": 7.777484840495651e-08,
      "loss": 0.0042,
      "step": 16799
    },
    {
      "epoch": 0.9965594969747301,
      "grad_norm": 19.296661376953125,
      "learning_rate": 7.645663063538096e-08,
      "loss": 0.6409,
      "step": 16800
    },
    {
      "epoch": 0.9966188159924072,
      "grad_norm": 0.021405721083283424,
      "learning_rate": 7.513841286580544e-08,
      "loss": 0.0004,
      "step": 16801
    },
    {
      "epoch": 0.9966781350100843,
      "grad_norm": 17.770917892456055,
      "learning_rate": 7.38201950962299e-08,
      "loss": 0.1003,
      "step": 16802
    },
    {
      "epoch": 0.9967374540277613,
      "grad_norm": 2.9125170707702637,
      "learning_rate": 7.250197732665437e-08,
      "loss": 0.0237,
      "step": 16803
    },
    {
      "epoch": 0.9967967730454383,
      "grad_norm": 0.015598730184137821,
      "learning_rate": 7.118375955707884e-08,
      "loss": 0.0004,
      "step": 16804
    },
    {
      "epoch": 0.9968560920631154,
      "grad_norm": 0.2827850580215454,
      "learning_rate": 6.98655417875033e-08,
      "loss": 0.0026,
      "step": 16805
    },
    {
      "epoch": 0.9969154110807925,
      "grad_norm": 11.440500259399414,
      "learning_rate": 6.854732401792777e-08,
      "loss": 0.8205,
      "step": 16806
    },
    {
      "epoch": 0.9969747300984696,
      "grad_norm": 0.045376479625701904,
      "learning_rate": 6.722910624835223e-08,
      "loss": 0.0006,
      "step": 16807
    },
    {
      "epoch": 0.9970340491161467,
      "grad_norm": 16.42613410949707,
      "learning_rate": 6.59108884787767e-08,
      "loss": 0.3644,
      "step": 16808
    },
    {
      "epoch": 0.9970933681338237,
      "grad_norm": 2.131870985031128,
      "learning_rate": 6.459267070920116e-08,
      "loss": 0.0526,
      "step": 16809
    },
    {
      "epoch": 0.9971526871515007,
      "grad_norm": 0.23894445598125458,
      "learning_rate": 6.327445293962564e-08,
      "loss": 0.0017,
      "step": 16810
    },
    {
      "epoch": 0.9972120061691778,
      "grad_norm": 0.04801774024963379,
      "learning_rate": 6.195623517005009e-08,
      "loss": 0.0007,
      "step": 16811
    },
    {
      "epoch": 0.9972713251868549,
      "grad_norm": 0.609744131565094,
      "learning_rate": 6.063801740047457e-08,
      "loss": 0.0028,
      "step": 16812
    },
    {
      "epoch": 0.997330644204532,
      "grad_norm": 5.486448287963867,
      "learning_rate": 5.931979963089903e-08,
      "loss": 0.3369,
      "step": 16813
    },
    {
      "epoch": 0.9973899632222091,
      "grad_norm": 0.4389588236808777,
      "learning_rate": 5.800158186132349e-08,
      "loss": 0.0062,
      "step": 16814
    },
    {
      "epoch": 0.9974492822398862,
      "grad_norm": 0.06791433691978455,
      "learning_rate": 5.6683364091747964e-08,
      "loss": 0.0009,
      "step": 16815
    },
    {
      "epoch": 0.9975086012575631,
      "grad_norm": 11.772062301635742,
      "learning_rate": 5.536514632217243e-08,
      "loss": 0.041,
      "step": 16816
    },
    {
      "epoch": 0.9975679202752402,
      "grad_norm": 0.005235420074313879,
      "learning_rate": 5.404692855259689e-08,
      "loss": 0.0002,
      "step": 16817
    },
    {
      "epoch": 0.9976272392929173,
      "grad_norm": 0.04113886505365372,
      "learning_rate": 5.272871078302136e-08,
      "loss": 0.0008,
      "step": 16818
    },
    {
      "epoch": 0.9976865583105944,
      "grad_norm": 7.716827392578125,
      "learning_rate": 5.1410493013445824e-08,
      "loss": 0.4515,
      "step": 16819
    },
    {
      "epoch": 0.9977458773282715,
      "grad_norm": 0.01871136948466301,
      "learning_rate": 5.009227524387029e-08,
      "loss": 0.0003,
      "step": 16820
    },
    {
      "epoch": 0.9978051963459486,
      "grad_norm": 0.3242724537849426,
      "learning_rate": 4.877405747429476e-08,
      "loss": 0.0027,
      "step": 16821
    },
    {
      "epoch": 0.9978645153636255,
      "grad_norm": 8.096091270446777,
      "learning_rate": 4.745583970471922e-08,
      "loss": 0.1097,
      "step": 16822
    },
    {
      "epoch": 0.9979238343813026,
      "grad_norm": 12.42285442352295,
      "learning_rate": 4.6137621935143684e-08,
      "loss": 0.119,
      "step": 16823
    },
    {
      "epoch": 0.9979831533989797,
      "grad_norm": 13.010923385620117,
      "learning_rate": 4.4819404165568156e-08,
      "loss": 0.5545,
      "step": 16824
    },
    {
      "epoch": 0.9980424724166568,
      "grad_norm": 0.014512049965560436,
      "learning_rate": 4.350118639599262e-08,
      "loss": 0.0005,
      "step": 16825
    },
    {
      "epoch": 0.9981017914343339,
      "grad_norm": 6.8990983963012695,
      "learning_rate": 4.218296862641709e-08,
      "loss": 0.2321,
      "step": 16826
    },
    {
      "epoch": 0.998161110452011,
      "grad_norm": 3.1891863346099854,
      "learning_rate": 4.086475085684155e-08,
      "loss": 0.0214,
      "step": 16827
    },
    {
      "epoch": 0.998220429469688,
      "grad_norm": 0.12031181901693344,
      "learning_rate": 3.9546533087266016e-08,
      "loss": 0.0019,
      "step": 16828
    },
    {
      "epoch": 0.998279748487365,
      "grad_norm": 1.9505995512008667,
      "learning_rate": 3.822831531769048e-08,
      "loss": 0.0362,
      "step": 16829
    },
    {
      "epoch": 0.9983390675050421,
      "grad_norm": 19.22550392150879,
      "learning_rate": 3.691009754811495e-08,
      "loss": 0.6305,
      "step": 16830
    },
    {
      "epoch": 0.9983983865227192,
      "grad_norm": 0.06963583827018738,
      "learning_rate": 3.559187977853942e-08,
      "loss": 0.0008,
      "step": 16831
    },
    {
      "epoch": 0.9984577055403963,
      "grad_norm": 0.010880112648010254,
      "learning_rate": 3.427366200896388e-08,
      "loss": 0.0003,
      "step": 16832
    },
    {
      "epoch": 0.9985170245580733,
      "grad_norm": 0.905335009098053,
      "learning_rate": 3.295544423938835e-08,
      "loss": 0.0064,
      "step": 16833
    },
    {
      "epoch": 0.9985763435757504,
      "grad_norm": 0.00843891967087984,
      "learning_rate": 3.163722646981282e-08,
      "loss": 0.0003,
      "step": 16834
    },
    {
      "epoch": 0.9986356625934274,
      "grad_norm": 9.520095825195312,
      "learning_rate": 3.0319008700237285e-08,
      "loss": 0.278,
      "step": 16835
    },
    {
      "epoch": 0.9986949816111045,
      "grad_norm": 0.3431936204433441,
      "learning_rate": 2.9000790930661746e-08,
      "loss": 0.0016,
      "step": 16836
    },
    {
      "epoch": 0.9987543006287816,
      "grad_norm": 2.6132893562316895,
      "learning_rate": 2.7682573161086215e-08,
      "loss": 0.0172,
      "step": 16837
    },
    {
      "epoch": 0.9988136196464587,
      "grad_norm": 4.117404460906982,
      "learning_rate": 2.636435539151068e-08,
      "loss": 0.0347,
      "step": 16838
    },
    {
      "epoch": 0.9988729386641357,
      "grad_norm": 0.21178777515888214,
      "learning_rate": 2.5046137621935145e-08,
      "loss": 0.003,
      "step": 16839
    },
    {
      "epoch": 0.9989322576818128,
      "grad_norm": 1.2014440298080444,
      "learning_rate": 2.372791985235961e-08,
      "loss": 0.0106,
      "step": 16840
    },
    {
      "epoch": 0.9989915766994899,
      "grad_norm": 1.0582849979400635,
      "learning_rate": 2.2409702082784078e-08,
      "loss": 0.0106,
      "step": 16841
    },
    {
      "epoch": 0.9990508957171669,
      "grad_norm": 0.03049766644835472,
      "learning_rate": 2.1091484313208546e-08,
      "loss": 0.0006,
      "step": 16842
    },
    {
      "epoch": 0.999110214734844,
      "grad_norm": 7.199010372161865,
      "learning_rate": 1.9773266543633008e-08,
      "loss": 0.0725,
      "step": 16843
    },
    {
      "epoch": 0.999169533752521,
      "grad_norm": 0.0978928729891777,
      "learning_rate": 1.8455048774057476e-08,
      "loss": 0.0012,
      "step": 16844
    },
    {
      "epoch": 0.9992288527701981,
      "grad_norm": 35.26040267944336,
      "learning_rate": 1.713683100448194e-08,
      "loss": 0.7225,
      "step": 16845
    },
    {
      "epoch": 0.9992881717878752,
      "grad_norm": 0.15150117874145508,
      "learning_rate": 1.581861323490641e-08,
      "loss": 0.0043,
      "step": 16846
    },
    {
      "epoch": 0.9993474908055523,
      "grad_norm": 6.05383825302124,
      "learning_rate": 1.4500395465330873e-08,
      "loss": 0.3691,
      "step": 16847
    },
    {
      "epoch": 0.9994068098232294,
      "grad_norm": 6.724822044372559,
      "learning_rate": 1.318217769575534e-08,
      "loss": 0.0263,
      "step": 16848
    },
    {
      "epoch": 0.9994661288409064,
      "grad_norm": 0.008534606546163559,
      "learning_rate": 1.1863959926179805e-08,
      "loss": 0.0002,
      "step": 16849
    },
    {
      "epoch": 0.9995254478585834,
      "grad_norm": 0.21450850367546082,
      "learning_rate": 1.0545742156604273e-08,
      "loss": 0.0024,
      "step": 16850
    },
    {
      "epoch": 0.9995847668762605,
      "grad_norm": 0.43326255679130554,
      "learning_rate": 9.227524387028738e-09,
      "loss": 0.0047,
      "step": 16851
    },
    {
      "epoch": 0.9996440858939376,
      "grad_norm": 1.9729527235031128,
      "learning_rate": 7.909306617453205e-09,
      "loss": 0.0214,
      "step": 16852
    },
    {
      "epoch": 0.9997034049116147,
      "grad_norm": 0.1423552930355072,
      "learning_rate": 6.59108884787767e-09,
      "loss": 0.0024,
      "step": 16853
    },
    {
      "epoch": 0.9997627239292918,
      "grad_norm": 2.020923376083374,
      "learning_rate": 5.2728710783021366e-09,
      "loss": 0.018,
      "step": 16854
    },
    {
      "epoch": 0.9998220429469687,
      "grad_norm": 5.450830936431885,
      "learning_rate": 3.9546533087266024e-09,
      "loss": 0.0304,
      "step": 16855
    },
    {
      "epoch": 0.9998813619646458,
      "grad_norm": 18.908708572387695,
      "learning_rate": 2.6364355391510683e-09,
      "loss": 0.3904,
      "step": 16856
    },
    {
      "epoch": 0.9999406809823229,
      "grad_norm": 8.89265251159668,
      "learning_rate": 1.3182177695755341e-09,
      "loss": 0.0969,
      "step": 16857
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3122702836990356,
      "learning_rate": 0.0,
      "loss": 0.0239,
      "step": 16858
    }
  ],
  "logging_steps": 1,
  "max_steps": 16858,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 3372,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0418643170605302e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
