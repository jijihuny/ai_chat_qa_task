{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ca74cc-700c-45f0-a5f0-f6c2b2ea6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/qa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    DataCollatorWithPadding,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training, \n",
    "    LoraConfig, \n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae1e82-8f3d-48d5-a8a6-401ea78d82b3",
   "metadata": {},
   "source": [
    "# ë°ì´í„°ì…‹ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4719c5d-6bca-4167-857d-3b7fff887839",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'illuni/illuni-llama-2-ko-7b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo)\n",
    "dataset = load_dataset(\"csv\", data_files=\"/home/jovyan/work/prj_data/open/train.csv\")\n",
    "max_length = 512\n",
    "stride = 128\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.backend_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    pair=\"<s> $A <s> $B </s>\",\n",
    "    special_tokens=[\n",
    "        (\"<s>\", tokenizer.convert_tokens_to_ids(\"<s>\")),\n",
    "        (\"</s>\", tokenizer.convert_tokens_to_ids(\"</s>\"))\n",
    "    ],\n",
    ")\n",
    "def preprocess_function(examples):\n",
    "    questions, contexts, answers = examples[\"question\"], examples[\"context\"], examples[\"answer\"]\n",
    "    def preprocess_text(text):\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    questions = list(map(preprocess_text, questions))\n",
    "    contexts = list(map(preprocess_text, contexts))\n",
    "    answers = list(map(preprocess_text, answers))\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # offset_mapping: [(token1 start, token1 end), (token2 ~, ), ...]\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs['overflow_to_sample_mapping']# inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        # sequence_ids: (token=None, question=0, context=1)\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # ì»¨í…ìŠ¤íŠ¸ì˜ ì‹œì‘ ë° ë§ˆì§€ë§‰ì„ ì°¾ëŠ”ë‹¤.\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "        \n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        \n",
    "        start_char = contexts[sample_idx].find(answer, offset[context_start][0], offset[context_end][1])\n",
    "        end_char = start_char + len(answer)\n",
    "\n",
    "        # ë§Œì¼ ì •ë‹µì´ ì»¨í…ìŠ¤íŠ¸ì— ì™„ì „íˆ í¬í•¨ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ë ˆì´ë¸”ì€ (0, 0)ì„\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì •ë‹µì˜ ì‹œì‘ ë° ë§ˆì§€ë§‰ ì¸ë±ìŠ¤\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "    \n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "# ë°ì´í„° í”„ë ˆì„ì„ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤\n",
    "# preprocess_function(dataset[\"train\"][6])# [15281]\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    batched = True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "# roBERTaì—ì„œëŠ” ì‚­ì œ, BERTì—ì„œëŠ” ì¤‘ìš”í•œ ì—­í• \n",
    "# train_dataset = train_dataset.remove_columns(\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707f8a87-601e-4c2d-b8d1-0583ac597acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: 6ì„¸ëŒ€, labels give: 6ì„¸ëŒ€\n",
      "<s> PM9A3 E1.Sê°€ ê¸°ë°˜í•œ Vë‚¸ë“œëŠ” ëª‡ ì„¸ëŒ€ì¸ê°€<s> ê¸°ë³¸ì ì¸ ë³´ì•ˆ ê¸°ëŠ¥ ë¿ë§Œ ì•„ë‹ˆë¼ ì•ˆí‹°ë¡¤ë°±, ë³´ì•ˆ ë¶€íŒ… ë“± ë‹¤ì–‘í•œ ë³´ì•ˆ ì†”ë£¨ì…˜ì„ ì œê³µí•œë‹¤. ì•ˆí‹°ë¡¤ë°±ì€ ë³´ì•ˆì´ ì·¨ì•½í•œ í•˜ìœ„ ë²„ì „ì˜ íŒì›¨ì–´ê°€ ë‹¤ìš´ë¡œë“œ ë˜ì§€ ëª»í•˜ë„ë¡ ë§‰ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ, PM9A3 E1.SëŠ” ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ëœ íŒì›¨ì–´ì— ëŒ€í•´ì„œëŠ” ì´ë ¥ì„ ë”°ë¡œ ì €ì¥í•´ë†“ê³  í•´ë‹¹ ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•  ê²½ìš° ì •ìƒì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šë„ë¡ ë§‰ëŠ”ë‹¤. ì´ë²ˆ SSDëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í—ˆê°€ë˜ì§€ ì•Šì€ ì ‘ê·¼ì´ ì•ˆë˜ë„ë¡ ì„¤ê³„ë¼ ìˆì§€ë§Œ, ë³´ì•ˆ ë¶€íŒ… ê¸°ëŠ¥ì„ ì¶”ê°€í•´ ë³´ì•ˆì„ ë”ìš± ê°•í™”í–ˆë‹¤. ë³´ì•ˆ ë¶€íŒ…ì€ SSD ë‚´ë¶€ì— ê°–ê³  ìˆëŠ” ì „ìì„œëª…ì„ ë¶€íŒ… ê³¼ì •ì—ì„œ ì²´í¬í•´, ì •ìƒì ìœ¼ë¡œ ì¸ì‹ë˜ëŠ” ê²½ìš°ì—ë§Œ ë¶€íŒ…ì´ ë  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ì‚¼ì„±ì „ì ë©”ëª¨ë¦¬ì‚¬ì—…ë¶€ ìƒí’ˆê¸°íšíŒ€ ë°•ì² ë¯¼ ìƒë¬´ëŠ” \"PM9A3 E1.SëŠ” 6ì„¸ëŒ€ Vë‚¸ë“œ ê¸°ë°˜ìœ¼ë¡œ ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì „ë ¥ íš¨ìœ¨ì„ êµ¬í˜„í•œ NVMe SSDë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ì„¼í„° ê³ ê°ë“¤ì—ê²Œ ìµœì ì˜ ì†”ë£¨ì…˜ì´ ë  ê²ƒ\"ì´ë¼ë©°, \"í–¥í›„ OCPì— ì°¸ì—¬í•œ ë‹¤ì–‘í•œ ê³ ê°ì‚¬ë“¤ê³¼ í˜‘ë ¥í•´ ë°ì´í„°ì„¼í„°ìš© SSD í‘œì¤€ì„ ë§Œë“¤ì–´ ë‚˜ê°ˆ ê²ƒ\"ì´ë¼ê³  ë°í˜”ë‹¤. í˜ì´ìŠ¤ë¶ì˜ OCP SSD ì´ê´„ ë¡œìŠ¤ ìŠ¤í…í¬íŠ¸ëŠ” â€œOCP NVMe í´ë¼ìš°ë“œ SSDëŠ” ìµœê·¼ ë°ì´í„°ì„¼í„°ì˜ ê¸°ìˆ ì  ë‚œì œë¥¼ í•´ê²°í•˜ëŠ”ë° ë§¤ìš° ì¤‘ìš”í•œ ì‹¤ë§ˆë¦¬ë¥¼ ì œì‹œí•´ì¤€ë‹¤â€ë©´ì„œ â€œíŠ¹íˆ ì‚¼ì„±ì „ìì˜ ì´ë²ˆ ì œí’ˆì€ ëŒ€ê·œëª¨ í™•ì¥ì´ í•„ìš”í•œ ë°ì´í„°ì„¼í„° í™˜ê²½ì— ì í•©í•œ SSD ìš”êµ¬ ì‚¬ì–‘ì„ ì¶©ì¡±í•˜ê³  ìˆë‹¤â€ê³  ë°í˜”ë‹¤. ì‚¼ì„±ì „ìëŠ” ì´ë²ˆ PM9A3 E1.S ì–‘ì‚°ì„ ì‹œì‘ìœ¼ë¡œ 5G ì‹œëŒ€ì˜ ë³¸ê²© ê°œë§‰ê³¼ ì´ˆì—°ê²° ë¼ì´í”„ ìŠ¤íƒ€ì¼ë¡œ ë³€í™”í•˜ëŠ” ì‹œëŒ€ì— ë°œë§ì¶° ê¸€ë¡œë²Œ ë°ì´í„°ì„¼í„° ì—…ì²´ë“¤ê³¼ ì§€ì† í˜‘ë ¥í•˜ë©° ì°¨ì„¸ëŒ€ ê¸°ìˆ  í™•ë³´ì™€ í‘œì¤€í™”ë¥¼ ì£¼ë„í•´ ë‚˜ê°ˆ ê³„íšì´ë‹¤.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
     ]
    }
   ],
   "source": [
    "idx = 9\n",
    "sample_idx = train_dataset[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = dataset['train']['answer'][sample_idx]\n",
    "\n",
    "start = train_dataset['start_positions'][idx]\n",
    "end = train_dataset['end_positions'][idx]\n",
    "labeled_answer = tokenizer.decode(train_dataset[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")\n",
    "print(tokenizer.decode(train_dataset[\"input_ids\"][idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51881a81-deed-47c7-aac0-3b998a272c73",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb7b1fd-581d-474a-8797-7fdfaa2c4336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [38:39<00:00, 773.31s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.89it/s]\n",
      "Some weights of LlamaForQuestionAnswering were not initialized from the model checkpoint at illuni/illuni-llama-2-ko-7b and are newly initialized: ['embed_tokens.weight', 'layers.0.input_layernorm.weight', 'layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.post_attention_layernorm.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.input_layernorm.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.post_attention_layernorm.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.input_layernorm.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.post_attention_layernorm.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.input_layernorm.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.post_attention_layernorm.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.input_layernorm.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.post_attention_layernorm.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.input_layernorm.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.post_attention_layernorm.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.input_layernorm.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.post_attention_layernorm.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.input_layernorm.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.post_attention_layernorm.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.input_layernorm.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.post_attention_layernorm.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.input_layernorm.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.post_attention_layernorm.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.input_layernorm.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.post_attention_layernorm.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.input_layernorm.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.post_attention_layernorm.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.input_layernorm.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.post_attention_layernorm.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.input_layernorm.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.post_attention_layernorm.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.input_layernorm.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.post_attention_layernorm.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.input_layernorm.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.post_attention_layernorm.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.input_layernorm.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.post_attention_layernorm.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.input_layernorm.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.post_attention_layernorm.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.input_layernorm.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.post_attention_layernorm.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.26.input_layernorm.weight', 'layers.26.mlp.down_proj.weight', 'layers.26.mlp.gate_proj.weight', 'layers.26.mlp.up_proj.weight', 'layers.26.post_attention_layernorm.weight', 'layers.26.self_attn.k_proj.weight', 'layers.26.self_attn.o_proj.weight', 'layers.26.self_attn.q_proj.weight', 'layers.26.self_attn.v_proj.weight', 'layers.27.input_layernorm.weight', 'layers.27.mlp.down_proj.weight', 'layers.27.mlp.gate_proj.weight', 'layers.27.mlp.up_proj.weight', 'layers.27.post_attention_layernorm.weight', 'layers.27.self_attn.k_proj.weight', 'layers.27.self_attn.o_proj.weight', 'layers.27.self_attn.q_proj.weight', 'layers.27.self_attn.v_proj.weight', 'layers.28.input_layernorm.weight', 'layers.28.mlp.down_proj.weight', 'layers.28.mlp.gate_proj.weight', 'layers.28.mlp.up_proj.weight', 'layers.28.post_attention_layernorm.weight', 'layers.28.self_attn.k_proj.weight', 'layers.28.self_attn.o_proj.weight', 'layers.28.self_attn.q_proj.weight', 'layers.28.self_attn.v_proj.weight', 'layers.29.input_layernorm.weight', 'layers.29.mlp.down_proj.weight', 'layers.29.mlp.gate_proj.weight', 'layers.29.mlp.up_proj.weight', 'layers.29.post_attention_layernorm.weight', 'layers.29.self_attn.k_proj.weight', 'layers.29.self_attn.o_proj.weight', 'layers.29.self_attn.q_proj.weight', 'layers.29.self_attn.v_proj.weight', 'layers.3.input_layernorm.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.post_attention_layernorm.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.30.input_layernorm.weight', 'layers.30.mlp.down_proj.weight', 'layers.30.mlp.gate_proj.weight', 'layers.30.mlp.up_proj.weight', 'layers.30.post_attention_layernorm.weight', 'layers.30.self_attn.k_proj.weight', 'layers.30.self_attn.o_proj.weight', 'layers.30.self_attn.q_proj.weight', 'layers.30.self_attn.v_proj.weight', 'layers.31.input_layernorm.weight', 'layers.31.mlp.down_proj.weight', 'layers.31.mlp.gate_proj.weight', 'layers.31.mlp.up_proj.weight', 'layers.31.post_attention_layernorm.weight', 'layers.31.self_attn.k_proj.weight', 'layers.31.self_attn.o_proj.weight', 'layers.31.self_attn.q_proj.weight', 'layers.31.self_attn.v_proj.weight', 'layers.4.input_layernorm.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.post_attention_layernorm.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.input_layernorm.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.post_attention_layernorm.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.input_layernorm.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.post_attention_layernorm.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.input_layernorm.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.post_attention_layernorm.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.input_layernorm.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.post_attention_layernorm.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.input_layernorm.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.post_attention_layernorm.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight', 'norm.weight', 'qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "print(\"start\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "        repo,\n",
    "        device_map=\"cuda:0\",\n",
    "        torch_dtype=torch.float32,\n",
    "        quantization_config=quantization_config,\n",
    ")\n",
    "print(\"end\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=['up_proj', \n",
    "                    'down_proj', \n",
    "                    'gate_proj', \n",
    "                    'k_proj', \n",
    "                    'q_proj', \n",
    "                    'v_proj', \n",
    "                    'o_proj'],\n",
    "    task_type=\"QUESTION_ANSWERING\"\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "accelerater = Accelerator()\n",
    "model, tokenizer = accelerater.prepare(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943aad63-fa25-4ec8-8646-bf148ab3a325",
   "metadata": {},
   "source": [
    "# Loss ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780df28-a853-4174-952d-a985d5a19db6",
   "metadata": {},
   "source": [
    "# í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3865bb26-e95e-436d-962c-761e35e8603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33muijinkim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/opt/conda/envs/qa/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"llama2\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    num_train_epochs=3,\n",
    "    save_steps=0.1,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=False\n",
    ")\n",
    "\n",
    "# Trainer ì„¤ì •\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19f877-1c71-4268-a9d9-25cae531b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/ai_chat_qa_task/code/test/wandb/run-20240809_173939-xu6yxb8h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uijinkim/huggingface/runs/xu6yxb8h' target=\"_blank\">llama2</a></strong> to <a href='https://wandb.ai/uijinkim/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uijinkim/huggingface' target=\"_blank\">https://wandb.ai/uijinkim/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uijinkim/huggingface/runs/xu6yxb8h' target=\"_blank\">https://wandb.ai/uijinkim/huggingface/runs/xu6yxb8h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/opt/conda/envs/qa/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='17532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   26/17532 05:12 < 63:15:58, 0.08 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df96a95-ab9f-4213-af0c-b2fa9adf242c",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ece9da2-b33f-4de3-aea3-30303f07a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/qa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32004, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "CHECK_POINT = \"/home/jovyan/work/ai_chat_qa_task/code/huggingface/roBERTa/checkpoint-29965\"\n",
    "TEST_fOLDER = '/home/jovyan/work/prj_data/open/test.csv'\n",
    "OUTPUT = \"test\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "csv = pd.read_csv(TEST_fOLDER)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "config = PeftConfig.from_pretrained(CHECK_POINT)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    # quantization_config=quantization_config,\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "# model = PeftModel.from_pretrained(model, CHECK_POINT)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.add_tokens(['ìœ„ì±—', 'ëŒ€ë§Œ ì„œë¶€', 'ë¨€ì˜¤ë¦¬í˜„', '(çˆ­è¨Ÿ)'])\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "592e72dd-2e6f-4398-9e6d-e333db61f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1507 [00:00<?, ?it/s]/tmp/ipykernel_3534194/1748160561.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  logit = torch.nn.functional.softmax(torch.tensor([answer_raw[0][0], answer_raw[1][0], answer_raw[2][0]]))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1507/1507 [07:17<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import yaml\n",
    "TEST_fOLDER = '/home/jovyan/work/prj_data/open/test.csv'\n",
    "csv = pd.read_csv(TEST_fOLDER)\n",
    "\n",
    "def get_prediction(question, context):\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=\"only_second\",\n",
    "        stride=256,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    inputs.pop(\"token_type_ids\")\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # ëª¨ë“  ì²­í¬ì— ëŒ€í•œ start/end ë¡œì§“ ê°€ì ¸ì˜¤ê¸°\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    \n",
    "    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë‹µë³€ ì°¾ê¸°\n",
    "    max_answer_score = [(-float('inf'), \"\")]\n",
    "    best_answer = \"\"\n",
    "\n",
    "    for i in range(len(start_logits)):\n",
    "        start_indexes = torch.argsort(start_logits[i], descending=True)[:3]\n",
    "        end_indexes = torch.argsort(end_logits[i], descending=True)[:3]\n",
    "        \n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # # ë‹µë³€ì˜ ê¸¸ì´ë¥¼ 50 í† í°ìœ¼ë¡œ ì œí•œ\n",
    "                # if end_index < start_index or end_index - start_index + 1 > 50 or end_index - start_index <= 1:\n",
    "                #     continue\n",
    "                # # ë‹µë³€ì´ CLSì¼ë•ŒëŠ” ì œì™¸\n",
    "                # if start_index==0 or end_index==0:\n",
    "                #     continue\n",
    "                \n",
    "                answer_score = start_logits[i][start_index] + end_logits[i][end_index]\n",
    "                best_answer = tokenizer.decode(inputs[\"input_ids\"][i][start_index:end_index+1])\n",
    "                max_answer_score.append((answer_score, best_answer))\n",
    "    max_answer_score.sort(key=lambda x: x[0], reverse=True)\n",
    "    # print(max_answer_score)\n",
    "    return max_answer_score[:3]\n",
    "    \n",
    "submission_list = []\n",
    "for idx, row in tqdm(csv.iterrows(), total=len(csv)):\n",
    "    answer_raw = get_prediction(row['question'], row['context'])\n",
    "    answer = [answer_raw[0][1], answer_raw[1][1], answer_raw[2][1]]\n",
    "    logit = torch.nn.functional.softmax(torch.tensor([answer_raw[0][0], answer_raw[1][0], answer_raw[2][0]]))\n",
    "\n",
    "    submission_dict = {\n",
    "        'id': f'TEST_{idx:04d}',  # IDëŠ” TEST_0000 í˜•ì‹ìœ¼ë¡œ ìƒì„±\n",
    "        'candidates': {\n",
    "            'generated_texts': answer,\n",
    "            'scores': logit.tolist()\n",
    "        }\n",
    "    }\n",
    "    # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    submission_list.append(submission_dict)\n",
    "\n",
    "with open('submission.yaml', 'w', encoding='utf-8') as yaml_file:\n",
    "    yaml.dump(submission_list, yaml_file, allow_unicode=True, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52c3fbe-8a73-4ad9-a91b-e7ec7068b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bert_stride256.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
